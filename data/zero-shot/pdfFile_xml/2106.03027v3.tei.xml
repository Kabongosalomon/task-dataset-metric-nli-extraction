<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Individual Task Accuracies on Split-miniImagenet</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-15">15 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Ramesh</surname></persName>
							<email>rahulram@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
							<email>pratikac@seas.upenn.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Individual Task Accuracies on Split-miniImagenet</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-15">15 Jun 2022</date>
						</imprint>
					</monogr>
					<note>M Z : A G &quot;B &quot; T L C</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Left: How well do existing continual learning methods work in the single-epoch setting?</head><p>We track the average accuracy (over all tasks seen until the current episode) on the Split-miniImagenet dataset. All methods in this plot (unless specified otherwise) are evaluated in the single-epoch setting <ref type="bibr" target="#b33">(Lopez-Paz and Ranzato, 2017)</ref>, i.e., each new task is allowed only 1 epoch of training. We compare our method Model Zoo and its variants (all in bold) to existing continual learning methods designed for the single-epoch setting (faint lines, see <ref type="table">Table 1</ref> for references). Isolated refers to a very simplistic realization of Model Zoo where a separate model is fitted at each episode without any continual learning, or data sharing between tasks; Isolated-small or Model Zoo-small refer to using a very small deep network with 0.12M weights. A number of surprising findings are seen here. (i) Isolated-small (black) outperforms existing methods by more than 10%, while having a faster training time, inference time, comparable model size and without performing any data replay. This indicates that existing methods do not sufficiently leverage data from multiple tasks. This also indicates the utility of simple methods like Isolated to perform a more prosaic, matter-of-fact, evaluation of continual learning. (ii) While the larger model with 3.6M weights per round, Isolated-Single Epoch (royal blue), performs poorly, its accuracy is better than existing methods (Isolated-Multi Epoch) upon being trained for multiple epochs. This indicates that methods may be severely under-trained in the single-epoch setting and this may not be the appropriate setting to build continual learning methods; this was also noticed by Lopez-Paz and Ranzato <ref type="formula">(2017)</ref>. (iii) Model Zoo and Model Zoo-small which replay all data from past tasks (A-GEM also replays 10% of the data), achieves around 10% improvement over its Isolated counterparts in both the single-epoch and multi-epoch setting; Model Zoo has an improved ability to solve each task by leveraging other tasks. This indicates that replaying data from past tasks is beneficial (Robins, 1995), even if replay may not conform to certain stylistic formulations of continual learning in the literature (Farquhar and Gal, 2019a; Kaushik et al., 2021). Not doing so significantly hurts forward and backward transfer, and average task accuracy. Right: Does the single-epoch setting show forward-backward transfer? The evolution of individual task accuracy of Model Zoo (the multi-epoch setting in bold and single-epoch setting in dotted), on the Split-miniImagenet dataset (only 5 tasks are plotted here, see <ref type="figure">Fig. A6 for the full version)</ref>. The X markers denote the accuracy of Isolated. Accuracy of tasks improves with each episode which indicates backward transfer. Also, the X markers are often below the initial accuracy of the task during continual learning, which indicates forward transfer. While both single-epoch and multi-epoch Model Zoo show good forward-backward transfer, the accuracy of tasks for the former is about 25% worse than the latter; corresponding plots for other methods are in Appendix B.6. This indicates that we should also pay attention to under-training and per-task accuracy in continual learning. episode, some use extremely small architectures, etc. We compare Model Zoo with existing methods in a number of these settings. Model Zoo obtains better accuracy than existing methods on the evaluated benchmarks. Improvement in average per-task accuracy is quite large in some cases, e.g., 30% for Split-miniImagenet. We also show that Model Zoo demonstrates strong forward and backward transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A critical look at continual learning</head><p>We find that even an Isolated learner, i.e., one which trains a (small) model on tasks from each episode and does not perform any continual learning, significantly outperforms most existing continual learning methods on the evaluated benchmark problems, e.g., by more than 8% in <ref type="figure">Fig. 1 and Table 1 and ??</ref>. This strong performance is surprising because it is a very simple learner that has better training/inference time, no data replay, and a comparable number of weights as that of existing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A This paper argues that continual learning methods can benefit by splitting the capacity of the learner across multiple models. We use statistical learning theory and experimental analysis to show how multiple tasks can interact with each other in a non-trivial fashion when a single model is trained on them. The generalization error on a particular task can improve when it is trained with synergistic tasks, but can also deteriorate when trained with competing tasks. This theory motivates our method named Model Zoo which, inspired from the boosting literature, grows an ensemble of small models, each of which is trained during one episode of continual learning. We demonstrate that Model Zoo obtains large gains in accuracy on a variety of continual learning benchmark problems. Code is available at https://github.com/grasp-lyrl/modelzoo_continual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">I</head><p>A continual learner seeks to leverage data from past tasks to learn new tasks shown to it in the future, and in turn, leverage data from these new tasks to improve its accuracy on past tasks. It stands to reason that the performance of such a learner would depend upon the relatedness of these tasks. If the two sets of tasks are dissimilar, learning on past tasks is unlikely to benefit future tasks-it may even be detrimental. And similarly, new tasks may cause the learner to "forget" and result in deterioration of accuracy on past tasks. Our goal in this paper is to model the relatedness between tasks and develop new methods for continual learning that result in good forward-backward transfer by accounting for similarities and dissimilarities between tasks. Our contributions are as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Theoretical analysis</head><p>We characterize when multiple tasks can be learned using a single model and, likewise, when doing so is detrimental to the accuracy of a particular task. The key technical idea here is to define a notion of relatedness between tasks. We first show how if the inputs of different tasks are "simple" transformations of each other (and likewise for the outputs), then one can learn a shared feature generator that generalizes better on every task, compared to training that task in isolation. Such tasks are strongly related to each other and therefore it is beneficial to fit a single model on all of them. We show that if tasks are not so strongly related, in particular if the optimal model for one task predicts poorly on another task, then fitting a single model on such tasks may be worse than training each task in isolation. Such tasks compete with each other for the fixed capacity in the single model. We also empirically study this competition using the CIFAR-100 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Algorithm development</head><p>The above analysis suggests that a continual learner could benefit from splitting its learning capacity across sets of synergistic tasks. We develop such a continual learner called Model Zoo. At each episode, a small multi-task model that is fitted to the current task and some of the past tasks is added to Model Zoo. This method is loosely inspired from AdaBoost in that it selects tasks that performed poorly in the past rounds and could therefore benefit the most from being trained with the current task. At inference time, given the task, we average predictions from all models in the ensemble that were trained on that task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Empirical results</head><p>We comprehensively evaluate Model Zoo on existing task-incremental continual learning benchmark problems and show comparisons with existing methods. There is a wide variety in the problem settings used by existing methods, e.g., some replay data from past tasks (like Model Zoo is designed to do), some replay only a subset of data, some train only for one epoch in each Avg. Accuracy (%) <ref type="bibr">SGD (47)</ref> EWC <ref type="formula" target="#formula_12">(48)</ref> AGEM <ref type="formula" target="#formula_3">(52)</ref> ER <ref type="formula">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A</head><p>In this section, we (i) formulate the problem of learning from multiple tasks, (ii) discuss a simple model that highlights when training one model on multiple tasks is beneficial, and (iii) show new results on how the fixed capacity of the model causes competition between tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">P F</head><p>A supervised learning task is defined as a joint probability distribution P (x, y) of inputs x ? X and labels y ? Y . The learner has access to m i.i.d samples S = {x i , y i } i=1,...,m from the task. A hypothesis is a function h : X ? Y with h ? H being the hypothesis space. The learner may select a hypothesis that minimizes the empirical risk</p><formula xml:id="formula_0">e S (h) = 1 m m i=1 1 {h(xi) =yi}</formula><p>with the hope of achieving a small population risk e P (h) = P(h(x) = y).</p><p>Classical PAC-learning results <ref type="bibr" target="#b64">(Vapnik, 1998)</ref> suggest that with probability at least 1 ? ? over draws of the data S, uniformly for any h ? H, we have e P (h) ?? S (h) + if</p><formula xml:id="formula_1">m = O (D ? log ?) 2<label>(1)</label></formula><p>where D = VC(H) is the VC-dimension of the hypothesis space H. We define the "excess risk" of a hypothesis as E P (h) = e P (h) ? inf h?H e P (h).</p><p>In the continual learning setting, a new task is shown to the learner at each episode (or round). Hence after n episodes, the learner is presented with n tasksP := (P 1 , . . . , P n ), with the corresponding training setsS := (S 1 , . . . , S n ), each with m samples, and the learner selects n hypotheses h = (h 1 , . . . , h n ) ? H n , each h i ? H. If it seeks a small average population risk eP (h) = 1 n n i=1 e Pi (h i ), it may do so by minimizing the average empirical risk</p><formula xml:id="formula_2">eS(h) = 1 n n i=1?</formula><p>Si (h i ).</p><p>As <ref type="bibr" target="#b2">Baxter (2000)</ref> shows, under very general conditions, if</p><formula xml:id="formula_3">m = O 1 2 d H (n) ? 1 n log ? ,<label>(2)</label></formula><p>then we have eP (h) ? eS(h) + for anyh ? H n . The quantity d H (n) here is a generalized VC-dimension for the family of hypothesis spaces H n , which depends on the joint distribution of tasks. Larger the number of tasks n, smaller the d H (n) <ref type="bibr" target="#b4">(Ben-David and Borbely, 2008)</ref>. Whether <ref type="formula" target="#formula_3">(2)</ref> is an improvement upon training the task in isolation as in (1) depends upon the hypothesis class H and the relatedness of tasks P 1 , . . . , P n through the quantity d H (n). The most important thing to note here is that according to these calculations, if one wishes to obtain a small average population risk across tasks, training multiple tasks together cannot be worse:</p><formula xml:id="formula_4">d H (n) ? VC(H).</formula><p>This result is the motivation for methods that train multiple tasks together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">C</head><p>An important goal of continual learning is to have low risk on all tasks. This is a stronger requirement than for (2) which bounds the average population risk on all tasks.</p><p>Suppose there exists a family F of functions f i : X ? X that map the inputs of one task to those of another, i.e., any task can be written as</p><formula xml:id="formula_5">P j (A) = f [P i ](A) = P i ({(f (x), y) : (x, y) ? A})</formula><p>for some function f ? F for any set A. We can assume without loss of generality that F acts as a group over the hypothesis space and H is closed under its action. In simple words, this entails that given h ? H suitable for task P , we can obtain a new hypothesis h ? f that is suitable for another task f [P ]. Instead of searching over the entire space H n like in ?2.1, we now only need to find a hypothesis h ? H such that its orbit</p><p>[h] F = {h : ?f ? F with h = h ? f } contains hypotheses that have low empirical risk on each of the n tasks. Conceptually, this step learns the inductive bias <ref type="bibr" target="#b2">(Baxter, 2000;</ref><ref type="bibr" target="#b59">Thrun and Pratt, 2012)</ref>. The sample complexity of doing so is exactly (2). From within this orbit, we can select a hypothesis that has low empirical risk for a chosen task P 1 . The sample complexity of this second step is</p><formula xml:id="formula_6">|S 1 | = O 1 2 (d max ? log ?)<label>(3)</label></formula><p>where d max = sup h?H VC([h] F ). By uniform convergence, as <ref type="bibr" target="#b5">Ben-David and Schuller (2003)</ref> show, this two-step procedure assures low excess risk for every task P 1 , . . . , P n . We have</p><formula xml:id="formula_7">sup h?H VC([h] F ) = d max ? d H (n + 1) ? d H (n) ? D = VC(H).</formula><p>(4) The total sample complexity is favorable to that of learning the task in isolation if both d H (n) and d max are small. For instance, if F is finite and n/ log n ? D, we have d H (n) ? 2 log |F | which indicates that we get a statistical benefit of learning with multiple tasks if D log |F |. Remark 1 (Data from other tasks may not improve accuracy even if they are synergistic). Let us make a few observations using the above analysis. (i) From (4), number of samples per task m decreases with n; this is the benefit of the strong relatedness among tasks and as we see next, this is not the case in general. (ii) The number of tasks scales essentially linearly with D, which indicates that one should use a small model if we have few tasks. (iii) But we cannot always use a small model. If tasks are diverse and related by complex transformations with a large |F |, we need a large hypothesis space to learn them together. If |F | is large and H is not appropriately so, the VC-dimension d max is as large as D itself; in this case there is again no statistical benefit of training multiple tasks together, but there is no deterioration either.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">T</head><p>There could be settings under which fitting one model on multiple tasks may not suffice. To study this, we consider a weaker notion of relatedness. We say that two tasks</p><formula xml:id="formula_8">P i , P j are ? ij -related if c E 1/?ij Pi (h) ? E Pj (h, h * i ), for all h ? H.<label>(5)</label></formula><p>Here E P (h, h ) := e P (h) ? e P (h ) and h * i = argmin h?H e Pi (h) is the best hypothesis for task P i ; we set c ? 1 to be a coefficient independent of i, j. Smaller the ? ij , more useful the samples from P i to learn P j . The definition suggests that all hypotheses h which have low excess risk on P i also have low excess risk on P j up to an additive term e Pj (h * ) and this effect becomes stronger as ? ij ? 1 + . Note that the definition of relatedness is not symmetric. <ref type="bibr" target="#b23">Hanneke and Kpotufe (2020)</ref> call this the transfer exponent. To gain some intuition, we can connect this definition to a certain triangle inequality between the tasks developed by <ref type="bibr" target="#b11">Crammer et al. (2008)</ref>: in the realizable setting where e Pi (h * i ) = 0, for c, ? ij = 1, we can write (5) as e Pi (h) + e Pj (h * i ) ? e Pj (h) which is akin to a triangle with vertices at h, h * i and h * j with terms like e Pi (h) representing the length of the side between h and h * i . This definition therefore models a set of tasks and hypothesis space that is not unduly pathological, e Pj (h) cannot be much worse than the sum of the other two sides. We can now show the following theorem bounds the excess risk E P1 (h) for a hypothesis h trained using data from multiple tasks. See Appendix C for the proof.</p><p>Theorem 2 (Task competition). Say we wish to find a good hypothesis for task P 1 and have access to n tasks P 1 , . . . , P n where each pair P i , P j are ? ij -related. Arrange tasks in an increasing order of ? i1 , i.e., their relatedness to P 1 . Let this ordering be P (1) , P (2) , . . . , P (n) with ? (1) ? ? (2) ? . . . ? ? (n) and P (1) ? P 1 and ? (1) = 1. Let? k be the hypothesis that minimizes the average empirical risk of the first k ? n tasks. Then, with probability at least 1 ? ? over draws of the training data,</p><formula xml:id="formula_9">E P1 (? k ) ? 1 k k i=1 E P1 (h * (i) ) + c k eS(h) + c D?log ? km 1/2 1/?max<label>(6)</label></formula><p>where ? max (k) = max ? (1) , . . . , ? (k) and c, c are constants.</p><p>Notice that the first term grows with the number of tasks k because we pick tasks with lower ? i1 that are more and more dissimilar to P 1 . The second term typically decreases with k. The empirical risk eS(h) is typically small; in our experiments with deep networks we achieve essentially zero training error on all. Increasing the number of tasks k, increases the effective number of samples km, thereby reducing the second term in totality. At the same time, these new samples are increasingly more inefficient because ? max (k) increases with k.</p><p>Remark 3 (Picking the size of the hypothesis space). The first and second terms characterize synergies and competition between tasks and balancing them is the key to good performance on a given task. Increasing the size of the hypothesis space reduces the first term since it allows a single hypothesis to more easily agree on two distinct distributions P i and P j . However, this comes at the cost of increasing the second term which grows with the size of the hypothesis space.</p><p>Remark 4 (The set of synergistic tasks can be different for different tasks). The right hand side in <ref type="formula" target="#formula_9">(6)</ref> is minimized for a choice of k (where 1 ? k ? n) that balances the first and second terms. The optimal k can vary with the task, e.g., a small optimal k indicates task dissonance, where the particular task, say P 1 should be trained with a specific set of other tasks. Even for typical datasets like CIFAR-100, it is highly nontrivial to understand the ideal set of tasks to train with; <ref type="figure" target="#fig_1">Fig. 2</ref> studies this experimentally.</p><p>Remark 5 (Continual learning is particularly challenging due to task competition). Theorem 2 indicates that not only is the learner shown tasks sequentially, but it also may have to work against the competition between the current task and the representation learned on a past task. It does not have access to synergistic tasks from the future while learning on the current task. And further, in settings where there is no data replay, the learner cannot benefit from past synergistic tasks explicitly, other than the representation that it has already learnt. This suggests that one must be even more careful about how the representation in continual learning should be updated.  In order to demonstrate how some tasks help and some tasks hurt each other, we run a multi-task learner for a varying number of tasks (X-axis) and track the accuracy on a few tasks from CIFAR100 (each task is a superclass). Each cell represents a different experiment, i.e, there is no continual learning being performed here. Cells are colored warm if accuracy is worse than the median accuracy of that row. For instance, multi-task training with 11 tasks is beneficial for "Man-made Outdoor" but accuracy drops drastically upon introducing task #12, it improves upon introducing #14, while task #17 again leads to a drop. One may study the other rows to reach a similar conclusion: there is non-trivial competition between tasks, even in commonly used datasets. As we show, tackling this effectively is the key to obtaining good performance on continual learning problems. See Appendix B.1 for a more elaborate version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">M Z : A</head><p>Theorem 2 can be thought of as a "no free lunch theorem". It indicates that one should not always expect improved excess risk by combining data from different tasks. This theorem also suggests a way to work around the problem via Remarks 3 and 4. If we learn small models on synergistic tasks, we can hope to have each task benefit from the synergies without deterioration of accuracy due to task competition with dissonant tasks. Model Zoo is a simple method that is designed for this purpose.</p><p>Let us assume that tasks P 1 , . . . , P n are shown sequentially to the continual learner. We assume that all tasks have the same input domain X but may have different output domains Y 1 , . . . , Y n . At each "episode" k, Model Zoo is designed to train using the current task P k and a subset of the past tasks. For example, at episode k = 2, we train a model with a feature generator h and task-specific classifiers to obtain models g 1 ? h : X ? Y 1 and g 2 ? h : X ? Y 2 . This model can classify inputs from both tasks and gives out a probability vector p gi?h (y | x), ?y ? Y i depending upon the task. We assume that the identity of the task is known at the test time.  Let the set of tasks considered at episode k be denoted b?</p><formula xml:id="formula_10">P k = {P ? 1 k , . . . , P ? b k } where b ? k is a hyper-parameter and ? i k ? {1, . . . , k}.</formula><p>Training onP k will involve, like the example above, training one model with a feature generator h k and task-specific classifiers g k,? i k for each task selected in that round. Such models, one trained in each round, together form the "Model Zoo". After k rounds, data from, say, P i with i ? k can be predicted using the average of class probabilities output by all models that were fitted on that task, i.e.,</p><formula xml:id="formula_11">p k,i (y | x) ? k l=1 1 {Pi?Pl} g l,i ? h l (x).<label>(7)</label></formula><p>This expression is also used to predict at test time.</p><p>Selecting tasks to train with for each round using boosting In principle, we could use the transfer exponents ? ij to select synergistic tasks, but computing the transfer exponents is essentially as difficult as training on all tasks, a continual learner does not have access to all tasks a priori. We therefore develop an automatic way to select tasks in each round. We draw inspiration from boosting <ref type="bibr" target="#b54">(Schapire and Freund, 2013)</ref> for this purpose. Recall the AdaBoost algorithm which builds an ensemble of weak learners (they can be any learner in principle <ref type="bibr" target="#b37">Mason et al. (1999)</ref>), each of which is fitted upon iteratively re-weighted training data <ref type="bibr" target="#b6">(Breiman, 1998)</ref>. We think of the models learned at each episode of continual learning in Model Zoo as the "weak learners" and each round of boosting as the equivalent of each episode of continual learning. Letw k ? R n be a normalized vector of task-specific weights. After episode k</p><formula xml:id="formula_12">w k,i ? exp ?1/m (x,y)?Si log p k,i (y | x) .<label>(8)</label></formula><p>for each task P i with i ? k; for i &gt; k,w k,i = 0. Tasks for the next roundP k+1 are drawn from a multinomial distribution with weightsw k . Therefore, tasks with a low empirical risk under the current Model Zoo get a low weight for the next boosting round. Just like AdaBoost drives down the training error on all samples to zero exponentially <ref type="bibr" target="#b54">(Schapire and Freund, 2013)</ref> by iteratively focusing upon difficult-to-classify samples, Model Zoo achieves a low empirical risk on all tasks as more models are added.</p><p>The key feature of Model Zoo is that it automatically splits the capacity across sets of tasks. Even if competing tasks are chosen in one round, which may result in high excess risk on some task, it will be chosen again in future rounds if it has a large error under the ensemble. Colloquially speaking, the ensemble in Model Zoo represents a "brain" that grows its learning capacity continually as more tasks are shown to it. Remark 6 (Assumptions in the formulation of Model Zoo). We assume that, both at training time and test time, the identity of the task is known to the continual learner. Data from past tasks is also stored with the task identity. This is known as the task-incremental setting in the literature (Van de <ref type="bibr" target="#b62">Ven and Tolias, 2019)</ref>. Recent work in continual learning also studies settings where such task identity is not known, e.g., <ref type="bibr" target="#b25">(Kaushik et al., 2021)</ref>, Model Zoo is not designed to handle such settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">E V 4.1 S</head><p>Datasets We evaluate on Rotated-MNIST (Lopez-Paz and Ranzato, 2017), Split-MNIST <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref>, Permuted-MNIST <ref type="bibr" target="#b27">(Kirkpatrick et al., 2017)</ref>, Split-CIFAR10 <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref>, Split-CIFAR100 * <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref>, Coarse-CIFAR100 <ref type="bibr" target="#b52">(Rosenbaum et al., 2017;</ref><ref type="bibr" target="#b71">Yoon et al., 2019;</ref><ref type="bibr" target="#b56">Shanahan et al., 2021)</ref> and Split-miniImagenet <ref type="bibr" target="#b66">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b10">Chaudhry et al., 2019b)</ref>. Split-MNIST, Split-CIFAR10, Split-CIFAR100 and Split-miniImagenet use consecutive groups of labels (2, 2, 5 and 10, respectively) to form tasks. Coarse-CIFAR100 is a variant of CIFAR100 where each super-class is considered a different task <ref type="bibr" target="#b71">(Yoon et al., 2019;</ref><ref type="bibr" target="#b56">Shanahan et al., 2021)</ref>. Our study in <ref type="figure" target="#fig_1">Fig. 2</ref> has found that Coarse-CIFAR100 is a difficult dataset for continual learning, perhaps because of the semantic differences among the different super-classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural architectures and training methodology</head><p>We use a small wide-residual network of Zagoruyko and Komodakis (2016) (WRN-16-4 with 3.6M weights) with task-specific classifiers (one fully-connected layer). We also use an even smaller network (0.12M weights) with 3 convolution layers (kernel size 3 and 80 filters) interleaved with max-pooling, ReLU, batch-norm layers, with task-specific classifier layers. Stochastic gradient descent (SGD) with Nesterov's momentum and cosine-annealed learning rate is used to train all models in mixed precision. Ray Tune <ref type="bibr" target="#b31">(Liaw et al., 2018)</ref> was used for hyper-parameter tuning using a multi-task learning model on all tasks from Coarse CIFAR-100. When we do full replay, Model Zoo samples b = min(k, 5) tasks at the k th episode; for problems with n = 5 tasks, we set b = 2; note that b = 1 indicates no data replay. All hyper-parameters are kept fixed for all datasets and all experiments (see ?4.2).</p><p>See Appendix A for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">E</head><p>There is a wide variety of problem formulations in the continual learning literature <ref type="bibr" target="#b17">(Farquhar and Gal, 2019a;</ref><ref type="bibr" target="#b46">Prabhu et al., 2020;</ref><ref type="bibr" target="#b67">Vogelstein et al., 2020;</ref><ref type="bibr" target="#b33">Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b62">Van de Ven and Tolias, 2019)</ref>. Formulations vary with respect to whether they allow replaying data from past tasks, the number of epochs the learner is allowed to train each task for, and the capacity of the model being fitted. We next explain these different formulations, the rationale behind them, and how we execute Model Zoo to conform to each of these settings.</p><p>(i) The strict formulation, e.g., <ref type="bibr" target="#b27">Kirkpatrick et al. (2017)</ref>; <ref type="bibr" target="#b25">Kaushik et al. (2021)</ref>, does not allow any replay of data. For the strict formulation of Model Zoo, we simply setw k,i = 0 for all i = k in (8). At each episode, a single model is trained on the current task and added to the zoo-we call this rather simplistic learner Isolated. From a practical standpoint, such a formulation imposes a constraint on the amount of computational resources (compute and/or memory) available during training. (ii) One can replay data to various degrees, e.g., all of it <ref type="bibr" target="#b43">(Nguyen et al., 2017;</ref><ref type="bibr" target="#b21">Guo et al., 2020b)</ref>, or a subset of it <ref type="bibr" target="#b9">(Chaudhry et al., 2019a)</ref>. Just like AdaBoost, Model Zoo is fundamentally designed to allow full replay of past tasks. However, we can easily execute it with limited replay by only using a subset of the data to compute gradient updates and also the accuracy on past tasks in the k th episode. We use the nomenclature Model Zoo (10% replay) to indicate that only 10% of the data from past tasks is used; algorithms like A-GEM <ref type="bibr" target="#b9">(Chaudhry et al., 2019a</ref>) also use 10% of past data on CIFAR100 datasets. See Appendix A.4 for implementation details. Note that Model Zoo without any data replay is * Some works <ref type="bibr" target="#b48">(Rebuffi et al., 2017a;</ref><ref type="bibr" target="#b33">Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b9">Chaudhry et al., 2019a;</ref><ref type="bibr" target="#b40">Mirzadeh et al., 2020b</ref>) evaluate on a split of the CIFAR100 dataset where each task is random subset of 5 classes. We do not evaluate on this variant because it is difficult to exactly reproduce the composition of tasks; as <ref type="figure" target="#fig_1">Fig. 2</ref> suggests different compositions can have vastly different task accuracy. This is also highlighted by large differences in the accuracy on Split-CIFAR100 and Coarse-CIFAR100 in our work. simply Isolated. Let us emphasize that across all these problem settings, Model Zoo remains a legitimate continual learner because it gets access to each task sequentially and has a fixed computational budget (b tasks) at each episode. For a multi-task learner, the computational complexity scales with the number of tasks. (iii) To impose a strict constraint on the computational complexity of each episode some works, e.g., <ref type="bibr" target="#b9">Chaudhry et al. (2019a)</ref>, train each task for a single epoch. We therefore show results using both Model Zoo (single epoch) (where we replay past data for 1 epoch) and Isolated (single epoch) (no replay). Even if the rationale behind using each datum only once is well-taken, one single epoch is quite insufficient to train modern deep networks; if one thinks of biological considerations, local-descent algorithms like stochastic gradient descent (SGD) are quite different from recurrent circuits in the biological brain <ref type="bibr" target="#b26">(Kietzmann et al., 2019)</ref>. We also run single epoch methods using a very small model (0.12M weights); these are Model Zoo/Isolated-small (single epoch). (iv) Multi-Head trains one single model on all tasks to minimize the average empirical risk with task-specific classifiers; mini-batches contain samples from different tasks. Since Multi-Head is trained on all tasks together, it is not a continual learner, but its accuracy is expected to be an upper bound on the accuracy of continual learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation criteria</head><p>We compare algorithms in terms of the validation accuracy averaged across all tasks at the end of all episodes, average per-task forward transfer (accuracy on a new task when it is first seen, larger this number more the forward transfer), average per-task forgetting (gap in the maximal accuracy of a task during continual learning and its accuracy at the end, larger this number more the forgetting and worse the backward transfer), training and inference time, and memory. Let us note that forward transfer is also sometimes called "learning accuracy" <ref type="bibr" target="#b50">(Riemer et al., 2018)</ref>, and another measure of backward transfer is the gap between the accuracy at the end of training and the initial accuracy of the task. <ref type="table" target="#tab_4">Table 1</ref> shows the validation accuracy of different continual learning methods on standard benchmark problems. There are many striking observations here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">R</head><p>(i) Accuracy of existing methods compared to in <ref type="table" target="#tab_4">Table 1</ref> (see ?? as well) is poorer than Isolated. This is surprising because Isolated can be thought of as the simplest possible continual learner-one that unfreezes new capacity at each episode and does not replay data. This indicates that existing methods may be failing to achieve forward or backward transfer compared to simply training the task in isolation; <ref type="table" target="#tab_3">Table 2</ref> investigates this further. (ii) In comparison, Model Zoo (all three variants: small, small with 10% data replay and the standard method) has better accuracy compared to both existing methods as well as Isolated. This shows the utility of splitting the capacity of the learner across multiple tasks. (iii) Model Zoo matches the accuracy of the multi-task learner in the last row of <ref type="table" target="#tab_4">Table 1</ref> which has access to all tasks beforehand. Surprisingly, Model Zoo performs better than Multi-Head in spite of being trained in continual fashion, especially on harder problems like Coarse-CIFAR100 and Split-miniImagenet. This is a direct demonstration of the effectiveness of Model Zoo in mitigating task competition: the capacity splitting mechanism not only avoids catastrophic forgetting, but it can also leverage data from other tasks even if they are shown sequentially.   <ref type="table" target="#tab_3">Table 2</ref>. Note: * indicates that the evaluation was on Split-CIFAR100 with each task containing randomly sampled labels and is hence it is not directly comparable to other methods. All numbers without a marker are from the paper cited in the first column. ? denotes that the accuracy is not from the original paper but from one of <ref type="bibr" target="#b43">(Nguyen et al., 2017;</ref><ref type="bibr" target="#b55">Serra et al., 2018;</ref><ref type="bibr" target="#b9">Chaudhry et al., 2019a)</ref>. Numbers for other methods on Split-MiniImagenet were computed by us using open-source implementations of the original authors.</p><p>(ii) If our methods are implemented in the multi-epoch setting, then the forward transfer is exceptionally good and almost as good as the average accuracy of the task. Surprisingly, this does not come at the cost of forgetting, which is again essentially zero.</p><p>(iii) Even if Model Zoo and its variants are implemented with very small models (0.12M weights/episode, which is 2.42M weights/20 episodes), the accuracy is better <ref type="table" target="#tab_4">(Table 1)</ref>. This suggests that Model Zoo is a performant and viable approach to continual learning. In fact, even the larger model used in Model Zoo is a WRN-16-4 with 3.6M weights and therefore we can train multiple models on the same GPU easily; this is why the training time of Model Zoo is about the same as that of Model Zoo-small.</p><p>(iv) The simplicity of Model Zoo and its variants results in much smaller training times and comparable inference times as compared to existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">R W</head><p>Theoretical work on learning from multiple tasks Works such as Baxter <ref type="formula" target="#formula_3">(2000)</ref>    <ref type="table" target="#tab_3">Table 2</ref> and <ref type="table" target="#tab_4">Table 1</ref> as far as comparison to other methods is concerned. Accuracy is roughly the same on Split-CIFAR100 across varying degrees of replay while it improves significantly on Split-miniImagenet; this suggests that Model Zoo also works with very small amounts of data replay. Accuracy on Split-CIFAR100 is consistent as the number of replay tasks is changed but increases on larger datasets like Split-miniImagenet where there are many more tasks. Finally, the performance of Model Zoo is not merely an artifact of ensembling. Even if Isolated is a strong model, a very large ensemble of Isolated compares poorly to Model Zoo with 100% replay; this indicates that Model Zoo can effectively leverage data from past tasks without forgetting. See the Appendix for more ablation studies.</p><p>task-specific classifiers are diverse enough. It is also appreciated that such a shared feature generator may not exist for dissimilar tasks. So a different perspective on the problem can found in <ref type="bibr" target="#b11">Crammer et al. (2008)</ref>; Ben-David et al. <ref type="formula" target="#formula_1">(2010)</ref>; Ben-David and Borbely (2008) who show that learning diverse tasks requires a larger feature generator and, thereby, more samples; we discuss this in ?2.2. We build upon <ref type="bibr" target="#b22">Hanneke and Kpotufe (2019;</ref> to construct the transfer exponent in ?2; their work shows that even in very favorable settings, e.g., when all tasks have the same optimal classifier, having access to a large number of tasks may not help. Model Zoo is strongly influenced from these results and we think of it as essentially a way to circumvent them.</p><p>There are a number of algorithmic tools to estimate task relatedness, e.g., <ref type="bibr" target="#b15">(Evgeniou et al., 2005;</ref><ref type="bibr" target="#b7">Cavallanti et al., 2010;</ref><ref type="bibr" target="#b28">Kumar and Daume III, 2012)</ref>, and although such methods are popular in transfer learning <ref type="bibr" target="#b45">(Pentina and Lampert, 2015;</ref><ref type="bibr" target="#b24">Jaakkola and Haussler, 1999)</ref>, one cannot apply them in continual learning because we do not know the tasks beforehand. As ?2 shows, task relatedness is critical to good learning. So, taking inspiration from AdaBoost <ref type="bibr" target="#b54">(Schapire and Freund, 2013)</ref>, Model Zoo uses a simple indicator of which past tasks can benefit from future ones, these are the ones with low accuracy under the current ensemble.</p><p>Catastrophic forgetting has been the focus of a number of continual learning techniques, e.g., episodic memory-based ones <ref type="bibr" target="#b33">(Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b9">Chaudhry et al., 2019a;</ref><ref type="bibr" target="#b16">Farajtabar et al., 2020;</ref><ref type="bibr" target="#b20">Guo et al., 2020a)</ref>, data replay <ref type="bibr" target="#b51">(Robins, 1995;</ref><ref type="bibr" target="#b57">Shin et al., 2017;</ref><ref type="bibr" target="#b29">Lee et al., 2017)</ref>, new architectures <ref type="bibr" target="#b55">(Serra et al., 2018)</ref>, generative replay-based <ref type="bibr" target="#b42">(Mocanu et al., 2016;</ref><ref type="bibr" target="#b57">Shin et al., 2017;</ref><ref type="bibr" target="#b32">Liu et al., 2020;</ref><ref type="bibr" target="#b65">Ven et al., 2020)</ref>, ensemble-based <ref type="bibr" target="#b1">(Aljundi et al., 2017;</ref><ref type="bibr" target="#b68">Wen et al., 2020)</ref> and methods that select locally-redundant directions in the weight space <ref type="bibr" target="#b27">(Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b0">Aljundi et al., 2018;</ref><ref type="bibr" target="#b73">Zenke et al., 2017;</ref><ref type="bibr" target="#b8">Chaudhry et al., 2018)</ref>. Variational methods, e.g., <ref type="bibr" target="#b43">(Nguyen et al., 2017;</ref><ref type="bibr" target="#b18">Farquhar and Gal, 2019b)</ref>, sequentially update a posterior over the weights and have an elegant foundation in Bayesian methods but implementing them for large datasets remains a challenge.</p><p>In spite of intense activity, an effective solution to forgetting remains largely unknown.</p><p>Model Zoo embraces the fact that forgetting is a fundamental phenomenon of learning multiple tasks and therefore splitting the capacity may be essential; our results indicate that this approach is effectively at tackling forgetting. This approach also significantly improves other key metrics, e.g., forward-backward transfer and computational complexity of training and inference that have received limited attention <ref type="bibr" target="#b13">(D?az-Rodr?guez et al., 2018)</ref>. Let us note that Model Zoo is designed for the task-incremental continual learning setting (Van de <ref type="bibr" target="#b62">Ven and Tolias, 2019)</ref>.</p><p>Parameter sharing/isolation A single shared feature generator (i.e., hard parameter sharing) is a popular architecture <ref type="bibr" target="#b27">(Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b33">Lopez-Paz and Ranzato, 2017;</ref><ref type="bibr" target="#b48">Rebuffi et al., 2017a;</ref><ref type="bibr" target="#b43">Nguyen et al., 2017;</ref><ref type="bibr" target="#b40">Mirzadeh et al., 2020b;</ref><ref type="bibr" target="#b10">Chaudhry et al., 2019b)</ref>. It has been recognized that this is not sufficient; this has given rise to methods for soft-parameter sharing that either design or learn specialized routing architectures <ref type="bibr" target="#b52">(Rosenbaum et al., 2017;</ref><ref type="bibr" target="#b58">Sun et al., 2019;</ref><ref type="bibr" target="#b19">Fernando et al., 2017;</ref><ref type="bibr" target="#b12">Devin et al., 2017;</ref><ref type="bibr" target="#b41">Misra et al., 2016;</ref><ref type="bibr" target="#b63">Vandenhende et al., 2019)</ref>. Model Zoo is a very simplistic instantiation of parameter isolation, or growing <ref type="bibr" target="#b53">(Rusu et al., 2016;</ref><ref type="bibr" target="#b69">Xu and Zhu, 2018)</ref>. Model Zoo trains on one episode and never updates the model again but its accuracy does play a role in determining whether a new model should be used for that past task, or not. To extend the analogy, just like soft-parameter sharing architectures use, say gradient conflict <ref type="bibr" target="#b0">(Aljundi et al., 2018)</ref> or attention <ref type="bibr" target="#b55">(Serra et al., 2018)</ref>, to determine which synapses to share, Model Zoo uses the training loss of the ensemble to decide what task the new model should be trained upon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">D</head><p>Continual learning is an important problem as deep learning systems transition from the traditional paradigm of having a fixed model that makes inferences on user queries to settings where we would like to update the model to handle new types of queries. The key desiderata of such a system are clear: it must display high per-task accuracy and strong forward-backward transfer. This paper seeks to develop such a continual learner and investigates the problem using the lens of task relatedness. It argues that the learner must split its capacity across sets of tasks to mitigate competition between tasks and benefit from synergies among them. We develop Model Zoo, which is a continual learning algorithm inspired by AdaBoost, that grows an ensemble of models, each of which is trained on data from the current episode along with a subset of past tasks. We show that across a wide variety of datasets, problem formulations, and evaluation criteria, Model Zoo and its variants outperform existing continual learning methods. We also show that a simple baseline method, where a separate, small model is trained independently in each episode, outperforms a number of existing continual methods. Appendix D discusses these results further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A D A.1 D</head><p>We performed experiments using the following datasets.</p><p>1. Rotated-MNIST (Lopez-Paz and Ranzato, 2017) uses the MNIST dataset to generate 5 different 10-way classification tasks. Each task involves using the entire MNIST dataset rotated by 0, 10, 20, 30, and 40 degrees, respectively. 2. Permuted-MNIST <ref type="bibr" target="#b27">(Kirkpatrick et al., 2017)</ref> involves 5 different 10-way classification tasks with each task being a different permutation of the input pixels. The first task is the original MNIST task as is convention. All other tasks are distinct random permutations of MNIST images. 3. Split-MNIST <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref> has 5 tasks with each task consisting of 2 consecutive labels (0-1, 2-3, 4-5, 6-7, 8-9) of MNIST. 4. Split-CIFAR10 <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref> has 5 tasks with each task consisting of 2 consecutive labels (airplane-automobile, bird-cat, deer-dog, frog-horse, ship-truck) of CIFAR10. 5. Split-CIFAR100 <ref type="bibr" target="#b73">(Zenke et al., 2017)</ref> has 20 tasks with each task consisting of 5 consecutive labels of CIFAR100. See the original paper for the exact constitution of each task. 6. Coarse-CIFAR100 <ref type="bibr" target="#b52">(Rosenbaum et al., 2017;</ref><ref type="bibr" target="#b71">Yoon et al., 2019)</ref> has 20 tasks with each task consisting of 5 labels. The tasks are based on an existing categorization of classes into super-classes (https://www.cs.toronto.edu/ kriz/cifar.html). 7. Split-miniImagenet <ref type="bibr" target="#b66">(Vinyals et al., 2016</ref>) is a variant introduced in Chaudhry et al. <ref type="formula" target="#formula_1">(2019b)</ref>, consisting of 20 tasks, with each task consisting of 10 consecutive labels. We merge the meta-train and meta-test categories to obtain a continual learning problem with 20 tasks. Each task containing 10 consecutive labels and 20% of the samples are used as the validation set.</p><p>The CIFAR10 and CIFAR100-based datasets consist of RGB images of size 32?32 while MNISTbased datasets consist of images of size 28?28. The Mini-imagenet dataset consists of RGB images of size 84?84.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 A</head><p>We use the Wide-Resnet (Zagoruyko and Komodakis, 2016) architecture for some of our experiments. The final pooling layer is replaced with an adaptive pooling layer in order to handle input images of different sizes. Convolutional layers are initialized using the Kaiming-Normal initialization. The bias parameter in batch normalization is set to zero with the affine scaling term set to one. The bias of the final classification layer is also set to zero; this helps keep the logits of the different tasks on a similar scale.</p><p>To ensure that the number of weights is similar to those in other methods, we also consider a smaller convolution neural network consisting of 3 convolution layers, with batch-normalization, ReLU and max-pooling present between each layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 T</head><p>Optimization All models are trained in mixed-precision (32-bit weights, 16-bit gradients) using Stochastic Gradient Descent (SGD) with Nesterov's acceleration with momentum coefficient set to 0.9 and cosine annealing of the learning rate schedule for 200 epochs. Training of any model with multiple tasks involves mini-batches that contain samples from all tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameter optimization</head><p>We used Ray Tune <ref type="bibr" target="#b31">(Liaw et al., 2018)</ref> for hyper-parameter optimization. The Async Successive Halving Algorithm (ASHA) scheduler <ref type="bibr" target="#b30">(Li et al., 2018</ref>) was used to prune hyper-parameter choices with the search space determined by Nevergrad <ref type="bibr" target="#b47">(Rapin and Teytaud, 2018)</ref>. The mini-batch size was varied over <ref type="bibr">[8,</ref><ref type="bibr">16,</ref><ref type="bibr">32,</ref><ref type="bibr">64]</ref>; the logarithm (base 10) of the learning rate was sampled from a uniform distribution on [?4, ?2]; dropout probability was sampled from a uniform distribution on [0.1, 0.5]; logarithm of the weight decay coefficient was sampled from [?6, ?2]. We used a set of experiments for continual learning on the Coarse-CIFAR100 dataset with different samples/class (100 and 500) to perform hyper-parameter tuning.</p><p>The final values of training hyper-parameters that were chosen are, learning-rate of 0.01, mini-batch size of 16, dropout probability of 0.2 and weight-decay of 10 ?5 .</p><p>Model Zoo uses b = min(k, 5) at each round of continual learning where n is the number of tasks; for tasks with only 5 tasks (MNIST-variants) we use b = 2. We did not tune these two hyper-parameters using Ray because it is quite cumbersome to do so. We selected these values manually across a few experiments; changing them may result in improved accuracy for Model Zoo.</p><p>All hyper-parameters are kept fixed for all datasets, architectures, and experimental settings . We are interested in characterizing the performance of Model Zoo and its variants across a broad spectrum of problems and datasets. While we believe we can get even better numerical accuracy, by tuning hyper-parameters specially for each problem, we do not so for the sake of simplicity. As the main paper discusses, we outperform existing methods quite convincingly across the board in both multi-task and continual learning.</p><p>Data augmentation MNIST and CIFAR10/100 datasets use padding (4 pixels) with random cropping to an image of size 28?28 or 32?32 respectively for data augmentation. CIFAR10/100 images additionally have random left/right flips for data augmentation. Images are finally normalized to have mean 0.5 and standard deviation 0.25. Split-miniImagenet uses the same augmentation as CIFAR-10 and CIFAR-100. We use augmentations even in the single epoch setting, although it is not beneficial to do so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 M Z L R</head><p>As discussed in ?4.2, this work considers Model Zoo (10%) which stores only 10% of the data from the past tasks, in order to compare to other methods that make use of limited replay. When the task (say task A) is first seen, Model Zoo is allowed to use all available data. For all future episodes, if Model Zoo picks a past task to retrain with, such a retraining uses only a fixed subset of the tasks' data (10% of the samples are selected at random for this purpose). We sample each mini-batch to contain an equal number of samples from all past and current task. At inference time, the member of Model Zoo that is trained on all data of task A (this is the model that was fitted when task A was first shown to the continual learner) is assigned a proportionately larger weight in Eq. <ref type="formula" target="#formula_11">(7)</ref>. For 10% replay, this will amount to 10 ? larger weight than other models which used 10% data from task A. Mathematically, both of these training and inference modifications are equivalent to using coefficients that scale up the loss of the past task depending upon the number of samples that it has.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 E T I T</head><p>In this section, we describe the methodology used to estimate training and inference times reported in <ref type="table" target="#tab_3">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference time</head><p>The column titled inference time corresponds to per-sample prediction latency in milli-seconds. All entries for inference time in <ref type="table" target="#tab_3">Table 2</ref> were computed by us on an Nvidia V100 GPU and therefore they can be compared directly with each other. Note that inference times can be computed using only the architecture built by each method at the end of all continual learning episodes. We  <ref type="formula" target="#formula_8">(5)</ref>. Although most pairs benefit each other (green), certain tasks, e.g., "Food Container" are best trained in isolation while others such as "Aquatic Mammals" are typically detrimental to most other tasks. One can study this matrix and identify many more such properties. In summary, whether tasks aid or hurt each other is quite nuanced even for CIFAR100. since this paper reports the sum of training times of 5 different runs). <ref type="bibr" target="#b9">Chaudhry et al. (2019a)</ref> also report the training time for naive fine-tuning (21 mins) which in theory, should be very similar to the training time of our Isolated learner (the training time for us is 20.76 mins on one V100 GPU). Since the two numbers are quite similar, we can estimate training time of the other continual learning methods using their computational cost relative to naive fine-tuning. Therefore, the estimate of the training times that we have reported in <ref type="table" target="#tab_3">Table 2</ref> can be compared to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A E B.1 U</head><p>To understand which tasks aid each other's learning and which compete for capacity and may thereby deteriorate performance, we investigated the Coarse-CIFAR100 dataset extensively. We first computed the pairwise task competition by comparing the relative gain/drop in classification accuracy of each pair of tasks when the row task is trained in isolated versus training the row and column tasks together using a simple multi-task learner (Multi-Head). <ref type="figure" target="#fig_4">Fig. A1</ref> discusses the results. <ref type="figure" target="#fig_1">Fig. A2</ref>, is the extended version of <ref type="figure" target="#fig_1">Fig. 2</ref>. It shows the validation accuracy of each task (along a single row) as more tasks are added to Multi-Head. Each column is a single Multi-Head model trained on a subset of tasks from scratch. As more tasks are added, the accuracy of most tasks increase However, the increase is not monotonic with each added task, and if one follows a particular row, there are non-trivial patterns wherein adding a particular task may deteriorate the performance on the row task Accuracy of task <ref type="figure" target="#fig_1">Figure A2</ref>: In order to demonstrate how some tasks help and some tasks hurt each other, we train a number of multi-task learners for a varying number of tasks (X-axis) and track the accuracy on each of the tasks from Coarse-CIFAR100 (100 samples/label for each task). The order of tasks is the same for rows (top to bottom) and the columns (left to right). In other words, the first cell (the diagonal) indicates the accuracy of the task trained by itself in isolation (Isolated). Cells are colored warm if accuracy is worse than the median accuracy of that row. For instance, multi-task training with 11 tasks is beneficial for "Man-made Outdoor" but accuracy drops drastically upon introducing task #12, it improves upon introducing #14, while task #17 again leads to a drop. One may study the other rows to reach a similar conclusion: there is non-trivial competition between tasks, even in commonly used datasets. Tackling this issue effectively is the key to obtaining good performance on multi-task learning problems and adding some other task later may recover the lost accuracy. This is a direct demonstration of the tussle between the task competition term (first) and the concentration term (third) in Theorem 2. This indicates that training on the appropriate set of tasks is crucial to learn from multiple tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 C</head><p>Next, we investigated such task competition on other continual learning datasets, namely, Permuted-MNIST, Rot-MNIST, Split-CIFAR10, and Split-MNIST. It is clear from <ref type="figure">Fig. A3</ref> that there is very little competition in this case. Either the tasks are quite different from each other (like the case of Permuted-MNIST), or they are synergistic (most cells are green), or they do not hurt each other's performance, i.e., they may correspond to the model in ?2.2. Note that Rotated-MNIST exactly corresponds to the multi-view setting discussed in ?2.2 were different input images are simple transformations of each other. Split-MNIST <ref type="figure">Figure A3</ref>: Each row is the relative increase/decrease (green/red) in accuracy of a two task multi-task learner compared to training on the task corresponding to the particular row in isolation; all entries are computed using 100 samples/class. Cells are colored green for accuracy gained, and warm for accuracy dropped; the entries in this matrix are a good proxy for the transfer coefficient ?ij in (5). A similar plot for Coarse-CIFAR100 tasks is shown in the right panel of <ref type="figure" target="#fig_1">Fig. 2</ref>. Split-CIFAR10 and Split-MNIST indicate that most tasks mutually benefit each other. This is also true, but to a lesser extent, for Rotated-MNIST. Permuted-MNIST is a qualitatively different problem than these, perhaps because there is no obvious relationship between the tasks and there exist some tasks that lead to a large deterioration of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure A4:</head><p>The iterations of Model Zoo are visualized for the Split-miniImagenet dataset for 20 rounds, with 5 tasks selected in every iteration of Model Zoo. Red elements are tasks that were selected by boosting in that particular round. We observe that the accuracy of most tasks improves over the rounds, which indicates the utility of Model Zoo-like training scheme This plot also indicates that Model Zoo can improve the per-task accuracy on nearly all tasks. The model is trained for only a single-epch per boosting round.</p><p>In order to understand how the accuracy of Model Zoo evolves on all tasks as a function of the episodes, we created <ref type="figure" target="#fig_3">Fig. A4</ref>. This is a very insightful picture and we can draw the following conclusions from it.</p><p>(i) The accuracy along the diagonal of most tasks increases along the row, i.e., across episodes.</p><p>Only for a few tasks like Food Container, the accuracy drops in later episodes. Note that we also see from <ref type="figure" target="#fig_4">Fig. A1</ref> that Food Container is a task that is best trained in isolation because it leads to deterioration of accuracy when trained with essentially any other task. (ii) There is strong backward transfer throughout the dataset, i.e., the accuracy of a task shown in earlier rounds increases, as later synergistic tasks are shown to the learner. (iii) We also see strong forward transfer. Roughly speaking, in the second half of the rows, the tasks already have a good initial accuracy.</p><p>We advocate that such plots should be made for different continual learning algorithms to obtain a precise picture of the amount of forward and backward transfer. Isolated Accuracies (500 samples/label) <ref type="figure">Figure A5</ref>: Per-task accuracies of Isolated on the Coarse-CIFAR100 dataset for two cases, one with 100 samples/class (top) and another with all 500 samples/class (bottom). Two points are very important to note here. First, there is a large improvement in the two accuracies for all tasks when the learner has access to more samples. Second, different tasks have very different accuracies when trained in isolation (using the same . This indicates that different tasks are very different in terms how hard they are, for some tasks such as People, the base accuracy of the model is quite low and one must have lots of samples in order to perform well. A lot of other multi-task learning datasets, e.g., derivatives of MNIST (or even CIFAR10 to an extent) are unlike Coarse-CIFAR100 in this respect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 S E M</head><p>We obtain metrics from publicly available implementations of a few different continual learning algorithms, which are shown in <ref type="table" target="#tab_3">Tables A1 and A2</ref>. We see that Model Zoo and its variants uniformly have essentially no forgetting and good forward transfer. The average per-task accuracy is also higher than existing methods on these datasets. These tables show results for single-epoch training (to be consistent with the implementation of these existing methods).   We next study how the individual per-task accuracy evolves on different datasets. The following figures are extended versions of the right panel of <ref type="figure">Fig. 1</ref>. We see that the accuracy of all tasks increases with successive episodes. This is quite uncommon for continual learning methods and indicates that Model Zoo essentially does not suffer from catastrophic forgetting. We have also juxtaposed the corresponding curves of the single-epoch setting with the multi-epoch training in Model Zoo; we would like to demonstrate the dramatic gap in the accuracy of these problem settings. Even if single-epoch variant of Model Zoo also does not forget (its accuracy is much better than existing continual learning methods), the multi-epoch variant has much higher accuracy for every task. This indicates that continual learning algorithms should also focus on per-task accuracy in addition to mitigating forgetting, if they are to be performant. The performance of Model Zoo is evidence that we can build effective continual learning methods that do not forget.  <ref type="table" target="#tab_3">Task1  Task2  Task3  Task4   Task5  Task6  Task7  Task8   Task9  Task10  Task11  Task12   Task13  Task14  Task15  Task16   Task17  Task18  Task19  Task20</ref> Individual Task Accuracies on Split-CIFAR100  <ref type="table" target="#tab_3">Task1  Task2  Task3  Task4   Task5  Task6  Task7  Task8   Task9  Task10  Task11  Task12   Task13  Task14  Task15  Task16   Task17  Task18  Task19  Task20</ref> Individual Task Accuracies on Split-miniImagenet and Split-CIFAR100 datasets with respect to average task accuracy. Model Zoo and its variants are in bold, similar to the left panel of <ref type="figure">Fig. 1</ref> (which is for Split-miniImagenet). Isolated-small and Model Zoo-small significantly outperform existing methods. All methods in the figure are run in the single-epoch setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>B.8 A C L E 100 /</p><p>We also performed continual learning experiments with 100 samples/class in <ref type="table" target="#tab_14">Table A3</ref>. We find that Model Zoo obtains an accuracy that lies in between those of Isolated and the approximate upper bound given by Multi-Head (multi-task learning). Doing so indicates strong ability of the learner for both forward and backward transfer. In some cases, the continual learner even outperforms Multi-Head trained on all tasks together.   <ref type="formula" target="#formula_9">(86)</ref> Split-CIFAR10 <ref type="figure" target="#fig_4">Figure A10</ref>: Per-task validation accuracy as a function of the number of episodes of continual learning for problems using variants of CIFAR10 and MNIST datasets using Model Zoo. Each task has 100 samples/class. X-markers denote accuracy of Isolated on the new task. We see both forward transfer (Model Zoo often starts with a higher accuracy than Isolated) and backward transfer (accuracy of some past tasks improves in later episodes). For problems like Permuted-MNIST and Rotated-MNIST, there is little forward or backward transfer.</p><p>We next visualize the evolution of the per-task test accuracy for various datasets in <ref type="figure" target="#fig_4">Fig. A10</ref>. This is a qualitative way to investigate forward and backward transfer in the learner. Forward transfer is positive if the accuracy of a newly introduced task in a particular episode is higher than what it would be if the task were trained in isolation. Backward transfer is positive if successive episodes and tasks result in an increase in the accuracy of tasks that were introduced earlier in continual learning. Both Appendix B.6 and <ref type="figure" target="#fig_4">Fig. A10</ref>    </p><formula xml:id="formula_13">(h) ? E P1 (h, h * i ) = E P1 (h) ? E P1 (h * i , h * 1 ).</formula><p>for any i, j ? n and h ? H. Let us denote ? (i) = ? i1 . We can sum over i ? {1, . . . , k} and divide by k to get</p><formula xml:id="formula_14">E P1 (h) ? 1 k k i=1 E P1 (h * (i) ) + c k k i=1 E 1/? (i) P (i) (h).</formula><p>The first term is a discrepancy term that measures how distinct different tasks are as measured by the probability of the disagreement of their individual hypotheses h * (i) with that of h * 1 under samples drawn from task P 1 . We need to bound the second term on the right-hand side to prove Theorem 2. We have</p><formula xml:id="formula_15">1 k k i=1 E 1/? (i) P (i) (h) ? 1 k k i=1 E 1/?max P (i) (h) = 1 k k i=1 (e Pi (h) ? e Pi (h * i )) 1/?max ? 1 k k i=1 e 1/?max Pi (h) ? e 1/?max P (h).</formula><p>where the final step involves Jensen's inequality andP = 1/k k i=1 P (i) . This is the population risk of a hypothesis h on the mixture distributionP and by uniform convergence, we can bound it as e 1/?max P (h) ? eS(h) + c D ? log ? km 1/2 1/?max for any h ? H, in particular? k , with probability 1 ? ?. Putting it all together we have:</p><formula xml:id="formula_16">E P1 (h) ? 1 k k i=1 E P1 (h * (i) ) + c k k i=1 E 1/? (i) P (i) (h) ? 1 k k i=1 E P1 (h * (i) ) + c k eS(h) + c D ? log ? km 1/2 1/?max D F<label>(FAQ )</label></formula><p>1. Why do you consider the setting with unlimited replay?</p><p>As mentioned in ?6, we would like to ground the practice of continual learning. Our investigation is inspired by the existing work on continual learning and with this paper we seek to encourage future works to focus their investigations on key desiderata of continual learning, namely per-task accuracy and forward-backward transfer.</p><p>With this goal, we are motivated by our results in Theorem 2 that fitting a single model on a set of tasks is fundamentally limiting in performance due to competition between tasks, this problem is only exacerbated by introducing the tasks sequentially. We have developed a general method named Model Zoo that, although designed for unlimited replay, can be executed in any of the standard continual learning settings. Our experiments show that Model Zoo significantly outperforms existing methods in all of these settings, including problem settings with no replay. We allow Model Zoo to revisit past data and grow its capacity iteratively in order to get to the heart of the problem of learning multiple tasks sequentially. In our view, if we can demonstrate effective continual learning without forgetting at least in this setting, it will provide a good foundation to build methods that conform to the stricter problem formulations.</p><p>We believe that such a foundation is needed today if we are to advance the practice of continual learning. Let us explain why with an example. The simplest "baseline" algorithm named Isolated in our work, surprisingly outperforms all existing continual learning methods, without performing any data replay, or leveraging data from multiple tasks. An upper bound for performance of a continual learner is the accuracy obtained by a multi-task learner that has access to all tasks before training. We argue that a good continual learner's performance should lie in between the above two: it should be-at least-comparable to training the task in isolation, and as close to the performance of the multi-task learner as possible. The fact that existing methods perform much poorly than even Isolated indicates that we need to thoroughly investigate the tradeoffs that these methods make, e.g., while the single epoch setting helps mitigate forgetting, it has quite poor accuracy. In short, we would like to argue that before we design new sophisticated methods for continual learning, we should take a step back and evaluate what simple methods can do and ascertain some level of baseline performance, so that we have a sound benchmark to compare the sophisticated method against. This is our rationale for considering the problem setting with unlimited replay. We would also like to emphasize that Model Zoo is a legitimate continual learner because it gets access to each task sequentially, and has a fixed computational budget at each episode. For a multi-task learner, the computational complexity scales with the number of tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Why do you call it continual learning, instead of, say, incremental or lifelong learning?</head><p>The current literature is quite inconclusive about the formal distinction between continual, incremental and lifelong learning. We have chosen to call our problem "continual learning" and, by that, we simply mean that the learner gets access to tasks sequentially instead of having access to all tasks before training begins.</p><p>3. Why are you not using the same neural architectures as those in the existing literature? Perhaps the methods in this paper work better because you use a larger/different neural architecture.</p><p>We use a small deep network (WRN-16-4 with 3.6M weights) for all our experiments. In particular, this is smaller than the Resnet-12 or Resnet-18 architectures that are used in a number of continual learning experiments (see <ref type="bibr" target="#b25">Kaushik et al. (2021)</ref>) and the Model Zoo has a comparable number of weights. The exceptional performance of Model Zoo indicates that these observations indicate that the significant gains in accuracy of Model Zoo are not simply a result of using a larger model. We also demonstrate results on continual learning with a much smaller model, a CNN with 0.12M weights (which entails that Model Zoo has about 2.42M weights). This is an extremely small model, and even this model, under all problem settings, improves the accuracy of continual learning over existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Why not compare Model Zoo to ensemble versions of other methods?</head><p>We compare the performance of Model Zoo with ensemble versions of Isolated in <ref type="figure" target="#fig_3">Fig. 4</ref>. We observe that Model Zoo performs better than an ensemble of Isolated models. We did not compare against ensemble variants of existing continual learning methods because as our results show in multiple places, Isolated significantly outperforms the state of the art as a continual learner. We therefore expect that Model Zoo will also outperform ensembles of existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Boosting is not novel.</head><p>We do not claim any novelty in developing boosting and moreover our method is only loosely inspired by it. The key property of Model Zoo that makes it effective is the ability to split the capacity of the learner across different sets of tasks, the ones that are chosen at each round. This entails that the implementation of Model Zoo is similar to that of boosting-based algorithms such as AdaBoost, but that is the extent of the similarity between the two. In particular, Model Zoo only uses the models that were trained on a particular task in order to make predictions for it. Unlike AdaBoost which combines all the weak-learners using specific weights, we simply average the predictions of all models trained on each task. To emphasize, boosting is not novel, but the ability of Model Zoo to split learning capacity across multiple models, one from each round, trained on a set of tasks, is novel.</p><p>6. Identifying that tasks compete is not novel. See ?6 and the references in ?2.1. The fact that tasks compete with each other is broadly appreciated-if not rigorously studied-in the theoretical machine learning literature. It is also appreciated broadly under the name of catastrophic forgetting in continual learning. Theorem 2 elucidates this competition and shows, together with <ref type="figure" target="#fig_1">Fig. 2</ref>, that it can be quite non-trivial. Even if some tasks compete, i.e., a hypothesis that is optimal for one performs poorly on the other, they may benefit each other if we have access to lots of samples from each task. An effective way to resolve this competition has been missing. Model Zoo is a simple and effective framework to tackle task competition; such a mechanism, and certainly its use for continual learning, is novel to our knowledge.</p><p>7. Why does the rate of convergence in Theorem 2 depend upon ? max , this seems quite inefficient.</p><p>The convergence rate in Theorem 2 which depends on ? max indeed seems pessimistic if one chooses a bad set of tasks to train together. But this may be a fundamental limitation of non-adaptive methods, e.g., that pool data from all tasks together to compute? k . If the learner uses adaptive methods, e.g., if it has access to ? ij and iteratively restricts the search space at iteration k to only consider hypotheses that achieve a low empirical risk? S (i) on all tasks closer than ? (k) , then as <ref type="bibr" target="#b23">(Hanneke and Kpotufe, 2020)</ref> shows, we can get better convergence rates if all tasks have the same optimal hypothesis. Let us note that we have chosen some drastic inequalities in Appendix C in order to elucidate the main point, and it may be possible to improve upon the rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Can you give some intuition for the transfer exponent?</head><p>The transfer exponent discussed in (5) is inspired by the work of <ref type="bibr" target="#b23">Hanneke and Kpotufe (2020)</ref> and is defined by the smallest value such that c E 1/?ij Pi (h) ? E Pj (h, h * i ) = E Pj (h) + e Pj (h * j ) ? e Pj (h * i ) for all h ? H. This should be understood as a measure of similarity between tasks that incorporates properties of the hypothesis space. A small value of ? ij ? 1 suggests that minimizing the excess risk on task P i (the left-hand side) is a good strategy if we want to minimize the excess risk on task P j (the right-hand side). But there may be instances when we can only reduce the left hand-side up to an additive term e Pj (h * j ) ? e Pj (h * i ) that may be non-zero (or large) if the optimal hypotheses h * j and h * i perform very differently on samples from P j . Mathematically, ? ij is seen as the rate of convergence of the concentration term in Theorem 2 if samples from P i are used to select a hypothesis for P j ; larger the transfer exponent, more inefficient these samples, even if this additive term is zero.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Competition between tasks in continual learning can be non-trivial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Ablation studies that show the average per-task accuracy as we vary the size of data replay for Model Zoo (left), the number of past tasks sampled at each episode (middle, b = 1 implies no replay), and compare Model Zoo with an ensemble of Isolated models (right). These results are for the single-epoch setting and are therefore directly comparable to those in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure A1 :</head><label>A1</label><figDesc>obtained the architectures used in each method from open-source implementations of the original authors (https://github.com/facebookresearch/agem and https://github.com/imirzadeh/stablecontinual-learning). Inference time is computed by processing 50 mini-batches from CIFAR-100, each of batch-size 16. The inference time is computed by normalizing the total computation time by (size of mini-batch ? number of mini-batches), which gives the average inference-time per sample. For Model-Zoo, we assume that inference time is approximately b = 5 times the inference time of Isolated, where b is number of tasks sampled in every round). Training time corresponds to the time (in minutes) required to train all episodes of the Split-CIFAR100 dataset (1 epoch per episode). Establishing an accurate comparison is difficult because different papers used different hardware but we have strived to be fair. The training time for EWC, Prog-NN, GEM and A-GEM are obtained from Chaudhry et al. (2019a) (we divide the numbers by 5 M e d . M a m m a ls A q . M a m m a ls F is h F lo w e r s F o o d C o n t a in e r F r u it s a n d V e g g ie s E le c t r ic a l D e v ic e s H o u s e h o ld F u r n it u r e In s e c t s L a r g e C a r n iv o r e s M a n -m a d e O u t d o o r N a t u r a l O u t d o o r O m n i-H e r b iv o r .2 2.8 -0.4 1.8 3 2.2 2.4 0.8 0.8 0.4 1.2 -2.2 0 -1.4 -1 3.4 0.6 -0.4 2 1.8 -2.6 0.4 2.8 -1 2 2 0.8 6 2.2 1.4 -2.8 0 3.2 0 4.8 4 -0.4 5.2 -1.6 -2.6 -0.8 0.2 2.4 -1.4 4.2 2 0.6 3.4 2.4 3.4 -1.6 -0.8 -1 1.8 0 0.8 -0.8 -0.4 1.8 0.4 0.8 5.4 4.4 -0.4 8.6 6 6 3.8 6.6 4.4 1.6 2.8 8.8 -0.2 3.2 0 4.6 5 1.4 -3.4 -1 2.2 3 -0.2 1.4 2 3.2 2.2 3.6 -1.6 2.4 2.6 4.8 -0.6 0.4 -2 Pairwise task competition matrix. Cells are colored by the gain(green)/loss(warm) of accuracy of pairwise Multi-Head training as compared to training the row-task in isolation; this is a good proxy for the transfer coefficient ?ij in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A7 :</head><label>A7</label><figDesc>Evolution of task accuracy on Split-CIFAR100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A8 :Figure A9 :</head><label>A8A9</label><figDesc>Evolution of task accuracy on Split-This figure compares Model Zoo to existing continual learning methods on the Coarse-CIFAR100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>shows a comparison of the methods developed in this paper with existing methods on Split-CIFAR100 in terms of continual-learning specific metrics. We find:(i) There are no significant differences in the forward transfer performance in the single epoch setting; larger variants of Isolated and Model Zoo do not work well here because a single</figDesc><table><row><cell>Method</cell><cell cols="2">Replay Single Rotated-Permuted-</cell><cell>Split-</cell><cell>Split-</cell><cell>Split-</cell><cell>Coarse-</cell><cell>Split-</cell></row><row><cell></cell><cell>Epoch MNIST</cell><cell cols="6">MNIST MNIST CIFAR10 CIFAR100 CIFAR100 MiniImagenet</cell></row><row><cell>GEM (Lopez-Paz and Ranzato, 2017)</cell><cell>86.07</cell><cell>82.60</cell><cell>-</cell><cell>-</cell><cell>67.8  *</cell><cell>-</cell><cell>51.86</cell></row><row><cell>A-GEM (Chaudhry et al., 2019a)</cell><cell>-</cell><cell>89.1</cell><cell>-</cell><cell>-</cell><cell>62.3  *</cell><cell>-</cell><cell>61.13</cell></row><row><cell>ER-Reservoir (Chaudhry et al., 2019b)</cell><cell>-</cell><cell>79.8</cell><cell>-</cell><cell>-</cell><cell>68.5  *</cell><cell>-</cell><cell>64.03</cell></row><row><cell>MC-SGD (Mirzadeh et al., 2020a)</cell><cell>82.63</cell><cell>85.3</cell><cell>-</cell><cell>-</cell><cell>63.30</cell><cell>-</cell><cell>-</cell></row><row><cell>MEGA-II (Guo et al., 2020a)</cell><cell>-</cell><cell>91.20</cell><cell>-</cell><cell>-</cell><cell>66.12</cell><cell>-</cell><cell>-</cell></row><row><cell>OGD (Farajtabar et al., 2020)</cell><cell>88.32</cell><cell>86.44</cell><cell>98.84</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Stable-SGD (Mirzadeh et al., 2020b)</cell><cell>70.8</cell><cell>80.1</cell><cell>-</cell><cell>-</cell><cell>59.9  *</cell><cell>-</cell><cell>57.79</cell></row><row><cell>TAG (Malviya et al., 2021)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>62.79</cell><cell>-</cell><cell>57.2</cell></row><row><cell>VCL (Nguyen et al., 2017)</cell><cell>-</cell><cell>95.5</cell><cell>98.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>FRCL (Titsias et al., 2020)</cell><cell>-</cell><cell>94.3</cell><cell>97.8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>FROMP (Pan et al., 2020)</cell><cell>-</cell><cell>94.9</cell><cell>99.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>EWC (Kirkpatrick et al., 2017)</cell><cell>? 84</cell><cell>? 96.9</cell><cell>-</cell><cell>-</cell><cell>? 42.40</cell><cell>-</cell><cell>-</cell></row><row><cell>Prog-Nets (Rusu et al., 2016)</cell><cell>-</cell><cell>? 93.5</cell><cell>-</cell><cell>-</cell><cell>? 59.2</cell><cell>-</cell><cell>-</cell></row><row><cell>SI (Zenke et al., 2017)</cell><cell>-</cell><cell>? 97.1</cell><cell>? 98.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>HAT(Serra et al., 2018)</cell><cell>-</cell><cell>98.6</cell><cell>99.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>APD (Yoon et al., 2019)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>56.81</cell><cell>-</cell></row><row><cell>FedWeIT (Yoon et al., 2021)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>55.16</cell><cell>-</cell></row><row><cell>RMN (Kaushik et al., 2021)</cell><cell>-</cell><cell>97.73</cell><cell>99.5</cell><cell>-</cell><cell>80.01</cell><cell>-</cell><cell>-</cell></row><row><cell>Our methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Isolated-small</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>96.88</cell><cell>90.18</cell><cell>69.07</cell><cell>82.48</cell></row><row><cell>Model Zoo-small</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>96.85</cell><cell>92.06</cell><cell>73.72</cell><cell>94.27</cell></row><row><cell>Model Zoo-small (10% replay)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>96.58</cell><cell>89.76</cell><cell>77.18</cell><cell>84.6</cell></row><row><cell>Isolated-Resnet</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>88.95</cell><cell>-</cell><cell>-</cell></row><row><cell>Model Zoo-Resnet</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>93.15</cell><cell>-</cell><cell>-</cell></row><row><cell>Isolated</cell><cell>99.64</cell><cell>98.03</cell><cell>99.98</cell><cell>97.46</cell><cell>91.90</cell><cell>80.72</cell><cell>86.28</cell></row><row><cell>Model Zoo</cell><cell>99.66</cell><cell>97.71</cell><cell>99.97</cell><cell>98.68</cell><cell>94.99</cell><cell>84.27</cell><cell>96.84</cell></row><row><cell>Multi-Head (multi-task)</cell><cell>99.66</cell><cell>98.16</cell><cell>99.98</cell><cell>98.11</cell><cell>95.38</cell><cell>83.19</cell><cell>90.83</cell></row></table><note>epoch is not sufficient to train modern deep networks. But Model Zoo and variants show less forgetting, it is essentially zero. This indicates that although existing methods are designed to avoid forgetting (the single epoch setting aids this directly), say, A-GEM, or EWC, they do forget. Forgetting can be mitigated by the capacity splitting mechanism in Model Zoo. The per-task accuracy of existing methods is also rather low compared to Model Zoo variants.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>MNIST, Permuted-MNIST and Rotated-MNIST are not informative benchmarks for judging forward and backward transfer because even Isolated achieves 99%+ accuracy. Model Zoo outperforms, by significant margins, all existing continual learning methods on all datasets. Accuracy of existing methods is worse than Isolated which suggests little to no forward or backward transfer. Model Zoo-small and Isolated-small have comparable number of weights as that of existing methods, and in some cases, much fewer. Model Zoo-Resnet18-S and Isolated-Resnet18-S, make use of the Resnet18-S architecture from Lopez-Paz and Ranzato (2017). Both Model Zoo/Isolated have similar accuracies on Split-CIFAR100 with 3 different architectures and all of them are better than existing methods. This indicates that the improvement in accuracy is not a result of the specific choice of architecture. For single-epoch numbers refer toFig. 1 and</figDesc><table /><note>Average per-task accuracy (%) at the end of all episodes.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>A comparison of continual learning evaluation metrics on Split-CIFAR100 for existing methods and the methods developed in this paper. Our methods demonstrate strong forward and backward transfer, high per-task accuracy, smaller training times and comparable inference times. Training times of other methods are from<ref type="bibr" target="#b9">Chaudhry et al. (2019a)</ref> and it is the total training time in minutes for all tasks. The Inference time is the per sample prediction latency averaged over 50 mini-batches of size 16. See Appendix A.5 for more details.</figDesc><table><row><cell>Replay</cell><cell>Split-</cell><cell>Split-</cell><cell># Tasks (b)</cell><cell>Split-</cell><cell>Split-</cell><cell>Method</cell><cell>Model</cell><cell>Ensemble of</cell></row><row><cell>(%)</cell><cell cols="2">CIFAR100 miniImagenet</cell><cell cols="3">(100% replay) CIFAR100 miniImagenet</cell><cell></cell><cell cols="2">Zoo Isolated (100?)</cell></row><row><cell>0 1 5 10 100</cell><cell>71.91 70.48 71.33 71.97 73.67</cell><cell>65.80 67.18 70.71 81.05 74.22</cell><cell>1 2 9 5 7</cell><cell>71.91 72.26 74.13 73.67 73.97</cell><cell>65.02 67.33 84.9 81.05 88.76</cell><cell cols="2">Split-CIFAR100 Split-miniImagenet 81.05 73.67</cell><cell>71.46 67.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table A1 :</head><label>A1</label><figDesc>Single Epoch continual learning metrics on Coarse-CIFAR100</figDesc><table><row><cell>Method</cell><cell cols="3">Avg. Accuracy Forgetting Forward</cell></row><row><cell>SGD</cell><cell>46.69</cell><cell>16.653</cell><cell>62.35</cell></row><row><cell>EWC</cell><cell>47.93</cell><cell>14.26</cell><cell>61.34</cell></row><row><cell>AGEM</cell><cell>51.86</cell><cell>10.102</cell><cell>61.13</cell></row><row><cell>ER</cell><cell>55.41</cell><cell>9.52</cell><cell>64.03</cell></row><row><cell>Stable-SGD</cell><cell>49.28</cell><cell>9.76</cell><cell>57.79</cell></row><row><cell>TAG</cell><cell>58.38</cell><cell>5.15</cell><cell>63.00</cell></row><row><cell>Isolated-small</cell><cell>65.8</cell><cell>0.0</cell><cell>65.8</cell></row><row><cell>Model Zoo-small</cell><cell>81.049</cell><cell>1.278</cell><cell>66.57</cell></row><row><cell>Isolated-large</cell><cell>40.2</cell><cell>0.0</cell><cell>40.25</cell></row><row><cell>Model Zoo-large</cell><cell>64.12</cell><cell>0.27</cell><cell>48.34</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table A2 :</head><label>A2</label><figDesc>Single Epoch continual learning metrics on Split-MinImagenet</figDesc><table><row><cell>B.6 T</cell><cell>I</cell><cell>T</cell><cell>A</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table A3 :</head><label>A3</label><figDesc>Average per-task accuracy (%) at the end of all episodes using 100 samples/class, bootstrapped across 5 datasets (mean ? std. dev.). Model Zoo performs better than Isolated on all problems even if tasks are shown sequentially.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>At each round of boosting, Model Zoo samples tasks according to equation(8)i.e., tasks with high loss under the current ensemble have a higher probability of being selected in the next round. To study the importance of this heuristic, we compare Model Zoo to a variant called Model Zoo (uniform).</figDesc><table><row><cell>B.9 M</cell><cell>Z</cell><cell>U</cell></row><row><cell cols="3">Model Zoo (uniform) samples uniformly over all seen tasks for each round, as opposed to using</cell></row><row><cell>equation (8).</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>consistently show non-trivial forward and backward transfer.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table A4</head><label>A4</label><figDesc>compares the accuracy of Model Zoo and Model Zoo (uniform) on the Coarse-CIFAR100 dataset. Model Zoo is marginally better than Model Zoo (uniform) indicating that using the training loss is a cheap proxy for splitting the capacity amongst related tasks. At the same time, this also indicates that a better measure of task-distances can further improve performance.</figDesc><table><row><cell>Method</cell><cell>Avg. Accuracy</cell></row><row><cell>Model Zoo</cell><cell>84.27</cell></row><row><cell>Model Zoo (uniform)</cell><cell>83.60</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table A4 :</head><label>A4</label><figDesc>Comparison of accuracies on the Coarse-CIFAR100 dataset C P From the definition of ? ij relatedness for tasks, we have</figDesc><table><row><cell>1/?i1 Pi Proof of Theorem 2. c E</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory aware synapses: Learning what (not) to forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="139" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Expert gate: Lifelong learning with a network of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3366" to="3375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A notion of task relatedness yielding provable multiple-task learning guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Borbely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting task relatedness for learning multiple tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Conference on Learning Theory</title>
		<meeting>the 16th Annual Conference on Learning Theory</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Arcing classifier (with discussion and a rejoinder by the author)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="801" to="849" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linear algorithms for online multitask classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cavallanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gentile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2901" to="2934" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torr</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="532" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient lifelong learning with a-gem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10486</idno>
		<title level="m">On tiny episodic memories in continual learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning from multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning modular neural network policies for multi-task and multi-robot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2169" to="2176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>D?az-Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lomonaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filliat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maltoni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.13166</idno>
		<title level="m">Don&apos;t forget, there is more than forgetting: new metrics for continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09434</idno>
		<title level="m">Few-Shot Learning via Learning the Representation, Provably</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning multiple tasks with kernel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Orthogonal gradient descent for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Azizan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3762" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09733</idno>
		<title level="m">Towards Robust Evaluations of Continual Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A unifying bayesian view of continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06494</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08734</idno>
		<title level="m">PathNet: Evolution Channels Gradient Descent in Super Neural Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improved schemes for episodic memory-based lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved schemes for episodic memory based lifelong learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">On the value of target data in transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hanneke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kpotufe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A no-free-lunch theorem for multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hanneke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kpotufe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.15785</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting generative models in discriminative classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="487" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Understanding catastrophic forgetting and remembering in continual learning with optimal relevance mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kortylewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11343</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recurrence is required to capture the representational dynamics of the human visual system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Kietzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Spoerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>S?rensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hauk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="21854" to="21863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6417</idno>
		<title level="m">Learning task grouping and overlap in multi-task learning</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting by incremental moment matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4652" to="4662" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gonina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05934</idno>
		<title level="m">A system for massively parallel hyperparameter tuning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05118</idno>
		<title level="m">Tune: A research platform for distributed model selection and training</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generative feature replay for class-incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Menta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raducanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>De We?er</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="226" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gradient episodic memory for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6470" to="6479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Piggyback: Adapting a single network to multiple tasks by learning to mask weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="67" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Packnet: Adding multiple tasks to a single network by iterative pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7765" to="7773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Tag: Task-based accumulated gradients for lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05155</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Boosting algorithms as gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Neural Information Processing Systems, NIPS&apos;99</title>
		<meeting>the 12th International Conference on Neural Information Processing Systems, NIPS&apos;99<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="512" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bounds for linear multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="117" to="139" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Mirzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ghasemzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04495</idno>
		<title level="m">Linear mode connectivity in multitask and continual learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Understanding the role of training regimes in continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Mirzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ghasemzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06958</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cross-stitch networks for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3994" to="4003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Mocanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eaton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liotta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05555</idno>
		<title level="m">Online contrastive divergence with generative replay: Experience replay without storing data</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10628</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Variational continual learning. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Continual deep learning by functional regularisation of memorable past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swaroop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Immer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eschenhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E E</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4453" to="4464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Lifelong learning with non-iid tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Gdumb: A simple approach that questions our progress in continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="524" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Nevergrad -A gradient-free optimization platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rapin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Teytaud</surname></persName>
		</author>
		<ptr target="https://GitHub.com/FacebookResearch/Nevergrad" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning multiple visual domains with residual adapters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">iCARL: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2001" to="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Learning to learn without forgetting by maximizing transfer and minimizing interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cases</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ajemian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.11910</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting, rehearsal and pseudorehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Routing networks: Adaptive selection of non-linear functions for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.01239</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04671</idno>
		<title level="m">Progressive neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Boosting: Foundations and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Emerald Group Publishing Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting with hard attention to the task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4548" to="4557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaplanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitrovi?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.13327</idno>
		<title level="m">Encoders and ensembles for task-free continual learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2994" to="3003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Adashare: Learning what to share for efficient deep multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12423</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Learning to Learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Functional regularisation for continual learning with gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tripuraneni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11650</idno>
		<title level="m">On the Theory of Transfer Learning: The Importance of Task Diversity</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07734</idno>
		<title level="m">Three scenarios for continual learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02920</idno>
		<title level="m">Branched multi-task networks: Deciding what layers to share</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Brain-inspired replay for continual learning with artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Siegelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Vogelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Helm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.12908</idno>
		<title level="m">Omnidirectional transfer for quasilinear lifelong learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Batchensemble: an alternative approach to efficient ensemble and lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06715</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Reinforced continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="907" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Federated continual learning with weighted inter-client transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12073" to="12086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Scalable and order-robust continual learning with additive parameter decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09432</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<title level="m">Wide residual networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Continual learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<idno>PMLR. 72.20 73.65 74.95 73.20 73.95 73.95 76.05 74.95 74.60 75.70 75.75 76.25 75.60 75.85 75.20 76.30 76.20 76.15 76.90 75.40 53.05 53.70 53.50 53.05 52.85 55.00 55.25 54.65 53.25 56.60 54.75 56.30 54.45 56.70 56.60 55.85 56.65 56.65 57.05 64.80 66.20 65.15 65.80 65.25 66.60 67.25 67.70 67.80 67.95 67.20 68.35 67.75 68.90 68.95 69.00 67.60 69.15 63.60 64.95 64.95 66.35 67.70 65.85 66.45 67.80 66.50 65.70 65.35 66.65 67.25 66.90 66.45 66.90 69.10 63.00 63.20 65.10 66.00 66.40 65.50 66.30 66.30 68.35 65.50 66.65 66.05 66.80 65.85 67.45 67.50 75.90 77.55 78.10 77.15 77.75 79.40 77.70 78.20 77.00 77.00 77.60 77.30 78.35 76.60 78.35 68.75 69.85 69.30 68.75 70.25 69.65 69.00 67.35 69.05 69.25 69.60 69.75 70.15 70.90 65.85 65.60 65.70 66.30 66.25 66.40 66.10 65.80 65.85 65.25 66.90 66.65 67.90 68.00 68.95 69.30 68.55 69.15 68.70 68.45 69.75 68.45 70.40 69.35 69.00 74.65 75.00 75.20 73.05 73.50 73.50 73.60 73.85 73.70 74.10 73.05 78.55 77.55 78.15 79.15 78.35 78.40 77.45 78.00 78.70 79.10</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3987" to="3995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Dataset Isolated Multi-Head (multi-task)</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
