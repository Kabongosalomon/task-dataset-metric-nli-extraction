<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binny</forename><surname>Mathew</surname></persName>
							<email>binnymathew@iitkgp.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Punyajoy</forename><surname>Saha</surname></persName>
							<email>punyajoys@iitkgp.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seid</forename><forename type="middle">Muhie</forename><surname>Yimam</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universit?t Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universit?t Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
							<email>pawang@cse.iitkgp.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animesh</forename><surname>Mukherjee</surname></persName>
							<email>animeshm@cse.iitkgp.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kharagpur</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public 1 for other researchers. Disclaimer: The article contains material that many will find offensive or hateful; however this cannot be avoided owing to the nature of the work. * Accepted at AAAI 2021. ? Equal Contribution 1 https://github.com/punyajoy/HateXplain</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The increase in online hate speech is a major cultural threat, as it already resulted in crime against minorities, see e.g. <ref type="bibr" target="#b52">(Williams et al. 2020)</ref>. To tackle this issue, there has been a rising interest in hate speech detection to expose and regulate this phenomenon. Several hate speech datasets <ref type="bibr" target="#b34">(Ousidhoum et al. 2019;</ref><ref type="bibr" target="#b39">Qian et al. 2019b;</ref><ref type="bibr" target="#b11">de Gibert et al. 2018;</ref><ref type="bibr" target="#b43">Sanguinetti et al. 2018)</ref>, models <ref type="bibr" target="#b56">(Zhang, Robinson, and Tepper 2018;</ref><ref type="bibr" target="#b32">Mishra et al. 2018;</ref><ref type="bibr">Qian et al. 2018b,a)</ref>, and shared tasks <ref type="bibr" target="#b2">(Basile et al. 2019;</ref><ref type="bibr" target="#b5">Bosco et al. 2018</ref>) have been made available in the recent years by the community, towards the development of automatic hate speech detection.</p><p>While many models have claimed to achieve state-ofthe-art performance on some datasets, they fail to generalize <ref type="bibr" target="#b1">(Arango, P?rez, and Poblete 2019;</ref><ref type="bibr" target="#b20">Gr?ndahl et al. 2018)</ref>. The models may classify comments that refer to certain commonly-attacked identities <ref type="bibr">(e.g., gay, black, muslim)</ref> as toxic without the comment having any intention of being toxic <ref type="bibr" target="#b14">(Dixon et al. 2018;</ref><ref type="bibr" target="#b3">Borkan et al. 2019)</ref>. A large prior on certain trigger vocabulary leads to biased predictions that may discriminate against particular groups who are already the target of such abuse <ref type="bibr" target="#b44">(Sap et al. 2019;</ref><ref type="bibr" target="#b9">Davidson, Bhattacharya, and Weber 2019)</ref>. Another issue with the current methods is the lack of explanation about the decisions made. With hate speech detection models becoming increasingly complex, it is getting difficult to explain their decisions <ref type="bibr" target="#b18">(Goodfellow, Bengio, and Courville 2016)</ref>. Laws such as General Data Protection Regulation (GDPR (Council 2016)) in Europe have recently established a "right to explanation". This calls for a shift in perspective from performance based models to interpretable models. In our work, we approach model explainability by learning the target classification and the reasons for the human decision jointly, and also to their mutual improvement.</p><p>We therefore have compiled a dataset that covers multiple aspects of hate speech. We collect posts from Twitter 2 and Gab 3 , and ask Amazon Mechanical Turk (MTurk) workers to annotate these posts to cover three facets. In addition to classifying each post into hate, offensive, or normal speech, annotators are asked to select the target communities mentioned in the post. Subsequently, the annotators are asked to highlight parts of the text that could justify their classification decision 4 . The notion of justification, here modeled as 'human attention', is very broad with many possible realizations <ref type="bibr" target="#b25">(Lipton 2018;</ref><ref type="bibr" target="#b15">Doshi-Velez 2017)</ref>. In this paper, we specifically focus on using rationales, i.e., snippets of text from a source text that support a particular categorization. Such rationales have been used in commonsense explanations <ref type="bibr" target="#b40">(Rajani et al. 2019</ref>), e-SNLI <ref type="bibr" target="#b7">(Camburu et al. 2018)</ref> and several other tasks <ref type="bibr" target="#b13">(DeYoung et al. 2020</ref>). If these rationales are good reasons for decisions, then models guided towards these in training could be made more human-decision-taking-like.</p><p>Consider the examples in <ref type="table">Table 1</ref>. The first row shows the tokens ('rationales') that were selected by human annotators which they believe are important for the classifi-Model Text Label</p><p>Human Annotator The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them HS CNN-GRU The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them HS BiRNN</p><p>The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them HS BiRNN-Attn</p><p>The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them HS BiRNN-HateXplain</p><p>The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them HS BERT</p><p>The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them OF BERT-HateXplain</p><p>The jews are again using holohoax as an excuse to spread their agenda . Hilter should have eradicated them OF <ref type="table">Table 1</ref>: Example of the rationales predicted by different models compared to human annotators. The green highlight marks tokens that the human annotator and model found important for the prediction. The orange highlight marks tokens which the model found important, but the human annotators did not.</p><p>cation. The next six rows show the important tokens (using LIME <ref type="bibr" target="#b42">(Ribeiro, Singh, and Guestrin 2016)</ref>), which helped various models in the classification. We observe that even when the model is making the correct prediction (hate speech -HS in this case), the reason ('rationales') for this varies across models. In case of BERT, we observe that it attends to several of the tokens that human annotators deemed important, but assigns the wrong label (offensive speech -OF).</p><p>In summary, we introduce HateXplain, the first benchmark dataset for hate speech with word and phrase level span annotations that capture human rationales for the labeling. Using MTurk, we collect a large dataset of around 20K posts and annotate them to cover three aspects of each post. We use several models on this dataset and observe that while they show a good model performance, they do not fare well in terms of model interpretability/explainability. We also observe that providing these rationales as input during training helps in improving a model's performance and reducing the unintended bias. We believe that this dataset would serve as a fundamental source for the future hate speech research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hate speech</head><p>The public expression of hate speech affects the devaluation of minority members <ref type="bibr" target="#b19">(Greenberg and Pyszczynski 1985)</ref> and such frequent and repetitive exposure to hate speech could increase an individual's outgroup prejudice <ref type="bibr" target="#b47">(Soral, Bilewicz, and Winiewski 2018)</ref>. Real world violent events could also lead to increased hate speech in online space <ref type="bibr" target="#b33">(Olteanu et al. 2018)</ref>. To tackle this, various methods have been proposed for hate speech detection <ref type="bibr" target="#b6">(Burnap and Williams 2016;</ref><ref type="bibr" target="#b41">Ribeiro et al. 2018;</ref><ref type="bibr" target="#b56">Zhang, Robinson, and Tepper 2018;</ref><ref type="bibr" target="#b37">Qian et al. 2018a</ref>). The recent interest in hate speech research has led to the release of datasets in multiple languages <ref type="bibr" target="#b34">(Ousidhoum et al. 2019;</ref><ref type="bibr" target="#b43">Sanguinetti et al. 2018)</ref> along with different computational approaches to combat online hate <ref type="bibr" target="#b36">(Qian et al. 2019a;</ref><ref type="bibr" target="#b31">Mathew et al. 2019b;</ref><ref type="bibr" target="#b0">Aluru et al. 2020)</ref>.</p><p>A recurrent issue with the majority of previous research is that many of them tend to conflate hate speech and abusive/offensive 5 language <ref type="bibr" target="#b10">(Davidson et al. 2017</ref>). Some of the <ref type="bibr">5</ref> We have used the terms offensive and abusive interchangeably works have combined offensive and hate language under a single concept, while very few works, such as <ref type="bibr" target="#b10">(Davidson et al. 2017;</ref><ref type="bibr" target="#b17">Founta et al. 2018)</ref> and <ref type="bibr" target="#b48">Van Huynh et al. (2019)</ref> have attempted to separate offensive from hate speech. We argue that this, although subjective, is an important aspect as there are lots of messages that are offensive but do not qualify as hate speech. For example, consider the word 'nigga'. The word is used everyday in online language by the African American community <ref type="bibr" target="#b49">(Vigna et al. 2017)</ref>. Similarly, words like hoe and bitch are used commonly in rap lyrics. Such language is prevalent on social media <ref type="bibr" target="#b50">(Wang et al. 2014)</ref> and any hate speech detection system should include these for the system to be usable. To this end, we have assumed that a given text can belong to one of the three classes: hate, offensive, normal. We have adopted the classes based on the work of <ref type="bibr" target="#b10">Davidson et al. (2017)</ref>. <ref type="table" target="#tab_1">Table 2</ref> provides a comparison between some hate speech datasets. <ref type="bibr" target="#b54">Zaidan, Eisner, and Piatko (2007)</ref> introduced the concept of using rationales, in which human annotators would highlight a span of text that could support their labeling decision. The authors utilized these enriched rationale annotation on a smaller set of training data, which helped to improve sentiment classification. <ref type="bibr" target="#b53">Yessenalina, Choi, and Cardie (2010)</ref> built on this work and developed methods that automatically generate rationales. <ref type="bibr" target="#b23">Lei, Barzilay, and Jaakkola (2016)</ref> also proposed an encoder-generator framework, which provides quality rationales without any annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explainability/Interpretability</head><p>In our paper, we utilize the concept of rationales and provide the first benchmark hate speech dataset with human level explanations. We have made our model and dataset public 1 for other researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset collection and annotation strategies</head><p>In this section, we provide the annotation strategies we have followed, the dataset selection approaches used, and the statistics of the collected dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset sampling</head><p>We collect our dataset from sources where previous studies on hate speech have been conducted: Twitter (Davidson in our paper as they are arguably very similar <ref type="bibr" target="#b17">(Founta et al. 2018</ref>   <ref type="bibr" target="#b16">Fortuna and Nunes 2018)</ref> and Gab <ref type="bibr" target="#b24">(Lima et al. 2018;</ref><ref type="bibr" target="#b30">Mathew et al. 2020;</ref><ref type="bibr" target="#b55">Zannettou et al. 2018)</ref>. Following the existing literature, we build a corpus of posts (tweets and gab posts) using lexicons. We combined the lexicon set provided by <ref type="bibr" target="#b10">Davidson et al. (2017)</ref>, <ref type="bibr" target="#b34">Ousidhoum et al. (2019)</ref>, and <ref type="bibr" target="#b28">Mathew et al. (2019a)</ref> to generate a single lexicon. For Twitter, we filter the tweets from the 1% randomly collected tweets in the time period Jan-2019 to Jun-2020. In case of Gab, we use the dataset provided by <ref type="bibr" target="#b28">Mathew et al. (2019a)</ref>. We do not consider reposts and remove duplicates. We also ensure that the posts do not contain links, pictures, or videos as they indicate additional information that might not be available to the annotators. However, we do not exclude the emojis from the text as they might carry important information for the hate and offensive speech labeling task. The posts were anonymized by replacing the usernames with &lt;user&gt;token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation procedure</head><p>We use Amazon Mechanical Turk (MTurk) workers for our annotation task. Each post in our dataset contains three types of annotations. First, whether the text is a hate speech, offensive speech, or normal. Second, the target communities in the text. Third, if the text is considered as hate speech, or offensive by majority of the annotators, we further ask the annotators to annotate parts of the text, which are words or phrases that could be a potential reason for the given annotation. These additional span annotations allow us to further explore how hate or offensive speech manifests itself.</p><p>Target group annotation The primary goal of the annotation task is to determine whether a given text is hateful, offensive, or neither of the two, i.e. normal. As noted above, we also get span annotations as reasons for the label assigned to a post (hateful or offensive). To further enrich the dataset, we ask the workers to decide the groups that the hate/offensive speech is targeting. <ref type="table" target="#tab_3">Table 3</ref> lists the target groups we have identified 6 .</p><p>Annotation instructions and design of the interface Before starting the annotation task, workers are explicitly warned that the annotation task displays some hateful or offensive content. We prepare instructions for workers that clearly explain the goal of the annotation task, how to annotate spans and also include a definition for each category. We 6 The data uses the label "homosexual" as defined at collection time instead of gay; other sexual and gender orientation categories have been pruned from the data due to low incidence; the published version of the paper wrongly mentions the LGBTQ category.   provided multiple examples with classification, target community and span annotations to help the annotators understand the task. To further ensure high quality dataset, we use built-in MTurk qualification requirements, namely the HIT Approval Rate (95%) for all Requesters' HITs and the Number of HITs Approved (5,000) requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset creation steps</head><p>For the dataset creation, we first conducted a pilot annotation study followed by the main annotation task. Pilot annotation: In the pilot task, each annotator was provided with 20 posts and they were required to do the hate/offensive speech classification as well as identify the target community (if any). In order to have a clear understanding of the task, they were provided with multiple examples along with explanations for the labelling process. The main purpose of the pilot task was to shortlist those annotators who were able to do the classification accurately. We also collected feedback from annotators to improve the main annotation task. A total of 621 annotators took part in the pilot task. Out of these, 253 were selected for the main task.</p><p>Main annotation: After the pilot annotation, once we had ascertained the quality of the annotators, we started with the main annotation task. In each round, we would select a batch of around 200 posts. Each post was annotated by three annotators, then majority voting was applied to decide the final label. The final dataset is composed of 9,055 posts from Twitter and 11,093 posts from Gab. <ref type="table" target="#tab_4">Table 4</ref> provides further details about the dataset collected.  annotator agreement is 0.46 which is much higher than other hate speech datasets <ref type="bibr" target="#b49">(Vigna et al. 2017;</ref><ref type="bibr" target="#b34">Ousidhoum et al. 2019</ref>).</p><p>Class labels: The class label (hateful, offensive, normal) of a post was decided based on majority voting. We found 919 cases where all the three annotators chose a different class. We did not consider these posts for our analysis.</p><p>To decide the target community of a post, we rely on majority voting. We consider that a target community is present in the post, if at least two out of the three annotators have selected the target from <ref type="table" target="#tab_3">Table 3</ref>. We also add a filter that the community should be present in at least 100 posts. Based on this criteria, our dataset had the following ten communities: African, Islam, Jewish, Gay, Women, Refugee, Arab, Caucasian, Hispanic, Asian. The target community information would allow researchers to delve into issues related to bias in hate speech <ref type="bibr" target="#b9">(Davidson, Bhattacharya, and Weber 2019)</ref>. In our dataset, the top three communities that are targets of hate speech are the African, Islam, and Jewish community. In case of offensive speech, the top three targets are Women, Africans, and Gay. These observations are in agreement with previous research <ref type="bibr" target="#b46">(Silva et al. 2016)</ref>.</p><p>For the rationales' annotation, each post that is labelled as hateful or offensive was further provided to the annotators 7 to highlight the rationales that could justify the final class. Each post had rationale explanations provided by 2-3 annotators. We observe that the average number of tokens highlighted per post is 5.48 for offensive speech, and 5.47 for hate speech. Average token per post in the whole dataset is 23.42. The top three content words in the hate speech rationales are nigger, kike, and moslems, which are found in 30.02% of all the hateful posts. The top three content words for the offensive highlights are retarded, bitch, and white, which are found in 47.36% of all the offensive posts. Ground truth attention: In order to generate the ground truth attention for the post with hate speech/offensive label, we first convert each rationale into an attention vector. This is a Boolean vector with length equal to the number of tokens in the sentence. The tokens in the rationale are indicated by a value of 1 in the attention vector. Now we take the average of the these attention vectors to represent a common ground truth attention vector for each post. The atten-  tion vectors from the attention based models usually have their sum of elements equal to 1. We normalize this common attention vector through a softmax function to generate the ground truth attention. One issue with the ground truth attention vector could be that the difference between the values of rationale and non-rationale tokens could be low. To handle this, we make use of the temperature parameter (? ) in the softmax function. This allows us to make the probability distribution concentrate on the rationales. We tune this parameter using the validation set. Finally, if the label of the post is normal, we ignore the attention vectors and replace each element in the ground truth attention with 1/(sentence length) to represent uniform distribution. We illustrate this computation in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics for evaluation</head><p>To build the HateXplain benchmark dataset, we consider multiple types of metrics to cover several aspects of hate speech. Taking inspiration from the different issues reported for hate speech classifications, we concentrate on three major types of metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance based metrics</head><p>Following the standard practices, we report accuracy, macro F1-score, and AUROC score. These metrics would be able to evaluate the classifier performance in distinguishing among the three classes, i.e., hate speech, offensive speech, and normal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bias based metrics</head><p>The hate speech detection models could make biased predictions for particular groups who are already the target of such abuse <ref type="bibr" target="#b44">(Sap et al. 2019;</ref><ref type="bibr" target="#b9">Davidson, Bhattacharya, and Weber 2019)</ref>. For example, the sentence "I love my niggas." might be classified as hateful/offensive because of the association of the word niggas with the black community. These unintended identity-based bias could have negative impact on the target community. To measure such unintended model bias, we rely on the AUC based metrics developed by <ref type="bibr" target="#b3">Borkan et al. (2019)</ref>. These include Subgroup AUC, Background Positive Subgroup Negative (BPSN) AUC, Background Negative Subgroup Positive (BNSP) AUC, Generalized Mean of Bias AUCs. The task here is to classify the post as toxic (hate speech, offensive) or not (normal). Here, the models will be evaluated on the grounds of how much they are able to reduce the unintended bias towards a target community <ref type="bibr" target="#b3">(Borkan et al. 2019)</ref>. We restrict the evaluation to the test set only. By having this restriction, we are able to evaluate models in terms of bias reduction. Below, we briefly describe each of the metrics. Subgroup AUC: Here, we select toxic and normal posts from the test set that mention the community under consideration. The ROC-AUC score of this set will provide us with the Subgroup AUC for a community. This metric measures the model's ability to separate the toxic and normal comments in the context of the community (e.g., Asians, Gay etc.). A higher value means that the model is doing a good job at distinguishing the toxic and normal posts specific to the community. BPSN (Background Positive, Subgroup Negative) AUC: Here, we select normal posts that mention the community and toxic posts that do not mention the community, from the test set. The ROC-AUC score of this set will provide us with the BPSN AUC for a community. This metric measures the false-positive rates of the model with respect to a community. A higher value means that a model is less likely to confuse between the normal post that mentions the community with a toxic post that does not. BNSP (Background Negative, Subgroup Positive) AUC: Here, we select toxic posts that mention the community and normal posts that do not mention the community, from the test set. The ROC-AUC score for this set will provide us with the BNSP AUC for a community. The metric measures the false-negative rates of the model with respect to a community. A higher value means that the model is less likely to confuse between a toxic post that mentions the community with a normal post without one. where, M p = the p th power-mean function, m s = the bias metric m calculated for subgroup s and N = number of identity subgroups (10). We use p = ?5 as was also done in the competition. We report the following three metrics for our dataset.</p><p>-GMB-Subgroup-AUC: GMB AUC with Subgroup AUC as the bias metric. -GMB-BPSN-AUC: GMB AUC with BPSN AUC as the bias metric. -GMB-BNSP-AUC: GMB AUC with BNSP AUC as the bias metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explainability based metrics</head><p>We follow the framework in the ERASER benchmark by <ref type="bibr" target="#b13">DeYoung et al. (2020)</ref> to measure the explainability aspect of a model. We measure this using plausibility and faithfulness. Plausibility refers to how convincing the interpretation is to humans, while faithfulness refers to how accurately it reflects the true reasoning process of the model (Jacovi and Goldberg 2020). For completeness, we explain the metrics briefly below. Plausibility To measure the plausibility, we consider metrics for both discrete and soft selection. We report the IOU F1-Score and token F1-Score metric for the discrete case, and the AUPRC score for soft token selection <ref type="bibr" target="#b13">(DeYoung et al. 2020)</ref>.</p><p>Intersection-Over-Union (IOU) permits credit assignment for partial matches. DeYoung et al. (2020) defines IOU on a token level: for two spans, it is the size of the overlap of the tokens they cover divided by the size of their union. A prediction is considered as a match if the overlap with any of the ground truth rationales is more than 0.5. We use these partial matches to calculate an F1-score (IOU F1). We also measure token-level precision and recall, and use these to derive token-level F1 scores (token F1). To measure the plausibility for soft token scoring, we also report the Area Under the Precision-Recall curve (AUPRC) constructed by sweeping a threshold over the token scores. Faithfulness To measure the faithfulness, we report two metrics: comprehensiveness and sufficiency (DeYoung et al. 2020).</p><p>-Comprehensiveness: To measure comprehensiveness, we create a contrast examplex i , for each post x i , wher? x i is calculated by removing the predicted rationales r i 9 from x i . Let m(x i ) j be the original prediction probability provided by a model m for the predicted class j. Then we define m(x i \r i ) j as the predicted probability ofx i (= x i \r i ) by the model m for the class j. We would expect the model prediction to be lower on removing the rationales. We can measure this as followscomprehensiveness = m(x i ) j ? m(x i \r i ) j . A high value of comprehensiveness implies that the rationales were influential in the prediction. -Sufficiency measures the degree to which extracted rationales are adequate for a model to make a prediction. We can measure this as follows -sufficiency = m(x i ) j ? m(r i ) j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model details</head><p>In this section, we provide details on the models used to evaluate the dataset. Each model has two versions, one where the models are trained using the ground truth class labels only (i.e., hate speech, offensive speech, and normal) and the other, where the models are trained using the ground truth attention and class labels, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. For training using the ground truth attention, the model needs to output some form of vector representing attention for each   token according to the model, hence, the second version is not feasible for BiRNN and CNN-GRU models 10 . <ref type="bibr" target="#b56">Zhang, Robinson, and Tepper (2018)</ref> used CNN-GRU to achieve state-of-the-art for multiple hate speech datasets. We modify the original architecture to include convolution 1D filters of window sizes 2, 3, 4 with each size having 100 filters. For the RNN part, we use GRU layer and finally max-pool the output representation from the hidden layers of the GRU architecture. This hidden layer is passed through a fully connected layer to finally output the prediction logits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN-GRU</head><p>BiRNN For the BiRNN <ref type="bibr" target="#b45">(Schuster and Paliwal 1997)</ref> model, we pass the tokens in the form of embeddings to a sequential model 11 . The last hidden state is passed through 2 fully connected layers. The output after that is used as the prediction logits. We use dropout layers after the embedding layer and before both the fully connected layers to regularise the trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BiRNN-Attention</head><p>This model is identical to the BiRNN model but includes an attention layer <ref type="bibr" target="#b26">(Liu and Lane 2016)</ref> 10 The limitation is due to the lack of an attention mechanism. <ref type="bibr">11</ref> We experiment with LSTM and GRU. after the sequential layer. This attention layer outputs an attention vector based on a context vector which is analogous to asking "which is the most important word?". Weights from the attention vector are multiplied with the output hidden units from the sequential layer and added to present a final representation of the sentence. This representation is passed through two fully connected layers as in the BiRNN model. Further to train the attention layer outputs, we compute cross entropy loss between the attention layer output and the ground truth attention (cf. <ref type="figure" target="#fig_0">Figure 1</ref> for its computation) as shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>BERT BERT <ref type="bibr" target="#b12">(Devlin et al. 2019</ref>) stands for Bidirectional Encoder Representations from Transformers pre-trained on data from English language 12 . It is a stack of transformer encoder layers with 12 "attention heads", i.e., fully connected neural networks augmented with a self attention mechanism. In order to fine-tune BERT, we add a fully connected layer with the output corresponding to the CLS token in the input. This CLS token output usually holds the representation of the sentence. Next, to add attention supervision, we try to match the attention values corresponding to the CLS token in the final layer to the ground truth attention, so that when the final weighted representation of CLS is generated, it would give attention to words as per the ground truth attention vector. This is calculated using a cross entropy between the attention values and the ground truth attention vector as shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameter tuning</head><p>All the methods are compared using the same train:development:test split of 8:1:1. We perform stratified split on the dataset to maintain class balance. All the results are reported on the test set and the development set is used for hyper-parameter tuning. We use the common crawl 13 pre-trained GloVe embeddings <ref type="bibr" target="#b35">(Pennington, Socher, and Manning 2014)</ref> to initialize the word embeddings for the non-BERT models. In our models, we set the token length to 128 for faster processing of the query 14 . We use Adam <ref type="bibr" target="#b22">(Kingma and Ba 2015)</ref> optimizer and find the learning rate to 0.001 for the non-BERT models and 2e-5 for BERT models using the development set. The RNN models prefer LSTM as the sequential layer with hidden layer size of 64 for BiRNN with attention and 128 for BiRNN. We use dropouts at different levels of the model. The regulariser ? controls how much effect the attention loss has on the total loss as in <ref type="figure" target="#fig_2">Figure 2</ref>. Optimum performance occurs with ? being set to 100 for BiRNN with attention and BERT with attention in the supervised setting 15 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We report the main results obtained in <ref type="table" target="#tab_9">Table 6</ref>. Bias: Similar to performance, models that utilize the human rationales as part of the training are able to perform better in reducing the unintended model bias for all the bias metrics. We observe that presence of community terms within the rationales is effective in reducing the unintended bias. We also looked at the model bias for each individual community in <ref type="figure" target="#fig_3">Figure 3</ref>. <ref type="figure" target="#fig_3">Figure 3a</ref> reports the community wise subgroup AUCROC. We observe that while the GMB-Subgroup 15 Please note that our selection of the best hyper-parameter was based on the model performance, which is in lines with what is suggested in the literature. One could have a variant where the model is optimized for the best explainability. This dataset gives researchers the flexibility to choose best parameters based on plausibility and/or faithfulness. <ref type="bibr">16</ref> &lt;model&gt;-HateXplain denotes the models where we use supervised attention using ground truth attention vector. metric reports ?0.8 AUROC, the score for individual community has large variations. Target communities like Asians have scores ?0.7, even for the best model. Communities like Hispanic seem to be biased toward having more false positives. Models like BERT-HateXplain seem to be able to handle this bias much better than other models. Future research on hate speech, should consider the impact of the model performance on individual communities to have a clear understanding on the impact. Explainability: We observe that models such as <ref type="bibr">BERT-HateXplain [LIME &amp; Attn]</ref>, which attain the best scores in terms of performance metrics and bias, do not perform well in terms of plausibility explainability metrics. In fact, BERT-HateXplain [Attn] has the worst score for sufficiency as compared to other models. BERT-HateXplain [LIME] seems to be the best model for comprehensiveness metric. For plausibility metrics, we observe BiRNN-HateXplain [Attn] to have the best scores. For sufficiency, CNN-GRU seems to be doing the best. For the token method, LIME seems to be generating more faithful results as compared to attention. These are in agreement with <ref type="bibr" target="#b13">DeYoung et al. (2020)</ref>. Overall, we observe that a model's performance metric alone is not enough. Models with slightly lower performance, but much higher scores for plausibility and faithfulness might be preferred depending on the task at hand. The HateXplain dataset could be a valuable tool for researchers to analyze and develop models that provide more explainable results. Variations with ?: We measure the effect of ? on model performance (macro F1 and AUROC) and explainability (token F1, AUPRC, comp., and suff.). We experiment with BiRNN-HateXplain [Attn] and BERT-HateXplain [Attn]. Increasing the value of ? improves the model performance, plausability, and sufficienty while degrading comprehensiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of our work</head><p>Our work has several limitations. First is the lack of external context. In our current models, we have not considered any external context such as profile bio, user gender, history of posts etc., which might be helpful in the classification task. Also, in this work we have focused on the English language. It does not consider multilingual hate speech into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and future work</head><p>In this paper, we have introduced HateXplain, a new benchmark dataset 1 for hate speech detection. The dataset consists of 20K posts from Gab and Twitter. Each data point is annotated with one of the hate/offensive/normal labels, target communities mentioned, and snippets (rationales) of the text marked by the annotators who support the label. We test several state-of-the-art models on this dataset and perform evaluation on several aspects of the hate speech detection. Models that perform very well in classification cannot always provide plausible and faithful rationales for their decisions.</p><p>As part of the future work, we plan to incorporate existing hate speech datasets <ref type="bibr" target="#b10">(Davidson et al. 2017;</ref><ref type="bibr" target="#b34">Ousidhoum et al. 2019;</ref><ref type="bibr" target="#b17">Founta et al. 2018</ref>) to our HateXplain framework.</p><p>We divided the interface into two parts. First, as shown in <ref type="figure">Figure 4</ref>, we classified the text as hate speech, offensive, or normal, along with the targets in the text. Second, in <ref type="figure" target="#fig_4">Figure 5</ref>, we asked the annotators to highlight the portions of the text that could justify the label given to the text (hate speech/offensive). In order to help the annotators with the task, we provided them with multiple example annotations and highlights. We also provided them with sample test cases (as shown in <ref type="figure" target="#fig_5">Figure 6</ref>) to test out the highlight system. <ref type="figure">Figure 4</ref>: The classification interface. The annotator is provided with 20 text messages and asked to selected the correct type and target of the message.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention supervision in BERT</head><p>In each encoder layer of BERT, an attention head computes key and query vectors to generate the attention values for   each token, based on other tokens in the sequence. These attention values multiplied with the input token representations generates the weighted encoded representation of the token. This way we get a representation of each token from each of the 12 heads. The outputs of each head in the same layer are combined and run through a fully connected layer. Each layer is wrapped with a skip-connection and a layer normalization is applied after it.</p><p>For attention supervision, we use x heads out of 12 heads in the last layer of BERT. We call these heads -supervised heads. For each supervised head, we use the attention weights corresponding to [CLS] 17 and calculate the cross entropy loss with ground truth attention vector as shown in <ref type="figure" target="#fig_6">Figure 7</ref>. This ensures that the final weighted output corresponding to CLS will give attention to words similar to the ground truth attention vector. Similarly, we do these steps for all supervised heads. The final loss from the attention supervision is the average of the cross entropy loss from each supervised heads, which is further multiplied with the regulariser-?. Other details about the finetuning is noted in BERT section of the main paper. Hyper-parameters used   <ref type="table" target="#tab_13">Table 8</ref> lists more examples corresponding to model predictions and rationales. In this example, BERT-HateXplain which uses token level rationales can attend better as compared to BERT. The prediction outcome is also correct for the BERT-HateXplain model. Wrong/incomplete attention (as shown) is one of the reason for incorrect predictions in BERT. For many of the false positives in BERT-HateXplain, the attended words are correct. In future, we plan to devise better mechanisms that can utilise attention for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>More examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotations</head><p>We looked into the quality of the fine-grained annotations as well. For this we computed the average pairwise Jaccard overlap between ground truth rationale annotations and compared them with the average pairwise overlap obtained through random annotation of the rationales. To generate the random rationale annotation, we chose 5 random tokens from a sentence as the rationale. For each sentence, we repeat this trial three times in order to denote 3 annotators. The average pairwise Jaccard overlap between the ground-truth annotations is 0.54, as compared to the random baseline of 0.36. This means that the annotators had more agreement on the token span annotations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Ground truth attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>GMB (Generalized Mean of Bias) AUC: This metric was introduced by the Google Conversation AI Team as part of their Kaggle competition 8 . This metric combines the peridentify Bias AUCs into one overall measure as M p (m s ) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Representation of the general model architecture showing how the attention of the model is trained using the ground truth (GT) attention. ? controls how much effect the attention loss has on the total loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Community-wise results for each of the bias metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Rationale highlight. The annotators are asked to highlight the portions of the text that would justify the label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Highlight testing. The annotators are provided further instructions on how to highlight the texts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>In this figure, we show attention supervision for a particular head in the n th layer. For this work, we use the last layer for attention supervision. The number of heads for training is a hyper-parameter in our experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>).</figDesc><table><row><cell>Dataset</cell><cell>Labels</cell><cell>Total Size</cell><cell>Language</cell><cell>Target Labels?</cell><cell>Rationales?</cell></row><row><cell>Waseem and Hovy (2016)</cell><cell>racist, sexist, normal</cell><cell>16,914</cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>Davidson et al. (2017)</cell><cell>Hate Speech, Offensive, Normal</cell><cell>24,802</cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>Founta et al. (2018)</cell><cell>Abusive, Hateful, Normal, Spam</cell><cell>80,000</cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>Ousidhoum et al. (2019)</cell><cell>Labels for five different aspects</cell><cell>13,000</cell><cell>English, French, Arabic</cell><cell></cell><cell></cell></row><row><cell>HateXplain (Ours)</cell><cell>Hate Speech, Offensive, Normal</cell><cell>20,148</cell><cell>English</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of different hate speech datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Target groups considered for the annotation.</figDesc><table><row><cell></cell><cell cols="2">Twitter Gab</cell><cell>Total</cell></row><row><cell>Hateful</cell><cell>708</cell><cell>5,227</cell><cell>5,935</cell></row><row><cell>Offensive</cell><cell>2,328</cell><cell>3,152</cell><cell>5,480</cell></row><row><cell>Normal</cell><cell>5,770</cell><cell>2,044</cell><cell>7,814</cell></row><row><cell cols="2">Undecided 249</cell><cell>670</cell><cell>919</cell></row><row><cell>Total</cell><cell>9,055</cell><cell cols="2">11,093 20,148</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Dataset details. "Undecided" refers to the cases where all the three annotators chose a different class.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Final ground</cell></row><row><cell></cell><cell></cell><cell>truth attention</cell></row><row><cell></cell><cell>Label is Normal</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Replace attention</cell></row><row><cell></cell><cell></cell><cell>value with</cell></row><row><cell></cell><cell></cell><cell>1/sentence length</cell></row><row><cell>Anno 1</cell><cell></cell><cell></cell></row><row><cell>Anno 2</cell><cell></cell><cell></cell></row><row><cell>Anno 3</cell><cell></cell><cell cols="2">Apply Softmax</cell></row><row><cell>Ground truth</cell><cell>Label is</cell><cell></cell></row><row><cell>attention</cell><cell>offensive/hate</cell><cell></cell></row><row><cell></cell><cell>speech</cell><cell>Take average of ground truth attention</cell><cell>Final ground truth attention</cell></row></table><note>shows samples of our dataset. The Krippendorff's ? for the inter-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Examples from our dataset. The highlighted portion of the text represents the annotator's rationale.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Macro F1? AUROC? GMB-Sub.? GMB-BPSN? GMB-BNSP? IOU F1? Token F1? AUPRC? Comp.? Suff.</figDesc><table><row><cell>Model [Token Method]</cell><cell cols="2">Performance</cell><cell></cell><cell>Bias</cell><cell></cell><cell></cell><cell cols="2">Explainability</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Plausibility</cell><cell></cell><cell cols="2">Faithfulness</cell></row><row><cell></cell><cell cols="10">Acc.? ?</cell></row><row><cell>CNN-GRU [LIME]</cell><cell>0.627 0.606</cell><cell>0.793</cell><cell>0.654</cell><cell>0.623</cell><cell>0.659</cell><cell>0.167</cell><cell>0.385</cell><cell>0.648</cell><cell>0.316</cell><cell>-0.082</cell></row><row><cell>BiRNN [LIME]</cell><cell>0.595 0.575</cell><cell>0.767</cell><cell>0.640</cell><cell>0.604</cell><cell>0.671</cell><cell>0.162</cell><cell>0.361</cell><cell>0.605</cell><cell>0.421</cell><cell>-0.051</cell></row><row><cell>BiRNN-Attn [Attn]</cell><cell>0.621 0.614</cell><cell>0.795</cell><cell>0.653</cell><cell>0.662</cell><cell>0.668</cell><cell>0.167</cell><cell>0.369</cell><cell>0.643</cell><cell>0.278</cell><cell>0.001</cell></row><row><cell>BiRNN-Attn [LIME]</cell><cell>0.621 0.614</cell><cell>0.795</cell><cell>0.653</cell><cell>0.662</cell><cell>0.668</cell><cell>0.162</cell><cell>0.386</cell><cell>0.650</cell><cell>0.308</cell><cell>-0.075</cell></row><row><cell>BiRNN-HateXplain [Attn]</cell><cell>0.629 0.629</cell><cell>0.805</cell><cell>0.691</cell><cell>0.636</cell><cell>0.674</cell><cell>0.222</cell><cell>0.506</cell><cell>0.841</cell><cell>0.281</cell><cell>0.039</cell></row><row><cell cols="2">BiRNN-HateXplain [LIME] 0.629 0.629</cell><cell>0.805</cell><cell>0.691</cell><cell>0.636</cell><cell>0.674</cell><cell>0.174</cell><cell>0.407</cell><cell>0.685</cell><cell>0.343</cell><cell>-0.075</cell></row><row><cell>BERT [Attn]</cell><cell>0.690 0.674</cell><cell>0.843</cell><cell>0.762</cell><cell>0.709</cell><cell>0.757</cell><cell>0.130</cell><cell>0.497</cell><cell>0.778</cell><cell>0.447</cell><cell>0.057</cell></row><row><cell>BERT [LIME]</cell><cell>0.690 0.674</cell><cell>0.843</cell><cell>0.762</cell><cell>0.709</cell><cell>0.757</cell><cell>0.118</cell><cell>0.468</cell><cell>0.747</cell><cell>0.436</cell><cell>0.008</cell></row><row><cell>BERT-HateXplain [Attn]</cell><cell>0.698 0.687</cell><cell>0.851</cell><cell>0.807</cell><cell>0.745</cell><cell>0.763</cell><cell>0.120</cell><cell>0.411</cell><cell>0.626</cell><cell>0.424</cell><cell>0.160</cell></row><row><cell>BERT-HateXplain [LIME]</cell><cell>0.698 0.687</cell><cell>0.851</cell><cell>0.807</cell><cell>0.745</cell><cell>0.763</cell><cell>0.112</cell><cell>0.452</cell><cell>0.722</cell><cell>0.500</cell><cell>0.004</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Model performance results. To select the tokens for explainability calculation, we used attention and LIME methods.</figDesc><table><row><cell></cell><cell>Sentence</cell><cell></cell><cell></cell></row><row><cell>Possible with model having attention as</cell><cell cols="2">Model architecture</cell><cell></cell></row><row><cell>output</cell><cell></cell><cell></cell><cell></cell></row><row><cell>GT</cell><cell>Predicted</cell><cell>Predicted</cell><cell>GT</cell></row><row><cell>attention</cell><cell>attention</cell><cell>labels</cell><cell>labels</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>This table represents the different hyper-parameter variations that we tried while tuning this model.</figDesc><table><row><cell>Hyper-parameters</cell><cell>BERT</cell><cell>BiRNN</cell><cell>BiRNN-Attention</cell><cell>CNN-GRU</cell></row><row><cell>No. of hidden units in sequential layer</cell><cell>-NA-</cell><cell>64, 128</cell><cell>64, 128</cell><cell>-NA-</cell></row><row><cell>Sequential layers type</cell><cell>-NA-</cell><cell>LSTM,GRU</cell><cell>LSTM,GRU</cell><cell>GRU</cell></row><row><cell>Train embedding layer</cell><cell>-NA-</cell><cell>True, False</cell><cell>True, False</cell><cell>True, False</cell></row><row><cell>Dropout after embedding layer</cell><cell>-NA-</cell><cell>0.1.0.2,0.5</cell><cell>0.1,0.2,0.5</cell><cell>0.1,0.2,0.5</cell></row><row><cell>Dropout after fully connected layer</cell><cell>0.1,0.2,0.5</cell><cell>0.1,0.2,0.5</cell><cell>0.1,0.2,0.5</cell><cell>0.1,0.2,0.5</cell></row><row><cell>Learning rate</cell><cell cols="4">2e-4,2e-5,2e-6 0.1,0.01,0.001 0.1,0.01,0.001 0.1,0.01,0.001</cell></row><row><cell>For supervised part</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Attention lambda (?)</cell><cell>0.001,0.01,0.1, 1,10,100</cell><cell>-NA-</cell><cell>0.001,0.01,0.1, 1,10,100</cell><cell>-NA-</cell></row><row><cell cols="2">Number of supervised heads (x) 1,6,12</cell><cell>-NA-</cell><cell>-NA-</cell><cell>-NA-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7</head><label>7</label><figDesc>reports the hyper-parameters we tested for our systems.</figDesc><table><row><cell>Model</cell><cell>Text</cell><cell>Label</cell></row><row><cell cols="3">Human Annotator I hate arabs HS</cell></row><row><cell>BERT</cell><cell cols="2">I hate arabs Normal</cell></row><row><cell cols="3">BERT-HateXplain I hate arabs HS</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>Example of the rationales predicted by different models compared to human annotators. The green highlight marks tokens that the human annotator and the model finds important for the prediction.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://twitter.com/ 3 https://gab.com/ 4 In case the post is classified as normal, the annotators does not need to highlight any span.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We tried to get the original annotator to highlight, however this was not always possible.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://www.kaggle.com/c/jigsaw-unintended-bias-intoxicity-classification/overview/evaluation</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">We select the top 5 tokens as the rationales. The top 5 is selected as it is the average length of the annotation span in the dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">We use the bert-base-uncased model having 12-layer, 768hidden, 12-heads, 110M parameters. 13 840B tokens, 2.2M vocab, cased, 300d vectors. 14 Almost all the posts consist of less than 128 tokens in the data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">the first row in the m * m attention weight matrix where m is the number of tokens in the tokenized sentence.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Interface design</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep Learning Models for Multilingual Hate Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Aluru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06465</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hate Speech Detection is Not as Easy as You May Think: A Closer Look at Model Validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arango</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poblete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Rangel Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of The 2019 World Wide Web Conference</title>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Association for Computing Machinery</title>
		<imprint>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of the EVALITA 2018 Hate Speech Detection Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maurizio</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">EVALITA 2018-Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian</title>
		<meeting><address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2263</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Us and them: identifying cyber hate on Twitter across multiple protected characteristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EPJ Data Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">e-SNLI: Natural Language Inference with Natural Language Explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9560" to="9572" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">EU Regulation 2016/679 General Data Protection Regulation (GDPR)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Council</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Official Journal of the European Union</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="88" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Racial Bias in Hate Speech and Abusive Language Detection Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated Hate Speech Detection and the Problem of Offensive Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Web and Social Media</title>
		<meeting>the Eleventh International Conference on Web and Social Media<address><addrLine>Montr?al, Qu?bec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hate Speech Dataset from a White Supremacy Forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garc?a-Pablos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuadros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ERASER: A Benchmark to Evaluate Rationalized NLP Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deyoung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">F</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4443" to="4458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Measuring and Mitigating Unintended Bias in Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2018 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="67" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Towards A Rigorous Science of Interpretable Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08608</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey on automatic detection of hate speech in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Founta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Djouvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chatzakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stringhini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vakali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sirivianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kourtellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Web and Social Media</title>
		<meeting>the Twelfth International Conference on Web and Social Media<address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The effect of an overheard ethnic slur on evaluations of the target: How to spread a social disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pyszczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">All You Need is: Evading Hate Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gr?ndahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pajola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Conti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asokan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security</title>
		<meeting>the 11th ACM Workshop on Artificial Intelligence and Security<address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4198" to="4205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Learning Representations</title>
		<meeting>3rd International Conference on Learning Representations<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>: International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rationalizing Neural Predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inside the rightleaning echo chambers: Characterizing gab, an unmoderated social system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Murai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vikatos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="515" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The mythos of model interpretability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="36" to="43" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech 2016, 17th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="685" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<title level="m">International Speech Communication Association</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spread of hate speech in online social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Web Science</title>
		<meeting>the 10th ACM Conference on Web Science</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Boston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usa</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hate Begets Hate: A Temporal Study of Hate Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Illendula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Thou shalt not hate: Countering online hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tharad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajgaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singhania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Maity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="369" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Author profiling for abuse detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Del Tredici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shutova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1088" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Effect of Extremist Violence on Hateful Speech Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Web and Social Media</title>
		<meeting>the Twelfth International Conference on Web and Social Media<address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="221" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multilingual and Multi-Aspect Hate Speech Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ousidhoum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4667" to="4676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Benchmark Dataset for Learning to Intervene in Online Hate Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4754" to="4763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hierarchical CVAE for Fine-Grained Hate Speech Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elsherief</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3550" to="3559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Leveraging Intra-User and Inter-User Representation Learning for Automated Hate Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elsherief</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="118" to="123" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to Decipher Hate Symbols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elsherief</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3006" to="3015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Explain Yourself! Leveraging Language Models for Commonsense Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">F</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4932" to="4942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Characterizing and Detecting Hateful Users on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Calais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A F</forename><surname>Almeida</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Web and Social Media</title>
		<meeting>the Twelfth International Conference on Web and Social Media<address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="676" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An Italian Twitter Corpus of Hate Speech against Immigrants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stranisci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation. Miyazaki, Japan: European Language Resources Association</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation. Miyazaki, Japan: European Language Resources Association</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Risk of Racial Bias in Hate Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1668" to="1678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Analyzing the Targets of Hate in Online Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Web and Social Media</title>
		<meeting>the Tenth International Conference on Web and Social Media<address><addrLine>Cologne, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="687" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Exposure to hate speech increases prejudice through desensitization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Soral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Winiewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aggressive behavior</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="136" to="146" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-T</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03644</idno>
		<title level="m">Hate Speech Detection on Vietnamese Social Media Text using the Bi-GRU-LSTM-CNN Model</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hate Me, Hate Me Not: Hate Speech Detection on Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Vigna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dell&amp;apos;orletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrocchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Italian Conference on Cybersecurity</title>
		<meeting>the First Italian Conference on Cybersecurity<address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1816</biblScope>
			<biblScope unit="page" from="86" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cursing in English on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thirunarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Sheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing</title>
		<meeting>the 17th ACM conference on Computer supported cooperative work &amp; social computing<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="415" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
	<note>: The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hate in the machine: anti-Black and anti-Muslim social media posts as predictors of offline racially and religiously aggravated crime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The British Journal of Criminology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="117" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Automatically Generating Annotator Rationales to Improve Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yessenalina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
	<note>The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Annotator Rationales&quot; to Improve Machine Learning for Text Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zaidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Piatko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics<address><addrLine>Rochester, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="260" to="267" />
		</imprint>
	</monogr>
	<note>The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">What is Gab: A Bastion of Free Speech or an Alt-Right Echo Chamber</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zannettou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bradlyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cristofaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sirivianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stringhini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blackburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of the The Web Conference 2018 on The Web Conference</title>
		<meeting><address><addrLine>Lyon , France</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2018-04-23" />
			<biblScope unit="page" from="1007" to="1014" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Tepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Semantic Web -15th International Conference</title>
		<meeting>The Semantic Web -15th International Conference<address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="745" to="760" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
