<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Convolutional Blind Denoising of Real Photographs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Guo</surname></persName>
							<email>guoshi28@outlook.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifei</forename><surname>Yan</surname></persName>
							<email>yanzifei@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
							<email>cskaizhang@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Convolutional Blind Denoising of Real Photographs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While deep convolutional neural networks (CNNs) have achieved impressive success in image denoising with additive white Gaussian noise (AWGN), their performance remains limited on real-world noisy photographs. The main reason is that their learned models are easy to overfit on the simplified AWGN model which deviates severely from the complicated real-world noise model. In order to improve the generalization ability of deep CNN denoisers, we suggest training a convolutional blind denoising network (CBDNet) with more realistic noise model and real-world noisy-clean image pairs. On the one hand, both signaldependent noise and in-camera signal processing pipeline is considered to synthesize realistic noisy images. On the other hand, real-world noisy photographs and their nearly noise-free counterparts are also included to train our CBD-Net. To further provide an interactive strategy to rectify denoising result conveniently, a noise estimation subnetwork with asymmetric learning to suppress under-estimation of noise level is embedded into CBDNet. Extensive experimental results on three datasets of real-world noisy photographs clearly demonstrate the superior performance of CBDNet over state-of-the-arts in terms of quantitative metrics and visual quality. The code has been made available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image denoising is an essential and fundamental problem in low-level vision and image processing. With decades of studies, numerous promising approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b61">61]</ref> have been developed and near-optimal performance <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50]</ref> has been achieved for the removal of additive white Gaussian noise (AWGN). However, in real camera system, image noise comes from multiple sources (e.g., dark current noise, short noise, and thermal noise) and is further affected by in-camera processing (ISP) pipeline (e.g., demosaicing, Gamma correction, and compression). All these make real noise much more different (a) "0002 02" from DND <ref type="bibr" target="#b44">[45]</ref> (b) Noisy (c) BM3D <ref type="bibr" target="#b11">[12]</ref> (d) DnCNN <ref type="bibr" target="#b61">[61]</ref> (e) FFDNet+ <ref type="bibr" target="#b62">[62]</ref> (f) CBDNet <ref type="figure">Figure 1</ref>: Denoising results of different methods on realworld noisy image "0002 02" from DND <ref type="bibr" target="#b44">[45]</ref>.</p><p>from AWGN, and blind denoising of real-world noisy photographs remains a challenging issue.</p><p>In the recent past, Gaussian denoising performance has been significantly advanced by the development of deep CNNs <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b62">62]</ref>. However, deep denoisers for blind AWGN removal degrades dramatically when applied to real photographs (see <ref type="figure">Fig. 1(d)</ref>). On the other hand, deep denoisers for non-blind AWGN removal would smooth out the details while removing the noise (see <ref type="figure">Fig. 1(e)</ref>). Such an phenomenon may be explained from the characteristic of deep CNNs <ref type="bibr" target="#b38">[39]</ref>, where their generalization largely depends on the ability of memorizing large scale training data. In other words, existing CNN denoisers tend to be over-fitted to Gaussian noise and generalize poorly to real-world noisy images with more sophisticated noise.</p><p>In this paper, we tackle this issue by developing a convolutional blind denoising network (CBDNet) for real-world photographs. As indicated by <ref type="bibr" target="#b38">[39]</ref>, the success of CNN denoisers are significantly dependent on whether the distributions of synthetic and real noises are well matched. Therefore, realistic noise model is the foremost issue for blind denoising of real photographs. According to <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b44">45]</ref>, Poisson-Gaussian distribution which can be approximated as heteroscedastic Gaussian of a signal-dependent and a stationary noise components has been considered as a more appropriate alternative than AWGN for real raw noise modeling. Moreover, in-camera processing would further makes the noise spatially and chromatically correlated which increases the complexity of noise. As such, we take into account both Poisson-Gaussian model and in-camera processing pipeline (e.g., demosaicing, Gamma correction, and JPEG compression) in our noise model. Experiments show that in-camera processing pipeline plays a pivot role in realistic noise modeling, and achieves notably performance gain (i.e., &gt; 5 dB by PSNR) over AWGN on DND <ref type="bibr" target="#b44">[45]</ref>.</p><p>We further incorporate both synthetic and real noisy images to train CBDNet. On one hand, it is easy to access massive synthetic noisy images. However, the noise in real photographs cannot be fully characterized by our model, thereby giving some leeway for improving denoising performance. On the other hand, several approaches <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b0">1]</ref> have suggested to get noise-free image by averaging hundreds of noisy images at the same scene. Such solution, however, is expensive in cost, and suffers from the oversmoothing effect of noise-free image. Benefited from the incorporation of synthetic and real noisy images, 0.3 ? 0.5 dB gain on PSNR can be attained by CBDNet on DND <ref type="bibr" target="#b44">[45]</ref>.</p><p>Our CBDNet is comprised of two subnetworks, i.e., noise estimation and non-blind denoising. With the introduction of noise estimation subnetwork, we adopt an asymmetric loss by imposing more penalty on under-estimation error of noise level, making our CBDNet perform robustly when the noise model is not well matched with real-world noise. Besides, it also allows the user to interactively rectify the denoising result by tuning the estimated noise level map. Extensive experiments are conducted on three real noisy image datasets, i.e., NC12 <ref type="bibr" target="#b28">[29]</ref>, DND <ref type="bibr" target="#b44">[45]</ref> and Nam <ref type="bibr" target="#b42">[43]</ref>. In terms of both quantitative metrics and perceptual quality, our CBDNet performs favorably in comparison to state-ofthe-arts. As shown in <ref type="figure">Fig. 1</ref>, both non-blind BM3D <ref type="bibr" target="#b11">[12]</ref> and DnCNN for blind AWGN <ref type="bibr" target="#b61">[61]</ref> fail to denoise the real-world noisy photograph. In contrast, our CBDNet achieves very pleasing denoising results by retaining most structure and details while removing the sophisticated real-world noise.</p><p>To sum up, the contribution of this work is four-fold:</p><p>? A realistic noise model is presented by considering both heteroscedastic Gaussian noise and in-camera processing pipeline, greatly benefiting the denoising performance.</p><p>? Synthetic noisy images and real noisy photographs are incorporated for better characterizing real-world image noise and improving denoising performance.</p><p>? Benefited from the introduction of noise estimation subnetwork, asymmetric loss is suggested to improve the generalization ability to real noise, and interactive denoising is allowed by adjusting the noise level map.</p><p>? Experiments on three real-world noisy image datasets show that our CBDNet achieves state-of-the-art results in terms of both quantitative metrics and visual quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Deep CNN Denoisers</head><p>The advent of deep neural networks (DNNs) has led to great improvement on Gaussian denoising. Until Burger et al. <ref type="bibr" target="#b5">[6]</ref>, most early deep models cannot achieve state-ofthe-art denoising performance <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b57">57]</ref>. Subsequently, CSF <ref type="bibr" target="#b53">[53]</ref> and TNRD <ref type="bibr" target="#b10">[11]</ref> unroll the optimization algorithms for solving the fields of experts model to learn stagewise inference procedure. By incorporating residual learning <ref type="bibr" target="#b18">[19]</ref> and batch normalization <ref type="bibr" target="#b20">[21]</ref>, Zhang et al. <ref type="bibr" target="#b61">[61]</ref> suggest a denoising CNN (DnCNN) which can outperform traditional non-CNN based methods. Without using clean data, Noise2Noise <ref type="bibr" target="#b29">[30]</ref> also achieves state-of-the-art. Most recently, other CNN methods, such as RED30 <ref type="bibr" target="#b37">[38]</ref>, Mem-Net <ref type="bibr" target="#b55">[55]</ref>, BM3D-Net <ref type="bibr" target="#b60">[60]</ref>, MWCNN <ref type="bibr" target="#b32">[33]</ref> and FFDNet <ref type="bibr" target="#b62">[62]</ref>, are also developed with promising denoising performance.</p><p>Benefited from the modeling capability of CNNs, the studies <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b55">55]</ref> show that it is feasible to learn a single model for blind Gaussian denoising. However, these blind models may be over-fitted to AWGN and fail to handle real noise. In contrast, non-blind CNN denoisiers, e.g., FFD-Net <ref type="bibr" target="#b62">[62]</ref>, can achieve satisfying results on most real noisy images by manually setting proper or relatively higher noise level. To exploit this characteristic, our CBDNet includes a noise estimation subnetwork as well as an asymmetric loss to suppress under-estimation error of noise level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Image Noise Modeling</head><p>Most denoising methods are developed for non-blind Gaussian denoising. However, the noise in real images comes from various sources (dark current noise, short noise, thermal noise, etc.), and is much more sophisticated <ref type="bibr" target="#b43">[44]</ref>. By modeling photon sensing with Poisson and remaining stationary disturbances with Gaussian, Poisson-Gaussian noise model <ref type="bibr" target="#b13">[14]</ref> has been adopted for the raw data of imaging sensors. In <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref>, camera response function (CRF) and quantization noise are also considered for more practical noise modeling. Instead of Poisson-Gaussian, Hwang et al. <ref type="bibr" target="#b19">[20]</ref> present a Skellam distribution for Poisson photon noise modeling. Moreover, when taking in-camera image processing pipeline into account, the channel-independent noise assumption may not hold true, and several approaches <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">43]</ref> are proposed for cross-channel noise modeling.</p><p>In this work, we show that realistic noise model plays a pivot role in CNN-based denoising of real photographs, and both Poisson-Gaussian noise and in-camera image processing pipeline benefit denoising performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Blind Denoising of Real Images</head><p>Blind denoising of real noisy images generally is more challenging and can involve two stages, i.e., noise estimation and non-blind denoising. For AWGN, several PCAbased <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b8">9]</ref> methods have been developed for estimating noise standard deviation (SD.). Rabie <ref type="bibr" target="#b48">[49]</ref> models the noisy pixels as outliers and exploits Lorentzian robust estimator for AWGN estimation. For Poisson-Gaussian model, Foi et al. <ref type="bibr" target="#b13">[14]</ref> suggest a two-stage scheme, i.e., local estimation of multiple expectation/standard-deviation pairs, and global parametric model fitting.</p><p>In most blind denoising methods, noise estimation is closely coupled with non-blind denoising. Portilla <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref> adopts a Gaussian scale mixture for modeling wavelet patches of each scale, and utilizes Bayesian least square to estimate clean wavelet patches. Based on the piecewise smooth image model, Liu et al. <ref type="bibr" target="#b31">[32]</ref> propose a unified framework for the estimation and removal of color noise. Gong et al. <ref type="bibr" target="#b14">[15]</ref> model the data fitting term as the weighted sum of the L 1 and L 2 norms, and utilize a sparsity regularizer in wavelet domain for handling mixed or unknown noises. Lebrun et al. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> propose an extension of non-local Bayes approach <ref type="bibr" target="#b26">[27]</ref> by modeling the noise of each patch group to be zero-mean correlated Gaussian distributed. Zhu et al. <ref type="bibr" target="#b63">[63]</ref> suggest a Bayesian nonparametric technique to remove the noise via the low-rank mix-ture of Gaussians (LR-MoG) model. Nam et al. <ref type="bibr" target="#b42">[43]</ref> model the cross-channel noise as a multivariate Gaussian and perform denoising by the Bayesian nonlocal means filter <ref type="bibr" target="#b23">[24]</ref>. Xu et al. <ref type="bibr" target="#b59">[59]</ref> suggest a multi-channel weighted nuclear norm minimization (MCWNNM) model to exploit channel redundancy. They further present a trilateral weighted sparse coding (TWSC) method for better modeling noise and image priors <ref type="bibr" target="#b58">[58]</ref>. Except noise clinic (NC) <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, MCWNNM <ref type="bibr" target="#b59">[59]</ref>, and TWSC <ref type="bibr" target="#b58">[58]</ref>, the codes of most blind denoisers are not available. Our experiments show that they are still limited for removing noise from real images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>This section presents our CBDNet consisting of a noise estimation subnetwork and a non-blind denoising subnetwork. To begin with, we introduce the noise model to generate synthetic noisy images. Then, the network architecture and asymmetric loss. Finally, we explain the incorporation of synthetic and real noisy images for training CBDNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Realistic Noise Model</head><p>As noted in <ref type="bibr" target="#b38">[39]</ref>, the generalization of CNN largely depends on the ability in memorizing training data. Existing CNN denoisers, e.g., DnCNN <ref type="bibr" target="#b61">[61]</ref>, generally does not work well on real noisy images, mainly due to that they may be over-fitted to AWGN while the real noise distribution is much different from Gaussian. On the other hand, when trained with a realistic noise model, the memorization ability of CNN will be helpful to make the learned model generalize well to real photographs. Thus, noise model plays a critical role in guaranteeing performance of CNN denoiser.</p><p>Different from AWGN, real image noise generally is more sophisticated and signal-dependent <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b13">14]</ref>. Practically, the noise produced by photon sensing can be modeled as Poisson, while the remaining stationary disturbances can be modeled as Gaussian. Poisson-Gaussian thus provides a reasonable noise model for the raw data of imaging sensors <ref type="bibr" target="#b13">[14]</ref>, and can be further approximated with a heteroscedastic Gaussian n(L) ? N (0, ? 2 (L)) defined as,</p><formula xml:id="formula_0">? 2 (L) = L ? ? 2 s + ? 2 c .<label>(1)</label></formula><p>where L is the irradiance image of raw pixels. n(L) = n s (L) + n c involves two components, i.e., a stationary noise component n c with noise variance ? 2 c and a signaldependent noise component n s with spatially variant noise variance L ? ? 2 s . Real photographs, however, are usually obtained after incamera processing (ISP), which further increases the complexity of noise and makes it spatially and chromatically correlated. Thus, we take two main steps of ISP pipeline, i.e., demosaicing and Gamma correction, into consideration, resulting in the realistic noise model as,</p><formula xml:id="formula_1">y = f (DM(L + n(L))),<label>(2)</label></formula><p>where y denotes the synthetic noisy image, f (?) stands for the camera response function (CRF) uniformly sampled from the 201 CRFs provided in <ref type="bibr" target="#b15">[16]</ref>. And L = Mf ?1 (x) is adopted to generate irradiance image from a clean image x. M(?) represents the function that converts sRGB image to Bayer image and DM(?) represents the demosaicing function <ref type="bibr" target="#b36">[37]</ref>. Note that the interpolation in DM(?) involves pixels of different channels and spatial locations. The synthetic noise in Eqn. <ref type="formula" target="#formula_1">(2)</ref> is thus channel and space dependent. Furthermore, to extend CBDNet for handling compressed image, we can include JPEG compression in generating synthetic noisy image, y = JP EG(f (DM(L + n(L)))).</p><p>(</p><p>For noisy uncompressed image, we adopt the model in Eqn.</p><p>(2) to generate synthetic noisy images. For noisy compressed image, we exploit the model in Eqn. <ref type="bibr" target="#b2">(3)</ref>. Specifically, ? s and ? c are uniformly sampled from the ranges of [0, 0.16] and [0, 0.06], respectively. In JPEG compression, the quality factor is sampled from the range <ref type="bibr" target="#b60">[60,</ref><ref type="bibr">100]</ref>. We note that the quantization noise is not considered because it is minimal and can be ignored without any obvious effect on denoising result <ref type="bibr" target="#b62">[62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Network Architecture</head><p>As illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>, the proposed CBDNet includes a noise estimation subnetwork CNN E and a non-blind denosing subnetwork CNN D . First, CNN E takes a noisy observation y to produce the estimated noise level map?(y) = F E (y; W E ), where W E denotes the network parameters of CNN E . We let the output of CNN E be the noise level map due to that it is of the same size with the input y and can be estimated with a fully convolutional network. Then, CNN D takes both y and?(y) as input to obtain the final denoising resultx = F D (y,?(y); W D ), where W D denotes the network parameters of CNN D . Moreover, the introduction of CNN E also allows us to adjust the estimated noise level map?(y) before putting it to the the non-blind denosing subnetwork CNN D . In this work, we present a simple strategy by letting? (y) = ? ??(y) for interactive denoising.</p><p>We further explain the network structures of CNN E and CNN D . CNN E adopts a plain five-layer fully convolutional network without pooling and batch normalization operations. In each convolution (Conv) layer, the number of feature channels is set as 32, and the filter size is 3 ? 3. The ReLU nonlinearity <ref type="bibr" target="#b41">[42]</ref> is deployed after each Conv layer. As for CNN D , we adopt an U-Net <ref type="bibr" target="#b51">[51]</ref> architecture which takes both y and?(y) as input to give a predictionx of the noise-free clean image. Following <ref type="bibr" target="#b61">[61]</ref>, the residual learning is adopted by first learning the residual mapping R(y,?(y); W D ) and then predictingx = y + R(y,?(y); W D ). The 16-layer U-Net architecture of CNN E is also given in <ref type="figure" target="#fig_0">Fig. 2</ref>, where symmetric skip connections, strided convolutions and transpose convolutions are introduced for exploiting multi-scale information as well as enlarging receptive field. All the filter size is 3?3, and the ReLU nonlinearity <ref type="bibr" target="#b41">[42]</ref> is applied after every Conv layer except the last one. Moreover, we empirically find that batch normalization helps little for the noise removal of real photographs, partially due to that the real noise distribution is fundamentally different from Gaussian.</p><p>Finally, we note that it is also possible to train a single blind CNN denoiser by learning a direct mapping from noisy observation to clean image. However, as noted in <ref type="bibr" target="#b62">[62,</ref><ref type="bibr" target="#b40">41]</ref>, taking both noisy image and noise level map as input is helpful in generalizing the learned model to images beyond the noise model and thus benefits blind denoising. We empirically find that single blind CNN denoiser performs on par with CBDNet for images with lower noise level, and is inferior to CBDNet for images with heavy noise. Furthermore, the introduction of noise estimation subnetwork also makes interactive denoising and asymmetric learning allowable. Therefore, we suggest to include the noise estimation subnetwork in our CBDNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Asymmetric Loss and Model Objective</head><p>Both CNN and traditional non-blind denoisers perform robustly when the input noise SD. is higher than the ground-truth one (i.e., over-estimation error), which encourages us to adopt asymmetric loss for improving generalization ability of CBDNet. As illustrates in FFDNet <ref type="bibr" target="#b62">[62]</ref>, BM3D/FFDNet achieve the best result when the input noise SD. and ground-truth noise SD. are matched. When the input noise SD. is lower than the ground-truth one, the results of BM3D/FFDNet contain perceptible noises. When the input noise SD. is higher than the ground-truth one, BM3D/FFDNet can still achieve satisfying results by gradually wiping out some low contrast structure along with the increase of input noise SD. Thus, non-blind denoisers are sensitive to under-estimation error of noise SD., but are robust to over-estimation error. With such property, BM3D/FFDNnet can be used to denoise real photographs by setting relatively higher input noise SD., and this might explain the reasonable performance of BM3D on the DND benchmark <ref type="bibr" target="#b44">[45]</ref> in the non-blind setting.</p><p>To exploit the asymmetric sensitivity in blind denoising, we present an asymmetric loss on noise estimation to avoid the occurrence of under-estimation error on the noise level map. Given the estimated noise level?(y i ) at pixel i and the ground-truth ?(y i ), more penalty should be imposed to their MSE when?(y i ) &lt; ?(y i ). Thus, we define the asymmetric loss on the noise estimation subnetwork as,</p><formula xml:id="formula_3">Lasymm = i |? ? I (?(y i )??(y i ))&lt;0 | ? (?(yi) ? ?(yi)) 2 ,<label>(4)</label></formula><p>where I e = 1 for e &lt; 0 and 0 otherwise. By setting 0 &lt; ? &lt; 0.5, we can impose more penalty to under-estimation error to make the model generalize well to real noise.</p><p>Furthermore, we introduce a total variation (TV) regularizer to constrain the smoothness of?(y),</p><formula xml:id="formula_4">LT V = ? h? (y) 2 2 + ?v?(y) 2 2 ,<label>(5)</label></formula><p>where ? h (? v ) denotes the gradient operator along the horizontal (vertical) direction. For the outputx of non-blind denoising, we define the reconstruction loss as,</p><formula xml:id="formula_5">Lrec = x ? x 2 2 .<label>(6)</label></formula><p>To sum up, the overall objective of our CBDNet is,</p><formula xml:id="formula_6">L = Lrec + ?asymmLasymm + ?T V LT V ,<label>(7)</label></formula><p>where ? asymm and ? T V denote the tradeoff parameters for the asymmetric loss and TV regularizer, respectively. In our experiments, the PSNR/SSIM results of CBDNet are reported by minimizing the above objective. As for qualitative evaluation of visual quality, we train CBDNet by further adding perceptual loss <ref type="bibr" target="#b22">[23]</ref> on relu3 3 of VGG-16 <ref type="bibr" target="#b54">[54]</ref> to the objective in Eqn. <ref type="bibr" target="#b6">(7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training with Synthetic and Real Noisy Images</head><p>The noise model in Sec. 3.1 can be used to synthesize any amount of noisy images. And we can also guarantee the high quality of the clean images. Even though, the noise in real photographs cannot be fully characterized by the noise model. Fortunately, according to <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b0">1]</ref>, nearly noisefree image can be obtained by averaging hundreds of noisy images from the same scene, and several datasets have been built in literatures. In this case, the scenes are constrained to be static, and it is generally expensive to acquire hundreds of noisy images. Moreover, the nearly noise-free image tends to be over-smoothing due to the averaging effect. Therefore, synthetic and real noisy images can be combined to improve the generalization ability to real photographs.</p><p>In this work, we use the noise model in Sec. 3.1 to generate the synthetic noisy images, and use 400 images from BSD500 <ref type="bibr" target="#b39">[40]</ref>, 1600 images from Waterloo <ref type="bibr" target="#b35">[36]</ref>, and 1600 images from MIT-Adobe FiveK dataset <ref type="bibr" target="#b6">[7]</ref> as the training data. Specifically, we use the RGB image x to synthesize clean raw image L = Mf ?1 (x) as a reverse ISP process and use the same f to generate noisy image as Eqns. <ref type="bibr" target="#b1">(2)</ref> or <ref type="formula" target="#formula_2">(3)</ref>, where f is a CRF randomly sampled from those in <ref type="bibr" target="#b15">[16]</ref>. As for real noisy images, we utilize the 120 images from the RENOIR dataset <ref type="bibr" target="#b3">[4]</ref>. In particular, we alternatingly use the batches of synthetic and real noisy images during training. For a batch of synthetic images, all the losses in Eqn. <ref type="bibr" target="#b6">(7)</ref> are minimized to update CBDNet. For a batch of real images, due to the unavailability of ground-truth noise level map, only L rec and L T V are considered in training. We empirically find that such training scheme is effective in improving the visual quality for denoising real photographs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Test Datasets</head><p>Three datasets of real-world noisy images, i.e., NC12 <ref type="bibr" target="#b28">[29]</ref>, DND <ref type="bibr" target="#b44">[45]</ref> and Nam <ref type="bibr" target="#b42">[43]</ref>, are adopted:</p><p>NC12 includes 12 noisy images. The ground-truth clean images are unavailable, and we only report the denoising results for qualitative evaluation.</p><p>DND contains 50 pairs of real noisy images and the corresponding nearly noise-free images. Analogous to <ref type="bibr" target="#b3">[4]</ref>, the nearly noise-free images are obtained by carefully postprocessing of the low-ISO images. PSNR/SSIM results are obtained through the online submission system.</p><p>Nam contains 11 static scenes and for each scene the nearly noise-free image is the mean image of 500 JPEG noisy images. We crop these images into 512 ? 512 patches and randomly select 25 patches for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>The model parameters in Eqn. <ref type="bibr" target="#b6">(7)</ref> are given by ? = 0.3, ? 1 = 0.5, and ? 2 = 0.05. Note that the noisy images from Nam <ref type="bibr" target="#b42">[43]</ref> are JPEG compressed, while the noisy images from DND <ref type="bibr" target="#b44">[45]</ref> are uncompressed. Thus we adopt the noise model in Eqn. (2) to train CBDNet for DND and NC12, and the model in Eqn. (3) to train CBDNet(JPEG) for Nam.</p><p>To train our CBDNet, we adopt the ADAM <ref type="bibr" target="#b25">[26]</ref> algorithm with ? 1 = 0.9. The method in <ref type="bibr" target="#b17">[18]</ref> is adopted for model initialization. The size of mini-batch is 32 and the size of each patch is 128 ? 128. All the models are trained with 40 epochs, where the learning rate for the first 20 epochs is 10 ?3 , and then the learning rate 5 ? 10 ?4 is used to further fine-tune the model. It takes about three days to train our CBDNet with the MatConvNet package [56] on a Nvidia GeForce GTX 1080 Ti GPU.  <ref type="bibr" target="#b64">[64]</ref> Non-blind sRGB 33.51 0.8244 TNRD <ref type="bibr" target="#b10">[11]</ref> Non-blind sRGB 33.65 0.8306 NCSR <ref type="bibr" target="#b12">[13]</ref> Non-blind sRGB 34.05 0.8351 MLP <ref type="bibr" target="#b5">[6]</ref> Non-blind sRGB 34.23 0.8331 FFDNet <ref type="bibr" target="#b62">[62]</ref> Non-blind sRGB 34.40 0.8474 BM3D <ref type="bibr" target="#b11">[12]</ref> Non-blind sRGB 34.51 0.8507 FoE <ref type="bibr" target="#b52">[52]</ref> Non-blind sRGB 34.62 0.8845 WNNM <ref type="bibr" target="#b16">[17]</ref> Non-blind sRGB 34.67 0.8646 GCBD <ref type="bibr" target="#b9">[10]</ref> Blind sRGB 35.58 0.9217 CIMM <ref type="bibr" target="#b4">[5]</ref> Non-blind sRGB 36.04 0.9136 KSVD <ref type="bibr" target="#b2">[3]</ref> Non-blind sRGB <ref type="bibr" target="#b35">36</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with State-of-the-arts</head><p>We consider four blind denoising approaches, i.e., NC <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28]</ref>, NI <ref type="bibr" target="#b1">[2]</ref>, MCWNNM <ref type="bibr" target="#b59">[59]</ref> and TWSC <ref type="bibr" target="#b58">[58]</ref> in our comparison. NI <ref type="bibr" target="#b1">[2]</ref> is a commercial software and has been included into Photoshop and Corel PaintShop. Besides, we also include a blind Gaussian denoising method (i.e., CDnCNN-B <ref type="bibr" target="#b61">[61]</ref>), and three non-blind denoising methods (i.e., CBM3D <ref type="bibr" target="#b11">[12]</ref>, WNNM <ref type="bibr" target="#b16">[17]</ref>, FFDNet <ref type="bibr" target="#b62">[62]</ref>). When apply non-blind denoiser to real photographs, we exploit <ref type="bibr" target="#b8">[9]</ref> to estimate the noise SD.. <ref type="figure">Fig. 3</ref> shows the results of an NC12 images. All the competing methods are limited in removing noise in the dark region. In comparison, CBDNet performs favorably in removing noise while preserving salient image structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NC12.</head><p>DND. <ref type="table" target="#tab_0">Table 1</ref> lists the PSNR/SSIM results released on the DND benchmark website. Undoubtedly, CDnCNN-B <ref type="bibr" target="#b61">[61]</ref> cannot be generalized to real noisy photographs and performs very poorly. Although the noise SD. is provided, non-blind Gaussian denoisers, e.g., WNNM <ref type="bibr" target="#b16">[17]</ref>, BM3D <ref type="bibr" target="#b11">[12]</ref> and FoE <ref type="bibr" target="#b52">[52]</ref>, only achieve limited performance, mainly due to that the real noise is much different from AWGN. MCWNNM <ref type="bibr" target="#b59">[59]</ref> and TWSC <ref type="bibr" target="#b58">[58]</ref> are specially designed for blind denoising of real photographs, and also achieve promising results. Benefited from the realistic noise model and incorporation with real noisy images, our CBDNet achieves the highest PSNR/SSIM results, and slightly better than MCWNNM <ref type="bibr" target="#b59">[59]</ref> and TWSC <ref type="bibr" target="#b58">[58]</ref>. CBD-Net also significantly outperforms another CNN-based denoiser, i.e., CIMM <ref type="bibr" target="#b4">[5]</ref>. As for running time, CBDNet takes about 0.4s to process an 512 ? 512 image. <ref type="figure">Fig. 4</ref> provides the denoising results of an DND image. BM3D and CDnCNN-B fail to remove most noise from real photograph, NC, NI, MCWNNM and TWSC still cannot remove all noise, and NI also suffers from the over-smoothing effect. In comparison, our CBDNet performs favorably in balancing noise removal and structure preservation.  Nam. The quantitative and qualitative results are given in <ref type="table" target="#tab_2">Table 2</ref> and <ref type="figure">Fig. 5</ref>. CBDNet(JPEG) performs much better than CBDNet (i.e., ? 1.3 dB by PSNR) and achieves the best performance in comparison to state-of-the-arts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Studies</head><p>Effect of noise model. Instead of AWGN, we consider heterogeneous Gaussian (HG) and in-camera processing (ISP) pipeline for modeling image noise. On DND and Nam, we implement four variants of noise models: (i) Gaussian noise (CBDNet(G)), (ii) heterogeneous Gaussian (CBDNet(HG)), (iii) Gaussian noise and ISP (CBD-Net(G+ISP)), and (iv) heterogeneous Gaussian and ISP (CBDNet(HG+ISP), i.e., full CBDNet. For Nam, CBD-Net(JPEG) is also included.  <ref type="bibr" target="#b16">[17]</ref> (c) FFDNet <ref type="bibr" target="#b62">[62]</ref> (d) NC <ref type="bibr" target="#b28">[29]</ref> (e) NI <ref type="bibr" target="#b1">[2]</ref> (f) MCWNNM <ref type="bibr" target="#b59">[59]</ref> (g) TWSC <ref type="bibr" target="#b58">[58]</ref> (h) CBDNet <ref type="figure">Figure 3</ref>: Denoising results of another NC12 image by different methods.</p><p>(a) Noisy image (b) BM3D <ref type="bibr" target="#b11">[12]</ref> (c) CDnCNN-B <ref type="bibr" target="#b61">[61]</ref> (d) NC <ref type="bibr" target="#b28">[29]</ref> (e) NI <ref type="bibr" target="#b1">[2]</ref> (f) MCWNNM <ref type="bibr" target="#b59">[59]</ref> (g) TWSC <ref type="bibr" target="#b58">[58]</ref> (h) CBDNet <ref type="figure">Figure 4</ref>: Denoising results of a DND image by different methods.</p><p>(a) Noisy image (b) WNNM <ref type="bibr" target="#b16">[17]</ref> (c) CDnCNN-B <ref type="bibr" target="#b61">[61]</ref> (d) NC <ref type="bibr" target="#b28">[29]</ref> (e) NI <ref type="bibr" target="#b1">[2]</ref> (f) MCWNNM <ref type="bibr" target="#b59">[59]</ref> (g) TWSC <ref type="bibr" target="#b58">[58]</ref> (h) CBDNet <ref type="figure">Figure 5</ref>: Denoising results of a Nam image by different methods.  noise-free images. In comparison, CBDNet(All) is effective in removing real noise while preserving sharp edges. Also quantitative results of the three models on DND are shown in <ref type="table" target="#tab_0">Table 1</ref>. CBDNet(All) obtains better PSNR/SSIM results than CBDNet(Syn) and CBDNet(Real). Asymmetric loss. <ref type="figure" target="#fig_3">Fig. 8</ref> compares the denoising results of CBDNet with different ? values, i.e., ? = 0.5, 0.4 and 0.3. CBDNet imposes equal penalty to under-estimation and over-estimation errors when ? = 0.5, and more penalty is imposed on under-estimation error when ? &lt; 0.5. It can be seen that smaller ? (i.e., 0.3) is helpful in improving the generalization ability of CBDNet to unknown real noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Interactive Image Denoising</head><p>Given the estimated noise level map?(y), we introduce a coefficient ? (&gt; 0) to interactively modify?(y) to? = ? ??(y). By allowing the user to adjust ?, the non-blind denoising subnetwork takes? and the noisy image as input to obtain denoising result. <ref type="figure">Fig. 6</ref> presents two real noisy DND images as well as the results obtained using different ? values. By specifying ? = 0.7 to the first image and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a CBDNet for blind denoising of realworld noisy photographs. The main findings of this work are two-fold. First, realistic noise model, including heterogenous Gaussian and ISP pipeline, is critical in making the learned model from synthetic images be applicable to real-world noisy photographs. Second, the denoising performance of a network can be boosted by incorporating both synthetic and real noisy images in training. Moreover, by introducing a noise estimation subnetwork into CBDNet, we were able to utilize asymmetric loss to improve its generalization ability to real-world noise, and perform interactive denoising conveniently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of our CBDNet for blind denoising of real-world noisy photograph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>? = 0.4 (c) ? = 0.7 (d) ? = 1.0 (e) ? = 1.3 (f) ? = 1.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Results by interactive image denoising on two DND images. Denoising results of CBDNet trained by different data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 :</head><label>8</label><figDesc>Denoising results of CBDNet with different ? values ? = 1.3 to the second, CBDNet can achieve the results with better visual quality in preserving detailed textures and removing sophisticated noise, respectively. Such interactive scheme can thus provide a convenient means for adjusting the denosing results in practical scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The quantitative results on the DND benchmark.</figDesc><table><row><cell>Method</cell><cell>Blind/Non-blind</cell><cell>Denoising on</cell><cell>PSNR</cell><cell>SSIM</cell></row><row><cell>CDnCNN-B [61]</cell><cell>Blind</cell><cell>sRGB</cell><cell>32.43</cell><cell>0.7900</cell></row><row><cell>EPLL</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The quantitative results on the Nam dataset<ref type="bibr" target="#b42">[43]</ref>.</figDesc><table><row><cell>Method</cell><cell>Blind/Non-blind</cell><cell>PSNR</cell><cell>SSIM</cell></row><row><cell>NI [2]</cell><cell>Blind</cell><cell>31.52</cell><cell>0.9466</cell></row><row><cell>CDnCNN-B [61]</cell><cell>Blind</cell><cell>37.49</cell><cell>0.9272</cell></row><row><cell>TWSC [58]</cell><cell>Blind</cell><cell>37.52</cell><cell>0.9292</cell></row><row><cell>MCWNNM [59]</cell><cell>Blind</cell><cell>37.91</cell><cell>0.9322</cell></row><row><cell>BM3D [12]</cell><cell>Non-blind</cell><cell>39.84</cell><cell>0.9657</cell></row><row><cell>NC [29]</cell><cell>Blind</cell><cell>40.41</cell><cell>0.9731</cell></row><row><cell>WNNM [17]</cell><cell>Non-blind</cell><cell>41.04</cell><cell>0.9768</cell></row><row><cell>CBDNet</cell><cell>Blind</cell><cell>40.02</cell><cell>0.9687</cell></row><row><cell>CBDNet(JPEG)</cell><cell>Blind</cell><cell>41.31</cell><cell>0.9784</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>PSNR/SSIM results by different noise models.</figDesc><table><row><cell>Method</cell><cell>DND [45]</cell><cell>Nam [43]</cell></row><row><cell>CBDNet(G)</cell><cell>32.52 / 0.79</cell><cell>37.62 / 0.9290</cell></row><row><cell>CBDNet(HG)</cell><cell>33.70 / 0.9084</cell><cell>38.40 / 0.9453</cell></row><row><cell>CBDNet(G+ISP)</cell><cell>37.41 / 0.9353</cell><cell>39.03 / 0.9563</cell></row><row><cell>CBDNet(HG+ISP)</cell><cell>37.57 / 0.9360</cell><cell>39.20 / 0.9579</cell></row><row><cell>CBDNet(JPEG)</cell><cell>-</cell><cell>40.51 / 0.9745</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>shows the PSNR/SSIM results of different noise models. G vs HG. Without ISP, CBDNet(HG) achieves about 0.8 ? 1 dB gain over CBDNet(G). When ISP is included, the gain by HG is moderate, i.e., CBDNet(HG+ISP) only outperforms CBDNet(G+ISP) about 0.15 dB. w/o ISP. In comparison, ISP is observed to be more critical for modeling real image noise. In particular, CBD-Net(G+ISP) outperforms CBDNet(G) by 4.88 dB, while CBDNet(HG+ISP) outperforms CBDNet(HG) by 3.87 dB on DND. For Nam, the inclusion of JPEG compression in ISP further brings a gain of 1.31 dB.</figDesc><table><row><cell>Incorporation of synthetic and real images. We imple-</cell></row><row><cell>ment two baselines: (i) CBDNet(Syn) trained only on syn-</cell></row><row><cell>thetic images, and (ii) CBDNet(Real) trained only on real</cell></row><row><cell>images, and rename our full CBDNet as CBDNet(All). Fig.</cell></row><row><cell>7 shows the denoising results of these three methods on a</cell></row><row><cell>NC12 image. Even trained on large scale synthetic image</cell></row><row><cell>dataset, CBDNet(Syn) still cannot remove all real noise,</cell></row><row><cell>partially due to that real noise cannot be fully character-</cell></row><row><cell>ized by the noise model. CBDNet(Real) may produce over-</cell></row><row><cell>smoothing results, partially due to the effect of imperfect</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by NSFC (grant no. 61671182, 61872118, 61672446) and HK RGC General Research Fund (PolyU 152216/18E).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A high-quality denoising dataset for smartphone cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Abdelhamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1692" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<ptr target="https://ni.neatvideo.com/home" />
	</analytic>
	<monogr>
		<title level="j">Neatlab ABSoft. Neat image</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ksvd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Renoir -a dataset for real low-light noise image reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josue</forename><surname>Anaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Barbu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Chaining identity mapping modules for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong Phuoc</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih Murat</forename><surname>Porikli</surname></persName>
		</author>
		<idno>abs/1712.02933</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with bm3d?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><forename type="middle">Christopher</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning photographic global tonal adjustment with a database of input / output image pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Bychkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?do</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyam</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
		</author>
		<title level="m">Is denoising dead? IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="895" to="911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An efficient statistical method for image noise level estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image blind denoising with generative adversarial network based noise modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3155" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Color image denoising via sparse 3d collaborative filtering with grouping constraint in luminancechrominance space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">O</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>:I -313-I -316</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisheng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Practical poissonian-gaussian noise modeling and fitting for single-image raw-data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mejdi</forename><surname>Trimeche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">O</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1737" to="1754" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image restoration with mixed or unknown noises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuowei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim-Chuan</forename><surname>Toh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Modeling and Simulation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="458" to="487" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling the space of camera response functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shree</forename><forename type="middle">K</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1272" to="1282" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2862" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Difference-based image noise modeling using skellam distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngbae</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Sik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In-So</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1329" to="1341" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Sebastian</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bayesian non-local means filter, image redundancy and adaptive dictionaries for noise removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Boulanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierrick</forename><surname>Coup?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSVM</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new in-camera imaging model for color computer vision and its application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seon Joo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><forename type="middle">Ting</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>S?sstrunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2289" to="2302" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A nonlocal bayesian image denoising algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lebrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1665" to="1688" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiscale image blind denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lebrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Colom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="3149" to="3161" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The noise clinic: a blind image denoising algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lebrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Colom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Michel</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPOL Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Munkberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Hasselgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.04189</idno>
		<title level="m">Noise2noise: Learning image restoration without clean data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Patch complexity, finite pixel correlations and optimal denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?do</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic estimation and removal of noise from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Sing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Multi-level wavelet-cnn for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengju</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<idno>abs/1805.07071</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Single-image noise level estimation for blind denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="5226" to="5237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Practical signal-dependent noise parameter estimation from a single noisy image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="4361" to="4371" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Waterloo exploration database: New challenges for image quality assessment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kede</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengfang</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1004" to="1016" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Highquality linear interpolation for demosaicing of bayerpatterned color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Henrique</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei</forename><surname>Malvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cutler</surname></persName>
		</author>
		<idno>iii-485</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings.(ICASSP&apos;04). IEEE International Conference on</title>
		<meeting>.(ICASSP&apos;04). IEEE International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>Acoustics, Speech, and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Jiao</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Bin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahoney</surname></persName>
		</author>
		<idno>abs/1710.09553</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int&apos;l Conf. Computer Vision</title>
		<meeting>8th Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001-07" />
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Burst denoising with kernel prediction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dillon</forename><surname>Sharlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2502" to="2510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A holistic approach to cross-channel image noise modeling and its application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonghyeon</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngbae</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuyuki</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seon Joo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1683" to="1691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Radiometric calibration of ccd sensors: dark current and fixed pattern noise estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4730" to="4735" />
		</imprint>
	</monogr>
	<note>Proceedings. ICRA &apos;04</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Benchmarking denoising algorithms with real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Plotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2750" to="2759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Blind non-white noise removal in images using gaussian scale mixtures in the wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Portilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Benelux Signal Processing Symposium</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Full blind denoising through noise covariance estimation using gaussian scale mixtures in the wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Portilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1217" to="1220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image noise level estimation by principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Pyatykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Hesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="687" to="699" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust estimation approach for blind denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rabie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1755" to="1765" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The little engine that could: Regularization by denoising (red)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1611.02862</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fields of experts: a framework for learning image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Shrinkage fields for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2774" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Memnet: A persistent memory network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4549" to="4557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Matconvnet -convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linli</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A trilateral weighted sparse coding scheme for real-world image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multi-channel weighted nuclear norm minimization for real color image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1105" to="1113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Bm3d-net: A convolutional neural network for transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Ffdnet: Toward a fast and flexible solution for cnn based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<idno>abs/1710.04026</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">From noise modeling to blind image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
