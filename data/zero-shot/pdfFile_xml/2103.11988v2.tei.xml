<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-paced ensemble learning for speech and audio classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolae-C?t?lin</forename><surname>Ristea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University Politehnica of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><forename type="middle">Tudor</forename><surname>Ionescu</surname></persName>
							<email>raducu.ionescu@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-paced ensemble learning for speech and audio classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: ensemble learning</term>
					<term>self-paced learning</term>
					<term>speech emotion recognition</term>
					<term>tropical species detection</term>
					<term>mask detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Combining multiple machine learning models into an ensemble is known to provide superior performance levels compared to the individual components forming the ensemble. This is because models can complement each other in taking better decisions. Instead of just combining the models, we propose a self-paced ensemble learning scheme in which models learn from each other over several iterations. During the self-paced learning process based on pseudo-labeling, in addition to improving the individual models, our ensemble also gains knowledge about the target domain. To demonstrate the generality of our self-paced ensemble learning (SPEL) scheme, we conduct experiments on three audio tasks. Our empirical results indicate that SPEL significantly outperforms the baseline ensemble models. We also show that applying self-paced learning on individual models is less effective, illustrating the idea that models in the ensemble actually learn from each other.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>State-of-the-art machine learning models are trained using supervision in the form of labeled data samples provided by an oracle (a domain expert or an ordinary human that knows how to label the samples). However, effective human learners have the ability to guide themselves through the learning activities, considering increasingly difficult concepts at their own pace, without the help of an oracle (a teacher). Indeed, most of the times, students choose what, how, when and how long to study, implicitly using a self-paced curriculum. These self-regulated aspects of learning influence the future results of the learner. This cognitive learning paradigm inspired researchers to study and propose machine learning models based on self-paced learning (SPL) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. We underline that SPL can be seen as a particular case of curriculum learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, in which the difficulty of the examples is estimated by the model itself, hence the self-pacing. A variety of SPL schemes have been designed for different computer vision <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref> and other pattern recognition tasks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, with demonstrated improvements over the standard supervised learning paradigm in specific scenarios. In signal processing, there are only a handful of approaches based on SPL <ref type="bibr" target="#b7">[8]</ref>.</p><p>In the most straightforward SPL approach, the model uses its own confidence scores to determine what are the next examples to learn. However, if the examples come from a different (target) domain and their ground-truth labels are not available, the model can only use the labels predicted by itself (pseudolabels). Therefore, in the context of unsupervised domain adaptation, we encounter a paradox: there is little new information to be learned from pseudo-labeled examples that are selected by the model with high confidence. To overcome the paradox, some methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> use an external difficulty predictor. In this work, we conjecture that useful information can be learned simply by training multiple models together. To this end, we propose to jointly train an ensemble of models that learn from each other through SPL. More precisely, an individual model from the ensemble will benefit from the pseudo-labels and the confidence scores provided by the whole ensemble, thus being able to take useful information from the other models included in the ensemble. To the best of our knowledge, we are the first to propose self-paced ensemble learning (SPEL) in the audio domain. By combining self-paced learning and ensemble learning into a single framework, there are two essential benefits: higher effectiveness and increased generality. To demonstrate the benefits of SPEL, we conduct experiments on three audio benchmark tasks, namely speech emotion recognition on CREMA-D <ref type="bibr" target="#b10">[11]</ref>, speech mask detection on MSC <ref type="bibr" target="#b11">[12]</ref> and bird and frog species detection on RCSAD <ref type="bibr" target="#b12">[13]</ref>. Our empirical results indicate that SPEL provides superior results than the baseline ensembles and the stateof-the-art methods. In addition, we present ablation results on CREMA-D showing that employing self-paced learning on an individual model is less effective, indicating that models in an ensemble can effectively learn from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Ensemble learning. On the one hand, traditional machine learning models may fail to attain the desired performance level when dealing with high-dimensional, noisy or imbalanced data. The reason behind this is that such models belong to restricted hypothesis classes, thus not being able to discover complex patterns revealing the underlying structure of the data. On the other hand, deep neural networks can model such complex patterns when sufficient data is available, but such models lack stability, mainly due to the random initialization of parameters and the stochastic optimization process. In both cases, ensemble learning <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> offers improved effectiveness and stability by integrating multiple models into a single framework. There are several ensemble learning methods in literature, ranging from majority voting <ref type="bibr" target="#b15">[16]</ref> and Bayesian model averaging <ref type="bibr" target="#b16">[17]</ref> to bagging <ref type="bibr" target="#b17">[18]</ref>, boosting <ref type="bibr" target="#b18">[19]</ref> and classifier stacking <ref type="bibr" target="#b19">[20]</ref>. As other ensemble learning methods applied in the audio domain <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, we employ Bayesian model averaging in our method. Different from the related methods, we adapt our ensemble to the target domain using self-paced learning, attaining superior results. Self-paced learning. The vast majority of SPL approaches proposed in literature are focused on computer vision topics, the technique being proved effective in many vision tasks <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. Sangineto et al. <ref type="bibr" target="#b22">[23]</ref> proposed a new protocol based on the selfpaced learning paradigm, where the main idea is to iteratively select a subset of images and bounding boxes that are the most reliable, and use them for training. The proposed method outperforms related weakly-supervised object detectors, attaining state-of-the-art results. Zhou et al. <ref type="bibr" target="#b23">[24]</ref> designed a model based on an SPL regime performing person re-identification, which usually suffers from noisy samples with background clutter and mutual occlusion, making it extremely difficult to distinguish different individuals across disjoint camera views. Their solution seems to overpass these issues, attaining superior performance in comparison with state-of-the-art approaches.</p><p>Different from these methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, we employ an algorithm that combines the advantages of ensemble learning and SPL, resulting in a more effective and stable approach. Self-paced ensemble learning. Pi et al. <ref type="bibr" target="#b24">[25]</ref> proposed a selfpaced boost learning method that incorporates an adaptive easyto-hard pace in the boosting process. The method is demonstrated on generic tasks using weak learners such as Logistic Regression or Support Vector Machines. Liu et al. <ref type="bibr" target="#b25">[26]</ref> introduced a self-paced ensemble method to cope with the class imbalance problem. The method is based on combining selfpaced learning with undersampling to generate a robust ensemble. As Pi et al. <ref type="bibr" target="#b24">[25]</ref>, they demonstrated the utility of the proposed method on ensembles of weak learners. Since deep neural networks require large data sets during training, the undersampling approach of Liu et al. <ref type="bibr" target="#b25">[26]</ref> is not suitable for deep models. In contrast, we propose an ensemble of deep models and apply SPL for unsupervised domain adaptation.</p><p>SPL has also been applied on clustering methods. For example, Zhou et al. <ref type="bibr" target="#b6">[7]</ref> proposed a novel self-paced clustering ensemble that gradually adds instances, from easy to difficult, into the ensemble learning. Their approach overcomes the existing problems of ensemble clustering methods, which usually exploit all data samples to learn a consensus clustering result, ignoring the adverse effects caused by difficult instances. Ghasedi et al. <ref type="bibr" target="#b26">[27]</ref> proposed a different clustering approach, in which a balanced self-paced learning algorithm improves the training process of deep generative adversarial clustering networks, tackling the drawbacks of training deep clustering models in an unsupervised manner. Unlike these methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b26">27]</ref>, we focus on supervised classification and detection problems.</p><p>Wang et al. <ref type="bibr" target="#b27">[28]</ref> used SPL in a very particular scenario, focusing on a Random Forest ensemble applied specifically to lung cancer prognosis. Different from Wang et al. <ref type="bibr" target="#b27">[28]</ref>, we consider ensembles composed of various deep neural architectures applied on a broad variety of audio tasks.</p><p>Unlike the aforementioned methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, we employ an ensemble of deep neural networks that are (i) trained on the source domain using standard supervision, then (ii) fine-tuned on the target domain using self-paced learning with pseudo-labeling, leading to a more robust ensemble with superior results on multiple audio classification and detection tasks. To the best of our knowledge, there is no prior work based on self-paced ensemble learning in the audio domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Data representation. We first transform each audio sample into a 2D representation in order to be able to employ stateof-the-art convolutional neural networks (CNNs) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> based on 2D convolutions. To this end, we compute the discrete Short Time Fourier Transform (STFT), as follows:</p><formula xml:id="formula_0">ST F T {x[n]}(m, k) = ? n=?? x[n]?w[n?mR]?e ?j 2? Nx kn , (1) where x[n] is the discrete input signal, w[n]</formula><p>is a window function (in our approach, Hann), Nx is the STFT length and R is the hop (step) size <ref type="bibr" target="#b30">[31]</ref>. Afterwards, we compute the spectrograms as the squared magnitude of the STFT, convert the result-ing values to a logarithmic scale (decibels) and normalize them to the interval [?1, 1], generating a single-channel grayscale image. Moreover, the frequency bins were mapped onto the Mel scale with 256 Mel bands. Baseline model ensemble. As our learning approach, we consider an ensemble of residual neural networks <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b31">32]</ref> that are combined through Bayesian model averaging. We employ residual nets because such architectures are known to produce state-of-the-art results on a wide variety of tasks, mainly due to their very high depth. In order to significantly increase the depth over the previous models <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref>, He et al. <ref type="bibr" target="#b28">[29]</ref> introduced skip connections to eliminate vanishing gradient problems in training very deep neural models, providing alternative pathways for the gradients during back-propagation. We opted for different residual architectures for each data set, adjusting each architecture and ensemble to match the complexity of the task and the number of data samples. Depending on the data set, our ensemble is typically formed of four or five residual nets. Self-paced ensemble learning. In self-paced learning, machine learning models learn at their own pace, taking into consideration the samples with high confidence predictions first. This technique is robust in solving problems with noisy labels <ref type="bibr" target="#b33">[34]</ref>. In our work, we consider an unsupervised domain adaptation scenario, in which the ground-truth labels of the target domain samples used for SPL are unknown. Hence, the model needs to learn from its own labels, called pseudo-labels. We propose an automatic self-paced ensemble learning technique that iteratively enriches the training data with self-annotated examples from the target domain. The proposed approach assumes no overhead at testing time, the network architectures being identical (we only update the models' weights). The steps required by our framework are formally described in Algorithm 1. The algorithm is divided into three stages. The first two stages are about training the ensemble, while the third stage is about evaluating the ensemble on the final test set.</p><p>In the first stage (steps 1-6), we employ the conventional training procedure based on stochastic gradient descent with mini-batches. Each neural network fi which is part of the ensemble is optimized until we reach an optimal convergence point. At the current iteration t, the first step (step 4) is to randomly sample a mini-batch of labeled examples from the training data set (X, T ). Then, at step 5, the weights ?i corresponding to the network fi are updated in the negative direction of the gradient of the loss function ?L, the update step being controlled through the learning rate ?.</p><p>In the second stage (steps 7-18), we employ our self-paced ensemble learning procedure for a number of k iterations, where k is a pre-established hyperparameter of our method. At each iteration, we start by computing the predicted labels P? and the confidence scores C? provided by the ensemble (step 8) for the unlabeled set? , which belongs to the target domain. Next, at step 9, we sort the set of samples? and the associated pseudo-labels P? with respect to C? , in decreasing order of the confidence scores. Afterwards, we select m ? j samples (step 10) and the corresponding pseudo-labels (step 11), which are added (steps 12 and 13) to the new training set (X , T ). We underline that at each iteration j, the number of extra samples is m, where m is another pre-established hyperparameter of our method. As the confidence scores of the previously included samples may change over time, we re-evaluate them at each iteration j, regenerating X and T . Hence, at iteration j, we add m ? j pseudo-labeled samples. Upon forming the new training set (X , T ), we continue the training of the individual models, applying stochastic gradient descent with mini-batches  while converge criterion not met do 4:</p><formula xml:id="formula_1">X (t) , T (t) ? mini-batch ? U ((X, T )) 5: ? (t+1) i = ? (t) i ? ? (t) ?L ? (t) i , X (t) , T (t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>t ? t + 1 Stage 2: Self-paced ensemble learning <ref type="bibr">7:</ref> for j ? 1 to k do 8:</p><formula xml:id="formula_2">P? , C? ? avg f1 ? (t) 1 ,? , ..., fn ? (t) n ,? 9:? , P? ? sort ? , P? with respect to C? 10:X (j) ?? [1 : m ? j] 11:T (j) ? P? [1 : m ? j] 12: X ? X ?X (j)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>T ? T ?T (j)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>for i ? 1 to n do <ref type="bibr">15:</ref> while converge criterion not met do <ref type="bibr" target="#b15">16</ref>:</p><formula xml:id="formula_3">X (t) , T (t) ? mini-batch ? U ((X , T )) 17: ? (t+1) i = ? (t) i ? ? (t) ?L ? (t) i , X (t) , T (t) 18: t ? t + 1 Stage 3: Prediction 19: PY ? avg f1 ? (t) 1 , Y , ..., fn ? (t) n , Y</formula><p>in steps 14-18. We underline that, by eliminating the second training stage, we fall back on the baseline ensemble learning.</p><p>In the third and final stage (step 19), we apply our ensemble based on Bayesian model averaging on the test set Y , obtaining the final predictions PY . We note that the proposed self-paced ensemble learning algorithm can be applied on top of any type of ensemble and it does not involve any additional overhead at test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data sets</head><p>CREMA-D. The CREMA-D multi-modal database <ref type="bibr" target="#b10">[11]</ref> contains 7,442 videoclips of 91 actors (48 male and 43 female) with different ethnic backgrounds. The actors were asked to simulate particular emotions while producing, with different intonations, 12 particular sentences that evoke the target emotions. There are six emotion categories: neutral, happy, anger, disgust, fear and sad. In our experiments, we consider only the audio modal-ity as source of information. We split the audio samples into 70% for training, 15% for validation and 15% for testing. RCSAD. The Rainforest Connection Species Audio Detection (RCSAD) data set <ref type="bibr" target="#b12">[13]</ref> is released by Rainforest Connection (RFCx) and is based on acoustic data collected while monitoring the ecosystem soundscape at tropical locations. RCSAD contains 4,727 audio files for training and 1,992 audio files for testing. We kept 20% of the training set for validation. The data set contains 24 classes representing bird and frog species from tropical regions. An audio sample may contain one or more species. Therefore, the goal is to solve a multi-label classification task. The data set is released in a recent Kaggle competition, implying that the only way to evaluate a model is by making a submission on Kaggle, i.e. the test labels are private. MSC. The Mask Augsburg Speech Corpus (MSC) is provided by the ComParE organizers <ref type="bibr" target="#b11">[12]</ref>. It comprises recordings of 32 German native speakers, with or without wearing surgical masks. Each data sample is a recording of 1 second at a sampling rate of 16 KHz. The data set is partitioned into a training set of 10,895 samples, a development set of 14,647 samples and a test set of 11,012 samples. Since the test labels are private, we report results on the development set, keeping 20% of the training set for validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation setup</head><p>Performance measures. For the CREMA-D data set, we report the classification accuracy. For the RCSAD data set, the Kaggle competition organizers decided to rank participants based on the weighted label-ranking average precision (WLRAP). Therefore, we report our performance in terms of this measure. Regarding the MSC data set, we report the unweighted average recall (UAR), this being the official measure in the ComParE challenge <ref type="bibr" target="#b11">[12]</ref>. Baselines. On all data sets, we consider as baseline the model ensemble trained without the second stage described in Algorithm 1. For the CREMA-D data set, we added as baselines two state-of-the-art methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> that reported the accuracy on the audio modality. For RCSAD, we refer to our ranking in the Kaggle competition, as there are no prior publications reporting results on this data set. For both CREMA-D and RCSAD, we also report the results of the best model in the baseline ensemble. For the MSC data set, we considered the official competition baseline as well as the approach proposed in <ref type="bibr" target="#b36">[37]</ref>, the latter approach coinciding with our baseline model ensemble. Data preprocessing and tuning. We first standardized all audio clips to a fixed dimension. For CREMA-D, we padded or clipped the audio files to 4 seconds, while for RCSAD, we extracted an 8 second window centered on each training detection and we applied the sliding window algorithm at test time, keeping the maximum probabilities. The length of the MSC audio files is already established by the organizers at 1 second. When applying the STFT, we used Nx = 1024, R = 64 and a window size of 512. Each utterance is represented as a Mel spectrogram of 1 ? L ? 256 components, where 256 is the number of Mel bins and L represents the number of time bins, which is 512 for CREMA-D and 618 for RCSAD. Exceptionally, on the MSC data set, we performed the preprocessing proposed in <ref type="bibr" target="#b36">[37]</ref>, which involves only STFT.</p><p>While our ensembles are all based on residual nets, we used slight different architectures on the three data sets. For CREMA-D, we employed an ensemble of five ResNet-18 models <ref type="bibr" target="#b28">[29]</ref> with leaky ADA activations <ref type="bibr" target="#b37">[38]</ref> which increase the model's capability to classify non-linearly separable data, such as emotions from voice recordings. For RCSAD, we consid- <ref type="table">Table 1</ref>: Results of our SPEL approach versus various baseline and state-of-the-art methods on CREMA-D. Significantly better self-paced learning results are marked with ?, using a paired McNemar's test <ref type="bibr" target="#b39">[40]</ref> at the significance level 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Accuracy</head><p>Shukla et al. <ref type="bibr" target="#b34">[35]</ref> 55.01 He et al. <ref type="bibr" target="#b35">[36]</ref> 58.71</p><p>ResNet-18 + leaky ADA <ref type="bibr" target="#b37">[38]</ref> 65.37 ResNet-18 + leaky ADA <ref type="bibr" target="#b37">[38]</ref>   ered an ensemble of five ResNeSt-50 models <ref type="bibr" target="#b31">[32]</ref>. We modified the classification layer of the ResNeSt-50 network to predict 24 classes and added a sigmoid activation function, such that the network is able to output the probability of each class independently of the other classes. For MSC, the ensemble comprises a ResNet-18, a ResNet-34, a ResNet-50 and a ResNet-101, being identical to the ensemble proposed by Ristea et al. <ref type="bibr" target="#b36">[37]</ref>. All models are optimized with Adam <ref type="bibr" target="#b38">[39]</ref>. For CREMA-D, we trained the ResNet-18 models for 70 epochs on mini-batches of 16 samples using a learning rate of 5 ? 10 ?4 . For RCSAD, we set the learning rate to 10 ?3 and trained the models for 30 epochs on mini-batches of 16 samples. For MSC, we used the same hyperparameters as Ristea et al. <ref type="bibr" target="#b36">[37]</ref>. Our SPEL framework, has two additional hyperparameters. For the parameter m, we considered values in the set {50, 100, 150, 200}. For the parameter k, we considered all possible values subject to m ? k ? 1, 000, i.e. we added at most 1, 000 pseudo-labeled samples during our second training stage. On CREMA-D, we obtained optimal results with m = 50 and k = 3. On the other two data sets, we obtained optimal results with m = 150 and k = 4. All hyperparameters are tuned on the validation sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>In <ref type="table" target="#tab_1">Tables 1, 2</ref> and 3, we present the results obtained on three different data sets by our SPEL approach against various baseline methods. We observe that SPEL attains the highest improvements on CREMA-D (see <ref type="table">Table 1</ref>), where it outperforms all state-of-the-art results with an accuracy of 68.12%. The improvement of 1.58% over the corresponding baseline ensemble is statistically significant according to a paired McNemar's test <ref type="bibr" target="#b39">[40]</ref> performed at the significance level 0.01. Additionally, we empirically demonstrate that our SPEL approach brings a higher gain (of 1.58%) than the gain (of 0.67%) of SPL applied on top of a single model. This indicates that the models in the ensemble are able to boost each others' accuracy.</p><p>On RCSAD (see <ref type="table" target="#tab_1">Table 2</ref>), the ensemble model trained with SPEL surpasses the baseline ensemble by a statistically  <ref type="bibr" target="#b39">[40]</ref> at the significance level 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method UAR</head><p>DeepSpectrum <ref type="bibr" target="#b11">[12]</ref> 63.4 Ristea et al. <ref type="bibr" target="#b36">[37]</ref> 72.2</p><p>Ristea et al. <ref type="bibr" target="#b36">[37]</ref> + SPEL 72.5 ? <ref type="figure" target="#fig_0">Figure 1</ref>: The absolute improvements brought by our SPEL algorithm at various steps, with respect to the corresponding baseline model ensemble. Best viewed in color.</p><p>significant margin of 0.6%. We obtained an additional postcompetition performance boost (of 3.7%), when we learned that a cheap post-processing (PP) 1 of the probabilities is useful.</p><p>In <ref type="table" target="#tab_2">Table 3</ref>, we observe that the model proposed by Ristea et al. <ref type="bibr" target="#b36">[37]</ref> gains a performance boost of 0.3% when SPEL is applied. Even if the magnitude of the performance gain seems small, a paired McNemar's test <ref type="bibr" target="#b39">[40]</ref> performed at the significance level 0.01 reveals that the difference is significant.</p><p>In <ref type="figure" target="#fig_0">Figure 1</ref>, we show the absolute performance gains brought by our approach with respect to the number of SPEL steps k. We observe that the generic behavior of SPEL is to increase the performance until a certain point (typically, after 3 to 5 steps), and afterwards, the performance slowly declines. We note that SPEL brings in pseudo-labeled examples during training, which means that a small percentage of the newly added sample have incorrect labels. The proportion of incorrectly labeled samples increases with the number of SPEL steps. Hence, when the signal-to-noise ratio of the labels becomes unfavorable, the performance starts to decline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we presented a self-paced ensemble learning algorithm in which models learn from each other over several iterations. To demonstrate the generality of our SPEL scheme, we conducted comprehensive experiments with neural architectures of various depths on three audio tasks, where we obtained statistically significant performance gains. In future work, we aim to study increasing the regularization when the ensemble's performance starts to decline. Acknowledgements. Work supported by a grant of the Romanian Ministry of Education and Research, CNCS -UEFISCDI, project no. PN-III-P1-1.1-TE-2019-0235, within PNCDI III.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1</head><label>1</label><figDesc>Self-paced ensemble learning (SPEL) Input: (X, T ) -a training set of samples and associated labels from the source domain; Y -a test set from the target domain; Y -an unlabeled set from the target domain; n -the number of models in the ensemble; k -the number of SPEL steps; m -the number of extra examples added at a SPEL step; ? -a learning rate; L -a loss function. Notations: fi -the i-th model in the ensemble; ?i -the weights of the i-th model; avg -a function that computes Bayesian model averaging; sort -a function that jointly sorts the input set; N (0, ?) -the normal distribution of mean 0 and standard deviation ?; U(S) -the uniform distribution over the set S; S[i : j] -subset of elements {si, si+1, ..., sj} from S. Initialization: ? (0) i ? N (0, ?), ?i ? {1, ..., n} Output: PY -the predictions for the test set Y .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Stage 1 :</head><label>1</label><figDesc>Pre-training of individual models 1: for i ? 1 to n do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results</figDesc><table><row><cell cols="3">of our SPEL approach versus several baselines</cell></row><row><cell cols="3">on RCSAD. Significantly better self-paced learning results are</cell></row><row><cell cols="3">marked with  ?, using a paired McNemar's test [40] at the sig-</cell></row><row><cell>nificance level 0.01.</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="2">WLRAP Kaggle Rank</cell></row><row><cell>ResNeSt-50</cell><cell>0.862</cell><cell>521 / 1143</cell></row><row><cell>5?ResNeSt-50</cell><cell>0.900</cell><cell>98 / 1143</cell></row><row><cell>5?ResNeSt-50 + SPEL</cell><cell>0.906  ?</cell><cell>84 / 1143</cell></row><row><cell>5?ResNeSt-50 + SPEL + PP</cell><cell>0.943  ?</cell><cell>28 / 1143</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of our SPEL approach versus the official competition baseline and the ensemble proposed by Ristea et al. [37] on MSC. Significantly better self-paced learning results are marked with ?, using a paired McNemar's test</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.kaggle.com/c/ rfcx-species-audio-detection/discussion/220389</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Self-Paced Learning for Latent Variable Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Selfpaced curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2694" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Curriculum learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Soviany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10382</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pixel-Level Self-Paced Learning For Super-Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP, 2020</title>
		<meeting>ICASSP, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="2538" to="2542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised feature selection by self-paced learning regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="4" to="11" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-Paced Clustering Ensemble</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A self-paced learning algorithm for change detection in synthetic aperture radar images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ghalamzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="375" to="387" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image Difficulty Curriculum for Generative Adversarial Networks (Cu-GAN)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Soviany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ardei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WACV, 2020</title>
		<meeting>WACV, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="3463" to="3472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Curriculum selfpaced learning for cross-domain object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Soviany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page">103166</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CREMA-D: Crowd-sourced emotional multimodal actors dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Keutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="390" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Batliner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bergler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-M</forename><surname>Messner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amiriparian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baumeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hantke</surname></persName>
		</author>
		<title level="m">The IN-TERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing &amp; Masks</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2042" to="2046" />
		</imprint>
	</monogr>
	<note>Proceedings of INTER-SPEECH</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rainforest Connection Species Audio Detection</title>
		<ptr target="https://www.kaggle.com/c/rfcx-species-audio-detection/" />
		<imprint>
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey on ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Computer Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Diversity-Penalizing Ensemble Training Method for Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3590" to="3594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving the prediction accuracy of heart disease with ensemble learning and majority voting rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Raza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">U-Healthcare Monitoring Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="179" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentiment analysis: Bayesian ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Messina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Pozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="26" to="38" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attribute bagging: improving accuracy of classifier ensembles by using random feature subsets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bryll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gutierrez-Osuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Quek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1291" to="1302" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combing semantic and prior polarity features for boosting twitter sentiment analysis using ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jianqiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DSC</title>
		<meeting>DSC</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="709" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Modified Stacking Ensemble Machine Learning Algorithm Using Genetic Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Al-Laymoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of International Technology and Information Management</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Predicting the perception of performed dynamics in music audio with ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elowsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Friberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2224" to="2242" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimized audio classification and segmentation algorithm by using ensemble methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yousaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Habib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Problems in Engineering</title>
		<imprint>
			<biblScope unit="volume">2015</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self paced deep learning for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Culibrk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="712" to="725" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep self-paced learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="739" to="751" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-paced boost learning for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1932" to="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Self-paced Ensemble for Highly Imbalanced Massive Data Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDE</title>
		<meeting>ICDE</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="841" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Balanced selfpaced learning for generative adversarial clustering network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ghasedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4391" to="4400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Random Forest with Self-Paced Bootstrap Learning in Lung Cancer Prognosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Multimedia Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1s</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Communications, and Applications</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A unified approach to short-time Fourier analysis and synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1558" to="1564" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08955</idno>
		<title level="m">ResNeSt: Split-Attention Networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A theoretical understanding of self-paced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">414</biblScope>
			<biblScope unit="page" from="319" to="328" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visually guided self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vougioukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP, 2020</title>
		<meeting>ICASSP, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="6299" to="6303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Image2Audio: Facilitating Semi-supervised Audio Emotion Recognition with Facial Expression Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR Workshops</title>
		<meeting>CVPR Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="912" to="913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Are you Wearing a Mask? Improving Mask Detection from Speech Using Augmentation by Cycle-Consistent GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ristea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH, 2020</title>
		<meeting>INTERSPEECH, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="2102" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Nonlinear Neurons with Human-like Apical Dendrite Activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-I</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-C</forename><surname>Ristea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.03229</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1895" to="1923" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
