<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HOME: Heatmap Output for future Motion Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Gilles</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Sabatini</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Tsishkou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Stanciulescu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Moutarde</surname></persName>
						</author>
						<title level="a" type="main">HOME: Heatmap Output for future Motion Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose HOME, a framework tackling the motion forecasting problem with an image output representing the probability distribution of the agent's future location. This method allows for a simple architecture with classic convolution networks coupled with attention mechanism for agent interactions, and outputs an unconstrained 2D topview representation of the agent's possible future. Based on this output, we design two methods to sample a finite set of agent's future locations. These methods allow us to control the optimization trade-off between miss rate and final displacement error for multiple modalities without having to retrain any part of the model. We apply our method to the Argoverse Motion Forecasting Benchmark and achieve 1 st place on the online leaderboard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Forecasting the future motion of surrounding actors is an essential part of the autonomous driving pipeline, necessary for safe planning and useful for simulation of realistic behaviors. In order to capture the complexity of a driving scenario, the prediction model needs to take into account the local map, the past trajectory of the predicted agent and the interactions with other actors. Its output needs to be multimodal to cover the different choices a driver could make, between going straight or turning, slowing down or overtaking. Each modality proposed should represent a possible trajectory that an agent could take in the immediate future.</p><p>The challenge in motion prediction resides not in having the absolute closest trajectory to the ground truth, but rather in avoiding big failures where a possibility has not been considered, and the future is totally missed by all modalities. An accident will rarely happen because most predictions are offset by half a meter, but rather because of one single case where a lack of coverage led to a miss of more than a few meters.</p><p>A classic way to obtain k modalities is to design a model that outputs a fixed number of k future trajectories <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b13">14]</ref>, as a regression problem. This approach has however significant drawbacks, as training predictions all together leads to mode collapse. The common solution to this problem is to only train the closest prediction to the ground truth, but this diminishes the training data allocated to each predicted modality as only one is learning at each sample.</p><p>Later methods adapt the model to the multi-modal problem by conditioning the prediction to specific inputs such as lanes <ref type="bibr" target="#b10">[11]</ref> or targets <ref type="bibr" target="#b33">[34]</ref>. Finally, recent methods use the topological lane graph itself to generate trajectory for each <ref type="bibr" target="#b0">1</ref> IoV team, Paris Research Center, Huawei Technologies France 2 MINES ParisTech, PSL University, Center for robotics Contact: thomas.gilles@mines-paristech.fr <ref type="figure">Fig. 1</ref>: Summary of our approach. The yellow/red heatmap is our predicted probability distribution and the blue points are the sampled final point predictions.</p><p>node <ref type="bibr" target="#b31">[32]</ref>. However each of these model constrains its prediction space to a restricted representation, that may be limited to represent the actual diversity of possible futures. For example, if the predicted modalities are constrained to the High Definition map graph, it becomes very hard to predict agent breaking traffic rules or slowing down to park at the side of the road.</p><p>In this paper, following the same principle as recent state of the art method, which is that a future trajectory can be almost fully defined by its final point <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b31">32]</ref>, we reformulate the prediction problem in three steps. We first represent the possible futures distribution by a 2D probability heatmap that gives an unconstrained approximation of the probability of the agent position. This heatmap is represented as a squared image and it naturally accommodates for multimodal predictions where each pixel represent a possible future position of the target agent. It also enables to fully describe the future uncertainty in a probability distribution, without having to choose its modes or means. In a second step, we sample from the heatmap a finite number of possible future locations with the possibility to choose which metric we want to optimize without retraining the model. Finally, we build the full trajectories based on the past history and conditioned on the sampled final points.</p><p>Our contributions are summarized as follow: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Deep learning has brought great progress to the motion forecasting results <ref type="bibr" target="#b21">[22]</ref>. A classic CNN architecture can be applied to a rasterized map to predict 2D coordinates <ref type="bibr" target="#b5">[6]</ref>.</p><p>In order to model interactions better between driving agents, attention has been introduced in multiple methods. The approach of <ref type="bibr" target="#b19">[20]</ref> encodes separately agents and centerlines with 1D CNN and LSTM and then applies multi-head attention from actors to other actors and lines. MHA-JAM <ref type="bibr" target="#b20">[21]</ref> concatenates agent features to a CNN-encoded map at their specific coordinates, and then applies attention on this joint representation. The work of <ref type="bibr" target="#b16">[17]</ref> also uses attention between agents for interactions, and parallely applies an attention head on encoded lane to obtain lane probabilities and generate a modality for each given lane. mmTransformer <ref type="bibr" target="#b15">[16]</ref> applies a general Transformer <ref type="bibr" target="#b29">[30]</ref> architecture to fuse history, map and interactions.</p><p>Another family of methods use a pool of anchor trajectories, predefined <ref type="bibr" target="#b3">[4]</ref> or model-based <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28]</ref>, and rank them with a learned model. This allows to avoid any mode collapse and assert realistic trajectories, but removes the ability to tune the trajectories accurately to the current situation.</p><p>Multimodality can also be obtained using generative approaches that model the actual future probability distribution <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. However, generative models require multiple independent sampling at inference time without any optimization of coverage or average distance.</p><p>More recently, methods have started to leverage the graph obtained from HD-map in order to better represent lane connectivity. VectorNet <ref type="bibr" target="#b8">[9]</ref> encodes both map features and agent trajectories as polylines then merge them with a global interaction graph. LaneGCN <ref type="bibr" target="#b13">[14]</ref> treats actor past and the lane graph separately, and then fuse them with a series of attention layers between lane and actors.</p><p>Other methods then use the graph to structure their multimodal outputs. TNT <ref type="bibr" target="#b33">[34]</ref> builds from the VectorNet backbone and combines it with multiple target proposals sampled from the lanes in order to diversify the prediction points. GoalNet <ref type="bibr" target="#b32">[33]</ref> also identifies possible goals and applied a prediction head for each on a localized raster in order to base the modalities on reachable lanes. WIMP <ref type="bibr" target="#b10">[11]</ref> matches possible polylines to the past trajectory and uses them as conditional input to their model. LaneRCNN <ref type="bibr" target="#b31">[32]</ref> adds actor features from the start to sampled nodes on the lanes, and then predicts a future point for each node along a probability.</p><p>Grid-based outputs have already been used in pedestrian behavior prediction such as <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26]</ref>. Their model architecture, training and sampling strategies however differ greatly from ours. The work of <ref type="bibr" target="#b26">[27]</ref> produces a future grid occupancy output prediction for each vehicle class in order to plan from it, but it is not instance-based and doesn't allow for individual vehicle prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>We describe our general pipeline in <ref type="figure" target="#fig_1">Fig. 2</ref>. Our method takes as input a rasterized image of the agent environment, and outputs a probability distribution heatmap representing where the agent could be at a fixed time horizon T in the future. A finite set of possible locations are then extracted from the heatmap to ensure appropriate coverage. Future locations are sampled to minimize either rate of misses or final displacement errors. Finally for each sampled future location, a trajectory representing the motion of agent from the initial state to the future location is computed.</p><p>The aim of motion estimation is to predict the future positions of the target agent a for T timesteps  Definition Map (HD map). We will focus in this paper on the prediction of the final points (x T a , y T a ), and then regress the whole trajectory conditioned on the end point.</p><formula xml:id="formula_0">{(x t a , y t a ) for t in [[1, T ]]}.</formula><p>A. Encoding history and local context information 1) Map and past trajectory encoding: The local context is available as a High Definition Map centered on the target agent. We rasterize the HD-Map in 5 semantic channels: drivable area, lane boundaries and directed center-lines with their headings encoded using HSV on 3 channels. We also add the target agent trajectory as a moving rectangle on 20 history channels and the other agents history on 20 more channels. The final input is a (224, 224, 45) image with a 0.5 x 0.5 m? resolution per pixel. This image is processed by a classic CNN model alternating convolutional layers and maxpooling for downscaling to obtain a <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr">512</ref>) encoding E raster as illustrated in the top-left part of <ref type="figure" target="#fig_0">Fig. 3</ref>.</p><p>The scalar history of the agents is also taken as input to the model as a list of 2D coordinates. Missing timesteps are padded with zeros and a binary mask indicating if padding was applied is concatenated to the trajectory, as well as the timestamps for each step, so to obtain a (H, 4) input for each agent. Each agent trajectory goes through a 1D convolutional layer followed by a UGRU <ref type="bibr" target="#b7">[8]</ref> recurrent layer. The weights are shared for all agents except the target agent.</p><p>2) Inter-agent attention for interaction: Similar to <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b16">17]</ref>, we use attention <ref type="bibr" target="#b29">[30]</ref> to model agent interaction. A query vector is generated for the target agent, while key and value vectors are created for the other actors. The normalized dot product of query and keys creates an attention map from the target agent to the other agent, then used to pool their value features into a context vector. The context vector is then added to the target vehicle feature vector through a residual connection followed by LayerNormalization <ref type="bibr" target="#b1">[2]</ref>. The obtained trajectory encoding E trajectory is then repeated to match the context encoding E raster dimensions. The final encoding E context is the result of the concatenation of both encodings E raster and E trajectory .</p><p>3) Increased output size for longer range: Due to high speed, some cars may go through a greater range in the time horizon T that is covered by the input range of 56m. However, simply increasing input size would greatly add to the computational burden while not necessarily bringing useful information. We therefore want to increase the output size while retaining the spatial correspondences through the layers. In order to do so, we apply Tranpose Convolutions with stride 1 and kernel size 3. Since 1 input pixel is connected to a grid of 3x3 output pixels, the edge pixels generate a new border of pixels around them, increasing the encoding size by 1 in each direction. We apply 2 of these layers, resulting in a <ref type="bibr" target="#b17">(18,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr">512)</ref> augmented encoding so that once upscaled the decoded image output will be of size (288, 288), corresponding to a 72m range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Heatmap output</head><p>The final part of the model is a convolutional decoder alternating transpose convolutions for upscaling and classic convolutions, topped with a sigmoid activation. We output an image? with similar resolution as the raster input (0.5 x 0.5 m? / pixel). The output target is an image Y with a Gaussian centered around the ground truth position. This image is trained with a pixel-wise focal loss inspired from <ref type="bibr" target="#b34">[35]</ref>, averaged over the total P pixels p of the heatmap:</p><formula xml:id="formula_1">L = ? 1 P p (Y p ?? p ) 2 f (Y p ,? p ) with f (Y p ,? p ) = log(? p ) if Y p =1 (1 ? Y p ) 4 log(1 ?? p ) else<label>(1)</label></formula><p>where the non-null pixels around the Gaussian center serve as penalty-reducing coefficients, and the square factor of (a) MR sampling (b) FDE sampling <ref type="figure">Fig. 4</ref>: Illustration of sampling methods error allows the gradient to focus on poorly-predicted pixels. We use a standard deviation of 4 pixels for the Gaussian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Modality sampling</head><p>Our aim is here to sample the probability heatmap in order to optimize the performance metric of our choice. In most datasets such as Argoverse <ref type="bibr" target="#b4">[5]</ref> and NuScenes <ref type="bibr" target="#b2">[3]</ref>, two main metrics are used for the final predicted point: MissRate (MR) and Final Displacement Error (FDE). MissRate corresponds to the percentage of prediction being farther than a certain threshhold to the ground truth, and FDE is simply the mean of l 2 distance between the prediction and the ground truth. When the output is multimodal, with k predictions, minimum Final Displacement Error minFDE k and Miss Rate over the k predictions MR k are used.</p><p>1) Optimizing Miss Rate: We design a sampling method in order to optimize the Miss Rate between the predicted modalities and the ground truth. A case is defined as missed if the ground truth is further than 2m from the prediction. For a given area A, the probability of the ground truth Y being in this area is equal to the integral of the probability distribution p under this ground truth.</p><formula xml:id="formula_2">P (Y ? A) = x?A p(x)dx<label>(2)</label></formula><p>Therefore, for k predictions, given a 2D probability distribution, the sampling minimizing the expected MR is the one maximizing the integral of the future probability distribution under the area defined as 2m radius circles around the k predictions:</p><formula xml:id="formula_3">E(1 min k c k ?Y &gt;2 ) = 1 ? k c k ?x &lt;2 p(x)dx<label>(3)</label></formula><p>We therefore process in a greedy way as described in Algo. 1, and iteratively select the location with the highest integrated probability value in its 2m circle. Once we obtain such a point, we set to zero the heatmap values under the defined circle and move on to selecting the next point with the same method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: MR Sampling Algorithm</head><p>input: Probability map p(x) K number of predictions R threshhold for Miss Rate</p><formula xml:id="formula_4">for k = 1..K do Find c k maximizing c k ?x &lt;R p(x)dx Set p(x) = 0 for all x such that c k ? x &lt; R end</formula><p>The result is illustrated in <ref type="figure">Fig. 4a</ref>. We see that each sampled point can be surrounded by a circle of radius 2m that barely overlaps with other circles. Each point is sampled almost equidistant to the others, as setting the probability under previous points to zero sets a very strict limit to the minimum distance between points.</p><p>For implementation, we process the covered area for each point using a convolution layer with kernel weights fixed so to approximate a 2m circle. In practice, we don't actually use a radius of 2 meters, but a 1.8 meters one as we found out it to yield better performance. We also upscale the heatmap to 0.25 x 0.25 m 2 per pixel with bilinear interpolation to have a more refined prediction location.</p><p>2) Optimizing Final Displacement Error: We inspire ourselves from KMeans to optimize minFDEk. The image output can be represented as a discrete probability distribution (x i , p i ) where x i represents the pixel centers and p i the associated probability value. Optimizing the Final Displacement Error over k predictions means finding k centroids c k that minimize the following quantity:</p><formula xml:id="formula_5">minimize c i p i c ? x i<label>(4)</label></formula><p>To do so we design our sampling algorithm for FDE optimization detailed in Algo. 2.</p><p>We replace the classic weighted average i p i x i for each centroid c k by i pi d k i x i where d k i is the distance between point x i and centroid c k to be more robust to outliers and take into account the optimisation of l 2 norm instead of its square.</p><p>In essence, we update each prediction as a weighted average of its local neighborhood in a radius of 3m. The coefficient mi</p><formula xml:id="formula_6">d k i</formula><p>, with m i the distance between point x i and its closest centroid allows for flexible partition boundaries compared to KMeans (where we would use 1 d k i &lt;=mi instead): when x i is in the partition of prediction k, its value is 1, while when it's outside it decreases, so as to be 0 when at the exact position of another prediction k , where it could never be improved by a displacement of k.</p><p>We initialize the centroids with the results of the Miss Rate optimization algorithm and use the number of iterations L as a parameter to tune the trade-off between Miss Rate and FDE: when L is zero, Miss Rate is optimized while </p><formula xml:id="formula_7">c k = 1 N i 1 d k i &lt;=3 p i d k i m i d k i x i with N = i 1 d k i &lt;=3 pi d k i mi d k i end end</formula><p>when L increases MR is sacrificed to get better FDE. The output of the algorithm is illustrated in <ref type="figure">Fig. 4b</ref>, where is it can be observed that centroids are brought closer together, sacrificing total coverage but getting closer to areas with high probabilities to reduce the expected distance. Results of this trade-off are illustrated further in Sec. IV-C.2, where we show in <ref type="figure" target="#fig_3">Fig. 6</ref> that every iteration of Algo. 2 diminishes minFDE 6 and increases MR 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Full trajectory generation</head><p>We use a separate model to generate full trajectories connecting the initial agent position to all sampled locations. This model applies a fully-connected layer to encode the target agent history into a vector of 32 features, which is then concatenated with the (x, y) coordinates of the target future location. Another fully-connected layer is then applied to obtain a 64 feature vector, which is then transformed through a last fully-connected layer to a set of locations representing the intermediate position of the agent in the time frame [[1, T ]]. The probability of a trajectory is the integral of the probability heatmap under the circle of radius 2m around the end point of the trajectory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>A. Experimental settings 1) Dataset: We use the Argoverse Motion Forecasting Dataset <ref type="bibr" target="#b4">[5]</ref>. It is a car trajectory prediction benchmark with 205942 training samples, 39472 validation samples and 78143 test samples. Each sample contains the position of all agents in the scene in the past 2s as well as the local map, and the labels are the 3s future positions of one target agent in the scene.</p><p>2) Metrics: We report the previously defined metrics MR k and minFDE k for k=1,6, completed by the minimum Average Displacement Error minADE k which is the average l 2 error over all successive trajectory points. We also report the metrics p-minFDE 6 and p-minADE 6 for the test set, where ? log(p) is added to the metric, p being the probability assigned to the best (closest to ground-truth) predicted trajectory. These later metrics allow to measure the quality of the probability distribution assigned to the predictions.</p><p>3) Implementation details: We train all models for 16 epochs with batch size 32, using Adam optimizer initialized with a learning rate of 0.001. Each sample frame is centered on the target agent and aligned with its heading. We divide learning rate by half at epochs 3, 6, 9 and 13. We augment the training data by dropping each raster channel with a probability of 0.1 and rotating the frame by a uniform random angle in [??/4, ?/4] in 50% of the samples. All convolution layers are CoordConv <ref type="bibr" target="#b14">[15]</ref> with a kernel of size 3x3 (3 for 1D Convs) and are followed by BatchNormalization and ReLU activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with State-of-the-art</head><p>We show in Tab. I our results compared to other methods on the Argoverse motion forecasting test set. The benchmark is ranked by MR 6 , where we rank first and significantly improve on previous results, demonstrating that having the heatmap output enables the best coverage with respect to the prior art. We also outperform other methods on both  Another interesting observation is that methods performing very well on minFDE 6 such as LaneGCN <ref type="bibr" target="#b13">[14]</ref> and TPCN <ref type="bibr" target="#b30">[31]</ref> have a worse MR 6 as drawback. PRIME <ref type="bibr" target="#b27">[28]</ref> has the closest MR 6 to ours but a much higher minFDE 6 in comparison. We show the results of both our sampling optimized for MR and minFDE with the same trained model. Our FDE sampling with L = 4 sacrifices 1.1 points of MR 6 for 9 cm of minFDE 6 , which gets us second best on minFDE 6 while still being good enough for 1 st position on the leaderboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation studies</head><p>We discuss the importance of our difference contributions, starting by comparing our output representation to the traditional scalar coordinates output, then decomposing our model architecture and sampling strategies. All metrics are reported on the Argoverse validation set. If not specified otherwise, MR sampling is used.</p><p>1) Heatmap output: We show the effect of output representation in Tab. II by using the same encoding backbone and replacing the image decoder with a global pooling followed by a regression head of 6 coordinate modalities. We train the regression output with a winner-takes-all l 1 regression loss similar to <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b5">6]</ref> and a classification loss where target is obtained through a softmax on distances between predictions and ground-truth, as in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b27">28]</ref>. Since the global pooling leads to loss of spatial information from the image, for fair comparison we also include a model with "scalar bottleneck" where pooling is also applied on the image encoding and is then reshaped to form an image on which is applied the heatmap decoder. We observe that heatmap outputs yields much better Miss Rate, and that having a scalar pooling bottleneck diminishes performance as it creates information loss, but not significantly. Interestingly, the regression output reaches better minFDE 6 when compared to the MRoptimized sampled image output models, but is still worse than FDE-optimized model, as this scalar coordinates output doesn't leave room for any post-processing optimization.</p><p>We also show the effect of adding more modalities to a regression output in <ref type="figure" target="#fig_2">Fig 5 :</ref> even if the MR k improves for the total number of modalities as k increases, the performance for a fixed k such as 1 or 6 worsens. <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b32">[33]</ref> notice a similar trend, obtaining much better results for lower k metrics when training less modalities. Furthermore, for a regression output model a new training is required each time to accommodate the maximum number of modalities, whereas with heatmap output any number of modalities can be obtained at will with the same training, and the lower k numbers are not impacted by the total number of modalities extracted, as showed by the dashed horizontal lines displayed for MR 1 , MR 3 and MR <ref type="bibr" target="#b5">6</ref> . Finally, our model heatmap output scales better with the number of k modalities, converging to a 0% MR faster that the regression output model.</p><p>2) Trajectory sampling: We show in <ref type="figure" target="#fig_3">Fig. 6</ref> the results of our trade-off between MR 6 and FDE 6 on the Argoverse test set thanks to the parameter L of Algo. 2. We also include points for the other top 10 methods of the leaderboard for comparison. Our method reaches best possible MR 6 , and  allows to improve FDE 6 to second-best while still being first in MR 6 (fourth curve point obtained with L = 4)</p><p>We highlight our sampling results in Tab III and compare them to other possible sampling strategies: we try ranking pixels by probability and select them in decreasing order while removing overlapping pixels that are closer than a 1.8m radius following a classic Non-Maximum Suppression method. We also try KMeans as is used in <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Qualitative results</head><p>We show supplementary qualitative results in <ref type="figure">Fig. 7</ref>. We highlight examples of straight line, overtaking, curve road, going outside the map and intersections. Our model heatmap output makes use and usually follows the prior from the context map, but it is also able to divert from it based on interactions, realistic observations and hints of divergence from history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We have presented HOME, a novel representation for multimodal trajectory prediction. It is based on predicting the future final point position on a 2D top-view grid, decoding then this final point into a full trajectory. This heatmap output represents the complete future probability distribution and its uncertainties, from which we design two prediction sampling methods. Sampling directly from the heatmap distribution enables a more optimized coverage, achieving state-of-theart performance on the Argoverse Motion Forecasting benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Example of input and output data for our model with brief description of architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 2 :</head><label>2</label><figDesc>FDE Sampling Algorithm input: Set of points x i with probability weight p i L number of iterations to run the algorithm Initialization of K centroids c k for l = 1..L do Compute d k i the matrix of distance of point x i to each centroid c k Compute m i the distance of point x i to the closest centroid c k for k = 1..K do Compute new centroid coordinates :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>Effect of maximum number k of modalities trained on metrics of lower fixed modality numbers. Full lines are results of regression output model. Dashed lines are result of our heatmap output model. We show the Miss Rate for total number of predicted modalities k (blue) and fixed number of modalities 1 (orange), 3 (green) and 6 (red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :</head><label>6</label><figDesc>FDE 6 -MR 6 trade-off. Lower-left is better. Points of the curve (blue) are obtained increasing number of iteration L of Algorithm 2 from 0 to 7. Points for other top-10 leaderboard methods are also included (orange).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>Results on Argoverse Motion Forecasting Leaderboard [1] (test set)</figDesc><table><row><cell></cell><cell></cell><cell>K=1</cell><cell></cell><cell></cell><cell></cell><cell>K=6</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">minADE minFDE</cell><cell>MR</cell><cell cols="4">minADE minFDE p-minADE p-minFDE</cell><cell>MR</cell></row><row><cell>WIMP [11]</cell><cell>1.82</cell><cell>4.03</cell><cell>62.9</cell><cell>0.90</cell><cell>1.42</cell><cell>2.69</cell><cell>3.21</cell><cell>16.7</cell></row><row><cell>LaneGCN [14]</cell><cell>1.71</cell><cell>3.78</cell><cell>59.1</cell><cell>0.87</cell><cell>1.36</cell><cell>2.66</cell><cell>3.16</cell><cell>16.3</cell></row><row><cell>Alibaba-ADLab</cell><cell>1.97</cell><cell>4.35</cell><cell>63.4</cell><cell>0.92</cell><cell>1.48</cell><cell>2.64</cell><cell>3.23</cell><cell>15.9</cell></row><row><cell>TPCN [31]</cell><cell>1.64</cell><cell>3.64</cell><cell>58.6</cell><cell>0.85</cell><cell>1.35</cell><cell>2.61</cell><cell>3.11</cell><cell>15.9</cell></row><row><cell>HIKVISION-ADLab-HZ</cell><cell>1.94</cell><cell>3.90</cell><cell>58.2</cell><cell>1.21</cell><cell>1.83</cell><cell>3.00</cell><cell>3.62</cell><cell>13.8</cell></row><row><cell>TNT [34]</cell><cell>1.78</cell><cell>3.91</cell><cell>59.7</cell><cell>0.94</cell><cell>1.54</cell><cell>2.73</cell><cell>3.33</cell><cell>13.3</cell></row><row><cell>Jean [20]</cell><cell>1.74</cell><cell>4.24</cell><cell>68.6</cell><cell>1.00</cell><cell>1.42</cell><cell>2.79</cell><cell>3.21</cell><cell>13.1</cell></row><row><cell>TMP [16]</cell><cell>1.70</cell><cell>3.78</cell><cell>58.4</cell><cell>0.87</cell><cell>1.37</cell><cell>2.66</cell><cell>3.16</cell><cell>13.0</cell></row><row><cell>LaneRCNN [32]</cell><cell>1.69</cell><cell>3.69</cell><cell>56.9</cell><cell>0.90</cell><cell>1.45</cell><cell>2.70</cell><cell>3.24</cell><cell>12.3</cell></row><row><cell>SenseTime_AP</cell><cell>1.70</cell><cell>3.76</cell><cell>58.3</cell><cell>0.87</cell><cell>1.36</cell><cell>2.66</cell><cell>3.16</cell><cell>12.0</cell></row><row><cell>poly (3 rd )</cell><cell>1.70</cell><cell>3.82</cell><cell>58.8</cell><cell>0.87</cell><cell>1.47</cell><cell>2.67</cell><cell>3.28</cell><cell>12.0</cell></row><row><cell>PRIME (2 nd ) [28]</cell><cell>1.91</cell><cell>3.82</cell><cell>58.7</cell><cell>1.22</cell><cell>1.56</cell><cell>2.71</cell><cell>3.04</cell><cell>11.5</cell></row><row><cell>Ours-HOME (FDE L=4)</cell><cell>1.72</cell><cell>3.73</cell><cell>58.4</cell><cell>0.92</cell><cell>1.36</cell><cell>2.64</cell><cell>3.08</cell><cell>11.3</cell></row><row><cell>Ours-HOME (MR) (1 st )</cell><cell>1.73</cell><cell>3.73</cell><cell>58.4</cell><cell>0.94</cell><cell>1.45</cell><cell>2.52</cell><cell>3.03</cell><cell>10.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell cols="5">: Ablation study on output representation</cell><cell></cell></row><row><cell cols="2">(Argoverse validation set)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bottleneck</cell><cell>Output</cell><cell>K=1</cell><cell></cell><cell>K=6</cell><cell></cell></row><row><cell></cell><cell></cell><cell>minFDE</cell><cell>MR</cell><cell>minFDE</cell><cell>MR</cell></row><row><cell>Scalar</cell><cell>Regression</cell><cell>3.81</cell><cell>61.7</cell><cell>1.26</cell><cell>13.0</cell></row><row><cell>Scalar</cell><cell>Heatmap</cell><cell>3.07</cell><cell>51.9</cell><cell>1.30</cell><cell>8.0</cell></row><row><cell>Image</cell><cell>Heatmap</cell><cell>3.02</cell><cell>50.7</cell><cell>1.28</cell><cell>6.8</cell></row><row><cell cols="6">p-minFDE 6 and p-minADE 6 , demonstrating superior mod-</cell></row><row><cell cols="6">elling of the probability distribution between predictions.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>Ablation study on trajectory sampling (Argoverse validation set)</figDesc><table><row><cell>Bottleneck</cell><cell>K=1</cell><cell></cell><cell>K=6</cell><cell></cell></row><row><cell></cell><cell>minFDE</cell><cell>MR</cell><cell>minFDE</cell><cell>MR</cell></row><row><cell>Pixel ranking with NMS</cell><cell>3.07</cell><cell>51.0</cell><cell>1.21</cell><cell>10.7</cell></row><row><cell>KMeans</cell><cell>3.06</cell><cell>51.6</cell><cell>1.23</cell><cell>9.3</cell></row><row><cell>Ours (MR)</cell><cell>3.02</cell><cell>50.7</cell><cell>1.28</cell><cell>6.8</cell></row><row><cell>Ours (FDE L=6)</cell><cell>3.01</cell><cell>50.5</cell><cell>1.16</cell><cell>7.4</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We would like to thank Thomas Wang and Camille Truong-Alli? for useful comments on the paper, as well as Arthur Moreau and Joseph Gesnouin for insightful discussions. <ref type="figure">Fig. 7</ref>: Qualitative examples. The yellow/red heatmap is our predicted probability distribution and the blue points are the sampled final point predictions. The ground truth trajectory is shown in green.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Argoverse motion forecasting competition</title>
		<ptr target="https://eval.ai/web/challenges/challenge-page/454/leaderboard/1279" />
		<imprint>
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Layer normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">nuScenes: A multimodal dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<idno>CVPR. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for Behavior Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<idno>CoRL. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Fang</forename><surname>Chang</surname></persName>
		</author>
		<idno>CVPR. 2019</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henggang</forename><surname>Cui</surname></persName>
		</author>
		<idno>ICRA. 2019</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">6th Place Solution: Very Custom GRU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Erdem</surname></persName>
		</author>
		<ptr target="www.kaggle.com/c/riiid-test-answer-prediction/discussion/209581" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Vectornet: Encoding hd maps and agent dynamics from vectorized representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<idno>CVPR. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Discrete residual flow for probabilistic pedestrian behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<idno>ECCV. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">What-If Motion Prediction for Autonomous Driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhesh</forename><surname>Khandelwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10587</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The garden of forking paths: Towards multi-future trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<idno>CVPR. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning lane graph representations for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<idno>ECCV. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An intriguing failing of convolutional neural networks and the CoordConv solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosanne</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multimodal Motion Prediction with Stacked Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicheng</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.11624</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Probabilistic Multi-modal Trajectory Prediction with Lane Attention for Autonomous Vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02574</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">From Goals, Waypoints &amp; Paths To Long Term Human Trajectory Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.01526</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">It is not the journey but the destination: Endpoint conditioned trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<idno>ECCV. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multi-head attention for multimodal joint vehicle motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Mercat</surname></persName>
		</author>
		<idno>ICRA. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Multi-Head Attention with Joint Agent-Map Representation for Trajectory Prediction in Autonomous Driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaouther</forename><surname>Messaoud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02545</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep learning-based vehicle behavior prediction for autonomous driving applications: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sajjad</forename><surname>Mozaffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tung</forename><surname>Phan-Minh</surname></persName>
		</author>
		<idno>CVPR. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vernaza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Rhinehart</surname></persName>
		</author>
		<idno>CVPR. 2019</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scene compliant trajectory forecast with agent-centric spatio-temporal grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Ridel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Perceive, predict, and plan: Safe motion planning through interpretable semantic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Sadat</surname></persName>
		</author>
		<idno>ECCV. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning to Predict Vehicle Trajectories with Model-based Planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04027</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Multiple Futures Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charlie</forename><surname>Yichuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">TPCN: Temporal Point Cloud Networks for Motion Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosheng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03067</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06653</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Map-Adaptive Goal-Based Trajectory Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyao</forename><surname>Zhang</surname></persName>
		</author>
		<idno>CoRL. 2020</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">TNT: Target-driven trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
