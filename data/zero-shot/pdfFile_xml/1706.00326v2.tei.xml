<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminative k-shot learning using probabilistic models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bauer</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename><surname>Jakub</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart?omiej</forename><surname>?wi?tkowski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminative k-shot learning using probabilistic models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>* MB and MR contributed equally to this work</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a probabilistic framework for k-shot image classification. The goal is to generalise from an initial large-scale classification task to a separate task comprising new classes and small numbers of examples. The new approach not only leverages the feature-based representation learned by a neural network from the initial task (representational transfer), but also information about the classes (concept transfer). The concept information is encapsulated in a probabilistic model for the final layer weights of the neural network which acts as a prior for probabilistic k-shot learning. We show that even a simple probabilistic model achieves state-ofthe-art on a standard k-shot learning dataset by a large margin. Moreover, it is able to accurately model uncertainty, leading to well calibrated classifiers, and is easily extensible and flexible, unlike many recent approaches to k-shot learning. arXiv:1706.00326v2 [stat.ML] 9 Dec 2017 examples from the original classes making it amenable to standard deep learning. In contrast, the transfer of conceptual information to the new classes relies on a relatively small number of existing classes and k-shot data points, which means probabilistic inference is appropriate. While generalisation accuracy is often the key objective when training a classifier, calibration is also a fundamental concern in many applications such as decision making for autonomous driving and medicine. Here, calibration refers to the agreement between a classifier's uncertainty and the frequency of its mistakes, which has recently received increased attention. For example, [8]   show that the calibration of deep architectures deteriorates as depth and complexity increase. Calibration is closely related to catastrophic forgetting in continual learning. However, to our knowledge, uncertainty has so far been over-looked by the k-shot community even though it is high in this setting. Our basic setup mimics that of the motivating example above: a standard deep convolutional neural network (CNN) is trained on a large labelled training set. This learns a rich representation of images at the top hidden layer of the CNN. Accumulated knowledge about classes is embodied in the top layer softmax weights of the network. This information is extracted by training a probabilistic model on these weights. K-shot learning can then 1) use the representation of images provided by the CNN as input to a new softmax function, 2) learn the new softmax weights by combining prior information about their likely form derived from the original dataset with the k-shot likelihood. The main contributions of our paper are: 1) We propose a probabilistic framework for k-shot learning. It combines deep convolutional features with a probabilistic model that treats the top-level weights of a neural network as data, which can be used to regularize the weights at k-shot time in a principled Bayesian fashion. We show that the framework recovers L 2 -regularised logistic regression, with an automatically determined setting of the regularisation parameter, as a special case. 2) We show that our approach achieves state-of-the-art results on the miniImageNet dataset by a wide margin of roughly 6% for 1-and 5-shot learning. We further show that architectures with better batch classification accuracy also provide features which generalize better at k-shot time. This finding is contrary to the current belief that episodic training is necessary for good performance and puts the success of recent complex deep learning approaches to k-shot learning into context. 3) We show on miniImageNet and CIFAR-100 that our framework achieves a good tradeoff between classification accuracy and calibration, and it strikes a good balance between learning new classes and forgetting the old ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Probabilistic k-shot learning K-shot learning task.</head><p>We consider the following discriminative k-shot learning task: First, we receive a large dataset</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A child encountering images of helicopters for the first time is able to generalize to instances with radically different appearance from only a handful of labelled examples. This remarkable feat is supported in part by a high-level feature-representation of images acquired from past experience. However, it is likely that information about previously learned concepts, such as aeroplanes and vehicles, is also leveraged (e.g. that sets of features like tails and rotors or objects like pilots/drivers are likely to appear in new images). The goal of this paper is to build machine systems for performing k-shot learning, which leverage both existing feature representations of the inputs and existing class information that have both been honed by learning from large amounts of labelled data. K-shot learning has enjoyed a recent resurgence in the academic community <ref type="bibr">[1]</ref><ref type="bibr">[2]</ref><ref type="bibr">[3]</ref><ref type="bibr">[4]</ref><ref type="bibr">[5]</ref>. Current state-of-the-art methods use complex deep learning architectures and claim that learning good features for k-shot learning entails training for k-shot specifically via episodic training that simulates many k-shot tasks. In contrast, this paper proposes a general framework based upon the combination of a deep feature extractor, trained on batch classification, and traditional probabilistic modelling. It subsumes two existing approaches in this vein <ref type="bibr">[5,</ref><ref type="bibr">6]</ref>, and is motivated by similar ideas from multi-task learning <ref type="bibr">[7]</ref>. The intuition is that deep learning will learn powerful feature representations, whereas probabilistic inference will transfer top-down conceptual information from old classes. Representational learning is driven by the large number of training</p><formula xml:id="formula_0">D = { u i , y i } N i=1</formula><p>of images u i and labels y i ? {1, . . . , C} that indicate which of the C classes each image belongs to. Second, we receive a small dataset D = {u i , y i } N i=1 of C new classes, y i ? { C + 1, C + C}, with k images from each new class. Our goal is to construct a model that can leverage the information in D and D to predict well on unseen images u * from the new classes; the performance is evaluated against ground truth labels y * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary.</head><p>In contrast to several recent k-shot learning approaches that mimic the k-shot learning task by episodic training on simulated k-shot tasks, we propose to use the large dataset D to train a powerful feature extractor on batch classification, which can then be used in conjunction with a simple probabilistic model to perform k-shot learning. In 2003, Bakker and Heskes introduced a general probabilistic framework for multi-task learning with multi-head models, in which all parameters of a generic feature extractor are shared between a set of tasks, and only the weights of the top linear layer (the "heads") are task dependent. In the following, we frame k-shot learning in a similar setting and propose a probabilistic framework for k-shot learning in this vein. Our framework comprises four phases that we refer to as 1) representational learning, 2) concept learning, 3) k-shot learning, and 4) k-shot testing, cf. <ref type="figure" target="#fig_1">Fig. 1 (right)</ref>. We then show that, for certain modelling assumptions, the obtained method is equivalent/related to regularised logistic regression with a specific choice for the regularisation parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">A framework for probabilistic k-shot learning</head><p>We provide a high-level description of the probabilistic framework and present a more detailed derivation in Appendix A. While it might appear overly formal, the resulting scheme will be simple and practical, and the probabilistic phrasing will make it extensible and automatic (no free parameters).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature extractor and representational learning.</head><p>We first introduce a convolutional neural network (CNN) ? ? as feature extractor whose last hidden layer activations are mapped to two sets of softmax output units corresponding to the C classes in the large dataset D and the C classes in the small dataset D, respectively. These separate mappings are parametrized by weight matrices W for the old classes and W for the new classes. Denoting the output of the final hidden layer as x = ? ? (u), the first softmax units compute p( y n | x n , W) = softmax( W x n ) and the second p(y n | x n , W) = softmax(Wx n ), cf. <ref type="figure" target="#fig_1">Fig. 1 (left)</ref>. For representational learning (phase 1) the large dataset D is used to train the CNN ? ? using standard deep learning optimisation approaches. This involves learning the parameters ? of the feature extractor up to the last hidden layer, as well as the softmax weights W. The network parameters ? are fixed from this point on and shared across later phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probabilistic modelling.</head><p>The next goal is to build a probabilistic method for k-shot prediction that transfers structure from the trained softmax weights W to the new k-shot softmax weights W and combines it with the k-shot training examples. Thus, given a test image u * during k-shot testing (phase 4), we compute its feature representation x * = ?(u * ), and the prediction for the new label y * is found  by averaging the softmax outputs over the posterior distribution of the softmax weights given the two datasets,</p><formula xml:id="formula_1">p(y * | x * , D, D) = p(y * | x * , W)p(W | D, D)dW.<label>(1)</label></formula><p>To this end, we consider a general class of probabilistic models in which the two sets of softmax weights are generated from shared hyperparameters ?, so that p( W, W, ?) = p(?)p( W|?)p(W|?) as indicated in the graphical model in <ref type="figure" target="#fig_1">Fig. 1 (right)</ref>. In this way, the large dataset D contains information about ? that in turn constrains the new softmax weights W. We further assume that there is very little uncertainty in W once the large initial training set is observed and so a maximum a posteriori (MAP) estimate, as returned by standard deep learning, suffices. As a consequence of this approximation and the structure of the model, the original data D are not required for the k-shot learning phase. Instead, the weights learned from these data, W MAP , can themselves be treated as observed data, which induce a predictive distribution over the k-shot weights p(W| W MAP ) via Bayes' rule. This argument is fully explained in Appendix A. We refer to this step as concept learning (phase 2) and note that all probabilistic modelling happens in the definition of p( W, W, ?), (see Sections 2.2 and 2.3).</p><p>During k-shot learning (phase 3) we treat this predictive distribution as our new prior on the weights and again use Bayes' rule to combine it with the softmax likelihood of the k-shot training examples D to obtain a new posterior over the weights that now also incorporates D,</p><formula xml:id="formula_2">p(W | D, D) ? p(W | D, W MAP ) ? p(W | W MAP ) N n=1 p(y n |x n , W).<label>(2)</label></formula><p>Finally, we approximate Eq. (2) by its MAP estimate W MAP , so that the integral in Eq. (1) becomes</p><formula xml:id="formula_3">p(y * | x * , D, D) ? p(y * | x * , D, W MAP ) ? p(y * | x * , W MAP ).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Choosing a model for the weights</head><p>The probabilistic model over the weights is key: a good model will transfer useful knowledge that improves performance. However, the usual trade-off between model complexity and learnability is particularly egregious in our setting as the weights W are few and high-dimensional and the number of k-shot samples is small. With an eye on simplicity, we make two simplifying assumptions. First, treating the weights from the hidden layer to the softmax outputs as a vector, we assume independence. Second, we assume the distribution between the weights of old and new classes to be identical,</p><formula xml:id="formula_4">p( W, W, ?) = p(?) C c =1 p( w c |?) C c=1 p(w c |?) where p( w c |?) dist = p(w c |?).<label>(4)</label></formula><p>After extensive testing, we found that a Gaussian model for the weights strikes the best compromise in the trade-off between complexity and learnability, cf. Section 4.2 for a detailed model comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Gaussian model and its relation to logistic regression</head><p>Our method.</p><p>We use a simple Gaussian model p(w|?) = N (w|?, ?) with its conjugate Normal-inverse-Wishart prior p(?) = p(?, ?) = N IW(?, ? | ? 0 , ? 0 , ? 0 , ? 0 ), and estimate MAP solutions for the parameters ? MAP = {? MAP , ? MAP }. The approximations discussed in Section 2.1 lead to</p><formula xml:id="formula_5">p(W | D) ? p(W | W MAP ) = N (W | ? MAP , ? MAP )</formula><p>, and the posterior at k-shot time becomes</p><formula xml:id="formula_6">p(W | D, D) ? N (W | ? MAP , ? MAP ) N n=1 p(y n | x n , W).<label>(5)</label></formula><p>For details see Appendix C.1. For k-shot testing we use the MAP estimates for the weights of the new classes. We found that restricting the covariance matrix to be isotropic, ? = ? 2 I, performed best at k-shot learning, probably due to the small number of data points to learn from as mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation to logistic regression.</head><p>Standard logistic regression corresponds to the maximum likelihood (MLE) solution of the softmax likelihood p(y n | x n , W) = softmax(Wx n ). Often, L 2 -regularisation on the weights W with inverse regularisation strength 1/C reg is used; the solution to this regularised optimisation problem corresponds to the MAP solution of a model with isotropic Gaussian prior on the weights with zero mean:</p><formula xml:id="formula_7">p(W | D) ? N (W|0, 1 2 C reg I) N n=1 p(y n | x n , W)</formula><p>. This method is analogous to Eq. (5). However, the probabilistic framework has several advantages: i) modelling assumptions and approximations are made explicit, ii) it is strictly more general and can incorporate non-zero means ? MAP , whereas standard regularised logistic regression assumes zero mean, and iii) the probabilistic interpretation provides a principled way of choosing the regularisation constant using the trained weights W:</p><formula xml:id="formula_8">C reg = 2? 2 W , where ? 2 W</formula><p>is the empirical variance of the weights W MAP . In k-shot learning, alternative (frequentist) methods such as cross-validation suffer in the face of the small number of k-shot examples, and are not applicable in 1-shot learning at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>Embedding methods map the k-shot training and test points into a non-linear space and perform classification by assessing which training points are closest, according to a metric, to the test points. Siamese Networks <ref type="bibr">[2]</ref> train the embedding using a same/different prediction task derived from the original dataset and use a weighted L 1 metric for classification. Matching Networks <ref type="bibr">[3]</ref> construct a set of k-shot learning tasks from the original dataset to train an embedding defined through an attention mechanism that linearly combines training labels weighted by their proximity to test points. More recently, Prototypical Networks <ref type="bibr">[4]</ref> are a streamlined version of Matching Networks in which embedded classes are summarised by their mean in the embedding space. These embedding methods learn representations for k-shot learning, but do not directly leverage concept transfer. Amortised optimisation methods <ref type="bibr">[9]</ref> also simulate related k-shot learning tasks from the initial dataset, but instead train a second network to initialise and optimise a CNN to perform accurate classification on these small datasets. This method can then be applied for new k-shot tasks. Importantly, both embedding and amortised inference methods improve when the system is trained for a specific k-shot task: to perform well in 5-shot learning, training is carried out with episodes containing 5 examples in each class. The general statement appears to be that training specifically for k-shot learning is essential for building features which generalise well at k-shot testing time. The approach proposed in this paper is more flexible; it is not tailored for a specific k and, thus, does not require retraining when switching, e.g., from 5-shot to 10-shot learning. Moreover, <ref type="bibr">[4]</ref> find that using a larger number of k-shot classes for the training episodes (e.g., train with 20 k-shot classes per episode when testing on only 5 new k-shot classes) can be beneficial, and they choose this number by cross-validation on a validation-set. This is in alignment with our finding that training with more data and more classes improves performance at k-shot time.</p><p>Deep probabilistic methods include the approach developed in this paper. The methods in this family are not unique to deep learning, and the idea of treating weights as data from which to transfer has been widely applied in multi-task learning <ref type="bibr">[7]</ref>. The work most closely related to our own is not an approach to k-shot learning per se, but rather a method for training CNNs with highly imbalanced classes <ref type="bibr">[5]</ref>. It is similar in that it trains a form of Gaussian mixture model over the final layer weights using MAP inference that regularises learning. <ref type="bibr">[6]</ref> propose an elegant approach to k-shot learning that is an instance of the framework described here: a Gaussian model is fit to the weights with MAP inference. The evaluation is promising, but preliminary. One of the goals of this paper is to provide a comprehensive evaluation. While not using a probabilistic approach, <ref type="bibr">[10]</ref> develop a method for k-shot learning that trains a recognition model to amortise MAP inference for the softmax weights which can then be used at k-shot learning time. While this method trains the mapping from activation to weights jointly with the classifier, and thus does not learn from the weights per se, it does exploit the structure in the weights for k-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>All the code used to produce the following experiments will be made available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset.</head><p>miniImageNet has become a standard testbed for k-shot learning and is derived from the Ima-geNet ILSVRC12 dataset <ref type="bibr">[11]</ref> by extracting 100 out of the 1000 classes. Each class contains 600 images downscaled to 84 ? 84 pixels. We use the 100 classes (64 train, 16 validation, 20 test) proposed by <ref type="bibr">[9]</ref>. As our approach does not require a validation set, we use both the training and validation data for the representational learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representational learning.</head><p>We employ standard CNNs that are inspired by ResNet-34 <ref type="bibr">[12]</ref> and VGG <ref type="bibr">[13]</ref> for the representational learning on the C base classes, cf. Phase 1 in Section 2.1. These trained networks provide both W MAP and the fixed feature representation ? ? for the k-shot learning and testing. We employed standard data augmentation from ImageNet for the representational learning but highlight that no data augmentation was used during the k-shot training and testing. For details on the architecture, training, and data augmentation see Appendix D.4. t-SNE embeddings <ref type="bibr">[14]</ref> of the learned last layer weights show sensible clusters, which highlights the structure exploited by the probabilistic model, see Appendix E.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines and competing methods.</head><p>We compare against several baselines as well as recent state-of-the-art methods mentioned in Section 3. The baselines are computed on the features x = ? ? (u) from the last hidden layer of the trained CNN: (i) Nearest Neighbours with cosine distance and (ii) regularized logistic regression with regularisation constant set either by cross-validation or (iii) using the variance of the weights, C = 2? 2 W , as motivated by our probabilistic framework, cf. Section 2.3. We also compare against three recent k-shot methods: (i) Matching Networks 1 <ref type="bibr">[3]</ref>, (ii) Prototypical Networks, with numbers reported from <ref type="bibr">[4]</ref> and (iii) Meta-learner LSTM, with numbers reported from <ref type="bibr">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-shot 5-shot 10-shot</head><p>ResNet-34 + Isotropic Gaussian (ours) 56.3 ? 0.4% 73.9 ? 0.3% 78.5 ? 0.3%</p><p>Matching Networks (reimplemented, 1-shot) 46.8 ? 0.5% --Matching Networks (reimplemented, 5-shot) -62.7 ? 0.5% -Meta-Learner LSTM <ref type="bibr">[9]</ref> 43.4 ? 0.8% 60.6 ? 0.7% -Prototypical Nets (1-shot) <ref type="bibr">[4]</ref> 49.4 ? 0.8% 65.4 ? 0.7% -Prototypical Nets (5-shot) <ref type="bibr">[4]</ref> 45.1 ? 0.8% 68.2 ? 0.7% - <ref type="table">Table 1</ref>: Accuracy on 5-way classification on miniImageNet. Our best method, an isotropic Gaussian model using ResNet-34 features consistently outperforms all competing methods by a wide margin. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing protocol.</head><p>We evaluate the methods on 600 random k-shot tasks by randomly sampling 5 classes from the 20 test classes and perform 5-way k-shot learning. Following <ref type="bibr">[4]</ref>, we use 15 randomly selected images per class for k-shot testing to compute accuracies and calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results on mini ImageNet</head><p>Overall k-shot performance.</p><p>We report performance on the miniImageNet dataset in <ref type="table">Table 1</ref> and Figs. 2 and 3. The best method uses as feature extractor a modified ResNet-34 with 256 features, trained with all 600 examples per training class, and a simple isotropic Gaussian model on the weights for concept learning. Despite its simplicity, our method achieves state-of-the-art and beats prototypical networks by a wide margin of about 6%. The baseline methods using the same feature extractor are also state-of-the-art compared to prototypical networks and both logistic regressions show comparable accuracy to our methods except for on 1-shot learning. In terms of log-likelihoods, Log Reg (C = 2? 2 W ) fares slightly better, whereas Log Reg (cv) is much worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deeper features lead to better k-shot learning.</head><p>We investigate the influence of different feature extractors of increasing complexity on performance in <ref type="figure">Fig</ref> . We find that the complexity of the feature extractor as well as training set size consistently correlate with the accuracy at k-shot time. For instance, on 5-shot, Gauss (iso) achieves 65% accuracy with a VGG network and 74% with a ResNet trained with all available data, a significant increase of almost 10%. Moreover, Gauss (iso) outperforms Log Reg (C = 2? 2 W ) on 1-shot learning across models, and performs similarly on 5-and 10-shot. We attribute the difference to the former's ability to also model the mean of the Gaussian, whereas logistic regression assumes a zero mean. Importantly, this result implies that training specifically for k-shot learning is not necessary for achieving high generalisation performance on this k-shot problem. On the contrary, training a powerful deep feature extractor on batch classification using all of the available training data, then building a simple probabilistic model using the learned features and weights achieves stateof-the-art. Recent models that use episodic training cannot leverage such deep feature extractors as for them the depth of the model is limited by the nature of training itself. The reference baseline in the k-shot learning literature is nearest neighbours, which performs on par with Gauss (iso) on 1-shot learning but is outperformed by all methods on 5-and 10-shot. This is evidence that building a simple classifier on top of the learned features works significantly better for k-shot learning than nearest neighbours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calibration.</head><p>A classifier is said to be calibrated when the probability it predicts for belonging to a given class is on par with the probability of it being the correct prediction. In other words, when examples for which it predicts a probability p of belonging to a given class are correctly classified for a fraction p of the examples. A calibration curve visualises the proportion of examples correctly classified as a function of their predicted probability; a perfectly calibrated classifier should result in a diagonal line. Following <ref type="bibr">[8]</ref>, we consider the log likelihood on the k-shot test examples as well as Expected Calibration Error (ECE) as summary measures of calibration. ECE can be interpreted as the weighted average of the distance of the calibration curve to the diagonal. We find that Log Reg (C = 2? 2 W ) and Gauss (iso) provide better accuracy and calibration than Log Reg (cross-validation), cf. <ref type="figure" target="#fig_2">Fig. 2</ref>. The difference in calibration quality for different regularisations of logistic regression highlights the importance of choosing the right constant, as we discuss now.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of the regularisation constant for logistic regression.</head><p>The results so far suggest that training a simple linear model such as regularised logistic regression might be sufficient to perform well in k-shot learning. However, while the accuracy at k-shot time does not vary dramatically as the regularisation constant changes, the calibration does, and jointly maximizing both quantities is not possible, cf. the first two plots of <ref type="figure">Fig. 4</ref>. The standard (frequentist) method to tune this constant is cross validation, which is not applicable in the 1-shot setting, and suffers from lack of data in 5-and 10-shot. Contrary, our probabilistic framework provides a principled way of selecting this regularisation parameter by transfer from the training weights: Log Reg (C = 2? 2 W ) strikes a good balance between accuracy and loglikelihood. The third plot in <ref type="figure">Fig. 4</ref> reports log-likelihood as a function of accuracy and provides further visualisation of the achieved trade-off between accuracy and calibration for Log Reg (C = 2? 2 W ), as well as the failure of Log Reg (cross-validation) to achieve a good compromise in 5-and 10-shot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation in an online setting.</head><p>We also briefly consider the online setting, in which we jointly test on 80 old and 5 new classes, for which catastrophic forgetting <ref type="bibr">[15]</ref> is a well known problem. During k-shot learning and testing we employ a softmax which includes both the new and the old weights resulting in a total of 85 weight vectors. We utilise ResNet-34 trained on 500 images per class to retain 100 test images on the old classes. While the k-shot weights were modelled probabilistically, we use the MAP estimate W MAP for the old weights. Accuracies are reported in <ref type="figure">Fig. 5</ref> for i) all the 85 classes, ii) the old 80 classes only, and iii) the new 5 classes only. For 5-and 10-shot, Gauss (iso) and Log Reg (2? 2 W ) only lose a couple of percent on the accuracy of the old classes, and perform well on the new classes, striking a good trade-off between forgetting and learning at k-shot time. For unregularised (MLE) logistic regression, the new weights completely dominate the old ones, highlighting that the right regularisation is important. Yet, cross-validation in this setting is often very challenging. When training Logistic Regression without including the old weights ("only new"), the new weights are dominated by the old ones and fail to learn the new classes, making training in the presence of the old weights an essential component for online learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model comparison on CIFAR-100</head><p>We performed an extensive comparison between different probabilistic models of the weights using different inference procedures, which we present in Appendix E.4. We report results on the CIFAR-100 dataset on (i) Gaussian, (ii) mixture of Gaussians, and (iii) Laplace, all with either MAP estimation or Hybrid Monte Carlo sampling. We found that the simple Gaussian model is on par with or outperforms other methods at k-shot time, which we attribute to it striking a good balance between choosing a complex model, which may better fit the weights, and statistical efficiency, as the number of weights C (80 in our case) is often smaller than the dimensionality of the feature representation (256 in our case), cf. Section 2. This finding is supported by computing the log-likelihood of held out training weights under such model, with the Gaussian model performing best. Experiments using Hybrid Monte Carlo sampling for k-shot learning returned very similar performance to MAP estimation and at a much higher computational cost, due to the difficulty of performing sampling in such a high dimensional parameter space. Our recommendation is that practitioners should use simple models and employ simple inference schemes to estimate all free parameters thereby avoiding expending valuable data on validation sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We present a probabilistic framework for k-shot learning that exploits the powerful features and class information learned by a neural network on a large training dataset. Probabilistic models are then used to transfer information in the network weights to new classes. Experiments on miniImageNet using a simple Gaussian model within our framework achieve state-of-the-art for 1-shot and 5-shot learning by a wide margin, and at the same time return well calibrated predictions. This finding is contrary to the current belief that episodic training is necessary to learn good k-shot features and puts the success of recent complex deep learning approaches to k-shot learning into context. The new approach is flexible and extensible, being applicable to general discriminative models and k-shot learning paradigms. For example, preliminary results on online k-shot learning indicate that the probabilistic framework mitigates catastrophic forgetting by automatically balancing performance on the new and old classes. The Gaussian model is closely related to regularised logistic regression, but provides a principled and fully automatic way to regularise. This is particularly important in k-shot learning, as it is a low-data regime, in which cross-validation performs poorly and where it is important to train on all available data, rather than using validation sets.</p><p>Appendix to "Discriminative k-shot learning using probabilistic models"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Details on the derivation and approximations from Section 2.1</head><p>As stated in the main text, the probabilistic k-shot learning approach comprises four phases mirroring the dataflow:</p><formula xml:id="formula_9">Phase 1: Representational learning.</formula><p>The large dataset D is used to train the CNN ? ? using standard deep learning optimisation approaches. This involves learning both the parameters ? of the feature extractor up to the last hidden layer, as well as the softmax weights W. The network parameters ? are fixed from this point on and shared across phases. This is a standard setup for multi-task learning and in the present case it ensures that the features derived from the representational learning can be leveraged for k-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase 2: Concept learning.</head><p>The softmax weights W are effectively used as data for concept learning by training a probabilistic model that detects structure in these weights which can be transferred for k-shot learning. This approach will be justified in the next section. For the moment, we consider a general class of probabilistic models in which the two sets of weights are generated from shared hyperparameters ?, so that p( W, W, ?) = p(?)p( W|?)p(W|?) (see <ref type="figure" target="#fig_1">Fig. 1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phases 3 and 4: k-shot learning and testing.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probabilistic model of the weights</head><p>Given the dataflow and the assumed probabilistic model in <ref type="figure" target="#fig_1">Fig. 1 (right)</ref>, a completely probabilistic approach would involve the following steps. In the concept learning phase, the initial dataset would be used to form the posterior distribution over the concept hyperparameters p(? | D). The k-shot learning phase combines the information about the new weights provided by D with the information in the k-shot dataset D to form the posterior distribution</p><formula xml:id="formula_10">p(W | D, D) ? p(W | D) n p(y n | x n , W) where p(W | D) = p(W | ?)p(? | D)d?.<label>(6)</label></formula><p>To see this, notice that</p><formula xml:id="formula_11">p(W | D, D) ? p(W, D, D) = p( D)p(W | D)p(D | D, W).<label>(7)</label></formula><p>The graphical model in <ref type="figure" target="#fig_1">Fig. 1</ref> entails that D is conditionally independent from D given W, such that</p><formula xml:id="formula_12">p(D | W, D) = p(D | W) = n p(y n | x n , W).<label>(8)</label></formula><p>We recover Eq. (6) by adding p( D) to the constant of proportionality. Inference in this model is generally intractable and requires approximations. The main challenge is computing the posterior distribution over the hyper-parameters given the initial dataset. However, progress can be made if we assume that the posterior distribution over the weights can be well approximated by the MAP value p( W | D) ? ?( W ? W MAP ). This is an arguably justifiable assumption as the initial dataset is large and so the posterior will concentrate on narrow modes (with similar predictive performance). In this case p(? | D) ? p(? | W MAP ) and, due to the structure of the probabilistic model, all instances of D in Eq. (6) and Eq. (1) can be replaced by the analogous expressions involving W MAP . This greatly simplifies the learning pipeline as the probabilistic modelling only needs to have access to the weights returned by representational learning. Remaining intractabilities involve only a small number of data points D and can be handled using standard approximate inference tools. The following summarizes the approximations and computational steps for each phase of training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Approximate inference methods</head><p>In this section we briefly discuss different inference methods for the probabilistic models. In the main text we only considered MAP inference as we found that other more complicated inference schemes do not yield a practical benefit. However, in Appendix E.4 we provide a detailed model comparison, in which we also consider other approximate inference methods. In all cases the gradients of the densities w.r.t. W can be computed, enabling MAP inference in the k-shot learning phase to be efficiently performed via gradient-based optimisation using L-BFGS <ref type="bibr">[1]</ref>. Alternatively, Markov Chain Monte Carlo (MCMC) sampling can be performed to approximate the associated integral, see Eq. (1). Due to the high dimensionality of the space and as gradients are available, we employ Hybrid Monte Carlo (HMC) <ref type="bibr">[2]</ref> sampling in the form of the recently proposed NUTS sampler that automatically tunes the HMC parameters (step size and number of leapfrog steps) <ref type="bibr">[3]</ref>. For the GMMs we employed pymc3 <ref type="bibr">[4]</ref> to perform MAP inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Models for the prior on the weights</head><p>As discussed in Section 2.1, we specify our model through p(W, W, ?) thus defining p(W | W M AP ) in Eq. (2). This section analyses different priors on the weights: (i) Gaussian models, (ii) Gaussian mixture models, and (iii) Laplace distribution. In the main paper, we only use a Gaussian model with MAP inference, as we saw no significant advantage in using other, more complex models. However, we provide an extensive comparison of the different models in Appendix E.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Gaussian model</head><p>Possibly the simplest approach consists of modelling p(W | W) as a Gaussian distribution:</p><formula xml:id="formula_13">p(W | W) = N (W | ?, ?)p(?, ? | W)d?d?.<label>(9)</label></formula><p>Details for this section can be found in <ref type="bibr">[5]</ref>. The normal-inverse-Wishart distribution for ? and ? is a conjugate prior for the Gaussian, which allows for the posterior to be written in closed form. More precisely,</p><formula xml:id="formula_14">p(?, ?) = N IW(?, ? | ? 0 , ? 0 , ? 0 , ? 0 ) = 1 Z |?| ?(? 0 +p)/2+1 e ? 1 2 tr(? 0 ? ?1 )? ? 0 2 (??? 0 ) t ? ?1 (??? 0 ) ,<label>(10)</label></formula><p>where Z is the normalising constant. The posterior p(?, ? | W) also follows a normal-inverse-Wishart distribution:</p><formula xml:id="formula_15">p(?, ? | W) = N IW(?, ? | ? N , ? N , ? N , ? N ),<label>(11)</label></formula><p>where</p><formula xml:id="formula_16">? N = ? 0 ? 0 + N ? 0 + N ? 0 + N W ? N = ? 0 + N ? N = ? 0 + S + ? 0 N ? 0 + N ( W ? ? 0 )( W ? ? 0 ) t ? N = ? 0 + N ,</formula><p>and S is the sample covariance of W. For this model, we can integrate (9) in closed form, which results in the following multivariate Student t-distribution:</p><formula xml:id="formula_17">p(W | W) = t ? N ?p+1 ? N , ? N (? N + 1) ? N (? N ? p + 1) .</formula><p>As with other approaches, one can also compute the MAP solutions for the mean ? MAP and covariance ? MAP , such that p(W | W) = N (W | ? MAP , ? MAP ). For both the analytic posterior and the MAP approximation, p(W | W) depends on the hyperparameters of the normal-inverse-Wishart distribution: ? 0 , ? 0 , ? 0 and ? 0 . There are different ways to choose these hyperparameters. One way would be by optimising the log probability of held out training weights, see Appendix E.4 for a brief discussion. In practise, it is common to choose uninformative or data dependent priors as discussed by <ref type="bibr">[5,</ref><ref type="bibr">Chapter 4</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Mixture of Gaussians (GMM)</head><p>A Gaussian mixture model can potentially leverage cluster structure in the weights (animal classes might have similar weights, for example). This is related to the tree-based prior proposed in <ref type="bibr">[6]</ref>. MAP inference is performed because exact inference is intractable. Similarly to the Gaussian case, different structures for the covariance of each cluster were tested. In our experiments, we fit the parameters of the GMM via maximum likelihood using the EM algorithm. GMM consists on modelling p(W | W) as a mixture of Gaussians with S components:</p><formula xml:id="formula_18">p(W | W) = S s=1 ? s N (W | ? s , ? s ) p(? 1 , . . . , ? S , ? 1 , . . . , ? S | W)d? 1 . . . d? S d? 1 . . . d? S ,<label>(12)</label></formula><p>where S s=1 ? s = 1. In this work, we only compute the MAP mean and covariance for each of the clusters, as opposed to averaging over the parameters of the mixture. The resulting posterior is</p><formula xml:id="formula_19">p(W | W) = S s=1 ? s N (W | ? M AP,s , ? M AP,s ).<label>(13)</label></formula><p>The components of the mixture are fit in two ways. For CIFAR-100, the classes are grouped into 20 superclasses, each containing 5 of the 100 classes. One option is therefore to initialize 20 components, each fit with the data points in the corresponding superclass. For each such individual Gaussian, the MAP inference method presented in the previous section can be used.</p><p>In order to increase the number of weight examples in each superclass, we merge the original superclasses into 9 larger superclasses. The merging of the superclasses is the following:</p><p>? Aquatic mammals + fish ? flowers + fruit and vegetables + trees ? insects + non-insect invertebrates + reptiles ? medium-sized mammals + small mammals ? large carnivores + large omnivores and herbivores ? people ? large man-made outdoor things + large natural outdoor things ? food containers + household electrical devices + household furniture ? Vehicles 1 + Vehicles 2. The parameters of the mixture can also be fit using maximum likelihood with EM. We use the implementation of EM in scikit-learn. Both 3 and 10 clusters are considered in CIFAR-100. Weight log-likelihoods under this model and k-shot performance can be found in Appendix E.4. Note that, similarly to the Gaussian model, we consider isotropic, diagonal or full covariance models for the covariance matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Laplace distribution</head><p>Sparsity is an attractive feature which could be helpful for modelling the weights. Indeed, it is reasonable to assume that each class uses a set of characteristic features which drive classification accuracy, while others are irrelevant. Sparse models would then provide sensible regularization. As such, we consider a product of independent Laplace distribution. Section 2.3 highlights the relation between a Gaussian prior on the weights and L 2 regularised logistic regression. One can similarly show that the Laplace prior is related to L 1 regularised logistic regression, which is well known for encouraging sparse weight vectors.</p><p>We consider a prior which factors along the feature dimensions:</p><formula xml:id="formula_20">p( W | {? j }, {? j }) = p j 1 2? j exp ? ? ? C i | W ij ? ? j | ? j ? ? .</formula><p>where the product over j is along the feature dimensions and the sum over i is across the classes. We fit the parameters ? and ? via maximum likelihood:</p><formula xml:id="formula_21">? MLE,j = median i ( W ij ) ? MLE,j = 1 N i | W ij ? ? j |, such that p(W | W) = p j 1 2? MLE,j exp ? C i |W ij ? ? MLE,j | ? MLE,j .</formula><p>An isotropic Laplace model with mean ? and scale ? is also considered:</p><formula xml:id="formula_22">p( W | ?, ?) = 1 2? exp ? ij | W ij ? ?| ? , where ? MLE = median( W) ? MLE = 1 N p ij | W ij ? ?|,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Training and evaluation procedure details D.1. mini ImageNet</head><p>To construct miniImageNet we use the same classes as initially proposed by <ref type="bibr">[7]</ref> and used in <ref type="bibr">[8]</ref>, which is split into 64 training classes (cf.  <ref type="table" target="#tab_4">Table 4</ref>). We will make a full list of image files available. As we do not require a validation set, we combine the training and validation set to form an extended training set. We extract 600 images per class from the ImageNet 2012 Challange dataset <ref type="bibr">[9]</ref>, scale the shorter side to 84 pixels and then centrally crop to 84 ? 84 pixels, that is, we preserve the original aspect ratio of the image content. We use these coloured 84 ? 84 ? 3 images as input for representational and k-shot learning and testing. In order to train very deep models, such as a ResNet, we need to perform data augmentation as is the case when training full ImageNet. We use the following standard data augmentation from ImageNet that we adapt to the size of the input images:</p><p>? random horizontal flipping ? randomly paste image into 100 ? 100 frame and cut out central 84 ? 84 pixels ? randomly change brightness, contrast, saturation and lighting We highlight that we do not perform any data augmentation for the k-shot learning and k-shot testing but use the original 84 ? 84 colour images as input to the feature extractor.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. CIFAR-100</head><p>CIFAR-100 consists of 100 classes each with 500 training and 100 test images of size 32 ? 32. The classes are grouped into 20 superclasses with 5 classes each. For example, the superclass "fish" contains the classes aquarium fish, flatfish, ray, shark, and trout. Unless otherwise stated, we used a random split into 80 base classes and 20 k-shot learning classes. For k-shot learning and testing, we split the 100 classes into 80 base classes used for network training and 20 k-shot learning classes.  <ref type="bibr">[ 8,</ref><ref type="bibr">11,</ref><ref type="bibr">12,</ref><ref type="bibr">20,</ref><ref type="bibr">23,</ref><ref type="bibr">26,</ref><ref type="bibr">29,</ref><ref type="bibr">30,</ref><ref type="bibr">31,</ref><ref type="bibr">33,</ref><ref type="bibr">37,</ref><ref type="bibr">39,</ref><ref type="bibr">41,</ref><ref type="bibr">47,</ref><ref type="bibr">57,</ref><ref type="bibr">68,</ref><ref type="bibr">71,</ref><ref type="bibr">72,</ref><ref type="bibr">81,</ref><ref type="bibr">84 ]</ref> We provide an exhaustive comparison of different probabilistic models for this k-shot learning task in Appendix E.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Network architecture and training: ResNet inspired</head><p>The network architecture is inspired by the ResNet-34 architecture for ImageNet <ref type="bibr">[10]</ref> that uses convolution blocks, with two convolutions each, that are bridged by skip connections. As a base, we utilise the example code 2 provided by tensorpack (https://github.com/ppwwyyxx/ tensorpack), a neural network training library built on top of tensorflow <ref type="bibr">[11]</ref>. We adapt the number of features as well as the size of the last fully connected layer to account for the smaller number of training samples and training classes. The final architecture is detailed in <ref type="table" target="#tab_7">Table 5</ref>. The network is trained using a decaying learning rate schedule and momentum SGD and is implemented in tensorpack using tensorflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. Network architecture and training: VGG Inspired</head><p>The network architecture was inspired by the VGG networks <ref type="bibr">[12]</ref>, but does not employ batch normalisation <ref type="bibr">[13]</ref>. To speed up training, we employ exponential linear units (ELUs), which have been reported to lead to faster convergence as compared to ordinary ReLUs <ref type="bibr">[14]</ref>. To regularise the networks, we employ dropout <ref type="bibr">[15]</ref> and regularisation of the weights in the fully connected layers. The networks are trained with the ADAM optimiser <ref type="bibr" target="#b31">[16]</ref> with decaying learning rate. The network is implemented in tensorpack using tensorflow. The points are coloured according to their respective superclass. The colouring by superclass makes the structure in the weights evident, as t-SNE overall recovers the structure in the dataset. For instance, oak tree, palm tree, willow tree and pine tree form a cluster on the bottom right. This structure motivates our approach, as the training weights contain information which may be useful at k-shot time, for instance given a few example from chestnut trees. Structure is still present and we observe meaningful patterns, even though the classes in miniImageNet are more unique than in CIFAR-100. For instance, goose, house finch, toucan, Arctic fox, green mamba and other animals are clustered on the top, with birds close to each other. Examples of other small clusters include poncho and miniskirt, or organ and oboe. For readability, not all class names are plotted.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Extended experiments E.1. t-SNE embedding of the weights</head><p>We provide t-SNE embeddings for the weights of a VGG network trained in CIFAR-100 and a ResNet-34 trained on miniImageNet. A structure in the weights is apparent and provides motivation for our framework. The results can be seen in <ref type="figure" target="#fig_8">Fig. 6</ref> and <ref type="figure" target="#fig_9">Fig. 7</ref>.  <ref type="figure">Fig. 9</ref> reports accuracy and calibration in terms of Expected Calibration Error (ECE) (lower is better) and log likelihoods (higher is better) for different regularisations of logistic regression for all three model architectures considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Extended results on mini ImageNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3. Choice of regularisation constant</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VGG-style Network for CIFAR-100</head><p>Output    We highlight that for all three architectures the order of the different methods as well as the main messages are the same. However, the general performance in terms of accuracy and calibration differ between the architectures. The more complex architecture trained on most images performs best in terms of accuracy, indicating that it learns better features for k-shot learning. Both ResNets behave very similarly on calibration whereas the VGG-style network performs better (lower ECE and higher log likelihood as well as more diagonal calibration curve). This is in line with observations by <ref type="bibr" target="#b32">[17]</ref> that calibration of deep architectures gets worse as depth and complexity increase. are drawn as black triangles. Dashed lines correspond to logistic regression with cross-validated (changing) regularisation constant. Colour brightness of the markers ranges from dark (C = 10 ?5 ) to bright (C = 10). In addition to <ref type="figure">Fig. 4</ref> we also provide results for calibration in terms of ECE (lower is better), which are consistent with log likelihoods (higher is better):</p><p>The Bayesian inspired choice of the regularisation parameter strikes a good balance between accuracy and calibration and consistently outperforms cross-validated choice of the parameter.  <ref type="table">Table 9</ref>: Held-out log probabilities on random 70/10-splits of the training weights for the different models on CIFAR-100. Values are averaged over 50 splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of the models on held-out training weights.</head><p>First, we analyse how well the different prior models for the new softmax weights are able to fit the C training weights W. We randomly excluded 10 of those weights and evaluated their held-out negative log likelihood given the remaining C ? 10 weights. We emphasise that this approach also constitutes a principled way to set the hyperparameters of the prior and, critically, relies on an explicit probabilistic model. The negative log probabilities are averaged over 50 random splits and results of best optimised values w.r.t. hyperparameters are shown in <ref type="table">Table 9</ref> for CIFAR-100 (lower is better). We find that all models behave very similar but that multivariate Gaussian models generally outperform other models. We attribute the good performance of the simpler models to the small number of data points (C ?10 = 70 training weights) and the high dimensionality of the space, which entail that fitting even simple models is difficult. Thus, more complicated models cannot improve over them.</p><p>k-shot performance in CIFAR-100. Accuracies are measured on a 5-way classification task on the k-shot classes for k ? {1, 5, 10}. Results were averaged two-fold: (i) 20 random splits of the 5 k-shot classes; (ii) 10 repetitions of each split with different k-shot training examples. Among our models, no statistically significant difference in accuracy is observed, with the exception of Laplace MAP and GMM (iso), which consistently underperforms. These findings are consistent in terms of log-likelihoods, see the first and second plots in <ref type="figure" target="#fig_1">Fig. 10</ref>. Finally, our methods are generally well calibrated, with Gaussian models generally better than Laplace models. Moreover, all methods (with the exception of Laplace and GMM (10, iso) have low ECE and high accuracy, see the third and fourth plots of <ref type="figure" target="#fig_1">Fig. 10</ref>. While Gauss (integr. prior) HMC and Gauss (MAP) HMC are sightly better calibrated than our proposed method in the main paper, Gauss (MAP) iso, we believe the gain in calibration is not worth the significant increase in computational resources needed for the sampling procedure. Interestingly, both GMM approaches are not able to outperform the other, simpler models. This is in line with the previous observation that the simpler models are better able to explain the weights. Again, we attribute this inability of mixture models to use their larger expressivity/capacity to the small number of data points and the high-dimensionality of weight-space which means learning even simple models is difficult. These observations suggest that the use of mixture models in this type of k-shot learning framework is not beneficial and is in contrast to the approach of [6],  <ref type="figure" target="#fig_1">Figure 10</ref>: Results on CIFAR-100 for VGG style architecture. We report accuracy, log-likelihood and calibration for the methods and inference procedures presented in <ref type="table">Table 8</ref>. With the exception of GMM (10, iso) and Laplace, all methods are similar terms of accuracy and log-likelihood. Gauss (integr. prior) HMC and Gauss (MAP) HMC are slightly better calibrated than our proposed Gauss (MAP) iso, but require significantly more computation for the sampling procedure.</p><p>who employ a tree-structured mixture model. The authors show compare a model in which the assignments to the superclasses in the tree are optimized over against a model with a naive initialisation of the superclass assignments, and show that the first outperforms the second. However, they do not compare against a simpler baseline, e.g., a single Gaussian model. Overall, we observe that there is no significant benefit of more complex methods over the simple isotropic Gaussian, either in terms of accuracy, log-likelihood or calibration. Thus, our recommendation is that practitioners should use simple models and employ simple inference schemes to estimate all free parameters thereby avoiding expending valuable data on validation sets</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>left: Shared feature extractor ? ? and separate top linear layers W and W with corresponding softmax units on old and new classes. right: Graphical model for probabilistic k-shot learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Results for miniImageNet with ResNet-34 style architecture and 600 training images per class. From left to right: accuracy and log likelihood (higher is better) for different k, Expected Calibration Error (ECE, lower is better) vs accuracy for 5-shot learning, and Calibration curve for 5-shot learning. Results on other architectures can be found in Appendix E.2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>. 3: i) a VGG style network (500 train images per class), ii) a ResNet-34 (500 Comparison of different network architectures and training set sizes on the k-shot learning task: VGG style network (trained on 500 images per class) and ResNet-34 style network (trained on 500 and 600 images per class, respectively). Both, deeper networks and larger number of training images, give rise to features that transfer better to k-shot learning. examples per class), and iii) a ResNet-34 (all 600 examples per class)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 WFigure 4 : 2 W</head><label>242</label><figDesc>C reg = 10 ?5 ? C reg = 10 C by cross-validation C = 2? Choice of regularisation constant for logistic regression for k-shot learning. Results for C reg = 2? are drawn as black triangles. Dashed lines correspond to logistic regression with cross-validated (changing) regularisation constant. Colour brightness of the markers ranges from dark (C = 10 ?5 ) to bright (C = 10). ECE plots are provided in Appendix E.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 : 2 W 2 W</head><label>522</label><figDesc>Online learning with ResNet-34 features. Gauss (iso) and Log Reg (2? ) strike a good trade-off between learning on new classes and forgetting of old classes. Unregularised Log Reg (MLE) and Log Reg (2? , only new), which has not been trained in the presence of the old weights, either completely forget the old classes or do not learn anything, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Probabilistic k-shot learning leverages the learned representation ? ? from phase 1 and the probabilistic model p( W, W, ?) from phase 2 to build a (posterior) predictive model for unseen new examples using examples from the small dataset D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Phase 1 :Phase 2 :</head><label>12</label><figDesc>Representational learning. Deep learning is used to train a CNN. The representation of input images at the last hidden layer, x = ? ? (u), is used in subsequent phases. The final layer softmax weights are assumed to be MAP estimates W MAP . Concept learning. A probabilistic model is fit directly to the MAP weights p(? | W MAP ) ? p(?)p( W MAP |?). For conjugate models a full posterior can be retained, otherwise a MAP estimate p(? | W MAP ) ? ?(? ? ? MAP ) is used. Phase 3: k-shot learning. The posterior distribution over the new softmax weights p(W | D, W MAP ) ? p(W | W MAP ) N n=1 p(y n |x n , W) is generally intractable. The posterior can, however, be approximated using the MAP estimate p(W | D, W MAP ) ? ?(W ? W MAP ) or through sampling W m ? p(W | D, W MAP ). Note that p(W | W MAP ) = p(W|?)p(? | W MAP )d? is analytic for conjugate models and, if instead a MAP estimate for ? is provided by the concept modelling stage, then p(W | W MAP ) ? p(W|? MAP ). Phase 4: k-shot testing. Approximate inference is used to compute p(y * | x * , D, W MAP ) = p(y * | x * , W)p(W | D, W MAP )dW. If the k-shot learning phase provides a MAP estimate of W then p(y * | x * , D, W MAP ) ? p(y * | x * , W MAP ). If samples are returned then p(y * | x * , D, W MAP ) ? 1 M M m=1 p(y * | x * , W m ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>t-SNE embedding of the CIFAR-100 weights W trained using a VGG style architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>t-SNE embedding of the miniImageNet weights trained using a ResNet-34 architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8</head><label>8</label><figDesc>provides extended results on k-shot learning for the miniImageNet dataset for different network architectures. We investigate the influence of different feature extractors of increasing complexity and training data size on performance on: i) a VGG style network trained on 500 images per class, ii) a ResNet-34 trained on 500 examples per class, and iii) a ResNet-34 trained on all 600 examples per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Extended results for the miniImageNet dataset utilising different network architectures and representational training. top: a ResNet-34 trained with all 600 examples per class; middle: a ResNet-34 trained with 500 images per class; bottom: a VGG style network trained with 500 images per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>= 2? 2 W= 2? 2 W= 2? 2 WFigure 9 :</head><label>2229</label><figDesc>C reg = 10 ?5 ? C reg = 10 C by cross-validation C C reg = 10 ?5 ? C reg = 10 C by cross-validation C C reg = 10 ?5 ? C reg = 10 C by cross-validation C Choice of regularisation constant for logistic regression on k-shot learning. Note that all three rows use the same raw data that are only visualised differently. Top: Summary of accuracy and calibration in terms of log likelihood and Expected Calibration Error (ECE). Middle: detailed plot of ECE vs. accuracy. Bottom: detailed plot of log likelihood vs. accuracy. Results for C reg = 2? 2 W</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note>), 16 validation classes (cf. Table 3), and 20 test classes (cf.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Training classes for miniImageNet as proposed by[7]   </figDesc><table><row><cell>n03075370 combination lock n02971356 carton n03980874 poncho n02114548 white wolf, Arctic wolf, Canis lupus tundrarum n03535780 horizontal bar, high bar n03584254 iPod n02981792 catamaran n03417042 garbage truck, dustcart n03770439 miniskirt, mini n02091244 Ibizan hound, Ibizan Podenco n02174001 rhinoceros beetle n09256479 coral reef n02950826 cannon n01855672 goose n02138441 meerkat, mierkat n03773504 missiles</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Validation classes for miniImageNet as proposed by[7]    </figDesc><table><row><cell>n02116738 African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus n02110063 malamute, malemute, Alaskan malamute n02443484 black-footed ferret, ferret, Mustela nigripes n03146219 cuirass n03775546 mixing bowl n03544143 hourglass n04149813 scoreboard n03127925 crate n04418357 theater curtain, theatre curtain n02099601 golden retriever n02219486 ant, emmet, pismire n03272010 electric guitar n04146614 school bus n02129165 lion, king of beasts, Panthera leo n04522168 vase n07613480 trifle n02871525 bookshop, bookstore, bookstall n01981276 king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica n02110341 dalmatian, coach dog, carriage dog n01930112 nematode, nematode worm, roundworm</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Test classes for miniImageNet as proposed by[7]   </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Network architecture. All unnamed layers are 2D convolutions with stated kernel size and padding SAME; the output of the shaded layer corresponds to ? ? (u), the feature space representation of the image u, which is used as input for probabilistic k-shot learning.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Network architectures. All 2D convolutions have kernel size 3 ? 3 and padding SAME; max-pooling is performed with stride 2. The output of the shaded layer corresponds to ? ? (u), the feature space representation of the image u, which is used as input for probabilistic k-shot learning</figDesc><table><row><cell></cell><cell>Accuracy</cell><cell></cell><cell cols="3">ResNet-34 trained on 600 images per class</cell></row><row><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>5 k-shot Gauss (iso)</cell><cell>10</cell><cell>W ) Log Reg (C = 2? 2 1 5 k-shot</cell><cell>Log Reg (cross-validation) 10</cell><cell>Nearest Neighbour</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">as reimplemented and optimised by https://github.com/AntreasAntoniou/MatchingNetworks to produce results that are superior to those originally published.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/ppwwyyxx/tensorpack/tree/master/examples/ResNet</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method name</head> <ref type="table">Table 7</ref><p>: Description of the inference for the parameters of the prior in phase 2 (concept learning) for the models in from <ref type="figure">Fig. 10</ref>. This specifies the inference procedure for ? in p(w | ?) after observing the training weights W.  <ref type="table">Table 8</ref>: Methods and inference procedure during phase 3 (k-shot learning) for the models used in <ref type="figure">Fig. 10</ref>. This specifies the inference procedure used when computing p(W | D, W) for the specified prior distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method name Phase 3: k-shot learning</head><p>In the main text, we only consider an isotropic Gaussian model with MAP inference since we do not observe benefits from using alternative methods in terms of k-shot performance and calibration. Moreover, while we report results on a VGG-like architecture, we could also use a ResNet architecture, and preliminary results point to the same conclusion as experiments on miniImageNet when switching from VGG to ResNet: the deeper features consistently lead to higher k-shot performance on all methods whereas the ordering of the methods stays roughly the same.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning workshop, International Conference of Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Prototypical Networks for Few-shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno>arXiv e-print: 1703.05175</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative transfer learning with tree-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">One-Shot Learning in Discriminative Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Robert</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Bayesian Deep Learning workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Task Clustering and Gating for Bayesian Multitask Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On Calibration of Modern Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>arXiv e-print: 1706.04599</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Few-Shot Image Recognition by Predicting Parameters from Activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno>arXiv e-print: 1706.03466</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>eprint: 1512.03385</idno>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for largescale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>arXiv e-print:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualizing Data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in cognitive sciences</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">This section reports an extensive model comparison on CIFAR-100, both for the model of the weights p(W | W) and for the inference procedure at k-shot time (MAP or Hybrid Monte Carlo (HMC) sampling using NUTS [3], see the description of approximate inference algorithms in Appendix B). We report log-likelihood of the weights under different models, as well as accuracy, log-likelihood and calibration in a k-shot learning task</title>
	</analytic>
	<monogr>
		<title level="m">Table 7 and Table 8 show descriptions of the methods analysed for respectively phase</title>
		<imprint/>
	</monogr>
	<note>concept learning) and phase 3 (k-shot learning</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong C Liu &amp;amp; Jorge</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MCMC using Hamiltonian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Markov Chain Monte Carlo</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Hoffman &amp;amp; Andrew Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic programming in Python using PyMC3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Salvatier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonnesbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Machine Learning: A Probabilistic Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminative transfer learning with treebased priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava &amp;amp; Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;amp;</forename><surname>Hugo Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Prototypical Networks for Few-shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno>arXiv e-print: 1703.05175</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno>eprint: 1512.03385</idno>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Shaoqing Ren, &amp; Jian Sun</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">aoqiang Zheng. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Software available from tensorflow.org</title>
		<editor>Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi?gas</editor>
		<meeting><address><addrLine>Dan Man?, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner; Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, &amp; Xi</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan &amp;amp; Andrew Zisserman</surname></persName>
		</author>
		<idno>arXiv e-print:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe &amp;amp; Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
		<idno>arXiv e-print:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djork-Arn?</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno>arXiv e-print:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Ilya Sutskever, &amp; Ruslan Salakhutdinov</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;amp; Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno>arXiv e-print:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">On Calibration of Modern Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<idno>arXiv e-print: 1706.04599</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
