<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking Spatial Invariance of Convolutional Networks for Object Counting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qi</forename><surname>Cheng</surname></persName>
							<email>zhiqic@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dai</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Southwest Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingkuan</forename><surname>Song</surname></persName>
							<email>jingkuan.song@gmail.com</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wu</surname></persName>
							<email>wuxiaohk@home.swjtu.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Southwest Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking Spatial Invariance of Convolutional Networks for Object Counting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous work generally believes that improving the spatial invariance of convolutional networks is the key to object counting. However, after verifying several mainstream counting networks, we surprisingly found too strict pixellevel spatial invariance would cause overfit noise in the density map generation. In this paper, we try to use locally connected Gaussian kernels to replace the original convolution filter to estimate the spatial position in the density map. The purpose of this is to allow the feature extraction process to potentially stimulate the density map generation process to overcome the annotation noise. Inspired by previous work, we propose a low-rank approximation accompanied with translation invariance to favorably implement the approximation of massive Gaussian convolution. Our work points a new direction for follow-up research, which should investigate how to properly relax the overly strict pixel-level spatial invariance for object counting. We evaluate our methods on 4 mainstream object counting networks (i.e., MCNN, CSRNet, SANet,. Extensive experiments were conducted on 7 popular benchmarks for 3 applications (i.e., crowd, vehicle, and plant counting). Experimental results show that our methods significantly outperform other state-of-the-art methods and achieve promising learning of the spatial position of objects 1 . * Corresponding authors. ? Work done during remote research collaboration with CMU.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object counting has been widely studied since it can potentially solve crowd flow monitoring, traffic management, etc. The previous works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b63">64]</ref> believe that the latchkey to improving the object counting is to improve the spatial invariance of CNNs. Based on this starting point, more and more networks (such as dilated CNNs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b38">39]</ref>, deformable CNNs <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b33">34]</ref> and multi-column CNNs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">Figure 1</ref>. The left shows the idea of density map generation, and the right is an example from SHTech-PartA dataset <ref type="bibr" target="#b77">[78]</ref>, where the red dot is the annotation in groundtruth, and the black dot is the real center position. The density map is generated by smoothing the center points with the multi-dimensional Gaussian distribution. There are two main types of noise: 1) the error between the true center points and the annotations and 2) the overlap ? caused by multiple Gaussian kernels. [Best view in color]. 73]) are studied for object counting.</p><p>However, this research direction has appeared performance bottlenecks. We noticed that the counting accuracy had not been significantly improved with further continuously optimizing the network architectures. Some recent studies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b59">60]</ref> also witnessed a lot of noise during density generation and conjecture that this might be the reason for the performance bottleneck. Although these efforts have made some progress, we are still ignorant of the following questions. 1) Is blindly improving spatial invariance valuable for object counting tasks? 2) How does density noise affect performance?</p><p>Before answering these questions, let's briefly introduce the generation process of the density map. <ref type="figure">Figure 1</ref> takes crowd counting as an example. The density map is generated by smoothing the center point with multiple Gaussian kernels. This preprocessing converts the discrete counting problem into a continuous density regression, but inevitably brings some noise. In general, there are two types of noise. 1) The error between the actual center point and annotation (i.e., between the red and black dots). 2) The overlay of Gaussian kernels (i.e., ?) 2 . More formal mathematical description is in Sec. 3.1 and 3.2.</p><p>To answer these problems, we have thoroughly verified four mainstream object counting methods (MCNN <ref type="bibr" target="#b78">[79]</ref>, CSRNet <ref type="bibr" target="#b27">[28]</ref>, SANet <ref type="bibr" target="#b3">[4]</ref> and ResNet-50 <ref type="bibr" target="#b17">[18]</ref>) in three different tasks (crowd, vehicles and plants counting). Extensive verification experiments reveal that too strict pixellevel spatial invariance will not only cause the large prediction variances, but also overfitting to the noise in the density map as Sec. 4.2. We observed that the existing models 1) cannot be generalized, even impossible within the same crowd counting task and 2) essentially impossible to learn the actual object position and distribution in the density maps. In general, these experiments provide the following answers. 1) Solely increasing the spatial invariance is not beneficial to object counting tasks. 2) The pixel-level spatial invariance makes the model easier to overfit the density map noise.</p><p>To solve these problems, inspired by the previous works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>, we try to replace the traditional convolution operation with Gaussian convolution. The motivation behind this is to mimic the Gaussian-style density generation throughout the whole feature learning, rather than merely generating the final density map. To a certain extent, this modification is equivalent to a relaxation of the pixel-level spatial invariance. After the pixel-grid filters are revised with Gaussian kernels, we can jump out of the over-strict pixel-level restrictions. Fortunately, the experimental result of Sec. 4.4 proved that this relaxation could allow us to avoid overfitting to the density map noise and promisingly learn the object position and distribution law.</p><p>Technically, we propose a novel low-rank approximation to simulate the process of Gaussian-style density map generation during the feature extraction. Although previous work <ref type="bibr" target="#b59">[60]</ref> uses a multivariate Gaussian approximation to optimize the density map in the loss function, it is unclear how to explicitly model this approximation during the convolution process. Note that the approximation in <ref type="bibr" target="#b59">[60]</ref> only imposes the constraints on predicted density maps, while leaving the density estimation unchanged. In contrast, our approach employs Gaussian convolution to replace standard convolution, where our low-rank approximation uses finite Gaussian kernels (Eq. 10) to approximate the massive Gaussian kernel convolution (Eq. 7). It is worth noting that our method concentrates on the density estimation process, while <ref type="bibr" target="#b59">[60]</ref> only focuses on the generated density maps.</p><p>As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, we replace the standard convolution operation with Gaussian convolution to provide a novel way to generate the density map. We first propose a Low-rank Approximation module to approximate the massive Gaussian convolution. Specifically, we sample a few Gaussian kernels from the groundtruth density map as input, and then employ Principal Component Analysis (PCA) to select some representative Gaussian kernels. Through a simple attention mechanism, the correlation between the se-lected Gaussian kernels is learned, which is operated to approximate the massive Gaussian convolution. Correspondingly, we also propose a Translation Invariance Module to accelerate the inference. On the input side, we adopt the translation invariance to decouple the Gaussian kernel operation to accelerate the convolution operation. On the output side, we utilize the weights obtained from the low-rank approximation module to accomplish approximation. Note that all of our implementations are based on CUDA. It can be seamlessly applied to mainstream CNNs and is end-toend trainable. To conclude, our contributions are mainly three folds:</p><p>? We reveal that the overly restrictive spatial invariance in object counting is unnecessary or even harmful when facing the noises in the density maps.</p><p>? A low-rank Gaussian convolution is proposed to handle the noises in density map generation. Equipped with low-rank approximation and translation invariance, we can favorably replace standard convolutions with several Gaussian kernels.</p><p>? Extensive experiments on seven datasets for three counting tasks (i.e. crowd, vehicle, plant counting) fully demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>We divide the literature into two directions as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Increase the spatial invariance with CNNs</head><p>Different from traditional manually designed counting detectors <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b46">47]</ref>, existing mainstream methods convert counting problems into density regression <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b75">76]</ref>. The main research direction is to improve the spatial invariance of CNNs. The mainstream technical routes include Multi-Column CNNs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b78">79]</ref>, Dilation CNNs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b71">72]</ref>, Deformable CNNs <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b33">34]</ref>, Residual CNNs <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b79">80]</ref>, Graph CNNs <ref type="bibr" target="#b37">[38]</ref>, Attention Mechanism <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b74">75]</ref>, Pyramid Pooling <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b50">51]</ref>, and Hierarchy/Hybrid Structures <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b51">52]</ref>. With the further optimization of parameters and structures, performance bottlenecks have appeared in these approaches, which makes us have to investigate the underlying reasons behind them.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, we briefly visualized the ideas of these methods. From the point of view of convolution, the accuracy can be improved by 1) relaxing the pixel-level spatial invariance (e.g., Dilation/ Deformable CNNs), 2) fusing more local features (e.g., Multi-Column CNNs and Spatial Pyramid Pooling), and 3) exploiting Attention/ Perspective information. Inspired by this, we utilize a set of low-rank Gaussian kernels with the attention mechanism to relax spatial invariance and fuse local features by replacing standard convolutions. Here we only offer one solution, and followup work can continue to explore how to properly relax the spatial invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dilated CNNs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Merge</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Column CNNs</head><p>Merge Offset </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deformable CNNs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dealing with noise in the density map</head><p>Similar to our findings, some studies have also shown notable label noise in density maps <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b76">77]</ref>. The mainstream approaches to overcome noise are to propose loss functions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b60">61]</ref>, optimize measurement metrics <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b54">55]</ref>, update matching rules <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b62">63]</ref>, finegrained noise regions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b55">56]</ref>, strengthen regular constraints <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71]</ref>, combine extra labels <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b81">82]</ref>, and optimize training processes <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b80">81]</ref>. Some recent studies have also started to use adversarial <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b83">84]</ref> and reinforcement learning <ref type="bibr" target="#b32">[33]</ref> to handle noise in the density learning.</p><p>In summary, these approaches do not reveal the correlation between the spatial invariance and the noise of density maps. Most of them only minimize noise by optimizing the loss or regularization term <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b69">70]</ref>. For example, a recent work called AutoScale <ref type="bibr" target="#b69">[70]</ref> attempts to normalize the densities of different image regions to within a reasonable range. Our work is inspired by previous work <ref type="bibr" target="#b59">[60]</ref>. Unlike it only focuses on optimizing the loss, our method attempts to modify the convolution operation to overcome noise during the feature learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>To better understand our method, we first briefly review the traditional density map generation to reveal the labeling noises of the object counting task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Traditional density map generation</head><p>The recent mainstream approach turns the object counting task into a density regression problem <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b64">65]</ref>. For N objects of image I, the center points of all objects are labeled as D 1 , ...,D i , ...D N . The Gaussian kernel can effectively overcome the singularity in the prediction process. Thus the density of any pixel in an image, ?p i ? I, is generated by multiple Gaussian kernels as,</p><formula xml:id="formula_0">y (p i ) = N i=1 N p i ;D i , ?I<label>(1)</label></formula><formula xml:id="formula_1">= N i=1 1 2?? exp(? 1 2 p i ?D i 2 ?I ),<label>(2)</label></formula><p>where N (D i , ?I) is the multivariate Gaussian kernel, the meanD i and the covariance ?I respectively depict the center point position and shape of the object. ? is the variance of the Gaussian kernel and x 2 ?I = x T (?I) ?1 x is the square Mahalanobis distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Noise in object counting task</head><p>However, similar to the previous work <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b76">77]</ref>, we found that there are naturally two kinds of unavoidable noises in density map as <ref type="figure">Figure 1</ref>.</p><p>1. The error between the true position of the object D i and the labeled center pointD i ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The error ? between object occlusion and overlapping of multiple Gaussian kernel approximation</head><formula xml:id="formula_2">N i=1 N (p i ;D i , ?I);</formula><p>Suppose the labeling error of the center point position is independent and identically distributed (i.i.d) and also obeys the Gaussian distribution. Similar to Eq. 1, the density map of any pixel ?p i ? I with the true center point Di =Di ? i can also be computed as,</p><formula xml:id="formula_3">y (p i ) = N i=1 N p i ;D i ? i , ?I (3) = N i=1 N (q i ; i , ?I) ,<label>(4)</label></formula><p>where we have made some equivalent changes to the equations. Further replacing p i with q i =D i ? p i , the density map is still as the combination of the Gaussian distribution N (?, ?). The values of mean ? and variance ? are respectively estimated as,</p><formula xml:id="formula_4">? ? E N i=1 N ( i, ?I) ? N i i,<label>(5)</label></formula><formula xml:id="formula_5">? ? N i=1 1 2?? N (0, ?I) ? N i=1 ? 2 i ,<label>(6)</label></formula><p>where ?, ?, ? are the variance parameters of the Gaussian function <ref type="bibr" target="#b2">3</ref> .  Although the updated density map still obeys a Gaussian distribution, according to Eq. 5 and 6, the mean ? (depicting the center point) and variance ? (representing shape and occlusion) have more complex forms. This mathematically sheds light on why strict pixel-level spatial invariance leads to severe overfitting label errors. As shown in Sec. 4.2, some state-of-the-art networks still fail to predict actual occlusion in high-density regions, and overestimate the density in low-density regions. Obviously, this is due to overfitting to noise, thereby completely ignoring the position and shape of objects. Below we will present our solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Low-rank Gaussian convolutional layer</head><p>Inspired by the previous works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>, we try to replace the standard convolution filters with Gaussian kernels (i.e., propose GauNet). In this way, the feature extraction can simulate the process of density map generation. After pixel-grid filters are replaced with Gaussian kernels, we can jump out of the strict pixel-level spatial constraints and learn the density map in a more relaxed spatial manner. The modified convolution is as,</p><formula xml:id="formula_6">Y s = N i=0 G(? i , ? i ) * X s + b s ,<label>(7)</label></formula><p>where * and b s are convolution operation and offsets. X s and Y are two-dimensional features. Here we only take the features of channel s as an example. Since we want to simulate the density map generation, all N Gaussian kernels G(? i , ? i ) have to be used for convolution. The position and shape of the objects are respectively stipulated by the mean ? i and the variation ? i .</p><p>However, Eq. 7 cannot be implemented because it requires massive Gaussian convolutions. Fortunately, previous work <ref type="bibr" target="#b59">[60]</ref> uses low-rank Gaussian distributions to approximate the density map. Inspired by this, we proposed a low-rank approximation module (Sec. 3.3.1) to achieve the approximation to Gaussian convolution, and accord-ingly equipped a translation invariance module (Sec. 3.3.2) to accelerate computation. As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, we will present these two modules below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Accelerate with Low-rank approximation</head><p>Low-rank approximation module uses a small number of Gaussian kernels with the low-rank connection to approximate an almost infinite Gaussian convolution (Eq. 7). It has been proven [60] that a density map generated by aggregating N Gaussian kernels (N can be hundreds to thousands 4 ) could be approximated by K Gaussian kernels</p><formula xml:id="formula_7">{G 1 (? 1 ), ..., G K (? K )}, where K N .</formula><p>Although previous work <ref type="bibr" target="#b59">[60]</ref> uses the low-rank approximation to optimize the density map in the loss function, it is still unclear how to approximate the massive Gaussian convolution.</p><p>To this end, we try to approximate the infinite Gaussian convolution by learning a few Gaussian kernels, as well as their correlations with an attention mechanism. During the approximation, a large number of Gaussian kernels are randomly sampled. After the Principal Component Analysis (PCA), the eigenvectors {G(? k )} K k=1 corresponding to K non-zero eigenvalues are obtained. Then we initialize the coefficients of picked K Gaussian kernels as,</p><formula xml:id="formula_8">w k = G(? k ), G(? I ) ,<label>(8)</label></formula><p>where &lt; . &gt; is the inner product, and ? I represents the identity matrix. Because we will further decompose the Gaussian kernel to speed up the computation, the mean ? of the Gaussian kernels is ignored here. Finally, we perform normalization operations,</p><formula xml:id="formula_9">?(w k ) = exp (w k ) K l=1 exp (w l ) ,<label>(9)</label></formula><p>where w k are also updated during training. In addition to fusing the local features, it can also help restrict the spatial information in the gradient back-propagation. <ref type="bibr" target="#b3">4</ref> N is the number of objects in image as shown in <ref type="table" target="#tab_1">Table 1</ref> Based on this improvement, the optimized Gaussian convolutional layer is computed as,</p><formula xml:id="formula_10">Y s = K j=0 (w j ? K i=0 (G(? i , ? j ) * X s )) + b s ,<label>(10)</label></formula><p>where ? is the entry-wise product. We utilize the low-rank Gaussian kernels to complete the approximation process. Following we will continue to apply the translation invariance module to further optimize our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Accelerate with translation invariance</head><p>Translation invariance module aims to decompose the convolution operation between the Gaussian kernel and the input feature map to accelerate the inference. Accomplishing convolution operations of all Gaussian kernels in Eq. 10 requires a lot of computational resources. Using the translation invariance of Gaussian kernels, the convolution operation between the Gaussian kernel and the input features can be efficiently implemented as,</p><formula xml:id="formula_11">G (? k , ? k ) * x = T ? k [G(0, ? k )] * x (11) = T ? k [G(0, ? k ) * x] ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_12">T ? k [y] = g(y ? ? k ) is the translation of the function g(). G(0, ? k )</formula><p>is Gaussian kernels with zero mean. The benefit of this is that we can ignore the mean of Gaussian kernels in the convolution operation. Since Eq. 12 is only accurate for discrete ? k , we treat the translation function g() as bilinear interpolation in the actual implementation,</p><formula xml:id="formula_13">T ? k [y] = i j a ij ? g(y ? ? k + i, j ),<label>(13)</label></formula><p>where a ij are the weights in bilinear interpolation, which allow computing subpixel displacements and can be implemented efficiently in CUDA. Finally, our proposed low-rank Gaussian convolutional layer can be computed as,</p><formula xml:id="formula_14">Y s = K k=0 (w k ? K j=0 (T ? k [G(? j ) * X s ]) + b s ,<label>(14)</label></formula><p>where all implementations are based on CUDA. Thus our proposed layer can be applied to mainstream CNNs. In most cases, we replace all the convolutional layers (or 3?3 convolutional layers in all residual and pyramid pooling blocks) with our Gaussian convolutional layers.  </p><formula xml:id="formula_15">O(KC i C o HW Kk w k h ),</formula><p>where K is the number of the sampled kernels, K N . By further applying translation invariance, the complexity of Eq. 14 is O(4KC i C o HW ), where 4 is related to the bilinear interpolation. <ref type="table" target="#tab_2">Table 2</ref> also shows experimental time cost of our method, which demonstrates the effectiveness of two acceleration components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment settings</head><p>Dataset. We evaluate our method on three application, i.e., crowd, vehicle, and plant counting. For crowd counting, five datasets are used for evaluation, including Shang-haiTech (SHTech) PartA and PartB <ref type="bibr" target="#b77">[78]</ref>, UCF CC 50 <ref type="bibr" target="#b21">[22]</ref>, UCF-QNRF <ref type="bibr" target="#b23">[24]</ref> and JHU-CROWD++ <ref type="bibr" target="#b49">[50]</ref>. For vehicle and plant counting, two datasets, i.e., TRANCOS <ref type="bibr" target="#b15">[16]</ref> and MTC <ref type="bibr" target="#b36">[37]</ref>) are used, respectively. <ref type="table" target="#tab_1">Table 1</ref> gives a summary of these datasets.</p><p>Baseline Networks. We evaluate our method by integrating it with four baselines including MCNN <ref type="bibr" target="#b78">[79]</ref>, CSR-Net <ref type="bibr" target="#b27">[28]</ref>, SANet <ref type="bibr" target="#b3">[4]</ref>, and ResNet-50 <ref type="bibr" target="#b17">[18]</ref>. The training procedures follow third-party Github repositories <ref type="bibr" target="#b4">5</ref> . Training details are slightly different from the original paper. For example, batch processing and other functions are included. Following previous works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b62">63]</ref>, MCNN and CSRNet are tested on the whole images, while SANet is evaluated on image patches. Additionally, Mean Absolute Error (MAE) and Mean Square Error (MSE) are used as evaluation measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Reveal the label noise of object counting</head><p>We verified the prediction variance on four mainstream object counting methods (i.e., MCNN <ref type="bibr" target="#b78">[79]</ref>, CSRNet <ref type="bibr" target="#b27">[28]</ref>, SANet <ref type="bibr" target="#b3">[4]</ref>, and ResNet-50 <ref type="bibr" target="#b17">[18]</ref>).</p><p>Large variance in prediction. As shown in <ref type="figure">Figure 5</ref>, four object counting methods have a large prediction variance on SHTech-PartA and UCF-QNRF datasets. Even more surprising is that the variance does not decrease as the performance (spatial invariance) increases. The results in <ref type="figure">Figure 5</ref> meaningfully reveal its hidden reason, namely that the overly strict pixel-level spatial invariance makes the model severely overfit to the density map noise.  Underestimation of high-density areas. We performed a similar validation for high-density regions to find out the reasons for the large prediction variance. In the second column of <ref type="figure">Figure 5</ref>, we noticed that the prediction variance in high-density areas is more severe than the entire image. The overall statistics prove that the model severely underestimates density in high-density areas. What is even more surprising is that this variance appears to increase as the performance (spatial invariance) increases.</p><p>Overestimated in low-density areas. Likewise, in the third column, we analyzed the low-density area. Overall, the variance is reduced compared to high-density areas. We speculate that fewer Gaussian kernels are in the lowdensity area, which inherently has lower annotation noise. Although the variance is slight than the high-density area, the overall variance is still more severe than the entire image. We guess this is because the high and low-density areas compensate for each other to reduce the variance.</p><p>Ignorance of position and shape. To further clarify the large prediction variance, we visualized some examples. <ref type="figure" target="#fig_3">Figure 4</ref> shows the obvious difference between the predicted density maps and the true position of the object (indicated by the red dot). In some low-density areas, the prediction results ignore many objects (i.e., the density map does not cover many red dots). Likewise, in some highdensity regions, the crowd is poorly estimated (that is, the clustering on the density map is inconsistent with the trend of the red dots). To sum up, these visualizations show that blindly improving spatial invariance does not learn the location and shape of objects.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation study</head><p>We perform ablation studies with our method. Due to space limitations, we only uses MCNN <ref type="bibr" target="#b78">[79]</ref> as an example.</p><p>Effectiveness of accelerated modules. We conduct ablation studies to verify the effectiveness of low-rank approximation and translation invariance modules. <ref type="table" target="#tab_2">Table 2</ref> shows the experimental time cost of our proposed layer. Compared with the original Gaussian convolution, our offered two acceleration modules can significantly improve the computational efficiency.</p><p>Where should it be replaced? As shown in <ref type="figure" target="#fig_5">Figure 6</ref>, we performed ablation studies on the three column convolutional structures of MCNN. Overall, the three column structures have roughly the same results. We noticed that replacing our layers in the first three convolutional layers will achieve larger improvements. We also got similar results in other baselines. Our method has fewer parameters than the original convolutional layer. Thus in most cases, we replace all the convolutional layers (or 3?3 convolutional layers in all residual blocks and pyramid pooling blocks) with our Gaussian convolutional layers.</p><p>How to set the Gaussian kernels? Our method has three hyperparameters, i.e., the mean ?, variance ?, and the number of Gaussian kernels K. The mean value can be instantly set according to the stride of the original convolutional layer. Thus we will only discuss variance ? and the number of K in the experiment. As shown in <ref type="figure">Figure 8</ref>, we have carried out studies on the three column structures of MCNN. When the value of K is <ref type="table">Table 3</ref>. Comparison with the state-of-the-art methods on SHTech-PartA <ref type="bibr" target="#b77">[78]</ref>, UCF CC 50 <ref type="bibr" target="#b21">[22]</ref>, UCF-QNRF <ref type="bibr" target="#b23">[24]</ref> and JHU-CROWD++ <ref type="bibr" target="#b49">[50]</ref> datasets. The best results are shown in bold. This also applies to the following tables.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Compare with state-of-the-art methods</head><p>We compared our method with state-of-the-art methods in three applications (crowd, vehicle, plant counting). Result of crowd counting. <ref type="table">Table 3</ref> shows the results of crowd counting in the free camera perspective. We took into account prediction variance and chose the average result for reporting. Except for MCNN, the other three modified baselines outperform other state-of-the-art methods. Compared to the original baselines, our variant has also achieved a huge improvement. The performance of the light MCNN is even close to some of the most advanced methods. <ref type="table" target="#tab_4">Table 4</ref> shows the results in the surveillance scenarios. Like free views, our model surpasses other state-of-the-art approaches, but the improvement in surveillance scenarios is not as much as free perspective. We guess there is more noise in generating density maps in the free view. Due to the noisy label in the groundtruth of SHTech-PartB, our method cannot further improve performance.</p><p>Result of object counting. We also evaluated vehicle and plant counting. <ref type="table" target="#tab_5">Table 5</ref> shows that our model works well for vehicle scenarios. The improvement is minor compared to the crowd counting because the vehicle scene holds less noise. For plant counting, we got similar results. Our model outperforms other state-of-the-art methods. Notable is the improvement in the MSE metric, which shows that our method is more robust. The overall performance is very close to the groundtruth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Robustness to annotation noise</head><p>We follow previous work <ref type="bibr" target="#b59">[60]</ref> to verify robustness to annotation noise. We generate a noisy dataset by randomly moving the annotation points by {4, 8, 16, 32} pixels. Then we train the model on noisy datasets with or without our proposed Gaussian convolutions. <ref type="table" target="#tab_6">Table 6</ref> shows the comparison. Though the performances of all methods decrease as the annotation noise increases, our method is still more robust than other methods. <ref type="figure" target="#fig_3">Figure 4</ref> also illustrates the predicted results of two examples with/without our method.</p><formula xml:id="formula_16">1e -5 1e -6 1e -6 1e -6 1e -4 1e -2 1e -1 1e -3 1e -3 1e -3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Visualization of convolution filters</head><p>We visualized the convolution filters to evaluate whether our model can simulate the density map generation and learn the spatial information of the objects. <ref type="figure">Figure 7</ref> shows the results after visualization. In general, our method can effectively learn the perspective law of the distribution of objects. The results in the plant counting (column 3) are particularly obvious due to the more consistent scenarios. Our method learns the planting distribution and even reflects the planting interval. In contrast, the original SANet <ref type="bibr" target="#b3">[4]</ref> only shows some noise in the image (e.g., marking Poles). Similarly, our method also learns the distribution of pedestrians and vehicles by counting pedestrians and vehicles under the surveillance viewing angle (columns 2 and 4). On the contrary, the original SANet blindly guesses high-density areas or overestimates low-density regions. We also found similar results under the free perspective (columns 1 and 5), where our method can approximate crowd density distribution in pedestrian streets and squares.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We reveal the relationship between spatial invariance and density map noise. Extensive experiments prove that if only instinctively improve the spatial invariance of CNNs, the model will easily overfit the density map noise. Inspired by this, we utilize a set of locally connected multivariate Gaussian kernels for replacing the convolution filters. Unlike the pixelized-based filter, our proposed variant can approximately simulate the process of density map generation. Considering the characteristics of object counting, we try to use translation invariance and low-rank approximation to improve efficiency. Extensive experiments show that our method outperforms other state-of-the-art methods. Our work points out the direction for future research. It can avoid wildly improving the spatial invariance for the object counting. In the future, we will further analyze the relationship between the Gaussian kernel and spatial invariance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary materials</head><p>In supplementary material, we introduce the network structures and training details of all baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation details</head><p>Let's first present the network architectures of all baselines to facilitate understanding of the details.</p><p>A.1. Network structure of baselines MCNN baseline. We modified the original MCNN <ref type="bibr" target="#b78">[79]</ref> network by replacing the convolution filters in the first to fourth layers with locally connected low-rank Gaussian kernels. As shown in Sec. 4.3, in the first two convolutional layers of three-column structures, each convolution filter is replaced with the equivalent 16 Gaussian kernels. The Gaussian kernel variance of each dimension is fixed in the range of [?0.5, 0.5] for sampling. Resembling the threecolumn convolution structure in the original MCNN (i.e., 3 ? 3, 5 ? 5, 7 ? 7 branches), we correspondingly implemented three convolution structures with different Gaussian kernel numbers (i.e., maximum, middle, smaller column). Specifically, the kernel number of the last two layers of the three branch structures (i.e., smaller, middle, and maximum) is set to 2, 4, and 6, respectively. At the end of the networks, we tallied a spatial pyramid pooling block to fuse the features of the three-column convolutional networks. The structure of the spatial pyramid pooling block is shown in <ref type="figure" target="#fig_1">Figure 3</ref>. Except for the first two convolutional layers, the variance of the remaining convolutional layer is fixed in the range of [?0.1, +0.1] for sampling. The number of low-rank Gaussian kernels in the spatial pyramid pooling module is 8. The mean of the Gaussian kernel is selected according to the four times the stride of the original convolutional network. Note that we also used the same settings in other baselines. So we will not discuss the mean of the Gaussian kernel later. CSRNet baseline. We retained the first ten convolutional layers of the VGG-16 <ref type="bibr" target="#b48">[49]</ref> backbone at the front end of CSRNet <ref type="bibr" target="#b27">[28]</ref> network, and only modified the subsequent four dilated convolution branch structures. The kernel number of the original A, B, C, and D branches are set to 2, 4, 6, and 8, respectively. Note that the variance of every convolutional layer is fixed in the range of [?0.1, +0.1] for sampling. Unlike the original CSRNet, after comparing the performance of all branch structures, only the B branch with the stride length of 2 was selected. We applied a spatial pyramid pooling block on top of CSRNet to fuse the convolutional features of the four branches. Similar to MCNN baseline, the number of low-rank Gaussian kernels in the spatial pyramid pooling module is also set as 8. According to the results of the ablation study on MCNN, since our modified layers are located at the back end of the original VGG-16 network, we did not use a large kernel number here. In addition, our ablation experiment in CSRNet also proved the branch with the kernel number of 4 achieves the best results. SANet baseline. We modified the first four-block convolutional layers in the original SANet <ref type="bibr" target="#b3">[4]</ref> network, and retained the deconvolutional layer at the end of the network. The kernel number in the first two layers of the convolutional network is set to 16. While kernel number of the 1 ? 1, 3 ? 3, 5 ? 5 and 7 ? 7 convolution kernels in the latter two layers are set to 8, 6, 4, and 2, respectively. Particularly, the range of the single dimension of the Gaussian kernel in the first two convolutional layers is [?0.5, +0.5], while the range of the latter two layers is [?0.1, +0.1]. ResNet-50 baseline. C 3 framework <ref type="bibr" target="#b14">[15]</ref> modified the original ResNet-50 <ref type="bibr" target="#b17">[18]</ref> network and applied it to the crowd counting task. Here we also used a similar setting. We retain the first convolutional layer in the original ResNet-50 network. Then we replace the 3 ? 3 convolution filters in all residual blocks with locally connected low-rank Gaussian kernels. The kernel number in all replacements is set to 4. Because of technical limitations, we correspondingly keep the 7 ? 7 filter in the first convolution layer and 1 ? 1 filters in the bottleneck layers. To preserve the scale of the final density maps, we change the stride of the 3rd convolutional layer from 2 to 1 as the encoder, and the decoder is composed of two convolutional layers. We also implemented down-sampling with max-pooling instead of using convolutions with a stride of 4. The value range of the single dimension of the Gaussian kernel in all replacements is [?0.1, +0.1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Data preprocessing and training details</head><p>Following understanding the network structure, let's introduce the details of data processing and training. Data preprocessing. We carried out the preprocessing of input size and label transformation on all seven object counting datasets. Specifically, we follow the setting of C 3 Framework [15] 6 to preprocess the SHTech-PartA <ref type="bibr" target="#b77">[78]</ref> and PatB <ref type="bibr" target="#b77">[78]</ref>, UCF-QNRF <ref type="bibr" target="#b23">[24]</ref> datasets in the crowd counting. Meanwhile, the preprocessing steps of the remaining datasets are set according to the code repositories released by <ref type="bibr" target="#b61">[62]</ref> to facilitate performance comparison. Training details. In addition to modifying some convolutional layers, the loss function and optimization process are set according to the original baseline. Typically, we utilize the same training settings as the C 3 framework <ref type="bibr" target="#b14">[15]</ref> and the previous work <ref type="bibr" target="#b61">[62]</ref>. Different from the original MCNN, CSRNet, and SANet implementations, we use the Batchsize training technique proposed by the C 3 framework to accelerate the training. For MCNN and SANet baselines, except for the modified convolutional layer, the parameters of other parts are randomly initialized by a Gaussian dis-tribution with a mean of 0 and standard deviation of 0.01. Adam optimizer <ref type="bibr" target="#b25">[26]</ref> with a learning rate of 1e?5 is used to train the model. For CSRNet, the first ten convolutional layers are from pre-trained VGG-16. The other layers are initialized in the same way as MCNN. Stochastic gradient descent (SGD) with a fixed learning rate of 1e?6 is applied during the training. The revised ResNet-50 baselines are trained by stochastic gradient descent first. Specifically, we employ the original ResNet-50 hyperparameters to pre-train on the ImageNet dataset, i.e., the learning rate of 0.1, the momentum of 0.9, weight decay of 1e?4, and a batch size of 256. Learning rate is reduced four times by a factor of 10 at the 30th, 60th, 80th, and 90th epoch. For the fine-tuning of ResNet-50, we adopt the same settings as the third-party code library C 3 Framework, i.e., the learning rate of 1e?4, weight decay is 0.995, and the learning rate is reduced layer by layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. More experimental results</head><p>In this section, we present more experiments to reveal the problem of the object counting task and prove the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. More ablation studies</head><p>The settings discovered in the ablation study on MCNN were directly applied to other baselines. In addition, we also explore the setting of Gaussian kernel K in all baselines. In CSRNet, because we continue to use the first ten convolutional layers of the VGG-16 network, we can only apply our method at the back end of the original network. The experimental results show that the branch structure with the K value of 4 achieved the best results. However, the performance is still improved after the fusion of the entire four branch structures. Therefore, we merge all four branches at the back end of CSRNet network, and set the K value as 2 to 32 in each column structure. We also verified the K value in the residual block, and noticed that when the K value is 4, the efficiency and performance have achieved the best balance. In the spatial pyramid pooling of MCNN and SANet, we observed that the performance would increase and decrease as the K value increased. We guess that this is caused by overfitting when the value of K is too large. Therefore, the K value in the spatial pyramid pooling layer is set as 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Reveal the problem of object counting</head><p>As shown in Sec. 4.2, we illustrate more results in the supplementary material. Here we test the performance of the different models that converge after randomly loading training data with the same hyperparameters. To ensure the validity of the results, we repeated the training 20 times in each baseline model. <ref type="figure" target="#fig_0">Figures A1 and A2</ref> are the experimental results. The variance we are discussing here refers to the prediction error of the trained model on the same image. In other words, the variance shows that the model cannot converge stably. Correspondingly, the error refers to the difference between the predicted result and the ground truth.</p><p>In general, we reach the same conclusions as in Sec. 4.2. We distinguish high-density and low-density areas in SHTech ParA <ref type="bibr" target="#b77">[78]</ref>, UCF-QNRF <ref type="bibr" target="#b23">[24]</ref>, and JHU-CROWD++ <ref type="bibr" target="#b49">[50]</ref> to further analyze the results. In these datasets, there are clear differences between high-density and low-density regions. In general, the prediction variance of the original baseline is about a quarter of the total error. This variance does not decrease as model performance (i.e. spatial invariance) increases.</p><p>In addition, we analyzed the full images in SHTech ParB <ref type="bibr" target="#b5">[6]</ref>, TRANCOS <ref type="bibr" target="#b15">[16]</ref>, MTC <ref type="bibr" target="#b36">[37]</ref> and UCF CC 50 <ref type="bibr" target="#b21">[22]</ref> dataset. We no longer distinguish between high-density and low-density areas, because these datasets are relatively in low-density or high-density scenarios. In general, we found that even in absolute low-density and high-density data sets, the model's prediction error is still very large.</p><p>We also analyzed the prediction variance of our modified baselines in <ref type="figure" target="#fig_0">Figures A1 and A2</ref>. We found that our modified method significantly reduced the variance in the prediction results compared to the original network.  <ref type="figure">Figure A1</ref>. Comparative analysis of the variance and error of the prediction results. The variance here refers to the difference in the prediction results for the same image at different convergence states. The error refers to the difference between the prediction and the ground truth. From left to right are the analysis results of the full image, high-density area, low-density area, and our modified baselines. The results clearly show that there is a huge variance in prediction results. [It is best to view in color and zoom in].</p><p>(a) Comparative analysis of prediction variance and error on SHTech ParB <ref type="bibr" target="#b77">[78]</ref>, TRANCOS <ref type="bibr" target="#b15">[16]</ref>, MTC <ref type="bibr" target="#b36">[37]</ref>, and UCF CC 50 <ref type="bibr" target="#b21">[22]</ref> datasets. Note that here are results on the MAE measurement.</p><p>(b) Comparative analysis of prediction variance and error on SHTech ParB <ref type="bibr" target="#b77">[78]</ref>, TRANCOS <ref type="bibr" target="#b15">[16]</ref>, MTC <ref type="bibr" target="#b36">[37]</ref>, and UCF CC 50 <ref type="bibr" target="#b21">[22]</ref> datasets. Note that here are results on the MSE measurement. <ref type="figure" target="#fig_0">Figure A2</ref>. The variance here refers to the difference in the prediction results for the same image at different convergence states. The error refers to the difference between the prediction and the ground truth. From left to right are the analysis results on SHTech ParB, TRANCOS, MTC, and UCF CC 50 datasets. The results clearly show that there is a huge variance in prediction results. [It is best to view in color and zoom in].</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Overview of research directions of CNNs in object counting. 1) Dilated CNNs gradually increase the strides of convolution filters to adapt to different sizes. 2) Multi-Column CNNs utilize different filters to merge features in different branches. 3) Deformable CNNs optimize the shape of filters to handle multi-scale densities. 4) Spatial pyramid pooling performs pyramid scaling on input features. 5) Attention/perspective uses perspective/attention maps through feature extraction. [Best viewed in color].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of Low-rank Gaussian convolutional layer. Our proposed layer mainly contains two acceleration modules. Lowrank approximation module has two steps: 1-Principal Component Analysis (PCA) is used to select the Gaussian kernels, 2-Inner product and softmax are used to get the fusion weights. Translation Invariance module also splits the Gaussian kernel operation into two steps: 1-Convolution with Gaussian kernels of zero means, 2-Translation result with other unique means. Our proposed layer can replace any standard convolutional layer, where the right part is two application examples of residual blocks and pyramid pooling. [Best view in color].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Complexity analysis. Theoretically, considering input X = [H, W, C i ] and output Y = [H, W, C o ], supposing N Gaussian kernels are used in density map generation, the complexity of the initial Gaussian convolution (Eq. 7) is O(C i C o HW N k w k h ), where k w , k h indicate the upper bound of the size of Gaussian kernels. When utilizing low-rank approximation, the complexity of Eq. 10 is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of robustness to annotation noise, where red dots are groundtruth annotations. Here we generate the noisy dataset by randomly moving the annotation points by {0, 8, 16, 32} pixels. Visualization results exhibit the results of two examples with/without our proposed Gaussian convolutional layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 . 4 MAE 4 MSE</head><label>544</label><figDesc>Comparative analysis of the prediction variance. The variance refers to the difference in the results at different convergence states. The error refers to the difference between the prediction and groundtruth. Left to right are the analysis results of the full image, high-density area, and low-density area. The results clearly show that there is a huge variance in prediction results.V -1 C O N V -1 -2 C O N V -1 -3 C O N V -1 -V -1 C O N V -1 -2 C O N V -1 -3 C O N V -1 -</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>The ablation study of MCNN<ref type="bibr" target="#b78">[79]</ref>. The numbers after CONV indicate the range of usage of our GauNet layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>The visualization of the convolution filters. From left to right are the results from SHTech-PartA, SHTech-PartB, MTC, TRAN-COS and UCF-QNRF. From top to bottom are example images, our revised SANet and the original SANet<ref type="bibr" target="#b3">[4]</ref>. Intuitively, our approach can fully understand the spatial information of objects and the perspective law of views. More details are shown in Sec. 4.6. Ablation study on MCNN<ref type="bibr" target="#b78">[79]</ref>. From left to right are the variance optimization changes in the 1-st to 4-th convolutional layers. The abscissa indicates the range of change, and the ordinate indicates the intensity of the change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Acknowledgements.</head><label></label><figDesc>This work was partially supported by the Air Force Research Laboratory under agreement number FA8750-19-2-0200; the financial assistance award 60NANB17D156 from U.S. Department of Commerce, National Institute of Standards and Technology (NIST); the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract number D17PC00340; the Defense Advanced Research Projects Agency (DARPA) grant funded under the GAILA program (award HR00111990063). The U.S. Government is authorized to reproduce and distribute reprints forGovernmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Air Force Research Laboratory or the U.S. Government.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) Comparative analysis of prediction variance and error on SHTech ParA<ref type="bibr" target="#b77">[78]</ref> dataset.(b) Comparative analysis of prediction variance and error on UCF-QNRF<ref type="bibr" target="#b23">[24]</ref> dataset.(c) Comparative analysis of prediction variance and error on JHU-CROWD++<ref type="bibr" target="#b23">[24]</ref> dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Object counting benchmarks. [Min, Max] and #images are the range of objects per image and the number of images.</figDesc><table><row><cell></cell><cell>Datasets</cell><cell cols="2">[Min, Max] #Images</cell></row><row><cell></cell><cell>SHTech-PartA [78]</cell><cell>[33, 3,139]</cell><cell>482</cell></row><row><cell></cell><cell>UCF CC 50 [22]</cell><cell>[94, 4,543]</cell><cell>50</cell></row><row><cell>Crowd</cell><cell>UCF-QNRF [24]</cell><cell>[49, 12,865]</cell><cell>1,525</cell></row><row><cell></cell><cell>JHU-CROWD++ [50]</cell><cell>[0, 7,286]</cell><cell>4,250</cell></row><row><cell></cell><cell>SHTech-PartB [78]</cell><cell>[9, 578]</cell><cell>716</cell></row><row><cell cols="2">Vehicle TRANCOS [16]</cell><cell>[9, 107]</cell><cell>1,244</cell></row><row><cell>Plant</cell><cell>MTC [37]</cell><cell>[0, 100]</cell><cell>361</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Time (milliseconds) Vanilla</cell><cell cols="2">LRA LRA+TI</cell></row><row><cell>Forward</cell><cell>51.3</cell><cell>13.3</cell><cell>4.1</cell></row><row><cell>Backward</cell><cell>160.0</cell><cell>44.1</cell><cell>12.6</cell></row></table><note>Cost on MCNN (batchsize 1, image size 256 2 ). LRA and TI refer to Low-Rank Approximation and Translation Invari- ance. The Vanilla setting uses 256 Gaussian kernels per layer.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Results on SHTech-PartB [78] dataset.</figDesc><table><row><cell>Methods</cell><cell>Venue</cell><cell cols="2">SHTech-PartB MAE MSE</cell></row><row><cell>ADSCNet [3]</cell><cell>CVPR'20</cell><cell>6.4</cell><cell>11.3</cell></row><row><cell>AMSNet [20]</cell><cell>ECCV'20</cell><cell>6.7</cell><cell>10.2</cell></row><row><cell>DM-Count [63]</cell><cell>NeurIPS'20</cell><cell>7.4</cell><cell>11.8</cell></row><row><cell>GLoss [61]</cell><cell>CVPR'21</cell><cell>7.3</cell><cell>11.7</cell></row><row><cell>URC [71]</cell><cell>ICCV'21</cell><cell>12.0</cell><cell>18.7</cell></row><row><cell>MCNN [79]</cell><cell>CVPR'16</cell><cell>26.4</cell><cell>41.3</cell></row><row><cell>CSRNet [28]</cell><cell>CVPR'18</cell><cell>10.6</cell><cell>16.0</cell></row><row><cell>SANet [4]</cell><cell>ECCV'18</cell><cell>8.4</cell><cell>13.2</cell></row><row><cell>GauNet (MCNN)</cell><cell>Ours</cell><cell>17.6</cell><cell>24.7</cell></row><row><cell>GauNet (CSRNet)</cell><cell>Ours</cell><cell>7.6</cell><cell>12.7</cell></row><row><cell>GauNet (SANet)</cell><cell>Ours</cell><cell>7.1</cell><cell>11.2</cell></row><row><cell cols="2">GauNet (ResNet-50) Ours</cell><cell>6.2</cell><cell>9.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Results on TRANCOS<ref type="bibr" target="#b15">[16]</ref> and MTC<ref type="bibr" target="#b36">[37]</ref> dataset. = 100), we estimate the change of Gaussian kernel variance in each convolution layer. We observe that the variance merely changed in the first convolutional layer. Inspired by this, we usually set K to 16 with variance from [?0.5, 0.5] in the first two convolutional layers, and set K to 2 or 4 in the successive convolutional layers with variance from [?0.1, 0.1]).</figDesc><table><row><cell>Methods</cell><cell cols="4">TRANCOS MAE MSE MAE MSE MTC</cell></row><row><cell>ADMG [59]</cell><cell>2.6</cell><cell>3.89</cell><cell>-</cell><cell>-</cell></row><row><cell>TasselNetv2 [68]</cell><cell>-</cell><cell>-</cell><cell>5.4</cell><cell>8.8</cell></row><row><cell>S-DCNet [69]</cell><cell>-</cell><cell>-</cell><cell>5.6</cell><cell>9.1</cell></row><row><cell>CSRNet [28]</cell><cell>3.56</cell><cell>-</cell><cell>9.4</cell><cell>14.4</cell></row><row><cell>GauNet (CSRNet)</cell><cell>2.2</cell><cell>2.6</cell><cell>3.2</cell><cell>4.6</cell></row><row><cell>GauNet (MCNN)</cell><cell>7.7</cell><cell>7.4</cell><cell>8.7</cell><cell>12.3</cell></row><row><cell>GauNet (SANet)</cell><cell>2.5</cell><cell>2.8</cell><cell>3.4</cell><cell>4.5</cell></row><row><cell>GauNet (ResNet-50)</cell><cell>2.1</cell><cell>2.6</cell><cell>3.1</cell><cell>4.3</cell></row><row><cell>large enough (K</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Robustness to annotation noise. Both [60] and CSRNet adopt VGG backbone. Results of VGG are from Figure 4 of [60].</figDesc><table><row><cell>MAE (?)</cell><cell>0</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell></row><row><cell>CSRNet (w/o)</cell><cell cols="2">119.2 125.4</cell><cell>133.7</cell><cell>142.5</cell><cell>166.2</cell></row><row><cell>VGG [60]</cell><cell>85.8</cell><cell>91.0</cell><cell>96.0</cell><cell>97.0</cell><cell>99.0</cell></row><row><cell>CSRNet (ours)</cell><cell>84.2</cell><cell>85.7</cell><cell>89.0</cell><cell>92.2</cell><cell>95.4</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that we have some abuse symbols here.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We simply reformulate the parameter by ? = 2? to make a concise expression. The derivation is similar to the previous work<ref type="bibr" target="#b59">[60]</ref>, but here the Gaussian distribution is two-dimensional.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/gjy3035/C-3-Framework</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://github.com/gjy3035/C-3-Framework</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Localization in the crowd with topological constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahira</forename><surname>Abousamra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interactive object counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Arteta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="504" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive dilated network with self-correction supervision for counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanzhe</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4594" to="4603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scale aggregation network for accurate and efficient crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Privacy preserving crowd monitoring: Counting people without people models or tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Antoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang-Sheng John</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From semi-supervised to transfer counting of crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Chen Change Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Variational attention: Propagating domain-specific knowledge for multi-domain learning in crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16065" to="16075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cumulative attribute space for age and crowd density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2467" to="2474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scale pyramid network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanrui</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning spatial awareness to improve crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="6152" to="6161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving the learning of multi-column convolutional neural network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1897" to="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An aggregated multicolumn dilated convolution network for perspective-free counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diptodip</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ventura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="195" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Sofa-net: Second-order and first-order attention network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shidong</forename><surname>Haoran Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Revisiting spatial invariance with lowrank local connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamaleldin</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">C 3 framework: An open-source pytorch code for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Extremely overlapping vehicle counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Guerrero-G?mez-Olmedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Torre-Jim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>L?pez-Sastre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saturnino</forename><surname>Maldonado-Basc?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Onoro-Rubio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPRIA</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dadnet: Dilated-attention-deformable convnet for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1823" to="1832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simultaneously optimizing weight and quantizer of ternary neural network using truncated gaussian approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhezhi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deliang</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nascount: Counting-by-density with neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuhui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stacked pooling for boosting scale invariance of crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2578" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-source multi-scale counting in extremely dense crowd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haroon</forename><surname>Idrees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imran</forename><surname>Saleemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cody</forename><surname>Seibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Composition loss for counting, density map estimation and localization in dense crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haroon</forename><surname>Idrees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhmmad</forename><surname>Tayyab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishan</forename><surname>Athrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somaya</forename><surname>Al-Maadeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="532" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Composition loss for counting, density map estimation and localization in dense crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haroon</forename><surname>Idrees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhmmad</forename><surname>Tayyab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishan</forename><surname>Athrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somaya</forename><surname>Al-Maadeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention scaling for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4706" to="4715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to count objects in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Csrnet: Dilated convolutional neural networks for understanding the highly congested scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Density map regression guided detection network for rgb-d crowd counting and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1821" to="1830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Direct measure matching for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bayesian model adaptation for crowd counts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4175" to="4183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cross-modal collaborative representation learning and a large-scale rgbt benchmark for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingbo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hefeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weighing counts: Sequential crowd counting by reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haipeng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="164" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adcrowdnet: An attention-injective deformable convolutional network for crowd understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hefeng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3225" to="3234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Exploiting sample correlation for crowd counting with multi-expert network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weigang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3215" to="3224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive mixture regression network with local counting map for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenrui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tasselnet: counting maize tassels in the wild via local counts regression network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant methods</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hybrid graph neural networks for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangchen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11693" to="11700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spatiotemporal dilated convolution with uncertain matching for video-based crowd estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Han</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Huang</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Crossing the line: Crowd counting by integer programming with local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2539" to="2546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Towards a universal model for cross-dataset crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3205" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bayesian loss for crowd count estimation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6142" to="6151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Resnetcrowd: A residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Marsden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel E O&amp;apos;</forename><surname>Connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVSS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Shallow feature based dense attention network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Crowd counting with decomposed uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peder</forename><surname>Min-Hwan Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthikeyan Natesan</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ramamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11799" to="11806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dense crowd counting convolutional neural networks with minimal data using semi-supervised dual-goal generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Olmschenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Density-aware person detection and tracking in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Yves</forename><surname>Audibert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2423" to="2430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Wisdom of (binned) crowds: A bayesian stratification paradigm for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sravya Vardhani Shivapuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divij</forename><surname>Mansi Pradeep Khamkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi Kiran</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarvadevabhatla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3574" to="3582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Jhu-crowd++: Large-scale crowd counting dataset and a benchmark method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwanath</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Yasarla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Generating highquality crowd density maps using contextual pyramid cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Ha-ccn: Hierarchical attention-based crowd counting network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="335" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Inverse attention guided deep crowd counting network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVSS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning to count in the crowd from limited labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><forename type="middle">Sam</forename><surname>Yasarla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatesh Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rethinking counting and localization in crowds: A purely point-based framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengkai</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3365" to="3374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">To choose or to fuse? scale selection for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2576" to="2583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Kernel transformer networks for compact spherical convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chuan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Spatially-adaptive filter units for compact and efficient deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domen</forename><surname>Tabernik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ale?</forename><surname>Leonardis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Adaptive density map generation for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1130" to="1139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Modeling noisy annotations for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A generalized loss function for crowd counting and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Kernelbased density map generation for dense object counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingzhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Distribution matching for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huidong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Hoai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deep people counting in extremely dense crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1299" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning from synthetic data for crowd counting in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8198" to="8207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Neuron linear transformation: Modeling the domain shift for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Towards adversarial patch analysis and certified defense against crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhikang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<idno>arXiv, 2021. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Tasselnetv2: in-field counting of wheat spikes with context-augmented local regression networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haipeng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Madec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">From open set to closed set: Counting objects by spatial divide-and-conquer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haipeng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8362" to="8371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingkang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<title level="m">Autoscale: learning to scale for crowd counting. arXiv</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">1912</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Crowd counting with partial annotations in an image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Crowd counting via perspective-guided fractional-dilation convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMM</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Embedding perspective analysis into multicolumn convolutional neural network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1395" to="1407" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Relational attention network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6788" to="6797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Attentional neural fields for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5714" to="5723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cross-scene crowd counting via deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="833" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Cross-view crossscene multi-view crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="557" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Single-image crowd counting via multi-column convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Single-image crowd counting via multi-column convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Cascaded residual density network for crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchuan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2199" to="2203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Active crowd counting with limited supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miaojing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Zhiwen Fang, Zhe Xiao, and Hongyuan Zhu. Locality-aware crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Jiawei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Adversarial learning for multiscale crowd counting under complex scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongru</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun-Yuan</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Cybern</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Coarse to fine: Domain adaptive crowd counting via adversarial scoring network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhikang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoye</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangjie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2185" to="2194" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
