<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
							<email>xinyu.gong@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">the University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
							<email>wuyang.chen@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">the University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
							<email>tianlong.chen@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">the University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">the University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present Sandwich Batch Normalization (SaBN), a frustratingly easy improvement of Batch Normalization (BN) with only a few lines of code changes. SaBN is motivated by addressing the inherent feature distribution heterogeneity that one can be identified in many tasks, which can arise from data heterogeneity (multiple input domains) or model heterogeneity (dynamic architectures, model conditioning, etc.). Our SaBN factorizes the BN affine layer into one shared sandwich affine layer, cascaded by several parallel independent affine layers. Concrete analysis reveals that, during optimization, SaBN promotes balanced gradient norms while still preserving diverse gradient directions -a property that many application tasks seem to favor. We demonstrate the prevailing effectiveness of SaBN as a drop-in replacement in four tasks: conditional image generation, neural architecture search (NAS), adversarial training, and arbitrary style transfer. Leveraging SaBN immediately achieves better Inception Score and FID on CIFAR-10 and ImageNet conditional image generation with three state-of-the-art GANs; boosts the performance of a state-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201; substantially improves the robust and standard accuracies for adversarial defense; and produces superior arbitrary stylized results. We also provide visualizations and analysis to help understand why SaBN works. Codes are available at: https://github.com/VITA-Group/ Sandwich-Batch-Normalization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper presents a simple, light-weight, and easy-toimplement modification of Batch Normalization (BN) <ref type="bibr" target="#b29">[30]</ref>, motivated by various observations <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref> drawn from several applications, that BN has troubles standardizing hidden features with a heterogeneous, multi-modal distribution. We call this phenomenon feature distribution heterogeneity. Such heterogeneity of hidden features could arise from multiple causes, often application-dependent:</p><p>? One straightforward cause is the input data heterogeneity. For example, when training a deep network on a diverse set of visual domains, that possess significantly different statistics, BN is found to be ineffective in normalizing the activations with only a single mean and variance <ref type="bibr" target="#b12">[13]</ref>, and often needs to be re-set or adapted <ref type="bibr" target="#b39">[40]</ref>.</p><p>? Another intrinsic cause could arise from the model heterogeneity, i.e., when the training is, or could be equivalently viewed as, on a set of different models. For instance, in neural architecture search (NAS) using weight sharing <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b16">17]</ref>, training the supernet during the search phase could be considered as training a large set of sub-models (with many overlapped weights) simultaneously. As another example, for conditional image generation <ref type="bibr" target="#b46">[47]</ref>, the generative model could be treated as a set of category-specific sub-models packed together, one of which would be "activated" by the conditional input each time.</p><p>The vanilla BN <ref type="figure" target="#fig_0">(Figure 1</ref> (a)) fails to perform well when there is data or model heterogeneity. Recent trends split the affine layer into multiple ones and leverage input signals to modulate or select among them <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>  <ref type="figure" target="#fig_0">(Figure 1 (b)</ref>); or even utilize several independent BNs to address such disparity <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b66">67]</ref>. While those relaxations alleviate the data or model heterogeneity, we suggest that they might be "too loose" in the normalization or regularization effects. Let us take the conditional image generation task of GANs as a concrete motivating example to illustrate our rationale. A GAN model is trained with an image dataset containing various image classes, tending to capture the distribution of real samples to produce similar image examples. As a helpful remedy for the generator to encode class-specific information, Categorical Conditional Batch Normalization (CCBN), is widely used in the conditional image generation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref>. It is composed of a normalization layer and a number of following separate affine layers for different image classes, which allows class-specific information to be encoded separately, thus enables the gen-erator to generate more vivid examples.</p><p>But what might be missing? Unfortunately, using separate affines ignores one important fact that different image classes, while being different, are not totally independent. Considering that images from the same dataset share some common characteristic (e.g., the object-centric bias for CI-FAR images), it is convincing to hypothesize the different classes to be largely overlapped at least (i.e., they still share some hidden features despite the different statistics). To put it simply: while it is oversimplified to normalize the different classes as "the same one", it is also unfair and unnecessary to treat them as "totally disparate".</p><p>More application examples can be found that all share this important structural feature prior. <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b66">67]</ref> train a large variety of child models, constituting model heterogeneity; but most child architectures inevitably have many weights in common since they are sampled from the same supernet. Similarly, in adversarial training, the model is trained by a mixture of the original training set ("clean examples") and its attacked counterpart with some small perturbations applied ("adversarial examples"). But the clean examples and adversarial examples could be largely overlapped, considering that all adversarial images are generated by perturbing clean counterparts only minimally.</p><p>Our Contributions: Recognizing the need to address feature normalization with "harmony in diversity", we propose a new SaBN as illustrated in <ref type="figure" target="#fig_0">Fig 1 (c)</ref>. SaBN modifies BN in an embarrassingly simple way: it is equipped with two cascaded affine layers: a shared unconditional sandwich affine layer, followed by a set of independent affine layers that can be conditioned. Compared to CCBN, the new sandwich affine layer is designed to inject an inductive bias, that all re-scaling transformations will have a shared factor, indicating the commodity.</p><p>We then dive into a detailed analysis of why SaBN shows to be effective, and illustrate that during optimization, SaBN promotes balanced gradient norms (leading to more fair learning paces among heterogeneous classes and features), while still preserving diverse gradient directions (leading to each class leaning towards discriminative feature clusters): a favorable inductive bias by many applications.</p><p>Experiments on the applications of conditional image generation and NAS demonstrate that SaBN addresses the model heterogeneity issue elegantly, improving generation quality in GAN and the search performance in NAS in a plug-and-play fashion. To better address the data heterogeneity altogether, SaBN could further integrate the idea of split/auxiliary BNs <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b66">67]</ref>, to decompose the normalization layer into multiple parallel ones. That yields the new variant called SaAuxBN, demonstrated by the example of adversarial training. Lastly, we extend the idea of SaBN to Adaptive Instance Normalization (AdaIN) <ref type="bibr" target="#b27">[28]</ref> and show the resulting SaAdaIN to improve arbitrary style transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Normalization in Deep Learning</head><p>Batch Normalization (BN) <ref type="bibr" target="#b29">[30]</ref> made critical contributions to training deep convolutional networks and nowadays becomes a cornerstone of the latter for numerous tasks. BN normalizes the input mini-batch of samples by the mean and variance, and then re-scales them with learnable affine parameters. The success of BNs was initially attributed to overcoming internal covariate shift <ref type="bibr" target="#b29">[30]</ref>, but later on raises many open discussions on its effect of improving landscape smoothness <ref type="bibr" target="#b54">[55]</ref>; enabling larger learning rates <ref type="bibr" target="#b3">[4]</ref> and reducing gradient sensitivity <ref type="bibr" target="#b1">[2]</ref>; preserving the rank of preactivation weight matrices <ref type="bibr" target="#b10">[11]</ref>; decoupling feature length and direction <ref type="bibr" target="#b34">[35]</ref>; capturing domain-specific artifacts <ref type="bibr" target="#b39">[40]</ref>; reducing BN's dependency on batch size <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b55">56]</ref>; preventing elimination singularities <ref type="bibr" target="#b52">[53]</ref>; and even characterizing an important portion of network expressivity <ref type="bibr" target="#b19">[20]</ref>.</p><p>Inspired by BN, a number of task-specific modifications exploit different normalization axes, such as Instance Normalization (IN) <ref type="bibr" target="#b56">[57]</ref> for style transfer; Layer Normalization (LN) <ref type="bibr" target="#b2">[3]</ref> for recurrent networks; Group Normalization (GN) <ref type="bibr" target="#b59">[60]</ref> for tackling small batch sizes; StochNorm <ref type="bibr" target="#b35">[36]</ref> for fine-tuning; Passport-aware Normalization <ref type="bibr" target="#b71">[72]</ref> for model IP protection; and <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b72">73]</ref> for image generation.</p><p>Several normalization variants have been proposed by modulating BN parameters, mostly the affine layer (mean and variance), to improve the controlling flexibility for more sophisticated usages. For example, Harm et al. <ref type="bibr" target="#b11">[12]</ref> presented Conditional BN, whose affine parameters are generated as a function of the input. Similarly, Conditional IN <ref type="bibr" target="#b18">[19]</ref> assigned each style with independent IN affine parameters. In <ref type="bibr" target="#b46">[47]</ref>, the authors developed Categorical Conditional BN for conditional GAN image generation, where each generated class has its independent affine parameters. Huang &amp; Belongie <ref type="bibr" target="#b27">[28]</ref> presented Adaptive IN (AdaIN), which used the mean and variance of style image to replace the original affine parameter, achieving arbitrary style transfer. Spatial adaptivity <ref type="bibr" target="#b50">[51]</ref> and channel attention <ref type="bibr" target="#b38">[39]</ref> managed to modulate BN with higher complexities.</p><p>A few latest works investigate to use multiple normalization layers instead of one in BN. <ref type="bibr" target="#b12">[13]</ref> developed mode normalization by employing a mixture-of-experts to separate incoming data into several modes and separately normalizing each mode. <ref type="bibr" target="#b68">[69]</ref> used two separate BNs to address the domain shift between labeled and unlabeled data in semisupervised learning. Very recently, <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b60">61]</ref> revealed the two-domain issue in adversarial training and find improvements by using two separate BNs (AuxBN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Brief Backgrounds for Related Applications</head><p>We use four important applications as testbeds. All of them appear to be oversimplified by using the vanilla BN, where the feature homogeneity and heterogeneity are not properly handled. We briefly introduce them below, and will concretely illustrate where the heterogeneity comes from and how our methods deal with it in Sec. 3.</p><formula xml:id="formula_0">Normalization Affine Normalization Af'ine ! . . . Af'ine " Feature map Feature map Conditional information (a) Batch Norm (b) Categorical Conditional Batch Norm Sandwich Affine Af'ine ! . . . Af'ine " Feature map (c) Sandwich Batch Norm Normalization Conditional information</formula><p>Generative Adversarial Network GAN has been prevailing since its origin <ref type="bibr" target="#b22">[23]</ref> for image generation. Many efforts have been made to improve GANs, such as modifying loss function <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32]</ref>, improving network architecture <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6]</ref> and adjusting training procedure <ref type="bibr" target="#b32">[33]</ref>. Recent works also tried to improve the generated image quality by proposing new normalization modules, such as Categorical Conditional BN and spectral normalization <ref type="bibr" target="#b46">[47]</ref>.</p><p>Neural Architecture Search (NAS) The goal of NAS is to automatically search for an optimal model architecture for the given task and dataset. It was first proposed in <ref type="bibr" target="#b73">[74]</ref> where a reinforcement learning algorithm iteratively samples, trains and evaluates candidate models from the search space. Due to its prohibitive time cost, the weight-sharing mechanism was introduced <ref type="bibr" target="#b51">[52]</ref> and becomes a popular strategy <ref type="bibr" target="#b42">[43]</ref>. However, weight-sharing causes performance deterioration due to unfair training <ref type="bibr" target="#b9">[10]</ref>, motivating other alternatives to accelerate NAS <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b44">45]</ref>. Besides, a few NAS benchmarks <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b69">70]</ref> were recently released, with ground-truth accuracy for candidate models pre-recorded, enabling researchers to evaluate the performance of the search method more easily <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b58">59]</ref>.</p><p>Adversarial Robustness Deep networks are notorious for the vulnerability to adversarial attacks <ref type="bibr" target="#b23">[24]</ref>. In order to enhance adversarial robustness, countless defense approaches have been proposed <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b15">16]</ref>. Among them, adversarial training (AT) <ref type="bibr" target="#b43">[44]</ref> is arguably the strongest, which trains the model over a mixture of clean and perturbed data. The normalization in AT had not been studied in-depth until the pioneering work <ref type="bibr" target="#b60">[61]</ref> introduced an auxiliary batch norm (AuxBN) to improve the clean image recognition accuracy.</p><p>Neural Style Transfer Style transfer <ref type="bibr" target="#b20">[21]</ref> generates a stylized image, by combining the content of one image with the style of another. Various improvements are made on the normalization methods <ref type="bibr" target="#b8">[9]</ref>. <ref type="bibr" target="#b56">[57]</ref> proposed Instance Normalization (IN), improving the stylized quality of generated images. Conditional Instance Normalization (CIN) <ref type="bibr" target="#b18">[19]</ref> and Adaptive Instance Normalization (AdaIN) <ref type="bibr" target="#b27">[28]</ref> enable a single network to perform multiple/arbitrary style transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Sandwich Batch Normalization</head><p>Given the input feature x ? R N ?C?H?W (N denotes the batch size, C the channel number, H height and W width), the vanilla Batch Normalization (BN) works as:</p><formula xml:id="formula_1">h = ?( x ? ?(x) ?(x) ) + ?,<label>(1)</label></formula><p>where ?(x) and ?(x) are the running estimates (or batch statistics) of input x's mean and variance along (N , H, W ) dimensions. ? and ? are the learnable parameters of the affine layer, and both are of shape C. However, the vanilla BN only has a single re-scaling transform and will treat any latent feature from one single distribution.</p><p>As an improved variant, Categorical Conditional BN (CCBN) <ref type="bibr" target="#b46">[47]</ref> is proposed to remedy the heterogeneity issue in the task of conditional image generation, boosting the quality of generated images. CCBN has a set of independent affine layers, whose activation is conditioned by the input domain index and each affine layer is learned to capture the class-specific information. It can be expressed as:  where ? i and ? i are parameters of the i-th affine layer. Concretely, i is the expected output class in the image generation task <ref type="bibr" target="#b47">[48]</ref>. However, we argue that this "separate/split" modification might cause imbalanced learning for different classes. Since the training data from each class might vary a lot (different number of examples, complicated/simple textures, large/small inner-class variation, etc.), different individual affine layers might have significantly diverged convergence speed, impeding the proper training of the whole network. Dominant classes will introduce stronger inductive biases on convolutional layers than minor classes. To better handle the imbalance, we present Sandwich BN (SaBN), that is equipped with a shared sandwich affine layer and a set of independent affine layers:</p><formula xml:id="formula_2">h = ? i ( x ? ?(x) ?(x) ) + ? i , i = 1, ..., C,<label>(2)</label></formula><formula xml:id="formula_3">h = ? i (? sa ( x ? ?(x) ?(x) ) + ? sa ) + ? i , i = 1, ..., C. (3)</formula><p>As depicted in <ref type="figure" target="#fig_0">Fig. 1 (d)</ref>, ? sa and ? sa denote the new sandwich affine layer, while ? i and ? i are the i-th affine parameters, conditioned on categorical inputs. Implementationwise, SaBN only takes a few lines of code changes over BN: please see the supplement for pseudo codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Why SaBN meaningfully works?</head><p>One might be curious about the effectiveness of SaBN, since at the inference time, the shared sandwich affine layer can be multiplied/merged into the independent affine layers, making the inference form of SaBN completely identical to CCBN. So where is its real advantage?</p><p>By the analysis below, we argue that: SaBN provides a favorable inductive bias for optimization. During training, we observe that SaBN promotes balanced gradient norms (leading to more fair learning paces among heterogeneous classes and features), while still preserving diverse gradient directions (leading to each class leaning towards discriminative feature clusters).</p><p>We take the training of the conditional image generation task as an example. As one of the state-of-the-art GANs, SNGAN <ref type="bibr" target="#b46">[47]</ref> successfully generates high-quality images in the conditional image generation task with CCBN. Intuitively, it uses independent affine layers to disentangle the image generation of different classes. We consider analyzing the following two models: 1) SNGAN (equipped with CCBN originally); 2) SNGAN-SaBN (simply replaces CCBN with our SaBN). Both of them are trained on the same subset of ImageNet, with the same training recipe (see Sec. 4.1 for details). Here we analyze the difference of inter-class gradients of the generator in two aspects: (1) gradient magnitude and (2) gradient direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SaBN Encourages Balanced Gradient Magnitudes.</head><p>For the first aspect, we analyze the standard deviation of the l 2 -norm (magnitude) of generator's gradients among different classes in <ref type="figure" target="#fig_2">Fig. 2 (a)</ref>. Concretely, we take the gradients from weights of convolution layers, which are right before the normalization modules. We observe that the gradient norms from SNGAN-SaBN mostly have lower standard deviations, indicating that the gradient magnitudes of different classes in SNGAN-SaBN are more balanced. A balanced distribution of gradient magnitudes is found to be preferred for model training, avoiding some features dominating the others, and facilitating the optimization of all sub-tasks at similar paces <ref type="bibr" target="#b67">[68]</ref>. SaBN Preserves Diversity of Gradient Directions. We then visualize the averaged cosine similarity of generator's gradients from different classes during training in <ref type="figure" target="#fig_2">Fig. 2  (b)</ref>. Specifically, we define the inter-class gradient similarity g inter , which aims to measure the divergence of gradients from different input class labels y and averaged over latent vectors (z):</p><formula xml:id="formula_4">g l inter = 1 m m?1 i=0 C ? ? l L(G(z i , y j ))| n?1 j=0<label>(4)</label></formula><p>Here the generator is denoted by G, and ? ? l L(G(z i , y j )) represents the gradients on convolution layers of the l-th stage of the generator (i.e., the derivative of loss L with respect to parameters in l-th stage ? l ; we omit the discriminator here). m and n are the total number of latent vectors z and class labels y, respectively. Function C calculates the averaged pair-wise cosine similarity of inputs:</p><formula xml:id="formula_5">C v i | N i=1 = 1 N (N ? 1) N i=1 N j=1,j? =i v i ? v j ?v i ??v j ? .<label>(5)</label></formula><p>We can see that SNGAN-SaBN has lower g inter , indicating the gradients from different classes are more diverse in their directions. This enables the generator to capture richer discriminative information among different classes and contribute to a visually more diverse generation. Summary: The above two characteristics brought by SaBN, i.e., overall more balanced gradient norms, and interclass more diverse gradient directions, together draw the big picture why SaBN facilitates the optimization especially in the presence of heterogeneous or multi-domain features. <ref type="figure" target="#fig_3">Fig. 3</ref> visualizes GAN training with and without SaBN: SNGAN with SaBN can achieve much lower generator loss L G (Eq. 6) than the original SNGAN ( <ref type="figure" target="#fig_3">Fig. 3 left)</ref>, and the generation quality of the former consistently outperforms the latter (by Inception Score <ref type="bibr" target="#b53">[54]</ref>, <ref type="figure" target="#fig_3">Fig. 3 right)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Sandwich Batch Normalization is an effective plug-andplay module. In this section, we present the experiment re- sults of naively applying it into two different tasks: conditional image generation and neural architecture search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Conditional Image Generation with SaBN</head><p>Following the discussion in the previous section, we present detailed settings and main results on the conditional image generation task using SaBN in this section. We choose three representative GAN models, SNGAN, BigGAN <ref type="bibr" target="#b4">[5]</ref> and AutoGAN-top1 <ref type="bibr" target="#b21">[22]</ref>, as our baselines. The generator of SNGAN and BigGAN are equipped with CCBN originally. AutoGAN-top1 does not have any normalization layer and is designed for unconditional image generation, thus we manually insert CCBN into its generator to adapt it to the conditional image generation task. We then construct SNGAN-SaBN, BigGAN-SaBN, and AutoGAN-top1-SaBN, by simply replacing all CCBN in the above baselines with our proposed SaBN. GAN models in our paper are all trained with the hinge version adversarial loss <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b4">5]</ref>: </p><formula xml:id="formula_6">L D = ? E (x,</formula><p>where L D and L G denote discriminator loss and generator loss respectively.</p><p>We test all the above models on CIFAR-10 dataset [37] (10 categories, resolution 32 ? 32). Furthermore, we test SNGAN and SNGAN-SaBN on high-resolution conditional image generation task with ImageNet <ref type="bibr" target="#b13">[14]</ref>, using the subset of all 143 classes belonging to the dog and cat super-classes, cropped to resolution 128 ? 128) following <ref type="bibr" target="#b46">[47]</ref>'s setting. Inception Score <ref type="bibr" target="#b53">[54]</ref> (the higher the better) and FID <ref type="bibr" target="#b26">[27]</ref> (the lower the better) are adopted as evaluation metrics. We summarize the best performance the models have achieved during training into <ref type="table" target="#tab_0">Table 1</ref>. We find that SaBN can consistently boost the generative quality of all three baseline GAN models, which demonstrates the effectiveness of the injected shared sandwich affine layer. We also provide visualization results of generated images in <ref type="figure" target="#fig_6">Fig. 4</ref>. Since images of CIFAR-10 dataset <ref type="bibr" target="#b36">[37]</ref> are too small to tell difference,  we only visualize the results on ImageNet <ref type="bibr" target="#b13">[14]</ref>. Specifically, we compare the generation results of SNGAN and SNGAN-SaBN. The images generated by SNGAN-SaBN are more visual appealing, showing better quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Architecture Heterogeneity in Neural Architecture Search (NAS)</head><p>Recent NAS works formulate the search space as a weight-sharing supernet that contains all candidate operations and architectures, and the goal is to find a sub-network that of the optimal performance. As one of the representative works in NAS, DARTS <ref type="bibr" target="#b42">[43]</ref> solves the search problem by assigning each candidate operation a trainable architecture parameter ?. Model weights ? and architecture parameters ? are optimized to minimize the cross-entropy loss in an alternative fashion. After searching, the final architecture is derived by choosing the operation with the highest ? value on each edge. However, such formulation introduces a strong model heterogeneity. As shown in <ref type="figure" target="#fig_7">Fig. 5</ref>, the output of each layer is the sum of all operations' output, weighted by associated architecture parameters ?. Such mixed model heterogeneity could be harmful to the search, making the algorithm hard to distinguish the contribution of each operation. Inspired by the application of CCBN in GANs, we preliminarily attempt to use CCBN disentangling the mixed model heterogeneity from the previous layer, by replacing the BN in each operation path with a CCBN (namely DARTS-CCBN). The total number of affine paths is equal to the number of candidate operations in the previous layer, and the conditional index i of CCBN is obtained by applying a multinomial sampling on the softmax of previous layers' architecture parameters (shown in <ref type="figure" target="#fig_7">Fig. 5</ref>). The search results of the vanilla DARTS and DARTS-CCBN are reported in Tab. 2. Compared with vanilla DARTS, DARTS-CCBN does not show consistent improvement w.r.t. the search results. We argue that the brutal "separate/split" modification  in CCBN might cause imbalanced learning for different operations due to their intrinsic difference, therefore leading to unfair competition among candidate operations.</p><p>To better handle such an unbalanced issue, we consider using SaBN instead of CCBN (DARTS-SaBN). The injected shared sandwich affine layer is designed to balance the learning among different operations, imposing a more fair competition among candidate operations. As shown in Tab. 2, we can observe that DARTS-SaBN outperforms the vanilla DARTS and DARTS-CCBN significantly, whose performance is even close to the Bench optimal. The performance gap between DARTS-CCBN and DARTS-SaBN demonstrates the effectiveness of the sandwich affine layer. We further include an additional ablation variant DARTSaffine, which simply enables the affine layer of the BN in DARTS. DARTS-SaBN also outperforms DARTS-affine with a considerable margin, implying the independent conditional affine layers are also important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Extended Applications of Sandwich Batch Normalization</head><p>In this section, we explore the possibility to extend Sandwich Batch Normalization to more tasks with minor modifications. Concretely, we apply two variants of SaBN on adversarial robustness and arbitrary style transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Sandwich Auxiliary Batch Norm (SaAuxBN) in Adversarial Robustness</head><p>AdvProp <ref type="bibr" target="#b60">[61]</ref> successfully utilized adversarial examples to boost network Standard Testing Accuracy (SA) by introducing Auxiliary Batch Norm (AuxBN). The design is quite simple: an additional BN is added in parallel to the original BN, where the original BN (clean branch) takes the clean image as input, while the additional BN (adversarial branch) is fed with only adversarial examples during training. That intuitively disentangles the mixed clean and adversarial distribution (data heterogeneity) into two splits, guaranteeing the normalization statistics and re-scaling are exclusively performed in either domain. The loss function of AdvProp can be formulated as: <ref type="bibr" target="#b6">(7)</ref> where f denotes the model and x, y denotes the input data, label respectively. L is the cross entropy loss. Therefore, f clean denotes the model is using the clean branch BN. x adv is the corresponding adversarial mini-batch generated by the model using adversarial branch BN. For simplicity, we call the two loss terms in Eq. 7 as clean loss and adversarial loss respectively.</p><formula xml:id="formula_8">L total = L(f clean (x clean ), y) + L(f adv (x adv ), y),</formula><p>However, one thing missed is that the domains of clean and adversarial images overlap largely, as adversarial images are generated by perturbing clean counterparts minimally. This inspires us to present a novel SaAuxBN, by leveraging domain-specific normalization and affine layers, and also a shared sandwich affine layer for homogeneity preserving. SaAuxBN can be defined as:</p><formula xml:id="formula_9">h = ? i (? sa ( x ? ? i (x) ? i (x) ) + ? sa ) + ? i , i = 0, 1.<label>(8)</label></formula><p>? i (x) and ? i (x) denote the i-th (moving) mean and variance of input, where i = 0 for adversarial images and i = 1 for clean images. We use independent normalization layer to decouple the data from two different distributions, i.e., the clean and adversarial. We replace AuxBN with SaAuxBN in AdvProp <ref type="bibr" target="#b60">[61]</ref> and find it can further improve SA of the network with its clean branch. The experiments are conducted on CIFAR-10 <ref type="bibr" target="#b36">[37]</ref> with ResNet-18 <ref type="bibr" target="#b25">[26]</ref>. For a fair comparison, we follow the settings in <ref type="bibr" target="#b43">[44]</ref>. In the adversarial training, we adopt ? ? based 10 steps Projected Gradient Descent (PGD) <ref type="bibr" target="#b43">[44]</ref> with step size ? = 2 255 and maximum perturbation magnitude   As for assessing RA, PGD-20 with the same configuration is adopted. The results are presented in Tab. 3.</p><p>We further conduct an experiment to test the Standard Testing Accuracy (SA) and Robust Testing Accuracy (RA) of the network using the adversarial branch of AuxBN and SaAuxBN. The comparison results are presented in Tab. 4. We can see that BN still achieves the highest performance on SA, but falls a lot on RA compared with other methods. Our proposed SaAuxBN is on par with the vanilla BN in terms of SA, while has significantly better results on RA than any other approaches. Compared with SaAuxBN, AuxBN suffers from both worse SA and RA.</p><p>We also visualize the testing clean loss and adversarial loss of models with AuxBN and SaAuxBN in <ref type="figure" target="#fig_8">Fig. 6</ref>, showing that the latter achieves lower value on both.</p><p>We additionally include ModeNorm <ref type="bibr" target="#b12">[13]</ref> as an ablation in our experiments, which was proposed to deal with multimodal distributions inputs, i.e., data heterogeneity. It shares some similarity with AuxBN as both consider multiple independent norms. ModeNorm achieves fair performance on both SA and RA, while still lower than SaAuxBN. The reason might be the output of ModeNorm is a summation of two features weighted by a set of learned gating functions, which still mixes the statistics from two domains, leading to inferior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Arbitrary Style Transfer with Sandwich Adaptive Instance Normalization (SaAdaIN)</head><p>Huang &amp; Belongie <ref type="bibr" target="#b27">[28]</ref> achieves arbitrary style transfer by introducing Adaptive Instance Norm (AdaIN), which is an effective module to encode style information into feature space. The AdaIN framework is composed of three parts: Encoder, AdaIN, and Decoder. Firstly, the Encoder will ex-tract content features and style features from content and style images. Then, the AdaIN is leveraged to perform style transfer on feature space, producing a stylized content feature. The Decoder is learned to decode the stylized content feature to stylized images. This framework is trained endto-end with two loss terms, a content loss and a style loss. Concretely, AdaIN firstly performs a normalization on the content feature, then re-scale the normalized content feature with style feature's statistic. It can be formulated as:</p><formula xml:id="formula_10">h = ?(y)( x ? ?(x) ?(x) ) + ?(y),<label>(9)</label></formula><p>where y is the style input, x is the content input. Note that ? and ? here are quite different from BN, which are performed along the spatial axes (H, W ) for each sample and each channel. The goal of style transfer is to extract the style information from the style input and render it to the content input. Obviously, style-dependent re-scale may be too loose and might further amplify the intrinsic data heterogeneity brought by the variety of the input content images, undermining the network's ability of maintaining the content information in the output. In order to reduce the data heterogeneity, we propose to insert a shared sandwich affine layer after the normalization, which introduce homogeneity for the style-dependent re-scaling transformation. Hereby, we present SaAdaIN: h = ?(y)(? sa ( x ? ?(x) ?(x) ) + ? sa ) + ?(y),</p><p>Besides AdaIN, we also include Instance-Level Meta Normalization with Instance Norm (ILM+IN) proposed by <ref type="bibr" target="#b30">[31]</ref> as a task-specific comparison baseline. Its styleindependent affine is not only conditioned on style information but also controlled by the input feature.</p><p>Our training settings for all models are kept identical with <ref type="bibr" target="#b27">[28]</ref>. The network is trained with style loss and content loss. We use the training set of MS-COCO <ref type="bibr" target="#b41">[42]</ref> and WikiArt <ref type="bibr" target="#b48">[49]</ref> as the training content and style images dataset, and the validation set of MS-COCO and testing set of WikiArt are used as our validation set.</p><p>We depict the loss curves of the training phase in <ref type="figure">Fig. 7  (a)</ref>. We can notice that both the content loss and style loss of the proposed SaAdaIN are lower than that of AdaIN and ILM+IN. This observation implies that the inserted sandwich affine layer makes the optimization easier. In <ref type="figure">Fig. 7</ref> (b), we show the content and style loss on validation set. In contrast with the AdaIN model, the network with SaAdaIN achieves lower validation content and style loss, indicating the inserted sandwich affine layer also benefits the model's generalizability. The visual results of style transfer are shown in <ref type="figure">Fig. 8</ref>. Compared with AdaIN and ILM-IN, SaBN generates more visual-appealing images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We present SaBN and its variants as plug-and-play normalization modules, which are motivated by addressing model &amp; data heterogeneity issues. We demonstrate their effectiveness on several tasks, including neural architecture search, adversarial robustness, conditional image generation, and arbitrary style transfer. Our future work plans to investigate the performance of SaBN on more applications, such as semi-supervised learning <ref type="bibr" target="#b68">[69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgment</head><p>Z. Wang is in part supported by IoBT REIGN subaward # 088831-18415, US Army Research Laboratory.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of (a) vanilla batch normalization (BN), composed of one normalization layer and one affine layer; (b) Categorical Conditional BN, composed of one normalization layer following a set of independent affine layers to intake conditional information; (c) Sandwich BN, sequentially composed of one normalization layer, one shared sandwich affine layer, and a set of independent affine layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Inter-class gradient magnitude standard deviation (b) Inter-class gradient cosine similarity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>The visualization of standard deviations of gradient magnitudes (the lower the better, i.e., more balanced optimization paces) and cosine similarity across different classes (the lower the better, i.e., more diverse features learned). The x-axis of each plot denotes the depth of generator network, where each generator is composed of four stages of convolution blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>(left) The generator loss LG of SNGAN and SNGAN-SaBN during training phase (ImageNet). (right) The Inception Score curves during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>y)?pdata [min(0, ?1 + D(x, y))] ? E z?pz,y?pdata [min(0, ?1 ? D(G(z, y), y))], L G = ? E z?pz,y?pdata D(G(z, y), y),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>The image generation results of SNGAN and SNGAN-SaBN on ImageNet. Each column is corresponding to a specific image class. Images are chosen without cherry-pick.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Two consecutive layers in the supernet. By default, a BN is integrated into each parameterized operation in vanilla DARTS. The output of each layer is the sum of all operation paths' output, weighted by their associated architecture parameter ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>The clean loss L(fclean(xclean), y) and adversarial loss L(fadv(xadv), y) on testing set. ? = 8 255 ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>The content loss and the style loss of using AdaIN, ILM+IN and SaAdaIN on training and validation set. In the first row, the noisy shallow-color curves are the original data, and the foreground smoothed curves are obtained via applying exponential moving average on the original data. The visual results of style transfer. The images on the top-left corner of each row are the reference style image. An ideally stylized output should be semantically similar to the content image, while naturally incorporate the style information from the referenced style image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Best Inception Scores ("IS", ?) and FIDs (?) achieved by conditional SNGAN, BigGAN, and AutoGAN-top1, using CCBN and SaBN on CIFAR-10 and ImageNet (dogs &amp; cats).</figDesc><table><row><cell></cell><cell>CIFAR-10</cell><cell></cell><cell cols="2">ImageNet (dogs &amp; cats)</cell></row><row><cell>Model</cell><cell>IS</cell><cell>FID</cell><cell>IS</cell><cell>FID</cell></row><row><cell>AutoGAN-top1</cell><cell>8.43</cell><cell>10.51</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN</cell><cell>8.91 1</cell><cell>8.57 1</cell><cell>-</cell><cell>-</cell></row><row><cell>SNGAN</cell><cell>8.76</cell><cell>10.18</cell><cell>16.75</cell><cell>79.14</cell></row><row><cell cols="3">AutoGAN-top1-SaBN 8.72(+0.29) 9.11(?1.40)</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN-SaBN</cell><cell cols="2">9.01(+0.10) 8.03(?0.54)</cell><cell>-</cell><cell>-</cell></row><row><cell>SNGAN-SaBN</cell><cell cols="4">8.89(+0.13) 8.97(?1.21) 18.31(+1.56) 60.38(?18.76)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>The ground-truth top-1 accuracy of the final searched architecture on NAS-Bench-201. DARTS-SaBN achieves the highest accuracy, with the lowest standard deviation. Bench optimal denotes the best test accuracy achievable in NAS-Bench-201.</figDesc><table><row><cell>Method</cell><cell>CIFAR-100</cell><cell>ImageNet16-120</cell></row><row><cell>DARTS</cell><cell>44.05 ? 7.47</cell><cell>36.47 ? 7.06</cell></row><row><cell>DARTS-affine</cell><cell>63.46 ? 2.41</cell><cell>37.26 ? 7.65</cell></row><row><cell>DARTS-CCBN</cell><cell>62.16 ? 2.62</cell><cell>31.25 ? 6.20</cell></row><row><cell cols="2">DARTS-SaBN (ours) 71.56 ? 1.39</cell><cell>45.85 ? 0.72</cell></row><row><cell>Bench Optimal</cell><cell>73.51</cell><cell>47.31</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Model performance (SA) using clean branch.</figDesc><table><row><cell>Evaluation</cell><cell>BN</cell><cell cols="3">ModeNorm AuxBN (clean branch) SaAuxBN (clean branch)</cell></row><row><cell cols="2">Clean (SA) 84.84</cell><cell>83.28</cell><cell>94.47</cell><cell>94.62</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Performance (SA&amp;RA) using the adversarial branch.</figDesc><table><row><cell>Evaluation</cell><cell>BN</cell><cell cols="3">ModeNorm AuxBN (adv branch) SaAuxBN (adv branch)</cell></row><row><cell>Clean (SA)</cell><cell>84.84</cell><cell>83.28</cell><cell>83.42</cell><cell>84.08</cell></row><row><cell cols="2">PGD-10 (RA) 41.57</cell><cell>43.56</cell><cell>43.05</cell><cell>44.93</cell></row><row><cell cols="2">PGD-20 (RA) 40.02</cell><cell>41.85</cell><cell>41.60</cell><cell>43.14</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Results obtained by using the author's officially unofficial PyTorch BigGAN implementation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Wasserstein gan. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Theoretical analysis of auto rate-tuning by batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaifeng</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03981</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">ton. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7694" to="7705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distilling portable generative adversarial networks for image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changyuan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3585" to="3592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural architecture search on imagenet in four gpu hours: A theoretically inspired perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11535</idno>
		<title level="m">Neural architecture search on imagenet in four gpu hours: A theoretically inspired perspective</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gated-gan: Adversarial gated networks for multi-collection style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="546" to="560" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Theoretical understanding of batch-normalization: A markov chain perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Hadi Daneshmand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lucchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01652</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modulating early visual processing by language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Harm De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?mie</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6594" to="6604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05466</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Mode normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamyar</forename><surname>Guneet S Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aran</forename><surname>Kossaifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01442</idno>
		<title level="m">Stochastic activation pruning for robust adversarial defense</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00902</idno>
		<title level="m">Adversarially robust neural architectures</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Nas-bench-102: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00326</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.07629</idno>
		<title level="m">Jonathon Shlens, and Manjunath Kudlur. A learned representation for artistic style</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morcos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00152</idno>
		<title level="m">Training batchnorm and only batchnorm: On the expressive power of random features in cnns</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Autogan: Neural architecture search for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3224" to="3234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m">Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Batch renormalization: Towards reducing minibatch dependence in batch-normalized models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1945" to="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Instance-level meta normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding-Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4865" to="4873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The relativistic discriminator: a key element missing from standard gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00734</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Exponential convergence rates for batch normalization: The power of length-direction decoupling in non-convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Daneshmand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Neymeyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10694</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stochastic normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichao</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Kilian Q Weinberger, and Serge Belongie. Positional normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1622" to="1634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfu</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01259</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Attentive normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Defense against adversarial attacks using high-level representation guided denoiser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhou</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1778" to="1787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06083</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Neural architecture search without training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot J</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7588" to="7598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Magnet: a two-pronged defense against adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="135" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05957</idno>
		<title level="m">Spectral normalization for generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05637</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">cgans with projection discriminator. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Painter by numbers, wikiart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiri</forename><surname>Nichol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05264</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Extending defensive distillation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Melody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03268</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Rethinking normalization and elimination singularity in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09738</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">How does batch normalization help optimization?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2483" to="2493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Filter response normalization layer: Eliminating batch dependence in the training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11237" to="11246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<title level="m">stance normalization: The missing ingredient for fast stylization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Attentive normalization for conditional image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Cong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5094" to="5103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.10490</idno>
		<title level="m">Weak nas predictors are all you need</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09665</idno>
		<title level="m">Adversarial examples improve image recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Intriguing properties of adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03787</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Feature squeezing: Detecting adversarial examples in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01155</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Renas: Relativistic evaluation of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangling</forename><surname>Jui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4411" to="4420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Hournas: Extremely fast neural architecture search through an hourglass lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10896" to="10906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09635</idno>
	</analytic>
	<monogr>
		<title level="m">Towards reproducible neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">101</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08928</idno>
		<title level="m">Slimmable neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Gradient surgery for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhe</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06782</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Split batch normalization: Improving semi-supervised learning under domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?</forename><surname>Zaj?c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanis?aw</forename><surname>Konrad?o?na</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jastrz?bski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03515</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.10422</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<title level="m">Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Passport-aware normalization for deep model protection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning semantic-aware normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heliang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
