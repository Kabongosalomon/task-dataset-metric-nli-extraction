<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pseudo-mask Matters in Weakly-supervised Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghui</forename><surname>Kuang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyang</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Qing Yuan Research Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Chen</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Zhang</surname></persName>
							<email>wayne.zhang@sensetime.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Shanghai AI Laboratory 4</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sensetime</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pseudo-mask Matters in Weakly-supervised Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most weakly supervised semantic segmentation (WSSS) methods follow the pipeline that generates pseudo-masks initially and trains the segmentation model with the pseudomasks in fully supervised manner after. However, we find some matters related to the pseudo-masks, including high quality pseudo-masks generation from class activation maps (CAMs), and training with noisy pseudo-mask supervision. For these matters, we propose the following designs to push the performance to new state-of-art: (i) Coefficient of Variation Smoothing to smooth the CAMs adaptively; (ii) Proportional Pseudo-mask Generation to project the expanded CAMs to pseudo-mask based on a new metric indicating the importance of each class on each location, instead of the scores trained from binary classifiers. (iii) Pretended Under-Fitting strategy to suppress the influence of noise in pseudo-mask; (iv) Cyclic Pseudo-mask to boost the pseudo-masks during training of fully supervised semantic segmentation (FSSS). Experiments based on our methods achieve new state-of-art results on two changeling weakly supervised semantic segmentation datasets, pushing the mIoU to 70.0% and 40.2% on PAS-CAL VOC 2012 and MS COCO 2014 respectively. Codes including segmentation framework are released at https://github.com/Eli-YiLi/PMM Applying our methods to a baseline algorithm called SEAM [33], we achieve new state-of-the-art results on arXiv:2108.12995v2 [cs.CV] 7 Sep 2021</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation is a fundamental computer vision problem and requires time-consuming pixel-level manual annotations. To reduce the annotation burden, weaklysupervised semantic segmentation approaches have been proposed using scribble annotations <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32]</ref>, bounding boxes <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref> , points <ref type="bibr" target="#b2">[3]</ref> or image-level labels <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b32">33]</ref>. In this paper, we focus on weakly-supervised semantic segmentation with image-level labels due to its easily available annotations.</p><p>Almost all the latest WSSS algorithms require pseudomask derived from CAM to train the FSSS model. Instead of the pseudo-mask, previous works mainly focus on the generation of CAMs, or the post-process of them. We observe that there are some matters about pseudo-mask that are not handled appropriately as follows: (i) argmax operation on the CAMs along the channel dimension projects multi-label class activation maps (CAMs) to single-label pseudo-masks, but the image-level classification for generating CAMs does not consider the conflicts of predictions on target locations; (ii) CAMs generated by the classification model tend to focus on the most discriminative part and result in partial activations; (iii) the noise in pseudo-masks is inevitable and impedes the training of fully-supervised semantic segmentation (FSSS). (iv) the predictions of FSSS are usually more accurate than supervisory signals (pseudomasks).</p><p>In this paper, we propose a series of strategies to boost the efficiency of pseudo-masks in aspects of both generation and utilization. Specifically, in the pseudo-mask generation step, we firstly compute the Coefficient of Variation (c v ) for each channel of CAMs, and then refine CAMs via exponential functions with c v as the control coefficient. This operation smooths the CAMs and could alleviate the partial response problem introduced by the classification pipeline. Instead of projecting the three-dimensional CAM after dense-CRF <ref type="bibr" target="#b17">[18]</ref> directly to two-dimensional pseudomask with the argmax operation on scores as in previous studies, we equip each pixel a scalar which is computed as the proportion between the pixel's attention and the attention sum of the channels over the whole image. Intuitively the scalar represents the importance of the corresponding pixel based on which the final pseudo-masks are generated. In the FSSS training step, we propose a Pretended Underfitting Strategy which suppresses the losses of the noise labels in the pseudo-masks. In addition, the model is evaluated on validation dataset and we update the masks cyclically in condition that prediction from model is better than the pseudo-masks, rather than use the fixed pseudo-masks generated in the first step. two challenging weakly-supervised semantic segmentation benchmarks. In particular, our approach reach the mIoU of 70.0% and 40.2% on In PASCAL VOC 2012 <ref type="bibr" target="#b9">[10]</ref> and MS COCO 2014 <ref type="bibr" target="#b23">[24]</ref> validation sets respectively.</p><p>The contributions of this paper are three-fold:</p><p>? We generate high-quality pseudo-masks by the proposed Proportional Pseudo-mask Generation with Coefficient of Variation Smoothing. The Coefficient of Variation Smoothing expands the activation area of CAMs to overcome the partial response problem based on the CAM's coefficient of variation, and the Proportional Pseudo-mask Generation computes the importance of each location for each class independently, based on which the final pseudo-masks are generated.</p><p>? We realize the effective utilization of pseudo-masks via reducing the influence of noise by our Pretended Under-fitting Strategy, and narrow the gap between ground-truths and pseudo-masks via Cyclic Pseudomasks. The pixel-wise losses are reweighted to suppress the noises in the Pretended Under-fitting Strategy and pseudo-masks are refined in a iterative manner.</p><p>? We conduct extensive experiments to validate the effectiveness of our proposed approach (Pseudomask Matters, PMM), and demonstrate that our approach achieves new state-of-the-art results on two challenging weakly-supervised semantic segmentation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Weakly Supervised Semantic Segmentation: What WSSS does is to simplify the supervision with less accuracy loss. The annotation cost weakens from mask <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40]</ref> (fully supervision) to scribble <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32]</ref>, bounding box <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref>, points <ref type="bibr" target="#b2">[3]</ref> and image label <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b32">33]</ref> gradually. Till image-level label, there is only category information without spatial supervision. Thanks to the translation invariance of CNNs, the classification contributed pixels keep high response in the feature map. After combining the weights of classifier with the feature map, we get the CAM <ref type="bibr" target="#b41">[42]</ref> as the initial semantic mask. Later works mostly focus on expanding the seed areas. The methods include adding CRF and dilation <ref type="bibr" target="#b33">[34]</ref>, designing new losses <ref type="bibr" target="#b16">[17]</ref>, erasing high response area <ref type="bibr" target="#b12">[13]</ref>, keeping scale consistency via siamese network and correlation module <ref type="bibr" target="#b32">[33]</ref>, clustering sub-categories for classification <ref type="bibr" target="#b4">[5]</ref>. Besides CAM based methods, weakly supervised object detection method is also used with proposal models <ref type="bibr" target="#b24">[25]</ref>.</p><p>For the overall pipeline of WSSS, firstly a binary classification model is trained to obtain the CAMs and several techniques have been proposed to improve its quality. Secondly post-processing has been applied on the CAMs to generate pseudo-masks. Finally, semantic segmentation model with pseudo-masks supervised is trained in fully supervised manner.</p><p>Pseudo-mask Generation: Pseudo-mask generation is to project three-dimensional CAM to two-dimensional pseudo-mask with some post-process algorithms. Following the manner of single label classification, the pixel-level labels are identified by argmax operation on the CAMs along the channel dimension after post-process, although the model to predict the CAMs is trained by binary classifiers which exclude the label competition.</p><p>Conditional Random Fields (CRF), a sort of statistical modeling method for structured prediction with considering neighboring samples, has been widely used as the post processing tool for segmentation. Some variations of CRF have been proposed. Dense-CRF <ref type="bibr" target="#b17">[18]</ref> applies the appearance kernel to link nearby pixels with similar color, and smoothness kernel to removes small isolated regions. Deeplabv1 <ref type="bibr" target="#b5">[6]</ref> is an early work that introduces fully connected CRF in to segmentation task as post process. Then, CRFasRNN <ref type="bibr" target="#b40">[41]</ref> combines the CNN and CRF end-to-end. Besides, DPN <ref type="bibr" target="#b25">[26]</ref> uses the MRF which is similar to CRF. Further more, G-CRF <ref type="bibr" target="#b3">[4]</ref> introduced CNN for potential learning to improve the performance.</p><p>Several post-process methods based on deep learning have also been proposed. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref> learn the contour of objects via an affinity network in inference stage. The training masks are synthesised from two CRF results with different background intensities. Besides the unsupervised contour learning method, other works introduce saliency detection models trained from extra dataset to refine CAMs <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b10">11</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>In this section, We firstly elaborate the traditional pipeline generating pseudo-mask which projects the class activation map X ? R C?H?W to pseudo-mask Y ? R H?W with CRF function crf and image I. Then we introduce our pseudo-mask generation method, Proportional Pseudo-mask Generation (PPMG) with Coefficient of Variation Smoothing (CVS) as <ref type="figure" target="#fig_0">Fig. 1</ref>. After that, the noise suppressing module, Pretended Under-fitting Strategy (PUS) for the FSSS is described. Finally, the overall pipeline with Cyclic Pseudo-masks (CPM) involved is presented. We name our pipeline PMM from the abbreviation of Pseudomask Matters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pseudo-mask Generation with CRF</head><p>The CRF algorithm crf here is dense-CRF <ref type="bibr" target="#b17">[18]</ref>. The CAMs are processed with operations, including normalization norm, exponentially background generation bg and argmax, and the results are set as the input to CRF. Specifically, Min-Max Normalization is applied on X c,:,: and formulated as:</p><formula xml:id="formula_0">norm(X c,h,w ) = X c,h,w ? min(X c,:,: ) max(X c,:,: ) ? min(X c,:,: )</formula><p>, ?c, h, w</p><p>(1) where h and w are the coordinates on the CAMs, and c represents the channel index.</p><p>After normalization for each pixel, we have X (n) . Then the normalized pixel X (n) c,h,w on background matrix is constructed exponentially with power ? from the normalized foreground pixels X </p><formula xml:id="formula_1">:,h,w ) = (1 ? max(X (n) :,h,w )) ? , ?h, w<label>(2)</label></formula><p>Then concatenate the background and foreground to form the input X (u) of unary potential function in CRF:</p><formula xml:id="formula_2">X (u) = concat(bg(X (n) ), X (n) )<label>(3)</label></formula><p>Finally, the pseudo-mask is identified via argmax operation in category channel after CRF:</p><formula xml:id="formula_3">Y = argmax(crf (I, X (u) )),<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Coefficient of Variation Smoothing</head><p>The motivation of Coefficient of Variation Smoothing (CVS) is to smooth the class activation map based on the variation of confidence in spatial domain. We believe different images and classes require varied smoothing intensity depending on its distribution of confidences. To measure it, we introduce the Coefficient of Variation (c v ) as the metric for the foreground pixels X (f ) c,:,: whose scores are higher than threshold t in normalized metric X (n) c,:,: at channel c. We define the cv function in Eq. <ref type="formula" target="#formula_4">(5)</ref> where D counts the deviation ? 2 and E counts the mean ?.</p><formula xml:id="formula_4">cv(X (n) c,:,: ) = D(X (f ) c,:,: ) E(X (f ) c,:,: ) ,<label>(5)</label></formula><p>Then the c v is used as exponential function power to each pixel. As X (n) ? [0, 1], lower exponential power under 1 leads smaller differences between the foreground pixels and smooths the CAM. Here, We define the cvs for each pixel with scale factor s as:</p><formula xml:id="formula_5">cvs(X (n) c,h,w , (c v ) c ) = (X (n) c,h,w ) (1?s?(cv)c) , ?c, h, w (6)</formula><p>The CVS is applied after the normalization operation Eq.(1), and expand the activation area of target objects.</p><p>Experimentally, CVS works more efficiently with stronger augmentations involved, which also requires more training iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Proportional Pseudo-mask Generation</head><p>One important concern in WSSS is that the CAMs are obtained from binary classifiers. Follow the independent manner of binary cross entropy loss, we generate classspecific background for the smoothed CAM X (s) c,:,: by bg and apply crf for it, then we return the binary foreground via f g, thus we have X (m) c,:,: as:</p><formula xml:id="formula_6">X (m) c,:,: = f g(crf (I, bg(X (s) c,:,: ))), ?c<label>(7)</label></formula><p>In this function, f g sets the foreground pixels whose scores are upper than t to 1, and other pixels to 0. So X (m) c,:,:</p><p>is a binary class mask. Then we concatenate the masks to X (m) .</p><p>However, more than one labels may be assigned to some pixels as activation areas of different classes could be overlapped. We do not assign the label to each pixel by activation scores on CAM, because in binary cross entropy, the loss only requires the network to distinguish positive sample and negatives for each category independently, and thus highlights the foreground consequently. But scores of different categories on foreground areas are not competitive during the training of binary classification. So rather than taking the index of the highest score as pseudo label, we compute a metric indicating the importance of each class on each pixel, based on which the pixel is assigned with more important label. Specifically, the CRF map is converted to a binary mask with the a thresholding operation and the computation of metric mention before could not be affected by the CRF score. The proportion function p is defined as:</p><formula xml:id="formula_7">p(X (n) c,h,w ) = X (n) c,h,w sum(X (n) (c,:,:) ? X (m)</formula><p>c,:,: )</p><p>, ?c, h, w</p><p>In Eq.(8) X (m) c,:,: is the foreground binary mask in channel c. Then, argmax is operated on the element-wise multiplication of mask and proportion map along channel dimension to generate pseudo-mask and formulated as:</p><formula xml:id="formula_9">Y = argmax(X (m) ? P )<label>(9)</label></formula><p>Thus, each pixel is equipped with a single label after the processing above and could be serve as supervision for semantic segmentation training.</p><p>The pseudo implementation of Proportional Pseudomask Generation is described in Alg.(1) :</p><p>Algorithm 1 Proportional Pseudo-mask Generation Input: image I and CAM X ? R C?H?W Output: pseudo-mask Y ? R H?W 1: normalize the CAM: X (n) = norm(X) 2: count c v for each class: c v = cv(X (n) ) 3: smooth the CAM: X (s) = cvs(X (n) , c v ) 4: compute binary mask with crf : X (m) c,:,: = f g(crf (I, bg(X (s) c,:,: ))), ?c 5: count the proportion map: P = p(X (n) ) 6: generare pseudo-mask: Y = argmax(X (m) ? P )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pretended Under-fitting Strategy</head><p>Compared with the manual annotations, pseudo-masks that serves as supervision signal to train the semantic segmentation are noisy. Previous studies focus on the generation of high quality pseudo-masks to reduce the noise and rare of them attempt to suppress the noise during the model training. Our approach is to reweight the losses of potential noise pixels in the optimization of FSSS. For this goal, we propose the Pretended Under-fitting Strategy as Eq. <ref type="formula" target="#formula_10">(10)</ref>:</p><formula xml:id="formula_10">(L) = mean(L) mean(L) &gt;= ? mean(pus(L)) mean(L) &lt; ?<label>(10)</label></formula><p>L ? R H?C is the loss map for pixels in the image from cross entropy loss, and means the loss of Pretended Underfitting Strategy for the loss map L. Funtion pus() is the operation of Pretended Under-fitting Strategy if the mean value of L below warm up threshold ?.</p><p>Three operations are implemented as followed:</p><formula xml:id="formula_11">pus clamp (L) = L h,w L h,w &lt; ? L h,w ? ? L h,w L h,w &gt;= ? ?h, w (11) pus pow (L) = L ?<label>(12)</label></formula><formula xml:id="formula_12">pus ignore (L) = L h,w L h,w &lt; ? 0 L h,w &gt;= ? ?h, w<label>(13)</label></formula><p>pus clamp sets a maximum of L to a hyper parameter ? while pus ignore drops these pixels. pus pow carries out a scaling strategy by exponential function. We later evaluate these operations in Tab. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Cyclic Pseudo-mask and Overall Pipeline</head><p>Obviously there is a large gap between pseudo-mask and real ground-truth. Previous studies have shown that CNN model is robust to noise in some degree. So a simple but effective method to narrow the gap is to update the pseudomask cyclically. We replace the pseudo-mask on training dataset as the predictions from the trained model on it. We call the new mask as Cyclic Pseudo-mask. This operation is validated in next section.</p><p>The overall pipeline is consisted of (i) classification for CAMs, (ii) pseudo-mask generation and (iii) training of FSSS. In the first step, multi-crop test is used to generate the CAMs instead of multi-scale test. Specifically, Multi-crop firstly resizes the image to different resolutions and crop the resized images with fixed crop size and stride, then compute the average of crop results. Meanwhile, we propose a multicrop training technique which transforms the image in the similar way to the test. Note that, we need a base mask to update the ground truth, as multi-crop may crops the background if the image is resized too large, causing the original labels invalid. In our study, the CAMs from SEAM <ref type="bibr" target="#b32">[33]</ref> are used as the base mask. The scale-friendly CNN structure, ScaleNet <ref type="bibr" target="#b21">[22]</ref>, is applied to train the classification model and multi-crop operation which loads the rough mask and update the image level label is implemented online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Setup</head><p>Datasets: We evaluate our approach on PASCAL VOC 2012 dataset and MS-COCO 2014 dataset. All the mask annotations are converted to image level multi-label groundtruths. VOC12 contains 20 foreground objects and one background. The dataset is divided into train set (1464 images), validation set (1449 images) and test set (1456 images). In general, additional annotations from SBD <ref type="bibr" target="#b11">[12]</ref> are used to augment training set to 10582 images. COCO14 dataset ranges from 1 to 90, among them 80 categories are valid foreground. The train set contains 82081 images and the number of validation set is 40137. We evaluate the experiments on the validation sets by Mean intersection over union (mIoU).</p><p>Implementation details: Our baseline of classification framework is SEAM. We replace the backbone from Wide ResNet38 <ref type="bibr" target="#b34">[35]</ref> in SEAM to ScaleNet101 <ref type="bibr" target="#b21">[22]</ref> to boost the multi-scale feature which is similar to multiple resolution training in SEAM. The output stride is 8 without extra dilations since the receptive fields of ScaleNet is massive. Feature maps from stage 3 and stage 4 are projected to 64 and 128 channels respectively by 1?1 convolution layers for the PCM module in SEAM.</p><p>The resize scales of multi-crop start from 0.75 to 3 (step 0.25). The resized images are cropped in size 448?448 with crop stride 300. In train phase, if crop area covers over 10% of foreground class c or over 10% area of crop is class c, we tag the ground-truth to positive in channel c. The training images is randomly selected from the multi-crop proposals. In test phase, the resize scales, crop size and stride are the same to train phase. We get the base mask from original SEAM with ? in CRF setting to be 24 without Random Walk. SEAM is trained as original settings. Note that multi-crop training requires 20 epochs to make sure that each cropped patch of images are involved. The initial learning rate:wq is set to 0.02 with batch size 16. The CAM background exponent ? and the scale factor s of cvh function are obtained from grid search (eg. 11 and 0.3), with foreground threshold t at 0.05.</p><p>For the fully supervised segmentation, we do not reproduce the performance of deeplab-v2 <ref type="bibr" target="#b6">[7]</ref> as described in <ref type="bibr" target="#b32">[33]</ref>, so we use the PSPnet <ref type="bibr" target="#b39">[40]</ref> to achieve the mIoU in the paper with codebase MMSegmentation <ref type="bibr" target="#b7">[8]</ref>. We follow the settings in MMSegmentation for VOC, and we add dense-CRF to it. For Pretended Under-fitting Strategy, set the warm up threshold ? and hyper parameter ? in PUS to 0.5 for VOC, and 0.8 for COCO. The training batch size is 16 on 8 gpus at learning rate 0.005 for 20000 iterations in ploy policy. On VOC12 dataset, the pseudo-mask is updated once according to the method described in 3.5 and we do only apply the pretended under-fitting strategy in the 1st round training. On COCO14 dataset, the pseudo mask is not updated as we observe that the performance on validation dataset is the best after the 1st round training. We set the class number to 91 (one background and 10 invalid), and the invalid classes are ignored in test. Besides that, we use 32 gpus, batch size 64, learning rate 0.02 and iteration 40000 for the training of COCO14. All of the backbones in FSSS are initialized with the pretrained model from ImageNet <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Studies</head><p>We make ablation studies for CAM generation, pseudomask generation and segmentation in different settings. All the results are evaluated on validation set of VOC12 for the consistency of comparison.</p><p>Improvements of CAM: In this paper, we push out a strong CAM baseline based on multi-crop and multi-scale network. In Tab. 1, the top part evaluates the effectiveness of multi-crop strategy. Notable, there is 3.49 improvement when multi-crop is applied on both train and test phase, compared to 1.21 in test phase only. Then we compare multi-scale backbones in the middle part, and we find the ScaleNet101 performs significantly better than Res2Net101 and wide ResNet38, which suggests that apply multi-scale operations in backbone benefits CAMs a lot. We add multicrop to train phase in last line for ScaleNet101, and the final result is 58. <ref type="bibr" target="#b20">21</ref>.</p><p>Improvements of Pseudo-mask Generation: We evaluate the effectiveness of CVS and PPMG in Tab. 2. We firstly apply dense-CRF on baseline (SEAM) and our variant in the top part. The mIoU of CAMs increases by 1.52 and 0.98 respectively in these two settings. These results are obtained from grid search of CRF background reduction hyper parameter ? from 0 to 20. In the middle part, we show the individual gains and we find the gains of PPMG are more. In the last line, PPMG with CVS and CRF improves the baseline by 4.6, and the gain of our CAM is 3.28. In <ref type="figure">Fig. 2</ref> we give some examples with its c v values and its results after CVS, we can observe that the disparity problem is more critical with larger c v values and CVS could handle it appropriately. Removal of Random Walk: Most WSSS algorithms deploy Random Walk to refine the CAM. It requires CRF operations at different ? values to synthesize the training data. However, the results in Tab. 3 suggest that the affinity network and Random Walk do not work in our settings. So we remove the affinity network and Random Walk in our pipeline. The visualization of our refined CAM is depicted in <ref type="figure" target="#fig_2">Fig. 3</ref>  the results from different pseudo-masks without PUS. The middle part shows the results of three pus functions, among which, pus clamp performs best. Compared to baseline pseudo-mask, the improvement rises from 0.45 to 3.46 after applying the pus clamp , which means the PUS is essential to our pipeline. We also validate the effectiveness of Cyclic Pseudomask in Tab. 5. We find VOC dataset needs to update the pseudo-mask once while COCO does not require cyclically updating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head><p>In Tab. 6, We show the accumulated gains of our methods, including the classification, segmentation and pseudomask generation methods. Although our classification pipeline improve the performance of CAM, application of RW instead of PPMG hurts the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with State-of-the-arts</head><p>We compare the final results after fully supervised segmentation step in Tab. 7. The backbones of segmentation framework are listed in the table. Our method does not require affinity network and Random Walk inference, while achieves new state-of-the-arts in both VOC12 and COCO14 validation datasets at 70.0 and 40.2 respectively. Compared to our baseline SEAM, the gain is 5.5 in VOC12 and 5.0 in COCO14. For the same backbone, the improvements are 4.0 and 5.0 respectively. Note that the performance of ScaleNet101 on VOC is lower than base model ResNet38, but it suits tiny objects well on COCO at mIoU 40.2.  In Tab. 8 we compare our PMM to methods with extra information like saliency model, bounding box supervision, extra dataset and segment-based object proposals. These methods introduce more information and thus take advantage to the methods in Tab. 7. Even though, our PMM achieves new SOTA in both VOC12 and COCO14 without extra information. Especially, on COCO14 our method significantly surpasses the best published results by 3.1.</p><p>In <ref type="figure" target="#fig_3">Fig. 4</ref>, we shows some qualitative results on VOC12 validation set, which verifies the effectiveness of our PMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Backbone RW val test COCO BFBP <ref type="bibr" target="#b28">[29]</ref> VGG16 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Failure Case and Remedy</head><p>In <ref type="figure" target="#fig_2">Fig. 3</ref> we can see that, the details of our pseudo-masks are much better than SEAM with Random Walk. But the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Extra Info val test COCO DSRG <ref type="bibr" target="#b13">[14]</ref> MSRA mIoU of ours is not very high. The problem is the underactivation CAM, which causes incomplete prediction map or false positive. For this issue, the experiment in Tab. 6 and visualization in <ref type="figure" target="#fig_4">Fig. 5</ref> prove that this phenomenon is able to remedy by fully supervised segmentation. Thus PPMG reserves the details, on the other hand, segmentation model remedies the miss area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In weakly supervised semantic segmentation, there are some matters about pseudo-mask in the generation and utilization. To solve these matters, we propose the Proportional Pseudo-mask Generation to identify the category in- dependently and avoid direct score comparison, and the Coefficient of Variation Smoothing to smooth the CAM by its distribution statistics. Then, we add Pretended Underfitting Strategy to FSSS, and verify the effectiveness of Cyclic Pseudo-mask experimentally. We solve the matters about pseudo-mask and achieves new state-of-the-art in both VOC12 and COCO14 datasets, even beyond the methods using extra information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head><p>The work is partially supported by Innovation and Technology Commission of the Hong Kong Special Administrative Region, China (Enterprise Support Scheme under the Innovation and Technology Fund B/E030/18).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustration of pseudo-mask generation. Top: traditional pipeline for pseudo-mask generation. Bottom: Proportional Pseudo-mask Generation with Coefficient of Variation Smoothing. cv counts the coefficient of variation for each channel and cvs smooths the CAM. bg generates the background with exponential function and f g returns the binary foreground. p counts the proportion of a pixel to the entire category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Qualitative results of pseudo-maskt. Top: original images in VOC12 validation set. Second row: ground truth with ignored boundary. Third row: pseudo-masks of SEAM (baseline) with Random Walk. Bottom : our pseudo-masks from PPMG with CVS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative segmentation results on the VOC12 validation set. Top: original images. Middle: ground truth with ignored boundary. Bottom: Our results of PMM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Failure cases of pseudo-masks and its segmentation results on VOC12 validation set. First line: original images. Second line: ground truth. Third line: failure cases of our pseudo-masks. Last line: segmentation remedy results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 6 .</head><label>6</label><figDesc>Accumulated gains on V0C12 validation set. Cls means our classification setting. RW is affinity with Random Walk. PPMG is Proportional Pesudo-mask Generation with CVS. PUS is fully-supervised segmentation with Pretended Under-fitting Strategy. Cyclic indicates Cyclic Pseudo-mask. R2N change the backbone of segmentation to Res2Net.</figDesc><table><row><cell>Ori Cls RW PPMG PUS Cyclic R2N mIoU</cell></row><row><cell>52.72</cell></row><row><cell>58.21</cell></row><row><cell>52.18</cell></row><row><cell>61.49</cell></row><row><cell>66.73</cell></row><row><cell>68.50</cell></row><row><cell>70.01</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 7 .</head><label>7</label><figDesc>Performance comparisons with state-of-the-art WSSS methods on VOC 2012 and COCO 2014 validation datasets. All the methods listed use image-level supervision only without extra models. Checkmarks suggest these methods need training an affinity network and Random Walk inference. SEAM in blue is our baseline and indicates our re-implementation baseline in same segmentation code.</figDesc><table><row><cell>x 46.6 48.0 20.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 8 .</head><label>8</label><figDesc>Performance comparisons state-of-the-art WSSS methods on VOC 2012 and COCO 2014 validation datasets. Except PMM, other methods use different supervision or extra models. S means external saliency models and D means supervision of detection. SOP is segment-based object proposals. ? indicates using VGG, ? indicates Res2Net and means ScaleNet others using ResNet.</figDesc><table><row><cell></cell><cell>-B</cell><cell>61.4</cell><cell>63.2</cell><cell>26.0  ?</cell></row><row><cell>BoxSup [9]</cell><cell>D</cell><cell>62.0  ?</cell><cell>64.6</cell><cell>-</cell></row><row><cell>FickleNet [20]</cell><cell>S</cell><cell>64.9</cell><cell>65.3</cell><cell>-</cell></row><row><cell>SDI [16]</cell><cell>D+BSDS</cell><cell>65.7</cell><cell>67.5</cell><cell>-</cell></row><row><cell>OAA + [15]</cell><cell>S</cell><cell>65.2</cell><cell>66.4</cell><cell></cell></row><row><cell>SGAN [37]</cell><cell>S</cell><cell>67.1</cell><cell>67.2</cell><cell>33.6</cell></row><row><cell>ICD [11]</cell><cell>S</cell><cell>67.8</cell><cell>68.0</cell><cell>-</cell></row><row><cell>Li et al. [21]</cell><cell>S</cell><cell>68.2</cell><cell>68.5</cell><cell>28.4  ?</cell></row><row><cell>LIID [25]</cell><cell>SOP</cell><cell>66.5</cell><cell>67.5</cell><cell>-</cell></row><row><cell>LIID [25]</cell><cell>SOP</cell><cell>69.4  ?</cell><cell>70.4</cell><cell>-</cell></row><row><cell>PMM</cell><cell>-</cell><cell>68.5</cell><cell>69.0</cell><cell>36.7</cell></row><row><cell>PMM</cell><cell>-</cell><cell>67.1</cell><cell>67.7</cell><cell>40.2</cell></row><row><cell>PMM</cell><cell>-</cell><cell cols="2">70.0  ? 70.5  ?</cell><cell>35.7  ?</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4981" to="4990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What&apos;s the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="549" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast, exact and multi-scale inference for semantic image segmentation with deep gaussian crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="402" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weaklysupervised semantic segmentation via sub-category exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8991" to="9000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">MMSegmentation Contributors. Mmsegmentation, an open source semantic segmentation toolbox</title>
		<ptr target="https://github.com/open-mmlab/mmsegmentation" />
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1635" to="1643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning integral objects with intra-class discriminator for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4283" to="4292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Self-erasing network for integral object attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Tao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09821</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7014" to="7023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Integral object mining via online attention accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Tao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Kai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2070" to="2079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple does it: Weakly supervised instance and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seed, expand and constrain: Three principles for weakly-supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="695" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected crfs with gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ficklenet: Weakly and semi-supervised semantic image segmentation using stochastic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungbeom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5267" to="5276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Group-wise semantic mining for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05007</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Data-driven neuron allocation for scale aggregation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghui</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11526" to="11534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Leveraging instance-, imageand dataset-level information for weakly supervised instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Song</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jun</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semantic image segmentation via deep parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1377" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Constrained convolutional neural networks for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1796" to="1804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From image-level to pixel-level labeling with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1713" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Built-in foreground/background prior for weaklysupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatemehsadat</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadegh Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose M</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="413" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Self-supervised difference detection for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wataru</forename><surname>Shimoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5208" to="5217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mining cross-image semantics for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="347" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Normalized cut loss for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yude</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Revisiting dilated convolution: A simple approach for weakly-and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7268" to="7277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wider or deeper: Revisiting the resnet model for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="119" to="133" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to segment under various forms of weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Saliency guided self-attention network for weakly and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>IEEE Access</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="14413" to="14423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Joint learning of saliency detection and weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunzhi</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihe</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7223" to="7233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Causal intervention for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiansheng</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12547</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Conditional random fields as recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1529" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
