<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminating Between Similar Nordic Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Haas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IT University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IT University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminating Between Similar Nordic Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic language identification is a challenging problem. Discriminating between closely related languages is especially difficult. This paper presents a machine learning approach for automatic language identification for the Nordic languages, which often suffer miscategorisation by existing state-of-the-art tools. Concretely we will focus on discrimination between six Nordic languages: Danish, Swedish, Norwegian (Nynorsk), Norwegian (Bokm?l), Faroese and Icelandic.</p><p>9 References</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic language identification is a challenging problem and especially discriminating between closely related languages is one of the main bottlenecks of state-of-the-art language identification systems <ref type="bibr" target="#b11">(Zampieri et al., 2014)</ref>.</p><p>Language technology for Scandinavian languages is in a nascent phase (e.g. <ref type="bibr" target="#b5">Kirkedal et al. (2019)</ref>). One problem is acquiring enough text with which to train e.g. large language models. Good quality language ID is critical to this data sourcing, though leading models often confuse similar Nordic languages. This paper presents a machine learning approach for automatic language identification between six closely-related Nordic languages: Danish, Swedish, Norwegian (Nynorsk), Norwegian (Bokm?l), Faroese and Icelandic. This paper explores different ways of extracting features from a corpus of raw text data consisting of Wikipedia summaries in respective languages and evaluates the performance of a selection of machine learning models.</p><p>Concretely we will compare the performance of classic machine learning models such as Logistic Regression, Naive Bayes, Support vector machine, and K nearest Neighbors with more contemporary neural network approaches such as Multilayer Perceptrons (MLP) and Convolutional Neural Networks (CNNs).</p><p>After evaluating these models on the Wikipedia data set we will continue to evaluate the best models on a data set from a different domain in order to investigate how well the models generalize when classifying sentences from a different domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The problem of discriminating between similar languages has been investigated in recent work <ref type="bibr" target="#b2">(Goutte et al., 2016;</ref><ref type="bibr" target="#b12">Zampieri et al., 2015)</ref> which discuss the results from two editions of the "Discriminating between Similar Languages (DSL) shared task". Over the two editions of the DSL shared task different teams competed to develop the best machine learning algorithms to discriminate between the languages in a corpus consisting of 20K sentences in each of the languages: Bosnian, Croatian, Serbian, Indonesian, Malaysian, Czech, Slovak, Brazil Portuguese, European Portuguese, Argentine Spanish, Peninsular Spanish, Bulgarian and Macedonian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Nordic DSL Dataset</head><p>This section describes the construction of the Nordic DSL (Distinguishing Similar Lanugages) dataset.</p><p>Data was scraped from Wikipedia. We downloaded summaries for randomly chosen Wikipedia articles in each of the languages, saved as raw text to six .txt files of about 10MB each. While Bornholmsk would be a welcome addition <ref type="bibr" target="#b1">(Derczynski and Kjeldsen, 2019)</ref>, exhibiting some similarity to Faroese and Danish, there is not yet enough digital text.</p><p>After the initial cleaning (described in the next section) the dataset contained just over 50K sentences in each of the language categories. From this, two datasets with exactly 10K and 50K sentences respectively were drawn from the raw dataset. In this way the datasets are stratified, containing the same number of sentences for each language.</p><p>We split these datasets, reserving 80% for the training set and 20% for the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Cleaning</head><p>This section describes how the dataset is initially cleaned and how sentences are extracted from the raw data.</p><p>Extracting Sentences The first pass in sentence tokenisation is splitting by line breaks. We then extract shorter sentences with the sentence tokenizer (sent_tokenize) function from the NLTK <ref type="bibr" target="#b6">(Loper and Bird, 2002)</ref> python package. This does a better job than just splitting by '.' due to the fact that abbreviations, which can appear in a legitimate sentence, typically include a period symbol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cleaning characters</head><p>The initial dataset has many characters that do not belong to the alphabets of the languages we work with. Often the Wikipedia pages for people or places contain names in foreign languages. For example a summary might contain Chinese or Russian characters which are not strong signals for the purpose of discriminating between the target languages.</p><p>Further, it can be that some characters in the target languages are mis-encoded. These misencodings are also not likely to be intrinsically strong or stable signals.</p><p>To simplify feature extraction, and to reduce the size of the vocabulary, the raw data is converted to lowercase and stripped of all characters with are not part of the standard alphabet of the six languages.</p><p>In this way we only accept the following character set 'abcdefghijklmnopqr stuvwxyz???ae????????? '</p><p>and replace everything else with white space before continuing to extract the features. For example the raw sentence 'Hesbjerg er dannet ved sammenlaegning af de 2 g?rde Store Hesbjerg og Lille Hesbjerg i 1822.' will be reduced to 'hesbjerg er dannet ved sammenlaegning af de g?rde store hesbjerg og lille hesbjerg i ',</p><p>We thus make the assumption that capitalisation, numbers and characters outside this character set do not contribute much information relevant for language classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baselines</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline With langid.py</head><p>As a baseline to compare the performance of the models in we compare with an off-the-shelf language identification system. "langid.py: An Offthe-shelf Language Identification Tool." <ref type="bibr" target="#b8">(Lui and Baldwin, 2012)</ref> is such a tool.</p><p>langid.py comes with with a pretrained model which covers 97 languages. The data for langid.py comes from from five different domains: government documents, software documentation, newswire, online encyclopedia and an internet crawl. Features are selected for cross-domain stability using the LD heuristic <ref type="bibr" target="#b7">(Lui and Baldwin, 2011)</ref>.</p><p>We evaluated how well langid.py performed on the Nordic DSL data set. It is a peculiar feature of the Norwegian language that there exist two different written languages but three different language codes. Since langid.py also returned the language id "no" (Norwegian) on some of the data points we restrict langid.py to only be able to return either "nn" (Nynorsk) or "nb" (Bokm?l) as predictions. <ref type="figure" target="#fig_0">Figure 1</ref> shows the confusion matrix for the langid.py classifier.</p><p>The largest confusions were between Danish and Bokm?l, and between Faroese and Icelandic. We see that langid.py was able to correctly classify most of the Danish instances; however, approximately a quarter of the instance in Bokm?l were incorrectly classified as Danish and just under an eighth was misclassified as Nynorsk. Furthermore, langid.py correctly classified most of the Icelandic data points; however, over half of the data points in Faroese were incorrectly classified as Icelandic. <ref type="table">Table 1</ref> shows results for running the models on a data set with 10K sentences in each language category. We see that the models tend to perform better if we use character bi-grams instead of single characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline with linear models</head><p>Also we see that logistic regression and support vector machines outperform Naive Bayes and Knearest neighbors in all cases. Furthermore, for all models, we get the best performance if we use the skip-gram model from FastText.</p><p>Comparing the CBOW mode from FastText with character bi-grams we see that the CBOW model is on par with bi-grams for the KNN and Naive Bayes classifiers, while bi-grams outperform CBOW for Logistic Regression and support vector machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Using FastText</head><p>The methods described above are quite simple. We also compared the above method with Fast- Text, which is a library for creating word embeddings developed by Facebook .  explain how FastText extracts feature vectors from raw text data. Fast-Text makes word embeddings using one of two model architectures: continuous bag of words (CBOW) or the continuous skip-gram model.</p><p>The skip-gram and CBOW models are first proposed in <ref type="bibr" target="#b10">(Mikolov et al., 2013)</ref> which is the paper introducing the word2vec model for word embeddings. FastText builds upon this work by proposing an extension to the skip-gram model which takes into account sub-word information.</p><p>Both models use a neural network to learn word embedding from using a context windows consisting of the words surrounding the current target word. The CBOW architecture predicts the current word based on the context, and the skipgram predicts surrounding words given the current word <ref type="bibr" target="#b10">(Mikolov et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Using A Convolutional Neural Network</head><p>While every layer in a classic multilayer perceptron is densely connected, such that each of the nodes in a layer are connected to all nodes in the next layer, in a convolutional neural network we use one or more convolutional layers. Convolutional Neural Networks have an established use for text classification <ref type="bibr" target="#b3">(Jacovi et al., 2018)</ref>.</p><p>The basic premise of a convolutional layer is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. 1 In a CNN a filter "slides" over the input. The CNN then takes e.g. the dot product of the weights of the filter and the corresponding input features, before applying a further function.   6 Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results with neural networks</head><p>Results for the neural network architectures are in <ref type="table" target="#tab_2">Table 2</ref>. Here we compare the result of doing character level uni-and bi-grams using Multilayer Perceptron and Convolutional neural networks. We see that the CNN performs the best, achieving an accuracy of 95.6% when using character bi-grams. Both models perform better using bi-grams than individual characters as features while the relative increase in performance is greater for the MLP model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Increasing the size of the data set</head><p>Often the performance of supervised classification models increases with more training data. To measure this effect we increase the amount of training data to 50K sentences in each of the language categories. Due to longer training times only the baseline models were included, with the skip-gram encoding from FastText which we saw achieved the highest accuracy.    algorithm improved slightly by including more data. Unexpectedly, performance of the support vector machine and Na?ve Bayes dropped slightly with extra data. Even when including five times the amount of data, the best result, logistic regression with an accuracy of 93.3%, is still worse than for the Convolutional Neural Network trained on 10K data points in each language.</p><p>In <ref type="table" target="#tab_5">Table 4</ref> we see the results for running the neural networks on the larger data set. Both models improve by increasing the amount of data and the Convolutional Neural Network reached an accuracy of 97% which is the best so far.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref> we see the confusion matrix for the convolutional Neural Network trained on the full Wikipedia data set with 300K data points pr language. We see that the largest classification errors still happens between Danish, Bokm?l and Nynorsk as well as between Icelandic and Faroese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Using FastText supervised</head><p>FastText can also be used for be supervised classification. In  the authors show that FastText can obtain performance on par with methods inspired by deep learning, while being much faster on a selection of different tasks, e.g. tag prediction and sentiment analysis. We apply FastText classification to the Nordic DSL task. The confusion matrix from running the FastText supervised classifier can be seen in <ref type="figure" target="#fig_3">Figure 4</ref>. We see that FastText performance is similar to that of the CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Cross-domain evaluation</head><p>Training on single-domain data can lead to classifiers that only work well on a single domain. To see how the two best performing models generalize, we tested on a non-Wikipedia data set.</p><p>For this, we used Tatoeba, 2 a large database of user-provided sentences and translations.</p><p>The language style used in the Tatoeba data set is different from the language used in Wikipedia. Folk som ikke synes at latin er det smukkeste sprog, har intet forst?et. (People who don't think Latin is the most beautiful language have understood nothing.)</p><p>In <ref type="figure" target="#fig_6">Figure 5a</ref> we see the number of sentences in each language for all sentences in the Tatoeba data set. Observe that we have very few samples in Nynorsk and Faroese.</p><p>We see that the performance drops when shifting to Tatoeba conversations. For reference the accuracy of langid.py on this data set is 80.9% so FastText actually performs worse than the baseline with an accuracy of 75.5% while the CNN is better than the baseline with an accuracy of 83.8 %.    One explanation for the drop in performance is that the sentences in the Tatoeba data are significantly shorter than the sentences in the Wikipedia data set as seen in <ref type="figure" target="#fig_6">Figure 5b</ref>. As we saw in the previous section, both models tend to misclassify shorter sentences more often than longer sentences. This and the fact that the text genre is different might explain why the models trained on the Wikipedia data set does not generalise to the Tatoeba data set without a drop on performance.</p><p>The CNN uses character bi-grams as features while, with the standard settings, FastText uses only individual words to train. The better performance of the CNN might indicate that character level n-grams are more useful features for language identification than words alone.</p><p>To test this we changed the setting of FastText to train using only character level n-grams in the range 1-5 instead of individual words. In <ref type="figure" target="#fig_7">Figure 6</ref> we see the confusion matrix for this version of the FastText model. This version still achieved 97.8% on the Wikipedia test set while improving the accuracy on the Tatoeba data set from 75.4% to 85.8% which is a substantial increase.</p><p>Thus, using character-level features seems to improve the FastText models' ability to generalize to sentences belonging to a domain different from the one they have been trained on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Retraining on the combined data set</head><p>To improve the accuracy over the Tatoeba data set, we retrained the FastText model on a combined data set consisting of data points from both the Wikipedia and Tatoeba data set.</p><p>The FastText model achieved an accuracy of 97.2% on this combined data set and an accu- racy of 93.2% when evaluating this model on the Tatoeba test set alone -the confusion matrix can be seen in <ref type="figure" target="#fig_8">Figure 7</ref>.</p><p>As was the case with the Wikipedia data set the mis-classified sentences tend to be shorter than the average sentence in the data set. In <ref type="figure" target="#fig_9">Figure 8</ref> we see the distribution of sentence lengths for the Tatoeba test set along with the mis-classified sentences.</p><p>In the Tatoeba test set the mean length of sentences is 37.66 characters with a standard deviation of 17.91 while the mean length is only 29.70 characters for the mis-classified sentences with a standard deviation of 9.65. This again supports the conclusion that shorter sentences are harder to classify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Principal Component analysis and t-SNE</head><p>To gain additional insight on how the different word embedding capture important information about each of the language classes, we visualized the embeddings using two different techniques for dimensionality reduction.</p><p>We used two different methods: Principal Component Analysis (PCA) and T-distributed Stochastic Neighbor Embedding (t-SNE). We begin with a brief explanation of the two techniques and proceed with an analysis of the results.</p><p>Principal Component Analysis The first step is to calculate the covariance matrix of the dataset. The components of the covariance matrix is given by</p><formula xml:id="formula_0">K X i ,X j = E[(X i ? ? i )(X j ? ? j )]<label>(1)</label></formula><p>where X i is the ith component of the feature vector and ? i is the mean of that component.</p><p>In matrix form we can thus write the covariance matrix as</p><formula xml:id="formula_1">K(x, z) = ? ? ? cov(x 1 , z 1 ) . . . cov(x 1 , z n ) . . . . . . . . . cov(x n , z 1 ) . . . cov(x n , z n ) ? ? ?</formula><p>(2) The next step is to calculate the eigenvectors and eigenvalues of the covariance matrix by solving the eigenvalue equation.</p><formula xml:id="formula_2">det(Kv ? ?v) = 0<label>(3)</label></formula><p>The eigenvalues are the variances along the direction of the eigenvectors or "Principal Components". To project our data set onto 2D space we select the two eigenvectors' largest associated eigenvalue and project our data set onto this subspace.</p><p>In <ref type="figure" target="#fig_11">Figure 9</ref> we see the result of running PCA on the wikipedia data set where we have used character level bi-grams as features, as well as the CBOW and skipgram models from FastText.</p><p>In the figure for encoding with character level bi-grams, the PCA algorithm resulted in two elongated clusters. Without giving any prior information about the language of each sentences, PCA is apparently able to discriminate between Danish, Swedish, Nynorsk and Bokm?l on one side, and Faroese and Icelandic on the other, since the majority of the sentences in each language belong to either of these two clusters.</p><p>With the FastText implementations we observe three clusters. For both CBOW and skipgram we see a distinct cluster of Swedish sentences. When comparing the two FastText models we see that the t-SNE algorithm with skipgrams seems to be able to separate Faroese and Icelandic data points to a high degree compared with the CBOW model. Also for the cluster identified with the sentences with Danish, Bokm?l and Nynorsk the skipgram models seem seem to give a better separation, however to a lesser degree than with the two former languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t-SNE</head><p>The T-distributed Stochastic Neighbor Embedding method was first proposed in <ref type="bibr" target="#b9">2008 (van der Maaten and</ref><ref type="bibr" target="#b9">Hinton, 2008)</ref>, which favours retaining local spatial relationships over remote ones.  In t-SNE, for a given data point x i , the probability of picking another data point x j as a neighbor to x i is given by:</p><formula xml:id="formula_3">p ji = exp(||x i ? x j || 2 /2? 2 i ) k =i exp(||x i ? x k || 2 /2? 2 i )<label>(4)</label></formula><p>Given this probability distribution the goal is to find the low-dimensional mapping of the data points x i which we denote y i follow a similar distribution. To solve what is referred to as the "crowding problem", t-SNE uses the Student tdistribution which is given by:</p><formula xml:id="formula_4">q ij = (1 + ||y i ? y j || 2 ) ?1 k =l (1 + ||y k ? y l || 2 ) ?1<label>(5)</label></formula><p>Optimization of this distribution is done using gradient decent on the Kullback-Leibler divergence which is given by:</p><formula xml:id="formula_5">?C ?y i = 4 j (p ij ? q ij )(y i ? y j )(1 + ||y i ? y j || 2 ) ?1 (6)</formula><p>The result from running the t-SNE algorithm on the Wikipedia data set can be seen in <ref type="figure" target="#fig_0">Figure 10</ref>. As was the case with PCA, it appears that the encoding with FastText seem to capture the most relevant information to discriminate between the languages; especially the skip-gram mode does well at capturing information relevant to this task.</p><p>Here we recover some interesting information about the similarity of the languages. The data points in Bokm?l lie in between those in Danish and Nynorsk, while Icelandic and Faroese have their own two clusters which are separated from the three former languages. This is in good agreement with what we already know about the languages. Interestingly the Swedish data points and quite scattered and the t-SNE is not able to make a coherent Swedish cluster.</p><p>This does not however mean that the Swedish data points are not close in the original space. Some care is needed when interpreting the plot since t-SNE groups together data points such that neighboring points in the input space will tend to be neighbors in the low dimensional space.</p><p>If points are separated in input space, t-SNE would like to separate them in the low dimensional space however it does not care how far they are separated. So clusters that are far away in the low dimensional space are not necessarily far away in the input space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Discussion</head><p>We used the dimensionality reduction techniques PCA and t-SNE to make visualizations of feature vectors obtained by making a one-hot encoding with character bi-grams and with the two modes from FastText.</p><p>These unsupervised techniques was able to separate the sentences from Wikipedia into different clusters. Without any prior knowledge about the actual language of each sentence these techniques indicated that the six languages can be divided into three main language categories: (1) Danish Nynorsk Bokm?l (2) Faroese Icelandic and <ref type="formula" target="#formula_2">(3)</ref> Swedish.</p><p>Generally the supervised models had the largest errors when discriminating between languages belonging to either of the language groups mentioned above.</p><p>For the "classical" models we saw that Logistic Regression and support vector machines achieved better performance than KNN and Naive Bayes, where the latter performed the worst. This was true in all cases irrespective of the method of feature extraction.</p><p>Additionally we saw that when we used feature vectors from the FastText skip-gram model the classification models achieved better results than when using either FastText CBOW or character ngrams.</p><p>Generally we saw that increasing the number of data points lead to better performance. When comparing the CNN with the "classical" models however the CNN performed better than any of the other models even when trained on less data points. In this way it seems that the CNN achieves higher sample efficiency compared to the other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper presented research on the difficult task of distinguishing similar languages applied for the first time to the Scandinavian context. We describe and release a dataset and detail baseline approaches and problem analysis.</p><p>The dataset and code are available at https: //github.com/renhaa/NordicDSL.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Confusion matrix with results from langid.py on the full dataset, 300K instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Diagram of Convolutional Neural network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Confusion matrix with results from the convolutional neural network on the full data set with 50K data points in each language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Confusion matrix with results from a supervised FastText model on the full data set with 300K data points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>The Tatoeba data set mainly consists of sentences written in everyday language. Below we see some examples from the Danish part of the Tatoeba data set. Hvordan har du det? (How are you?) P? trods af al sin rigdom og ber?mmelse, er han ulykkelig. (Despite all his riches and renown, he is unlucky.) Vi fl?j over Atlanterhavet. (We flew over the Atlantic Ocean.) Jeg kan ikke lide aeg. (I don't like eggs.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2</head><label></label><figDesc>tatoeba.org/ (a) Distribution of the number of sentences in each language in the Tatoeba data set. (b) Distribution of the length of sentences in the Tatoeba data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Distribution of the lengths and language classes of Tatoeba sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Confusion matrix for FastText trained using only character level n-grams on the Wikipedia data set and evaluated on the Tatoeba data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Results for FastText trained w. char n-grams on Wikipedia+Tatoeba and evaluated on Tatoeba.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Distribution of sentence lengths Tatoeba test set along with the mis-classified sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Dimensionality reduction using PCA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Dimensionality reduction using t-SNE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overview of results for the neural network models for the data set with 10K data points in each language.</figDesc><table><row><cell>Model</cell><cell cols="2">Encoding Accuracy</cell></row><row><cell>Knn</cell><cell>skipgram</cell><cell>0.931</cell></row><row><cell cols="2">Logistic Regression skipgram</cell><cell>0.933</cell></row><row><cell>Naive Bayes</cell><cell>skipgram</cell><cell>0.806</cell></row><row><cell>SVM</cell><cell>skipgram</cell><cell>0.925</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Overview of results for the data set with 50K data points in each language.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>shows that the performance of the logistic regression model and the K-nearest-neighbors</figDesc><table><row><cell>Model</cell><cell>Encoding</cell><cell>Accuracy</cell></row><row><cell>MLP</cell><cell>char bi-gram</cell><cell>0.918</cell></row><row><cell>CNN</cell><cell>char bi-gram</cell><cell>0.970</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Overview of results for the data set with 50K data points in each language.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source: https://realpython.com/ python-keras-text-classification/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We compared four different classical models: K nearest Neighbors, Logistic regression, Naive Bayes and a linear support vector machines with two neural network architectures: Multilayer perceptron and a convolutional neural network. The two best performing models, FastText supervised and CNN, saw low performance when going offdomain. Using character n-grams as features instead of words increased the performance for the FastText supervised classifier. By also training FastText on the Tatoeba data set as well as the Wikipedia data set resulted in an additional increase in performance.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bornholmsk natural language processing: Resources and tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Speed Kjeldsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Nordic Conference on Computational Linguistics</title>
		<meeting>the 22nd Nordic Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="338" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Discriminating similar languages: Evaluations and explorations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>L?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding convolutional neural networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><forename type="middle">Sar</forename><surname>Shalom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5408</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The lacunae of danish natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kirkedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Nordic Conference on Computational Linguistics</title>
		<meeting>the 22nd Nordic Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="356" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nltk: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. Philadelphia: Association for Computational Linguistics</title>
		<meeting>the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. Philadelphia: Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Crossdomain feature selection for language identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th international joint conference on natural language processing</title>
		<meeting>5th international joint conference on natural language processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="553" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Langid.py: An off-the-shelf language identification tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations, ACL &apos;12</title>
		<meeting>the ACL 2012 System Demonstrations, ACL &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A report on the dsl shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Ljubesic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VarDial@COLING</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Overview of the dsl shared task 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Ljube?ic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>page 1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
