<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
							<email>amehri@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dialog Research Center</orgName>
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dialog Research Center</orgName>
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. USR is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level: 0.42, systemlevel: 1.0) and PersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces interpretable measures for several desirable properties of dialog. Metallinou, et al. 2018. On evaluating and comparing open domain dialog systems. arXiv preprint arXiv:1801.03625.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The lack of meaningful automatic evaluation metrics is a significant impediment for open-domain dialog generation research. Standard language generation metrics have been shown to be ineffective for dialog evaluation <ref type="bibr" target="#b1">(Deriu et al., 2019;</ref><ref type="bibr" target="#b12">Liu et al., 2016)</ref>. Without well-accepted, meaningful automatic metrics, open-domain dialog researchers have come to rely on human evaluation. Due to its time-and cost-intensive nature, human evaluation is typically only used for the final dialog model. As such, during development dialog systems are generally optimized for poorly-correlated automatic metrics (e.g., F-1, BLEU, PPL) which can result in sub-par human evaluation scores <ref type="bibr" target="#b3">(Dinan et al., 2019)</ref>. To facilitate development of opendomain dialog models with meaningful automatic metrics, this paper presents the UnSupervised and Reference free (USR) evaluation metric for dialog.</p><p>Standard automatic metrics for evaluating dialog generation (e.g., BLEU, F-1, METEOR, ROUGE) have several shortcomings that make them unsuitable for dialog evaluation: (1) The one-to-many nature of dialog <ref type="bibr">(Zhao et al., 2017)</ref> makes wordoverlap metrics ineffective for scoring valid system output that deviates from the ground-truth response <ref type="bibr" target="#b12">(Liu et al., 2016;</ref><ref type="bibr" target="#b7">Gupta et al., 2019)</ref>. (2) Human evaluation of dialog typically measures multiple properties (e.g., appropriate, interesting, consistent). Automatic metrics on the other hand, condense the multi-faceted nature of dialog quality to a single uninterpretable metric.</p><p>(3) There are many definitions of what a good dialog is and, as such, it is not feasible to construct a "one size fits all" metric. Depending on the task and the data, the desired qualities of a dialog system may differ <ref type="bibr">(Walker et al., 1997;</ref><ref type="bibr" target="#b1">Deriu et al., 2019)</ref>.</p><p>USR is a reference-free metric that consists of several interpretable sub-metrics which are combined in a configurable manner. Rather than relying on a ground-truth reference response, unsupervised models are trained to measure desired qualities of dialog (e.g., interesting, natural). As such, USR (1) alleviates the one-to-many issue of standard metrics, (2) produces interpretable measures for desirable properties of dialog, and (3) provides a configurable mechanism for combining several submetrics into an overall quality score.</p><p>To evaluate the performance of USR, human quality annotations were collected for models trained on the Topical-Chat <ref type="bibr" target="#b6">(Gopalakrishnan et al., 2019)</ref> and the PersonaChat corpora <ref type="bibr">(Zhang et al., 2018)</ref>. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level Spearman: 0.42, system-level Spearman: 1.0) and PersonaChat (turn-level Spearman: 0.48 and system-level Spearman: 1.0). The strong correlation with human judgment across two datasets and a variety of model types shows that USR is a valuable tool for the dialog community. Further, since USR does not require any explicit supervision, it has the potential to generalize to several dialog tasks and datasets. arXiv:2005.00456v1 [cs.CL] 1 May 2020</p><p>The contributions of this paper as as follows: (1) a strongly-correlated, unsupervised and reference free metric is proposed for evaluating open-domain dialog systems, (2) a thorough human quality annotation is carried out and is released 1 to facilitate future benchmarking of dialog evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Standard automatic metrics for language generation correlate poorly with human judgement of dialog <ref type="bibr" target="#b12">(Liu et al., 2016;</ref><ref type="bibr" target="#b14">Lowe et al., 2017;</ref><ref type="bibr" target="#b7">Gupta et al., 2019)</ref>. For example, the F-1 score can be gamed by outputting the most frequent words, regardless of the context <ref type="bibr" target="#b3">(Dinan et al., 2019)</ref>.</p><p>The poor performance of present metrics is largely due to the one-to-many nature of dialog <ref type="bibr">(Zhao et al., 2017)</ref>. To avoid comparing to a single reference response, several authors have proposed using multiple reference responses. Multiple reference responses can be obtained with retrieval models <ref type="bibr" target="#b5">(Galley et al., 2015;</ref><ref type="bibr" target="#b5">Sordoni et al., 2015)</ref> or through data collection <ref type="bibr" target="#b7">(Gupta et al., 2019)</ref>. These multi-reference metrics show improvement in performance, but it is infeasible to thoroughly cover the space of potential responses. As such, this paper addresses the one-to-many issue of dialog by presenting a reference-free metric. <ref type="bibr" target="#b14">Lowe et al. (2017)</ref> train ADEM to produce a quality score conditioned on the dialog context, the reference response and the generated response. <ref type="bibr">Venkatesh et al. (2018)</ref> present a framework for evaluation of Alexa prize conversations, which attains moderate correlation with user ratings. Both of these methods are trained on explicit quality annotations. In contrast, USR requires no explicit supervision and will more easily generalize to new datasets and tasks. <ref type="bibr" target="#b10">Li et al. (2017)</ref> proposes a reference-free dialog evaluator which is trained to discriminate between human and generated responses. This work is similar to USR in that it evaluates the quality of a response without a reference or quality annotation training data. Using the evaluation model as a reward during reinforcement learning exhibited strong performance. However, correlation with human judgement was not evaluated. Intuitively, it appears insufficient to rely on a discriminator as a meaningful evaluation of dialog since this assumes that all human responses are perfect and all generated responses are imperfect. 1 http://shikib.com/usr</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Human Quality Annotation</head><p>To evaluate the correlation of automatic metrics with human judgment, human quality annotation was carried out across two open-domain dialog corpora. Generated responses were obtained from several models described in Section 3.3. For each dialog context, an additional human response was also written. Human annotation was then carried out on sixty dialog contexts, with six responses per context for Topical-Chat (four system outputs, one newly-annotated human output, one original ground-truth response) and five for PersonaChat (one less system output). Each response was given six different scores: Understandable (0-1), Natural (1-3), Maintains Context (1-3), Interesting (1-3), Uses Knowledge (0-1), Overall Quality (1-5). Three annotators labeled each response.</p><p>The task instructions were very detailed in order to minimize subjectivity in the quality annotations. For example, individuals may differ in their definition of Interesting (e.g., some individuals find football interesting, others do not). Thus, the instructions contained a clear, albeit somewhat rigid definition, of Interesting. The instructions for Overall Quality annotation, however, were less rigid and therefore those annotations contain some amount of annotator-specific subjectivity.</p><p>The data collection and experiments with Per-sonaChat were carried out to assess the generality of the USR metric. As such, the annotation questions used were specifically tailored to Topical-Chat, but are still suitable for PersonaChat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topical-Chat Dataset</head><p>The Topical-Chat dataset <ref type="bibr" target="#b6">(Gopalakrishnan et al., 2019)</ref> is a large collection of human-human knowledge-grounded open-domain conversations that consists of 11,319 dialogs and 248,014 utterances. Following the same experimental setup as <ref type="bibr" target="#b6">Gopalakrishnan et al. (2019)</ref>, heuristics are employed to identify the most relevant fact for each response. As such, the task is to produce a response conditioned on both a dialog context and a fact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PersonaChat Dataset</head><p>The PersonaChat dataset <ref type="bibr">(Zhang et al., 2018)</ref> is a corpus of human-human persona-conditioned conversations that consists of 10,907 dialogs and 162,064 utterances. Each worker is asked to condition their responses on a persona, which we consider to be analogous to the facts in the Topical- <ref type="figure">Figure 1</ref>: On the Topical-Chat corpus, six responses are obtained for each dialog context. Four use the trained Transformer model with different decoding strategies. One is a new human-generated response. One is the original ground-truth. A similar setup was employed for PersonaChat, albeit with different models.</p><p>Chat corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Topical-Chat Models</head><p>A Transformer <ref type="bibr">(Vaswani et al., 2017)</ref> is trained to produce the response, r, conditioned on dialog context, c, and fact, f . The input to the transformer is the concatenation of c and f , similar to <ref type="bibr" target="#b6">Gopalakrishnan et al. (2019)</ref>. The transformer consists of 6 layers, a hidden size of 512, randomly-initialized word embeddings of size 300, a dropout rate of 0.1 and it is trained for 50 epochs.</p><p>A single Transformer model is trained, which matches the automatic metrics reported by <ref type="bibr" target="#b6">Gopalakrishnan et al. (2019)</ref>. Different decoding strategies are used to obtain four different outputs from this model. In addition to standard argmax sampling, nucleus sampling <ref type="bibr" target="#b8">(Holtzman et al., 2019)</ref> is used at three different rates: p = {0.3, 0.5, 0.7}. The outputs from these four decoding strategies are listed with the original ground-truth utterance and a new human-generated response, for a total of six responses for each context, as shown in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">PersonaChat Models</head><p>Three models were used to generate system outputs: a sequence-to-sequence model (Seq2Seq), an LSTM language model (LM) and a Key-Value Profile Memory Network (KV-MemNN). We use the pre-trained models provided in ParlAI 2 for the ConvAI2 competition <ref type="bibr" target="#b3">(Dinan et al., 2019)</ref>.</p><p>A fourth open-source model was also used to produce output for quality annotation, however it was ultimately excluded from the released dataset and experiments due to possible data leakage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Annotation</head><p>Quality annotation was performed by six dialog researchers. Using a crowdsourcing platform, such as Amazon Mechanical Turk (AMT), would have allowed for more efficient and scalable annotation. However, crowdsourcing was not used because (1) the annotation instructions are lengthy, (2) a preliminary annotation pass was carried out, followed by a group discussion, (3) having many annotations from a few annotators allows examination of annotator-specific subjectivity.</p><p>Annotators were provided with a set of instructions (Appendix A). A small preliminary annotation pass was carried out, with each individual annotating 5 dialog contexts (for a total of 30 responses). The inter-annotator agreement was computed for each of the questions. The instructions were refined after the preliminary pass and a discussion meeting (e.g., Maintains Context was changed to be a 3-point rating instead of a 2-point rating). After the instructions were modified, the full annotation pass was carried out.</p><p>Each response was rated according to the qualities mentioned at the beginning of this section. Instructions for each of qualities are summarized below:</p><p>? Understandable (0 -1): Is the response understandable given the previous context?</p><p>? Natural (1 -3): Does the response seem to be something that a person would naturally say?</p><p>? Maintains Context (1 -3): Does the response serve as a valid continuation of the preceding conversation?</p><p>? Interesting (1 -3): Is the response dull or interesting?</p><p>? Uses Knowledge (0 -1): Given the fact that the response is conditioned on, how well does the response use that fact?</p><p>? Overall Quality (1 -5): Given your answers above, what is your overall impression of the quality of this utterance? The instructions contained detailed descriptions and examples of what constitutes a response in each category (e.g., what makes a response score 2 on Maintains Context). These instructions were written to minimize subjectivity in the annotations, which results in clear, agreed upon definitions.</p><p>For Topical-Chat, the full annotation consisted of 60 dialog contexts randomly sampled from the frequent test set, for a total of 360 responses scored on six different qualities. For PersonaChat, 60 dialog contexts were sampled from the ConvAI2 validation set, with a total of 300 responses scored on six different qualities. Each response was labeled by three different annotators. Annotators were randomly assigned to each dialog context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Analysis</head><p>Inter-annotator agreements for the different ratings across both datasets are presented in <ref type="table">Table 1</ref>. The correlation between each pair of annotations is computed and the average correlation over all the pairs is reported. Correlation is used instead of Cohen's Kappa in order to better account for the ordinal nature of the ratings (i.e., 4 should correlate better with 5 than 1), and to maintain consistency with the evaluation of the automatic metrics. Most inter-annotator correlations are above 0.4, which indicates moderate to strong agreement. The low agreement for Understandable on PersonaChat is likely a consequence of the simple language in the dataset. Most responses are understandable, except for those requiring background knowledge (e.g., that 'cod' is an acronym for 'Call of Duty'). Since the annotators have differing background knowledge, the few occasions where they fail to understand an utterance will differ, hence the lower agreement. The agreement for Overall Quality is relatively high (0.71 for Topical-Chat and 0.66 for PersonaChat) which suggests that any ambiguity in the specific dialog qualities is mitigated when the annotator is asked for an overall impression. <ref type="table" target="#tab_2">Table 2</ref> presents the scores for the different systems on each of the six qualities. Across both datasets and all qualities, the new human generated response strongly outperforms all other response types, even the original ground truth. This may be because the new human generated response was written with this quality annotation in mind, and as such is optimized for turn-level evaluation. On the other hand, the workers who produced the original ground-truth response, were more concerned with the quality of the overall dialog than with the quality of each individual response.</p><p>On the Topical-Chat corpus, argmax decoding has a moderately higher performance over the nucleus sampling <ref type="bibr" target="#b8">(Holtzman et al., 2019)</ref> methods. This should not be taken as an indication that argmax decoding is the superior method, since the hyperparameters (e.g., temperature) were not tuned for nucleus sampling. It should be noted that the objective was not to train and evaluate the best performing models, but instead to produce responses of varying qualities and obtain accurate human judgements of these responses.</p><p>A regression was trained to map from the five ratings to the overall score in order to analyze the relationship between them. For better interpretability of the regression weights, the scores were normalized (using z-score) before training the regression. For better interpretability, a softmax was computed over the weights. Since individuals may differ in their definition of a good response, a specific regression is trained for each of the five annotators who labeled responses for the Topical-Chat corpus. <ref type="figure" target="#fig_0">Figure 2</ref> displays the weights attributed to each of the five qualities by each of the annotators.</p><p>Annotators attributed different weights to the specific features. For example, A3 emphasized naturalness while A2 paid more attention to whether a response was grounded on knowledge. Despite the differences across annotators, a good response was generally expected to be natural, maintain con-   text, and be interesting. These annotator-specific weights demonstrate that individuals define good dialog differently. Future work could explore personalized dialog evaluation wherein the evaluation metric is tailored to a specific individual. A potential criticism of this quality annotation could be that certain dialog qualities are missing. To address concerns about the completeness of the set of five qualities, a regression can be trained to produce the overall score conditioned on the quality ratings. The Spearman correlation between the predicted score and the original overall score is 0.9654, which signifies that the set of qualities is thorough and contains enough information to reflect the overall quality of the response.</p><formula xml:id="formula_0">System Und (0-1) Nat (1-3) MCtx (1-3) Int (1-3) UK (0-1) OQ (1-5) Topical-Chat Original Ground-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Automatic Metrics</head><p>This section describes the automatic metrics explored for evaluating generated responses. Section 4.1 describes several existing metrics that were studied. Section 4.2 presents USR, a novel unsupervised and reference-free metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Metrics</head><p>Several existing and easily-applicable metrics for dialog evaluation are compared. the list of available metrics is not exhaustive. Only the most commonly used and the most accessible are addressed.</p><p>F-1 score computes the word-overlap between the generated response and the ground-truth, by taking the harmonic mean of the precision and recall. It is one of the four metrics used by the creators of the Topical-Chat dataset <ref type="bibr" target="#b6">(Gopalakrishnan et al., 2019)</ref>, along with perplexity and unique unigram/bigram counts. Dinan et al. (2019) described a simple adversarial example that attains a high F-1 score on PersonaChat. We produce a similar example for the Topical-Chat dataset and find that always outputting a concatenation of the ten most common tokens in the dataset (". i the , that a to it is of") attains an F-1 score of 25.6 which is a +3.6 improvement over the Transformer presented by <ref type="bibr" target="#b6">Gopalakrishnan et al. (2019)</ref>.</p><p>BLEU <ref type="bibr" target="#b17">(Papineni et al., 2002)</ref> is a well-known word overlap metric that computes n-gram precision between the generated sequence and the reference. Because precision favors shorter sentences, BLEU also adds a brevity penalty that punishes shorter sentences. BLEU has been found to correlate poorly with human judgment <ref type="bibr" target="#b12">(Liu et al., 2016;</ref><ref type="bibr" target="#b14">Lowe et al., 2017;</ref><ref type="bibr" target="#b7">Gupta et al., 2019)</ref>.</p><p>METEOR <ref type="bibr" target="#b0">(Denkowski and Lavie, 2014)</ref> was designed as an improvement on BLEU using a harmonic mean of precision and recall, as well as stemming and synonyms. ROUGE-L <ref type="bibr" target="#b11">(Lin, 2004)</ref> identifies the longest common subsequence between the generated and reference sequence to better account for sentencelevel structure when computing word overlap.</p><p>Greedy Matching <ref type="bibr" target="#b18">(Rus and Lintean, 2012)</ref> is an embedding-based metric that greedily matches each word in the generated sequence to a reference word based on the cosine similarity of their embeddings. The final score is then an average over all the words in the generated sequence.</p><p>Embedding Average (Wieting et al., 2015) computes a sentence embedding for both the generated sequence and the ground-truth response by taking an average of word embeddings. The score is then a cosine similarity of the average embedding for both the generated and reference sequence.</p><p>Vector Extrema <ref type="bibr" target="#b4">(Forgues et al., 2014</ref>) follows a similar setup to Embedding Average, where the score is the cosine similarity between sentence embeddings. Rather than taking an average over word embeddings, this method identifies the maximum value for each dimension of the word embedding. Taking the maximum is motivated by the idea that common words will be de-emphasized as they will be closer to the origin. Vector Extrema has been shown to perform better on dialog tasks than other metrics <ref type="bibr" target="#b7">(Gupta et al., 2019;</ref><ref type="bibr" target="#b12">Liu et al., 2016)</ref>.</p><p>Skip-Thought <ref type="bibr" target="#b9">(Kiros et al., 2015)</ref> uses a recurrent neural network to produce a sentence-level embedding for the generated and reference sequences. A cosine similarity is then computed between the two embeddings. The implementation provided by <ref type="bibr" target="#b19">Sharma et al. (2017)</ref> is used.</p><p>BERTScore (Zhang et al., 2019) uses a pretrained BERT <ref type="bibr" target="#b2">(Devlin et al., 2018)</ref> model to greedily match each word in a reference response with one word in the generated sequence. By doing so, it computes the recall of the generated sequence. BERTScore was shown to have strong system-level and segment-level correlation with human judgment on several machine translation and captioning tasks. However, although it is a more sophisticated metric, it still compares word similarity between a reference and a generated sequence. While this method may work well for tasks where there is a limited space of outputs for each input (e.g., captioning, translation), it is ineffective at dealing with the one-to-many nature of dialog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Proposed Metric</head><p>This section proposes describes the USR metric, an unsupervised, reference-free evaluation metric for dialog. USR leverages pre-trained language models, specifically RoBERTa <ref type="bibr" target="#b13">(Liu et al., 2019)</ref>, to measure properties of dialog. USR is designed to be reference-free because there is no one right answer due to the inherent one-to-many nature of dialog <ref type="bibr">(Zhao et al., 2017)</ref>.</p><p>Several sub-metrics were developed for the different qualities of dialog (e.g., Natural, Interesting, Uses Knowledge). While USR measures the overall quality of a response, its sub-metrics assess specific dialog qualities and therefore facilitate better understanding of a model's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Masked Language Modelling Metric</head><p>The masked language modelling (MLM) metric uses a fine-tuned RoBERTa <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> model to estimate the likelihood of a response. RoBERTa is pre-trained on a massive amount of English data and fine-tuned on the corpus being evaluated (either Topical-Chat or PersonaChat), making it capable of identifying unnatural and incorrect responses. The likelihood estimated by the fine-tuned RoBERTa model is used as an automatic metric for evaluating the understandability and naturalness of responses.</p><p>The RoBERTa-base model <ref type="bibr" target="#b13">(Liu et al., 2019</ref>) is fine-tuned on the training set of the Topical-Chat corpus <ref type="bibr" target="#b6">(Gopalakrishnan et al., 2019)</ref>  The language model is fine-tuned on only the dialog, without any of the facts, for a single epoch.</p><p>RoBERTa uses both past and future context to predict a probability distribution for a masked word. The input sequence to MLM is a concatenation of a dialog context, c, and a response, r. One word at a time, each word in r is masked and its log likelihood is computed. Given the masked loglikelihood for the i-th word of r as l i , the value of the metric is then computed to be ? |r| i l i . <ref type="figure" target="#fig_2">Figure  3</ref> visualizes this process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Dialog Retrieval Metrics</head><p>Recent research has highlighted the complementary nature of dialog retrieval and generation with respect to multi-tasking (Wolf et al., 2019b) and pre-training . Because of this complimentary nature, using dialog retrieval (DR) for evaluating generative models is an intuitive choice, especially for metrics like Maintains Context and Uses Knowledge. The fine-tuned RoBERTa model described in Section 4.2.1 is further fine-tuned for the retrieval task. This task is set up in the same manner as the Ubuntu dialog corpus <ref type="bibr" target="#b15">(Lowe et al., 2015)</ref>. The model is trained given a context x, a response r, and a binary label y indicating whether r is the true response or randomly sampled. The context x may consist of the dialog history and the fact, denoted c, or just the fact, denoted f . Two different versions of the dialog retrieval (DR) metric are trained, with different values of x. The DR metric score is defined to be the probability P (y = 1| x, r) a given DR metric model produces.</p><p>Though the DR metric is trained for the task of retrieval, this is done in an unsupervised manner. The retrieval task is an unsupervised task since it requires no additional labels during training (e.g., explicit quality annotations).</p><p>The DR metric is appropriate for Maintains Context, Interesting and Uses Knowledge. If a retrieval model predicts that a generated response is contextually relevant to a dialog context, it indicates that the response Maintains Context. Likewise, if a retrieval model predicts that the response r is contextually relevant to fact f , it signifies that r most likely Uses Knowledge.</p><p>Interesting is the measure of whether the response is dull/generic or if it provides some interesting/engaging information. The DR metric is trained to distinguish between a ground-truth response (y = 1) and a randomly sampled response (y = 0). Generic responses are applicable to many contexts, and will often appear as both groundtruth responses and randomly sampled responses. As such, the model will likely learn to assign a low probability distribution to these generic responses and will often output P (y = 1| r, x) = 0.5. As such, generic responses will generally be scored lower than other contextually relevant, interesting responses. The DR metrics will learn to favor responses that are unique to a given context x, rather than being applicable to many different contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">The USR Metric</head><p>Given meaningful automatic metrics for each of the five dialog qualities, USR combines the scores into an overall measure that correlates well with Overall Quality ratings.</p><p>In Section 3.5, a regression model was trained to reproduce the overall score from each of the specific quality scores. The predictions of this regression model attained a 0.9654 Spearman correlation with the original scores. This same regression is used by USR on top of the automatic metrics presented in Sections 4.2.1 and 4.2.2.</p><p>USR combines its sub-metrics into one measure of overall quality. This combination is configurable, adaptable to different datasets or tasks. For example, if a specific application prefers natural responses over interesting ones, the weights of the regression model can be adjusted. Analysis demonstrated that individuals used different weights when producing the overall score ( <ref type="figure" target="#fig_0">Figure 2)</ref>. USR might be able to be personalized for specific individuals by adjusting the weights of the regression model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>This section evaluates all of the automatic metrics described in Section 4, by comparing them to human judgement. The best sub-metrics for each dialog quality are used as input for the regression model of the USR metric. While the best performing sub-metrics are not consistent across the two datasets, the USR metric nonetheless exhibits strong results. The annotations for the original ground-truth are not used for evaluation, in order to accurately compare referenced and reference-free metrics. <ref type="table" target="#tab_4">Table 3</ref> shows turn-level correlations of the best automatic metrics for each dialog quality on Topical-Chat. USR is shown to strongly outperform both word-overlap and embedding-based metrics across all of the dialog qualities. Interestingly, the best non-USR metric is consistently either ME-TEOR or BERTScore -possibly because both methods are adept at comparing synonyms during evaluation. For some dialog qualities, the overall USR metric outperforms the best sub-metric. For example, USR does better for Maintains Context  than USR-DR. This is likely because the information from the other sub-metrics (e.g., Uses Knowledge) is valuable and effectively leveraged by USR. <ref type="table" target="#tab_6">Table 4</ref> reports the turn-level correlations of the best automatic metrics for each dialog quality on the PersonaChat corpus. Across all dialog qualities, USR strongly outperforms the word-overlap and embedding-based metrics. Conversations in PersonaChat generally consist of individuals communicating facts from their own persona in a relevant and coherent manner. As such, when models trained on PersonaChat produce subpar outputs, it is generally because the outputs either (1) do not effectively use the persona or (2) are not relevant/coherent to the dialog context. This explains why the correlations are significantly higher for Maintains Context and Uses Knowledge. As a consequence of PersonaChat's strong dependency on both the dialog context and the persona, USR-DR (x = c) which uses both the dialog context and the persona to perform dialog retrieval, generally outperforms all other metrics.    the automatic metrics. USR shows a strong improvement over all other methods. This strong performance can be attributed to two factors: (1) the ability of MLM and DR to accurately quantify qualities of a generated response without a reference response, and (2) the ability of USR to effectively combine MLM and DR into a better correlated overall metric.</p><p>USR shows a similar improvement over all other metrics on PersonaChat, as shown in <ref type="table" target="#tab_8">Table 6</ref>. However, DR (x = c) outperforms USR despite the fact that four out of the five sub-metrics input into the USR regression are DR (x = c). This result is probably due to PersonaChat's strong dependancy on both dialog context and persona, both of which DR (x = c) explicitly leverages. We compute the system-level correlation between all automatic metrics and the Overall Quality ratings. USR significantly (p &lt; 0.01) outperforms all other metrics with a Spearman correlation of 1.0 on both datasets and Pearson correlations of 0.92 (Topical-Chat) and 0.82 (PersonaChat). The full set of system-level correlations can be found in the appendix.</p><p>These results demonstrate USR's effectiveness. It strongly outperforms other metrics on both turnlevel and system-level correlations. <ref type="bibr" target="#b6">Gopalakrishnan et al. (2019)</ref> use the F-1 score as their primary automatic evaluation metric when presenting Topical-Chat. The results demonstrate a significant difference between USR and the F-1 score, suggesting that USR is a better metric for the Topical-Chat corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>USR achieves statistically significant correlations with human judgement. The results hold across two datasets, Topical-Chat <ref type="bibr" target="#b6">(Gopalakrishnan et al., 2019)</ref> and <ref type="bibr">PersonaChat (Zhang et al., 2018)</ref>.</p><p>USR is configurable. Notably it is composed of several specific dialog quality sub-metrics. These sub-metrics are combined in a configurable manner, using a regression. For other tasks, datasets or even users, this regression can be adjusted, allowing qualities to be removed or re-weighted. Additional sub-metrics could be added.</p><p>USR should be used alongside human evaluation. USR was created to facilitate development and tuning of dialog models. As such, USR can be used for model selection and hyperparameter tuning. USR should not be used to claim superior performance over another method.</p><p>USR may not work with non-generative models, which were not addressed here. Responses produced by a model that is too similar to the evaluation models (e.g., to DR) are a particular concern.</p><p>7 Conclusions This paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. To address the shortcomings of standard metrics for language generation, USR (1) is reference-free, (2) is composed of multiple sub-metrics that evaluate specific qualities of dialog, (3) has a definition of good dialog that is configurable. Thus the metric may be adapted to different tasks and datasets. USR is shown to strongly correlate with human judgment on Topical-Chat (turn-level: 0.42, system-level: 1.0) and PersonaChat (turn-level: 0.48, systemlevel: 1.0).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Metric Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Code and Data Release</head><p>The code for the metrics can be found at https:// github.com/shikib/usr and the human quality annotations can be found at http://shikib.com/ usr. The human quality annotations will allow benchmarking of additional metrics.</p><p>Annotation Instructions You will be given a conversation between two individuals. You will then be given several potential responses for the next turn in the conversation. These responses all concern an interesting fact, which will be provided as well. Your task is to rate each of the responses on several metrics. The response for one metric should not influence the other metrics. For example, if a response is not understandable or has grammatical errorsyou should try to ignore this when considering whether it maintains context or if it is interesting. Please make sure you read and understand these instructions carefully. Feel free to ask if you require clarification. Please keep this document open while reviewing, and refer to it as needed. Understandable (0-1) Is the response understandable in the context of the history? (Not if its on topic, but for example if it uses pronouns they should make sense)</p><p>? A score of 0 (no) means that the response is difficult to understand. You do not know what the person is trying to say.</p><p>i did n't know that . i love to watch the movie inception , it 's also the first racing movie to be a woman haha . i guess the movie was originally titled " inception " awesome movie ! -Context: in my religion , there is no star . how about you Response: yeah it was back in 1975 .</p><p>? A score of 1 (yes) means that the response is understandable. You know what the person is trying to say.</p><p>my favorite role would have to be quarterback . it is such an interesting role . that is true . i think lebron is the highest paid celebrity , i wonder if he will be in the space jam sequel .</p><p>Natural (1-3) Is the response naturally written?</p><p>? A score of 1 (bad) means that the response is unnatural.</p><p>-Context: A: wow . do you believe in stars of the zodiac ? what is your star ? B: in my religion , there is no star . how about you Response: yeah , it was back in 1975 . i think he is , he is a great teacher and he also taught ellie kemper , she is a great teacher</p><p>? A score of 2 (ok) means the response is strange, but not entirely unnatural.</p><p>-Context: A: wow . do you believe in stars of the zodiac ? what is your star ? B: in my religion , there is no star . how about you Response: i read it sometimes for the fun of it .</p><p>? A score of 3 (good) means that the response is natural.</p><p>i think it 's funny that the soviet union sent a spacecraft to venus . Does the response serve as a valid continuation of the conversation history?</p><p>? A score of 1 (no) means that the response drastically changes topic or ignores the conversation history.</p><p>-Context: A: wow . do you believe in stars of the zodiac ? what is your star ? B: in my religion , there is no star . how about you Response: i think it 's funny that the soviet union sent a spacecraft to venus .</p><p>? A score of 2 (somewhat) means the response refers to the conversation history in a limited capacity (e.g., in a generic way) and shifts the conversation topic.</p><p>-Context: i do like some drama stuff , yeah he was awesome in that . Response: yeah . do you like jon hamm ? -Context: i believe that ! he would have played longer i 'm sure if he did the granny style approach to shooting freethrows ! Response: i agree . did you know that space jam is the highest grossing basketball movie of all time ?</p><p>? A score of 3 (yes) means the response is on topic and strongly acknowledges the conversation history.</p><p>-Context: B: wow , that 's great . especially because more than of nba players go broke 5 years after retirement . A: i believe that ! he would have played longer i 'm sure if he did the granny style approach to shooting freethrows ! Response: a lot of players can make money by starring in movies . did you know space jam is the highest grossing movie of all time ? maybe one of the broke retired players can be in the sequel ! -Context: B: you like drama ? patrick stewart teaches classes now . i loved him in star trek A: i do like some drama stuff , yeah he was awesome in that . Response: jonn hamm was also a drama teacher . he taught erin from the office</p><formula xml:id="formula_1">Interesting (1-3)</formula><p>Is the response dull/interesting?</p><p>? A score of 1 (dull) means that the response is generic and dull.</p><p>thats true . i agree .</p><p>? A score of 2 (somewhat interesting) means the response is somewhat interesting and could engage you in the conversation (e.g., an opinion, thought)</p><p>my favorite role would have to be quarterback . it is such an interesting role .</p><p>i love tom brady . i love tom brady .</p><p>? A score of 3 (interesting) means the response is very interesting or presents an interesting fact i agree . did you know that space jam is the highest grossing basketball movie of all time ? a lot of players can make money by starring in movies . did you know space jam is the highest grossing movie of all time ? maybe one of the broke retired players can be in the sequel ! Annotation Instructions (ctd.) Uses Knowledge (0-1)</p><p>Given the interesting fact that the response is conditioned on, how well does the response use the fact?</p><p>? A score of 0 (no) means the response does not mention or refer to the fact at all ? A score of 1 (yes) means the response uses the fact well Overall Quality (1-3) Given your answers above, what is your overall impression of this utterance?</p><p>? A score of 1 (very bad). A completely invalid response. It would be difficult to recover the conversation after this.</p><p>? A score of 2 (bad). Valid response, but otherwise poor in quality.</p><p>? A score of 3 (neutral) means this response is neither good nor bad. This response has no negative qualities, but no positive ones either.</p><p>? A score of 4 (good) means this is a good response, but falls short of being perfect because of a key flaw.</p><p>? A score of 5 (very good) means this response is good and does not have any strong flaws.             </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Weight attributed to each of the five specific metrics by each annotator, when labeling Overall Quality. Lighter colors signify more weight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>using the implementation open-sourced by Wolf et al. (2019a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Visualization of the masked language modelling (MLM) metric. Context words are in grey; response words are in red. The red words are masked, and RoBERTa must predict the likelihood of their true value (shown in green).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Average scores for the six different responses, on the six quality: Understandable, Natural, Maintains Context, Interesting, Uses Knowledge and Overall Quality.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Turn-level correlations on Topical-Chat. We show: (1) best non-USR metric, (2) best USR sub- metric and (3) USR metric. All measures in this table are statistically significant to p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>shows turn-level correlation with the</cell></row><row><cell>Overall Quality ratings on Topical-Chat, for all of</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>Metric</cell><cell cols="2">Spearman Pearson</cell></row><row><cell cols="2">Word-Overlap Metrics</cell><cell></cell></row><row><cell>F-1</cell><cell>0.1645</cell><cell>0.1690</cell></row><row><cell>BLEU-1</cell><cell>0.2728</cell><cell>0.2876</cell></row><row><cell>BLEU-2</cell><cell>0.2862</cell><cell>0.3012</cell></row><row><cell>BLEU-3</cell><cell>0.2569</cell><cell>0.3006</cell></row><row><cell>BLEU-4</cell><cell>0.2160</cell><cell>0.2956</cell></row><row><cell>METEOR</cell><cell>0.3365</cell><cell>0.3908</cell></row><row><cell>ROUGE-L</cell><cell>0.2745</cell><cell>0.2870</cell></row><row><cell cols="2">Embedding Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.1712</cell><cell>0.1943</cell></row><row><cell>Embedding Average</cell><cell>0.1803</cell><cell>0.2038</cell></row><row><cell>Vector Extrema</cell><cell>0.2032</cell><cell>0.2091</cell></row><row><cell>Skip-Thought</cell><cell>0.1040</cell><cell>0.1181</cell></row><row><cell>BERTScore (base)</cell><cell>0.3229</cell><cell>0.3540</cell></row><row><cell>BERTScore (large)</cell><cell>0.2982</cell><cell>0.3252</cell></row><row><cell cols="2">Reference Free Metrics</cell><cell></cell></row><row><cell>USR -MLM</cell><cell>0.3086</cell><cell>0.3345</cell></row><row><cell>USR -DR (x = c)</cell><cell>0.3245</cell><cell>0.4068</cell></row><row><cell>USR -DR (x = f)</cell><cell>0.1419</cell><cell>0.3221</cell></row><row><cell>USR</cell><cell>0.4192</cell><cell>0.4220</cell></row></table><note>Turn-level correlations on Persona-Chat. We show: (1) best non-USR metric, (2) best USR sub- metric and (3) USR metric. All values with p &gt; 0.05 are italicized.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell>Metric</cell><cell cols="2">Spearman Pearson</cell></row><row><cell cols="2">Word-Overlap Metrics</cell><cell></cell></row><row><cell>F-1</cell><cell>0.1422</cell><cell>0.1241</cell></row><row><cell>BLEU-1</cell><cell>0.0434</cell><cell>0.0469</cell></row><row><cell>BLEU-2</cell><cell>0.1122</cell><cell>0.0943</cell></row><row><cell>BLEU-3</cell><cell>0.1202</cell><cell>0.0924</cell></row><row><cell>BLEU-4</cell><cell>0.1353</cell><cell>0.0899</cell></row><row><cell>METEOR</cell><cell>0.2527</cell><cell>0.2713</cell></row><row><cell>ROUGE-L</cell><cell>0.0659</cell><cell>0.0385</cell></row><row><cell cols="2">Embedding Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0916</cell><cell>0.0625</cell></row><row><cell>Embedding Average</cell><cell>0.1182</cell><cell>0.1428</cell></row><row><cell>Vector Extrema</cell><cell>0.1570</cell><cell>0.1410</cell></row><row><cell>Skip-Thought</cell><cell>-0.0393</cell><cell>-0.0452</cell></row><row><cell>BERTScore (base)</cell><cell>0.1690</cell><cell>0.1526</cell></row><row><cell>BERTScore (large)</cell><cell>0.1518</cell><cell>0.1211</cell></row><row><cell cols="2">Reference Free Metrics</cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.0795</cell><cell>0.0788</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0495</cell><cell>-0.0454</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.4814</cell><cell>0.6087</cell></row><row><cell>USR</cell><cell>0.4693</cell><cell>0.4115</cell></row></table><note>Turn-level correlations between all automatic metrics and the Overall Quality ratings for the Topical- Chat corpus. All values with p &gt; 0.05 are italicized.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Turn-level correlations between all automatic metrics and the Overall Quality ratings for the Per- sonaChat corpus. All values with p &gt; 0.05 are itali- cized.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Tables 6, 7 and 8 show the annotation instructions used for human quality annotation. These instructions and examples are verbatim what was shown to the annotators.</figDesc><table><row><cell cols="2">Marilyn A Walker, Diane J Litman, Candace A Kamm,</cell></row><row><cell cols="2">and Alicia Abella. 1997. Paradise: A framework for</cell></row><row><cell cols="2">evaluating spoken dialogue agents. arXiv preprint</cell></row><row><cell>cmp-lg/9704004.</cell><cell></cell></row><row><cell cols="2">John Wieting, Mohit Bansal, Kevin Gimpel, and</cell></row><row><cell cols="2">Karen Livescu. 2015. Towards universal para-</cell></row><row><cell>phrastic sentence embeddings.</cell><cell>arXiv preprint</cell></row><row><cell>arXiv:1511.08198.</cell><cell></cell></row><row><cell cols="2">Thomas Wolf, Lysandre Debut, Victor Sanh, Julien</cell></row><row><cell cols="2">Chaumond, Clement Delangue, Anthony Moi, Pier-</cell></row><row><cell cols="2">ric Cistac, Tim Rault, R'emi Louf, Morgan Funtow-</cell></row><row><cell cols="2">icz, and Jamie Brew. 2019a. Huggingface's trans-</cell></row><row><cell cols="2">formers: State-of-the-art natural language process-</cell></row><row><cell>ing. ArXiv, abs/1910.03771.</cell><cell></cell></row><row><cell cols="2">Thomas Wolf, Victor Sanh, Julien Chaumond, and</cell></row><row><cell cols="2">Clement Delangue. 2019b. Transfertransfo: A</cell></row><row><cell cols="2">transfer learning approach for neural network</cell></row><row><cell>based conversational agents.</cell><cell>arXiv preprint</cell></row><row><cell>arXiv:1901.08149.</cell><cell></cell></row><row><cell cols="2">Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur</cell></row><row><cell cols="2">Szlam, Douwe Kiela, and Jason Weston. 2018. Per-</cell></row><row><cell cols="2">sonalizing dialogue agents: I have a dog, do you</cell></row><row><cell cols="2">have pets too? arXiv preprint arXiv:1801.07243.</cell></row><row><cell cols="2">Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q</cell></row><row><cell cols="2">Weinberger, and Yoav Artzi. 2019. Bertscore: Eval-</cell></row><row><cell cols="2">uating text generation with bert. arXiv preprint</cell></row><row><cell>arXiv:1904.09675.</cell><cell></cell></row><row><cell cols="2">Tiancheng Zhao, Ran Zhao, and Maxine Eskenazi.</cell></row><row><cell cols="2">2017. Learning discourse-level diversity for neural</cell></row><row><cell cols="2">dialog models using conditional variational autoen-</cell></row><row><cell cols="2">coders. arXiv preprint arXiv:1703.10960.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>in the main paper showed turn-level cor-</cell></row><row><cell>relations for each specific quality. Due to space</cell></row><row><cell>limitations, the table only included results for only</cell></row><row><cell>the best correlated metrics. The full results are</cell></row><row><cell>shown in Tables 9 -21.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Annotation instructions (part 1 of 3).</figDesc><table><row><cell>Annotation Instructions (ctd.)</cell></row><row><cell>Maintains</cell></row><row><cell>Context</cell></row><row><cell>(1-3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>: Annotation instructions (part 2 of 3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell>: Annotation instructions (part 3 of 3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Correlations of all the metrics with Overall Quality ratings on Topical-Chat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.1422</cell><cell>0.1241</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>0.0434</cell><cell>0.0469</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>0.1122</cell><cell>0.0943</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>0.1202</cell><cell>0.0924</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>0.1353</cell><cell>0.0899</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>0.2527</cell><cell>0.2713</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>0.0659</cell><cell>0.0385</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0916</cell><cell>0.0625</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average 0.1182</cell><cell>0.1428</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>0.1570</cell><cell>0.1410</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>-0.0393</cell><cell>-0.0452</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.1690</cell><cell>0.1526</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>0.1518</cell><cell>0.1211</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.0795</cell><cell>0.0788</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.4814</cell><cell>0.6087</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0495</cell><cell>-0.0454</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.4693</cell><cell>0.4115</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Correlations of all the metrics with Overall Quality ratings on PersonaChat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.0425</cell><cell>0.0620</cell><cell>0.8000</cell><cell>0.6481</cell></row><row><cell>BLEU-1</cell><cell>0.1794</cell><cell>0.1522</cell><cell>0.6000</cell><cell>0.8360</cell></row><row><cell>BLEU-2</cell><cell>0.2360</cell><cell>0.2081</cell><cell>0.7000</cell><cell>0.8262</cell></row><row><cell>BLEU-3</cell><cell>0.2099</cell><cell>0.2137</cell><cell>0.7000</cell><cell>0.9018</cell></row><row><cell>BLEU-4</cell><cell>0.2010</cell><cell>0.2175</cell><cell>0.7000</cell><cell>0.8663</cell></row><row><cell>METEOR</cell><cell>0.2452</cell><cell>0.2246</cell><cell>0.7000</cell><cell>0.9424</cell></row><row><cell>ROUGE-L</cell><cell>0.2069</cell><cell>0.1632</cell><cell>0.7000</cell><cell>0.8208</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0839</cell><cell>0.0868</cell><cell>0.6000</cell><cell>0.5664</cell></row><row><cell cols="2">Embedding Average 0.0509</cell><cell>0.0961</cell><cell>0.6000</cell><cell>0.9204</cell></row><row><cell>Vector Extrema</cell><cell>0.1561</cell><cell>0.1321</cell><cell>0.6000</cell><cell>0.6113</cell></row><row><cell>Skip-Thought</cell><cell>0.0810</cell><cell>0.0706</cell><cell>0.2000</cell><cell>0.4725</cell></row><row><cell>BERTScore (base)</cell><cell>0.2611</cell><cell>0.2502</cell><cell>0.7000</cell><cell>0.9118</cell></row><row><cell>BERTScore (large)</cell><cell>0.2556</cell><cell>0.2263</cell><cell>0.7000</cell><cell>0.8577</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.3264</cell><cell>0.3268</cell><cell>0.7000</cell><cell>0.4666</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.1500</cell><cell>0.2213</cell><cell>0.9000</cell><cell>0.9337</cell></row><row><cell>USR-DR (x = f)</cell><cell>0.0881</cell><cell>0.1967</cell><cell>0.7000</cell><cell>0.8420</cell></row><row><cell>USR</cell><cell>0.2932</cell><cell>0.3152</cell><cell>0.9000</cell><cell>0.9329</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>Correlations of all the metrics with the Understandable ratings on Topical-Chat. All values with p ? 0.05 are italicized. The USR-MLM metric has poor system-level correlations, however the USR metric leverages predictions from the other sub-metrics to improve this.</figDesc><table><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>-0.0340</cell><cell>-0.0550</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>0.0123</cell><cell>-0.0196</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>0.0854</cell><cell>0.0221</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>0.0412</cell><cell>0.0249</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>0.0537</cell><cell>0.0279</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>0.0820</cell><cell>0.0431</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>0.0346</cell><cell>0.0076</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0594</cell><cell>0.0710</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average 0.0573</cell><cell>0.0835</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>0.1097</cell><cell>0.1113</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>-0.0338</cell><cell>-0.0297</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.0676</cell><cell>0.0685</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>0.0380</cell><cell>0.0086</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.1313</cell><cell>0.1186</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.0728</cell><cell>0.1446</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0390</cell><cell>-0.0433</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.0997</cell><cell>0.1337</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 13 :</head><label>13</label><figDesc>Correlations of all the metrics with Understandable ratings on PersonaChat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.0301</cell><cell>0.0398</cell><cell>0.6000</cell><cell>0.5605</cell></row><row><cell>BLEU-1</cell><cell>0.1606</cell><cell>0.1334</cell><cell>0.7000</cell><cell>0.7976</cell></row><row><cell>BLEU-2</cell><cell>0.1959</cell><cell>0.1648</cell><cell>0.9000</cell><cell>0.7888</cell></row><row><cell>BLEU-3</cell><cell>0.1896</cell><cell>0.1745</cell><cell>0.9000</cell><cell>0.8979</cell></row><row><cell>BLEU-4</cell><cell>0.1799</cell><cell>0.1748</cell><cell>0.9000</cell><cell>0.8973</cell></row><row><cell>METEOR</cell><cell>0.2121</cell><cell>0.1906</cell><cell>0.9000</cell><cell>0.9297</cell></row><row><cell>ROUGE-L</cell><cell>0.1760</cell><cell>0.1457</cell><cell>0.9000</cell><cell>0.7902</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0534</cell><cell>0.0483</cell><cell>0.8000</cell><cell>0.5271</cell></row><row><cell cols="2">Embedding Average 0.0477</cell><cell>0.0970</cell><cell>0.7000</cell><cell>0.8875</cell></row><row><cell>Vector Extrema</cell><cell>0.1009</cell><cell>0.0761</cell><cell>0.8000</cell><cell>0.5363</cell></row><row><cell>Skip-Thought</cell><cell>0.0959</cell><cell>0.0858</cell><cell>0.5000</cell><cell>0.5313</cell></row><row><cell>BERTScore (base)</cell><cell>0.2164</cell><cell>0.2088</cell><cell>0.9000</cell><cell>0.9024</cell></row><row><cell>BERTScore (large)</cell><cell>0.2260</cell><cell>0.2094</cell><cell>0.9000</cell><cell>0.8319</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.3370</cell><cell>0.3254</cell><cell>0.9000</cell><cell>0.4485</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.1325</cell><cell>0.2148</cell><cell>0.7000</cell><cell>0.9222</cell></row><row><cell>USR-DR (x = f)</cell><cell>0.0313</cell><cell>0.1611</cell><cell>0.9000</cell><cell>0.8808</cell></row><row><cell>USR</cell><cell>0.2763</cell><cell>0.3037</cell><cell>1.0000</cell><cell>0.9220</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 14 :</head><label>14</label><figDesc>Correlations of all the metrics with the Natural ratings on Topical-Chat. All values with p ? 0.05 are italicized. The USR-MLM metric has poor system-level correlations, however the USR metric leverages predictions from the other sub-metrics to improve this.</figDesc><table><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.0815</cell><cell>0.0717</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>-0.0072</cell><cell>-0.0216</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>0.0838</cell><cell>0.0344</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>0.0823</cell><cell>0.0457</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>0.1081</cell><cell>0.0499</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>0.0989</cell><cell>0.0950</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>0.0096</cell><cell>-0.0087</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.1029</cell><cell>0.0665</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average 0.1413</cell><cell>0.1152</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>0.1458</cell><cell>0.1375</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>-0.0355</cell><cell>-0.0365</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.0606</cell><cell>0.0585</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>0.0494</cell><cell>0.0477</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.0999</cell><cell>0.1119</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.1733</cell><cell>0.2291</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0033</cell><cell>0.0642</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.1862</cell><cell>0.2430</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 15 :</head><label>15</label><figDesc>Correlations of all the metrics with the Natural ratings on PersonaChat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.1290</cell><cell>0.1199</cell><cell>0.6000</cell><cell>0.6483</cell></row><row><cell>BLEU-1</cell><cell>0.2097</cell><cell>0.2228</cell><cell>1.0000</cell><cell>0.8754</cell></row><row><cell>BLEU-2</cell><cell>0.2087</cell><cell>0.2353</cell><cell>0.9000</cell><cell>0.8555</cell></row><row><cell>BLEU-3</cell><cell>0.1736</cell><cell>0.2377</cell><cell>0.9000</cell><cell>0.9090</cell></row><row><cell>BLEU-4</cell><cell>0.1307</cell><cell>0.2345</cell><cell>0.5000</cell><cell>0.8464</cell></row><row><cell>METEOR</cell><cell>0.2495</cell><cell>0.3018</cell><cell>0.9000</cell><cell>0.9573</cell></row><row><cell>ROUGE-L</cell><cell>0.1928</cell><cell>0.2031</cell><cell>0.9000</cell><cell>0.8410</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.1036</cell><cell>0.1249</cell><cell>0.8000</cell><cell>0.6078</cell></row><row><cell cols="2">Embedding Average 0.1197</cell><cell>0.1511</cell><cell>1.0000</cell><cell>0.9460</cell></row><row><cell>Vector Extrema</cell><cell>0.1839</cell><cell>0.1840</cell><cell>0.8000</cell><cell>0.6275</cell></row><row><cell>Skip-Thought</cell><cell>0.0326</cell><cell>0.0568</cell><cell>0.6000</cell><cell>0.5237</cell></row><row><cell>BERTScore (base)</cell><cell>0.2432</cell><cell>0.2642</cell><cell>0.9000</cell><cell>0.9160</cell></row><row><cell>BERTScore (large)</cell><cell>0.2140</cell><cell>0.2328</cell><cell>0.9000</cell><cell>0.8779</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.3099</cell><cell>0.3243</cell><cell>0.9000</cell><cell>0.5190</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.3391</cell><cell>0.3650</cell><cell>0.3000</cell><cell>0.8899</cell></row><row><cell>USR-DR (x = f)</cell><cell>0.0594</cell><cell>0.1836</cell><cell>0.5000</cell><cell>0.8188</cell></row><row><cell>USR</cell><cell>0.4160</cell><cell>0.3769</cell><cell>0.7000</cell><cell>0.9270</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 16 :</head><label>16</label><figDesc>Correlations of all the metrics with the Maintains Context ratings on Topical-Chat. All values with p ? 0.05 are italicized. Several referenced metrics perform strongly on the system-level correlations, however USR strongly outperforms all other metrics on the turn-level correlations.</figDesc><table><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.1073</cell><cell>0.0747</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>0.0713</cell><cell>0.0799</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>0.0949</cell><cell>0.1372</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>0.1270</cell><cell>0.1461</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>0.1467</cell><cell>0.1508</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>0.2500</cell><cell>0.2564</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>0.1135</cell><cell>0.0910</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.1503</cell><cell>0.1631</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average 0.1010</cell><cell>0.1660</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>0.2288</cell><cell>0.2631</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>0.0243</cell><cell>0.0139</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.1770</cell><cell>0.1686</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>0.1877</cell><cell>0.1569</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.1805</cell><cell>0.2067</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.6021</cell><cell>0.5625</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0198</cell><cell>-0.0164</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.6065</cell><cell>0.5280</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 17 :</head><label>17</label><figDesc>Correlations of all the metrics with the Maintains Context ratings on PersonaChat. All values with p ? 0.05 are italicized. Several referenced metrics perform strongly on the system-level correlations, however USR strongly outperforms all other metrics on the turn-level correlations.</figDesc><table><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.2523</cell><cell>0.2565</cell><cell>0.6000</cell><cell>0.5944</cell></row><row><cell>BLEU-1</cell><cell>0.3144</cell><cell>0.3343</cell><cell>0.7000</cell><cell>0.8197</cell></row><row><cell>BLEU-2</cell><cell>0.3184</cell><cell>0.3323</cell><cell>0.9000</cell><cell>0.8099</cell></row><row><cell>BLEU-3</cell><cell>0.2782</cell><cell>0.3247</cell><cell>0.9000</cell><cell>0.9047</cell></row><row><cell>BLEU-4</cell><cell>0.2322</cell><cell>0.3156</cell><cell>0.9000</cell><cell>0.8883</cell></row><row><cell>METEOR</cell><cell>0.3668</cell><cell>0.4391</cell><cell>0.9000</cell><cell>0.9398</cell></row><row><cell>ROUGE-L</cell><cell>0.2946</cell><cell>0.2995</cell><cell>0.9000</cell><cell>0.8084</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.1989</cell><cell>0.2111</cell><cell>0.8000</cell><cell>0.5512</cell></row><row><cell cols="2">Embedding Average 0.1940</cell><cell>0.2161</cell><cell>0.7000</cell><cell>0.9056</cell></row><row><cell>Vector Extrema</cell><cell>0.2101</cell><cell>0.2050</cell><cell>0.8000</cell><cell>0.5694</cell></row><row><cell>Skip-Thought</cell><cell>0.1139</cell><cell>0.1356</cell><cell>0.5000</cell><cell>0.5187</cell></row><row><cell>BERTScore (base)</cell><cell>0.3512</cell><cell>0.3725</cell><cell>0.9000</cell><cell>0.9108</cell></row><row><cell>BERTScore (large)</cell><cell>0.3167</cell><cell>0.3349</cell><cell>0.9000</cell><cell>0.8480</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.3189</cell><cell>0.3337</cell><cell>0.9000</cell><cell>0.4663</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.3533</cell><cell>0.4877</cell><cell>0.7000</cell><cell>0.9233</cell></row><row><cell>USR-DR (x = f)</cell><cell>0.2006</cell><cell>0.4110</cell><cell>0.9000</cell><cell>0.8685</cell></row><row><cell>USR</cell><cell>0.4555</cell><cell>0.4645</cell><cell>1.0000</cell><cell>0.9297</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 18 :</head><label>18</label><figDesc>Correlations of all the metrics with the Interesting ratings on Topical-Chat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.0473</cell><cell>0.0132</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>-0.1081</cell><cell>-0.0922</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>-0.1048</cell><cell>-0.1010</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>-0.1247</cell><cell>-0.1151</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>-0.1359</cell><cell>-0.1242</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>-0.0458</cell><cell>0.0116</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>-0.1456</cell><cell>-0.1354</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>-0.1778</cell><cell>-0.2080</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average -0.0141</cell><cell>-0.0177</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>-0.1883</cell><cell>-0.1746</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>-0.0882</cell><cell>-0.0916</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.0325</cell><cell>0.0491</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>-0.0418</cell><cell>-0.0245</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>-0.1045</cell><cell>-0.1007</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.0606</cell><cell>0.2634</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0022</cell><cell>-0.0039</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.0315</cell><cell>0.0171</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 19 :</head><label>19</label><figDesc>Correlations of all the metrics with the Interesting ratings on PersonaChat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.1495</cell><cell>0.1485</cell><cell>0.6000</cell><cell>0.5970</cell></row><row><cell>BLEU-1</cell><cell>0.2888</cell><cell>0.3033</cell><cell>0.7000</cell><cell>0.8357</cell></row><row><cell>BLEU-2</cell><cell>0.2819</cell><cell>0.3066</cell><cell>0.9000</cell><cell>0.8309</cell></row><row><cell>BLEU-3</cell><cell>0.2442</cell><cell>0.3106</cell><cell>0.9000</cell><cell>0.9259</cell></row><row><cell>BLEU-4</cell><cell>0.2126</cell><cell>0.3096</cell><cell>0.9000</cell><cell>0.9084</cell></row><row><cell>METEOR</cell><cell>0.3328</cell><cell>0.3909</cell><cell>0.9000</cell><cell>0.9534</cell></row><row><cell>ROUGE-L</cell><cell>0.3099</cell><cell>0.3273</cell><cell>0.9000</cell><cell>0.8333</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.2327</cell><cell>0.2306</cell><cell>0.8000</cell><cell>0.5874</cell></row><row><cell cols="2">Embedding Average 0.1812</cell><cell>0.1827</cell><cell>0.7000</cell><cell>0.9151</cell></row><row><cell>Vector Extrema</cell><cell>0.2294</cell><cell>0.2111</cell><cell>0.8000</cell><cell>0.5917</cell></row><row><cell>Skip-Thought</cell><cell>0.0986</cell><cell>0.1145</cell><cell>0.5000</cell><cell>0.5397</cell></row><row><cell>BERTScore (base)</cell><cell>0.2847</cell><cell>0.2947</cell><cell>0.9000</cell><cell>0.9308</cell></row><row><cell>BERTScore (large)</cell><cell>0.2909</cell><cell>0.3167</cell><cell>0.9000</cell><cell>0.8703</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>0.2195</cell><cell>0.2261</cell><cell>0.9000</cell><cell>0.5070</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.2285</cell><cell>0.4179</cell><cell>0.7000</cell><cell>0.9155</cell></row><row><cell>USR-DR (x = f)</cell><cell>0.2220</cell><cell>0.4468</cell><cell>0.9000</cell><cell>0.8884</cell></row><row><cell>USR</cell><cell>0.3175</cell><cell>0.3353</cell><cell>1.0000</cell><cell>0.9469</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 20 :</head><label>20</label><figDesc>Correlations of all the metrics with the Uses Knowledge ratings on Topical-Chat. All values with p ? 0.05 are italicized.</figDesc><table><row><cell>Metric Name</cell><cell cols="4">Turn-Level Correlation System-Level Correlation</cell></row><row><cell></cell><cell>Pearson</cell><cell>Spearman</cell><cell>Spearman</cell><cell>Pearson</cell></row><row><cell></cell><cell cols="2">Word-Overlap Metrics</cell><cell></cell><cell></cell></row><row><cell>F-1</cell><cell>0.0869</cell><cell>0.1056</cell><cell>1.0000</cell><cell>0.9956</cell></row><row><cell>BLEU-1</cell><cell>0.0737</cell><cell>0.0729</cell><cell>0.6000</cell><cell>0.2599</cell></row><row><cell>BLEU-2</cell><cell>0.1083</cell><cell>0.0722</cell><cell>0.4000</cell><cell>0.6816</cell></row><row><cell>BLEU-3</cell><cell>0.0999</cell><cell>0.0594</cell><cell>0.4000</cell><cell>0.6668</cell></row><row><cell>BLEU-4</cell><cell>0.0698</cell><cell>0.0528</cell><cell>0.8000</cell><cell>0.8413</cell></row><row><cell>METEOR</cell><cell>0.1678</cell><cell>0.1719</cell><cell>0.8000</cell><cell>0.9065</cell></row><row><cell>ROUGE-L</cell><cell>0.0710</cell><cell>0.0632</cell><cell>0.0000</cell><cell>0.1710</cell></row><row><cell></cell><cell cols="3">Embedding-Based Metrics</cell><cell></cell></row><row><cell>Greedy Matching</cell><cell>0.0382</cell><cell>0.0057</cell><cell>0.8000</cell><cell>0.3808</cell></row><row><cell cols="2">Embedding Average 0.0402</cell><cell>0.0618</cell><cell>0.8000</cell><cell>0.8628</cell></row><row><cell>Vector Extrema</cell><cell>0.0564</cell><cell>-0.0008</cell><cell>0.6000</cell><cell>0.4349</cell></row><row><cell>Skip-Thought</cell><cell>-0.0686</cell><cell>-0.0609</cell><cell>-0.2000</cell><cell>0.2599</cell></row><row><cell>BERTScore (base)</cell><cell>0.0719</cell><cell>0.0465</cell><cell>0.8000</cell><cell>0.5173</cell></row><row><cell>BERTScore (large)</cell><cell>0.0271</cell><cell>0.0094</cell><cell>0.0000</cell><cell>0.2410</cell></row><row><cell></cell><cell cols="2">Reference Free Metrics</cell><cell></cell><cell></cell></row><row><cell>USR-MLM</cell><cell>-0.0782</cell><cell>-0.0756</cell><cell>-0.4000</cell><cell>-0.2842</cell></row><row><cell>USR-DR (x = c)</cell><cell>0.4508</cell><cell>0.6309</cell><cell>1.0000</cell><cell>0.8202</cell></row><row><cell>USR-DR (x = f)</cell><cell>-0.0927</cell><cell>-0.0903</cell><cell>-0.2108</cell><cell>-0.0178</cell></row><row><cell>USR</cell><cell>0.4027</cell><cell>0.3177</cell><cell>1.0000</cell><cell>0.8084</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 21 :</head><label>21</label><figDesc>Correlations of all the metrics with the Uses Knowledge ratings on PersonaChat. All values with p ? 0.05 are italicized.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/facebookresearch/ ParlAI/tree/master/projects/convai2</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>We thank the following individuals for their help with annotation: Evgeniia Razumovskaia, Felix Labelle, Mckenna Brown and Yulan Feng.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Meteor universal: Language specific translation evaluation for any target language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="376" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Deriu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Otegi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Echegoyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Cieliebak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.04071</idno>
		<title level="m">Survey on evaluation methods for dialogue systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00098</idno>
		<title level="m">The second conversational intelligence challenge (convai2)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bootstrapping dialog systems with word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Forgues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Marie</forename><surname>Larchev?que</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?al</forename><surname>Tremblay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nips, modern machine learning and natural language processing workshop</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">deltaBLEU: A discriminative metric for generation tasks with intrinsically diverse targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-2073</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="445" to="450" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Topical-chat: Towards knowledge-grounded open-domain conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinlang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anu</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raefer</forename><surname>Gabriel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1891" to="1895" />
		</imprint>
	</monogr>
	<note>Dilek Hakkani-T?r, and Amazon Alexa AI</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Investigating evaluation of open-domain dialogue systems with human generated multiple references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Pavel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10568</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09751</idno>
		<title level="m">The curious case of neural text degeneration</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06547</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Rouge: A package for automatic evaluation of summaries. Text Summarization Branches Out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08023</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards an automatic Turing test: Learning to evaluate dialogue responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Angelard-Gontier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1103</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1116" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08909</idno>
		<title level="m">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniia</forename><surname>Razumovsakaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00414</idno>
		<title level="m">Pretraining methods for dialog context representation learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparison of greedy and optimal assessment of natural language student input using word-to-word similarity metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasile</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Lintean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Building Educational Applications Using NLP</title>
		<meeting>the Seventh Workshop on Building Educational Applications Using NLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="157" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremie</forename><surname>Zumer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09799</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
