<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">mSLAM: Massively multilingual joint pre-training for speech and text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Jia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Khanuja</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Riesa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
						</author>
						<title level="a" type="main">mSLAM: Massively multilingual joint pre-training for speech and text</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present mSLAM, a multilingual Speech and LAnguage Model that learns cross-lingual crossmodal representations of speech and text by pretraining jointly on large amounts of unlabeled speech and text in multiple languages. mSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on character-level text, along with Connectionist Temporal Classification (CTC) losses on paired speech and transcript data, to learn a single model capable of learning from and representing both speech and text signals in a shared representation space. We evaluate mSLAM on several downstream speech understanding tasks and find that joint pre-training with text improves quality on speech translation, speech intent classification and speech language-ID while being competitive on multilingual ASR, when compared against speech-only pre-training. Our speech translation model demonstrates zeroshot text translation without seeing any text translation data, providing evidence for cross-modal alignment of representations. mSLAM also benefits from multi-modal fine-tuning, further improving the quality of speech translation by directly leveraging text translation data during the finetuning process. Our empirical analysis highlights several opportunities and challenges arising from large-scale multimodal pre-training, suggesting directions for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multilingual pre-trained models have demonstrated large quality gains on a variety of multilingual Natural Language Processing (NLP) tasks <ref type="bibr" target="#b29">(Hu et al., 2020;</ref><ref type="bibr" target="#b46">Ruder et al., 2021)</ref>. With the emergence of multilingual pre-trained models of speech like XLSR <ref type="bibr" target="#b19">(Conneau et al., 2020;</ref><ref type="bibr" target="#b3">Babu et al., 2021)</ref>, * Equal contribution 1 Google, USA. Correspondence to: Ankur Bapna &lt;ankurbpn@google.com&gt;, Colin Cherry &lt;col-incherry@google.com&gt;, Yu Zhang &lt;ngyuzh@google.com&gt;. similar improvements have also been observed on speech understanding tasks. One key advantage of multilingual pre-trained models is the ability to overcome data skew across languages to improve quality on low resource languages . By training a shared set of (usually attention-based) parameters on many languages, these models can learn crosslingually aligned representations of text or speech in a shared representation space <ref type="bibr" target="#b38">(Kudugunta et al., 2019;</ref><ref type="bibr" target="#b52">Wu et al., 2019)</ref>. These shared multilingual representations allow multilingual pretrained models to use supervised data in one language to benefit lower-resource languages <ref type="bibr" target="#b16">(Conneau &amp; Lample, 2019</ref>). An extreme scenario of cross-lingual transfer learning is zero-shot transfer, where using supervised data to fine-tune a pre-trained model on a source language exhibits non-zero performance on a target language; without utilizing any supervision for the target language <ref type="bibr" target="#b31">(Johnson et al., 2017;</ref><ref type="bibr" target="#b17">Conneau et al., 2018)</ref>.</p><p>Given the convergence of architectures <ref type="bibr" target="#b48">(Vaswani et al., 2017)</ref> and objectives <ref type="bibr" target="#b20">(Devlin et al., 2019;</ref><ref type="bibr" target="#b4">Baevski et al., 2020;</ref><ref type="bibr" target="#b7">Chung et al., 2021)</ref> across the speech and text modalities, building a single model that could learn cross-lingual cross-modal representations of speech and text from hundreds of languages is the next natural step. Such a model can enable transfer learning across the two modalities, directly benefiting languages (and domains) with limited amounts of speech or text data. In addition, joint models of speech and text can likely enable end-to-end speech understanding tasks directly from the speech signal, including tasks like speech translation, speaker intent classification and speech language-identification, bypassing errors introduced by an intermediate automatic speech recognition (ASR) system. While there are several potential advantages from multilingual pre-trained models of speech and text, these models suffer from interference and capacity dilution . This effect has also been documented in multilingual pre-trained models of text. While lower resource languages benefit from transfer learning, with increasing multilinguality, high resource languages lose quality <ref type="bibr" target="#b14">(Caruana, 1997;</ref><ref type="bibr" target="#b2">Arivazhagan et al., 2019;</ref>. This deterioration is typically addressed by either increasing model capacity <ref type="bibr" target="#b3">Babu et al., 2021)</ref> or incorporating approaches from multi-task learning to reduce arXiv:2202.01374v1 [cs.CL] 3 Feb 2022 mSLAM: Massively multilingual joint pre-training for speech and text interference by leveraging architectural or optimization improvements <ref type="bibr" target="#b45">Raffel et al., 2019)</ref>.</p><p>In this work we present mSLAM, a multilingual pre-trained model of speech and text that has been pre-trained with speech from 51 languages and text from 101 languages. mSLAM is a multilingual extension of SLAM , with the addition of a Connectionist Temporal Classification (CTC) loss <ref type="bibr" target="#b26">(Graves et al., 2006)</ref> on the paired speech-text data, to reduce interference and encourage stronger alignment across the two modalities.</p><p>On several downstream speech understanding tasks, including CoVoST-2 21?En speech translation <ref type="bibr" target="#b50">(Wang et al., 2021b)</ref>, Fleurs speech language identification (Section 4.2) and Minds-14 speech intent classification <ref type="bibr" target="#b23">(Gerz et al., 2021)</ref>, mSLAM demonstrates significant quality improvements over equivalent models trained only on speech. On multilingual ASR tasks, including MLS-10Hr <ref type="bibr" target="#b43">(Pratap et al., 2020)</ref>, VoxPopuli <ref type="bibr" target="#b49">(Wang et al., 2021a)</ref> and Babel <ref type="bibr" target="#b22">(Gales et al., 2014)</ref>, mSLAM matches the performance of the speechonly baseline. We also evaluate mSLAM on XNLI <ref type="bibr" target="#b17">(Conneau et al., 2018)</ref>, to understand its strengths and limitations on text tasks. We find that the addition of the CTC loss significantly improves quality on several speech and text understanding tasks, highlighting the importance of alleviating interference in multi-modal pre-trained models.</p><p>We also conduct analyses to understand the extent of multimodal representation alignment in mSLAM. When finetuned with only speech translation data, mSLAM is capable of zero-shot text translation in several languages, suggesting that the model is capable of learning from data in one modality to improve quality in the other. mSLAM also benefits from multi-modal supervised data. On CoVoST-2, we jointly fine-tune mSLAM on multilingual speech translation and text translation, further improving speech translation quality by 2 BLEU; improving over a significantly larger XLS-R (2B) model  and establishing a new state of the art on this dataset. Increasing mSLAM model capacity to 2B parameters results in further quality improvements on most downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>Multimodal pre-training: SLAM ) is a multimodal speech and text pretraining method, which trains a single Conformer <ref type="bibr" target="#b27">(Gulati et al., 2020)</ref> with SpanBERT <ref type="bibr" target="#b32">(Joshi et al., 2020)</ref> and w2v-BERT <ref type="bibr" target="#b7">(Chung et al., 2021)</ref> self-supervised losses that leverage unlabeled monomodal data, as well as a TLM loss <ref type="bibr" target="#b16">(Conneau &amp; Lample, 2019;</ref><ref type="bibr">Zheng et al., 2021)</ref> and a speech-text matching loss  that both use supervised speech recognition data. Pre-trained speech representations have been shown to be close to text  and SLAM leverages this similarity for cross-modal transfer. Compared to mono-modal pre-trained models, SLAM shows improvements on speech translation, similar performance on speech recognition but degradation on text downstream tasks, exposing a transfer-interference trade-off that has been previously studied in multilingual models . Because SLAM focuses on English it is harder to notice cross-modal transfer, as both modalities have a large amount of unlabeled data. In many languages, speech data is scarcer than text, or vice-versa. In this scenario crossmodal transfer is more likely, similar to how high-resource languages transfer to low-resource languages in multilingual pre-training. mSLAM exploits both cross-lingual and cross-modal transfer by simultaneously training on both modalities in a large number of languages.</p><p>Multilingual pre-training: In multilingual understanding literature, models like mBERT <ref type="bibr" target="#b20">(Devlin et al., 2019)</ref>, XLM-R <ref type="bibr" target="#b16">(Conneau &amp; Lample, 2019)</ref> or mT5 <ref type="bibr" target="#b55">(Xue et al., 2021b)</ref> have shown the benefit of cross-lingual transfer for improving representations of low-resource languages: on these languages, multilingual models strongly outperform monolingual pre-trained models on public benchmarks <ref type="bibr" target="#b17">(Conneau et al., 2018;</ref><ref type="bibr" target="#b40">Lewis et al., 2019;</ref><ref type="bibr" target="#b29">Hu et al., 2020;</ref><ref type="bibr" target="#b46">Ruder et al., 2021)</ref>. Past work has also leveraged parallel data to improve multilingual text representations, e.g. with TLM (Conneau &amp; Lample, 2019), explicit alignment  or nmT5 . Similarly, in speech understanding, multilingual pre-trained models <ref type="bibr" target="#b35">(Kawakami et al., 2020;</ref><ref type="bibr" target="#b19">Conneau et al., 2020;</ref><ref type="bibr" target="#b3">Babu et al., 2021</ref>) based on self-supervised losses <ref type="bibr" target="#b42">(Oord et al., 2018;</ref><ref type="bibr" target="#b4">Baevski et al., 2020)</ref> improve representations of low-resource languages at the cost of reduced performance on high-resource languages. In particular, multilingual pre-trained models like XLS-R expanded the few-shot learning capability of wav2vec 2.0  to many other languages, both for speech recognition and speech translation <ref type="bibr" target="#b50">(Wang et al., 2021b)</ref>. Interestingly, for speech, no lexical overlap across languages is leveraged during training, but multilingual representations still emerge from parameter sharing of the Transformer network . Leveraging text can potentially create connections between speech representations across languages through shared text anchor embeddings of identical character strings. Past work also leverages supervised ASR data to build multilingual representations of speech <ref type="bibr" target="#b34">(Kannan et al., 2019;</ref><ref type="bibr" target="#b6">Bai et al., 2021)</ref>, similar to how multilingual machine translation in NLP is used to build multilingual representations <ref type="bibr" target="#b21">(Eriguchi et al., 2018;</ref><ref type="bibr" target="#b47">Siddhant et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pre-training Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture and Objectives</head><p>Our pre-training approach builds on SLAM  and extends it to the massively multilingual setting.</p><p>Rushing is useless; one has to leave on time. To such Truth witness is given by the Tortoise and the Hare. "Let's make a bet," the former once said, "that you won't touch That line as soon as I." "As soon? Are you all there, Neighbor?" said the rapid beast. "You need a purge: four grains at least Of hellebore, you're now so far gone." "All there or not, the bet's still on." So it was done; the wagers of the two Were placed at the finish, in view. It doesn't matter what was down at stake, Nor who was the judge that they got. Our Hare had, at most, four steps or so to take. Rushing is useless; one has to leave on time. To such Truth witness is given by the Tortoise and the Hare. "Let's make a bet," the former once said, "that you won't touch That line as soon as I." "As soon? Are you all there, Neighbor?" said the rapid beast. "You need a purge: four grains at least Of hellebore, you're now so far gone." "All there or not, the bet's still on." So it was done; the wagers of the two Were placed at the finish, in view. It doesn't matter what was down at stake, Nor who was the judge that they got. Our Hare had, at most, four steps or so to take. Specifically, we build on SLAM-TLM, that combines together pre-training on speech unlabeled data with w2v-BERT <ref type="bibr" target="#b7">(Chung et al., 2021)</ref>, text with spanBERT <ref type="bibr" target="#b32">(Joshi et al., 2020)</ref> and on paired speech-transcript data with TLM (Conneau &amp; Lample, 2019). We skip the Speech-Text-Matching (STM) task since preliminary experiments didn't reveal any advantages over SLAM-TLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech ConvNet layers</head><p>mSLAM pre-training differs from SLAM on a couple of points. First, instead of using 32k token sentence-piece tokenization <ref type="bibr" target="#b37">(Kudo &amp; Richardson, 2018)</ref>, we use a character vocabulary, containing 4096 tokens spanning 101 languages. This results in longer sequence lengths, which we cap to 512 characters. We also increase the length of masked spans from 5 to 20 tokens for the spanBERT objective. Second, we apply a CTC loss <ref type="bibr" target="#b26">(Graves et al., 2006;</ref><ref type="bibr" target="#b25">Graves &amp; Jaitly, 2014)</ref> on the speech portion of the paired input, using the characterlevel transcript as the target. This CTC loss is applied in addition to TLM, so the input consists of a concatenated masked speech and masked text sequence, with the CTC loss applied to the speech portion of the output. We share the softmax vocabulary and parameters used for CTC with the softmax used for training the spanBERT objective with text input. We find that this CTC loss ensures stronger alignment between the speech and text representations learnt by the model, as further discussed in Sections 5 and 6.</p><p>In our 2B model, we increase the model dimension from 1024 to 1408, and the number of conformer layers from 24 to 40. We keep 8 layers in the contrastive block, and 32 in the MLM block. The peak learning rate is reduced from 6.0e ? 4 to 3.6e ? 4 for better training stability. Other hyper-parameters remain the same as the base 600M model. Note that our 2B model contains close 1.84B parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pre-training Data</head><p>We use three types of data for pre-training mSLAM; unlabeled speech drawn from multiple public datasets, unlabeled text from mC4 <ref type="bibr" target="#b54">(Xue et al., 2021a)</ref> and paired speech and text transcript data from multiple sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">UNLABELED SPEECH DATA</head><p>We use approximately 429k hours of unlabeled speech data in 51 languages 1 . Our unlabeled speech data closely follows the pre-training data used for XLS-R  with one major difference: we do not use VoxLingua. As a consequence our model is pre-trained on speech from 51 languages as compared to 128 for XLS-R, and our pretraining set is smaller by 6.6k hours.</p><p>We train on 372k hours of speech data spanning 23 languages from VoxPopuli <ref type="bibr" target="#b49">(Wang et al., 2021a)</ref>, read speech data in 25 languages drawn from the v6.1 release of Common Voice <ref type="bibr" target="#b0">(Ardila et al., 2019)</ref>, 50k hours of read books data in eight European languages from Multilingual Lib-riSpeech <ref type="bibr" target="#b43">(Pratap et al., 2020)</ref> and 1k hours of telephonic conversation data spanning 17 African and Asian languages from BABEL <ref type="bibr" target="#b22">(Gales et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">UNLABELED TEXT DATA</head><p>For pre-training with unlabeled text, we use the mC4 dataset <ref type="bibr" target="#b55">(Xue et al., 2021b)</ref> spanning 101 languages. We upsample lower resource languages using temperature-based sampling , with T = 3.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">PAIRED SPEECH-TRANSCRIPT DATA</head><p>In addition to training with unlabeled speech and text, we also use approximately 2.4k hours of paired speech and transcript data spanning 32 languages, for training with the CTC and TLM alignment losses. This data is drawn from the following sources:</p><p>VoxPopuli: Approximately 1.3k hours of speech and transcript data spanning 14 languages. We exclude languages with less than 1 hour of data following <ref type="bibr" target="#b49">Wang et al. (2021a)</ref>.</p><p>Multilingual LibriSpeech (MLS): We use the 10 hour training splits of the paired data for each of the 8 MLS languages. We exclude any paired data outside the 10 hour splits to align with our downstream evaluations.</p><p>Babel: 1k hours of speech and transcript data spanning 17 languages from the Babel ASR task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimization and Hyperparameters</head><p>At each training step, we train mSLAM on all three types of data; each batch is composed of 2048 sequences of unlabeled speech, 8192 sequences of text and 256 sequences of paired data. Our speech-only baseline, w2v-bert-51 (0.6B), sees a batch composed of 4096 unlabeled speech sequences at every step. For our best run based on CoVoST dev performance, the speech loss has a coefficient of 1.0, the text loss has a coefficient of 0.3 and the paired CTC loss has a coefficient of 0.03 (to avoid over-fitting to the small paired data). We use the Adam optimizer <ref type="bibr" target="#b36">(Kingma &amp; Ba, 2014)</ref> with a Transformer learning rate schedule <ref type="bibr" target="#b48">(Vaswani et al., 2017)</ref>. We use 40k warmup steps, linearly increasing the learning rate to 6 ? 10 ?4 , followed by inverse square root decay. We train all 600M models for 1.3m steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Speech Classification</head><p>Fleurs-LangID: Fleurs 3 is a speech extension of the FLO-RES massively multilingual benchmark for MT . Fleurs contains 2009 sentences from the FLORES multi-way parallel evaluation set in 102 languages. We collect read speech corresponding to these sentences, and split these utterances into train-dev-test splits with 1109 for training (around 1.3 hours of data), 400 for dev and 500 for test, per-language. We collected 2.3 utterances per sentence on average. We evaluate our pre-trained models on Speech Language Identification (LangID) on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MINDS-14:</head><p>MINDS-14 <ref type="bibr" target="#b23">(Gerz et al., 2021</ref>) is an intent classification task from spoken data. It covers 14 intents extracted from the e-banking domain, with spoken examples in 14 language varieties. We merge monolingual datasets into a single dataset, with a 30-20-50 train-dev-test split.</p><p>Fine-tuning setup: When fine-tuning our models on speech classification we train the multi-modal and speech encoders. Speech input is fed into the speech encoder, and the outputs from the multi-modal encoder are max-pooled together before feeding into a softmax classifier. Optionally a projection layer is applied before pooling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Multilingual Speech Recognition</head><p>VoxPopuli: Following <ref type="bibr" target="#b49">Wang et al. (2021a)</ref>, we evaluate on the 14 languages with more than 1-Hr of data from the VoxPopuli ASR task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLS-10Hr:</head><p>We report results on the 10-Hr training split for the MLS task <ref type="bibr" target="#b43">(Pratap et al., 2020)</ref>.</p><p>Babel: Following Babu et al. <ref type="formula">(2021)</ref>, we report results on 5 languages from the Babel-ASR task.</p><p>Fine-tuning Setup: We fine-tune our pre-trained encoders with a 2-layer LSTM <ref type="bibr" target="#b28">(Hochreiter &amp; Schmidhuber, 1997)</ref> as a conformer-transducer model, following <ref type="bibr" target="#b7">Chung et al. (2021)</ref>. We use a merged grapheme vocabulary based on the task-specific training set for all ASR fine-tuning experiments. We do not use language-model fusion for any experiments. For VoxPopuli and MLS we report results with multilingual fine-tuning, while we fine-tune separate models per language for Babel. Our finetuning parameters follow <ref type="bibr" target="#b27">(Zhang et al., 2020)</ref>; for the pre-trained encoder, we use a peak learning rate of 3e ? 4 with 5k warm-up steps, while for the decoder, a peak learning rate of 1e ? 3 and 1.5k warm-up steps. All finetuning experiments on ASR use a constant 256 batch size. In practice, these parameters worked well across several tasks and amounts of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Text Classification</head><p>XNLI: We also evaluate mSLAM models on the XNLI sentence-pair classification task <ref type="bibr" target="#b17">(Conneau et al., 2018)</ref> to understand its strengths and weaknesses on text understanding tasks. We evaluate our models under both the zero-shot and translate-train-all settings <ref type="bibr" target="#b46">(Ruder et al., 2021)</ref>, and compare performance against mT5 <ref type="bibr" target="#b54">(Xue et al., 2021a)</ref>.</p><p>Fine-tuning setup: We train the multi-modal and text encoders on XNLI. We tune batch sizes over {16, 32}, learning rates over {2e ? 5, 4e ? 5}, projection over {N one, model dim} and number of epochs over {3, 5}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Multilingual Speech Translation</head><p>ST fine-tuning: Multilingual speech translation results are shown in <ref type="table" target="#tab_4">Table 1</ref>. Removing all text and paired data from pre-training gives us our speech-only pre-training baseline, w2v-bert-51 (0.6B), which is already very competitive with the state-of-the-art, outperforming XLS-R (1B) , despite having fewer parameters and not using a pre-trained decoder. mSLAM-TLM adds text and a paired TLM objective to pre-training as described by <ref type="bibr" target="#b7">Bapna et al. (2021)</ref>, and actually leads to an average degradation in ST quality, potentially due to interference between the speech and text modalities alongside the additional pressure of mas- ST + MT joint fine-tuning: The picture becomes more interesting as we introduce MT (text-to-text) data during fine-tuning in the bottom four lines of <ref type="table" target="#tab_4">Table 1</ref>. On top of the speech-only w2v-bert-51 (0.6B), adding MT data produces a modest average improvement of +0.6 BLEU. However, adding MT data to mSLAM-CTC, results in a larger improvement of +1.8 BLEU, suggesting that exposure to text during pre-training makes the encoder more amenable to using text during fine-tuning. This results in a new state-of-the art for the CoVoST 21?En task, surpassing the 4? larger XLS-R (2B) by 0.3 BLEU, enabled by large gains on high-resource languages. Increasing the capacity of mSLAM-CTC to 2B parameters further improves performance by 2.4 BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Speech Classification</head><p>Evaluations on the MINDS-14 and Fleurs-LangID tasks are detailed in <ref type="table" target="#tab_5">Table 2</ref>. We find that pre-training jointly with text and paired data with a TLM loss, mSLAM-TLM, improves over our speech-only baseline, w2v-bert-51 (0.6B), by 1.3% and 4.6% on MINDS-14 and Fleurs-LangID respectively. The addition of a CTC loss in mSLAM-CTC  We present ASR results on VoxPopuli, Babel and MLS-10hrs in <ref type="table" target="#tab_6">Table 3</ref>. Our speech-only pre-training baseline, w2v-bert-51 (0.6B) already outperforms XLS-R (Babu et al., 2021) on VoxPopuli and MLS-10hrs as shown in <ref type="table" target="#tab_6">Table 3</ref>. Our mSLAM-CTC (0.6B) model slightly outperforms the speech-only baseline on VoxPopuli and slightly lags on MLS-10hrs, but both improve over published results. On Babel, our model is behind XLS-R (1B) ; possibly due to a lack of language model fusion. mSLAM-CTC is very close to w2v-bert-51 (0.6B) and both improve over mSLAM-TLM. In conclusion, mSLAM achieves competitive ASR results without losing speech capacity across a variety of ASR tasks and languages. Increasing mSLAM-CTC capacity to 2B parameters results in improvements over both, the 600M model and our speech-only baseline. On XNLI, similar to SLAM results on GLUE, we observe decreases in performance compared to mono-modal models due to capacity dilution (see <ref type="table" target="#tab_7">Table 4</ref>). In the translatetrain-all setting, our mSLAM-CTC (0.6B) model obtains 70.0% accuracy on average compared to 79.8% for an mT5-Base model (0.6B). However, it performs comparably to the smaller mT5-Small model (0.3B) which gets 71.3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Multilingual Speech Recognition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Text Classification</head><p>On zero-shot classification, we observe a bigger drop in performance when using multi-modal pre-training compared to the mT5 models. Zero-shot classification being a testbed for the sharing of multilingual representations, we attribute this to speech interfering with the sharing of text representations across languages. Looking more closely at per-language results, the performance drops in particular for non-European languages, e.g. Thai and Chinese where the model loses around 20% accuracy. Note that the paired data used during pre-training is predominantly from European languages, and the performance of mSLAM-CTC improves significantly over mSLAM-TLM on this set of languages.</p><p>We hypothesize that having in-language paired data and alignment losses could be contributing to reduced interference between speech and text for these languages, resulting in more robust representations. This is also supported by the significantly improved performance on non-European languages with the mSLAM-CTC (2B) model, where the increased capacity might alleviate some of the interference. However, there are other confounding factors in our text pre-training approach compared to standard multilingual text pre-training, including the conformer architecture and fully character-level encoder pre-training, which might be contributing to these findings. We leave the study of multilingual representation alignment in joint speech-text models to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Analysis</head><p>Do we really need text pre-training or just alignment losses? mSLAM-CTC models add two improvements over the speech-only baseline: (i) TLM and CTC alignment losses over paired data, and (ii) Pre-training with large amounts of web-text. This raises the question whether our improvements are arising from (i), (ii) or a combination of the two. To answer this question we train a mSLAM-CTC model on unlabeled speech and paired speech text data, but no unlabeled text. We evaluate this model on CoVoST ST, MINDS-14 and Fleurs-LangID and present results in Table 5. We find that the performance of the mSLAM-CTC model without text falls somewhere between our speechonly model and mSLAM-CTC on MINDS-14 and Fleurs-LangID, suggesting that the additional text pre-training data is at least partially responsible for the observed improvements on these tasks. On CoVoST-2, mSLAM-CTC without text almost matches the performance of mSLAM-CTC when fine-tuning jointly with text translation data, suggesting that a majority of the improvements in this setting arise from MT data, and the alignment loss might be enough to enable the model to benefit from text supervised data for fine-tuning. Are cross-modal representations really aligned?</p><p>We have seen benefits from adding text to pre-training alongside a CTC loss. The importance of this CTC loss suggests that some amount of cross-modal representation alignment is necessary to take advantage of speech and text data in the same model, but can we construct an experiment to clearly demonstrate this alignment?</p><p>Zero-shot performance is one strong indicator for representation alignment. To that end, we use our joint fine-tuning infrastructure to conduct CoVoST 2, 21?En translation experiments where we fine-tune the mSLAM-CTC model on one modality (speech or text) and evaluate on the CoVoST 2 test set using the the other input modality.</p><p>Cross-modal results, alongside the amount of paired data  <ref type="table" target="#tab_9">Table 6</ref>. For score calibration, the S?S column shows a modalitymatched scenario of fine tuning on speech and testing on speech, corresponding to the sixth row of <ref type="table" target="#tab_4">Table 1</ref>. First, note that zero-shot cross-modal translation is possible: the S?T column shows that fine-tuning on speech and testing on text results in translation performance above 5 BLEU for 13 of 21 languages. Furthermore, 6 of those 13 languages had no paired data available during pre-training, demonstrating the power of being both multimodal and multilingual. Most surprisingly of all, Russian (ru) has an excellent zero-shot score of 21.9 BLEU, and it not only has no paired data during pre-training, but also no paired data in its Cyrillic script, yet the mSLAM model can translate it into English.</p><p>We tested for the same behavior with w2v-bert-51 (0.6B) and mSLAM-TLM and found no evidence of zero-shot S?T transfer. We also tested the impact of unlabeled text: average zero-shot BLEU is 9.4 for full mSLAM-CTC but only 6.4 without any unlabeled text during pre-training (not shown). The languages without paired data suffer disproportionately: Swedish (sv) drops from 15.2 to 0.7 BLEU and Russian (ru) drops from 21.9 to 4.2 BLEU.</p><p>There is still much work left to be done. Russian is somewhat of an outlier in terms of script sensitivity, all other cross-modal success stories are for predominantly European languages in the Latin script. Furthermore, some languages such as Turkish (tr) have paired data available during pretraining, but demonstrate limited zero-shot transfer. Finally, note that this zero-shot transfer does not work in the other direction: the T?S column clearly shows that a system fine-tuned only on text cannot translate speech. Source Il r?alise aussi quelques courts-m?trages. Gold He also makes short films.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S?T</head><p>He also writes a few short films either short films either short films.</p><p>Source Il a r?alis? deux courts-m?trages. Gold He produced two short films. S?T He created two short short films.</p><p>Examining zero-shot text translation outputs. While the system's cross-modal capabilities are surprising, there is still a substantial drop in BLEU for zero-shot translation of text: compare the S?S column to the S?T column in Table 6. This reduced performance often manifests as repeated or empty outputs: see <ref type="table" target="#tab_11">Table 8</ref> for contrastive zero-shot text translation examples. This is reminiscent of oscillatory hallucinations caused by unexpected inputs <ref type="bibr" target="#b39">(Lee et al., 2018)</ref>.</p><p>Visualizing cross-modal alignment with a CTC probe.</p><p>To visualize the information available when text is input to a model fine-tuned only for speech, we create a CTC probe for mSLAM encodings. Freezing the mSLAM encoder after pre-training, we tune only the softmax parameters of a CTC decoder using a 21-language ASR objective on the CoV-oST 2 data: speech is input, and the gold character-level transcription is the output. We can then decode the CoV-oST 2 test set using either speech or text inputs. If speech is input, the ASR task matches the fine-tuning objective. If text is input, this represents a zero-shot character-level auto-encoding (CAE) task. We measure the success of both tasks using character-error-rate (CER).</p><p>Per-language results of this CTC probe are also shown in <ref type="table" target="#tab_9">Table 6</ref> as S?T CAE. First, it is notable that even with a frozen encoder and a far less powerful decoder, we still see zero-shot transfer from speech to text inputs. In fact, with the exception of Turkish (tr) and Russian (ru), zeroshot CAE performance with less than 20 CER is predictive of zero-shot translation performance greater than 5 BLEU. Russian again is an interesting case, with terrible zero-shot CAE performance, but excellent zero-shot MT performance. However, the real value of such a probe is the ability to inspect the outputs. <ref type="table" target="#tab_10">Table 7</ref> shows randomly selected examples for both, a typical success (French, fr) and one of our more mysterious languages (Russian, ru). For French, most of the content is retained with text input, though some capitalization and punctuation is lost. Interestingly, for Russian, its Cyrillic text input results in a partial transliteration into the Latin script. This suggests that Russian is mapped into the same encoding space as Latin script languages during pre-training, which helps explain its strong cross-modal and cross-lingual transfer behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We introduced mSLAM, a multilingual pretrained model capable of representing speech and text in a shared representation space. mSLAM is trained on unlabeled speech in 51 languages with a w2v-BERT objective and character-level text in 101 languages with a SpanBERT objective. In addition to unlabeled data, we train mSLAM on small amounts of paired speech-transcript data with a novel TLM+CTC objective to encourage representation sharing across the two modalities. Downstream evaluations on CoVoST 2 Speech Translation, Speech intent classification and Speech LangID demonstrate that mSLAM improves over equivalent speechonly baselines on speech understanding tasks, while maintaining similar quality on ASR. In addition to fine-tuning with labeled speech data, mSLAM can also leverage text supervision to improve the quality of end-to-end speech tasks, as demonstrated by our experiments on CoVoST 2 Speech Translation, establishing a new state of the art on this dataset. Increasing the capacity of mSLAM to 2B parameters further improves quality on Speech Translation, Speech Language Identification and multilingual ASR.</p><p>On XNLI sentence-pair classification, we observe crosslingual zero-shot performance equivalent to text-only models half the size of mSLAM on (European) languages with relatively large amounts of paired data, but severe quality degradation on languages with scarce parallel data. We notice that this degradation can be addressed to some extent by increasing the capacity of the joint speech-text model.</p><p>When fine-tuned on speech translation only, mSLAM is capable of cross-modal zero-shot text translation, demonstrating strong evidence for representation alignment. Probing a frozen mSLAM encoder with a CTC head fine-tuned for ASR demonstrates high quality on text reconstruction, providing additional supporting evidence in favour of aligned speech-text representations.</p><p>The use of paired data and alignment losses results in quantitative improvements on several speech understanding tasks and reduced degradation on text understanding tasks, highlighting the need for mitigating interference in multilingual multi-modal pre-training. We hope that this work catalyzes further research towards improving and understanding universal, multi-modal pre-trained models.</p><p>Zhang, Y., Qin, J., Park, D. S., Han, W., Chiu, C.-C., Pang, R., Le, Q. V., and Wu, Y. Pushing the limits of semisupervised learning for automatic speech recognition. arXiv preprint arXiv:2010.10504, 2020.</p><p>Zheng, R., Chen, J., Ma, M., and Huang, L. Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation, 2021.</p><p>mSLAM: Massively multilingual joint pre-training for speech and text  Prior work  XLS-R (0.3B) 14.8 10.5 24.5 14.2 12.3 8.9 12.8 XLS-R (1B) 12.5 8.7 19.5 11.3 10.0 7.1 10.6</p><p>Our work: Speech-only w2v-bert-51 (0.6B) 10.5 7.0 15.8 9.3 9.1 6.0 9.3</p><p>Our work: Speech + Text mSLAM-TLM (0.6B) 10.5 7.1 15.8 9.0 10.0 6.2 9.4 mSLAM-CTC (0.6B) 10.3 7.0 14.2 9.2 9.1 5.9 9.2 mSLAM-CTC (2B) 10.5 6.8 15.1 8.7 9.1 6.0 9.1  Number of training hours 10 10 10 10 10 10 10 10 -</p><p>Prior work (monolingual fine-tuning)  XLS-R(0.3B) 15.9 9.0 13.5 12.4 8.1 13.1 17.0 13.9 12.8 XLS-R(1B) 12.9 7.4 11.6 10.2 7.1 12.0 15.8 10.5 10.9 XLS-R(2B) 14.0 7.6 11.8 10.0 6.9 12.1 15.6 9.8 11.0</p><p>Our work: Speech Only (multilingual fine-tuning)</p><p>w2v-bert-51 (0.6B) 12.7 7.0 12.6 8.9 5.9 10.3 14.6 6.9 9.9</p><p>Our work: Speech + Text (multilingual fine-tuning)</p><p>mSLAM-TLM (0.6B) 13.9 7.2 13.0 9.9 5.8 10.7 14.2 8.4 10.4 mSLAM-CTC (0.6B) 13.3 7.0 12.5 9.7 5.5 10.5 14.1 8.5 10.1 mSLAM-CTC (2B) 11.9 6.6 12.4 8.5 5.8 9.8 15.2 7.7 9.7 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The 2B model was pre-trained for 350k steps.<ref type="bibr" target="#b1">Ardila et al., 2020)</ref>. The audio consists of read speech crowd-sourced through the Mozilla Common Voice project. We evaluate on a multilingual XX-to-English task that covers translation from 21 source languages into English. The training data ranges in size from 264 hours speech for French to about 1 hour speech for Indonesian.Multi-modal fine-tuning: Apart from fine-tuning with just ST data, we leverage the ability of mSLAM to learn from both speech and text modalities by using text translation data in addition to the CoVoST 2 ST data for multi-modal joint fine-tuning. For each CoVoSt 2 XX-to-English language pair, we use the text translation data from CoVoST 2 combined with all data from either WMT or TED Talks, as available. Specifically, we pair with WMT20<ref type="bibr" target="#b9">(Barrault et al., 2020)</ref> for ja, ta, WMT19<ref type="bibr" target="#b8">(Barrault et al., 2019)</ref> for de, ru, zh, WMT18<ref type="bibr" target="#b13">(Bojar et al., 2018)</ref> for et, tr, WMT17 (Bojar et al., 2017) for lv, WMT15<ref type="bibr" target="#b11">(Bojar et al., 2015)</ref> for fr, WMT13<ref type="bibr" target="#b10">(Bojar et al., 2013)</ref> and TED59<ref type="bibr" target="#b44">(Qi et al., 2018)</ref> for ar, fa, id, it, nl, pt, sl, sv, leaving ca and cy unpaired.We attach a 6-layer, 512-dimension Transformer decoder to our pre-trained encoders. This decoder has 34M parameters. For ST-only fine-tuning, this model is then fine-tuned on the CoVoST 2 ST dataset. A dropout probability 0.3 is used on the input embedding and all residual connections in the Transformer decoder to mitigate overfitting. For multimodal fine-tuning, this model is fine-tuned on the CoVoST 2 ST dataset simultaneously with the MT dataset described above. Each training batch contains equal numbers of ST and MT examples, with a higher loss weight, 5.0, on the MT objective. A lower dropout probability 0.1 is used because more training data is available. 2</figDesc><table><row><cell>4. Downstream tasks</cell></row><row><cell>4.1. Multilingual Speech Translation</cell></row><row><cell>CoVoST 2 Speech Translation: CoVoST 2 (Wang et al.,</cell></row><row><cell>2021b) is a multilingual speech translation (ST) dataset</cell></row><row><cell>created by professional translation of the Common Voice</cell></row><row><cell>speech corpus (</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We tune hyperparameters on dev performance; tuning batch sizes over {16, 32, 64}, learning rates over {2e?6, 4e?6, 2e?5, 4e? 5} and projection over {N one, model dim}. For MINDS we tune number of epochs over {100, 300} and for Fleurs over {5, 10, 20}. We pick the run with the best dev performance and evaluate on the test split. For MINDS-14, we report the macro-averaged accuracy over all 14 languages.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Speech translation -CoVoST 2 X?En summarized results in BLEU. Full per-language results are available in the AppendixTable 9.</figDesc><table><row><cell>X ? English</cell><cell cols="2">high mid low</cell><cell>all</cell></row><row><cell cols="4">Prior work, mBART decoder init. (Babu et al., 2021)</cell></row><row><cell>XLS-R (0.3B)</cell><cell>30.6 18.9</cell><cell>5.1</cell><cell>13.2</cell></row><row><cell>XLS-R (1B)</cell><cell cols="2">34.3 25.5 11.7</cell><cell>19.3</cell></row><row><cell>XLS-R (2B)</cell><cell cols="2">36.1 27.7 15.1</cell><cell>22.1</cell></row><row><cell>Our Work: Speech Only</cell><cell></cell><cell></cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell cols="2">35.6 25.3 13.4</cell><cell>20.4</cell></row><row><cell cols="2">Our Work: Speech + Text</cell><cell></cell><cell></cell></row><row><cell cols="3">mSLAM-TLM (0.6B) 34.4 23.4 11.3</cell><cell>18.6</cell></row><row><cell cols="3">mSLAM-CTC (0.6B) 35.5 25.2 13.7</cell><cell>20.6</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell cols="2">36.3 27.5 15.6</cell><cell>22.4</cell></row><row><cell cols="3">Our Work: Speech Only w/ joint fine-tuning</cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell cols="2">36.4 25.9 13.8</cell><cell>21.0</cell></row><row><cell cols="3">Our Work: Speech + Text w/ joint fine-tuning</cell><cell></cell></row><row><cell cols="3">mSLAM-TLM (0.6B) 35.5 25.3 12.3</cell><cell>19.8</cell></row><row><cell cols="3">mSLAM-CTC (0.6B) 37.6 27.8 15.1</cell><cell>22.4</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell cols="2">37.8 29.6 18.5</cell><cell>24.8</cell></row><row><cell cols="4">sive multilinguality. Fortunately, mSLAM-CTC's addition</cell></row><row><cell cols="4">of a CTC component to the TLM objective, as described</cell></row><row><cell cols="4">in Section 3, recovers w2v-bert-51 (0.6B) performance; in</cell></row><row><cell cols="4">fact, it improves slightly, mostly on low-resource languages.</cell></row><row><cell cols="4">As we show in Section 6, this CTC component is essential</cell></row><row><cell cols="2">to zero-shot cross-modal behavior.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Speech Classification -MINDS-14 speech intent classification and Fleurs speech language identification accuracy.</figDesc><table><row><cell>Model</cell><cell cols="2">MINDS-14 Fleurs-LangID</cell></row><row><cell>Our work: Speech Only</cell><cell></cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell>82.7</cell><cell>71.4</cell></row><row><cell cols="2">Our work: Speech + Text</cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell>84.0</cell><cell>76.0</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>86.9</cell><cell>73.3</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell>86.6</cell><cell>77.7</cell></row><row><cell cols="3">further improves accuracy by 2.9% on MINDS-14. On</cell></row><row><cell cols="3">Fleurs-LangID, mSLAM-CTC is worse than mSLAM-TLM</cell></row><row><cell cols="3">by around 2.7%, still maintaining an accuracy improvement</cell></row><row><cell cols="3">of 1.9% over our speech-only baseline. Increasing mSLAM-</cell></row><row><cell cols="3">CTC capacity to 2B parameters results in further 1.7% im-</cell></row><row><cell cols="3">provement over our previous best accuracy on Fleurs, while</cell></row><row><cell>being 0.</cell><cell></cell><cell></cell></row></table><note>3% worse than the 600M model on MINDS-14.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>Model</cell><cell cols="3">VoxPop Babel MLS</cell></row><row><cell cols="2">Prior work (Babu et al., 2021)</cell><cell></cell><cell></cell></row><row><cell>XLS-R (0.3B)</cell><cell>12.8</cell><cell>32.0</cell><cell>12.8</cell></row><row><cell>XLS-R (1B)</cell><cell>10.6</cell><cell>29.5</cell><cell>10.9</cell></row><row><cell>XLS-R (2B)</cell><cell>-</cell><cell>29.5</cell><cell>11.0</cell></row><row><cell>Our work: Speech-only</cell><cell></cell><cell></cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell>9.3</cell><cell>32.8</cell><cell>9.9</cell></row><row><cell cols="2">Our work: Speech + Text</cell><cell></cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell>9.4</cell><cell>33.2</cell><cell>10.4</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>9.2</cell><cell>32.9</cell><cell>10.1</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell>9.1</cell><cell>31.3</cell><cell>9.7</cell></row></table><note>Speech Recognition -Average Word Error Rate (WER) on the VoxPopuli, Babel and MLS-10Hr datasets. Per-language re- sults can be found in Appendix Tables 10, 11 and 12 respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Text Classification -XNLI dev accuracy on English, European (bg, de, el, es, fr) andNon-European (ar, hi, ru, sw, th,  tr, ur, vi, zh)  languages. Full results inAppendix Table 13. Note, for mSLAM models, only 450M and 1.4B out of the 600M and 2B parameters are fine-tuned for text tasks.</figDesc><table><row><cell>Model</cell><cell cols="4">English Euro Non-Euro Avg</cell></row><row><cell cols="4">Prior work: Text Only, Zero-shot (Xue et al., 2021b)</cell><cell></cell></row><row><cell>mT5-Small (0.3B)</cell><cell>79.6</cell><cell>66.6</cell><cell>60.4</cell><cell>63.8</cell></row><row><cell>mT5-Base (0.6B)</cell><cell>84.5</cell><cell>77.1</cell><cell>69.5</cell><cell>73.0</cell></row><row><cell cols="2">Our work: Speech + Text, Zero-shot</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell>75.7</cell><cell>57.5</cell><cell>48.6</cell><cell>53.4</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>80.4</cell><cell>71.4</cell><cell>49.5</cell><cell>58.9</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell>80.1</cell><cell>74.4</cell><cell>59.9</cell><cell>66.1</cell></row><row><cell cols="5">Prior work: Text Only, Translate-Train-All (Xue et al., 2021b)</cell></row><row><cell>mT5-Small (0.3B)</cell><cell>78.3</cell><cell>73.6</cell><cell>69.2</cell><cell>71.3</cell></row><row><cell>mT5-Base (0.6B)</cell><cell>85.9</cell><cell>82.1</cell><cell>77.9</cell><cell>79.8</cell></row><row><cell cols="3">Our work: Speech + Text, Translate-Train-All</cell><cell></cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell>74.1</cell><cell>69.3</cell><cell>64.6</cell><cell>66.8</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>81.1</cell><cell>76.0</cell><cell>65.5</cell><cell>70.0</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell>84.1</cell><cell>80.5</cell><cell>73.7</cell><cell>76.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Comparing</figDesc><table><row><cell cols="4">mSLAM-CTCmodels trained with and with-</cell></row><row><cell cols="4">out unlabeled text on CoVoST-2 ST BLEU (with joint fine-tuning),</cell></row><row><cell cols="3">MINDS-14 accuracy and Fleurs-LangID accuracy.</cell><cell></cell></row><row><cell></cell><cell cols="3">CoVoST Avg. MINDS-14 Fleurs</cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell>21.0</cell><cell>82.7</cell><cell>71.4</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>22.4</cell><cell>86.9</cell><cell>73.3</cell></row><row><cell>mSLAM-CTC (0.6B) -Text</cell><cell>22.2</cell><cell>85.0</cell><cell>71.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Zero-shot Performance -CoVoST 2 translation results with X?Y indicating X as the fine tuning modality and Y as the testing modality: S=Speech, T=Text. CAE is our CTC zero-shot character auto-encoding probe.</figDesc><table><row><cell></cell><cell>Hours</cell><cell></cell><cell>BLEU ?</cell><cell cols="2">CER ?</cell></row><row><cell cols="6">Lang Paired S?S S?T T?S S?T CAE</cell></row><row><cell>ar</cell><cell>0</cell><cell>13.3</cell><cell>0.0</cell><cell>0.0</cell><cell>82.6</cell></row><row><cell>fa</cell><cell>0</cell><cell>6.2</cell><cell>0.0</cell><cell>0.0</cell><cell>80.0</cell></row><row><cell>ja</cell><cell>0</cell><cell>1.6</cell><cell>0.0</cell><cell>0.0</cell><cell>100.0</cell></row><row><cell>zh</cell><cell>0</cell><cell>8.7</cell><cell>0.0</cell><cell>0.0</cell><cell>100.0</cell></row><row><cell>cy</cell><cell>0</cell><cell>6.1</cell><cell>0.1</cell><cell>0.0</cell><cell>24.3</cell></row><row><cell>mn</cell><cell>0</cell><cell>0.5</cell><cell>0.1</cell><cell>0.0</cell><cell>78.4</cell></row><row><cell>id</cell><cell>0</cell><cell>3.9</cell><cell>5.1</cell><cell>0.0</cell><cell>10.4</cell></row><row><cell>lv</cell><cell>0</cell><cell>19.4</cell><cell>8.2</cell><cell>0.0</cell><cell>18.4</cell></row><row><cell>et</cell><cell>0</cell><cell>17.2</cell><cell>8.3</cell><cell>0.0</cell><cell>16.5</cell></row><row><cell>sv</cell><cell>0</cell><cell>33.1</cell><cell>15.2</cell><cell>0.0</cell><cell>13.9</cell></row><row><cell>ca</cell><cell>0</cell><cell>33.4</cell><cell>16.7</cell><cell>0.0</cell><cell>10.0</cell></row><row><cell>ru</cell><cell>0</cell><cell>41.7</cell><cell>21.9</cell><cell>0.0</cell><cell>85.9</cell></row><row><cell>sl</cell><cell>6</cell><cell>24.9</cell><cell>7.8</cell><cell>0.0</cell><cell>10.6</cell></row><row><cell>pt</cell><cell>10</cell><cell>34.2</cell><cell>17.2</cell><cell>0.0</cell><cell>9.0</cell></row><row><cell>nl</cell><cell>41</cell><cell>32.6</cell><cell>16.8</cell><cell>0.0</cell><cell>11.3</cell></row><row><cell>ta</cell><cell>63</cell><cell>0.3</cell><cell>0.0</cell><cell>0.0</cell><cell>91.2</cell></row><row><cell>tr</cell><cell>69</cell><cell>11.7</cell><cell>1.7</cell><cell>0.0</cell><cell>12.6</cell></row><row><cell>it</cell><cell>79</cell><cell>35.0</cell><cell>19.7</cell><cell>0.0</cell><cell>11.2</cell></row><row><cell>es</cell><cell>140</cell><cell>39.1</cell><cell>21.2</cell><cell>0.0</cell><cell>7.9</cell></row><row><cell>fr</cell><cell>179</cell><cell>36.7</cell><cell>20.0</cell><cell>0.0</cell><cell>9.4</cell></row><row><cell>de</cell><cell>197</cell><cell>32.7</cell><cell>16.8</cell><cell>0.0</cell><cell>8.3</cell></row><row><cell cols="5">available during pre-training, are shown in</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>CTC Probing Examples -CoVoST CTC Probe with zero-shot text input to visualize zero-shot text encodings. Gold is the desired output as well as the text input. Romanization is provided by the GOST 7.79 System B standard for Cyrillic transliteration.</figDesc><table><row><cell>fr</cell><cell>Gold S?T (CAE)</cell><cell cols="2">Certains d?partements sont mieux?quip?s que d'autres. certains d?partements sont mieux?quip?s que d'autres</cell></row><row><cell></cell><cell>Gold</cell><cell>? ??? ??????? ????????????????? ??.??.</cell></row><row><cell>ru</cell><cell cols="3">Romanized Gold I nam sleduet rukovodstvovat'sya im.</cell></row><row><cell></cell><cell>S?T (CAE)</cell><cell>nam sleduet rucovodstvowats</cell><cell>im.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Zero-shot text translation examples.</figDesc><table><row><cell>Drawn from the</cell></row><row><cell>CoVoST 2 FrEn test set, decoded by mSLAM-CTC (0.6B).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Speech translation -CoVoST 2 X?En full results in BLEU.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">High-resource</cell><cell></cell><cell></cell><cell cols="2">Mid-resource</cell><cell></cell><cell></cell><cell cols="2">Low-resource</cell><cell></cell></row><row><cell>X ? English</cell><cell>fr</cell><cell>de</cell><cell>es</cell><cell>ca</cell><cell>fa</cell><cell>it</cell><cell>ru</cell><cell>pt</cell><cell>zh</cell><cell>tr</cell><cell>ar</cell><cell>et</cell></row><row><cell>Train Hours</cell><cell cols="9">264h 184h 113h 136h 49h 44h 18h 10h 10h</cell><cell>4h</cell><cell>2h</cell><cell>3h</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Speech recognition -VoxPopuli ASR results in terms of WER.</figDesc><table><row><cell></cell><cell>en</cell><cell>de</cell><cell>it</cell><cell>fr</cell><cell>es</cell><cell>pl</cell><cell>ro</cell><cell>hu</cell></row><row><cell>Labeled data</cell><cell cols="8">543h 282h 91h 211h 166h 111h 89h 63h</cell></row><row><cell cols="2">Prior work (Babu et al., 2021)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>XLS-R (0.3B)</cell><cell cols="4">10.2 13.0 19.2 12.6</cell><cell>9.8</cell><cell>9.6</cell><cell cols="2">7.9 11.6</cell></row><row><cell>XLS-R (1B)</cell><cell cols="4">8.8 11.5 15.1 10.8</cell><cell>8.2</cell><cell>7.7</cell><cell>7.3</cell><cell>9.6</cell></row><row><cell>Our work: Speech-only</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell>7.2</cell><cell cols="2">9.0 15.8</cell><cell>9.2</cell><cell>8.6</cell><cell>6.5</cell><cell>7.6</cell><cell>8.4</cell></row><row><cell cols="2">Our work: Speech + Text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell>7.3</cell><cell cols="2">8.9 15.6</cell><cell>9.3</cell><cell>8.7</cell><cell>6.5</cell><cell>8.5</cell><cell>8.4</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell>7.1</cell><cell cols="2">8.9 15.6</cell><cell>9.3</cell><cell>8.6</cell><cell>6.5</cell><cell>8.5</cell><cell>8.1</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell>7.0</cell><cell cols="2">8.7 15.4</cell><cell>9.4</cell><cell>8.4</cell><cell>6.4</cell><cell>7.8</cell><cell>8.4</cell></row><row><cell></cell><cell>nl</cell><cell>cs</cell><cell>sl</cell><cell>fi</cell><cell>hr</cell><cell cols="2">sk Avg</cell></row><row><cell>Labeled data</cell><cell>53h</cell><cell cols="2">62h 10h</cell><cell>27h</cell><cell>43h</cell><cell>35h</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>Speech recognition -BABEL ASR baselines in five languages, reporting WER.</figDesc><table><row><cell>Model</cell><cell>as</cell><cell>tl</cell><cell>sw</cell><cell>lo</cell><cell>ka</cell><cell>Avg</cell></row><row><cell cols="6">Number of pretraining hours 55h 76h 30h 59h 46h</cell><cell>-</cell></row><row><cell cols="6">Number of fine-tuning hours 55h 76h 30h 59h 46h</cell><cell>-</cell></row><row><cell cols="3">Prior work (with LM) (Babu et al., 2021)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>XLS-R (0.3B)</cell><cell cols="6">42.9 33.2 24.3 31.7 28.0 32.0</cell></row><row><cell>XLS-R (1B)</cell><cell cols="6">40.4 30.6 21.2 30.1 25.1 29.5</cell></row><row><cell>XLS-R (2B)</cell><cell cols="6">39.0 29.3 21.0 29.7 24.3 28.7</cell></row><row><cell>Our work: Speech-only, no LM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>w2v-bert-51 (0.6B)</cell><cell cols="6">42.8 32.9 26.7 30.6 31.1 32.8</cell></row><row><cell cols="2">Our work: Speech + Text, no LM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mSLAM-TLM (0.6B)</cell><cell cols="6">43.0 32.7 27.6 30.9 31.8 33.2</cell></row><row><cell>mSLAM-CTC (0.6B)</cell><cell cols="6">42.7 32.6 27.1 30.7 31.4 32.9</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell cols="6">41.1 31.1 25.1 29.9 29.1 31.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>Speech recognition -Multilingual LibriSpeech (MLS) ASR baselines in 8 languages, reporting WER.</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>de</cell><cell>nl</cell><cell>fr</cell><cell>es</cell><cell>it</cell><cell>pt</cell><cell>pl</cell><cell>Avg</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>Text Classification -XNLI dev accuracy for all 15 languages. For mSLAM models, only 450M and 1.4B out of the 600M and 2B parameters are fine-tuned for XNLI. Our work: Speech + Text, Zero-shot mSLAM-TLM (0.6B) 75.7 47.3 56.7 55.1 52.2 60.9 62.8 48.6 58.5 46.0 46.9 51.3 47.2 50.7 41.0 53.4 mSLAM-CTC (0.6B) 80.4 46.5 69.8 72.1 67.5 74.7 72.9 42.0 68.7 45.5 42.9 48.7 44.2 63.3 43.3 58.9 mSLAM-CTC (2B) 80.1 61.1 73.3 74.7 72.7 76.0 75.3 59.4 70.9 52.2 56.8 63.9 59.0 65.9 50.1 66.1</figDesc><table><row><cell>Model</cell><cell>en</cell><cell>ar</cell><cell>bg</cell><cell>de</cell><cell>el</cell><cell>es</cell><cell>fr</cell><cell>hi</cell><cell>ru</cell><cell>sw</cell><cell>th</cell><cell>tr</cell><cell>ur</cell><cell>vi</cell><cell>zh</cell><cell>Avg</cell></row><row><cell cols="5">Prior work: Text Only, Zero-shot (Xue et al., 2021b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mT5-Small (0.3B)</cell><cell cols="16">79.6 62.2 67.8 64.8 65.8 68.4 66.2 59.0 65.3 55.4 63.2 58.9 54.5 61.8 63.4 63.8</cell></row><row><cell>mT5-Base (0.6B)</cell><cell cols="16">84.5 71.2 76.9 75.6 76.3 79.0 77.7 66.9 74.9 63.6 70.0 69.2 64.8 72.0 72.5 73.0</cell></row><row><cell cols="6">Prior work: Text Only, Translate-Train-All (Xue et al., 2021b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mT5-Small (0.3B)</cell><cell cols="16">78.3 68.8 73.5 73.2 73.4 74.4 73.5 67.4 71.1 67.2 71.1 69.9 63.6 70.5 72.9 71.3</cell></row><row><cell>mT5-Base (0.6B)</cell><cell cols="16">85.9 78.8 82.2 81.6 81.4 83.0 82.1 77.0 81.1 74.8 78.6 78.4 73.3 78.9 80.2 79.8</cell></row><row><cell cols="4">Our work: Speech + Text, Translate-Train-All</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="17">mSLAM-TLM (0.6B) 74.3 64.2 68.7 69.5 69.2 70.2 71.4 64.5 65.4 63.4 65.6 65.9 62.4 67.3 64.4 67.1</cell></row><row><cell cols="17">mSLAM-CTC (0.6B) 81.1 63.5 76.7 76.0 73.1 77.8 76.4 63.6 73.1 64.1 64.9 66.8 60.5 68.4 64.5 70.0</cell></row><row><cell>mSLAM-CTC (2B)</cell><cell cols="16">84.1 80.2 80.1 78.7 82.9 80.5 74.4 72.1 76.8 71.7 73.8 76.2 69.8 75.9 72.8 76.1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Counting languages with more than 1 hour of speech data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">These hyper-parameters were found by optimizing the w2v-BERT speech-only baseline for CoVoST 2 development BLEU.3 Dataset to be released with another publication.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henretty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06670</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Common Voice: A massively-multilingual speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henretty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Language Resources and Evaluation Conference</title>
		<meeting>Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cherry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05019</idno>
		<title level="m">Massively multilingual neural machine translation in the wild: Findings and challenges</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Xls-r: Self-supervised cross-lingual speech representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tjandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Saraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09296</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11084</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Joint unsupervised and supervised training for multilingual asr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Siddhartha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.08137</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Slam: A unified encoder for speech and language modeling via speech-text joint pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.10329</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Findings of the 2019 conference on machine translation (WMT19)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Costa-Juss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-5301</idno>
		<ptr target="https://aclanthology.org/W19-5301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation</title>
		<meeting>the Fourth Conference on Machine Translation<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="61" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Findings of the 2020 conference on machine translation (WMT20)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biesialska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Costa-Juss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Joanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ljube?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.wmt-1.1" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Conference on Machine Translation</title>
		<meeting>the Fifth Conference on Machine Translation<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Findings of the 2013 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W13-2201" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Findings of the 2015 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turchi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-3001</idno>
		<ptr target="https://aclanthology.org/W15-3001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Findings of the 2017 conference on machine translation (WMT17)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turchi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4717</idno>
		<ptr target="https://aclanthology.org/W17-4717" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="169" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Findings of the 2018 conference on machine translation (WMT18)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6401</idno>
		<ptr target="https://aclanthology.org/W18-6401" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Shared Task Papers</title>
		<meeting>the Third Conference on Machine Translation: Shared Task Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="272" to="303" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Multitask</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Learning</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1007379606734</idno>
		<idno>1573-0565. doi: 10.1023/ A:1007379606734</idno>
		<ptr target="https://doi.org/10.1023/A:1007379606734" />
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997-07" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">w2v-BERT: Combining contrastive learning and masked language modeling for self-supervised speech pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASRU</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-lingual language model pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating cross-lingual sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xnli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Unsupervised cross-lingual representation learning for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2006.13979</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Zero-shot cross-lingual classification using multilingual neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eriguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Speech recognition and keyword spotting for low-resource languages: Babel project research at cued</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J F</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ragni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Rath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLTU</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multilingual and cross-lingual intent detection from spoken data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kusztos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vuli?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08524</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The flores-101 evaluation benchmark for lowresource and multilingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03193</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards end-to-end speech recognition with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1764" to="1772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Conformer: Convolution-augmented transformer for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4411" to="4421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Explicit alignment objectives for multilingual bidirectional encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.284</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.284" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="3633" to="3643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Google&apos;s multilingual neural machine translation system: Enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="339" to="351" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving pre-training by representing and predicting spans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spanbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">nmt5 -is parallel data still relevant for pre-training massively multilingual language models?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Large-scale multilingual speech recognition with a streaming end-to-end model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05330</idno>
	</analytic>
	<monogr>
		<title level="m">mSLAM: Massively multilingual joint pre-training for speech and text</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning robust and multilingual speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11128</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sentencepiece</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2012</idno>
		<ptr target="https://aclanthology.org/D18-2012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kudugunta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02197</idno>
		<title level="m">Investigating multilingual nmt representations at scale</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hallucinations in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fannjiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2018 Interpretability and Robustness for Audio, Speech and Language Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mlqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07475</idno>
		<title level="m">Evaluating cross-lingual extractive question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Align before fuse: Vision and language representation learning with momentum distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mls</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03411</idno>
		<title level="m">A large-scale multilingual dataset for speech research</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">When and why are pre-trained word embeddings useful for neural machine translation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2084</idno>
		<ptr target="https://aclanthology.org/N18-2084" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="529" to="535" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xtremer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07412</idno>
		<title level="m">Towards more challenging and nuanced multilingual evaluation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evaluating the crosslingual effectiveness of massively multilingual neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8854" to="8861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Voxpopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rivi?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Talnikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haziza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupoux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00390</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">CoVoST 2 and massively multilingual speech-to-text translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Gradient vaccine: Investigating and improving multi-task optimization in massively multilingual models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05874</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Emerging cross-lingual structure in pretrained language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.01464</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Selftraining and pre-training are complementary for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Likhomanenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tomasello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3030" to="3034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">mT5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.41</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.41.Priorwork" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
	<note>mBART Decoder init. (Babu et al.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Our Work: Speech Only</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Our Work: Speech Only w/ joint fine-tuning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Our Work: Speech + Text w/ joint fine-tuning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Low-resource Prior work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xls-R</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2B) 1.6 31.7 29.6 19.5 19.6 0.5 3.5 16.5 14.0 36.1 27.7 15.1 22.1</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Our Work: Speech Only</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Our Work: Speech Only w/ joint fine-tuning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Our Work: Speech + Text w/ joint fine-tuning</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
