<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
							<email>chuxiangxiang@xiaomi.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
							<email>zhangbo11@xiaomi.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
							<email>xuruijun@xiaomi.com</email>
						</author>
						<title level="a" type="main">FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One of the most critical problems in weight-sharing neural architecture search is the evaluation of candidate models within a predefined search space. In practice, a one-shot supernet is trained to serve as an evaluator. A faithful ranking certainly leads to more accurate searching results. However, current methods are prone to making misjudgments. In this paper, we prove that their biased evaluation is due to inherent unfairness in the supernet training. In view of this, we propose two levels of constraints: expectation fairness and strict fairness. Particularly, strict fairness ensures equal optimization opportunities for all choice blocks throughout the training, which neither overestimates nor underestimates their capacity. We demonstrate that this is crucial for improving the confidence of models' ranking. Incorporating the one-shot supernet trained under the proposed fairness constraints with a multi-objective evolutionary search algorithm, we obtain various state-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation accuracy on ImageNet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The advent of neural architecture search (NAS) has brought deep learning into an era of automation <ref type="bibr" target="#b54">[55]</ref>. Abundant efforts have been dedicated to searching within carefully designed search space <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b45">46]</ref>. Meanwhile, the evaluation of a network's performance is an important building block for NAS. Conventional approaches evaluate an enormous amount of models based on resource-devouring training <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b44">45]</ref>. Recent attention has been drawn to improve its efficiency via parameter sharing <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Generally speaking, the weight-sharing approaches all involve training a supernet that incorporates many candidate subnetworks. They can be roughly classified into two categories: those who couple searching and training within one stage <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b48">49]</ref> and others who decouple them into two stages, where the trained supernet is treated as an evaluator for final searching <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">32]</ref>. The supernet is a * This work was done when all the authors were at Xiaomi AI Lab. so-called one-shot model.</p><p>Despite being widely utilized due to searching efficiency, weight sharing approaches are roughly built on empirical experiments instead of solid theoretical ground. Several fundamental issues remain to be addressed. Namely, a) Why is there a large gap between the range of supernet predicted accuracies and that of "ground-truth" ones by stand-alone training from scratch <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref>? b) How to build a good evaluator that neither overestimates nor underestimates subnetworks? c) Why does the weight-sharing mechanism work, if under some conditions?</p><p>In this paper, we attempt to answer the above three questions for two-stage weight-sharing approaches. We present Fair Neural Architecture Search (FairNAS) in which we train the supernet under the proposed fairness constraints to improve evaluation confidence. Our analysis and experiments are conducted in a widely used search space as in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b41">42]</ref>, as well as a cell-based search space from a common benchmark NAS-Bench-201 <ref type="bibr" target="#b12">[13]</ref>. The contributions can be summarized as follows.</p><p>Firstly, we prove it is due to unfair bias that the supernet misjudges submodels' performance, which is inevitable in current one-shot approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref>.</p><p>Secondly, we propose two levels of fairness constraints: Expectation Fairness (EF) and Strict Fairness (SF). They are enforced to alleviate supernet bias and to boost evaluation capability. Both outperform the existing unfair approaches while SF performs best with a ranking (? ) of 0.7412 on NAS-Bench-201.</p><p>Thirdly, we unveil the root cause of the validity of singlepath supernet training under our fairness perspective. That is, different choice blocks are interchangeable during the supernet training as they learn similar feature maps, according to their high cosine similarity measure, see <ref type="figure">Figure 2</ref>.</p><p>Last but not the least, our fair single-path sampling is memory-friendly, and its GPU costs can also be linearly amortized to the number of target models, see <ref type="figure" target="#fig_1">Fig. 1</ref>. We then incorporate our supernet with an EA-based multi-objective searching framework, from which we obtain three state-ofthe-art networks within a single proxyless run at a cost of 12 GPU days on ImageNet.  <ref type="figure" target="#fig_1">Figure 1</ref>. Left: The supernet trained with Strict Fairness (FairNAS) gives more reliable accuracy prediction (higher correlation ? ) than those of Expectation Fairness (EF). Top: Relation between supernet-predicted accuracies on ImageNet and ground-truth ones. Bottom: Histograms of validation accuracies from a stratified sample (960 each) of one-shot models. Note EF baselines sample one path and perform k = 6 iterations at each step, while SPOS <ref type="bibr" target="#b14">[15]</ref> is a special case of EF. All methods use the same lr except the light blue one that reduces to 1/6lr. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.0</head><p>A v g : 0 .9 3 A v g : 0 .9 5 A v g : 0 .9 4 A v g : 0 .9 3 A v g : 0 .9 5 A v g : 0 .9 4 <ref type="figure">Figure 2</ref>. Left: Feature maps activated from 6 blocks of the first layer in our supernet trained with strict fairness. Right: Cross-block cosine similarity averaged on each channel. Each block learns very similar feature maps (similarity all above 0.9)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Fairness Taxonomy of Weight-sharing NAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Review of Biased Supernets</head><p>On the one hand, supernet training and searching for good models are nested. In ENAS <ref type="bibr" target="#b34">[35]</ref>, the sampling policy ?(m, ?) of an LSTM controller <ref type="bibr" target="#b16">[17]</ref> and a sampled subnetwork m are alternatively trained. The final models are sampled again by the trained policy ?, one who has the highest reward on a mini-batch of validation data is finally chosen. DARTS <ref type="bibr" target="#b28">[29]</ref> combines the supernet training and searching within a bi-level optimization where each operation is associated with a coefficient denoting its importance. Both two methods treat all subnetworks unequally and introduce gradually increasing biases through optimization. Those who have better initial performance are more likely to be sampled or to maintain higher coefficients, resulting in a suboptimal or an even worse solution. For instance, architectures from DARTS usually contain an excessive number of skip connections <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b25">26]</ref>, which damage the outcome performance. Therefore, the prior-learning DARTS is biased as per skip connections, while a random approach doesn't suffer <ref type="bibr" target="#b24">[25]</ref>. DARTS overrated 'bad' models (jammed by skip connections), meantime many other good candidates are depreciated.</p><p>On the other hand, the rest one-shot methods consider the trained supernet as a confident proxy, which we also follow, to predict the real performance of all subnetworks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b14">15]</ref>. We emphasize that a reliable proxy supernet should neither severely overestimate nor underestimate the ground-truth performance of any model. The next searching stage is decoupled from training and it can be implemented with random sampling, evolutionary algorithms, or reinforcement learning.</p><p>SMASH <ref type="bibr" target="#b1">[2]</ref> invents a hyper network (referred to as Hy-perNet H) to generate the weights of a neural architecture by its binary encoding. This HyperNet resembles a typical supernet in that they can both produce weights for any architecture in the search space. At each step, a model is randomly sampled and trained based on the generated weights from H, and in turn, it updates the weights of H. For a set of randomly sampled models, a correlation between predicted validation errors and ground-truth exists, but it has a large discrepancy between the ranges, i.e., 40%-90% vs. 25%-30% on CIFAR-100 <ref type="bibr" target="#b23">[24]</ref>.</p><p>One-Shot <ref type="bibr" target="#b0">[1]</ref> involves a dynamic dropout rate for the supernet, each time only a subset is optimized. Apart from its training difficulty, there is also an evident performance gap of submodels with inherited weights compared with their ground-truth, i.e., 30%-90% vs. 92%-94.5% on CIFAR-10 [24].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Evaluating Supernets by Ranking Ability</head><p>Regardless of how supernets are trained, what matters most is how well they predict the performance of candidate models. To this end, a recent work <ref type="bibr" target="#b40">[41]</ref> evaluates weight-sharing supernets with Kendall Tau (? ) metric <ref type="bibr" target="#b21">[22]</ref>. It measures the relation between one-shot models and standalone trained ones. The range of ? is from -1 to 1, meaning the rankings are totally reversed or completely preserved, whereas 0 indicates no correlation at all. Surprisingly, most recent approaches behave incredibly poorly on this metric <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41]</ref>. A method based on time-consuming incomplete training only reaches an average ? of 0.474 <ref type="bibr" target="#b53">[54]</ref>.</p><p>Given the above biased supernets, we are motivated to revisit one-shot approaches to discover what might be the cause of the obvious range disparity, and, how much does unfair training affect their ranking ability. We ponder that if the supernet is trained free of bias, will it improve evaluation confidence and narrow the accuracy gap? Next, we start with a formal discussion of fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Formal Formulation of Fairness</head><p>What kind of fairness can we think of? Will fairness help to improve supernet performance and ranking ability? First of all, to remove the training difference between a supernet and its submodels, we scheme an equality principle on training modality. Only those who train a single path model at each step meet this principle by its definition. On the contrary, other methods like DARTS <ref type="bibr" target="#b28">[29]</ref> train the supernet with all paths altogether, One-Shot <ref type="bibr" target="#b0">[1]</ref> dynamically drops out some paths, and ProxylessNAS <ref type="bibr" target="#b3">[4]</ref> uses two paths, directly violating the principle.</p><p>Formally, we discuss fairness in a common supernet that consists of L layers, each with several choice blocks. Without loss of generality, we suppose each layer has an equal number of choices, say m. A model is generated by sampling a block layer by layer. The weights are updated for n times in total. Therefore, we can describe the training process as P (m, n, L).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">First Attempt: Expectation Fairness</head><p>In order to reduce the above mentioned bias in Section 2.1, a natural way is to guarantee all choices blocks have equal expectations after n steps. We define this basic requirement as expectation fairness in Definition 2.2. Definition 2.2. Expectation Fairness. On the basis of Definition 2.1, let ? be the sampling space containing m basic events {l 1 , l 2 , ..., l m }, which are generated by selecting a block from layer l with m choice blocks. Let Y li be the number of times that the outcome l i is observed (updated) over n trials. Then the expectation fairness is that for P (m, n, L),</p><formula xml:id="formula_0">E(Y l1 ) = E(Y l2 ) = ... = E(Y lm ) holds, ?l ? L.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">An EF Example: Uniform Sampling</head><p>Let us check a single-path routine <ref type="bibr" target="#b14">[15]</ref> which uses uniform sampling. As sampling on any layer l is independent of others, we first consider the case P (m, n, l). Selecting a block from layer l is subject to a categorical distribution. In this case, each basic event occurs with an equal probability p(X = l i ) = 1 m . For n steps, the expectation and variance of Y li can be written as,</p><formula xml:id="formula_1">E(Y li ) = n * p li = n/m Var(Y li ) = n * p li (1 ? p li ) = n(m ? 1) m 2<label>(1)</label></formula><p>That's to say, all choices share the same expectation and variance. Consequently, uniform sampling meets Expectation Fairness by Definition 2.2 and it seems superficially fair for various choices. However, Expectation Fairness is not enough. For example, we can randomly sample each model and keep it training for k times, then switch to another. This procedure also meets Definition 2.2, but it's very unstable to train.</p><p>Even in SPOS <ref type="bibr" target="#b14">[15]</ref> with uniform sampling, there is a latent ordering issue. For a sequence of choices (M 1 , M 2 ,</p><formula xml:id="formula_2">M 3 ), it implies an inherent training order M 1 ? M 2 ? M 3 .</formula><p>Since each model is usually trained by back-propagation, the trained weights of M 1 are immediately updated to the supernet and those of M 2 are renewed next while carrying the effect of the former update, so for M 3 . A simple permutation of (M 1 , M 2 , M 3 ) does comply with Expectation Fairness but yields different results. Besides, if the learning rate lr is changed within the sequence, the situation thus becomes even more complicated.</p><p>Generally, for P (m, n, L) where m, n, L are positive integers, assume the sampling times n can be divided by m(? 2). If we adopt uniform sampling, as n goes infinite, it is impossible for m choices to be sampled for an exactly equal number of times. This is formally stated as below.</p><formula xml:id="formula_3">Lemma 2.1. Regarding P (m, n, L), ? n ? {x : x%m = 0, x ? N + }, lim n?+? p(Y l1 = Y l2 = ... = Y lm ) = 0. Proof. Let f (m, n) = p(Y l1 = Y l2 = ... = Y lm ). f (m, n) = C n m n C n m n(m?1) m ...C n m n m 1 m n = n! ( n m !) m 1 m n (2)</formula><p>Firstly, we prove the existence of limitation, f (n) strictly decreases monotonically with n and f (n) ? 0, therefore, its limitation exists.</p><p>Secondly, we calculate its limitation using equivalent infinity replacement based on Stirling's approximation about factorial <ref type="bibr" target="#b47">[48]</ref>.</p><formula xml:id="formula_4">lim n?+? f (m, n) = lim n?+? n! ( n m !) m ? m n = lim n?+? ? 2?n( n e ) n 2? n m m ( n e ) n = lim n?+? ? m 2?n m m?1 2 = 0 (3) Q.E.D.</formula><p>Lemma 2.1 is somewhat counter-intuitive and thereby neglected in previous works. To throw light on this phenomenon, we plot this probability curve in <ref type="figure" target="#fig_4">Figure 3</ref>. We see that f (2, n) decreases below 0.2 when n ? 20. In most cases, n ? 10 6 , which suffers severely from this issue.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">A Meticulous Overhaul: Strict Fairness</head><p>Our insights come from the above overlooked phenomenon. We propose a more rigorous requirement that ensures the parameter of every choice block be updated the same amount of times at any stage, which is called strict fairness and formally as Definition 2.3.</p><formula xml:id="formula_5">Definition 2.3. Strict Fairness. Regarding P(m, n, L), ? n ? {x : x%m = 0, x ? N + } , Y l1 = Y l2 = ... = Y lm holds. Definition 2.3 imposes a constraint more demanding than Definition 2.2. That is, p(Y l1 = Y l2 = ... = Y lm ) = 1</formula><p>holds at any time. It seems subtle but it will be later proved to be crucial. Nevertheless, we have to be aware that it is not ultimate fairness since different models have their own optimal initialization strategy and hyperparameters, which we single them out for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fair Neural Architecture Search</head><p>Our NAS pipeline is divided into two stages: training the supernet and searching for competitive models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Stage 1: Train Supernet with Strict Fairness</head><p>We first propose a fair sampling and training algorithm to strictly abide by Defintion 2.3. We use uniform sampling without replacement and sample m models at step t so that each choice block must be activated and updated only once. This is detailed in Algorithm 1 and depicted by for i = 1 to N do for data, labels in D do for l = 1 to L do c l = an uniform index permutation for the choices of layer l end for Clear gradients recorder for all parameters ?? j,l = 0, j = 1, 2, ..., m, l = 1, 2, ..., To reduce the bias from different training orders, we don't perform back-propagation and update parameters immediately for each model as in the previous works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>. Instead, we define one supernet step as several back-propagation operations (BPs) accompanied by a single parameter update. In particular, given a mini-batch of training data, each of m single-path models is trained with back-propagation. Gradients are then accumulated across the selected m models but supernet's parameters get updated only when all m BPs are done. This approach also doesn't suffer from the ordering issue as each choice block is updated regardless of external learning rate strategies.</p><formula xml:id="formula_6">L for k = 1 to m do Build model k = (c 1 k , c 2 k , .., c L k ) from</formula><p>Strict Fairness Analysis. We now check whether our proposed Algorithm 1 satisfies Strict Fairness. By its design, each choice block is activated only once during a parameter update step.  </p><formula xml:id="formula_7">Thus Y l1 = Y l2 = ... = Y lm holds. In particular, Y l1 = Y l2 = ... = Y lm = n/m</formula><formula xml:id="formula_8">E(Y li ) = n/m, Var(Y li ) = 0<label>(4)</label></formula><p>Compared with Equation 1, the obvious difference lies in the variance. For the single-path approach with uniform sampling <ref type="bibr" target="#b14">[15]</ref>, the variance spreads along with n, which gradually increases the bias. However, our approach calibrates this inclination and assures fairness at every step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Stage 2: Searching with Supernet</head><p>For searching, we can either choose random search, vanilla evolutionary algorithms, or reinforcement learning. In practice, there are many requirements and objectives to achieve, e.g., inference time, multiply-adds, and memory costs, etc. This leads us to adopt a multi-objective solution. Besides, as the search space is too vast to enumerate all models, we need an efficient approach to balance the exploration and exploitation trade-off instead of a random sampling strategy. Here we adopt a searching algorithm from an NSGA-II <ref type="bibr" target="#b8">[9]</ref> with a small variation by using Proximal Policy Optimization <ref type="bibr" target="#b39">[40]</ref> as the default reinforcing algorithm. The whole process is given in Algorithm 2. Benefiting from the fast evaluation of the weight-sharing supernet, we can achieve tremendous speed-up in terms of GPU days by two orders of magnitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Search Space. We use several search spaces in this paper. The first one is that of NAS-Bench-201 <ref type="bibr" target="#b12">[13]</ref>, which is a new benchmark for NAS methods. Besides, We adopt two extra search spaces to compare with other NAS methods on ImageNet, (a) A search space for fairness analysis, which is based on MobileNetV2's inverted bottleneck blocks as done in <ref type="bibr" target="#b3">[4]</ref>. In particular, we retain the same amount of layers <ref type="bibr" target="#b2">3</ref>  </p><formula xml:id="formula_9">for i = 1 to G do R i = P i ? Q i for all p ? R i do Evaluate model p with inherited weights from SN on D end for F = non-dominated-sorting(R i )</formula><p>Pick N individuals to form P i+1 by ranks and the crowding distance. M = tournament-selection(P i+1 ) Q i+1 = crossover(M ) ? hierarchical-mutation(M ) end for Select K evenly-spaced models from P G+1 to train with standard MobileNetV2 <ref type="bibr" target="#b38">[39]</ref>. Convolution kernels are with the size in <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7)</ref> and expansion rates are of <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b5">6)</ref>. We keep the number of filters unchanged. Besides, the squeezeand-excitation block <ref type="bibr" target="#b19">[20]</ref> is excluded. In total, it has a size of 6 16 . (b) A search space of 19 layers as ProxylessNAS <ref type="bibr" target="#b3">[4]</ref>, whose size spreads to 6 <ref type="bibr" target="#b18">19</ref> . This is to be on par with various state-of-the-art methods.</p><p>Training Hyperparameters. For NAS-Bench-201, we train the supernet for 50 epochs using a batch size of 128. The initial learning rate is 0.025 and decayed to zero by the cosine schedule.</p><p>For search space (a), we train the supernet for 150 epochs using a batch size of 256 and adopt a stochastic gradient descent optimizer with a momentum of 0.9 <ref type="bibr" target="#b42">[43]</ref> based on standard data augmentation as <ref type="bibr" target="#b38">[39]</ref>. A cosine learning rate decay strategy <ref type="bibr" target="#b29">[30]</ref> is applied with an initial learning rate of 0.045. Moreover, We regularize the training with L2 weight decay (4 ? 10 ?5 ). Our supernet is thus trained to fullness in 10 GPU days.</p><p>For search space (b), we follow the same strategy as above for training the supernet, but we adopt vanilla data processing as well as training tricks in <ref type="bibr" target="#b44">[45]</ref> for stand-alone models. Regarding the stand-alone training of sampled models, we use similar training tricks. To be consistent with the previous works, we don't employ tricks like cutout <ref type="bibr" target="#b9">[10]</ref> or mixup <ref type="bibr" target="#b52">[53]</ref>, although they can further improve the scores on the test set.   <ref type="table" target="#tab_3">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Search</head><p>Notably, FairNAS-A obtains a highly competitive result 75.3% top-1 accuracy for ImageNet classification, which surpasses MnasNet-92 (+0.5%) and Single-Path-NAS (+0.3%). FairNAS-B matches Proxyless-GPU with much fewer parameters and multiply-adds. Besides, it surpasses Proxyless-R Mobile (+0.5%) with a comparable amount of multiply-adds.</p><p>Our models also reach a new state of the art when equipped with combined tricks such as Squeeze-and-Excitation <ref type="bibr" target="#b19">[20]</ref>, Swish activations <ref type="bibr" target="#b35">[36]</ref> and AutoAugment <ref type="bibr" target="#b7">[8]</ref>. Namely, FairNAS-A obtains 77.5% top-1 accuracy by using similar FLOPS as EfficientNet-B0 . Even without mixed kernels <ref type="bibr" target="#b46">[47]</ref>, FairNAS-B (77.2%) outperforms MixNet-M (77.0%) with 11M fewer FLOPS. The most light-weight model FairNAS-C (76.7%) also outperforms EfficientNet-B0 with about 20% fewer FLOPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Search on NAS-Bench-201.</head><p>To be comparable with existing methods, we formulate our problem as a single objective one: finding the best model. Specially, we use a standard evolutionary algorithm in the second stage after the supernet is fairly trained. The result is shown in <ref type="table">Table 2</ref>. Our method outperforms the other baselines in most datasets with the lowest search cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Transferred Results on CIFAR</head><p>To validate transferability of FairNAS models, we adapt the pre-trained models on ImageNet to CIFAR-10 and CIFAR-100 following the configuration of GPipe <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b22">[23]</ref>. <ref type="table">Table 3</ref> shows that FairNAS models outperform the rest transferred models with higher top-1 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Transferability on Object Detection</head><p>For object detection, we treat FairNAS models as drop-in replacements for RetinaNet's backbone <ref type="bibr" target="#b26">[27]</ref>. We follow the same setting as <ref type="bibr" target="#b26">[27]</ref> and exploit MMDetection toolbox <ref type="bibr" target="#b4">[5]</ref> for training. All the models are trained and evaluated on MS COCO dataset (train2017 and val2017 respectively) <ref type="bibr" target="#b27">[28]</ref> for 12 epochs with a batch size of 16. The initial learning rate is 0.01 and decayed by 0.1? at epochs 8 and 11. The input features from these backbones to the FPN module are from the last depthwise layers of stage 2 to 5 4 . The number of output channels of FPN is kept 256 as <ref type="bibr" target="#b26">[27]</ref>. We also use ? = 0.25 and ? = 2.0 for the focal loss. Given longer training epochs and other tricks, the detection performance can be improved further. However, it's sufficient to compare the transferability of various methods. The results are given in <ref type="table">Table 4</ref>, we have the best transferability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Transferability on Semantic Segmentation</head><p>We further evaluate FairNAS models as a feature extractor with DeepLabv3+[6] on the mobile semantic segmentation task, which confirms FairNAS backbones are competitive. All models are first pre-trained on COCO dataset <ref type="bibr" target="#b27">[28]</ref>, then coarsely trained on VOC2012 <ref type="bibr" target="#b13">[14]</ref>  i.e. model ranking.</p><p>For supernet training, we set up three control groups that meet Expectation Fairness as our baselines. a) EF lr, uniformly sampling one path and train k times, followed by parameter update. b) EF 1/6lr: same as the first one except that the learning rate is scaled by 1 k . In practice, we set k = 6 to make it comparable to FairNAS. c) SPOS : an reimplementation of Single-Path One-Shot <ref type="bibr" target="#b14">[15]</ref>. Other hyperparameters are kept the same. Note a), c) and FairNAS all use the same learning rate lr.</p><p>We run the search pipeline for 200 epochs with a population size of 64, sampling 12,800 models in total. It takes only 2 GPU days due to accelerated evaluation. Due to high training cost, we sampled 13 models at approximately equal distances on the Pareto front and trained them from scratch to get the ranking, which is shown to the right of <ref type="figure" target="#fig_1">Figure 1</ref>. We observe that the FairNAS supernet gives a highly relevant ranking while Single-Path One-Shot <ref type="bibr" target="#b14">[15]</ref> doesn't. The training process of sampled models is plotted in <ref type="figure">Figure 9</ref> (see supplementary).</p><p>We further adopt Kendall Tau <ref type="bibr" target="#b21">[22]</ref> for the ranking analysis following a recent work <ref type="bibr" target="#b40">[41]</ref> that evaluates NAS approaches. A method based on incomplete training reaches an average ? of 0.474 <ref type="bibr" target="#b53">[54]</ref>. Instead, we hit a new high record of the Kendall rank correlation coefficient ? = 0.9487. We show our ranking comparison with baseline groups in Table <ref type="bibr" target="#b5">6</ref>. In general, methods with EF have a better ranking than those without EF, while SF is the best of all, which discloses the relevance of fairness to ranking in one-shot approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparisons of Searching Algorithms</head><p>For the second-stage, we adopt multi-objective optimization where three objectives are considered: accuracies, multiply-adds, and the number of parameters. Specifically, we apply MoreMNAS with a minor modification in which PPO <ref type="bibr" target="#b39">[40]</ref> is utilized instead of REINFORCE <ref type="bibr" target="#b43">[44]</ref>.</p><p>We construct several comparison groups that cover the main searching algorithms: a) EA: NSGA-II with reinforced mutation, b) random search, c) Multi-objective RL: Mnas-Net which uses PPO with a mixed multi-objective reward <ref type="bibr" target="#b44">[45]</ref>. The results are shown in <ref type="figure" target="#fig_12">Figure 5</ref>, control groups generally align within our Pareto front and are constricted within a narrow range, affirming an excellent advantage in the MoreMNAS variant.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Component Contribution Analysis</head><p>Being a two-stage method, which stage contributes more to the final performance of the architecture? The experiment in NAS-Bench-201 has answered this question. To be complete, we further compare various supernet training strategies while fixing the second stage using the ImageNet dataset. Considering it's not affordable to train the entire models from Pareto front, we impose an explicit constraint of maximum 400M FLOPS. The best models from One-Shot <ref type="bibr" target="#b1">[2]</ref> (no EF) and SPOS (EF) <ref type="bibr" target="#b6">[7]</ref> reach 74.0% and 74.6% top-1 accuracies, indicating that our result (75.3%) benefits mainly from the ranking capacity of the supernet in the first stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Why Does Single-Path Training Work?</head><p>Our supernet generates a relatively small range of oneshot accuracies, from which we postulate that choice blocks be quite alike in terms of capacity. In fact, given an input of a chickadee image, the choice blocks of the first layer yield similar feature maps on the same channel, as shown in <ref type="figure">Figure 2</ref>. But how much do they resemble each other? We involve the cosine similarity <ref type="bibr" target="#b33">[34]</ref> to measure the distance among various feature vectors. It ranges from -1 (opposite) to 1 (identical), where 0 indicates no correlation. In <ref type="figure">Figure 6</ref>, each 6?6 symmetric matrix shows the cross-block distances per channel, they are very similar (above 0.9).  <ref type="figure">Figure 6</ref>. Cross-block channel-wise cosine similarity matrix on feature maps of 6 choice blocks in Layer 1. We observe that each choice block learns very similar features on the same channel In summary, the channel-wise feature maps generated by our supernet come with high similarities. We conclude that this important characteristic significantly stabilizes the whole training process. For layer l + 1, its input is randomly from choice blocks in the previous layer l. As different choices have highly similar channel-aligned features, the random sampling constructs a mechanism mimicking feature augmentation, which boosts the supernet training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Fairness Closes Supernet Accuracy gap</head><p>As discussed in Section 2.1, previous one-shot methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1]</ref> have a large accuracy gap between the one-shot and stand-alone models. We define it as supernet accuracy gap, ? = |? oneshot ? ? standalone |, where ? oneshot is the accuracy range of one-shot models, and ? standalone for stand-alone models. Ideally, ? oneshot can be obtained by evaluating all paths from the supernet but not affordable since the search space is enormous. Instead, we can approximate ? oneshot by covering a wide range of models. We randomly sample 1,000 models from our supernet, then we evaluate these models directly on the ImageNet validation set. Their top-1 accuracies (see <ref type="figure" target="#fig_1">Figure 1</ref>) range from 0.666 to 0.696, which leads to ? oneshot = 0.03, hence it reduces ? as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this work, we scrutinize the weight-sharing neural architecture search with a fairness perspective. Observing that unfairness inevitably incurs a severely biased evaluation of one-shot model performance, we propose two degrees of fairness enhancement, where Strict Fairness (SF) works best. Our supernet trained under SF then acts as a performance evaluator. In principle, the fair supernet can be incorporated in any search pipeline that requires an evaluator. To demonstrate its effectiveness, we adopt a multi-objective evolutionary backend. After searching proxylessly on Im-ageNet for 12 GPU days, we harvest three state-of-the-art models of different magnitudes nearby Pareto Optimality. Future works remain as to study fairness under heterogenous search spaces and to improve the evaluation performance of the supernet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. More Discussion of Algorithms</head><p>A.1. Supernet Training <ref type="figure" target="#fig_6">Figure 4</ref> details the supernet training stage of our approach. In fact, it's inherently efficient regarding GPU utilization. Even on powerful machines such as Tesla V100, it can make full use of GPU without special optimization. As most of the existing deep learning frameworks allow paralleled execution between data generation and gradient calculation, our algorithm can exploit this parallelism to the extreme since a mini-batch of data is reused by m times of backpropagation. The GPUs are always busy because the data is ready whenever required, which shortens the training time. Moreover, our method works in a single-path way, which is memory friendly.</p><p>Irregular Search Spaces. Note that SF in the paper can be easily extended by a preprocessing function in case of irregular search spaces (i.e. the number of operations are not the same for each layer). We only need to make a minor modification of Algorithm 1. Say the l-th layer has m l choices. Suppose M = max(m l ), we randomly choose M ? m l extra operations from m l choices and regard these extra options as different ones from the original search space. Therefore, the input condition of Algorithm 1 still hold and we can use it directly. This procedure can be regarded as an approximated SF. However, perfect SF for irregular cases remains as our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Evolutionary Searching Pipeline</head><p>With our supernet fairly trained as a model evaluator, we adopt an evolutionary-based algorithm for searching, detailed in Algorithm 2 (main text) and <ref type="figure">Figure 7</ref>. Generally, it is built on the ground of MoreMNAS <ref type="bibr" target="#b6">[7]</ref> by replacing its incomplete-training evaluator with our fairly trained supernet. FairNAS supernet exhibits tremendous speed-up in terms of GPU days by two orders of magnitudes. We also use Proximal Policy Optimization as the default reinforcement algorithm <ref type="bibr" target="#b39">[40]</ref>.  <ref type="figure">Figure 7</ref>. Evolutionary searching with the supernet trained with strict fairness. In each generation, candidate models in the current population inherit weights from the supernet for evaluation. Their estimated accuracies are fed into the searching pipeline as one of the objectives. The evolution loops till Pareto optimality.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. A Fairness Taxonomy</head><p>We compare current weight-sharing NAS methods based on the defined fairness in <ref type="table" target="#tab_6">Table 7</ref>. SPOS <ref type="bibr" target="#b14">[15]</ref> satisfies Expectation Fairness, while FairNAS meets Strict Fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiment Details</head><p>Dataset. The supernet experiments are performed on ImageNet <ref type="bibr" target="#b37">[38]</ref> and we randomly select 50,000 images from the training set as our validation set (50 samples from each class). The remaining training set is used as our training set, while the original validation set is taken as the test set to measure the final performance of each model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Architectures of Searched Models</head><p>The searched FairNAS-A, B and C models are illustrated in <ref type="figure" target="#fig_8">Figure 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Hyperparameters for MoreMNAS variant</head><p>We list the hyperparameters for the adopted MoreMNAS <ref type="bibr" target="#b6">[7]</ref> variant in <ref type="table" target="#tab_7">Table 8</ref>. It has a population N of 64 models. It also takes a hierarchical mutation strategy. Respectively, p rm , p re , p pr indicate probabilities for random mutation, reinforce mutation and prior regulator, where p re again is divided into p K?M for roulette wheel selection, and p M for reinforced controller. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Training of stand-alone models</head><p>We picked 13 models to train from scratch whose oneshot accuracies are approximately evenly spaced, ranging in   <ref type="figure">Figure 9</ref> plots the training process, from which we observe the ranking of one-shot models are generally maintained. The model-meta (indices of operations) of these 13 models are listed in <ref type="table">Table 9</ref>. Besides, the mapping from an index in model-meta to a searchable operation is given in <ref type="table" target="#tab_3">Table 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index</head><p>Model Meta 0 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 1 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 2 [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] 3 [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0] 4</p><p>[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0] 5 [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0] 6 [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0] 7 [0, 1, 0, 1, 1, 4, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0] 8</p><p>[0, 1, 4, 1, 0, 3, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0] 9</p><p>[0, 1, 0, 0, 1, 5, 1, 1, 0, 5, 1, 1, 0,  <ref type="table">Table 9</ref>. Model-meta of 13 sampled stand-alone models for ranking analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Evolutionary Searching</head><p>The evolutionary search of FairNAS based on MoreM-NAS variant <ref type="bibr" target="#b6">[7]</ref> is shown in <ref type="figure" target="#fig_1">Figure 10</ref>. At each generation, 64 models are evaluated by our fair supernet, after 200 generations, the evolution converges, the Pareto-front is shown in bright yellow, each dot represents a candidate network. <ref type="table" target="#tab_3">Rate   0  3  3  1  5  3  2  7  3  3  3  6  4  5  6  5</ref> 7 6   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Meta Index kernel Expansion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5. Object Detection</head><p>For object detection, we treat FairNAS models as drop-in replacements for RetinaNet's backbone <ref type="bibr" target="#b26">[27]</ref>. We follow the same setting as <ref type="bibr" target="#b26">[27]</ref> and exploit MMDetection toolbox <ref type="bibr" target="#b4">[5]</ref> for training. All the models are trained and evaluated on MS COCO dataset (train2017 and val2017 respectively) <ref type="bibr" target="#b27">[28]</ref> for 12 epochs with a batch size of 16. The initial learning rate is 0.01 and decayed by 0.1? at epochs 8 and 11.</p><p>All baselines in the paper are mobile networks. The input features from these backbones to the FPN module are from the last depthwise layers of stage 2 to 5 5 . The number of output channels of FPN is kept 256 as <ref type="bibr" target="#b26">[27]</ref>. We also use ? = 0.25 and ? = 2.0 for the focal loss. Given longer training epochs and other tricks, the detection performance can be improved further. However, it's sufficient to compare the transferability of various methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 B</head><label>1</label><figDesc>Right: Comparison of amortized GPU cost and memory consumption Layer lo c k 0 B lo c k 1 B lo c k 2 B lo c k 3 B lo c k 4 B lo c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Definition 2 . 1 .</head><label>21</label><figDesc>Equality Principle. Training a supernet satisfies the equality principle if and only if it is in the same way how a submodel is trained.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>The function curve of f (m, n) in Lemma 2.1. When sampling uniformly from m blocks for n trials, the probability of having an equal sampling number for each block quickly reaches zero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 . 1 :</head><label>41</label><figDesc>Algorithm Stage 1 -Fair Supernet Training. Input: training steps n, search space S (m,L) , m ? L supernet parameters ?(m, L), search layer depth L, choice blocks m per layer, training epochs N , training data loader D, loss function Loss initialize every ? j,l in ? (m,L) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Our strict fairness sampling and training strategy for supernet. A supernet training step t consists of training m models, each on one batch of data. The supernet gets its weights updated after accumulating gradients from each single-path model. All operations are thus ensured to be equally sampled and trained within every step t. There are (6!) 18 choices per step in our experiments 2 expectation and variance as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Result 4 . 2 . 1</head><label>421</label><figDesc>Search on ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 (</head><label>8</label><figDesc>supplementary) exhibits the resulting FairNAS-A, B and C models, which are sampled from our Pareto front to meet different hardware constraints. The quantitative result is shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 .</head><label>5</label><figDesc>Pareto front (last generation elitists PG+1) of the MoreM-NAS variant (adopted) compared with Left: NSGA2 (EA-like baseline) with RL mutator and random search (random baseline), Right: MnasNet (RL baseline). Each samples 1,088 models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 8 .</head><label>8</label><figDesc>Architectures of FairNAS-A,B,C (from top to bottom). MBEx Ky means an expansion rate of x and a kernel size of y for its depthwise convolution [0.641, 0.7]. We keep the exactly same hyperparameters as the supernet training. Their corresponding stand-alone accuracies are within [0.692, 0.715].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Train and validation accuracies (ground truth) of all 13 stand-alone models when being fully trained with the same hyperparameters. Lines are labelled with corresponding one-shot accuracies (predicted) sorted in descending order (as reflected by color gradient). FairNAS evolution process of 200 generations, with 64 models sampled in each generation. Number of parameters, multiply-adds are charted with top-1 accuracies on the ImageNet validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>sampled index Calculate gradients for model k based on Loss, data, labels. Accumulate gradients for activated parameters, ?? c1 k ,1 , ?? c2 k ,2 , ..., ?? c L k ,L end for update ? (m,L) by accumulated gradients.</figDesc><table><row><cell>end for</cell></row><row><cell>end for</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>holds<ref type="bibr" target="#b2">3</ref> . Here, we write its</figDesc><table><row><cell></cell><cell cols="6">sample m models without replacement and train them sequentially</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>step t:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>stem</cell><cell>op1 op2 op3 op4</cell><cell></cell><cell>op1 op2 op3 op4</cell><cell></cell><cell>op1 op2 op3 op4</cell><cell cols="3">op1 op2 op3 op4</cell><cell cols="2">op1 op2 op3 op4</cell></row><row><cell>Layer 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Layer 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>...</cell><cell>...</cell><cell>?? 1</cell><cell>...</cell><cell>?? 2</cell><cell>...</cell><cell>?? 3</cell><cell>...</cell><cell cols="2">?? 4 update ?</cell><cell>...</cell></row><row><cell>Layer L</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tail</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Models</cell><cell cols="3">?+ P Top-1 M</cell><cell>Cost</cell></row><row><cell></cell><cell cols="3">(M) (M) (%)</cell><cell>(GPU days)</cell></row><row><cell>MobileNetV2 [39]</cell><cell cols="3">300 3.4 72.0 -</cell><cell>-</cell></row><row><cell>NASNet-A [56]</cell><cell cols="3">564 5.3 74.0 SM</cell><cell>1800</cell></row><row><cell>MnasNet-92 [45]</cell><cell cols="3">388 3.9 74.8 SM</cell><cell>?4k</cell></row><row><cell>DARTS [29]</cell><cell cols="3">574 4.7 73.3 SN</cell><cell>0.5</cell></row><row><cell cols="4">PC-DARTS (CIFAR10) [50] 586 5.3 74.9 SN</cell><cell>0.1</cell></row><row><cell cols="2">One-Shot Small (F=32) [1] -</cell><cell cols="2">5.1 74.2 SN</cell><cell>4</cell></row><row><cell>AtomNAS-A [33]</cell><cell cols="3">258 3.9 74.6 SN</cell><cell>20.5</cell></row><row><cell>FBNet-B [49]</cell><cell cols="3">295 4.5 74.1 SP</cell><cell>9</cell></row><row><cell>Proxyless-R [4]</cell><cell cols="3">320 4.0 74.6 TP</cell><cell>8.3</cell></row><row><cell>Proxyless GPU [4]</cell><cell cols="3">465 7.1 75.1 TP</cell><cell>8.3</cell></row><row><cell cols="4">Single Path One-Shot [15] 323 3.5 74.4 SP</cell><cell>12</cell></row><row><cell>Single-Path NAS [42]</cell><cell cols="3">365 4.3 75.0 SP</cell><cell>1.25</cell></row><row><cell>FairNAS-A (Ours)</cell><cell cols="3">388 4.6 75.3 SP</cell><cell>12</cell></row><row><cell>FairNAS-B (Ours)</cell><cell cols="3">345 4.5 75.1 SP</cell><cell>12</cell></row><row><cell>FairNAS-C (Ours)</cell><cell cols="3">321 4.4 74.7 SP</cell><cell>12</cell></row><row><cell>MnasNet-A2 [45]</cell><cell cols="3">340 4.8 75.6 SM</cell><cell>?4k</cell></row><row><cell>MobileNetV3 Large [18]</cell><cell cols="3">219 5.4 75.2 SM</cell><cell>?3k</cell></row><row><cell>GhostNet 1.3? [16]</cell><cell cols="3">226 7.3 75.7 -</cell><cell>-</cell></row><row><cell>EfficientNet B0 [46]</cell><cell cols="3">390 5.3 76.3 SM</cell><cell>?3k</cell></row><row><cell>OFA w/ PS #75 [3]</cell><cell cols="2">230 -</cell><cell>76.9 SP</cell><cell>175</cell></row><row><cell>BigNAS-S [51]</cell><cell cols="3">242 4.5 76.5 SP</cell><cell>48  ?</cell></row><row><cell>MixNet-M [47]</cell><cell cols="3">360 5.0 77.0 SM</cell><cell>?3k</cell></row><row><cell>AtomNAS-C+ [33]</cell><cell cols="3">363 5.9 77.6 SN</cell><cell>20.5</cell></row><row><cell>FairNAS-A  ? (Ours)</cell><cell cols="3">392 5.9 77.5 SP</cell><cell>12</cell></row><row><cell>FairNAS-B  ? (Ours)</cell><cell cols="3">349 5.7 77.2 SP</cell><cell>12</cell></row><row><cell>FairNAS-C  ? (Ours)</cell><cell cols="3">325 5.6 76.7 SP</cell><cell>12</cell></row></table><note>. Comparison of mobile models on ImageNet. M : Memory cost at all sampled sub-models (SM), a single path or two paths (SP/TP), and a whole supernet (SN). : from code,? : w/ SE and Swish, P: Number of parameters, : Cost shared among A, B and C.? : reportedly 3? EfficientNet Training</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 Table 4 .</head><label>34</label><figDesc>77?0.00 54.30?0.00 15.03?0.00 15.61?0.00 16.43?0.00 16.32?0.00 ENAS [35] 14058 37.51?3.19 53.89?0.58 13.37?2.35 13.96?2.33 15.06?1.95 14.84?2.10 SETN [11] 34139 84.04?0.28 87.64?0.00 58.86?0.06 59.05?0.24 33.06?0.02 32.52?0.21 GDAS [12] 31609 89.89?0.08 93.61?0.09 71.34?0.04 70.70?0.30 41.59?1.33 41.71?0.98 FairNAS (ours) 9845 90.07?0.57 93.23?0.18 70.94?0.94 71.00?1.46 41.90?1.00 42.19?0.31 300 72.0 28.3 46.7 29.3 14.8 30.7 38.1 SingPath NAS [42] 365 75.0 30.7 49.8 32.2 15.4 33.9 41.6 MobileNetV3 [18] 219 75.2 29.9 49.3 30.8 14.9 33.3 41.1 MnasNet-A2 [45] 340 75.6 30.5 50.2 32.0 16.6 34.1 41.1 Object detection on COCO with various drop-in backbones.</figDesc><table><row><cell>extra annotated images</cell></row></table><note>. Comparison of state-of-the-art methods on CIFAR.??? : Reimplemented.? : With or without recalculating batch normalization, ? holds the same. For EF methods, k = 6 iterations are performed at each training step</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>Comparison of state-of-the-art weight-sharing NAS methods as per cost and fairness basis. Ct, Cs: train and search cost measured in GPU days. EF: Expectation Fairness, SF: Strict Fairness.</figDesc><table /><note>? : searched on CIFAR-10,? : TPU</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Hyperparameters for the second-stage EA search.</figDesc><table><row><cell>Item</cell><cell>value Item</cell><cell>value</cell></row><row><cell cols="3">Population N 64 Mutation Ratio 0.8</cell></row><row><cell>prm</cell><cell>0.2 pre</cell><cell>0.65</cell></row><row><cell>ppr</cell><cell>0.15 pM</cell><cell>0.7</cell></row><row><cell>pK?M</cell><cell>0.3</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .</head><label>10</label><figDesc>Mapping between model-meta index and operations</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.695</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.69</cell></row><row><cell>Train Accuracy</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.685 0.68 0.675 0.67 0.665 0.66 0.655</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.65</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.645</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.64</cell></row><row><cell></cell><cell>0</cell><cell>25</cell><cell>50</cell><cell>75</cell><cell>100</cell><cell>125</cell><cell>150</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Epochs</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We use n to denote the total number of BPs operations to match Eq 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We follow the typical nomination for the definition of stages and the orders start from 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We follow the typical nomination for the definition of stages and the orders start from 1.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding and Simplifying One-Shot Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SMASH: One-Shot Model Architecture Search through HyperNetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Once for All: Train One Network and Specialize it for Efficient Deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-Objective Reinforced Evolution in Mobile Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshop</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">AutoAugment: Learning Augmentation Policies from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Fast and Elitist Multi-objective Genetic Algorithm: NSGA-II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrit</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamt</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improved Regularization of Convolutional Neural Networks with Cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">One-Shot Neural Architecture Search via Self-Evaluated Template Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3681" to="3690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Searching for A Robust Neural Architecture in Four GPU Hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html" />
		<title level="m">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Single Path One-Shot Neural Architecture Search with Uniform Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">GhostNet: More Features from Cheap Operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for Mo-bileNetV3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A New Measure of Rank Correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Do Better Imagenet Models Transfer Better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2661" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Random Search and Reproducibility for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingqiu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kechen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06035</idno>
		<title level="m">DARTS+: Improved Differentiable Architecture Search with Early Stopping</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal Loss for Dense Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Microsoft COCO: Common Objects in Context. In European Conference on Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic Gradient Descent with Warm Restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">NSGA-NET: A Multi-Objective Genetic Algorithm for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashesh</forename><surname>Dhebar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="419" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural Architecture Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">AtomNAS: Fine-Grained End-to-End Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieru</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochen</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cosine Similarity Metric Learning for Face Verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="709" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameter Sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Melody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<title level="m">Searching for Activation Functions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Regularized Evolution for Image Classifier Architecture Search. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MobileNetV2: Inverted Residuals and Linear Bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Proximal Policy Optimization Algorithms. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaicheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<title level="m">Evaluating the Search Phase of Neural Architecture Search. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Stamoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Lymberopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodhi</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the Importance of Initialization and Momentum in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">MnasNet: Platform-Aware Neural Architecture Search for Mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Mixed Depthwise Convolutional Kernels. The British Machine Vision Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixconv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">James Stirling&apos;s Methodus Differentialis: An Annotated Translation of Stirling&apos;s Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Tweddle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">FBNet: Hardware-Aware Efficient Con-vNet Design via Differentiable Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">BigNAS: Scaling up Neural Architecture Search with Big Single-stage Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<title level="m">Yassine Marrakchi, Thomas Brox, and Frank Hutter. Understanding and Robustifying Differentiable Architecture Search. International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multinomial Distribution Learning for Effective Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiawu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
