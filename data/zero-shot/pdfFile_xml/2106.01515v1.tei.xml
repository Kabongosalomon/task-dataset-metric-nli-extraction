<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Question Answering Over Temporal Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Saxena</surname></persName>
							<email>apoorvsaxena@iisc.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science Bangalore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
							<email>soumen@cse.iitb.ac.in</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
							<email>partha@google.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Question Answering Over Temporal Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (e.g., start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broadcoverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340?. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformerbased solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Temporal Knowledge Graphs (Temporal KGs) are multi-relational graph where each edge is associated with a time duration. This is in contrast to a regular KG where no time annotation is present. For example, a regular KG may contain a fact such as (Barack Obama, held position, President of USA), while a temporal KG would contain the start and end time as well -(Barack Obama, held position, President of <ref type="bibr">USA, 2008</ref><ref type="bibr">USA, , 2016</ref>. Edges may be associated with a set of non-contiguous time intervals as well. These temporal scopes on facts can be either automatically estimated <ref type="bibr" target="#b32">(Talukdar et al., 2012)</ref> or user contributed. Several such Temporal KGs have been proposed in the literature, where the focus is on KG completion <ref type="bibr" target="#b6">(Dasgupta et al. 2018;</ref><ref type="bibr" target="#b9">Garc?a-Dur?n et al. 2018;</ref><ref type="bibr" target="#b17">Leetaru and Schrodt 2013;</ref><ref type="bibr" target="#b15">Lacroix et al. 2020;</ref><ref type="bibr" target="#b12">Jain et al. 2020)</ref>.</p><p>The task of Knowledge Graph Question Answering (KGQA) is to answer natural language questions using a KG as the knowledge base. This is in contrast to reading comprehension-based question answering, where typically the question is accompanied by a context (e.g., text passage) and the answer is either one of multiple choices <ref type="bibr" target="#b26">(Rajpurkar et al., 2016)</ref> or a piece of text from the context <ref type="bibr" target="#b36">(Yang et al., 2018)</ref>. In KGQA, the answer is usually an entity (node) in the KG, and the reasoning required to answer questions is either single-fact based <ref type="bibr" target="#b2">(Bordes et al., 2015)</ref>, multi-hop <ref type="bibr" target="#b37">(Yih et al. 2015</ref><ref type="bibr" target="#b38">, Zhang et al. 2017</ref> or conjunction/comparison based reasoning <ref type="bibr" target="#b31">(Talmor and Berant, 2018)</ref>. Temporal KGQA takes this a step further where:  <ref type="bibr" target="#b13">Jia et al. (2018a)</ref>. We do not have an explicit number of temporal questions for ComplexWebQuestions, but since it is constructed automatically using questions from WebQuestions, we expect the percentage to be similar to WebQuestions (16%). Please refer to Section 2.1 for details.</p><p>Temporal KG embeddings are another upcoming area where entities, relations and timestamps in a temporal KG are embedded in a low-dimensional vector space <ref type="bibr" target="#b6">(Dasgupta et al. 2018</ref><ref type="bibr" target="#b15">, Lacroix et al. 2020</ref><ref type="bibr" target="#b12">, Jain et al. 2020</ref><ref type="bibr" target="#b10">, Goel et al. 2019</ref>. Here too, the main application so far has been temporal KG completion. In our work, we investigate whether temporal KG Embeddings can be applied to the task of Temporal KGQA, and how they fare compared to non-temporal embeddings or off-the-shelf methods without any KG Embeddings.</p><p>In this paper we propose CRONQUESTIONS, a new dataset for Temporal KGQA. CRONQUES-TIONS consists of both a temporal KG and accompanying natural language questions. There were three main guiding principles while creating this dataset: 1. The associated KG must provide temporal annotations. 2. Questions must involve an element of temporal reasoning. 3. The number of labeled instances must be large enough that it can be used for training models, rather than for evaluation alone. Guided by the above principles, we present a dataset consisting of a Temporal KG with 125k entities and 328k facts, along with a set of 410k natural language questions that require temporal reasoning.</p><p>On this new dataset, we apply approaches based on deep language models (LM) alone, such as T5 <ref type="bibr" target="#b25">(Raffel et al., 2020)</ref>, BERT <ref type="bibr" target="#b7">(Devlin et al., 2019)</ref>, and KnowBERT <ref type="bibr" target="#b23">(Peters et al., 2019)</ref>, and also hybrid LM+KG embedding approaches, such as Entities-as-Experts <ref type="bibr" target="#b8">(F?vry et al., 2020)</ref> and Em-bedKGQA <ref type="bibr" target="#b28">(Saxena et al., 2020)</ref>. We find that these baselines are not suited to temporal reasoning. In response, we propose CRONKGQA, an enhancement of EmbedKGQA, which outperforms baselines across all question types. CRONKGQA achieves very high accuracy on simple temporal reasoning questions, but falls short when it comes to questions requiring more complex reasoning. Thus, although we get promising early results, CRONQUESTIONS leaves ample scope to improve complex Temporal KGQA. Our source code along with the CRONQUESTIONS dataset can be found at https://github.com/apoorvumang/CronKGQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work 2.1 Temporal QA data sets</head><p>There have been several KGQA datasets proposed in the literature <ref type="table" target="#tab_0">(Table 1</ref>). In SimpleQuestions <ref type="bibr" target="#b2">(Bordes et al., 2015)</ref> one needs to extract just a single fact from the KG to answer a question. MetaQA <ref type="bibr" target="#b38">(Zhang et al., 2017)</ref> and <ref type="bibr">WebQuestionsSP (Yih et al., 2015)</ref> require multi-hop reasoning, where one must traverse over multiple edges in the KG to reach the answer. ComplexWebQuestions <ref type="bibr" target="#b31">(Talmor and Berant, 2018)</ref> contains both multi-hop and conjunction/comparison type questions. However, none of these are aimed at temporal reasoning, and the KG they are based on is non-temporal.</p><p>Temporal QA datasets have mostly been studied in the area of reading comprehension. One such dataset is TORQUE <ref type="bibr" target="#b22">(Ning et al., 2020)</ref>, where the system is given a question along with some context (a text passage) and is asked to answer a multiple choice question with five choices. This is in contrast to KGQA, where there is no context, and the answer is one of potentially hundreds of thousands of entities.</p><p>TempQuestions <ref type="bibr" target="#b13">(Jia et al., 2018a</ref>) is a KGQA dataset specifically aimed at temporal QA. It consists of a subset of questions from WebQuestions, Free917 <ref type="bibr" target="#b4">(Cai and Yates, 2013)</ref> and Complex-Questions <ref type="bibr" target="#b0">(Bao et al., 2016)</ref>   nature. They gave a definition for "temporal question" and used certain trigger words (for example 'before', 'after') along with other constraints to filter out questions from these datasets that fell under this definition. However, this dataset contains only 1271 questions -useful only for evaluation -and the KG on which it is based (a subset of FreeBase <ref type="bibr" target="#b1">(Bollacker et al., 2008)</ref>) is not a temporal KG. Another drawback is that FreeBase has not been under active development since 2015, therefore some information stored in it is outdated and this is a potential source of inaccuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Temporal QA algorithms</head><p>To the best of our knowledge, recent KGQA algorithms <ref type="bibr" target="#b21">(Miller et al. 2016;</ref><ref type="bibr" target="#b30">Sun et al. 2019;</ref>) work with nontemporal KGs, i.e., KGs containing facts of the form (subject, relation, object). Extending these to temporal KGs containing facts of the form (subject, relation, object, start time, end time) is a non-trivial task. TEQUILA <ref type="bibr" target="#b14">(Jia et al., 2018b)</ref> is one method aimed specifically at temporal KGQA. TEQUILA decomposes and rewrites the question into nontemporal sub-questions and temporal constraints. Answers to sub-questions are then retrieved using any KGQA engine. Finally, TEQUILA uses constraint reasoning on temporal intervals to compute final answers to the full question. A major drawback of this approach is the use of pre-specified templates for decomposition, as well as the assumption of having temporal constraints on entities. Also, since it is made for non-temporal KGs, there is no direct way of applying it to temporal KGs where facts are temporally scoped.</p><p>3 CRONQUESTIONS: The new Temporal KGQA dataset CRONQUESTIONS, our Temporal KGQA dataset consists of two parts: a KG with temporal annotations, and a set of natural language questions requiring temporal reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Temporal KG</head><p>To prepare our temporal KG, we started by taking all facts with temporal annotations from the Wiki-Data subset proposed by <ref type="bibr" target="#b15">Lacroix et al. (2020)</ref>. We removed some instances of the predicate "member of sports team" in order to balance out the KG since this predicate constituted over 50 percent of the facts. Timestamps were discretized to years. This resulted in a KG with 323k facts, 125k entities and 203 relations. However, this filtering of facts misses out on important world events. For example, the KG subset created using the aforementioned technique contains the entity World War II but no associated fact that tells us when World War II started or ended. This knowledge is needed to answer questions such as "Who was the President of the USA during World War II?." To overcome this shortcoming, we first extracted entities from WikiData that have a "start time" and "end time" annotation. From this set, we then removed entities which were game shows, movies or television series (since these are not important world events, but do have a start and end time annotation), and then removed entities with less than 50 associated facts. This final set of entitities was then added as facts in the format <ref type="bibr">(WWII, significant event, occurred, 1939</ref><ref type="bibr">(WWII, significant event, occurred, , 1945</ref>. The final Temporal KG consisted of 328k facts out of which 5k are event-facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Temporal Questions</head><p>To generate the QA dataset, we started with a set of templates for temporal reasoning. These were made using the five most frequent relations from our WikiData subset, namely ? member of sports team ? position held ? award received ? spouse   ? employer This resulted in 30 unique seed templates over five relations and five different reasoning structures (please see <ref type="table" target="#tab_2">Table 2</ref> for some examples). Each of these templates has a corresponding procedure that could be executed over the temporal KG to extract all possible answers for that template. However, similar to <ref type="bibr" target="#b38">Zhang et al. (2017)</ref>, we chose not to make this procedure a part of the dataset, to remove unwelcome dependence of QA systems on such formal candidate collection methods. This also allows easy augmentation of the dataset, since only question-answer pairs are needed.</p><p>In the same spirit as ComplexWebQuestions, we then asked human annotators to paraphrase these templates in order to generate more linguistic diversity. Annotators were given slot-filled templates with dummy entities and times, and asked to rephrase the question such that the dummy entities/times were present in the paraphrase and the question meaning did not change. This resulted in 246 unique templates.</p><p>We then used the monolingual paraphraser developed by <ref type="bibr" target="#b11">Hu et al. (2019)</ref> to automatically generate paraphrases using these 246 templates. After verifying their correctness through annotators, we ended up with 654 templates. These templates were then filled using entity aliases from WikiData to generate 410k unique question-answer pairs.</p><p>Finally, while splitting the data into train/test folds, we ensured that 1. Paraphrases of train questions are not present in test questions. 2. There is no entity overlap between test questions and train questions. Event overlap is allowed. The second requirement implies that, if the question "Who was president before Obama" is present in the train set, the test set cannot contain any question that mentions the entity 'Obama'. While this policy may appear like an overabundance of caution, it ensures that models are doing temporal reasoning rather than guessing from entities seen during training. <ref type="bibr" target="#b19">Lewis et al. (2020)</ref> noticed an issue in WebQuestions where they found that almost 30% of test questions overlapped with training questions. The issue has been seen in the MetaQA dataset as well, where there is significant overlap between test/train entities and test/train question paraphrases, leading to suspiciously high performance on baseline methods even with partial KG data <ref type="bibr" target="#b28">(Saxena et al., 2020)</ref>, which suggests that models that apparently perform well are not necessarily performing the desired reasoning over the KG.</p><p>A drawback of our data creation protocol is that question/answer pairs are generated automatically. Therefore, the question distribution is artificial from a semantic perspective. (Complex-WebQuestions has a similar limitation.) However, since developing models that are capable of temporal reasoning is an important direction for natural language understanding, we feel that our dataset provides an opportunity to both train and evaluate KGQA models because of its large size, notwithstanding its lower-than-natural linguistic variety. In Section 6.4, we show the effect that training data size has on model performance.</p><p>Summarizing, each of our examples contains 1. A paraphrased natural language question. 2. A set of entities/times in the question. 3. A set of 'gold' answers (entity or time).</p><p>The entities are specified as WikiData IDs (e.g., Q219237), and times are years (e.g., 1991). We include the set of entities/times in the test questions as well since similar to other KGQA datasets (MetaQA, WebQuestions, ComplexWebQuestions) and methods that use these datasets (PullNet, EmQL), entity linking is considered as a separate problem and complete entity linking is as-sumed. We also include the seed template and head/tail/time annotation in the train fold, but omit these from the test fold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Question Categorization</head><p>In order to aid analysis, we categorize questions into "simple reasoning" and "complex reasoning" questions (please refer to These are further categorized into the types "before/after'', "first/last" and "time join"please refer <ref type="table" target="#tab_2">Table 2</ref> for examples of these questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Temporal KG Embeddings</head><p>We investigate how we can use KG embeddings, both temporal and non-temporal, along with pretrained language models to perform temporal KGQA. We will first briefly describe the specific KG embedding models we use, and then go on to show how we use them in our QA models. In all cases, the scores are turned into suitable losses with regard to positive and negative tuples in an incomplete KG, and these losses minimized to train the entity, time and relation representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ComplEx</head><p>ComplEx <ref type="bibr" target="#b33">(Trouillon et al., 2016)</ref> represents each entity e as a complex vector u e ? C D . Each relation r is represented as a complex vector v r ? C D as well. The score ? of a claimed fact (s,</p><formula xml:id="formula_0">r, o) is ?(s, r, o) = ( u s , v r , u o ) = D d=1 u s [d]v r [d]u o [d]<label>(1)</label></formula><p>where (?) denotes the real part and c is the complex conjugate. Despite further developments, ComplEx, along with refined training protocols <ref type="bibr" target="#b16">(Lacroix et al., 2018)</ref> remains among the strongest KB embedding approaches <ref type="bibr" target="#b27">(Ruffinelli et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TComplEx, TNTComplEx</head><p>Lacroix et al. (2020) took an early step to extend ComplEx with time. Each timestamp t is also represented as a complex vector w t ? C D . For a claimed fact (s, r, o, t), their TComplEx scoring function is</p><formula xml:id="formula_1">?(s, r, o, t) = ( u s , v r , u o , w t )<label>(2)</label></formula><p>Their TNTComplEx scoring function uses two representations of relations r: v T r , which is sensitive to time, and v r , which is not. The scoring function is the sum of a time-sensitive and a time-insensitive part:</p><formula xml:id="formula_2">( u s , v T r , u o , w t + u s , v r , u o , 1 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">TimePlex</head><p>TimePlex <ref type="bibr" target="#b12">(Jain et al., 2020)</ref> augmented Com-plEx with embeddings u t ? C D for discretized time instants t. To incorporate time, TimePlex uses three representations for each relation r, viz.,</p><formula xml:id="formula_3">(v SO r , v ST r , v OT r ) and writes the base score of a tuple (s, r, o, t) as ?(s, r, o, t) = u s , v SO r , u o + ? u s , v ST r , u t + ? u o , v OT r , u t + ? u s , u o , u t ,</formula><p>(3) where ?, ?, ? are hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CRONKGQA: Our proposed method</head><p>We start with a temporal KG, apply a time-agnostic or time-sensitive KG embedding algorithm (Com-plEx, TComplEx, or TimePlex) to it, and obtain entity, relation, and timestamp embeddings for the temporal KG. We will use the following notation. ? E is the matrix of entity embeddings ? T is the matrix of timestamp embeddings ? E.T is the concatenation of E and T matrices. This is used for scoring answers, since the answer can be either an entity or timestamp. In case entity/timestamp embeddings are complex valued vectors in C D , we expand them to real valued vectors of size 2D, where the first half is the real part and the second half is the complex part of the original vector.</p><p>We first apply EmbedKGQA <ref type="bibr" target="#b28">(Saxena et al., 2020)</ref> directly to the task of Temporal KGQA. In its original implementation, EmbedKGQA uses Com-plEx (Section 4.1) embeddings and can only deal with non-temporal KGs and single entity questions. In order to apply it to CRONQUESTIONS, we set the first entity encountered in the question as the  "head entity" needed by EmbedKGQA. Along with this, we set the entity embedding matrix E to be the ComplEx embedding of our KG entities, and initialize T to a random learnable matrix. EmbedKGQA then performs prediction over E.T . Next, we modify EmbedKGQA so that it can use temporal KG embeddings. We use TComplEx (Section 4.2) for getting entity and timestamp embeddings. CRONKGQA <ref type="figure" target="#fig_0">(Figure 1)</ref> utilizes two scoring functions, one for predicting entity and one for predicting time. Using a pre-trained LM (BERT in our case) CRONKGQA finds a question embedding qe. This is then projected to get two embeddings, qe ent and qe time , which are question embeddings for entity and time prediction respectively. Entity scoring function: We extract a subject entity s and a timestamp t from the question. If either is missing, we use a dummy entity/time. Then, using the scoring function ?(s, r, o, t) from equation 2, we calculate a score for each entity e ? E as ? ent (e) = ( u s , qe ent , u e , w t ) (4)</p><p>where E is the set of entities in the KG. This gives us a score for each entity being an answer. Time scoring function: Similarly, we extract a subject entity s and object entity o from the question, using dummy entities if none are present. Then, using 2, we calculate a score for each times-</p><formula xml:id="formula_4">tamp t ? T as ? time (t) = ( u s , qe time , u o , w t )<label>(5)</label></formula><p>The scores for all entities and times are concatenated, and softmax is used to calculate answer probabilities over this combined score vector. The model is trained using cross entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments and diagnostics</head><p>In this section, we aim to answer the following questions: 1. How do baselines and CRONKGQA perform on the CRONQUESTIONS task? (Section 6.2.) 2. Do some methods perform better than others on specific reasoning tasks? (Section 6.3.) 3. How much does the training dataset size (number of questions) affect the performance of a model? (Section 6.4.) 4. Do temporal KG embeddings confer any advantage over non-temporal KG embeddings? (Section 6.5.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Other methods compared</head><p>It has been shown by <ref type="bibr" target="#b24">Petroni et al. (2019)</ref> and <ref type="bibr" target="#b25">Raffel et al. (2020)</ref> that large LMs, such as BERT and its variants, capture real world knowledge (collected from their massive, encyclopedic training corpus) and can directly be applied to tasks such as QA. In these baselines, we do not specifically feed our version of the temporal KG to the model -  we instead expect the model to have the real world knowledge to compute the answer. BERT: We experiment with BERT, RoBERTa <ref type="bibr" target="#b20">(Liu et al., 2019)</ref> and KnowBERT <ref type="bibr" target="#b23">(Peters et al., 2019)</ref> which is a variant of BERT where information from knowledge bases such as WikiData and WordNet has been injected into BERT. We add a prediction head on top of the [CLS] token of the final layer and do a softmax over it to predict the answer probabilities. T5: In order to apply T5 <ref type="bibr" target="#b25">(Raffel et al., 2020)</ref> to temporal QA, we transform each question in our dataset to the form 'temporal question: question ?'. For evaluation there are two cases: 1. Time answer: We do exact string matching between T5 output and correct answer. 2. Entity answer: We compare the system output to the aliases of all entities in the KG. The entity having an alias with the smallest edit distance <ref type="bibr" target="#b18">(Levenshtein, 1966)</ref> to the predicted text output is taken as the predicted entity. Entities as experts: <ref type="bibr" target="#b8">F?vry et al. (2020)</ref> proposed EaE, a model which aims to integrate entity knowledge into a transformer-based language model. For temporal KGQA on CRONQUES-TIONS, we assume that all grounded entity and time mention spans are marked in the question 1 . We will refer to this model as  <ref type="table" target="#tab_9">Table 5</ref> shows the results of various methods on our dataset. We see that methods based on large pre-trained LMs alone (BERT, RoBERTa, T5), as well as KnowBERT, perform significantly worse than methods that are augmented with KG embeddings (temporal or non-temporal). This is probably because having KG embeddings specific to our temporal KG helps the model to focus on those entities/timestamps. In our experiments, BERT performs slightly better than KnowBERT, even though KnowBERT has entity knowledge in its parameters. T5-3B performs the best among the LMs we tested, possibly because of the large number of parameters and pre-training. Even among methods that use KG embeddings, CRONKGQA performs the best on all metrics, followed by T-EaE-replace. Since EmbedKGQA has non-temporal embeddings, its performance on questions where the answer is a time is very lowcomparable to BERT -which is the LM used in our EmbedKGQA implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Main results</head><p>Another interesting thing to note is the performance on simple reasoning questions. CRONKGQA far outperforms baselines for simple questions, achieving close to 0.99 hits@1, which is much lower for T-EaE (0.329). We believe there might be a few reasons that contribute to this: 1. There is the inductive bias of combining embeddings using TComplEx scoring function in CRONKGQA, which is the same one used in creating the entity and time embeddings, thus making the simple questions straightforward to answer. However, not relying on a scoring function means that T-EaE can be extended to any KG embedding, whereas CRONKGQA cannot. For each dataset size, models were trained until validation hits@10 did not increase for 10 epochs. Please refer to Section 6.4 for details.</p><p>2. Another contributing reason could be that there are fewer parameters to be trained in CRONKGQA while a 6-layer Transformer encoder needs to be trained from scratch in T-EaE. Transformers typically require large amounts of varied data to train successfully. <ref type="table" target="#tab_12">Table 6</ref> shows the performance of KG embedding based models across different types of reasoning. As stated above in Section 6.2, CRONKGQA performs very well on simple reasoning questions (simple entity, simple time). Among complex question types, all models (except EmbedKGQA) perform the best on time join questions (e.g., 'Who played with Roberto Dinamite on the Brazil national football team'). This is because such questions typically have multiple answers (such as all the players when Roberto Dinamite was playing for Brazil), which makes it easier for the model to make a correct prediction. In the other two question types, the answer is always a single entity/time. Before/after questions seem most challenging for all methods, with the best method achieving only 0.288 hits@1. <ref type="figure" target="#fig_1">Figure 2</ref> shows the effect of training dataset size on model performance. As we can see, for T-EaE-add, increasing the training dataset size from 10% to 100% steadily increases its performance for both simple and complex reasoning type questions. This effect is somewhat present in CRONKGQA for complex reasoning, but not so for simple reasoning type questions. We hypothesize that this is because T-EaE has more trainable parameters -it has a 6-layer transformer that needs to be trained from scratch -in contrast to CRONKGQA that needs to merely fine tune BERT and train some shallow projection layers. These results affirm our hypothesis that having a large, even if synthetic, dataset is useful for training temporal reasoning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Performance across question types</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Effect of training dataset size</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Temporal vs. non-temporal KG embeddings</head><p>We conducted further experiments to study the effect of temporal vs. non-temporal KG embeddings. We replaced the temporal entity embeddings in T-EaE-replace with ComplEx embeddings, and treated timestamps as regular tokens (not associated with any entity/time mentions). CRONKGQA-CX is the same as EmbedKGQA. The results can be seen in <ref type="table" target="#tab_13">Table 7</ref>. As we can see, for both CRONKGQA and T-EaE-replace, using temporal KGE (TComplex) gives a significant boost in performance compared to non-temporal KGE (Com-plEx). CRONKGQA receives a much larger boost in performance compared to T-EaE-replace, probably because the scoring function has been modeled after TComplEx and not ComplEx, while there is no such embedding-specific engineering in T-EaE-replace. Another observation is that questions having temporal answers achieve very low accuracy (0.057 and 0.062 respectively) in both CRONKGQA-CX and T-EaE-replace-CX, which is much lower than what these models achieve with TComplEx. This shows that having temporal KG embeddings is essential for achieving good performance for KG embedding-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we introduce CRONQUESTIONS, a new dataset for Temporal Knowledge Graph Question Answering. While there exist some Temporal KGQA datasets, they are all based on non-temporal KGs (e.g., Freebase) and have relatively few questions. Our dataset consists of both a temporal KG as well as a large set of temporal questions requiring various structures of reasoning. In order to develop such a large dataset, we used a synthetic   generation procedure, leading to a question distribution that is artificial from a semantic perspective. However, having a large dataset provides an opportunity to train models, rather than just evaluate them. We experimentally show that increasing the training dataset size steadily improves the performance of certain methods on the TKGQA task. We first apply large pre-trained LM based QA methods on our new dataset. Then we inject KG embeddings, both temporal and non-temporal, into these LMs and observe significant improvement in performance. We also propose a new method, CRONKGQA, that is able to leverage Temporal KG Embeddings to perform TKGQA. In our experiments, CRONKGQA outperforms all baselines. These results suggest that KG embeddings can be effectively used to perform temporal KGQA, although there remains significant scope for improvement when it comes to complex reasoning questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Entities as Experts (EaE)</head><p>The model architecture follows Transformer <ref type="bibr" target="#b35">(Vaswani et al., 2017)</ref> interleaved with an entity memory layer. It has two embedding matrices, for tokens and entities. It works on the input sequence x as follows. X 0 = TokenEmbed(x) X 1 = Transformer 0 (X 0 , num layers = l 0 ) X 2 = EntityMemory(X 1 ) X 3 = LayerNorm(X 2 + X 1 ) X 4 = Transformer 1 (X 3 , num layers = l 1 )</p><formula xml:id="formula_5">X 5 = TaskSpecificHeads(X 4 ) (6)</formula><p>The whole model (transformers, token and entity embeddings, and task-specific heads) is trained end to end using losses for entity linking, mention detection and masked language modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 EaE for Temporal KGQA</head><p>CRONQUESTIONS does not provide a text corpus for training language models.</p><p>Therefore, we use BERT <ref type="bibr" target="#b7">(Devlin et al., 2019)</ref> for Transformer 0 as well as TokenEmbed (eqn. 6). For EntityMemory, we use TComplEx/TimePlex embeddings of entities and timestamps that have been pre-trained using the CRONQUESTIONS KG (please refer to Section 4 for details on KG embeddings). The modified model is as follows:</p><formula xml:id="formula_6">X 1 = BERT(x)</formula><p>X 2 = EntityTimeEmbedding(X 1 ) X 3 = LayerNorm(X 2 + X 1 ) X 4 = Transformer 1 (X 3 , num layers = 6)</p><formula xml:id="formula_7">X 5 = PredictionHead(X 4 )<label>(7)</label></formula><p>For simplicity, we assume that all grounded entity and time mention spans are marked in the question, i.e., for each token, we know. which entity or timestamp it belongs to (or if it doesn't belong to any). Thus, for each token x i in the input x,</p><formula xml:id="formula_8">? X 1 [i] contains the contextual BERT embedding of x i ? For X 2 [i] there are 3 cases. -x i is a mention of entity e. Then X 2 [i] = E[e]. -x i is a mention of timestamp t. Then X 2 [i] = T [t]</formula><p>. x i is not a mention. Then X 2 [i] is the zero vector. PredictionHead takes the final output from Transformer 1 of the token corresponding to the [CLS] token of BERT as the predicted answer embedding. This answer embedding is scored against E.T using dot product to get a score for each possible answer, and softmax is taken to get answer probabilities. The model is trained on the QA dataset using cross-entropy loss. We will refer to this model as T-EaE-add since we are taking element-wise sum of BERT and entity/time embeddings.</p><p>T-EaE-replace Instead of adding entity/time and BERT embeddings, we replace the BERT embeddings with the entity/time embeddings for entity/time mentions. Specifically, before feeding to Transformer 1 in step 4 of eqn. 7, 1. if x i is not an entity or time mention,</p><formula xml:id="formula_9">X 3 [i] = BERT(X 1 [i]) 2. if x i is an entity or time mention, X 3 [i] = EntityTimeEmbedding(X 1 [i])</formula><p>The rest of the model remains the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Examples</head><p>Tables 8 to 12 contain some example questions from the validation set of CRONQUESTIONS, along with the top 5 predictions of the models we experimented with. T5-3B has a single prediction since it is a text-to-text model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>Who held the position of Prime Minister of Sweden before 2nd World War   <ref type="bibr">1995</ref><ref type="bibr">, 1993</ref><ref type="bibr">, 1999</ref><ref type="bibr">, 1991</ref><ref type="bibr">, 1987</ref><ref type="bibr">KnowBERT 1993</ref><ref type="bibr">, 1996</ref><ref type="bibr">, 1994</ref><ref type="bibr">, 2006</ref><ref type="bibr">, 1995</ref><ref type="bibr">T5-3B 1997</ref><ref type="bibr">EmbedKGQA 2017</ref><ref type="bibr" target="#b1">, 2008</ref><ref type="bibr">, 2004</ref><ref type="bibr">T-EaE-add 2008</ref><ref type="bibr">, 2009</ref><ref type="bibr">, 2005</ref><ref type="bibr">, 1999</ref><ref type="bibr">, 2007</ref><ref type="bibr">T-EaE-replace 2009</ref><ref type="bibr" target="#b1">, 2008</ref><ref type="bibr">, 2005</ref><ref type="bibr">, 2006</ref><ref type="bibr">, 2007</ref><ref type="bibr">CRONKGQA 2008</ref><ref type="bibr">, 2007</ref><ref type="bibr">, 2009</ref><ref type="bibr">, 2002</ref><ref type="bibr">, 1945</ref>     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The CRONKGQA method. (i) A temporal KG embedding model (Section 4) is used to generate embeddings for each timestamp and entity in the temporal knowledge graph (ii) BERT is used to get two question embeddings: qe ent and qe time . (iii) Embeddings of entity/time mentions in the question are combined with question embeddings using equations 4 and 5 to get score vectors for entity and time prediction. (iv) Score vectors are concatenated and softmax is used get answer probabilities. Please refer to Section 5 for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Model performance (hits@10) vs. training dataset size (percentage) for CRONKGQA and T-EaEadd. Solid line is for simple reasoning and dashed line is for complex reasoning type questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>KGQA dataset comparison. Statistics about percentage of temporal questions for WebQuestions are taken from</figDesc><table><row><cell>Question Types</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>that are temporal in When did {head} hold the position of {tail} When did Obama hold the position of President of USA Simple entity Which award did {head} receive in {time} Which award did Brad Pitt receive in 2001 Before/After Who was the {tail} {type} {head} Who was the President of USA before Obama First/Last When did {head} play their {adj} game When did Messi play their first game Time join Who held the position of {tail} during {event} Who held the position of President of USA during WWII</figDesc><table><row><cell>Reasoning</cell><cell>Example Template</cell><cell>Example Question</cell></row><row><cell>Simple time</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Example questions for different types of temporal reasoning. {head}, {tail} and {time} correspond to entities/timestamps in facts of the form(head, relation, tail, timestamp). {event} corresponds to entities in event facts eg. WWII. {type} can be one of before/after and {adj} can be one of first/last. Please refer to Section 3.2 for details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Template When did {head} play in {tail} Seed Qn When did Messi play in FC Barcelona Human Paraphrases When was Messi playing in FC Barcelona Which years did Messi play in FC Barcelona When did FC Barcelona have Messi in their team What time did Messi play in FC Barcelona Machine Paraphrases When did Messi play for FC Barcelona When did Messi play at FC Barcelona When has Messi played at FC Barcelona</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Slot-filled paraphrases generated by humans and machine. Please refer to Section 3.2 for details.</figDesc><table><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Simple Entity</cell><cell>90,651</cell><cell>7,745</cell><cell>7,812</cell></row><row><cell>Simple Time</cell><cell>61,471</cell><cell>5,197</cell><cell>5,046</cell></row><row><cell>Before/After</cell><cell>23,869</cell><cell>1,982</cell><cell>2,151</cell></row><row><cell>First/Last</cell><cell cols="3">118,556 11,198 11,159</cell></row><row><cell>Time Join</cell><cell>55,453</cell><cell>3,878</cell><cell>3,832</cell></row><row><cell cols="4">Entity Answer 225,672 19,362 19,524</cell></row><row><cell>Time Answer</cell><cell cols="3">124,328 10,638 10,476</cell></row><row><cell>Total</cell><cell cols="3">350,000 30,000 30,000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Number of questions in our dataset across dif- ferent types of reasoning required and different answer types. Please refer to Section 3.2.1 for details.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>for the distribu-</cell></row><row><cell>tion statistics).</cell></row><row><cell>Simple reasoning: These questions require a sin-</cell></row><row><cell>gle fact to answer, where the answer can be ei-</cell></row><row><cell>ther an entity or a time instance. For example the</cell></row><row><cell>question "Who was the President of the United</cell></row><row><cell>States in 2008?" requires a single fact to answer</cell></row><row><cell>the question, namely (Barack Obama, held posi-</cell></row><row><cell>tion, President of USA, 2008, 2016)</cell></row><row><cell>Complex reasoning: These questions require</cell></row><row><cell>multiple facts to answer and can be more varied.</cell></row><row><cell>For example "Who was the first President of</cell></row><row><cell>the United States?" This requires reasoning</cell></row><row><cell>over multiple facts pertaining to the entity</cell></row><row><cell>"President of the United States". In our dataset,</cell></row><row><cell>all questions that are not "simple reasoning"</cell></row><row><cell>questions are considered complex questions.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>BERT-2.1, 30.2, ...  -3.1, -50, ...</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Harry Truman</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1944</cell></row><row><cell>Barack Obama</cell><cell>po si tio n he ld 20 08 -20 16</cell><cell></cell><cell></cell><cell>1945</cell></row><row><cell>Harry Truman</cell><cell>po si tio n he ld 19 45 -19 53</cell><cell>President of USA</cell><cell>Temporal KGE Model</cell><cell>&lt;empty&gt; Q11696: President of USA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Q11613: Harry</cell></row><row><cell></cell><cell>significant</cell><cell></cell><cell></cell><cell>Truman</cell></row><row><cell>World War II</cell><cell>event 1939 -1945</cell><cell>occured</cell><cell></cell><cell>Q362: World</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>War II</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Temporal KG Embeddings</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[CLS] Who was the President of USA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>after World War II</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Performance of baselines and our methods on the CRONQUESTIONS dataset. Methods above the midrule do not use any KG embeddings, while the ones below use either temporal or non-temporal KG embeddings.</figDesc><table><row><cell>Hits@10 are not available for T5-3B since it is a text-to-text model and makes a single prediction. Please refer to</cell></row><row><cell>Section 6.2 for details.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>Hits@1 for different reasoning type questions. 'Simple Entity' and 'Simple Time' correspond to simple question type inTable 5while the others correspond to complex question type. Please refer to section 6.3 for more details.</figDesc><table><row><cell>Question</cell><cell cols="4">CRONKGQA T-EaE-replace</cell></row><row><cell>Type</cell><cell>CX</cell><cell>TCX</cell><cell>CX</cell><cell>TCX</cell></row><row><cell>Simple</cell><cell cols="3">0.29 0.987 0.248</cell><cell>0.329</cell></row><row><cell>Complex</cell><cell cols="3">0.286 0.392 0.247</cell><cell>0.257</cell></row><row><cell cols="4">Entity Answer 0.411 0.699 0.347</cell><cell>0.318</cell></row><row><cell>Time Answer</cell><cell cols="3">0.057 0.549 0.062</cell><cell>0.231</cell></row><row><cell>Overall</cell><cell cols="3">0.288 0.647 0.247</cell><cell>0.288</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: Hits@1 for CRONKGQA and T-EaE-replace</cell></row><row><cell>using ComplEx(CX) and TComplEx(TCX) KG embed-</cell></row><row><cell>dings. Please refer to Section 6.5 for more details.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Question Type Before/After Gold answer(s) Per Albin Hansson BERT Emil Stang, Sr., Sigurd Ibsen, Johan Nygaardsvold, Laila Freivalds, J. S. Woodsworth Tage Erlander, Carl Gustaf Ekman, Arvid Lindman, Hjalmar Branting T-EaE-add Per Albin Hansson, Manuel Roxas, Arthur Sauv?, Konstantinos Demertzis, Karl Renner T-EaE-replace Per Albin Hansson, Tage Erlander, Arvid Lindman, Val?re Bernard, Vladko Ma?ek CRONKGQA Per Albin Hansson, Tage Erlander, Arvid Lindman, Carl Gustaf Ekman, Hjalmar Branting</figDesc><table><row><cell>KnowBERT</cell><cell>Benito Mussolini,?sten Und?n, Hans-Dietrich Genscher, Winston Churchill, Lutz Graf Schwerin von Krosigk</cell></row><row><cell>T5-3B</cell><cell>bo osten unden</cell></row><row><cell cols="2">EmbedKGQA Per Albin Hansson,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>Before/After reasoning type question.</figDesc><table><row><cell>Question</cell><cell>When did Man on Wire receive Oscar for Best Documentary Feature</cell></row><row><cell cols="2">Question Type Simple time</cell></row><row><cell cols="2">Gold answer(s) 2008</cell></row><row><cell>BERT</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9 :</head><label>9</label><figDesc>Simple reasoning question with time answer. EmbedKGQA John Lasseter, Floyd Norman, Duncan Marjoribanks, Glen Keane, Theodore Ty T-EaE-add John Lasseter, Anne Marie Bardwell, Will Finn, Floyd Norman, Rejean Bourdages T-EaE-replace John Lasseter, Will Finn, Floyd Norman, Nik Ranieri, Ken Duncan CRONKGQA John Lasseter, Floyd Norman, Duncan Marjoribanks, David Pruiksma, Theodore Ty</figDesc><table><row><cell>Question</cell><cell>Who did John Alan Lasseter work with while employed at Pixar</cell></row><row><cell cols="2">Question Type Time join</cell></row><row><cell cols="2">Gold answer(s) Floyd Norman</cell></row><row><cell>BERT</cell><cell>Tim Cook, Eleanor Winsor Leach, David R. Williams, Robert M. Boynton, Jules Steeg</cell></row><row><cell>KnowBERT</cell><cell>1994, 1997, Walt Disney Animation Studios, Christiane Kubrick, 1989</cell></row><row><cell>T5-3B</cell><cell>john alan lasseter</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Time join type question. Question Where did John Hubley work before working for Industrial Films Question Type Before/After Gold answer(s) The Walt Disney Studios BERT The Walt Disney Studios, Warner Bros. Cartoons, Pixar, Microsoft, United States Navy KnowBERT? cole Polytechnique, Piti?-Salp?tri?re Hospital, The Walt Disney Studios,</figDesc><table><row><cell></cell><cell>Elisabeth Buddenbrook, Yale University</cell></row><row><cell>T5-3B</cell><cell>london film school</cell></row><row><cell>EmbedKGQA</cell><cell>The Walt Disney Studios, Coll?ge de France, Warner Bros. Cartoons, University of Naples Federico II, ETH Zurich</cell></row><row><cell>T-EaE-add</cell><cell>The Walt Disney Studios, Fleischer Studios, UPA, Walter Lantz Productions, Wellesley College</cell></row><row><cell>T-EaE-replace</cell><cell>The Walt Disney Studios, City College of New York, UPA, Yale University, Indiana University</cell></row><row><cell>CRONKGQA</cell><cell>The Walt Disney Studios, UPA, Saint Petersburg State University, Warner Bros. Cartoons, Coll?ge de France</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 11 :</head><label>11</label><figDesc>Before/After reasoning type question.QuestionThe last person that Naomi Foner Gyllenhaal was married to was Hetty Broedelet-Henkes, Naomi Foner Gyllenhaal, Miles Copeland, Jr., member of the Chamber of Representatives of Colombia</figDesc><table><row><cell cols="2">Question Type First/Last</cell></row><row><cell cols="2">Gold answer(s) Stephen Gyllenhaal</cell></row><row><cell>BERT</cell><cell>1928, Jennifer Lash, Stephen Mallory, Martin Landau, Bayerische Verfassungsmedaille in Gold</cell></row><row><cell>KnowBERT</cell><cell>Nadia Benois, Eugenia Zukerman, Germany national football team, Talulah Riley, Lola Landau</cell></row><row><cell>T5-3B</cell><cell>gyllenhaal</cell></row><row><cell>EmbedKGQA</cell><cell>Stephen Gyllenhaal, Naomi Foner Gyllenhaal, Wolfhard von Boeselager, Heinrich Schweiger, Bruce Paltrow</cell></row><row><cell>T-EaE-add</cell><cell>Stephen Gyllenhaal, Marianne Zoff, Cotter Smith, Douglas Wilder, Gerd Vespermann</cell></row><row><cell cols="2">T-EaE-replace Stephen Gyllenhaal, CRONKGQA Stephen Gyllenhaal, Antonia Fraser, Bruce Paltrow, Naomi Foner Gyllenhaal, Wolfhard von Boeselager</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 12 :</head><label>12</label><figDesc>First/Last reasoning type question.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their constructive feedback, and Pat Verga and William Cohen from Google Research for their insightful comments. We would also like to thank Chitrank Gupta (IIT Bombay) for his help in debugging the source code and dataset. This work is supported in part by a gift from Google Research, India and a Jagadish Bose Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Constraint-based question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2503" to="2514" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1145/1376616.1376746</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;08</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="423" to="433" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Scalable neural methods for reasoning with a symbolic knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Alex</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Siegler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">HyTE: Hyperplane-based temporally aware knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swayambhu</forename><surname>Shib Sankar Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Nath Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talukdar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1225</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baldini</forename><surname>Livio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07202</idno>
		<title level="m">Entities as experts: Sparse memory access with entity supervision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning sequence encoders for temporal knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garc?a-Dur?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastijan</forename><surname>Duman?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1516</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4816" to="4821" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Diachronic embedding for temporal knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishab</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Seyed Mehran Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Brubaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poupart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved lexically constrained decoding for translation and monolingual rewriting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Edward</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Culkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sushant</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.305</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3733" to="3747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tempquestions: A benchmark for temporal question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishiraj</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Str?tgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/3184558.3191536</idno>
	</analytic>
	<monogr>
		<title level="m">Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1057" to="1062" />
		</imprint>
	</monogr>
	<note>Companion Proceedings of the The Web Conference 2018, WWW &apos;18</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishiraj</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Str?tgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3269247</idno>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timoth?e</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04926</idno>
		<title level="m">Tensor decompositions for temporal knowledge base completion</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Canonical tensor decomposition for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timoth?e</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Obozinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07297</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gdelt: Global data on events, location, and tone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalev</forename><surname>Leetaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schrodt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISA annual convention</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vladimir I Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet physics doklady</title>
		<meeting><address><addrLine>Soviet Union</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1966" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Roberta: A robustly optimized bert pretraining approach</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03126</idno>
		<title level="m">Key-value memory networks for directly reading documents</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rujun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<title level="m">Torque: A reading comprehension dataset of temporal ordering questions</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidur</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Knowledge enhanced contextual word representations</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Language models as knowledge bases?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>text transformer</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">You can teach an old dog new tricks! on training knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ruffinelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving multi-hop question answering over knowledge graphs using knowledge base embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditay</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.412</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4498" to="4507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">O</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m">Faithful embeddings for knowledge base queries</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1059</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="641" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Coupled temporal scoping of relational facts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derry</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?o</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Nilesh Agrawal, and Partha Talukdar. 2020. Interacte: Improving convolution-based knowledge graph embeddings by increasing feature interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Nitin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3009" to="3016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09600</idno>
		<title level="m">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1128</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Variational reasoning for question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
