<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Networks for Joint Affine and Non-parametric Image Registration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Shen</surname></persName>
							<email>zyshen@cs.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">UNC Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UNC</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenlin</forename><surname>Xu</surname></persName>
							<email>zhenlinx@cs.unc.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">UNC</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">UNC</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Networks for Joint Affine and Non-parametric Image Registration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce an end-to-end deep-learning framework for 3D medical image registration. In contrast to existing approaches, our framework combines two registration methods: an affine registration and a vector momentum-parameterized stationary velocity field (vSVF) model. Specifically, it consists of three stages. In the first stage, a multi-step affine network predicts affine transform parameters. In the second stage, we use a Unet-like network to generate a momentum, from which a velocity field can be computed via smoothing. Finally, in the third stage, we employ a self-iterable map-based vSVF component to provide a non-parametric refinement based on the current estimate of the transformation map. Once the model is trained, a registration is completed in one forward pass. To evaluate the performance, we conducted longitudinal and cross-subject experiments on 3D magnetic resonance images (MRI) of the knee of the Osteoarthritis Initiative (OAI) dataset. Results show that our framework achieves comparable performance to state-of-the-art medical image registration approaches, but it is much faster, with a better control of transformation regularity including the ability to produce approximately symmetric transformations, and combining affine and non-parametric registration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Registration is a fundamental task in medical image analysis to establish spatial correspondences between different images. To allow, for example, localized spatial analyses of cartilage changes over time or across subject populations, images are first registered to a common anatomical space.</p><p>Traditional image registration algorithms, such as elastic <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">25]</ref>, fluid <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">29,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr">31]</ref> or B-spline models <ref type="bibr" target="#b25">[24]</ref>, are based on the iterative numerical solution of an optimization problem. The objective of the optimization is to minimize image mismatch and transformation irregularity. The sought-for solution is then a spatial transformation which aligns a source image well to a target image while assuring that the transformation is sufficiently regular. To this end, a variety of different similarity measures to assess image mismatch have been proposed. For image pairs with a similar intensity distribution, Mean Square Error (MSE) on intensity differences is widely used. For multi-modal registration, however, Normalized Cross Correlation (NCC) and Mutual Information (MI) usually perform better. Besides, smooth transformation maps are typically desirable. Methods encouraging or enforcing smoothness use, for example, rigidity penalties <ref type="bibr" target="#b27">[26]</ref> or penalties that encourage volume preservation <ref type="bibr" target="#b28">[27,</ref><ref type="bibr" target="#b23">22]</ref> to avoid folds in the transformation. Diffeomorphic transformations can also be achieved by optimizing over sufficiently smooth velocity fields from which the spatial transformation can be recovered via integration. Such methods include Large Displacement Diffeomorphic Metric Mapping (LDDMM) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> and Diffeomorphic Demons <ref type="bibr" target="#b30">[29]</ref>. As optimizations are typically over very high-dimensional parameter spaces, they are computationally expensive.</p><p>Recently, taking advantage of deep learning, research has focused on replacing costly numerical optimization with a learned deep regression model. These methods are extremely fast as only the evaluation of the regression model is required at test time. They imitate the behavior of conventional, numerical optimization-based registration algorithms as they predict the same types of registration parameters: displacement fields, velocity fields or momentum fields. Depending on the predicted parameters, theoretical properties of the original registration model can be retained. For example, In Quicksilver <ref type="bibr" target="#b34">[33]</ref>, a network is learned to predict the initial momentum of LDDMM, which can then be used to find a diffeomorphic spatial transformation via LDDMM's shooting equations. While earlier work has focused on training models based on previously obtained registration parameters via costly numerical optimization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">32]</ref>, recent work has shifted to end-to-end formulations <ref type="bibr" target="#b0">1</ref>  <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9]</ref>. These end-to-end approaches integrate image resampling into their network and were inspired by the spatial-transformer work of Jaderberg et al. <ref type="bibr" target="#b12">[13]</ref>. Non end-to-end approaches require the sought-for registration parameters at training time. To obtain such data via numerical optimization for large numbers of image pairs can be computationally expensive, whereas end-to-end approaches effectively combine the training of the network with the implicit optimization over the registration parameters (as part of the network architecture).</p><p>Existing deep learning approaches to image registration exhibit multiple limitations. First, they assume that images have already been pre-aligned, e.g., by rigid or affine registration. These pre-alignment steps can either be done via a specifically trained network <ref type="bibr" target="#b6">[7]</ref> or via standard numerical optimization. In the former case the overall registration approach is no longer end-to-end, while in the latter the preregistration becomes the computational bottleneck. Second, many approaches are limited by computational memory and hence either only work in 2D or resort to small patches in 3D. Though some work explores end-to-end formulations for entire 3D volumes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>, these approaches perform computations based on the full resolution transformation map, in which case a very simple network can easily exhaust the memory and thus limit extensions of the model. Third, they do not explore iterative refinement.</p><p>Our proposed approach addresses these shortcomings. Specifically, our contributions are:</p><p>? A novel vector momentum-parameterized stationary velocity field registration model (vSVF). The vector momentum field allows decoupling transformation smoothness and the prediction of the transformation parameters. Hence, sufficient smoothness of the resulting velocity field can be guaranteed and diffeomorphisms can be obtained even for large displacements. ? An end-to-end registration method, merging affine and vSVF registration into a single framework. This framework achieves comparable performance to the corresponding optimization-based method and state-of-theart registration approaches while dramatically reducing the computational cost. ? A multi-step approach for the affine and the vSVF registration components in our model, which allows refining registration results. ? An entire registration model via map compositions to avoid unnecessary image interpolations. ? An inverse consistency loss both for the affine and the vSVF registration components thereby encouraging the regression model to learn a mapping which is less dependent on image ordering. I.e., registering image A to B will result in similar spatial correspondences as registering B to A.</p><p>Our approach facilitates image registration including affine pre-registration within one unified regression model. In what follows, we refer to our approach as AVSM (Affine-vSVF-Mapping). <ref type="figure" target="#fig_0">Fig. 1</ref> shows an overview of the AVSM framework illustrating the combination of the affine and the vSVF registration components. The affine and the vSVF components are designed independently, but easy to combine. In the affine stage, a multi-step affine network predicts affine parameters for an image pair. In the vSVF stage, a Unet-like network generates a momentum, from which a velocity field can be computed via smoothing. The initial map and the momentum are then fed into the vSVF component to output the sought-for transformation map. A specified number of iterations can also be used to refine the results. The entire registration framework operates on maps and uses map compositions. In this way, the source image is only interpolated once thereby avoiding image blurring. Furthermore, as the transformation map is assumed to be smooth, interpolations to up-sample the map are accurate. Therefore, we can obtain good registration results by predicting a down-sampled transformation. However, the similarity measure is evaluated at full resolution during training. Computing at low resolution greatly reduces the computational cost and allows us to compute on larger image volumes given a particular memory budget. E.g., a map with 1/2 the size only requires 1/8 of the computations and 1/8 of the memory in 3D.</p><p>We compare AVSM to publicly available optimizationbased methods <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b25">24,</ref><ref type="bibr">19</ref>, 2] on longitudinal and crosssubject registrations of 3D image pairs of the OAI dataset. <ref type="figure">Figure 2</ref>. Multi-step affine network structure. As in a recurrent network, the parameters of the affine network are shared by all steps. At each step, the network outputs the parameters to refine the previously predicted affine transformation. I.e., the current estimate is obtained by composition (indicated by dashed line). The overall affine transformation is obtained at the last step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>This section explains our overall approach. It is divided into two parts. The first part explains the affine registration component which makes use of a multi-step network to refine predictions of the affine transformation parameters. The second part explains the vector momentumparameterized stationary velocity field (vSVF) which accounts for local deformations. Here, a momentum generation network first predicts the momentum parameterizing the vSVF model and therefore the transformation map. The vSVF component can also be applied in a multi-step way thereby further improving registration results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multi-step Affine Network</head><p>Most existing non-parametric registration approaches are not invariant to affine transformations as they are penalized by the regularizers. Hence, non-parametric registration approaches typically start from pre-registered image pairs, most typically based on affine registration, to account for large, global displacements or rotations. Therefore, in the first part of our framework, we use a multi-step affine network directly predicting the affine registration parameters and the corresponding transformation map.</p><p>The network needs to be flexible enough to adapt to both small and large affine deformations. Although deep convolutional networks can have large receptive fields, our experiments show that training a single affine network does not perform well in practice. Instead, we compose the affine transformation from several steps. This strategy results in significant improvements in accuracy and stability.</p><p>Network: Our multi-step affine network is a recurrent network, which progressively refines the predicted affine trans-formation. <ref type="figure">Fig. 2</ref> shows the network architecture. To avoid numerical instabilities and numerical dissipation due to successive trilinear interpolations, we directly update the affine registration parameters rather than resampling images in intermediate steps. Specifically, at each step we take the target image and the warped source image (obtained via interpolation from the source image using the previous affine parameters) as inputs and then output the new affine parameters for the transformation refinement. Let the affine parameters be ? = A b , where A ? R d?d represents the linear transformation matrix; b ? R d denotes the translation and d is the image dimension. The update rule is as follows:</p><formula xml:id="formula_0">A (t) =? (t) A (t?1) , b (t) =? (t) b (t?1) +b (t) , s.t. A (0) = I, b (0) = 0.<label>(1)</label></formula><p>Here,? (t) , A (t) represent the linear transformation matrix output and the composition result at the t-th step, respectively. Similarly,b (t) denotes the affine translation parameter output at the t-th step and b (t) the composition result. Finally, if we consider the registration from the source image to the target image in the space of the target image, the affine map is obtained by</p><formula xml:id="formula_1">? ?1 a (x, ?) = A (t last ) x + b (t last )</formula><p>. Loss: The loss of the multi-step affine network consists of three parts: an image similarity loss L a-sim , a regularization loss L a-reg and a loss encouraging transformation symmetry L a-sym . Let us denote I 0 as the source image and I 1 as the target image. The superscripts st and ts denote registrations from I 0 to I 1 and I 1 to I 0 , respectively 2 .</p><p>The image similarity loss L a-sim (I 0 , I 1 , ? ?1 a ) can be any standard similarity measure, e.g., Normalized Cross Correlation (NCC), Localized NCC (LNCC), or Mean Square Error (MSE). Here we generalize LNCC to a multikernel LNCC formulation (mk-LNCC). Standard LNCC is computed by averaging NCC scores of overlapping sliding windows centered at sampled voxels. Let V be the volume of the image; x i , y i refer to the i th (i ? {1, .., |V |}) voxel in the warped source and target volumes, respectively. N s refers to the number of sliding windows with cubic size s?s?s. Let ? s j refer to the window centered at the j th voxel andx j ,? j to the average image intensity values over ? s j in the warped source and target image, respectively. LNCC with window size s, denoted as ? s , is defined by</p><formula xml:id="formula_2">? s (x, y) = 1 N s j i?? s j (x i ?x j )(y i ?? j ) i?? s j (x i ?x j ) 2 i?? s j (y i ?? j ) 2 .</formula><p>(2) We define mk-LNCC as a weighted sum of LNCCs with different window sizes. For computational efficiency LNCC can be evaluated over windows centered over a subset of voxels of V . The image similarity loss is then</p><formula xml:id="formula_3">L a-sim (I 0 , I 1 , ?) = i ? i ? si (I 0 ? ? ?1 a , I 1 ), s.t. ? ?1 a (x, ?) = Ax + b and i ? i = 1, w i ? 0.<label>(3)</label></formula><p>The regularization loss L a-reg (?) penalizes deviations of the composed affine transform from the identity:</p><formula xml:id="formula_4">L a-reg (?) = ? ar (||A ? I|| 2 F + ||b|| 2 2 ),<label>(4)</label></formula><p>where ? F denotes the Frobenius norm and ? ar ? 0 is an epoch-dependent weight factor designed to be large at the beginning of the training to constrain large deformations and then gradually decaying to zero. See Eq. 14 for details.</p><p>The symmetry loss L a-sym (?, ? ts ) encourages the registration to be inverse consistent. I.e.,, we want to encourage that the transformation computed from source to target image is the inverse of the transformation computed from the target to the source image (i.e., A ts (Ax</p><formula xml:id="formula_5">+ b) + b ts = x): L a-sym (?, ? ts ) = ? as (||A ts A?I|| 2 F +||A ts b+b ts || 2 2 ), (5) where ? as ? 0 is a chosen constant.</formula><p>The complete loss L a (I 0 , I 1 , ?, ? ts ) is then:</p><formula xml:id="formula_6">L a (I 0 , I 1 , ?, ? ts ) = a (I 0 , I 1 , ?) + a (I 1 , I 0 , ? ts ) + L a-sym (?, ? ts ),<label>(6)</label></formula><p>where a (I 0 , I 1 , ?) = L a-sim (I 0 , I 1 , ?) + L a-reg (?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Vector Momentum-parameterized SVF</head><p>This section presents the momentum based stationary velocity field method followed by the network to predict the momentum. For simplicity, we describe the one step vSVF here, which forms the basis of the multi-step approach.</p><p>vSVF Method: To capture large deformations and to guarantee diffeomorphic transformations, registration algorithms motivated by fluid mechanics are frequently employed. Here, the transformation map ? 3 in source image space is obtained via time-integration of a velocity field v(x, t), which needs to be estimated. The governing differential equation is:</p><formula xml:id="formula_7">? t (x, t) = v(?(x, t), t), ?(x, 0) = ? (0) (x), where ? (0)</formula><p>is the initial map. For a sufficiently smooth velocity field v one obtains a diffeomorphic transformation. Sufficient smoothness is achieved by penalizing non-smoothness of v. Specifically, the optimization prob-</p><formula xml:id="formula_8">lem is v * = argmin v ? vr 1 0 v 2 L dt + Sim[I 0 ? ? ?1 (1), I 1 ], s.t. ? ?1 t + D? ?1 v = 0 and ? ?1 (0) = ? ?1 (0) ,<label>(7)</label></formula><p>where D denotes the Jacobian and v 2 L = L ? Lv, v is a spatial norm defined by specifying the differential operator L and its adjoint L ? . As the vector-valued momentum m is equivalent to m = L ? Lv, one can express the norm <ref type="bibr" target="#b2">3</ref> The subscript v of ?v is omitted, where v refers to vSVF method. <ref type="figure">Figure 3</ref>. vSVF registration framework illustration (one step), including the momentum generation network and the vSVF registration. The network outputs a low-resolution momentum. The momentum and the down-sampled initial map are input to the vSVF unit outputting a low-resolution transformation map, which is then up-sampled to full resolution before warping the source image.</p><p>as v 2 L = m, v . In the LDDMM approach <ref type="bibr" target="#b4">[5]</ref>, timedependent vector fields v(x, t) are estimated. A slightly simpler approach is to use a stationary velocity field (SVF) v(x) <ref type="bibr" target="#b18">[18]</ref>. The rest of the formulation remains the same. While the SVF registration algorithms optimize directly over the velocity field v, we propose a vector momentum SVF (vSVF) formulation which is computed as</p><formula xml:id="formula_9">m * = argmin m0 ? vr m 0 , v 0 + Sim[I 0 ? ? ?1 (1), I 1 ], s.t. ? ?1 t + D? ?1 v = 0, ? ?1 (0) = ? ?1 (0) , v 0 = (L ? L) ?1 m 0 ,<label>(8)</label></formula><p>where m 0 denotes the vector momentum and ? vr &gt; 0 is a constant. This formulation can be considered a simplified version of the vector momentum-parameterized LD-DMM formulation <ref type="bibr" target="#b31">[30]</ref>. The benefit of such a formulation is that it allows us to explicitly control spatial smoothness as the deep network predicts the momentum which gets subsequently smoothed to obtain the velocity field, instead of predicting the velocity field v directly which would then require the network to learn to predict a smooth vector field. <ref type="figure">Fig. 3</ref> illustrates the framework of the vector momentumparameterized stationary velocity field (vSVF) registration. We compute using a low-resolution velocity field, which greatly reduces memory consumption. The framework consists of two parts: 1) a momentum generation network taking as the input the warped source image, together with the target image, outputting the low-resolution momentum; 2) the vSVF registration part. Specifically, the predicted momentum and the down-sampled initial map are input into the vSVF unit, the output of which is finally up-sampled to obtain the full resolution transformation map. Inside the vSVF unit, a velocity field is obtained by smoothing the momentum and then used to solve the advection equation,</p><formula xml:id="formula_10">? ?1 (? )t + D? ?1 (? ) v = 0,</formula><p>for unit time (using several discrete time points). This then results in the sought-for transformation map. The initial map mentioned here can be the affine map or the map obtained from a previous vSVF step, namely for the ? -th step, set ? ?1 (? ) (x, 0) = ? ?1 (? ?1) (x, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum Generation Network:</head><p>We implement a deep neural network to generate the vector momentum. As our work does not focus on the network architecture, we simply implement a four-level U-net with residual links <ref type="bibr" target="#b24">[23,</ref><ref type="bibr" target="#b15">16]</ref>. Implementation details can be found in the supplementary material. During training, the gradient is first backpropagated through the integrator for the advection equation followed by the momentum generation network. This can require a lot of memory. Therefore, to reduce memory requirements, the network outputs a low-resolution momentum. In practice, we remove the last decoder level of the U-net. In this case, the remaining vSVF component also operates on the low-resolution map.</p><p>Loss: Similar to the loss in the affine network, the loss for the vSVF part of the network also consists of three terms: a similarity loss L v-sim , a regularization loss L v-reg and a symmetry loss L v-sym .</p><p>The similarity loss L v-sim (I 0 , I 1 , ? ?1 ) is the same as for the affine network. I.e., we also use mk-LNCC.</p><p>The regularization loss L v-reg (m 0 ) penalizes the velocity field. Thus, we have</p><formula xml:id="formula_11">L v-reg (m 0 ) = ? vr v 2 L = ? vr m 0 , v 0 ,<label>(9)</label></formula><p>where v 0 = (L ? L) ?1 m 0 . We implement (L ? L) ?1 as a convolution with a multi-Gaussian kernel <ref type="bibr" target="#b21">[21]</ref>.</p><p>The symmetric loss is defined as <ref type="bibr" target="#b1">2</ref> 2 , (10) where id denotes the identity map, ? vs ? 0 refers to the symmetry weight factor, (? ts ) ?1 denotes the map obtained from registering the target to the source image in the space of the source image and ? ?1 denotes the map obtained from registering the source image to the target image in the space of the target image. Consequentially, the composition also lives in the target image space.</p><formula xml:id="formula_12">L v-sym (? ?1 , (? ts ) ?1 ) = ? vs ? ?1 ?(? ts ) ?1 ?id</formula><p>The complete loss L v (I 0 , I 1 , ? ?1 , (? ts ) ?1 , m 0 , m ts 0 ) for vSVF registration with one step is as follows:</p><formula xml:id="formula_13">L v (I 0 , I 1 ,? ?1 , (? ts ) ?1 , m 0 , m ts 0 ) = v (I 0 , I 1 , ? ?1 , m 0 ) + v (I 1 , I 0 , (? ts ) ?1 , m ts 0 ) + L v-sym (? ?1 , (? ts ) ?1 ),<label>(11)</label></formula><formula xml:id="formula_14">where: v (I 0 , I 1 , ? ?1 , m 0 ) = L v-sim (I 0 , I 1 , ? ?1 ) + L v-reg (m 0 ).</formula><p>For the vSVF model with T steps, the complete loss is: Training details: The training stage includes two parts: 1) Training multi-step affine net: It is difficult to train the multi-step affine network from scratch. Instead, we train a single-step network first and use its parameters to initialize the multi-step network. For longitudinal registration, we train with a three-step affine network, but use a seven-step network during testing. This results in better testing performance than a three-step network. Similarly, for crosssubject registration we train with a five-step network and test with a seven-step one. The affine symmetry factor ? as is set to 10.</p><formula xml:id="formula_15">T ? =1 L v (I 0 , I 1 , ? ?1 (? ) , ? ts (? ) ?1 , m 0(? ) , m ts 0(? ) ) s.t. ? ?1 (? ) (x, 0) = ? ?1 (? ?1) (x, 1), (? ts (? ) ) ?1 (x, 0) = (? ts (? ?1) ) ?1 (x, 1).<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments and Results</head><p>2) Training momentum generation network: During training, the affine part is fixed. For vSVF, we use 10 time-steps and a multi-Gaussian kernel with standard deviations {0.05, 0.1, 0.15, 0.2, 0.25} and corresponding weights {0.067, 0.133, 0.2, 0.267, 0.333} (spacing is scaled so that the image is in [0, 1] 3 ). We train with two steps for both longitudinal and cross-subject registrations. The vSVF regularization factor ? vr is set to 10 and the symmetry factor ? vs is set to 1e-4. For both parts, we use the same training strategy: 1 pair per batch, 400 batches per epoch, 200 epochs per experiment; we set a learning rate of 5e-4 with a decay factor of 0.5 after every 60 epochs. We use mk-LNCC as the similarity measure with (?, s) = {(0.3, S/4), (0.7, S/2)}, where S refers to the smallest image dimension. Besides, in our implementation of mk-LNCC, we set the sliding window stride to S/4 and kernel dilation to 2.</p><p>Additionally, the affine regularization factor ? ar is epoch-dependent during training and defined as:</p><formula xml:id="formula_16">? ar := C ar K ar K ar + e n/Kar ,<label>(13)</label></formula><p>where C ar is a constant, K ar controls the decay rate, and n is the epoch count. In both longitudinal and cross-subject experiments, K ar is set to 4 and C ar is set to 10. <ref type="figure">Figure 4</ref>. Illustration of registration results achieved by AVSM, each column refers to an example. The first five rows refer to source, target, warped image by AVSM, warped image with deformation grid (visualizing ? ?1 ), warped image by multi-step affine respectively, followed by source label, target label and warped label by AVSM separately. There is high similarity between the warped and the target labels and the deformations are smooth.</p><p>Baseline methods: We implement the corresponding numerically optimized versions (e.g., directly optimizing the momentum) of affine (affine-opt) and vSVF (vSVF-opt) registrations. We compare with three widely-used public registration methods: SyN [2, 1], Demons <ref type="bibr" target="#b30">[29,</ref><ref type="bibr" target="#b29">28]</ref> and NiftyReg <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b25">24,</ref><ref type="bibr">19]</ref>. Besides, we also compare the most recent VoxelMorph variant <ref type="bibr" target="#b8">[9]</ref>. We report their performance after an in-depth search for good parameters. For Demons, SyN and NiftyReg, we use isotropic voxel spacing 1 ? 1 ? 1mm 3 as this gives improved results compared to using physical spacing. This implies anisotropic regularization in physical space. For our approaches, isotropic or anisotropic regularization in physical space gives similar results. Hence, we choose the more natural isotropic regularization in physical space.</p><p>Optimization-based multi-scale affine registration: Instead of optimizing for the affine parameters on a single image scale, we use a multi-scale strategy. Specifically, we start at a low image-resolution, where affine parameters are roughly estimated, and then use them as the initialization for the next higher scale. Stochastic gradient descent is used with a learning rate of 1e-4. Three image scales {0. <ref type="bibr" target="#b26">25</ref> Optimization-based multi-scale vSVF registration: We take the affine map (resulting from the optimization-based multi-scale affine registration) as the initial map and then numerically optimize the vSVF model. The same multiscale strategy as for the affine registration is used. The momentum is up-sampled between scales. We use L-BGFS <ref type="bibr" target="#b14">[15]</ref> for optimization. In our experiments, we use three scales {0.25, 0.5, 1.0} with 60 iterations per scale. The same mk-LNCC similarity measure as for the optimization-based multi-scale affine registration is used. The number of time steps for the integration of the advection equation and the settings for the multi-Gaussian kernel are the same as for the proposed deep network model.</p><p>NiftyReg: We run two registration phases: affine followed by B-spline registration. Three scales are used in each phase and the interval of the B-spline control points is set to 10 voxels. In addition, we find that using LNCC as the similarity measure, with a standard deviation of 40 for the Gaussian kernel, performs better than the default Normalized Mutual Information, but introduces folds in the transformation. In LNCC experiments, we therefore use a log of the Jacobi determinant penalty of 0.01 to reduce folds.</p><p>Demons: We take the affine map obtained from NiftyReg as the initial map and use the Fast Symmetric Forces Demons Algorithm <ref type="bibr" target="#b30">[29]</ref> via SimpleITK. The Gaussian smoothing standard deviation for the displacement field is set to 1.2. We use MSE as the similarity measure.</p><p>SyN: We compare with Symmetric Normalization (SyN), a widely used registration method implemented in the ANTs software package <ref type="bibr" target="#b0">[1]</ref>. We take Mattes as the metric for affine registration, and take CC with sampling radius set to 4 for SyN registration. We use multi-resolution optimization with four scales with {2100, 1200, 1200, 20} iterations; the standard deviation for Gaussian smoothing at each level is set to {3, 2, 1, 0}. The flow standard deviation to smooth the gradient field is set to 3.</p><p>VoxelMorph: We compute results based on the most re-  <ref type="table">Table 1</ref>. Dice scores (standard deviation) of different registration methods for longitudinal and cross-subject registrations on the OAI dataset. Affine-opt and vSVF-opt refer to optimization-based multi-scale affine and vSVF registrations. AVSM (n-step) refers to a seven-step affine network and an n-step vSVF model. Folds cent VoxelMorph variant <ref type="bibr" target="#b8">[9]</ref>, which is also a deep-learning based. As VoxelMorph assumes that images are prealigned, for a fair comparison, we therefore initialized it via our proposed multi-step affine network. Best parameters are determined via grid search. NiftyReg, Demons and SyN are run on a server with i9-7900X (10 cores @ 3.30GHz) , while all other methods run on a single NVIDIA GTX 1080Ti. Tab.1 compares the performance of our framework with its corresponding optimization version and public registration tools. Overall, our AVSM framework performs best in cross-subject registration and achieves slightly better performance than optimization-based methods, both for affine and non-parametric registrations. NiftyReg with LNCC shows similar performance. For longitudinal registration, AVSM shows good performance, but slightly lower than the optimization-based methods, including vSVF-opt which AVSM is based on. A possible explanation is that for longitudinal registrations deformations are subtle and source/target image pairs are very similar in appearance. Hence, numerical optimization can very accurately align such image-pairs at convergence. VoxelMorph runs fastest among all the methods. Without initial affine registration, it unsurprisingly performs poorly. Once the input pair is well pre-aligend, VoxelMorph shows competitive results for longitudinal registrations, but is outperformed by our approach for the more challenging cross-subject registration. To evaluate the smoothness of the transformation map, we compute the determinant of the Jacobian of the estimated map, J ? (x) := |D? ?1 (x)|, and count folds defined by |{x : J ? (x) &lt; 0}| in each image (192 ? 192 ? 80 voxels in total). We also report the absolute value of the determinant of the Jacobian in these cases indicating the severity of the fold. Even though the regularization is used, numerical optimization (vSVF-opt) always results in diffeomorphisms, but very few folds remain in AVSM for cross-subject registration. This may be caused by numerical discretization artifacts, by very large predicted momenta, or by inaccuracies of the predictions with respect to the numerical optimization results. <ref type="figure" target="#fig_3">Fig. 5</ref> shows the corresponding boxplot results. AVSM achieves small variance and high performance in both registration tasks and exhibits less registration failures (outliers). As AVSM only requires one forward pass to complete both the affine and the vSVF registration, it is much faster than using iterative numerical optimization.</p><p>Tab. 2 shows results for an ablation study on AVSM. For the affine part, it is difficult to train the single-step affine network without the regularization term. Hence, registrations fail. Introducing multi-step and inverse consistency boosts the affine performance. Compared with using NCC as similarity measure, our implementation of mk-LNCC improves results greatly. In the following vSVF part, we observe a large difference between methods IV and VI, illustrating that vSVF registration results in large improvements. Adding mk-LNCC and multi-step training in methods VII and VIII further improves performance. The exception is the vSVF symmetry loss which slightly worsens the performance for both longitudinal and cross-subject registration, but results in good symmetry measures (see <ref type="figure" target="#fig_4">Fig. 6</ref>).</p><p>We still retain the symmetric loss as it helps the network to converge to solutions with smoother maps as shown in <ref type="figure" target="#fig_4">Fig. 6</ref>. Instead of using larger Gaussian kernels, which can remove local displacements, penalizing asymmetry helps regularize the deformation without smoothing the map too much and without sacrificing too much performance. To numerically evaluate the symmetry, we compute ln( 1</p><formula xml:id="formula_17">|V | ? ?1 ? (? ts ) ?1 ?id 2</formula><p>2 ) for all registration methods, where V refers to the volume size and ? the map obtained via composition of the affine and the deformable transforms. Since differ-  <ref type="table">Table 2</ref>. Ablation study of AVSM using different combinations of methods. Afand vSVFseparately refer to the affine and to the vSVF related methods; Reg refers to adding epoch-dependent regularization; Multi refers to multi-step training and testing; Sym refers to adding the symmetric loss; MK refers to using mk-LNCC as similarity measure (default NCC). Except for the last approach which uses vSVF-Sym (last row) and encourages symmetric vSVF solutions, all other approaches result in performance improvements. ent methods treat boundaries differently, we only evaluate this measure in the interior of the image volume (10 voxels away from the boundary). <ref type="figure" target="#fig_5">Fig. 7</ref> shows the results. AVSM obtains low values for both registration tasks, confirming its good symmetry properties. Both the Demons and SyN also encourage symmetry, but only AVSM shows a nice compromise between accuracy and symmetry. <ref type="figure" target="#fig_6">Fig. 8</ref> shows the average Dice sores over the number of test iteration steps of vSVF. The model is trained using a two-step vSVF. It can be observed that iterating the model for more than two steps can increase performance as these iterations result in registration refinements. However, the average number of folds also increases, mostly at boundary regions and in regions of anatomical inconsistencies. Examples are shown in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions and Future Work</head><p>We introduced an end-to-end 3D image registration approach (AVSM) consisting of a multi-step affine network and a deformable registration network using a momentumbased SVF algorithm. AVSM outputs a transformation map which includes an affine pre-registration and a vSVF nonparametric deformation in a single forward pass. Our results on cross-subject and longitudinal registration of knee MR images show that our method achieves comparable and sometimes better performance to popular registration tools  with a dramatically reduced computation time and with excellent deformation regularity and symmetry. Future work will focus on also learning regularizers and evaluations on other registration tasks, e.g. in the brain and the lung. Acknowledgements: Research reported in this publication was supported by the National Institutes of Health (NIH) and the National Science Foundation (NSF) under award numbers NSF EECS1711776 and NIH 1R01AR072013. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or the NSF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplementary material</head><p>This supplementary material provides additional details illustrating the proposed approach. Specifically, Sec. A.1 describes how the affine training is regularized in an epochdependent way. Sec. A.2 shows registration performance for different numbers of steps for the affine registration-part of the network. Sec. A.3 details the structure of the momentum generation network. Lastly, Sec. A.4 shows additional registration examples.</p><p>A.1. Affine regularization factor <ref type="figure">Figure 9</ref>. Graph of the affine regularization factor. Its value decays to zero over the epochs.</p><p>To help with convergence of the affine registration network, we use an epoch-dependent regularization factor, which discourages large transformations at the start of the training. Specifically, we define this epoch-dependent regularization factor as ? ar := C ar K ar K ar + e n/Kar ,</p><p>where C ar is a constant, K ar controls the decay rate, and n is the epoch count. <ref type="figure">Fig. 9</ref> shows the value of ? ar plotted over the epochs. As the value decays to zero with the epochs, its influence on the training becomes negligible. For both longitudinal and cross-subject experiments, K ar is set to 4 and C ar is set to 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Dice over steps in Multi-step Affine Network</head><p>The main manuscript shows the average Dice scores over the number of test iteration steps for the vSVF registration component. For completeness, <ref type="figure" target="#fig_0">Fig. 10</ref> shows the average Dice scores over the number of steps for the affine network. The model is trained using a three-step affine network for longitudinal registrations and using five steps for cross-subject registration. Similar to the vSVF registration, it can be observed that model performance improves with large number of steps and saturates at a high performance level. <ref type="figure" target="#fig_0">Figure 10</ref>. Multi-step Affine registration results over iteration steps. The affine network is trained using three steps for longitudinal registration (red) and five steps for cross-subject registration (blue). Performance increases with steps and finally saturates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Structure of Momentum Generation Network</head><p>As the network structure itself is not the main contribution of our work, we do not describe it in detail in the main manuscript. For completeness, we describe the architecture here. <ref type="figure" target="#fig_0">Fig. 11</ref> shows the structure of the Momentum Generation Network. It takes a pair of images as the input and outputs a low-resolution initial momentum. We use a fourlevel U-net <ref type="bibr" target="#b24">[23,</ref><ref type="bibr" target="#b15">16]</ref> with residual links, but remove the last decoder level to output the low-resolution momentum. As the momentum can be positive or negative, no activation function (e.g. ReLu <ref type="bibr">[?]</ref> or leakyRelu [?]) is used after the last two convolutional layers, which output the momentum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Visualization</head><p>To provide more insight into the registration behavior of our network, we visualize results illustrating deformation folds, results for different steps in the multi-step approach, and additional examples. Specifically, we show the following:</p><p>? Folds: To better visualize the folds produced by the multi-step vSVF, we report the registration results, shown in <ref type="figure" target="#fig_0">Fig. 12</ref>, from the six-step vSVF. These folds mostly occur at regions of anatomical inconsistency or at the image boundary where map interpolation artifacts may influence the solution. In these regions, very large momentum values may be predicted which can result in folds due to discretization artifacts when integrating the advection equation.</p><p>? Multi-step in vSVF registration: <ref type="figure" target="#fig_0">Fig. 13</ref> shows the registration results over the steps of the vSVF. Although folds may result from the multi-step strategy in some very large deformation cases, the transformation maps are largely well regularized. We observe that the registration results improve over the steps. AVSM registration results. It can be observed that AVSM achieves good registration results with smooth transformation maps for cases with large and small deformations. <ref type="figure" target="#fig_0">Figure 13</ref>. Illustration of the results of one registration case (with six steps) by AVSM (trained using a two-step vSVF). From left to right, each column shows results for different steps. The first five rows refer to source, target, warped image by AVSM, warped image with deformation grid (visualizing ? ?1 ) and warped image by the multi-step affine network respectively. The last three rows show the source label, target label and warped label for the AVSM result. The transformation map gets refined over the six steps and the registration result improves as indicated by a better correspondence between the target label and the warped label images (last two rows).</p><p>learning approach. NeuroImage, 158:378-396, 2017. 1 <ref type="figure" target="#fig_0">Figure 14</ref>. Illustration of results of six registration cases by AVSM. Each column refers to an example registration case. The first five rows refer to source, target, warped image by AVSM, warped image with deformation grid (visualizing ? ?1 ) and warped image by the multi-step affine network respectively. The last three rows show the source label, target label and warped label by AVSM. There is high similarity between the warped and the target images and the deformations are smooth, illustrating the good registration performance of our proposed AVSM approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Our framework consists of affine (left) and vSVF (right) registration components. The affine part outputs the affine map and the affinely warped source image. The affine map initializes the map of the vSVF registration. The affinely warped image and the target image are input into the momentum generation network to predict the momentum of the vSVF registration model. The outputs of the vSVF component are the composed transformation map and the warped source image, which can be either taken as the final registration result or fed back (indicated by the dashed line) into the vSVF component to refine the registration solution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, 0.5, 1.0} are used, each with {200, 200, 50} iterations. We use mk-LNCC as the similarity measure. At each scale k, let image size (smallest length among image dimensions) be S k , here k ? {0.25, 0.5, 1.0}. At scale 1.0, parameters are set to (?, s) = {(0.3, S k /4), (0.7, S k /2)}, i.e., the same parameters as for the network version; at scales 0.5 and 0.25, (?, s) = {(1.0, S k /2)}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(|{x : J ? (x) &lt; 0}|) refers to the average number of folds and corresponding absolute Jacobi determinant value in square brackets; Time refers to the average time per image registration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Box-plots of the performance of the different registration methods for longitudinal registration (green) and crosssubject registration (orange). Both AVSM and NiftyReg (LNCC) show high performance and small variance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Illustration of symmetric loss for AVSM. The left column shows the source and target images. The right column shows the warped image from a network trained with and without symmetric loss. The deformation with symmetric loss is smoother.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Box-plots of the symmetry evaluation (the lower the better) of different registration methods for longitudinal registration (green) and cross-subject registration (orange). AVSM (tested with two-step vSVF) shows good results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Multi-step vSVF registration results for two-step vSVF training. Performance increases with steps (left), but the number of folds also increases (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>?Figure 11 .</head><label>11</label><figDesc>More AVSM examples: Fig. 14 shows additional Illustration of the structure of Momentum Generation Network. It follows the structure of the U-net but the last level decoder is removed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The Osteoarthritis Initiative (OAI) dataset consists of 176 manually labeled magnetic resonance (MR) images from 88 patients (2 longitudinal scans per patient) and 22,950 unlabeled MR images from 2,444 patients. Labels are available for femoral and tibial cartilage. All images are of size 384 ? 384 ? 160, where each voxel is of size 0.36 ? 0.36 ? 0.7mm 3 . We normalize the intensities of each image such that the 0.1th percentile and the 99.9th percentile are mapped to 0, 1 and clamp values that are smaller to 0 and larger to 1 to avoid outliers. All images are downsampled to size 192 ? 192 ? 80.</figDesc><table /><note>Dataset:Evaluation: We evaluate on both longitudinal and cross- subject registrations. We divide the unlabeled patients into a training and a validation group, with a ratio of 7:3. For the longitudinal registrations, 4,200 pairs from the training group (obtained by swapping the source and the target from 2,100 pairs of images) are randomly selected for training, and 50 pairs selected from the validation group are used for validation. All 176 longitudinal pairs with labels are used as our test set. For the cross-subject registrations, we ran- domly pick 2,800 (from 1,400 pairs) cross-subject training pairs and 50 validation pairs; 300 pairs (from 150 pairs) are randomly selected as the test set. We use the average Dice score [11] over all testing pairs as the evaluation metric.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Method Af-Reg Af-Multi Af-Sym Af-MK vSVF vSVF-MK vSVF-Multi vSVF-Sym LongitudinalBetter? Cross-subject Better?</figDesc><table><row><cell>I</cell><cell>-</cell><cell>-</cell></row><row><cell>II</cell><cell>55.41</cell><cell>28.68</cell></row><row><cell>III</cell><cell>64.78</cell><cell>36.31</cell></row><row><cell>IV</cell><cell>68.87</cell><cell>37.54</cell></row><row><cell>V</cell><cell>77.75</cell><cell>44.58</cell></row><row><cell>VI</cell><cell>80.71</cell><cell>59.21</cell></row><row><cell>VII</cell><cell>81.64</cell><cell>64.56</cell></row><row><cell>VIII</cell><cell>82.81</cell><cell>69.08</cell></row><row><cell>IV</cell><cell>82.67</cell><cell>68.40</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For these end-to-end approaches, the sought-for registration parameterization is either the final output of the network (for the prediction of displacement fields) or an intermediate output (for the prediction of velocity fields) from which the transformation map can be recovered. The rest of the formulation stays the same.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">To simplify the notation, we omit st (source to target registration) in what follows and only emphasize ts (target to source registration).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The manuscript is organized as follows: Sec. 2 describes our ASVM approach; Sec. 3 shows experimental results; Sec. 4 presents conclusions and avenues for future work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">L</forename><surname>Avants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James C</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Advanced normalization tools (ANTS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Brian B Avants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Tustison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>Insight j</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiresolution elastic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruzena</forename><surname>Bajcsy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stane</forename><surname>Kova?i?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An unsupervised learning model for deformable medical image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guha</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">V</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="9252" to="9260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computing large deformation metric mappings via geodesic flows of diffeomorphisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Trouv?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Younes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deformable image registration using a cue-aware deep regression network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1900" to="1911" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Pew-Thian Yap, and Dinggang Shen</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Airnet: Self-supervised affine registration for 3d medical images using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelyn</forename><surname>Chee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02583</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large displacement optical flow from nearest neighbor fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2443" to="2450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised learning for fast probabilistic diffeomorphic registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guha</forename><surname>Adrian V Dalca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert R</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sabuncu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04605</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">End-to-end unsupervised deformable image registration with a convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Floris</forename><forename type="middle">F</forename><surname>Bob D De Vos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><forename type="middle">A</forename><surname>Berendsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Marius Staring, and Ivana I?gum</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="204" to="212" />
		</imprint>
	</monogr>
	<note>MLCDS</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measures of the amount of ecologic association between species</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee R Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An optimal control approach for deformable registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Non-rigid image registration using fully convolutional networks with deep selfsupervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00799</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="503" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed-Ahmad</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<title level="m">Fourth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Global image registration using a symmetric block-matching approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Modat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gavin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ourselin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parametric non-rigid registration using a stationary velocity field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Modat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Daga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Ourselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Gerard R Ridgway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ashburner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Workshop on Mathematical Methods in Biomedical Image Analysis (MMBIA)</title>
		<imprint>
			<biblScope unit="page" from="145" to="150" />
			<date type="published" when="2012" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Fast free-form deformation using graphics processing units. Computer methods and programs in biomedicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Modat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gerard R Ridgway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manja</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><forename type="middle">C</forename><surname>Hawkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ourselin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Reconstructing a 3D structure from serial histological sections. Image and vision computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>S?bastien Ourselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?rard</forename><surname>Roche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Subsol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ayache</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Simultaneous fine and</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Risser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois-Xavier</forename><surname>Vialard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Wolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darryl</forename><forename type="middle">D</forename><surname>Holm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Each column refers to an example registration case. From top to bottom source, target, warped image by AVSM and warped image with deformation grid (visualizing ? ?1 ) are shown. Folds are shown in gray. From left to right, the first three columns refer to cases with anatomical inconsistency and the last column refers to a case where the folds occur at the boundary. coarse diffeomorphic registration: application to atrophy measurement in Alzheimers disease</title>
	</analytic>
	<monogr>
		<title level="m">Figure 12. Examples of folds produced by a six-step vSVF (trained using a two-step vSVF)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="610" to="617" />
		</imprint>
	</monogr>
	<note>MICCAI</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Volume-preserving nonrigid registration of MR breast images using free-form deformation with an incompressibility constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Calvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael A</forename><surname>Bluemke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="730" to="741" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nonrigid registration using free-form deformations: application to breast MR images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmel</forename><surname>Sonoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Derek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="712" to="721" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">HAMMER: hierarchical attribute matching mechanism for elastic registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinggang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1421" to="1439" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A rigidity penalty term for nonrigid registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Staring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical physics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4098" to="4108" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Volume and shape preservation of enhancing lesions when applying non-rigid registration to a time series of contrast enhancing MR breast images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Derek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="327" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Symmetric log-domain diffeomorphic registration: A demons-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Vercauteren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Pennec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="754" to="761" />
		</imprint>
	</monogr>
	<note>Aymeric Perchant, and Nicholas Ayache</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Diffeomorphic demons: Efficient nonparametric image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Vercauteren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Pennec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Aymeric Perchant, and Nicholas Ayache</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Diffeomorphic 3D image registration via geodesic shooting using an efficient adjoint calculation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F-X</forename><surname>Vialard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Risser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Cotter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="241" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient sparse-to-dense optical flow estimation using a learned basis and layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="120" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast predictive image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DLMIA</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="48" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Styner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<title level="m">Quicksilver: Fast predictive image registration-a deep</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
