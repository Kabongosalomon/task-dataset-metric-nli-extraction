<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Poseur: Direct Human Pose Regression with Transformers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weian</forename><surname>Mao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongtao</forename><surname>Ge</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibin</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Alibaba Damo Academy</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Poseur: Direct Human Pose Regression with Transformers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>2D Human Pose Estimation</term>
					<term>Keypoint Detection</term>
					<term>Trans- former</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a direct, regression-based approach to 2D human pose estimation from single images. We formulate the problem as a sequence prediction task, which we solve using a Transformer network. This network directly learns a regression mapping from images to the keypoint coordinates, without resorting to intermediate representations such as heatmaps. This approach avoids much of the complexity associated with heatmap-based approaches. To overcome the feature misalignment issues of previous regression-based methods, we propose an attention mechanism that adaptively attends to the features that are most relevant to the target keypoints, considerably improving the accuracy. Importantly, our framework is end-to-end differentiable, and naturally learns to exploit the dependencies between keypoints. Experiments on MS-COCO and MPII, two predominant pose-estimation datasets, demonstrate that our method significantly improves upon the state-of-the-art in regression-based pose estimation. More notably, ours is the first regression-based approach to perform favorably compared to the best heatmap-based pose estimation methods. Code is available at: https://github.com/aim-uofa/Poseur</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>pixel in a region corresponds to a particular skeleton keypoint. The current stateof-the-art methods use a fully convolutional network (FCN) to estimate this heatmap. The final keypoint location estimate corresponds to the peak in the heatmap intensity. Most current pose estimation methods are heatmap-based because this approach has thus far achieved higher accuracy than regression-based approaches. Heatmap-based methods have their disadvantages, however. 1) The ground-truth heatmaps need to be manually designed and heuristically tuned. The noise inevitably introduced impacts on the final results <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref>. 2) A post-processing operation is required to find a single maximum of the heatmap. This operation is often heuristic, and non-differentiable, which precludes endto-end training-based approaches.</p><p>3) The resolution of heatmaps predicted by the FCNs is usually lower than the resolution of the input image. The reduced resolution results in a quantization error and limits the precision of keypoint localization. This quantization error might be ameliorated somewhat by various forms of interpolation, but this makes the framework less differentiable, more complicated and introduces some extra hyper-parameters. shows crucial spatial information is inevitably lost with GAP. We alleviate both issues with the design in (c).</p><p>Regression-based methods directly map the input image to the coordinates of body joints, typically using a fully-connected (FC) prediction layer, eliminating the need for heatmaps. The pipeline of regression-based methods is much more straightforward than heatmap-based methods, as pose estimation is naturally formulated as a process of predicting a set of coordinate values. A regressionbased approach also alleviates the need for non-maximum suppression, heatmap generation, and quantization compensation, and is inherently end-to-end differentiable.</p><p>Regression-based pose-estimation has received less attention than heatmapbased methods due to its inferior performance. There are a variety of causes of this performance deficit. First, in order to reduce the number of parameters in the final FC prediction layer, models such as DeepPose <ref type="bibr" target="#b30">[31]</ref> and RLE <ref type="bibr" target="#b17">[18]</ref> employ a global average pooling that is applied to reduce the CNN feature map's resolution before the FC layers, as illustrated in <ref type="figure">Fig. 2(b)</ref>. This global average pooling destroys the spatial structure of the convolutional feature maps, and has a significantly negative impact on performance. Next, as shown in <ref type="figure">Fig. 2(a)</ref>, the convolutional features and predictions of some regression-based models (e.g. DirectPose <ref type="bibr" target="#b29">[30]</ref> and SPM <ref type="bibr" target="#b25">[26]</ref>) are misaligned, which consequently reduces localization precision. Lastly, regression-based methods only regress the coordinates of body joints and do not exploit the structured dependency between them <ref type="bibr" target="#b27">[28]</ref>.</p><p>Recently, Transformers have been applied to a range of tasks in computer vision, achieving impressive results <ref type="bibr">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">40]</ref>. This, and the fact that transformers were originally designed for sequence-to-sequence tasks, motivated our formulation of single person pose estimation as a sequence prediction problem. Specifically, we pose the problem as that of predicting a length-K sequence of coordinates, where K is the number of body joints for one person. This leads to a simple and novel regression-based pose estimation framework, that we label as Poseur.</p><p>As shown in <ref type="figure" target="#fig_4">Fig. 3</ref>, taking as inputs the feature maps of an encoder CNN, the transformer predicts K coordinate pairs. In doing so, Poseur alleviates the aforementioned difficulties of regression-based methods. First, it does not need global average pooling to reduce feature dimensionality (cf. RLE <ref type="bibr" target="#b17">[18]</ref>). Second, Poseur eliminates the misalignment between the backbone features and predictions with the proposed efficient cross-attention mechanism. Third, since the self-attention module is applied across the keypoint queries, the transformer naturally captures the structured dependencies among the keypoints. Lastly, as shown in <ref type="figure">Fig. 1</ref>, Poseur outperforms heatmap-based methods with a variety of backbones. The improvement is more significant for the backbones using low-resolution representation, e.g., MobileNet V2 and ResNet. The results indicate that Poseur can be deployed with fast backbones of low-resolution representation without large performance drop, which is difficult to be achieved for heatmap-based methods. We refer readers to Sec. 4.4 for more details.</p><p>Our main contributions are as follows.</p><p>-We propose a transformer-based framework (termed Poseur) for directly human pose regression, which is lightweight and can work well with the backbones using low-resolution representation.  <ref type="bibr" target="#b14">[15]</ref>, which is end-to-end trainable and can overcome many drawbacks of the heatmap-based methods. In this end-to-end setting, our method outperforms the previously best end-to-end top-down method PointSet Anchor <ref type="bibr" target="#b33">[34]</ref> by 3.8 AP with the HRNet-W48 backbone on the COCO val set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Heatmap-based pose estimation. Heatmap-based 2D pose estimation methods <ref type="bibr">[2,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36]</ref> estimate per-pixel likelihoods for each keypoint location, and currently dominate in the field of 2D human pose estimation. A few works <ref type="bibr">[2,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> attempt to design powerful backbone networks which can maintain high-resolution feature maps for heatmap supervision. Another line of works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref> focus on alleviating biased data processing pipeline for heatmapbased methods. Despite the good performance, the heatmap representation bears a few drawbacks in nature, e.g. , non-differentiable decoding pipeline <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> and quantization errors <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39]</ref> due to the down sampling of feature maps.</p><p>Regression-based pose estimation. 2D human pose estimation is naturally a regression problem <ref type="bibr" target="#b28">[29]</ref>. However, regression-based methods have historically not been as accurate as heatmap-based methods, and it has received less attention as a result <ref type="bibr">[5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>. Integral Pose <ref type="bibr" target="#b28">[29]</ref> proposes integral regression, which shares the merits of both heatmap representation and regression approaches, to avoid non-differentiable post-processing and quantization error issues. However, integral regression is proven to have an underlying bias compared with direct regression according to <ref type="bibr" target="#b13">[14]</ref>. RLE <ref type="bibr" target="#b17">[18]</ref> develops a regression-based method using maximum likelihood estimation and flow models. RLE <ref type="bibr" target="#b17">[18]</ref> is the first to push the performance of the regression-based method to a level comparable with that of the heatmap-based methods. However, it is trained on the backbone that pre-trained by the heatmap loss.</p><p>Transformer-based architectures. Transformers have been applied to the pose estimation task with some success. TransPose <ref type="bibr" target="#b36">[37]</ref> and HRFormer <ref type="bibr" target="#b37">[38]</ref> enhance the backbone via applying the Transformer encoder to the backbone; TokenPose <ref type="bibr" target="#b21">[22]</ref> designs the pose estimation network in a ViT-style fashion by splitting image into patches and applying class tokens, which makes the pose estimation more explainable. These methods are all heatmap-based and use a heavy transformer encoder to improve the model capacity. In contrast, Poseur is a regression-based method with a lightweight transformer decoder. Thus, Poseur is more computational efficient while can still achieve high performance.</p><p>PRTR <ref type="bibr" target="#b19">[20]</ref> leverage the encoder-decoder structure in transformers to perform pose regression. PRTR is based on DETR <ref type="bibr">[4]</ref>, i.e., it uses Hungarian matching strategy to find a bipartite matching between non class-specific queries and   </p><formula xml:id="formula_0">b). Keypoint Encoder $! &amp; ! $" &amp; " d). Residual Log-Likelihood Estimation (RLE) $ &amp; Regression Model (?) = ? ? &amp; + $ #( ? ) $,#( |?) Image(?) $( |?) e). Uncertainty Score ? + Normalizing Flow (?) ( ? ) ? = #( ? ) #( ? ) $,#( |?) + ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simplified Version</head><p>Only used in training stage ground-truth joints. It brings two issues: 1) heavy computational cost; 2) redundant queries for each instance. In contrast, Poseur can alleviate both issues while achieving much higher performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Poseur Architecture</head><p>Our proposed pose estimator Poseur aims to predict K human keypoint coordinates from a cropped single person image. As shown in <ref type="figure">Fig. 2</ref>(c), The core idea of our method is to represent human keypoints with queries, i.e., each query corresponds to a human keypoint. The queries are input to the deformable attention module <ref type="bibr">[40]</ref>, which adaptively attends to the image features that most relevant to the query/keypoint. In this way, the information about a specific keypoint can be summarized and encoded into a single query, which is used to regress the keypoint coordinate later. As such, the issue of losing spatial information caused by the global average pooling in RLE <ref type="bibr" target="#b18">[19]</ref> (As shown in <ref type="figure">Fig. 2(b)</ref>) is well addressed. Specifically, in Poseur framework (shown in <ref type="figure" target="#fig_4">Fig. 3</ref>), two main components are added upon the backbone: a keypoint encoder and a query decoder. An input image is first encoded as dense feature maps with the backbone, which are followed by an FC layer to predict the rough keypoint coordinates, used as a set of rough proposals. We denote the proposal coordinates as? f ? R K?2 . Then, those proposals are used to initialize the keypoint-specific query Q ? R K?C (where C is the embedding dimension) in the keypoint encoder. Finally, the feature maps from the backbone and Q are sent into the query decoder to obtain the final features for the keypoints, each of which is sent into a linear layer to predict the corresponding keypoint coordinates. In addition, unlike previous methods simply regressing the keypoint coordinates and applying the L 1 loss for supervision, Poseur, following RLE <ref type="bibr" target="#b18">[19]</ref>, predicts a probability distribution reflecting the probability of the ground truth appearing in each location and supervise the network by maximum the probability on the ground truth location. Specifically, a location parameter? q and a scale parameterb q are predicted by Poseur (?) for shifting and scaling the distribution generated by a flow model ? (refer to Sec. 3.2).? q is the center of the distribution and can be regarded as the predicted keypoint coordinates. Backbone. Our method is applicable to both CNN (e.g. ResNet <ref type="bibr" target="#b15">[16]</ref>, HR-Net <ref type="bibr" target="#b26">[27]</ref>) and transformer backbones (e.g. HRFormer <ref type="bibr" target="#b37">[38]</ref>). Given the backbone, multi-level feature maps are extracted and then fed into the query decoder. At the same time, a global average pooling operation is conducted in the last stage of the backbone and followed by an FC layer to regress the coarse keypoint coordinates? f (normalized in [0, 1]) and the corresponding scale parameterb f , supervised by Residual Log-Likelihood Estimation (RLE) process introduced in Sec. 3.2. Keypoint encoder. The keypoint encoder is used to initialize each query Q for the query decoder. For initializing the query better, two keypoints' attributes, location and category, are encoded into the query in the keypoint encoder. Specifically, first, for location attribute, we encode the rough x-y keypoint coordinates? f with the fixed positional encodings, transforming the x-y coordinates to the sine-cosine positional embedding following <ref type="bibr" target="#b31">[32]</ref>. The obtained tensor is denoted by? * f ? R K?C ; second, for the category attribute, K learnable vectors Q c ? R K?C , called class embedding, is used to represent K different categories separately. Finally, the initial queries Q z ? R K?C are generated by fusing the location and category attribute through element-wise addition of the positional and class embedding, i.e.Q z = Q c +? * f . However,? f is just a coarse proposal, which sometimes goes wrong during inference. To make our model more robust for the wrong proposal, we introduce a query augmentation process, named noisy reference points sampling strategy, used only during training. The core idea of noisy reference points sampling strategy is to simulate the case that the coarse proposals? f goes wrong and force the decoder to located correct keypoint with wrong proposal. Specifically, during training, we construct two types of keypoint queries. The first type of keypoint query is initialized with the proposal? f ; the second type of keypoint query is initialized with normalized random coordinates? n (noisy proposal). And then, both of two types query are processed equally in all following training stages. Our experiment shows that training the decoder network with noisy proposal ? n improves its robustness to errors introduced by coarse proposal? f during the inference stage. Note, that during inference randomly initialized keypoint queries are not used. Query decoder. In query decoder, query and feature map are mainly used to module the relationship between keypoints and input image. As shown in <ref type="figure" target="#fig_4">Fig. 3</ref>, the decoder follows the typical transformer decoder paradigm, in which, there are N identical layers in the decoder, each layer consisting of self-attention, crossattention and feed-forward networks (FFNs). The query Q goes through these modules sequentially and generates an updated Q as the input to the next layer. As in DETR <ref type="bibr">[4]</ref>, the self-attention and FFNs are a multi-head self-attention <ref type="bibr" target="#b31">[32]</ref> module and MLPs, respectively. For the cross-attention networks, we propose an efficient multi-scale deformable attention (EMSDA) module, based on MSDA proposed by Deformable DETR <ref type="bibr">[40]</ref>. Similar to MSDA, in EMSDA, each query learns to sample relevant features from the feature maps by given the sampling offset around a reference point (a pair of coordinates, and which will be introduced later); and then, the sampled features are summarized by the attention mechanism to update the query. Different from MSDA, which applies a linear layer to the entire feature maps and thus is less efficient, we found that it is enough to only apply the linear layer to the sampled features after bilinear interpolation. Experiments show that the latter can have a similar performance while being much more efficient. Specifically, EMSDA can be written as</p><formula xml:id="formula_1">EMSDA(Qq,pq, {x l } L l=1 ) = Concat(head1, . . . , headM)W o where headi = ( L l=1 S s=1 A i,l,q,s ? x l (? l (pq) + ?p i,l,q,s ))W v i ,<label>(1)</label></formula><p>where Q q ? R C ,p q ? R 2 and {x l } L l=1 are the q-th input query vector, the reference point offset of q-th query and l-th level of feature maps from the backbone; the dimension of each feature vector in x is C. head i represents i-th attention head. L, M and S represent the number of feature map levels used in the decoder, the number of attention heads and the number of sampling points on each level feature map, respectively. A i,l,q,s ? R 1 and ?p i,l,q,s ? R 2 represent the attention weights and the sampling offsets of the i-th head, l-th level, q-th query and s-th sampling point, respectively; The query feature Q q is fed to a linear projection to generate A i,l,q,s and ?p i,l,q,s . A i,l,q,s satisfies the limitation, L l=1 S s=1 A i,l,q,s = 1. ? l (?) is the function transforming thep q to the coordinate system of the l-th level features. x l (? l (p q ) + ?p i,l,q,s ) represents sampling the feature vector located in offset (? l (p q )+?p i,l,q,s ) on the feature map x l by bilinear interpolation. W o ? R C?C and W v i ? R C?(C/M ) are two groups of trainable weights. The reference pointp q will be updated at the end of each decoder layer by applying a linear layer on Q q . Note, the FC output? f is leveraged as reference point for the initial query Q z . For more details and computational complexity, we refer readers to our supplementary material.</p><p>To sum up, the relations between different keypoints are modeled through a self-attention module, and the relations between the input image and keypoints are modeled through EMSDA module. Notably, the problem of feature misalignment in fully-connected regression is solved by EMSDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Targets and Loss Functions</head><p>Following RLE <ref type="bibr" target="#b17">[18]</ref>, we calculate a probability distribution P ?,? (x|I) reflecting the probability of the ground truth appearing in the location x conditioning on the input image I, where ? is the parameters of Poseur and ? is the parameters of a flow model. As shown in <ref type="figure" target="#fig_4">Fig. 3(d)</ref>, The flow model f ? is leveraged to reflect the deviation of the output from the ground truth ? g by mapping a initial distributionz ? N (0, I) to a zero-mean complex distributionx ? G ? (x). Then P ? (x) is obtained by adding a zero-mean Laplace distribution L(x) to G(x). The regression model ? predictions the center?, and scaleb of the distribution. Finally, the distribution P ?,? (x|I) is built upon P ? (x) by shifting and rescalin? x into x, where x =x ?? +?. We refer readers to <ref type="bibr" target="#b17">[18]</ref> for more details.</p><p>Different from RLE <ref type="bibr" target="#b17">[18]</ref>, we only use the proposal (? f ,b f ) for coarse prediction. This prediction is then updated by the query-based approach described above to generate an improved estimate (? q ,b q ). Both coarse proposal (? f ,b f ) and query decoder preditions (? q ,b q ) are supervised with the maximum likelihood estimation (MLE) process. The learning process of MLE optimizes the model parameters so as to make the observed ground truth ? g most probable.</p><p>The loss function of FC predictions (? f ,b f ) can be defined as:</p><formula xml:id="formula_2">L f c rle = ? log P ? f ,? f (x|I) x=? g ,<label>(2)</label></formula><p>where ? f and ? f are the parameters of the backbone and flow model, respectively. Similarly, the loss of distribution associated with query decoder preditions (? q ,b q ) can be defined as:</p><formula xml:id="formula_3">L dec rle = ? log P ?q,?q (x|I) x=? g ,<label>(3)</label></formula><p>where ? q and ? q are the parameters of the query decoder and another flow model, respectively. Finally, we sum the two loss functions to obtain the total loss:</p><formula xml:id="formula_4">L total = L f c rle + ?L dec rle ,<label>(4)</label></formula><p>where ? is a constant and used to balance the two losses. We set ? = 1 by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inference</head><p>Inference pipeline. During the inference stage, Poseur predicts the (? q ,b q ) for each keypoint as mentioned;? q is taken as the predicted keypoint coordinates andb q is used to calculate the keypoint confidence score. Prediction uncertainty estimation. For heatmap-based methods, e.g. Sim-pleBaseline <ref type="bibr" target="#b35">[36]</ref>, the prediction score of each keypoint is combined with a bounding box score to enhance the final human instance score:</p><formula xml:id="formula_5">s inst = s bbox k i=1 s kp i K ,<label>(5)</label></formula><p>where s inst is the final prediction score of the instance; s bbox is the bounding box score predicted by the person detector, s kp i is the i-th keypoint score predicted by the keypoint detector and K is the total keypoint number of each human. Most previous regression-based methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref> ignore the importance of the keypoint score. As a result, compared to heatmap based methods, regression methods typically achieve higher recall but lower precision. Given the same well-trained Poseur model, adding the keypoint score brings 4.7 AP improvement (74.7 AP vs. 70.0 AP) due to the significantly reduced number of false positives, and both of the models achieve almost the same average recall (AR).</p><p>Our model predicts a probability distribution over the image coordinates for each human keypoint. We define the i-th keypoint prediction score s kp i to be the probability of the keypoint falling into the region ([? i ? a,? i + a]) near the prediction coordinate? i , i.e.</p><formula xml:id="formula_6">s kp i = ? i +? ? i ?a P ?q,?q (x|I)dx,<label>(6)</label></formula><p>where a is a hyperparameter that controls the size of the ?-adjacent interval, and? i are the coordinates of the corresponding keypoint predicted by Poseur. In practice, running the normalization flow model during the inference stage would add more computational cost. We found that comparable performance can be achieved by shifting and re-scaling the zero-mean Laplace distribution L(x) with query decoder predictions (? q ,b q ). So the probability density function can be rewritten as:</p><formula xml:id="formula_7">P ?q,?q (x|I) ? f (x|? i ,b i ) = 1 2b i exp (? |x ?? i | b i ),<label>(7)</label></formula><p>where? i is the center of the Laplacian distribution and the predicted keypoint coordinates, andb i is the scale parameter predicted by Poseur. Finally, s kp i can be written as:</p><formula xml:id="formula_8">s kp i = ? i +? ? i ?a f (x|? i ,b i )dx = 1 ? exp (? ? b i ).<label>(8)</label></formula><p>Note that the score s kp i on x-axis and y-axis will be calculated separately and then merged by a multiplication operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>Datasets. Our experiments are mainly conducted on COCO2017 Keypoint Detection <ref type="bibr" target="#b32">[33]</ref> benchmark, which contains about 250K person instances with 17 keypoints. We report results on the val set for ablation studies and compare with other state-of-the-art methods on both of the val set and test-dev sets. The Average Precision (AP) based on Object Keypoint Similarity (OKS) is employed as the evaluation metric on COCO dataset. We also conduct experiments on MPII <ref type="bibr">[1]</ref> dataset with Percentage of Correct Keypoint (PCK) as evaluation metric.</p><p>Model settings. Unless specified, ResNet-50 <ref type="bibr" target="#b15">[16]</ref> is used as the backbone in ablation study. The size of input image is 256 ? 192. The weights pre-trained on ImageNet <ref type="bibr" target="#b8">[9]</ref> are used to initialize the ResNet backbone. The rest parts of our network are initialized with random parameters. All the decoder embedding size is set as 256; 3 decoder layers are used by default. Training. All the models are trained with batch size 256 (batch size 128 for HRFormer-B due to the limited GPU memory), and are optimized by AdamW <ref type="bibr" target="#b22">[23]</ref> with a base learning rate of 1?10 ?3 decreased to 1?10 ?4 and 1?10 ?5 at the 255-th epoch and 310-th epoch and ended at the 325-th epoch; ? 1 and ? 2 are set to 0.9 and 0.999, respectively; Weight decay is set to 10 ?4 . Following Deformable DETR [40], the learning rate of the the linear projections for sampling offsets and reference points are multiplied by a factor of 0.1. Following RLE <ref type="bibr" target="#b17">[18]</ref>, we adopt RealNVP <ref type="bibr" target="#b10">[11]</ref> as the flow model. Other settings follow that of mmpose <ref type="bibr" target="#b7">[8]</ref>. For HRNet-W48 and HRFormer-B, cutout <ref type="bibr" target="#b9">[10]</ref> and color jitter augmentation are applied to avoid over-fitting. Inference. Following conventional settings, we use the same person detector as in SimpleBaseline <ref type="bibr" target="#b35">[36]</ref> for COCO evaluation. According to the bounding box generated by the person detector, the single person image patch is cropped out from the original image and resized to a fix resolution, e.g. 256 ? 192. The flow model is removed during the inference. We set a = 0.2 in Eq. (7) by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>Initialization of keypoint queries. We conduct experiments to verify the impact of initialization of keypoint queries. Deformable DETR [40] introduces reference points that represent the location information of object queries. In their paper, reference points are 2-d tensors predicted from the 256-d object queries via a linear projection. We set this configuration as our baseline model. As shown in <ref type="table">Table 1a</ref>, the baseline model achieves 72.3 AP with 3 decoder layers, which is 0.6 AP lower than keypoint queries which initialized from coarse proposal? f . This indicates that coarse proposal? f provide a good initialization for the keypoint queries. Noisy reference points sampling strategy. As mentioned in Sec. 3.1, we apply the noisy reference points sampling strategy during the training. To validate its effectiveness, we perform ablation experiment on COCO, as show in <ref type="table">Table 1b</ref>. The experiment result shows that the noisy reference points sampling strategy can improve the accuracy by 0.6 AP without adding any extra computational cost during inference. Varying the levels of feature map. We explore the impact of feeding different levels of backbone features into the proposed query decoder. As shown in Table 1d, the performance grows consistently with more levels of feature maps, e.g., 73.7 AP, 74.2 AP, 74.4 AP, 74.7 AP for 1, 2, 3, 4 levels of feature maps, respectively. Uncertainty estimation. As mentioned in Sec. 3.3, we redesign the prediction confidence score proposed in <ref type="bibr" target="#b17">[18]</ref>. To study the effectiveness of the proposed score s kp , we compare it with predictions without re-score and predictions with RLE <ref type="table">Table 1</ref>: Ablation of proposed Poseur on COCO val2017 split. "Ours": Using the fully convolutional layer at the end of backbone to regress the coarse proposal? f ; "Noisy Reference Points": applying the noisy reference points sampling strategy in the keypoint encoder; "Res-i": i-th level feature map of ResNet; "N d ": the number of decoder layers  <ref type="table">Table 1e</ref>, the performance grows at the first three layers and saturates at the sixth decoder layer.</p><p>Varying the input size. We conduct experiments to explore the robust of Poseur under different input resolutions. <ref type="table">Table 2b</ref> compares Poseur with Sim-pleBaseline, showing that our method consistently outperforms SimpleBaseline in all input sizes. The results also indicate that heatmap-based method suffers larger performance drop with the low-resolution input. For example, the proposed method outperforms SimpleBaseline by 14.6 AP in 64?64 input resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Extensions: End-to-End Pose Estimation</head><p>Our framework can easily extend to end-to-end human pose estimation, i.e., detecting multi-person poses without the manual crop operation. With Poseur as a plug-and-play scheme, end-to-end top-down keypoint detectors can obtain additional improvement. Here, we take Mask-RCNN as example to show the superiority of our method. The original keypoint head of Mask R-CNN is stacked 8 convolutional layers, followed by a deconv layer and 2? bilinear upscaling, <ref type="table">Table 2</ref>: Comparison with heatmap methods by varying the backbone and the input resolution on the COCO val set. "SimBa": SimpleBaseline <ref type="bibr" target="#b35">[36]</ref>. For (a), the input resolution is 256?192 and the number of decoder layers is 5. For (b), we use ResNet-50 as backbone and the number of decoder layers is 3.   producing an output resolution of 56?56. We replace the deconv layer by an average pooling layer and an FC layer like <ref type="bibr" target="#b17">[18]</ref>. The output of the FC layer is used to produce initial coarse proposal? f . Then coarse proposal? f is feed into the keypoint encoder and query decoder as described in Sec. 3.1. We randomly sample 600 queries per image for training efficiency. Note that we conduct EMSDA on multi-scale backbone feature maps, rather than on ROI features. The output of FC layer and transformer decoder are both supervised with RLE loss <ref type="bibr" target="#b17">[18]</ref>. We perform scale jittering <ref type="bibr" target="#b12">[13]</ref> with random crops during training. We train the entire network for 180,000 iterations, with a batchsize of 32 in total. Other parameters are the same as the Detectron2 <ref type="bibr" target="#b34">[35]</ref>. As shown in <ref type="table" target="#tab_3">Table 3</ref>, Poseur outperforms the heatmap-based Mask R-CNN with ResNet 101 by 1.9 AP. Poseur outperforms the state-of-the-art regression-based method, PointSet Anchor with HRNet-W48 by 3.8 AP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Main Results</head><p>Gains on low-resolution backbone. In this part, we show the great improvement of Poseur on non-HRNet paradigm backbone which encode the input image as low-resolution representation. All models and training settings are tightly aligned. The input resolution of all models is 256 ? 192.</p><p>In <ref type="table">Table 2a</ref>, Poseur with ResNet-50 significantly outperforms SimpleBaseline, and it is even higher than HRNet-W32, while the computational cost is much lower. Apart from that, Poseur with the lightweight backbone MobileNet-V2 can achieve comparable performance with SimpleBaseline using ResNet-50 backbone. In contrast, the performance of the MobileNet-V2 based SimpleBase- line is much worse, 6.0 AP lower than our method with the same backbone. It is worth noting that the computational cost of Poseur with MobileNet-V2 is only about one-ninth that of SimpleBaseline with the same backbone. Comparison with the state-of-the-art methods. We compare the proposed Poseur with state-of-the-art methods on COCO and MPII dataset. Poseur outperforms all regression-based and heatmap-based methods when using the same backbone, and achieves state-of-the-art performance with HRFormer-B backbone, i.e., 79.6 AP on the COCO val set and 78.3 AP on the COCO test-dev set. Poseur with HRFormer-B can even outperform the previous state-of-the-art UDP-Pose (384 ? 288) by 1.1 AP on the COCO val set, when using lower input resolution (256 ? 192). Quantitative results are reported in <ref type="table" target="#tab_5">Table 5</ref> and Sec. 4.3. On the MPII val set, Poseur with HRNet-W32 is 0.4 PCKh higher than heatmapbased method with HRNet-W32. Quantitative results are reported in <ref type="table" target="#tab_4">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have proposed a novel pose estimation framework named Poseur built upon Transformers, which largely improves the performance of the regression-based pose estimation and bypasses the drawbacks of heatmap-based methods such as the non-differentiable post-processing and quantization error. Extensive experiments on the MS-COCO and MPII benchmarks show that Poseur can achieve state-of-the-art performance among both regression-based methods and heatmapbased methods.   <ref type="bibr">[5]</ref> and RLE <ref type="bibr">[3]</ref>, use fully-connected layers as decoder to regress keypoints, while Poseur has a transformer-based decoder. As the number of decoder layers increases, the model parameters increases rapidly, which may limit the deployment of Poseur for real-time applications that run on mobile devices.</p><p>In this section, we explore reducing the parameters of Poseur by sharing weights between different decoder layers. As shown in Tab. 3, the number of parameters of Poseur is significantly reduced, while the performance of Poseur only drops by 0.5 AP. Notably, the number of parameters of the backbone (ResNet-50) is 23.5 M, which means Poseur with weight sharing only introduces 2.7 M parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Computational Cost of EMSDA</head><p>Let us denote the number of queries by K, and denote the number of pixels in the input feature maps {x l } L l=1 as P , and other notations follow our paper. The  Consumption": memory consumption of one image during the training stage complexity of MSDA can be written as O(KC 2 + P C 2 + 5KSC). Since P is much larger than K, C and S (i.e., P = 4080 when the input image resolution is 256 ? 192 and the feature maps from Res2 to Res5 are taken as the input), the computational cost mostly comes from the factor O(P C 2 ). In our design, the EMSDA module significantly reduces the complexity to O(KC 2 +KC 2 +5KSC), where K ? P (17 vs. 4080). As shown in Tab. 4, the performance of EMSDA is almost the same with that of MSDA, while EMSDA significantly reduces the computational cost from 1.25 GFLOPs to 0.44 GFLOPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comparing the Performance of Poseur and RLE</head><p>As shown in Tab. 5, Poseur with ResNet-50 backbone achieves higher performance than RLE with HRNet-w32 backbone (75.4 AP vs. 74.3 AP), and has a faster inference speed than RLE (94 FPS vs. 62 FPS). The memory consumption of Poseur during the training is lower then that of RLE (1386 M vs. 1456 M). Although the memory consumption of Poseur during the testing is sightly higher than that of RLE (86.25 M vs. 68.12 M), the memory consumption of the whole system during the test (human detector and pose estimator) is exactly the same (? 2000 M) for most of methods in Tab.10 of the paper, including both Poseur and RLE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Verifying the Effect of Keypoint Encoder and Query Decoder in Poseur</head><p>Compared to RLE <ref type="bibr">[3]</ref>, the proposed keypoint encoder and query decoder (without uncertainty estimation) can boost the performance by 3.8 AP on COCO <ref type="bibr">[4]</ref>. This ablation study is performed with ResNet-50 <ref type="bibr">[1]</ref>; all the settings are strictly aligned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">The Explanation of the Positional Encoding in Keypoint Encoder</head><p>Positional encoding in the proposed keypoint encoder transforms the coarse proposal? f ? R K?2 from the x-y coordinates to the sine-cosine positional embedding. Denote an element in? f as pos, which is normalized to [0, 2?], The positional encoding function can be written as P E(pos, 2i) = sin(pos/10000 2i/d ); P E(pos, 2i + 1) = cos(pos/10000 2i/d ), where d = 128, 2i and 2i + 1 are the 2i th and (2i + 1) th dimension. In this way, a pair of x-y coordinates is transferred to two positional embeddings representing x and y axis respectively, which are concatenated to be the final encodings? * f ? R K?256 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Robustness to Truncation</head><p>Truncation is very common in real world scenes. We conduct qualitative visualization to show the superiority of our method. As depicted in <ref type="figure">Fig. 1</ref>, heatmapbased Mask R-CNN can only detect the joints inside the predicted boxes, while our method can infer the joints outside the boxes since the queries can attend to the whole input image.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :Fig. 2 :</head><label>12</label><figDesc>Comparing the proposed Poseur against heatmap-based methods with various backbone networks on COCO val. set. Baseline refers to heatmap-based methods. Heatmap-based baseline of MobileNet-V2 and ResNet use the same deconvolutional head as Sim-pleBaseline [36]. Comparison of Poseur and previous regression-based methods. 'GAP' indicates global average pooling. (a) shows the feature misalignment issue. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FFN</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FFN</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :</head><label>3</label><figDesc>The architecture of Poseur. The model directly predicts a sequence of keypoint coordinates in parallel by combining (a) backbone network with (b) keypoint encoder and (c) query decoder. (d) Residual Log-likelihood Estimation<ref type="bibr" target="#b17">[18]</ref>. (e) The proposed uncertainty score for our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>AP on the COCO val set. -Poseur significantly improves the performance of regression-based methods, to the point where it is comparable to the state-of-the-art heatmap-based approaches. For example, it improves on the previously best regression-based method (RLE [18]) by 4.9 AP with the ResNet-50 backbone on the COCO val set and outperforms the previously best heatmap-based method UDP-Pose [27] by 1.0 AP with HRNet-W48 on the COCO test-dev set. -Our proposed framework can be easily extended to an end-to-end pipeline without manual crop operation, for example, we integrate Poseur into Mask R-CNN</figDesc><table><row><cell>For example, with 49% fewer</cell></row><row><cell>FLOPs, ResNet-50 based Poseur outperforms the heatmap-based method</cell></row><row><cell>SimpleBaseline [36] by 5.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison with end-to-end top-down methods on the COCO val set.</figDesc><table><row><cell>Method</cell><cell>Backbone Type AP AP50 AP75</cell></row><row><cell>PRTR [20]</cell><cell>HRNet-W48 Reg. 64.9 87.0 71.7</cell></row><row><cell>Mask R-CNN [15]</cell><cell>ResNet-101 HM. 66.0 86.9 71.5</cell></row><row><cell cols="2">Mask R-CNN + RLE [18] ResNet-101 Reg. 66.7 86.7 72.6</cell></row><row><cell cols="2">PointSet Anchor  ? [34] HRNet-W48 Reg. 67.0 87.3 73.5</cell></row><row><cell cols="2">Mask R-CNN + Poseur ResNet-101 Reg. 68.6 87.5 74.8</cell></row><row><cell cols="2">Mask R-CNN + Poseur HRNet-W48 Reg. 70.1 88.0 76.5</cell></row><row><cell cols="2">Mask R-CNN + Poseur  ? HRNet-W48 Reg. 70.8 87.9 77.0</cell></row></table><note>? denote flipping and multi-sacle test- ing. Reg: regression-based approach; HM: heatmap-based approach</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">Comparisons on MPII</cell></row><row><cell cols="3">validation set (PCKh@0.5).</cell></row><row><cell cols="3">SimBa: SimpleBaseline [36].</cell></row><row><cell cols="3">Reg: regression-base approach;</cell></row><row><cell cols="3">HM: heatmap-based approach</cell></row><row><cell>Method</cell><cell cols="2">Backbone Type Mean</cell></row><row><cell>SimBa. [36]</cell><cell cols="2">ResNet-152 HM. 89.6</cell></row><row><cell>HRNet [27]</cell><cell cols="2">HRNet-W32 HM. 90.1</cell></row><row><cell cols="2">TokenPose [22] L/D24</cell><cell>HM. 90.2</cell></row><row><cell>Integral [29]</cell><cell cols="2">ResNet-101 Reg. 87.3</cell></row><row><cell>PRTR [20]</cell><cell cols="2">HRNet-W32 Reg. 89.5</cell></row><row><cell>Poseur</cell><cell cols="2">HRNet-W32 Reg. 90.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparisons with state-of-the-art methods on the COCO val set. Input size and the GFLOPs are calculated under top-down single person pose estimation setting. Unless specified, the number of decoder layers is set to 6. "3 Dec.": three decoder layers.</figDesc><table><row><cell cols="8">Method Backbone / Type Input Size GFLOPs AP kp AP kp 50 AP kp 75 AP kp M AP kp L</cell></row><row><cell cols="3">Heatmap-based methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SimBa. [36]</cell><cell>ResNet-50</cell><cell>256 ? 192</cell><cell>8.9</cell><cell cols="4">70.4 88.6 78.3 67.1 77.2</cell></row><row><cell>SimBa. [36]</cell><cell>ResNet-152</cell><cell cols="2">256 ? 192 15.7</cell><cell cols="4">72.0 89.3 79.8 68.7 78.9</cell></row><row><cell cols="3">HRNet [27] HRNet-W32 256 ? 192</cell><cell>7.1</cell><cell cols="4">74.4 90.5 81.9 70.8 81.0</cell></row><row><cell cols="4">HRNet [27] HRNet-W48 384 ? 288 32.9</cell><cell cols="4">76.3 90.8 82.9 72.3 83.4</cell></row><row><cell>TransPose [37]</cell><cell>H-A6</cell><cell cols="2">256 ? 192 21.8</cell><cell>75.8 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>TokenPose [22]</cell><cell>S-V2</cell><cell cols="2">256 ? 192 11.6</cell><cell cols="4">73.5 89.4 80.3 69.8 80.5</cell></row><row><cell>TokenPose [22]</cell><cell>B</cell><cell>256 ? 192</cell><cell>5.7</cell><cell cols="4">74.7 89.8 81.4 71.3 81.4</cell></row><row><cell>TokenPose [22]</cell><cell>L/D6</cell><cell>256 ? 192</cell><cell>9.1</cell><cell cols="4">75.4 90.0 81.8 71.8 82.4</cell></row><row><cell>TokenPose [22]</cell><cell>L/D24</cell><cell cols="2">256 ? 192 11.0</cell><cell cols="4">75.8 90.3 82.5 72.3 82.7</cell></row><row><cell cols="3">HRFormer [38] HRFormer-T 256 ? 192</cell><cell>1.3</cell><cell cols="4">70.9 89.0 78.4 67.2 77.8</cell></row><row><cell cols="3">HRFormer [38] HRFormer-S 256 ? 192</cell><cell>2.8</cell><cell cols="4">74.0 90.2 81.2 70.4 80.7</cell></row><row><cell cols="4">HRFormer [38] HRFormer-B 256 ? 192 12.2</cell><cell cols="4">75.6 90.8 82.8 71.7 82.6</cell></row><row><cell cols="4">HRFormer [38] HRFormer-B 384 ? 288 26.8</cell><cell cols="4">77.2 91.0 83.6 73.2 84.2</cell></row><row><cell cols="3">UDP-Pose [17] HRNet-W32 256 ? 192</cell><cell>7.2</cell><cell cols="4">76.8 91.9 83.7 73.1 83.3</cell></row><row><cell cols="4">UDP-Pose [17] HRNet-W48 384 ? 288 33.0</cell><cell cols="4">77.8 92.0 84.3 74.2 84.5</cell></row><row><cell cols="3">Regression-based methods</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PRTR [20]</cell><cell>ResNet-50</cell><cell cols="2">384 ? 288 11.0</cell><cell cols="4">68.2 88.2 75.2 63.2 76.2</cell></row><row><cell cols="4">PRTR [20] HRNet-W32 384 ? 288 21.6</cell><cell cols="4">73.1 89.4 79.8 68.8 80.4</cell></row><row><cell cols="4">PRTR [20] HRNet-W32 512 ? 384 37.8</cell><cell cols="4">73.3 89.2 79.9 69.0 80.9</cell></row><row><cell>RLE [19]</cell><cell>ResNet-50</cell><cell>256 ? 192</cell><cell>4.0</cell><cell cols="3">70.5 88.5 77.4 -</cell><cell>-</cell></row><row><cell cols="3">RLE [19] HRNet-W32 256 ? 192</cell><cell>7.1</cell><cell cols="3">74.3 89.7 80.8 -</cell><cell>-</cell></row><row><cell cols="3">Ours MobileNet-v2 256 ? 192</cell><cell>0.5</cell><cell cols="4">71.9 88.9 78.6 65.2 74.3</cell></row><row><cell>Ours</cell><cell>ResNet-50</cell><cell>256 ? 192</cell><cell>4.6</cell><cell cols="4">75.4 90.5 82.2 68.1 78.6</cell></row><row><cell>Ours</cell><cell>ResNet-152</cell><cell cols="2">256 ? 192 11.9</cell><cell cols="4">76.3 91.1 83.3 69.1 79.5</cell></row><row><cell cols="3">Ours HRNet-W32 256 ? 192</cell><cell>7.4</cell><cell cols="4">76.9 91.0 83.5 70.1 79.7</cell></row><row><cell cols="4">Ours HRNet-W48 384 ? 288 33.6</cell><cell cols="4">78.8 91.6 85.1 72.1 81.8</cell></row><row><cell cols="3">Ours (3 Dec.) HRFormer-T 256 ? 192</cell><cell>1.4</cell><cell cols="4">74.3 90.1 81.4 67.5 76.9</cell></row><row><cell cols="3">Ours (3 Dec.) HRFormer-S 256 ? 192</cell><cell>3.0</cell><cell cols="4">76.6 91.0 83.4 69.8 79.4</cell></row><row><cell cols="4">Ours HRFormer-B 256 ? 192 12.6</cell><cell cols="4">78.9 92.0 85.7 72.3 81.7</cell></row><row><cell cols="4">Ours HRFormer-B 384 ? 288 27.4</cell><cell cols="4">79.6 92.1 85.9 72.9 82.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparison with top-down methods on the COCO test-dev set. The proposed paradigm outpeforms heatmap-based methods in various settings. The input resolution of all methods is 384 ? 288.</figDesc><table><row><cell>Method</cell><cell cols="2">Backbone AP kp AP kp 50 AP kp 75 AP kp M AP kp L</cell></row><row><cell cols="3">Heatmap-based methods</cell></row><row><cell>SimBa  ? [36]</cell><cell cols="2">ResNet-152 73.7 91.9 81.1 70.3 80.0</cell></row><row><cell cols="3">HRNet  ? [27] HRNet-W32 74.9 92.5 82.8 71.3 80.9</cell></row><row><cell cols="3">HRNet  ? [27] HRNet-W48 75.5 92.5 83.3 71.9 81.5</cell></row><row><cell>TokenPose [22]</cell><cell>L/D24</cell><cell>75.9 92.3 83.4 72.2 82.1</cell></row><row><cell cols="3">HRFormer [38] HRFormer-B 76.2 92.7 83.8 72.5 82.3</cell></row><row><cell cols="3">UDP-Pose [17] HRNet-W48 76.5 92.7 84.0 73.0 82.4</cell></row><row><cell cols="3">Regression-based methods</cell></row><row><cell>PRTR [20]</cell><cell cols="2">ResNet-101 68.8 89.9 76.9 64.7 75.8</cell></row><row><cell>PRTR [20]</cell><cell cols="2">HRNet-W32 71.7 90.6 79.6 67.6 78.4</cell></row><row><cell>RLE [19]</cell><cell cols="2">ResNet-152 74.2 91.5 81.9 71.2 79.3</cell></row><row><cell>RLE [19]</cell><cell cols="2">HRNet-W48 75.7 92.3 82.9 72.3 81.3</cell></row><row><cell cols="3">Ours (6 Dec.) HRNet-W48 77.6 92.9 85.0 74.4 82.7</cell></row><row><cell cols="3">Ours (6 Dec.) HRFormer-B 78.3 93.5 85.9 75.2 83.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>40. Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable DETR: Deformable Transformers for end-to-end object detection. In: Proc. Int. Conf. Learn. Representations (2021)</figDesc><table><row><cell>Ground Truth</cell><cell>Mask R-CNN</cell><cell>Ours</cell></row><row><cell cols="3">Fig. 1: Qualitative comparison</cell><cell>Fig. 2: Visualization of the self-</cell></row><row><cell cols="3">on truncations. Heatmap-based</cell><cell>attention weights between keypoint</cell></row><row><cell cols="3">methods (e.g.Mask R-CNN) can</cell><cell>queries for left shoulder. Dots repre-</cell></row><row><cell cols="3">only predict keypoints within</cell><cell>sent the keypoints. Lines depict atten-</cell></row><row><cell cols="3">the bounding box, while Poseur</cell><cell>tion weights between different joints.</cell></row><row><cell cols="3">can predict keypoints outside the</cell><cell>Thicker line indicates larger attention</cell></row><row><cell>bounding box</cell><cell></cell><cell></cell><cell>weight</cell></row><row><cell></cell><cell cols="3">Self-Attn. AP kp AP kp 50 AP kp 75 AP kp M AP kp L</cell></row><row><cell></cell><cell>?</cell><cell cols="2">74.0 90.2 80.9 66.8 77.2 75.5 90.7 82.7 68.7 78.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 2 :Table 3 :</head><label>23</label><figDesc>The effect of self-attention module on the COCO val set Share weight Param. AP kp AP kp 50 AP kp 75 AP kp M AP kp L 32.3M 75.5 90.7 82.7 68.7 78.3 ? 26.2M 75.0 90.3 81.9 68.0 77.7 The parameter reduction technique on the COCO val set 3 Reducing the Number of Parameters Former works, e.g. Deeppose</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>type GFLOPs (Dec.) AP kp AP kp 50 AP kp 75 AP kp M AP kp L MSDA 1.25 73.6 89.8 80.6 66.6 75.5 EMSDA 0.44 73.6 89.6 80.1 66.7 75.4 Comparison between EMSDA and MSDA on the COCO val set. "GFLOPs (Dec.)": computatuional cost of the decoder Method backbone GFLOPs FPS Mem. Consumption AP kp</figDesc><table><row><cell cols="2">RLE HRNet-w32</cell><cell>7.1</cell><cell>62</cell><cell>1456M</cell><cell>74.3</cell></row><row><cell>Poseur</cell><cell>R-50</cell><cell>4.6</cell><cell>94</cell><cell>1386M</cell><cell>75.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Comparison between RLE and Poseur on the COCO val set. "Mem.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Moreover, We also visualize the self-attention weights across queries in <ref type="figure">Fig. 2</ref>. The left shoulder query attends to the most relevant keypoints, including left elbow, left wrist and left ear.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">2d human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3686" to="3693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning delicate local representations for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="455" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Openpose: realtime multiperson 2d pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="172" to="186" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Endto-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Human pose estimation with iterative error feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4733" to="4742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7103" to="7112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Higherhrnet: Scaleaware representation learning for bottom-up human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5386" to="5395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Openmmlab pose estimation toolbox and benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Contributors</surname></persName>
		</author>
		<ptr target="https://github.com/open-mmlab/mmpose" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<title level="m">Improved regularization of convolutional neural networks with cutout. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Density estimation using real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Representations</title>
		<meeting>Int. Conf. Learn. Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simple copy-paste is a strong data augmentation method for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2918" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Removing the bias of integral pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11067" to="11076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The devil is in the details: Delving into unbiased data processing for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5700" to="5709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Human pose regression with residual log-likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Human pose regression with residual log-likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pose recognition with cascade transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1944" to="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<title level="m">Rethinking on multi-stage networks for human pose estimation. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">TokenPose: Learning keypoint tokens for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Representations</title>
		<meeting>Int. Conf. Learn. Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Rethinking the heatmap regression for bottom-up human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15175</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Single-stage multi-person pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6951" to="6960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Compositional human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2602" to="2611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="529" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Directpose: Direct end-to-end multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deeppose: Human pose estimation via deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst</title>
		<meeting>Advances in Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mscoco keypoints challenge 2018</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Point-set anchors for object detection, instance segmentation and pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simple baselines for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="466" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">TransPose: Keypoint localization via Transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">HRFormer: High-resolution transformer for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst</title>
		<meeting>Advances in Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distribution-aware coordinate representation for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Human pose regression with residual log-likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Human pose regression with residual log-likelihood estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deeppose: Human pose estimation via deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
