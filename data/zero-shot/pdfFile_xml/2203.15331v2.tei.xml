<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Gavrikov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IMLA</orgName>
								<orgName type="institution" key="instit2">Offenburg University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janis</forename><surname>Keuper</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IMLA</orgName>
								<orgName type="institution" key="instit2">Offenburg University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">CC-HPC</orgName>
								<orgName type="institution">Fraunhofer ITWM</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Fraunhofer Research Center ML</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Data &amp; Project website: https://github.com/ paulgavrikov/cnn-filter-db</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Currently, many theoretical as well as practically relevant questions towards the transferability and robustness of Convolutional Neural Networks (CNNs) remain unsolved. While ongoing research efforts are engaging these problems from various angles, in most computer vision related cases these approaches can be generalized to investigations of the effects of distribution shifts in image data. In this context, we propose to study the shifts in the learned weights of trained CNN models. Here we focus on the properties of the distributions of dominantly used 3 ? 3 convolution filter kernels. We collected and publicly provide a dataset with over 1.4 billion filters from hundreds of trained CNNs, using a wide range of datasets, architectures, and vision tasks. In a first use case of the proposed dataset, we can show highly relevant properties of many publicly available pre-trained models for practical applications: I) We analyze distribution shifts (or the lack thereof) between trained filters along different axes of meta-parameters, like visual category of the dataset, task, architecture, or layer depth. Based on these results, we conclude that model pre-training can succeed on arbitrary datasets if they meet size and variance conditions. II) We show that many pre-trained models contain degenerated filters which make them less robust and less suitable for fine-tuning on target applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Despite their overwhelming success in the application to various vision tasks, the practical deployment of convolutional neural networks (CNNs) is still suffering from several inherent drawbacks. Two prominent examples are I) the dependence on very large amounts of annotated training data <ref type="bibr" target="#b0">[1]</ref>, which is not available for all target domains * Funded by the Ministry for Science, Research and Arts, Baden-Wuerttemberg, Grant 32-7545.20/45/1 (Q-AMeLiA). The authors also thank Margret Keuper for her support and encouragement to submit this work. and is expensive to generate; and II) still widely unsolved problems with the robustness and generalization abilities of CNNs <ref type="bibr" target="#b1">[2]</ref> towards shifts of the input data distributions. One can argue that both problems are strongly related, since a common practical solution to I) is the fine-tuning <ref type="bibr" target="#b2">[3]</ref> of pre-trained models by small datasets from the actual target domain. This results in the challenge to find suitable pre-trained models based on data distributions that are "as close as possible" to the target distributions. Hence, both cases (I+II) imply the need to model and observe distribution shifts in the contexts of CNNs. In this paper, we propose not to investigate these shifts in the input (image) domain, but rather in the 2D filter-kernel distributions of the CNNs themselves. We argue that e.g. the distributions of trained convolutional filters in a CNN, which implicitly reflect the sub-distributions of the input image data, are more suitable and easier accessible representations for this task. In order to foster systematic investigations of learned filters, we collected and publicly provide a dataset of over 1.4 billion filters with meta data from hundreds of trained CNNs, using a wide range of data sets, architectures, and vision tasks. To show the scientific value of this new data source, we conduct a first analysis and report a series of novel insights into widely used CNN models. Based on our presented methods we show that many publicly provided models suffer from degeneration. We show that overparameterization leads to sparse and/or nondiverse filters <ref type="figure" target="#fig_0">(Fig. 1)</ref>, while robust training increases filter diversity, and reduces sparsity. Our results also show that learned filters do not significantly differ across models trained for various tasks, except for extreme outliers such as GAN-Discriminators. Models trained on datasets of different visual categories do not significantly drift either. Most shifts in studied models are due to degeneration, rather than an actual difference in structure. Therefore, our results imply that pre-training can be performed independent of the actual target data, and only the amount of training data and its diversity matters. This is inline with recent findings that models can be pre-trained even with images of fractals <ref type="bibr" target="#b3">[4]</ref>. For classification models we show that the most variance in learned filters is found in the beginning and end of the model, while object/face detection models only show significant variance in early layers. Also, the most specialized filters are found in the last layers. We summarize our key contributions as follows:</p><p>? Publication of a diverse database of over 1.4B 3 ? 3 convolution filters alongside with relevant meta information of the extracted filters and models <ref type="bibr" target="#b4">[5]</ref>. ? Presentation of a data-agnostic method based on sparsity and entropy of filters to find "degenerated" convolution layers due to overparameterization or non-convergence of trained CNN models. ? Showing that publicly available models often contain degenerated layers and can therefore be questionable candidates for transfer tasks. ? Analysis of distribution shifts in filters over various groups, providing insights that formed filters are fairly similar across a wide-range of examined groups. ? Showing that the model-to-model shifts that exist in classification models are, contrary to the predominant opinion, not only seen in deeper layers but also in the first layers.</p><p>Paper organization. We give an overview of our dataset and its collection process in Sec. 3, followed by an introduction of methods studying filter structure, distributions shifts, and layer degeneration such as randomness, low variance in filter structure, and high sparsity of filters. Then in Sec. <ref type="bibr" target="#b3">4</ref> we apply these methods to our collected data. We show the impact of overparameterization and robust training on filter degeneration and provide intuitions for threshold finding. Then we analyze filter structures by determining a suitable filter basis and looking into reproducibility of filters in training, filter formation during training, and an analysis of distribution shifts for various dimensions of the collected meta-data. We discuss limitations of our approach in Sec. <ref type="bibr" target="#b4">5</ref> and, finally, draw conclusions in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We are unaware of any systematic, large scale analysis of learned filters across a wide range of datasets, architectures and task such as the one performed in this paper. However, there are of course several partially overlapping aspects of our analysis that have been covered in related works: Filter analysis. An extensive analysis of features, connections, and their organization extracted from trained Incep-tionV1 <ref type="bibr" target="#b5">[6]</ref> models was presented in <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr">[15]</ref>. The authors claim different CNNs will form similar features and circuits even when trained for different tasks.</p><p>Transfer learning. A survey on transfer learning for image classification CNNs can be found in <ref type="bibr">[16]</ref> and general surveys for other tasks and domains are available in <ref type="bibr">[17,</ref><ref type="bibr">18]</ref>. The authors of [19] studied learned filter representations in ImageNet1k classification models and presented the first approaches towards transfer learning. They argued that different CNNs will form similar filters in early layers which will mostly resemble gabor-filters and color-blobs, while deeper layers will capture specifics of the dataset by forming increasingly specialized filters.</p><p>[20] captured convolution filter pattern distributions with Gaussian Mixture Models to achieve cross-architecture transfer learning.</p><p>[21] demonstrated that convolutions filters can be replaced by a fixed filter basis that 1 ? 1 convolution layers blend.</p><p>Pruning criteria. Although we do not attempt pruning, our work overlaps with pruning techniques as they commonly rely on estimation criteria to understand which parameters to compress. These either rely on data-driven computation of a forward-pass <ref type="bibr">[22]</ref><ref type="bibr">[23]</ref><ref type="bibr">[24]</ref><ref type="bibr">[25]</ref><ref type="bibr">[26]</ref>, or backward-propagation <ref type="bibr" target="#b13">[27,</ref><ref type="bibr" target="#b14">28]</ref>, or estimate importance solely based on the numerical weight (typically any ?-norm) of the parameters <ref type="bibr" target="#b15">[29]</ref><ref type="bibr" target="#b16">[30]</ref><ref type="bibr" target="#b17">[31]</ref><ref type="bibr" target="#b18">[32]</ref><ref type="bibr" target="#b19">[33]</ref>. CNN distribution shifts. A benchmark for distribution shifts that arise in real-world applications is provided in <ref type="bibr" target="#b20">[34]</ref> and <ref type="bibr" target="#b21">[35]</ref> measured robustness to natural distribution shifts of 204 ImageNet1k models. The authors concluded that robustness to real-world shifts is low. Lastly, <ref type="bibr" target="#b22">[36]</ref> studied the correlation between transfer performance and distribution shifts of image classification models and find that increasing training set and model capacity increases robustness to distribution shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Collecting filters</head><p>We collected a total of 647 publicly available CNN models from <ref type="bibr" target="#b23">[37]</ref><ref type="bibr" target="#b24">[38]</ref><ref type="bibr" target="#b25">[39]</ref> and other sources that have been pre-trained for various 2D visual tasks <ref type="bibr" target="#b0">1</ref> . In order to provide a heterogeneous and diverse representation of convolution filters "in the wild", we retrieved pre-trained models for 11 different tasks e.g. such as classification, segmentation and image generation. We also recorded various metadata such as depth and frequency of included operations for each model, and manually categorized the variety of used training sets into 16 visually distinctive groups like natural scenes, medical ct, seismic, or astronomy. In total, the models were trained on 71 different datasets. The dominant subset is formed by image classification models trained on ImageNet1k <ref type="bibr" target="#b26">[40]</ref> (355 models). All models were trained with full 32-bit precision <ref type="bibr" target="#b1">2</ref> but may have been trained on variously scaled input data. Included in the dataset are low-resolution variants of AlexNet <ref type="bibr" target="#b28">[42]</ref>, DenseNet-121/161/169 <ref type="bibr" target="#b30">[43]</ref>, ResNet-9/14/18/34/50/101/152 <ref type="bibr" target="#b31">[44]</ref>, VGG-11/13/16/19 <ref type="bibr" target="#b32">[45]</ref>, Mo-bileNet v2 <ref type="bibr" target="#b33">[46]</ref>, Inception v3 <ref type="bibr" target="#b34">[47]</ref> and GoogLeNet <ref type="bibr" target="#b5">[6]</ref> image classification models that we have purposely trained on simple datasets such as CIFAR-10/100 <ref type="bibr" target="#b35">[48]</ref>, MNIST <ref type="bibr" target="#b36">[49]</ref>, Kuzushiji-MNIST (KMNIST) <ref type="bibr" target="#b37">[50]</ref> and Fashion-MNIST <ref type="bibr" target="#b38">[51]</ref> in order to study the effect of overparameterization on learned filters. All collected models were converted into the ONNX format <ref type="bibr" target="#b39">[52]</ref> which allows a streamlined filter extraction without framework dependencies. Hereby, only the widely used filters from regular convolution layers with a kernel size of 3 ? 3 were taken into account. Transposed (sometimes also called de-convolution or up-convolution) convolution layers were not included. In total, 1,464,797,156 filters from 21,436 layers have been obtained for our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Analyzing filter structures</head><p>We apply a full-rank principal component analysis (PCA) transformation implemented via a singular-value decomposition (SVD) to understand the underlying structure of the filters <ref type="bibr" target="#b40">[53]</ref>. First, we stack the relevant set of n flattened filters into a n? 9 matrix X. Thereupon, we center the matrix and perform a SVD into a n ? 9 rotation matrix U , a 9?9 diagonal scaling matrix ?, and a 9 ? 9 rotation matrix V T . The diagonal entries ? i , i = 0, . . . , n ? 1 of ? form the singular values in decreasing order of their magnitude. Row vectors v i , i = 0, . . . , n ? 1 in V T then form the principal components. Every row vector c ij , j = 0, . . . , n?1 in U is the coefficient vector for f i .</p><formula xml:id="formula_0">X * = X ?X = U ?V T<label>(1)</label></formula><p>WhereX denotes the vector of column-wise mean values of any matrix X. Then we obtain a vector? of the explained <ref type="bibr" target="#b0">1</ref> For more details refer to the supplementary materials. <ref type="bibr" target="#b1">2</ref> Although, initial experiments indicated that mixed/reduced precision training <ref type="bibr" target="#b27">[41]</ref> does not affect distribution shifts beyond noise. variance ratio of each principal component. ? ? ? 1 denotes the ? 1 -norm. ? a = (? ? I) 2 /(n ? 1) a = ? a/?? a? <ref type="bibr" target="#b0">1</ref> (2)</p><p>Finally, each filter f ? is described by a linear, shifted sum of principal components v i weighted by the coefficients c i .</p><formula xml:id="formula_1">f ? = i c i v i +X i (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Measuring distribution shifts</head><p>All probability distributions are represented by histograms. The histogram range is defined by the minimum and maximum value of all coefficients. Each histogram is divided into 70 uniform bins. The divergence between two distributions is measured by the symmetric, non-negative variant of Kullback-Leibler (KL sym ) <ref type="bibr" target="#b41">[54]</ref>.</p><formula xml:id="formula_2">KL(P ? Q) = x?X P (x) log P (x) Q(x) KL sym (P ? Q) = KL(P ? Q) + KL(Q ? P )<label>(4)</label></formula><p>We define the drift D between two filter sets by the sum of the divergence of the coefficient distributions P i , Q i along every principal component index i. The sum is weighted by the ratio of variance? i explained by the i-th principal component.</p><formula xml:id="formula_3">D(P ? Q) = i? i ? KL sym (P i ? Q i )<label>(5)</label></formula><p>To avoid undefined expressions, all probability distributions F are set to hold ?x ? X : F (x) ? ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Measuring layer degeneration</head><p>Lottery Ticket Hypothesis <ref type="bibr" target="#b42">[55]</ref> suggests that each architecture has a specific amount of convolution filters that saturate its ability to transform a given dataset into a well separable feature-space. Exceeding this number will result in a partitioning of the model into multiple inter-connected submodels. We hypothesize that these are seen in the form of degenerated filters in CNNs. In like manner, an insufficient amount of training samples or training epochs will also lead to degenerated filters. We characterize the following types of degeneration.</p><p>1. High sparsity: Filters are dominantly close to zero and therefore produce quasi-zero feature-maps <ref type="bibr" target="#b15">[29]</ref>. These feature-maps carry no vital information and can be discarded.</p><p>2. Low diversity in structure: Filters are structurally similar to each other and therefore redundant. They produce similar feature-maps in different scales and could be represented by a subset of present filters.  3. Randomness: Filter weights are conditionally independent of their neighbours. This indicates that no or not sufficient training was performed.</p><p>Sparsity degeneration is detectable by the share of sparse filters S in a given layer. We call a filter f sparse if all entries are near-zero. Consequently, given the number of input channels c in , number of output channels c out , and a set of filters in layer L, we can measure the layer sparsity by:</p><formula xml:id="formula_4">S(L) = |{f |f ? L ? (?w ? f : ?? 0 ? w ? ? 0 )}| c in c out<label>(6)</label></formula><p>To detect the other types of degeneration we introduce a layer-wise metric based on the Shannon-Entropy of the explained variance ratio of each principal component obtained from a SVD of all filters in the examined layer (Sec. 3.2).</p><formula xml:id="formula_5">H = ? i? i log 10?i<label>(7)</label></formula><p>If H is close to zero this indicates one strong principal component from which most of the filters can be reconstructed and is therefore a low filter diversity degeneration. On the other hand, a large entropy indicates a (close to) uniform distribution of the singular values and, thus, a randomness of the filters. Sparse layers are a specific form of low diversity degeneration and, generally both are correlated, whereas, sparsity and randomness are mutually exclusive. It should be noted, that |? ? I| = min(c in c out , 9) and therefore the entropy only becomes expressive if c in c out ? 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results: Analysis of trained CNN filters 4.1. Layer degeneration</head><p>In this section we study different causes of degeneration and aim provide thresholds for evaluation.</p><p>Overparameterization. The majority of the models that we have trained on our low resolution datasets are heavily overparameterized for these relatively simple problems. We base this argument on the fact that we have models with different depth for most architectures and already observe near perfect performance with the smallest variants. Therefore it is safe to assume that larger models are overparameterized especially given that the performance only increases marginally <ref type="bibr" target="#b0">1</ref> . First we analyze layer sparsity and entropy for these models trained on CIFAR-10/100 in comparison to all ImageNet1k classification models found in our dataset. For each dataset we have trained identical networks with identical hyperparameters. Both, CIFAR-10 and CIFAR-100, consist of 60,000 32?32px images, but CIFAR-100 includes 10x more labels and thus fewer samples per class forming a more challenging dataset. <ref type="figure" target="#fig_1">Fig. 2a</ref> shows that the overparameterized models contain significantly more sparse filters on average, and that sparsity increases with depth. In particular, we see the most sparse filters for CIFAR-10. However, ImageNet1k classifiers also seem to have some kind of "natural" sparsity, even though we do not consider most of these models as overparameterized. Entropy, on the other hand, decreases with increasing medical mri natural plants textures 2 0 2 c0</p><formula xml:id="formula_6">all 2 0 2 c1 2 0 2 c2 2 0 2 c3 2 0 2 c4 2 0 2 c5 2 0 2 c6 2 0 2 c7</formula><p>2 0 2 c8 <ref type="figure">Figure 3</ref>. KDEs of the coefficient distributions along every principal component for selected 1 visual categories. layer depth for every classifier, but more rapidly in overparameterized models <ref type="figure" target="#fig_1">(Fig. 2b)</ref>. Again, the CIFAR-10 models degrade faster and show more degeneration. The overparameterized models contain layers that have a entropy close to 0 towards deeper layers which indicates that these models are "saturated" and only produce differently scaled variants of the same filters. In line with the oversaturation, these models also have increasingly sparse filters, presumably as an effect of regularization.</p><p>Filter degeneration and model robustness. Our dataset also contains robust models from the RobustBench leaderboard <ref type="bibr" target="#b24">[38]</ref>. When comparing robust models with nonrobust models trained on ImageNet1k, it becomes clear that robust models form almost no sparse filters after in deeper convolution layers ( <ref type="figure" target="#fig_1">Fig. 2c</ref>), while regular models show some sparsity there. The entropy of robust models is also higher throughout depth ( <ref type="figure" target="#fig_1">Fig. 2d</ref>), indicating that robust models learn more diverse filters.</p><p>Thresholds. To obtain a threshold for randomness given a number of filters n per layer we perform multiple experiments in which we initialize convolution filters of different sizes from a standard normal distribution and fit a sigmoid T H to the minimum results obtained for entropy.</p><formula xml:id="formula_7">T H (n) = L 1 + e ?k(log 2 (n)?x0) + b<label>(8)</label></formula><p>We obtain the following values L = 1.26, x 0 = 2.30, k = 0.89, b = ?0.31 and call any layer L with H &gt; T H (n) random. On the opposite, defining a threshold for low diversity degeneration seems less intuitive and one can only rely on statistics: The average entropy H is 0.69 over all layers and continuously decreases from an average of 0.75 to 0.5 with depth. Additionally, the minimum of the 1.5 IQR also steadily decreases with depth. The same applies to sparsity: the average sparsity S over all layers is 0.12 and only 56.5% of the layers in our dataset hold S &lt; 0.01 and 9.9% even show S &gt; 0.5. In terms of convolution depth, the average sparsity varies between 9.9% and 14% with the largest sparsity found in the last 20% of the model depth. The largest outliers of the 1.5 interquartile range (IQR) are, however, found in the first decile. In both cases we find it difficult to provide a meaningful general threshold and suggest to determine this value on a case-by-case basis 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Filter structure</head><p>In the next series of experiments, we analyze only the structure of 3?3 filters, neglecting their actual numerical weight in the trained models. Therefore, we normalize each filter f individually by the absolute maximum weight into f ? .</p><formula xml:id="formula_8">d i = max i,j |f ij | f ? ij = f ij /d i , if d i ? = 0 f ij ,<label>else (9)</label></formula><p>Then we perform a PCA transformation on the scaled filters. <ref type="figure" target="#fig_5">Fig. 5</ref> shows some qualitative examples of obtained principal components, split by several meta-data dimensions. The images of the formed basis are often similar for all groups except for few outliers (such as GANdiscriminators). The explained variance however fluctuates significantly and sometimes changes the order of components. Consistently, we observe substantially higher variance on the first principal components. The explained variance does not necessarily correlate with the shift observed between models. Here, the biggest mean drift is also located in the first principal component (D = 0.90), but is then followed by the sixth, third, second component (D = 0.78, 0.69, 0.58). The coefficients of the sixth component also contain the strongest outliers ( <ref type="figure" target="#fig_6">Fig. 6</ref>). We visualize the distributions of PCA coefficients along every component for each group by plots of kernel density estimates (KDEs), e.g. <ref type="figure">Fig. 3</ref> depicts the distributions of filters grouped by some selected visual categories in comparison to the distribution of coefficients for the full dataset. Filters extracted from models with degenerated layers (as seen in medical mri) result in spiky/multi-modal KDEs. The distributions can alternatively be visualized by bi-variate scatter plots that may reveal more details than KDEs. For example, they let us  categorize the distributions into phenotypes depending on their distribution characteristic in the PCA space ( <ref type="figure" target="#fig_3">Fig. 4)</ref>: sun: distributions where both dimensions are gaussian-like. These are to be expected coefficient distributions without significant sparsity/low diversity degeneration. Yet, this phenotype may also include non-converged filters; spikes: distributions suffering from a low variance degeneration resulting in local hotspots; symbols: at least one distribution is multi-modal, non-centered, highly sparse or otherwise nonnormal (low variance degeneration); point: coefficients are primarily located in the center (sparsity degeneration).</p><p>Reproducibility of filters. We train low-resolution networks on CIFAR-10 multiple times with identical hyperparameters except for random seeds and save a checkpoints of each model at the best validation epoch. Most models are converging to highly similar coefficient distributions when retrained with different weight initialization (e.g. ResNet-9 with D &lt; 5.3 ? 10 ?4 ). However, some architectures such as MobileNetv2 show higher shifts (D &lt; 2.6 ? 10 ?2 ). We assume that this is due to the structure of the loss surface, e.g. the residual skip connections found in ResNets smooth the surface, whereas other networks way contain more local minima due to noisy surfaces <ref type="bibr" target="#b43">[56]</ref>.</p><p>Formation of filter structures during training. Although our dataset only includes trained convolutional filters we tried to understand how the coefficient distribution shifts during training. Therefore we recorded checkpoints of a ResNet-9 trained on CIFAR-10 every 10 training epochs beginning right after the weight initialization. <ref type="figure" target="#fig_7">Fig. 7</ref> shows that the coefficient distributions along all principal components are gaussian-like distributed in the beginning and eventually shift during training. For this specific model, distributions along major principal components retain the standard deviation during training, while less-significant component distributions decrease. The initialization observation helped us removing models from our collection where we failed to load the trained parameters for any reason and is foundation for our provided randomness metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Distribution shifts between trained models</head><p>In this subsection we are investigating transfer distance in different meta-dimensions of pre-trained models. We compute the shift D and visualize this is the form of heatmaps ( <ref type="figure" target="#fig_8">Fig. 8</ref>) that show shifts between all pairings.</p><p>Shifts between tasks. Unsurprisingly, classification, segmentation, object detection, and GAN-generator distributions are quite similar, since the non-classification models typically include a classification backbone. The smallest mean shift to other tasks is observed in object detection, GAN-generators, and depth estimation models. The least transferable distributions are GAN-discriminators. Their distributions do barely differ along principal components and can be approximated by a gaussian distribution. By our randomness metric this indicates a filter distribution that is close to random initialization, implying a "confused" discriminator that cannot distinguish between real and fake samples towards the end of (successful) training. It may be surprising to see a slightly larger average shift for classification. This is presumably due to many degenerated layers in our collected models, which are also visible in the form of spikes when studying the KDEs. An evaluation 1 of distributions including only non-degenerated classifiers actually shows a lower average shift due to the aforementioned similarity to other tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shifts between visual categories and training sets.</head><p>We find that the distribution shift is well balanced across most visual categories and training sets. Notable outliers include all medical types. They have visible spikes in the KDEs, once again indicating degenerated layers. Indeed, the average sparsity in these models is extreme in the last 80% of the model depth. Another interesting, albeit less significant outlier is the fractal category. It consists of models trained on Fractal-DB, which was proposed as a synthetic pre-training alternative to ImageNet1k <ref type="bibr" target="#b3">[4]</ref>. The standard deviations of coefficient distributions tend to shrink towards the least significant principal components but this trend is not visible for this category indicating that sorting the basis by variance would yield a different order for this task and perhaps the basis itself is not well suited. Also notable is a remarkably high standard deviation on the distribution of the first principal component. Interestingly, we also observe sub-average degeneration for this category. Shifts in other categories can usually be explained by a biased representation. For example we only have one model for plants, our handwriting models consist exclusively of overparameterized networks that suffer from layer degeneration, and textures consists of only one GAN-discriminator which will naturally shows a high randomness.</p><p>Shifts by filter/layer depth. The shift between layers of    various depth deciles increases with the difference in depth, with distributions in the last decile of depth forming the most distinct interval, and outdistancing the second-to-last and first decile that follow next. An interesting aspect is also the model-to-model shift across deciles. This shift exemplifies the uniqueness of formed filters. Our observations overhaul the general recommendation for fine-tuning to freeze early layers in classification models, as the largest shifts are not only seen in deep layers but also in early vision ( <ref type="figure" target="#fig_9">Fig. 9</ref>). Segmentation 1 models show the most drift in deeper layers. Contrary, object/face detection models only show drift in the early vision (object detection in the first, face detection in the first four depth deciles), but marginal drift in later convolution stages.</p><p>Shifts within model families. The shift between models of the same family trained for the same task is negligible ( <ref type="figure" target="#fig_0">Fig. 10</ref>), indicating that every large enough dataset is good enough and the common practice of pre-training models with ImageNet1k even for visually distant application domains is indeed a valid approach. ResNet-family outliers only consist out of models that show a high amount of sparsity. Additionally, this observation may be exploited by training small teacher networks and apply knowledge distillation <ref type="bibr" target="#b44">[57]</ref> to initialize deeper models of the same family.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>Our data is biased against classification models and/or natural datasets such as ImageNet1k. Further, some splits will over-represent specific dimensions e.g. tasks may include exclusive visual categories and vice versa. Also, as previously shown, many of the collected models show a large amount of degenerated layers that impact the distributions. This also biases measurements of the distribution shifts. We performed an ablation study by removing filters extracted from degenerated layers, but were unable to find a clear correlation between degeneration and distribution shifts 1 , presumably due to a lack of justified thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Our first results support our initial hypothesis that the distributions of trained convolutional filters are a suitable and Object Detection <ref type="formula" target="#formula_0">(16)</ref> GAN-Generator <ref type="formula" target="#formula_2">(24)</ref> Depth Estimation <ref type="formula">(2)</ref> Style Transfer <ref type="formula" target="#formula_3">(5)</ref> Super Resolution (4) Panoptic Segmentation <ref type="formula">(2)</ref> Sematic Segmentation (15) Classification (555) Segmentation <ref type="formula" target="#formula_0">(11)</ref> Face Recognition <ref type="formula" target="#formula_0">(1)</ref> Auto-Encoder <ref type="formula" target="#formula_0">(1)</ref> Face Detection (4) GAN-Discriminator <ref type="formula" target="#formula_5">(7)</ref> Object Detection (16) GAN-Generator (24) Depth Estimation <ref type="formula">(2)</ref> Style Transfer (5) Super Resolution (4) Panoptic Segmentation (2) Sematic Segmentation (15) Classification (555) Segmentation (11) Face Recognition <ref type="formula" target="#formula_0">(1)</ref> Auto-Encoder (1) Face Detection (4) GAN-Discriminator <ref type="formula" target="#formula_5">(7)</ref> faces <ref type="formula" target="#formula_0">(16)</ref> depth <ref type="formula">(2)</ref> natural <ref type="formula" target="#formula_3">(557)</ref> map <ref type="formula">(2)</ref> thermal <ref type="formula" target="#formula_0">(1)</ref> astronomy <ref type="formula">(2)</ref> art <ref type="formula" target="#formula_3">(5)</ref> seismic <ref type="formula" target="#formula_2">(4)</ref> cars <ref type="formula" target="#formula_0">(1)</ref> medical ct <ref type="formula" target="#formula_2">(4)</ref> fractals <ref type="formula">(2)</ref> textures <ref type="formula">(2)</ref> medical xray (9) medical mri <ref type="formula">(3)</ref> plants <ref type="formula" target="#formula_0">(1)</ref> faces (16) depth (2) natural (557) map (2) thermal (1) astronomy <ref type="bibr" target="#b1">(2)</ref> art <ref type="formula" target="#formula_3">(5)</ref> seismic <ref type="formula" target="#formula_2">(4)</ref> cars (1) medical ct <ref type="bibr" target="#b3">(4)</ref> fractals <ref type="formula">(2)</ref> textures (2) medical xray (9) medical mri <ref type="formula">(3)</ref> plants <ref type="formula" target="#formula_0">(1)</ref> [0.0, 0.   easy-to-access proxy for the investigation of image distributions in the context of transferring pre-trained models and robustness. While the presented results are still in the early stages of a thorough study, we report several interesting findings that could be explored to obtain better model generalizations and assist in finding suitable pre-trained models for fine-tuning. One finding is the presence of large amounts of degenerated (or untrained) filters in large, wellperforming networks -resulting in the phenotypes points, spikes, and symbols. We assume that their existence is a symptom in line with the Lottery Ticket Hypothesis <ref type="bibr" target="#b42">[55]</ref>.</p><p>We conclude that ideal models should have relatively high entropy (but H &lt; T H ) throughout all layers and almost no sparse filters. Models that show an increasing or generally high sparsity or a massive surge in entropy with depth are most likely overparameterized and could be pruned, which would benefit inference and training speed. Whereas, initialized but not trained models will have a constantly high entropy H ? T H throughout all layers and virtually no sparsity.</p><p>Another striking finding is the observation of very low shifts in filter structure between different meta-groups: I) shifts inside a family of architectures are very low; II) shifts are mostly independent of the target image distribution and task; III) also we observe rather small shifts between convolution layers of different depths with the highest shifts in the first and last layers. Overall, the analysis of over 1.4 billion learned convolutional filters in the provided dataset gives a strong indication that the common practice of pretraining CNNs is indeed a sufficient approach if the chosen model is not heavily overparameterized. Our first results indicate that the presented dataset is a rich source for further research in transfer learning, robustness and pruning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset details</head><p>We provide CNN Filter DB as a ca. 100 GB large HDF5 file which contains the unprocessed 3 ? 3 filters along with meta information as reported in Tab. 3.</p><p>We have collected models of the following tasks: Classification, GAN-Generator, Segmentation, Object Detection, Style Transfer, Depth Estimation, Face Detection, Super Resolution, GAN-Discriminator, Face Recognition, Auto-Encoder. The training sets were distributed into the following categories: plants, natural, art, map, handwriting, medical ct, medical mri, depth, faces, textures, fractals, seismic, astronomy, thermal, medical xray, cars.</p><p>A visualization of the accumulated frequency of models and filters by task, visual category, and training dataset combination can be found in <ref type="figure" target="#fig_1">Fig. 27</ref>. Heatmaps for aggregated frequency of filters/models by task and visual category are shown in <ref type="figure" target="#fig_0">Fig. 11</ref>.</p><p>As previously mentioned, we used rescaled filters for all distribution shift related experiments. In <ref type="figure" target="#fig_0">Fig. 12</ref> we show the mean scale per layer depth decile of the unprocessed filters. We group the filters f by model and depth decile in sets S and compute the mean scale as follows:</p><formula xml:id="formula_9">scale = f ?S max ij f ij ? min ij f ij |S|<label>(10)</label></formula><p>The distributions show an unsurprising decrease with depth but also a high variance and many outliers across models, especially in the first two deciles.</p><p>Lastly, Tab. 4 contains all models we have used for our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Derivation of randomness threshold</head><p>We draw n = 2 1 , . . . , 2 21 filters with 3 ? 3 shape from a standard normal distribution and calculate the entropy H as defined in the Methods section. We repeat this process 1000 times for each n and fit a sigmoid to the lowest entropy we have observed for each n. <ref type="figure" target="#fig_0">Fig. 13</ref> shows the obtained samples alongside the fitted sigmoid T H .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation study: Degeneration impact</head><p>As mentioned in the Limitations section, we attempted to reproduce our experiments with a dataset that did not include filters from degenerated layers. We applied the following selection criterion to detect degeneration based on entropy H and sparsity S as defined in our Methods section:</p><formula xml:id="formula_10">(H ? T H ? 0.02) ? (H &lt; 0.5) ? (S ? 0.14)<label>(11)</label></formula><p>While we had a solid foundation for the entropy upper bound (minus some noise), the lower bound for entropy and the bound for sparsity are based on the average we found in our datasets. Note that increasing the lower bound for H results in more similar distributions and therefore lower shift. Hence, this value should be picked very carefully to not filter out vital layers. Sparsity is usually seen in peaks around the center of the KDEs. Tuning this value has a significant impact on the shift <ref type="figure" target="#fig_0">(Fig. 16</ref>) since the large center peaks increase the KL-Divergence significantly <ref type="figure" target="#fig_0">(Fig. 14)</ref>. With the selected threshold we fail to find a meaningful correlation between the ratio of degenerated layers and the average shift to other groups (i.e. tasks or visual categories; <ref type="figure" target="#fig_0">Fig. 15</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Distribution shift by precision</head><p>We initially assumed that quantization may lead to the spikes phenotype, so we decided to test what shift we obtain when training with fp16 instead of fp32 precision. Spiky distributions should show high shifts in comparison to smooth distributions. We train all our low resolution models on CIFAR-10 with the same hyperparameters and observe marginal shifts <ref type="figure" target="#fig_0">Fig. 17</ref>. Outliers with somewhat higher shifts include MobileNet v2. But we have verified that the shift for MobileNet v2 does not exceed the shift one would measure by retraining with random seeds. The ResNet-9 shift does not exceed its retraining shift, therefore we assume that this also applies to other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Distribution shift by convolution depth</head><p>In addition to the main paper we also report the shift by absolute depth for the first 20 layers in <ref type="figure" target="#fig_0">Fig. 18</ref> of classification models and the shift by relative depth for more tasks in <ref type="figure" target="#fig_0">Fig. 19</ref>. Please note, that <ref type="figure" target="#fig_0">Fig. 19e</ref> only contains the same network trained on different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. More principal components</head><p>In <ref type="figure" target="#fig_1">Fig. 20</ref> we add interesting counter-parts to the filter basis shown in the main paper. As one can observe the filter basis remains quite similar. Changes usually affect the order of the components (since they are sorted by explained variance ratio), inversion (though this is not characteristic, since the coefficients can simply be inverted), and noise presumably due to degeneration.      <ref type="figure" target="#fig_1">Fig. 29</ref> shows KDEs for all tasks. <ref type="figure" target="#fig_0">Fig. 31</ref> shows only KDEs of tasks of models that were trained with datasets belonging to the natural visual category. <ref type="figure" target="#fig_27">Fig. 30</ref> shows KDEs for every visual category. Some categories show shifts due to bias representation while other clearly contain a majority of degenerated filters. <ref type="figure" target="#fig_1">Fig. 32</ref> show KDEs by the visual category of  the training dataset limited to classification models. Several categories such as medical xray, plants, handwriting are clearly impacted by degeneration. <ref type="figure" target="#fig_30">Fig. 33</ref> shows KDEs of classification models split by convolution depth decile. The distribution shift with depth reminds us of the shift of all filters we have seen during training ResNet-9 in our Results section. <ref type="figure" target="#fig_5">Fig. 35</ref> shows some selected models from the same family, showing clear shifts between the families but low shifts within. Lastly, <ref type="figure" target="#fig_3">Fig. 34</ref> shows all models trained on MNIST. These are consist exclusively of the intentionally overparameterized models. The KDEs show very clear signs of major degeneration, by stark spikes, especially around null.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. More KDEs plots</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Phenotype scatter plots</head><p>The main paper showed only scatter plots between two select coefficient distributions c i and c j . Here we include the all bi-variate scatter plots of selected examples for each phenotype over all pairs of distributions (i.e. i = 0, . . . , 8 and j = 0, . . . , 8): <ref type="figure" target="#fig_1">Fig. 22</ref> shows the scatter plots over all filters that we have extracted; <ref type="figure" target="#fig_1">Fig. 23</ref> shows spikes of filters that belong to the visual category medical ct; <ref type="figure" target="#fig_1">Fig. 24</ref> shows symbols based on filters that belong to an EfficientNet-l2-ns-475 pretrained on the massive JFT-300m and fintetuned on ImageNet1k; <ref type="figure" target="#fig_1">Fig. 25</ref> shows point computed on filters of our intentionally overparameterized models trained on MNIST; and <ref type="figure" target="#fig_1">Fig. 26</ref> shows spikes computed on filters of the task depth estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Training of low resolution models</head><p>Models were taken from <ref type="bibr" target="#b46">[59]</ref> and slightly modified by us to support different input channel and class modalities. Additionally, some more architectures were added. Generally, <ref type="figure" target="#fig_0">Figure 17</ref>. Distribution shift D between low resolution models between trained on CIFAR-10 with fp16 and fp32 precision. these models are quite similar to the architectures proposed in their respective original publications. However typically, Pooling will be reduced, dilated or strided convolutions will be replaced by regular convolutions, and convolution kernel sizes are reduced to be no larger than 3 ? 3.</p><p>All models are trained on NVIDIA A100 GPUs and hyper-parameters independent of the dataset. Stochastic matrix multiplication is turned off via cuDNN settings. Inputs are scaled to 32 ? 32 px and channel-wise normalized. CIFAR data is additionally zero-padded by 4 px along each dimension, and then transformed using a 32 ? 32 random crops, and random horizontal flips. For the hyper parameters an initial learning rate of 1e-8, a weight decay of 1e-2, a batch-size of 256 and a nesterov momentum of 0.9 is used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J. Training of ResNet-9 variants on CIFAR-10</head><p>The ResNet-9 models were trained as detailed in Appendix I. However, the different random seed were provided for each model. Results are reported in Tab. 1.                Represents frequency of this particular ONNX operator was found in the processed model. Please note that individual operators may have been fused in later ONNX operator sets. <ref type="table">Table 4</ref>. List of all collected models. Mainly sourced from <ref type="bibr" target="#b23">[37,</ref><ref type="bibr" target="#b24">38,</ref><ref type="bibr" target="#b46">59]</ref>. Where possible, the dataset IDs correspond to the TensorFlow naming <ref type="bibr" target="#b47">[60]</ref>. Models that start with hso denote out intentionally overparametrized models (highly sparse and overparametrized).  <ref type="bibr" target="#b56">[69]</ref> -cifar100 Classification natural 356672 hso lowres densenet169 fashionmnist 11 <ref type="bibr" target="#b54">[67]</ref> fashion mnist Classification natural 335936 hso lowres densenet169 cifar100 11 <ref type="bibr" target="#b54">[67]</ref> -cifar100 Classification natural 336064 hso lowres googlenet fashionmnist 11 <ref type="bibr" target="#b56">[69]</ref> fashion mnist Classification natural 356288 hso lowres googlenet cifar10 11 <ref type="bibr" target="#b56">[69]</ref> -cifar10 Classification natural 356672 hso lowres densenet169 kmnist 11 <ref type="bibr" target="#b54">[67]</ref> kmnist Classification handwriting 335936 hso lowres densenet161 cifar10 11 <ref type="bibr" target="#b54">[67]</ref> -cifar10 Classification natural 719136 hso lowres densenet169 cifar10 11 <ref type="bibr" target="#b54">[67]</ref> -cifar10 Classification natural 336064 hso lowres densenet161 fashionmnist 11 <ref type="bibr" target="#b54">[67]</ref> fashion mnist Classification natural 718944 hso lowres densenet169 mnist 11 <ref type="bibr" target="#b54">[67]</ref> mnist Classification handwriting 335936 hso lowres densenet161 kmnist 11 <ref type="bibr" target="#b54">[67]</ref> kmnist Classification handwriting 718944 hso lowres densenet161 mnist 11 <ref type="bibr" target="#b54">[67]</ref> mnist Classification handwriting 718944 hso lowres googlenet kmnist 11 <ref type="bibr" target="#b56">[69]</ref> kmnist Classification handwriting 356288 hso lowres googlenet mnist 11 <ref type="bibr" target="#b56">[69]</ref> mnist Classification handwriting 356288 facebook detr resnet 50 coco2017 12 <ref type="bibr" target="#b57">[70]</ref> coco/2017 Object Detection natural 1257472 hso lowres mobilenet v2 fashionmnist 11 <ref type="bibr" target="#b33">[46]</ref> fashion mnist Classification natural 7168 hso lowres mobilenet v2 kmnist 11 <ref type="bibr" target="#b33">[46]</ref> kmnist Classification handwriting 7168 hso lowres mobilenet v2 cifar10 11 <ref type="bibr" target="#b33">[46]</ref> -cifar10 Classification natural 7232 hso lowres mobilenet v2 cifar100 11 <ref type="bibr" target="#b33">[46]</ref> -cifar100 Classification natural 7232 hso lowres mobilenet v2 mnist 11 <ref type="bibr" target="#b33">[46]</ref> mnist Classification handwriting 7168 hso lowres inception v3 cifar100 11 <ref type="bibr" target="#b58">[71]</ref> -cifar100 Classification natural 614976 hso lowres inception v3 cifar10 11 <ref type="bibr" target="#b58">[71]</ref> -cifar10 Classification natural 614976 hso lowres inception v3 fashionmnist 11 <ref type="bibr" target="#b58">[71]</ref> fashion mnist Classification natural 614592 hso lowres inception v3 kmnist 11 <ref type="bibr" target="#b58">[71]</ref> kmnist Classification handwriting 614592 hso lowres inception v3 mnist 11 <ref type="bibr" target="#b58">[71]</ref> mnist Classification handwriting 614592 facebook detr resnet 50 dc5 panoptic coco2017 12 <ref type="bibr" target="#b57">[70]</ref> coco/2017 Segmentation natural 1371728 facebook detr resnet 50 panoptic coco2017 12 <ref type="bibr" target="#b57">[70]</ref> coco/2017 Segmentation natural 1371728 facebook detr resnet 50 dc5 coco2017 12 <ref type="bibr" target="#b57">[70]</ref> coco/2017 Object Detection natural 1257472 hso lowres resnet101 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 2371776 hso lowres resnet14 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 303296 hso lowres resnet101 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 2371776 hso lowres resnet14 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 303296 hso lowres resnet14 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 303168 hso lowres resnet14 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 303168 hso lowres resnet101 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 2371648 hso lowres resnet14 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 303168 hso lowres resnet101 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 2371648 hso lowres resnet101 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 2371648 hso lowres resnet152 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 3289280 hso lowres resnet18 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 1220800 hso lowres resnet152 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 3289280 hso lowres resnet18 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 1220800 hso lowres resnet18 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 1220672 hso lowres resnet18 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 1220672 hso lowres resnet152 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 3289152 hso lowres resnet152 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 3289152 hso lowres resnet152 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 3289152 hso lowres resnet18 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 1220672 hso lowres resnet34 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 2343104 hso lowres resnet34 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 2343104 hso lowres resnet34 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 2342976 hso lowres resnet34 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 2342976 hso lowres resnet34 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 2342976 hso lowres resnet50 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 1257664 hso lowres resnet50 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 1257664 hso lowres resnet50 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 1257536 hso lowres resnet50 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 1257536 hso lowres resnet50 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 1257536</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continued on next page</head><p>Model ID</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pretraining-Dataset</head><p>Training-Dataset Task Visual Category</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">? Filters</head><p>hso lowres resnet9 cifar100 11 <ref type="bibr" target="#b59">[72]</ref> -cifar100 Classification natural 729280 hso lowres resnet9 cifar10 11 <ref type="bibr" target="#b59">[72]</ref> -cifar10 Classification natural 729280 hso lowres resnet9 fashionmnist 11 <ref type="bibr" target="#b59">[72]</ref> fashion mnist Classification natural 729152 hso lowres resnet9 kmnist 11 <ref type="bibr" target="#b59">[72]</ref> kmnist Classification handwriting 729152 hso lowres resnet9 mnist 11 <ref type="bibr" target="#b59">[72]</ref> mnist Classification handwriting 729152 hso lowres vgg11 bn cifar10 11 <ref type="bibr" target="#b60">[73]</ref> -cifar10 Classification natural 1024192 hso lowres vgg11 bn cifar100 11 <ref type="bibr" target="#b60">[73]</ref> -cifar100 Classification natural 1024192 hso lowres vgg11 bn fashionmnist 11 <ref type="bibr" target="#b60">[73]</ref> fashion mnist Classification natural 1024064 hso lowres vgg11 bn kmnist 11 <ref type="bibr" target="#b60">[73]</ref> kmnist Classification handwriting 1024064 hso lowres vgg11 bn mnist 11 <ref type="bibr" target="#b60">[73]</ref> mnist Classification handwriting 1024064 hso lowres vgg13 bn cifar100 11 <ref type="bibr" target="#b60">[73]</ref> -cifar100 Classification natural 1044672 hso lowres vgg13 bn cifar10 11 <ref type="bibr" target="#b60">[73]</ref> -cifar10 Classification natural 1044672 hso lowres vgg13 bn fashionmnist 11 <ref type="bibr" target="#b60">[73]</ref> fashion mnist Classification natural 1044544 hso lowres vgg13 bn kmnist 11 <ref type="bibr" target="#b60">[73]</ref> kmnist Classification handwriting 1044544 hso lowres vgg13 bn mnist 11 <ref type="bibr" target="#b60">[73]</ref> mnist Classification handwriting 1044544 hso lowres vgg16 bn fashionmnist 11 <ref type="bibr" target="#b60">[73]</ref> fashion mnist Classification natural 1634368 hso lowres vgg16 bn cifar100 11 <ref type="bibr" target="#b60">[73]</ref> -cifar100 Classification natural 1634496 hso lowres vgg16 bn cifar10 11 <ref type="bibr" target="#b60">[73]</ref> -cifar10 Classification natural 1634496 hso lowres vgg16 bn kmnist 11 <ref type="bibr" target="#b60">[73]</ref> kmnist Classification handwriting 1634368 hso lowres vgg16 bn mnist 11 <ref type="bibr" target="#b60">[73]</ref> mnist Classification handwriting 1634368 hso lowres vgg19 bn cifar100 11 <ref type="bibr" target="#b60">[73]</ref> -cifar100 Classification natural 2224320 hso lowres vgg19 bn cifar10 11 <ref type="bibr" target="#b60">[73]</ref> -cifar10 Classification natural 2224320 hso lowres vgg19 bn fashionmnist 11 <ref type="bibr" target="#b60">[73]</ref> fashion mnist Classification natural 2224192 hso lowres vgg19 bn kmnist 11 <ref type="bibr" target="#b60">[73]</ref> kmnist Classification handwriting 2224192 hso lowres vgg19 bn mnist 11 <ref type="bibr" target="#b60">[73]</ref> mnist Classification handwriting 2224192 lungmask unet LTRCLobes 11 <ref type="bibr" target="#b61">[74]</ref> ltrc Segmentation medical ct 3137600 lungmask unet R231CovidWeb 11 <ref type="bibr" target="#b61">[74]</ref> -r231, covidweb Segmentation medical ct 3137600 lungmask unet R231 11 <ref type="bibr" target="#b61">[74]</ref> -r231 Segmentation medical ct 3137600 mealv1 resnest50 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 1257472 mealv2 efficientnet b0 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 2720 mealv2 mobilenet v3 large 100 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 2160 mealv2 mobilenetv3 small 075 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 224 mealv2 mobilenetv3 small 100 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 224 mealv2 resnest50 380x380 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 1257472 mealv2 resnest50 cutmix imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -imagenet1k Classification natural 1257472 mealv2 resnest50 imagenet 11 <ref type="bibr" target="#b62">[75]</ref> -  <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 3292256 timm resnet200d imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 3554400 timm resnet26 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 696320 timm resnet26d imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 699488 timm resnet34 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 2342912 timm resnet34d imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 2346080 timm resnest269e imagenet 11 <ref type="bibr" target="#b79">[92]</ref> -imagenet1k Classification natural 5759168 timm resnet50 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 1257472 timm resnet50d imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 1260640 timm resnet51q imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 111152 timm resnetrs101 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 2378848 timm resnetrs152 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 3296352 timm resnetrs200 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 3558496 timm resnetrs50 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 1264736 timm resnext50 32x4d imagenet 11 <ref type="bibr" target="#b150">[163]</ref> -imagenet1k Classification natural 157184 timm resnetrs270 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 5020768 timm resnext50d 32x4d imagenet 11 <ref type="bibr" target="#b150">[163]</ref> -imagenet1k Classification natural 160352 timm rexnet 100 imagenet 11 <ref type="bibr" target="#b151">[164]</ref> -imagenet1k Classification natural 8654 timm rexnet 130 imagenet 11 <ref type="bibr" target="#b151">[164]</ref> -imagenet1k Classification natural 11256 timm rexnet 150 imagenet 11 <ref type="bibr" target="#b151">[164]</ref> -imagenet1k Classification natural 12984 timm rexnet 200 imagenet 11 <ref type="bibr" target="#b151">[164]</ref> -imagenet1k Classification natural 17308 timm selecsls42b imagenet 11 <ref type="bibr" target="#b152">[165]</ref> -imagenet1k Classification natural 3214432 timm resnetrs350 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 6380640 timm selecsls60 imagenet 11 <ref type="bibr" target="#b152">[165]</ref> -imagenet1k Classification natural 2913504 timm selecsls60b imagenet 11 <ref type="bibr" target="#b152">[165]</ref> -imagenet1k Classification natural 3175648 timm semnasnet 100 imagenet 11 <ref type="bibr" target="#b142">[155]</ref> -imagenet1k Classification natural 4160 timm seresnet50 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 1257472 timm seresnext26d 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 90208 timm resnetrs420 imagenet 11 <ref type="bibr" target="#b149">[162]</ref> -imagenet1k Classification natural 7494752 timm seresnext26t 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 89928 timm seresnet152d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 3292256 timm seresnext50 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 157184 timm skresnet18 imagenet 11 <ref type="bibr" target="#b153">[166]</ref> -imagenet1k Classification natural 1220608 timm skresnet34 imagenet 11 <ref type="bibr" target="#b153">[166]</ref> -imagenet1k Classification natural 2342912 timm spnasnet 100 imagenet 11 <ref type="bibr" target="#b154">[167]</ref> -imagenet1k Classification natural 2552 timm skresnext50 32x4d imagenet 11 <ref type="bibr" target="#b153">[166]</ref> -imagenet1k Classification natural 314368 timm ssl resnet18 imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 1220608 timm ssl resnet50 imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 1257472 timm ssl resnext50 32x4d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 157184 timm ssl resnext101 32x4d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 296448 timm swsl resnet18 imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 1220608 timm ssl resnext101 32x8d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 1185792 timm swsl resnet50 imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 1257472 timm ssl resnext101 32x16d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> yfcc100m imagenet1k Classification natural 4743168 timm swsl resnext101 32x4d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 296448 timm swsl resnext50 32x4d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 157184 timm swsl resnext101 32x8d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 1185792 timm tf efficientnet b0 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 2720 timm tf efficientnet b0 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 2720 timm tf efficientnet b0 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 2720 timm tf efficientnet b1 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 5280 timm tf efficientnet b1 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 5280 timm swsl resnext101 32x16d imagenet 11 <ref type="bibr" target="#b155">[168]</ref> instagram1b imagenet1k Classification natural 4743168 timm tf efficientnet b1 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 5280 timm tf efficientnet b2 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 5760 timm tf efficientnet b2 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 5760 timm tf efficientnet b2 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 5760 timm tf efficientnet b3 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 7000 timm tf efficientnet b3 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 7000 timm tf efficientnet b3 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 7000 timm tf efficientnet b4 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 8952</p><p>Continued on next page </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>First 3 ? 3 filters extracted of each convolution layer in a ResNet-18 trained on CIFAR-10. The filters show a clear loss of diversity and increasing sparsity with depth. The colormap range is determined layer-wise by the absolute peak weight of all filters in that layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Comparison of layer entropy and sparsity of overparameterized, robust, and regular classification models. Outliers are hidden for clarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Bi-variate plots between component distributions showing the four phenotypes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Selected 1 depiction of the filter basis and (cumulative) explained variance ratio per component for filters from ? full dataset, ? models trained on images of fractals, ? GAN discriminators, ? first convolution layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Distribution of the shift D along principal components computed on all possible pairings of models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Coefficient distribution of a ResNet-9 trained on CIFAR-10 every 10 epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Heatmaps over the shift D for different filters groupings. The number in brackets denotes the number of models in this group. Low values/dark colors denote low shifts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Boxplots showing the distribution of pair-wise modelto-model shift D of classification models per convolution depth decile (top to bottom in decreasing order). Our intentionally overparameterized models were left out of this analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Heatmap over the shift D between different pairings of ResNet-classifiers. Each row/column depicts one model. Intentionally overparameterized models were not included.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Fig. 21 contains the (a) model frequency (b) filter frequency Figure 11. Bi-variate heatmap showing frequency aggregated by task and visual category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 .</head><label>12</label><figDesc>Boxplots showing average filter range per convolution depth decile (top to bottom in decreasing order) for each classification model in the dataset. Outliers are hidden for clarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 .</head><label>13</label><figDesc>Sampled entropy for randomly initialized convolution layers with n filters and fitted sigmoid TH .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 14 .</head><label>14</label><figDesc>Most significant principal component KDEs of classification models by tasks before (left) and after removal of degenerated layers (right).cumulative explained variance ratio plots for all tasks and visual categories. For the sake of completeness, we also add that SVD centeringX = [?0.04262863, ?0.0411367, ?0.04461834, ?0.0407119, ?0.03574134, ?0.04268694, ?0.04350573, ?0.04138637, ?0.04486743] for the full dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 28</head><label>28</label><figDesc>shows the KDEs (KDEs created with<ref type="bibr" target="#b45">[58]</ref>) for every principal component on the full dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 15</head><label>15</label><figDesc>. (Lack of) correlation between mean shift D and layer degeneration ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 16 .</head><label>16</label><figDesc>Heatmaps over the shift D for different filters groupings computed on the dataset without degenerated layers. The number in brackets denotes the number of models in this group. Low values/dark colors denote low shifts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 18 .</head><label>18</label><figDesc>Boxplots showing the distribution of pair-wise modelto-model shift D of classification models per convolution depth. Our intentionally overparameterized models were left out of this analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 19 .Figure 21 .</head><label>1921</label><figDesc>Boxplots showing the distribution of pair-wise model-to-model shift D of models trained for various tasks per convolution depth decile. Note the change in scale of the x-axis. Task: GAN-Generator (f) Task: GAN-Discriminator (g) First convolution layer (h) Last convolution layers Figure 20. Depiction of the filter basis and (cumulative) explained variance ratio per component for filters grouped by various meta-data dimensions. Cumulative ratio of explained variance over the first n components by all tasks and visual categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 22 .</head><label>22</label><figDesc>Bi-variate coefficient scatter plot over the full dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 23 .</head><label>23</label><figDesc>Bi-variate coefficient scatter plot of the phenotype spikes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 24 .</head><label>24</label><figDesc>Bi-variate coefficient scatter plot of the phenotype symbols.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 25 .</head><label>25</label><figDesc>Bi-variate coefficient scatter plot of the phenotype point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 26 .</head><label>26</label><figDesc>Bi-variate coefficient scatter plot of the phenotype sun.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 28 .</head><label>28</label><figDesc>Distribution of the coefficients along the principal components of the full dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 29 .</head><label>29</label><figDesc>Distribution of the coefficients along the principal components by model task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 30 .</head><label>30</label><figDesc>Distribution of the coefficients along the principal components by visual category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 31 .</head><label>31</label><figDesc>Distribution of the coefficients along the principal components by model task for datasets belonging to the natural visual category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Figure 32 .</head><label>32</label><figDesc>Distribution of the coefficients along the principal components by visual training category for image classification models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 33 .</head><label>33</label><figDesc>Distribution of the coefficients along the principal components by convolution depth decile for image classification models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 34 .</head><label>34</label><figDesc>Distribution of the coefficients along the principal components of models trained on the MNIST dataset. All these models belong to our intentionally overparameterized models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 35 .</head><label>35</label><figDesc>Distribution of the coefficients along the principal components of selected models from similar families.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345-1359, 2010. 2</figDesc><table><row><cell cols="6">[14] Chelsea Voss, Gabriel Goh, Nick Cammarata,</cell></row><row><cell cols="2">Michael Petrov,</cell><cell cols="2">Ludwig Schubert,</cell><cell cols="2">and Chris</cell></row><row><cell>Olah,</cell><cell>"Branch</cell><cell>specialization,"</cell><cell cols="2">Distill,</cell><cell>2021.</cell></row><row><cell cols="6">https://distill.pub/2020/circuits/branch-specialization.</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">[15] Michael Petrov, Chelsea Voss, Ludwig Schubert, Nick</cell></row><row><cell cols="6">Cammarata, Gabriel Goh, and Chris Olah, "Weight band-</cell></row><row><cell cols="6">ing," Distill, 2021. https://distill.pub/2020/circuits/weight-</cell></row><row><cell cols="2">banding. 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">[16] Mahbub Hussain, Jordan J. Bird, and Diego R. Faria, "A</cell></row><row><cell cols="6">study on cnn transfer learning for image classification," in</cell></row><row><cell cols="6">Advances in Computational Intelligence Systems (Ahmad</cell></row><row><cell cols="6">Lotfi, Hamid Bouchachia, Alexander Gegov, Caroline Lan-</cell></row><row><cell cols="6">gensiepen, and Martin McGinnity, eds.), (Cham), pp. 191-</cell></row><row><cell cols="5">202, Springer International Publishing, 2019. 2</cell></row><row><cell cols="6">[17] Sinno Jialin Pan and Qiang Yang, "A survey on transfer</cell></row><row><cell>learning,"</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>[18] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He, "A comprehensive survey on transfer learning," 2020. 2 [19] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lip- son, "How transferable are features in deep neural net- works?," vol. 4, 2014. 2 [20] Mehmet Aygun, Yusuf Aytar, and Hazim Kemal Ekenel, "Exploiting convolution filter patterns for transfer learn- ing," in Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops, Oct 2017. 2 [21] Muhammad Tayyab and Abhijit Mahalanobis, "Basisconv: A method for compressed representation and learning in cnns," 2019. 2 [22] Guillaume Alain and Yoshua Bengio, "Understanding in- termediate layers using linear classifier probes," 2018. 2 [23] Jian-Hao Luo, Jianxin Wu, and Weiyao Lin, "Thinet: A filter level pruning method for deep neural network com- pression," 2017. 2 [24] Yihui He, Xiangyu Zhang, and Jian Sun, "Channel pruning for accelerating very deep neural networks," in 2017 IEEE International Conference on Computer Vision (ICCV), pp. 1398-1406, 2017. 2 [25] Shaohui Lin, Rongrong Ji, Yuchao Li, Yongjian Wu, Feiyue Huang, and Baochang Zhang, "Accelerating convolutional networks via global &amp; dynamic filter pruning," in Proceed- ings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, pp. 2425-2432, Inter- national Joint Conferences on Artificial Intelligence Orga- nization, 7 2018. 2 [26] Shaohui Lin, Rongrong Ji, Chenqian Yan, Baochang Zhang, Liujuan Cao, Qixiang Ye, Feiyue Huang, and David Doermann, "Towards optimal structured cnn prun- ing via generative adversarial learning," in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2785-2794, 2019. 2</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Performance of retrained ResNet-9 models with random seeds obtained after the validation epoch with the highest validation accuracy.</figDesc><table><row><cell cols="2">Model ID Best</cell><cell>Train</cell><cell>Train</cell><cell>Valid.</cell><cell>Valid.</cell></row><row><cell></cell><cell>Epoch</cell><cell>Loss</cell><cell>Accur.</cell><cell>Loss</cell><cell>Accur.</cell></row><row><cell>resnet9 0</cell><cell>93</cell><cell>0.016</cell><cell cols="2">99.996 0.174</cell><cell>94.792</cell></row><row><cell>resnet9 1</cell><cell>94</cell><cell>0.016</cell><cell cols="2">99.980 0.176</cell><cell>94.631</cell></row><row><cell>resnet9 2</cell><cell>96</cell><cell>0.016</cell><cell cols="2">99.986 0.177</cell><cell>94.571</cell></row><row><cell>resnet9 3</cell><cell>89</cell><cell>0.017</cell><cell cols="2">99.976 0.175</cell><cell>94.812</cell></row><row><cell>resnet9 4</cell><cell>99</cell><cell>0.015</cell><cell cols="2">99.992 0.175</cell><cell>94.762</cell></row><row><cell>resnet9 5</cell><cell>94</cell><cell>0.016</cell><cell cols="2">99.994 0.174</cell><cell>94.822</cell></row><row><cell>resnet9 6</cell><cell>91</cell><cell>0.016</cell><cell cols="2">99.986 0.175</cell><cell>94.812</cell></row><row><cell>resnet9 7</cell><cell>94</cell><cell>0.016</cell><cell cols="2">99.994 0.173</cell><cell>94.852</cell></row><row><cell>resnet9 8</cell><cell>91</cell><cell>0.017</cell><cell cols="2">99.992 0.174</cell><cell>94.862</cell></row><row><cell>resnet9 9</cell><cell>96</cell><cell>0.016</cell><cell cols="2">99.988 0.178</cell><cell>94.832</cell></row></table><note>A SGD optimizer is used, and scheduled to linearly increase the learning rate on each step for the first 30 epochs to 1e-1. Then, a cosine annealing schedule follows for the remaining 70 epochs. The loss is determined using Categorical Cross Entropy. Results are reported in Tab. 2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Performance of low resolution models with random seeds obtained after the validation epoch with the highest validation accuracy. Model Best Epoch Train Loss Train Acc. Val. Loss Val. Acc.DatasetModelBest Epoch Train Loss Train Acc. Val. Loss Val. Acc.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cifar10</cell><cell>alexnet</cell><cell>95</cell><cell>0.563</cell><cell>80.717</cell><cell>0.604</cell><cell>79.297</cell></row><row><cell>cifar10</cell><cell>densenet121</cell><cell>96</cell><cell>0.047</cell><cell>99.716</cell><cell>0.247</cell><cell>93.780</cell></row><row><cell>cifar10</cell><cell>densenet161</cell><cell>97</cell><cell>0.042</cell><cell>99.830</cell><cell>0.232</cell><cell>94.311</cell></row><row><cell>cifar10</cell><cell>densenet169</cell><cell>98</cell><cell>0.046</cell><cell>99.742</cell><cell>0.235</cell><cell>94.171</cell></row><row><cell>cifar10</cell><cell>googlenet</cell><cell>97</cell><cell>0.064</cell><cell>99.651</cell><cell>0.242</cell><cell>92.919</cell></row><row><cell>cifar10</cell><cell>inception v3</cell><cell>96</cell><cell>0.062</cell><cell>99.501</cell><cell>0.254</cell><cell>93.550</cell></row><row><cell>cifar10</cell><cell>mobilenet v2</cell><cell>96</cell><cell>0.074</cell><cell>98.892</cell><cell>0.237</cell><cell>93.760</cell></row><row><cell>cifar10</cell><cell>resnet101</cell><cell>96</cell><cell>0.041</cell><cell>99.329</cell><cell>0.242</cell><cell>93.399</cell></row><row><cell>cifar10</cell><cell>resnet14</cell><cell>97</cell><cell>0.040</cell><cell>99.567</cell><cell>0.254</cell><cell>92.588</cell></row><row><cell>cifar10</cell><cell>resnet152</cell><cell>99</cell><cell>0.032</cell><cell>99.629</cell><cell>0.249</cell><cell>93.490</cell></row><row><cell>cifar10</cell><cell>resnet18</cell><cell>97</cell><cell>0.033</cell><cell>99.685</cell><cell>0.250</cell><cell>92.929</cell></row><row><cell>cifar10</cell><cell>resnet34</cell><cell>99</cell><cell>0.027</cell><cell>99.714</cell><cell>0.253</cell><cell>93.399</cell></row><row><cell>cifar10</cell><cell>resnet50</cell><cell>97</cell><cell>0.039</cell><cell>99.473</cell><cell>0.227</cell><cell>93.780</cell></row><row><cell>cifar10</cell><cell>resnet9</cell><cell>93</cell><cell>0.016</cell><cell>99.996</cell><cell>0.174</cell><cell>94.792</cell></row><row><cell>cifar10</cell><cell>vgg11 bn</cell><cell>95</cell><cell>0.024</cell><cell>99.860</cell><cell>0.254</cell><cell>92.258</cell></row><row><cell>cifar10</cell><cell>vgg13 bn</cell><cell>98</cell><cell>0.021</cell><cell>99.942</cell><cell>0.198</cell><cell>94.111</cell></row><row><cell>cifar10</cell><cell>vgg16 bn</cell><cell>99</cell><cell>0.021</cell><cell>99.912</cell><cell>0.228</cell><cell>93.930</cell></row><row><cell>cifar10</cell><cell>vgg19 bn</cell><cell>97</cell><cell>0.022</cell><cell>99.878</cell><cell>0.242</cell><cell>93.800</cell></row><row><cell>cifar100</cell><cell>densenet121</cell><cell>94</cell><cell>0.192</cell><cell>98.678</cell><cell>1.082</cell><cell>75.040</cell></row><row><cell>cifar100</cell><cell>densenet161</cell><cell>98</cell><cell>0.171</cell><cell>99.373</cell><cell>1.044</cell><cell>76.412</cell></row><row><cell>cifar100</cell><cell>densenet169</cell><cell>97</cell><cell>0.177</cell><cell>99.171</cell><cell>1.063</cell><cell>75.341</cell></row><row><cell>cifar100</cell><cell>googlenet</cell><cell>97</cell><cell>0.331</cell><cell>98.109</cell><cell>1.077</cell><cell>73.417</cell></row><row><cell>cifar100</cell><cell>inception v3</cell><cell>97</cell><cell>0.276</cell><cell>98.395</cell><cell>1.055</cell><cell>75.040</cell></row><row><cell>cifar100</cell><cell>mobilenet v2</cell><cell>93</cell><cell>0.342</cell><cell>94.940</cell><cell>1.009</cell><cell>75.200</cell></row><row><cell>cifar100</cell><cell>resnet101</cell><cell>95</cell><cell>0.133</cell><cell>98.596</cell><cell>1.070</cell><cell>74.740</cell></row><row><cell>cifar100</cell><cell>resnet14</cell><cell>98</cell><cell>0.380</cell><cell>93.321</cell><cell>1.110</cell><cell>70.673</cell></row><row><cell>cifar100</cell><cell>resnet152</cell><cell>97</cell><cell>0.127</cell><cell>98.846</cell><cell>1.059</cell><cell>74.720</cell></row><row><cell>cifar100</cell><cell>resnet18</cell><cell>98</cell><cell>0.163</cell><cell>98.257</cell><cell>1.103</cell><cell>72.536</cell></row><row><cell>cifar100</cell><cell>resnet34</cell><cell>97</cell><cell>0.103</cell><cell>99.165</cell><cell>1.161</cell><cell>72.546</cell></row><row><cell>cifar100</cell><cell>resnet50</cell><cell>96</cell><cell>0.131</cell><cell>98.834</cell><cell>1.062</cell><cell>74.159</cell></row><row><cell>cifar100</cell><cell>resnet9</cell><cell>91</cell><cell>0.075</cell><cell>99.806</cell><cell>1.000</cell><cell>75.591</cell></row><row><cell>cifar100</cell><cell>vgg11 bn</cell><cell>98</cell><cell>0.095</cell><cell>99.303</cell><cell>1.307</cell><cell>69.621</cell></row><row><cell>cifar100</cell><cell>vgg13 bn</cell><cell>94</cell><cell>0.088</cell><cell>99.393</cell><cell>1.158</cell><cell>73.017</cell></row><row><cell>cifar100</cell><cell>vgg16 bn</cell><cell>96</cell><cell>0.110</cell><cell>98.702</cell><cell>1.267</cell><cell>72.907</cell></row><row><cell>cifar100</cell><cell>vgg19 bn</cell><cell>96</cell><cell>0.136</cell><cell>97.917</cell><cell>1.349</cell><cell>71.945</cell></row><row><cell>mnist</cell><cell>alexnet</cell><cell>86</cell><cell>0.053</cell><cell>98.444</cell><cell>0.045</cell><cell>98.668</cell></row><row><cell>mnist</cell><cell>densenet121</cell><cell>92</cell><cell>0.035</cell><cell>99.980</cell><cell>0.044</cell><cell>99.579</cell></row><row><cell>mnist</cell><cell>densenet161</cell><cell>93</cell><cell>0.035</cell><cell>99.983</cell><cell>0.043</cell><cell>99.609</cell></row><row><cell>mnist</cell><cell>densenet169</cell><cell>96</cell><cell>0.036</cell><cell>99.977</cell><cell>0.042</cell><cell>99.649</cell></row><row><cell>mnist</cell><cell>googlenet</cell><cell>90</cell><cell>0.046</cell><cell>99.873</cell><cell>0.045</cell><cell>99.579</cell></row><row><cell>mnist</cell><cell>inception v3</cell><cell>98</cell><cell>0.046</cell><cell>99.873</cell><cell>0.041</cell><cell>99.679</cell></row><row><cell>mnist</cell><cell>mobilenet v2</cell><cell>96</cell><cell>0.035</cell><cell>99.983</cell><cell>0.042</cell><cell>99.659</cell></row><row><cell>mnist</cell><cell>resnet101</cell><cell>87</cell><cell>0.020</cell><cell>99.978</cell><cell>0.032</cell><cell>99.539</cell></row><row><cell>mnist</cell><cell>resnet14</cell><cell>80</cell><cell>0.021</cell><cell>99.985</cell><cell>0.030</cell><cell>99.669</cell></row><row><cell>mnist</cell><cell>resnet152</cell><cell>94</cell><cell>0.019</cell><cell>99.990</cell><cell>0.030</cell><cell>99.589</cell></row><row><cell>mnist</cell><cell>resnet18</cell><cell>83</cell><cell>0.020</cell><cell>99.993</cell><cell>0.030</cell><cell>99.639</cell></row><row><cell>mnist</cell><cell>resnet34</cell><cell>79</cell><cell>0.019</cell><cell>99.977</cell><cell>0.029</cell><cell>99.609</cell></row><row><cell>mnist</cell><cell>resnet50</cell><cell>86</cell><cell>0.020</cell><cell>99.982</cell><cell>0.032</cell><cell>99.559</cell></row><row><cell>mnist</cell><cell>resnet9</cell><cell>83</cell><cell>0.006</cell><cell>99.998</cell><cell>0.016</cell><cell>99.679</cell></row><row><cell>mnist</cell><cell>vgg11 bn</cell><cell>75</cell><cell>0.017</cell><cell>99.995</cell><cell>0.027</cell><cell>99.639</cell></row><row><cell>mnist</cell><cell>vgg13 bn</cell><cell>90</cell><cell>0.017</cell><cell>99.998</cell><cell>0.026</cell><cell>99.649</cell></row><row><cell>mnist</cell><cell>vgg16 bn</cell><cell>90</cell><cell>0.017</cell><cell>99.992</cell><cell>0.026</cell><cell>99.639</cell></row><row><cell>mnist</cell><cell>vgg19 bn</cell><cell>85</cell><cell>0.017</cell><cell>99.988</cell><cell>0.027</cell><cell>99.649</cell></row><row><cell>kmnist</cell><cell>alexnet</cell><cell>97</cell><cell>0.047</cell><cell>98.775</cell><cell>0.191</cell><cell>94.872</cell></row><row><cell>kmnist</cell><cell>densenet121</cell><cell>88</cell><cell>0.037</cell><cell>99.982</cell><cell>0.092</cell><cell>98.668</cell></row><row><cell>kmnist</cell><cell>densenet161</cell><cell>87</cell><cell>0.038</cell><cell>99.972</cell><cell>0.084</cell><cell>98.688</cell></row><row><cell>kmnist</cell><cell>densenet169</cell><cell>89</cell><cell>0.037</cell><cell>99.987</cell><cell>0.096</cell><cell>98.518</cell></row><row><cell>kmnist</cell><cell>googlenet</cell><cell>97</cell><cell>0.044</cell><cell>99.970</cell><cell>0.112</cell><cell>97.947</cell></row><row><cell>kmnist</cell><cell>inception v3</cell><cell>97</cell><cell>0.044</cell><cell>99.970</cell><cell>0.090</cell><cell>98.658</cell></row><row><cell></cell><cell></cell><cell cols="2">Continued on next page</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Description of columns present in the meta data. the extracted filter i.e. how many convolution layers were hierarchically below the layer, that this filter was extracted from.</figDesc><table><row><cell>Column</cell><cell>Values</cell><cell>Description</cell><cell></cell></row><row><cell>model id</cell><cell>int</cell><cell>Unique ID of the model.</cell><cell></cell></row><row><cell cols="4">conv depth Convolution depth of conv depth norm int float Similar to conv depth but normalized by the maximum conv depth. Will be a float between 0 (first</cell></row><row><cell></cell><cell></cell><cell>layers) . . . , 1 (towards head).</cell><cell></cell></row><row><cell>filter ids</cell><cell>list of ints</cell><cell cols="2">List of Filter IDs that belong to this record. These can directly be mapped to the rows of the filter array.</cell></row><row><cell>model</cell><cell>str</cell><cell>Unique string ID of the model.</cell><cell>Typically, but not reliably in the format</cell></row><row><cell></cell><cell></cell><cell>{name} {trainingset} {onnx opset}.</cell><cell></cell></row><row><cell>producer</cell><cell>str</cell><cell cols="2">Producer of the ONNX export. Typically various versions of PyTorch.</cell></row><row><cell>op set</cell><cell>int</cell><cell cols="2">Version of the ONNX operator set used for export.</cell></row><row><cell>depth</cell><cell>int</cell><cell cols="2">Total hierarchical depth of the model including all layers.</cell></row><row><cell>Name</cell><cell>str</cell><cell>Name of the model.</cell><cell></cell></row><row><cell>Paper</cell><cell>str</cell><cell>Link to the original publication.</cell><cell></cell></row><row><cell>Pretraining-</cell><cell>str</cell><cell cols="2">Name of the pretraining dataset(s) if pretrained. Combined datasets are separated by commas.</cell></row><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training-Dataset</cell><cell>str</cell><cell cols="2">Name of the training dataset(s). Combined datasets are separated by commas.</cell></row><row><cell>Visual Category</cell><cell>str</cell><cell cols="2">Visual, manual categorization of the training datasets.</cell></row><row><cell>Task</cell><cell>str</cell><cell>Task of the model.</cell><cell></cell></row><row><cell>Accessible</cell><cell>str</cell><cell cols="2">Represents where the model can be found. Typically, this will be a link to GitHub.</cell></row><row><cell>Dataset URL</cell><cell>str</cell><cell cols="2">URL of the training dataset. Usually only entered for exotic datasets.</cell></row><row><cell>total filters</cell><cell>int</cell><cell>Total number of convolution filters in this model.</cell><cell></cell></row><row><cell>(X, Y) filters</cell><cell>int</cell><cell cols="2">Represents frequency of filters with shape (X, Y) were found in the processed model.</cell></row><row><cell>onnx operator</cell><cell>int</cell><cell></cell><cell></cell></row><row><cell>(e.g. Conv, Add,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Relu, MaxPool)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">(a) model frequency (b) filter frequency Figure 27. Total frequency per filter sub-set. Log scale.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b124">[137]</ref> <p>kaist Object Detection thermal 6189152 timm coat lite mini imagenet 11 <ref type="bibr" target="#b125">[138]</ref> -imagenet1k Classification natural 2560 stylegan flickerhq 1024 gen 11 <ref type="bibr" target="#b122">[135]</ref> ff hq/1024 GAN-Generator faces 2096896 timm coat lite tiny imagenet 11 <ref type="bibr" target="#b125">[138]</ref> -imagenet1k Classification natural 1920 timm cspdarknet53 imagenet 11 <ref type="bibr" target="#b126">[139]</ref> -imagenet1k Classification natural 2412640 timm coat lite small imagenet 11 <ref type="bibr" target="#b125">[138]</ref> -imagenet1k Classification natural 5200 timm cspresnet50 imagenet 11 <ref type="bibr" target="#b126">[139]</ref> -imagenet1k Classification natural 1257472 timm cspresnext50 imagenet 11 <ref type="bibr" target="#b126">[139]</ref> -imagenet1k Classification natural 157184 timm densenet121 imagenet 11 <ref type="bibr" target="#b54">[67]</ref> -imagenet1k Classification natural 237568 timm coat mini imagenet 11 <ref type="bibr" target="#b125">[138]</ref> -imagenet1k Classification natural 6860 timm dla102 imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 1712896 timm coat tiny imagenet 11 <ref type="bibr" target="#b125">[138]</ref> -imagenet1k Classification natural 4940 timm dla102x2 imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 428800 timm dla102x imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 214784 timm dla34 imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 1547008 timm dla46 c imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 56064 timm dla169 imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 2769664 timm dla46x c imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 7680 timm dla60 imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 1123072 timm dla60 res2net imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 645216 timm dla60 res2next imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 105984 timm dla60x c imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 9728 timm dla60x imagenet 11 <ref type="bibr" target="#b127">[140]</ref> -imagenet1k Classification natural 141056 timm dpn68 imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 206366 timm dpn68b imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 206366 timm dpn107 imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 438400 timm dpn92 imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 152928 timm dpn131 imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 432640 timm ecaresnet101d pruned imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 1623471 timm dpn98 imagenet 11 <ref type="bibr" target="#b129">[142]</ref> -imagenet1k Classification natural 344960 timm ecaresnet101d imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 2374752 timm ecaresnet26t imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 699208 timm ecaresnet50d imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 1260640 timm ecaresnet50d pruned imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 985657 timm ecaresnet50t imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 1260360 timm efficientnet b0 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 2720 timm ecaresnetlight imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -imagenet1k Classification natural 1527808 timm efficientnet b1 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 5280 timm efficientnet b2 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 5760 timm efficientnet b1 pruned imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 4030 timm efficientnet b2 pruned imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 4753 timm efficientnet b3 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 7000 timm efficientnet b3 pruned imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 5186 timm efficientnet b4 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 8952 timm efficientnet el imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 181368 timm efficientnet el pruned imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 181368 timm efficientnet em imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 108384 timm efficientnet es imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 79456 timm efficientnet es pruned imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 79456 timm efficientnet lite0 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 2720 timm ecaresnet269d imagenet 11 <ref type="bibr" target="#b130">[143]</ref> -  <ref type="bibr" target="#b136">[149]</ref> -imagenet1k Classification natural 85431 timm ghostnet 100 imagenet 11 <ref type="bibr" target="#b51">[64]</ref> -imagenet1k Classification natural 4616 timm gluon inception v3 imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 632928 timm gluon resnet101 v1b imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 2371584 timm gluon resnet101 v1d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 2374752 timm gluon resnet101 v1c imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 2374752 timm gluon resnet101 v1s imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 2384064 timm gluon resnet18 v1b imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 1220608 timm gluon resnet34 v1b imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 2342912 timm gluon resnet152 v1b imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 3289088 timm gluon resnet50 v1b imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 1257472 timm gluon resnet152 v1s imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 3301568 timm gluon resnet50 v1d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 1260640 timm gluon resnet50 v1c imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 1260640 timm gluon resnet152 v1d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 3292256 timm gluon resnet152 v1c imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 3292256 timm gluon resnet50 v1s imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 1269952 timm gluon resnext50 32x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 157184 timm gluon resnext101 32x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 296448 timm gluon seresnext50 32x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 157184 timm gluon seresnext101 32x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 296448 timm gluon resnext101 64x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 592896 timm hardcorenas a imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 128 timm gluon seresnext101 64x4d imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 592896 timm hardcorenas b imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 2264 timm hardcorenas c imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 2192 timm gluon xception65 imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 46336 timm hardcorenas d imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 2776 timm gluon senet154 imagenet 11 <ref type="bibr" target="#b137">[150]</ref> -imagenet1k Classification natural 3176128 timm hardcorenas e imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 1880 timm hardcorenas f imagenet 11 <ref type="bibr" target="#b138">[151]</ref> -imagenet1k Classification natural 3728 timm hrnet w18 small imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 934592 timm hrnet w18 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 1809204 timm hrnet w18 small v2 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 1188004 timm hrnet w30 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 3595380 timm hrnet w32 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 3979456 timm hrnet w40 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 5762560 timm hrnet w44 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 6802192 timm hrnet w48 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 7940544 timm inception resnet v2 imagenet 11 <ref type="bibr" target="#b135">[148]</ref> -imagenet1k Classification natural 714848 timm inception v4 imagenet 11 <ref type="bibr" target="#b135">[148]</ref> -imagenet1k Classification natural 531552 timm legacy seresnet101 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 2371584 timm hrnet w64 imagenet 11 <ref type="bibr" target="#b139">[152]</ref> -imagenet1k Classification natural 13481152 timm legacy seresnet18 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 1220608 timm legacy seresnet34 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 2342912 timm legacy senet154 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 3176128 timm legacy seresnet152 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 3289088 timm legacy seresnet50 imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 1257472 timm legacy seresnext26 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 87040 timm legacy seresnext101 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 296448 timm legacy seresnext50 32x4d imagenet 11 <ref type="bibr" target="#b140">[153]</ref> -imagenet1k Classification natural 157184 timm mixnet l imagenet 11 <ref type="bibr">[</ref>  <ref type="bibr" target="#b144">[157]</ref> -imagenet1k Classification natural 576 timm regnetx 002 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 26208 timm pnasnet5large imagenet 11 <ref type="bibr" target="#b147">[160]</ref> -imagenet1k Classification natural 37590 timm regnetx 004 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 94304 timm regnetx 006 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 125664 timm regnetx 008 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 93280 timm regnetx 016 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 161376 timm regnetx 032 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 472416 timm regnetx 040 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 476896 timm regnetx 064 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 636704 timm regnety 002 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 26208 timm regnety 004 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 34080 timm regnety 006 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 73824 timm regnetx 120 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 1655904 timm regnety 008 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 72800 timm regnetx 080 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 1683296 timm regnety 016 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 199392 timm regnety 032 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 245472 timm repvgg b0 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 1450176 timm regnety 040 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 622688 timm regnety 064 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 933216 timm regnetx 160 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 2211936 timm repvgg a2 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 2675904 timm regnety 120 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 1655904 timm regnety 080 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 733920 timm repvgg b1 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 5529792 timm repvgg b1g4 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 3784896 timm regnetx 320 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 4261920 timm regnety 160 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 2107488 timm repvgg b2g4 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 5911232 timm res2net101 26w 4s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 1174212 timm repvgg b3g4 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 8116416 timm res2net50 26w 4s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 622596 timm repvgg b2 imagenet 11 <ref type="bibr" target="#b148">[161]</ref> -imagenet1k Classification natural 8637632 timm res2net50 26w 6s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 1037660 timm regnety 320 imagenet 11 <ref type="bibr" target="#b146">[159]</ref> -imagenet1k Classification natural 5651616 timm res2net50 48w 2s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 707328 timm res2net50 14w 8s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 421204 timm res2net50 26w 8s imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -imagenet1k Classification natural 1452724 timm res2next50 imagenet 11 <ref type="bibr" target="#b128">[141]</ref> -  <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 8952 timm tf efficientnet b5 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 14304 timm tf efficientnet b5 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 14304 timm tf efficientnet b5 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 14304 timm tf efficientnet b6 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 17136 timm tf efficientnet b6 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 17136 timm tf efficientnet b6 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 17136 timm tf efficientnet b7 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 25216 timm tf efficientnet el imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 181368 timm tf efficientnet b7 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 25216 timm tf efficientnet b7 ns imagenet 11 <ref type="bibr" target="#b157">[170]</ref> jft300m imagenet1k Classification natural 25216 timm tf efficientnet b8 ap imagenet 11 <ref type="bibr" target="#b156">[169]</ref> -imagenet1k Classification natural 29232 timm tf efficientnet em imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 108384 timm tf efficientnet b8 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 29232 timm tf efficientnet es imagenet 11 <ref type="bibr" target="#b131">[144]</ref> -imagenet1k Classification natural 79456 timm tf efficientnet lite0 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 2720 timm tf efficientnet lite1 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 3344 timm tf efficientnet lite2 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 3632 timm tf efficientnet lite3 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 4640 timm tf efficientnet lite4 imagenet 11 <ref type="bibr" target="#b65">[78]</ref> -imagenet1k Classification natural 6176 timm tf efficientnetv2 b0 imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 32000 timm tf efficientnetv2 b1 imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 47776 timm tf efficientnetv2 b2 imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 56912 timm tf efficientnetv2 b3 imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 70040 timm tf efficientnetv2 s imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 123272 timm tf efficientnetv2 m imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 217608 timm tf efficientnetv2 m in21ft1k imagenet 11 <ref type="bibr" target="#b133">[146]</ref> imagenet21k</p><p>imagenet1k Classification natural 217608 timm tf efficientnetv2 s in21ft1k imagenet 11 <ref type="bibr" target="#b133">[146]</ref> imagenet21k imagenet1k Classification natural 123272 timm tf efficientnetv2 m in21k imagenet21k e 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet21k e Classification natural 217608 timm tf inception v3 imagenet 11 <ref type="bibr" target="#b58">[71]</ref> -imagenet1k Classification natural 632928 timm tf efficientnetv2 s in21k imagenet21k e 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet21k e Classification natural 123272 timm tf mixnet l imagenet 11 <ref type="bibr" target="#b141">[154]</ref> -imagenet1k Classification natural 3868 timm tf efficientnetv2 l imagenet 11 <ref type="bibr" target="#b133">[146]</ref> -imagenet1k Classification natural 458784 timm tf mixnet m imagenet 11 <ref type="bibr" target="#b141">[154]</ref> -imagenet1k Classification natural 2918 timm tf efficientnetv2 l in21ft1k imagenet 11 <ref type="bibr" target="#b133">[146]</ref> imagenet21k imagenet1k Classification natural 458784 timm tf efficientnetv2 l in21k imagenet21k e 11 <ref type="bibr" target="#b133">[146]</ref> -  <ref type="bibr" target="#b160">[173]</ref> -imagenet1k Classification natural 1184 tinynet e imagenet 11 <ref type="bibr" target="#b160">[173]</ref> -imagenet1k Classification natural 1136 timm twins svt base imagenet 11 <ref type="bibr" target="#b162">[175]</ref> -imagenet1k Classification natural 1440 timm twins pcpvt base imagenet 11 <ref type="bibr" target="#b162">[175]</ref> -imagenet1k Classification natural 1024 torchseg dfn R101 v1c voc 11 <ref type="bibr" target="#b163">[176]</ref> voc/2012 Segmentation natural 6649810 torchseg pspnet R101 v1c ade 11 <ref type="bibr" target="#b164">[177]</ref> -ade20k Segmentation natural 4481216 alexnet imagenet 11 <ref type="bibr" target="#b53">[66]</ref> -imagenet1k Classification natural 237568 densenet121 imagenet 11 <ref type="bibr" target="#b54">[67]</ref> -imagenet1k Classification natural 237568 timm twins svt large imagenet 11 <ref type="bibr" target="#b162">[175]</ref> -imagenet1k Classification natural 1920 densenet161 imagenet 11 <ref type="bibr" target="#b54">[67]</ref> -imagenet1k Classification natural 718848 densenet169 imagenet 11 <ref type="bibr" target="#b54">[67]</ref> -imagenet1k Classification natural 335872 googlenet imagenet 11 <ref type="bibr" target="#b56">[69]</ref> -imagenet1k Classification natural 368384 mnasnet0 5 imagenet 11 <ref type="bibr" target="#b142">[155]</ref> -imagenet1k Classification natural 1288 mobilenet v2 imagenet 11 <ref type="bibr" target="#b33">[46]</ref> -imagenet1k Classification natural 7232 mnasnet1 0 imagenet 11 <ref type="bibr" target="#b142">[155]</ref> -imagenet1k Classification natural 2528 densenet201 imagenet 11 <ref type="bibr" target="#b54">[67]</ref> -imagenet1k Classification natural 401408 inception v3 imagenet 11 <ref type="bibr" target="#b58">[71]</ref> -imagenet1k Classification natural 632928 resnet101 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 2371584 timm twins pcpvt large imagenet 11 <ref type="bibr" target="#b162">[175]</ref> -imagenet1k Classification natural 1024 resnet152 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 3289088 resnet18 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 1220608 resnet34 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 2342912 resnet50 imagenet 11 <ref type="bibr" target="#b59">[72]</ref> -imagenet1k Classification natural 1257472 resnext101 32x8d imagenet 11 <ref type="bibr" target="#b150">[163]</ref> -imagenet1k Classification natural 1185792 resnext50 32x4d imagenet 11 <ref type="bibr" target="#b150">[163]</ref> -imagenet1k Classification natural 157184 shufflenet v2 x0 5 imagenet 11 <ref type="bibr" target="#b165">[178]</ref> -imagenet1k Classification natural 1104 shufflenet v2 x1 0 imagenet 11 <ref type="bibr" target="#b165">[178]</ref> -imagenet1k Classification natural 2532 squeezenet1 0 imagenet 11 <ref type="bibr" target="#b166">[179]</ref> -imagenet1k Classification natural 61440 squeezenet1 1 imagenet 11 <ref type="bibr" target="#b166">[179]</ref> -imagenet1k Classification natural 61632 vgg11 bn imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1024192 vgg16 bn imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1634496 vgg13 imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1044672 vgg11 imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1024192 vgg13 bn imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1044672 vgg16 imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 1634496 vgg19 bn imagenet 11 <ref type="bibr" target="#b60">[73]</ref> -imagenet1k Classification natural 2224320 torchxrayvision densenet121 all 11 <ref type="bibr" target="#b167">[180]</ref> - </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="843" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Threat of adversarial attacks on deep learning in computer vision: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveed</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajmal</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14410" to="14430" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for medical image analysis: Full training or fine tuning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Suryakanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Gotway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1312" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Pre-training without natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokatsu</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazushige</forename><surname>Okayasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asato</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eisuke</forename><surname>Yamagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryosuke</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nakamasa</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akio</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Satoh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Gavrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janis</forename><surname>Keuper</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6371680</idno>
		<idno>v1.0.0</idno>
		<ptr target="https://doi.org/10.5281/zenodo.6371680.2" />
		<imprint>
			<date type="published" when="2022-06" />
		</imprint>
	</monogr>
	<note type="report_type">CNN-Filter-DB</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Zoom in: An introduction to circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An overview of early vision in inceptionv1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Carter</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/early-vision.2" />
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Curve detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/curve-detectors.2" />
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Naturally occurring equivariance in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/equivariance.2" />
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">High-low frequency detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/frequency-edges.2" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Distill</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Curve circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/curve-circuits.2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Visualizing weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cammarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swee Kiat</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://distill.pub/2020/circuits/visualizing-weights.2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nisp: Pruning networks using neuron importance score propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Fu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Hsin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingfei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Yung</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9194" to="9203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Centripetal sgd for pruning very deep convolutional networks with complicated structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4938" to="4948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting kernel sparsity and entropy for interpretable cnn compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning both weights and connections for efficient neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Pruning filters for efficient convnets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Durdanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Peter</forename><surname>Graf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Filter pruning via geometric median for deep convolutional neural networks acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4335" to="4344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Soft filter pruning for accelerating deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="2234" to="2240" />
		</imprint>
	</monogr>
	<note>International Joint Conferences on Artificial Intelligence Organization</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wilds: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Lanas</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Stavness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berton</forename><surname>Earnshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imran</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshul</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Kundaje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>Marina Meila and Tong Zhang</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Measuring robustness to natural distribution shifts in image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<idno>2020. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On robustness and transferability of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Romijnders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander D&amp;apos;</forename><surname>Amour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="16458" to="16468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robustbench: a standardized adversarial robustness benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikash</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edoardo</forename><surname>Debenedetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Flammarion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mung</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Mixed precision training,&quot; 2018. 3</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>2015. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>2015. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cifar-10 (canadian institute for advanced research)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The mnist database of handwritten digit images for machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="141" to="142" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>best of the web</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Deep learning for classical japanese literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarin</forename><surname>Clanuwat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asanobu</forename><surname>Kitamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<idno>2018. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Fashionmnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno>2017. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Onnx: Open neural network exchange</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2019. 3</idno>
		<ptr target="https://github.com/onnx/onnx" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On Information and Sufficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03635</idno>
		<title level="m">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Is the skip connection provable to reform the neural network loss landscape?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2020. 6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno>2015. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">tommyod/kdepy: Kernel density estimation in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommy</forename><surname>Odland</surname></persName>
		</author>
		<idno>2018. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">huyvnphan/pytorch cifar10</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Phan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">TensorFlow Datasets</title>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
	<note>Online; accessed 29. Mar. 2022</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Agripredict disease-classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agripredict</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno>2020. 20</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Ghostnet: More features from cheap operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Hardnet: A low memory traffic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Yang</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shan</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Hsiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youn-Long</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Compnet: Complementary segmentation network for brain mri extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raunak</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Hong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<idno>2020. 21</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1921" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hofmanninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forian</forename><surname>Prayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeanny</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>R?hrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Radiology Experimental</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Savvides</surname></persName>
		</author>
		<title level="m">Meal v2: Boosting vanilla resnet-50 to</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Towards robust monocular depth estimation: Mixing datasets for zero-shot crossdataset transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren?</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Lasinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno>2020. 22</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Are these birds similar: Learning branched networks for fine-grained representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Shah Nawaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moreno</forename><surname>Calefati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Caraffini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignazio</forename><surname>Landro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Image and Vision Computing New Zealand (IVCNZ)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Dex: Deep expectation of apparent age from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Rasmus Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision Workshop (ICCVW)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Training deep networks for facial expression recognition with crowd-sourced label distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Barsoum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cristian Canton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno>2016. 22</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<idno>2016. 22</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno>2017. 22</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Ultra-lightweight face detection model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linzaer</surname></persName>
		</author>
		<ptr target="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Yolov3: An incremental improvement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Yolo9000: Better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Yolov4: Optimal speed and accuracy of object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Yuan Mark</forename><surname>Liao</surname></persName>
		</author>
		<idno>2020. 23</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
	<note>Resnest: Split-attention networks,&quot; 2020. 23, 24</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niannan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno>2019. 23</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Understanding convolution for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panqu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrison</forename><surname>Cottrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Real-esrgan: Training real-world blind super-resolution with pure synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangbin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Pre-training without natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokatsu</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazushige</forename><surname>Okayasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asato</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eisuke</forename><surname>Yamagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryosuke</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nakamasa</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akio</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Satoh</surname></persName>
		</author>
		<idno>2020. 23</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Towards achieving adversarial robustness beyond perceptual limits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sravanti</forename><surname>Addepalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurang</forename><surname>Sriramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivangi</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Babu Radhakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2021 Workshop on Adversarial Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Understanding and improving fast adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Flammarion</surname></persName>
		</author>
		<idno>2020. 23</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Adversarial robustness on in-and out-distribution improves explainability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Augustin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Meinke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<idno>2020. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Unlabeled data improves adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<idno>2019. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Efficient robust training via backward smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<idno>2020. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Adversarial robustness: From self-supervised pre-training to fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<idno>2020. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Learnable boundary guided adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno>2021. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">A winning hand: Compressing deep networks can improve out-of-distribution robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Diffenderfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">R</forename><surname>Bartoldson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Chaganti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jize</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavya</forename><surname>Kailkhura</surname></persName>
		</author>
		<idno>2021. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Mma training: Direct input space margin maximization through adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Gavin Weiguang Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kry Yik Chau</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruitong</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Shibani Santurkar, and Dimitris Tsipras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Salman</surname></persName>
		</author>
		<idno>2019. 24</idno>
	</analytic>
	<monogr>
		<title level="j">Robustness</title>
		<imprint/>
	</monogr>
	<note>python library</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<idno>2019. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Uncovering the limits of adversarial training against norm-bounded adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongli</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Using pre-training can improve model robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<idno>2019. 24</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Augmix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<idno>2021. 25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Selfadaptive training: beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2020. 25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">On the effectiveness of adversarial training against common corruptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klim</forename><surname>Kireev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Flammarion</surname></persName>
		</author>
		<idno>2021. 25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Exploring architectural ingredients of adversarially robust deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">Monazam</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<idno>2021. 25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Helper-based adversarial training: Reducing excessive margin to achieve a better accuracy vs. robustness tradeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Rade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed-Mohsen</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2021 Workshop on Adversarial Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Boosting adversarial training with hypersphere embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<idno>2020. 25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Fixing data augmentation to improve adversarial robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">A</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Calian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Stimberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Wiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Overfitting in adversarially robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz</forename><forename type="middle">S</forename><surname>Hafemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Granger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Do adversarially robust imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikash</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Jana</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<title level="m">Hydra: Pruning adversarially robust neural networks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Robust learning meets generative models: Can proxy distributions improve adversarial robustness?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikash</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Mahloujifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinashe</forename><surname>Handina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihui</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mung</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<idno>2021. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Sat: Improving adversarial training via curriculumbased loss smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chawin</forename><surname>Sitawarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supriyo</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<idno>2021. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Improving neural network robustness via persistency of excitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustubh</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Sokolsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Insup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Weimer</surname></persName>
		</author>
		<idno>2021. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Improving adversarial robustness requires revisiting misclassified examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Difan</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Fast is better than free: Revisiting adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Adversarial weight perturbation helps robust generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisen</forename><surname>Shu Tao Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">Theoretically principled trade-off between robustness and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaodong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiantao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">You only propagate once: Accelerating adversarial training via maximal principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Geometry-aware instance-reweighted adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno>2021. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Attacks which do not kill training make adversarial learning stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno>2020. 26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Deepseismic: a deep learning library for seismic interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salvaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaznady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paunic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Karmanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Tok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chikkerur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Misiura</surname></persName>
		</author>
		<idno>2018. 26</idno>
		<ptr target="https://github.com/nekitmm/starnet" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">Stack-gan++: Realistic image synthesis with stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Domain adaptation for privacypreserving pedestrian detection in thermal imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">My</forename><surname>Kieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIAP</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Coscale conv-attentional image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<idno>2021. 27</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Cspnet: A new backbone that can enhance learning capability of cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Yuan Mark</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Hau</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueh-Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping-Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Wei</forename><surname>Hsieh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">Deep layer aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Res2net: A new multi-scale backbone architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Dual path networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Eca-net: Efficient channel attention for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Banggu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Efficientnet-edgetpu: Creating accelerator-optimized neural networks with automl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyog</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-08" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">An energy and gpu-computation efficient backbone network for real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangrok</forename><surname>Joong Won Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuseok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongyoul</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title level="m" type="main">Efficientnetv2: Smaller models and faster training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Alemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Neural architecture design for gpu-efficient networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Gluoncv and gluonnlp: Deep learning in computer vision and natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Lausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Hardcore-nas: Hard constrained differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonathan</forename><surname>Aflalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihi</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<idno>2021. 28</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<idno>2020. 28</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhua</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Mixconv: Mixed depthwise convolutional kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1928" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1928" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Rethinking spatial dimensions of vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongho</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong Joon</forename><surname>Oh</surname></persName>
		</author>
		<idno>2021. 29</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title level="m" type="main">Tensorflowslim image classification model library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<idno>2016. 29</idno>
		<ptr target="https://github.com/tensorflow/models/tree/master/research/slim" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno>2020. 29</idno>
		<imprint/>
	</monogr>
	<note>Kaiming He, and Piotr Doll?r</note>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Repvgg: Making vggstyle convnets great again</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>2021. 29</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Revisiting resnets: Improved training and scaling strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<idno>2021. 30</idno>
	</analytic>
	<monogr>
		<title level="m">Jonathon Shlens, and Barret Zoph</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title level="m" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Rethinking channel dimensions for efficient model design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongho</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Yoo</surname></persName>
		</author>
		<idno>2021. 30</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Xnect: Real-time multi-person 3d motion capture with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elgharib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno>2020. 30</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">Selective kernel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<idno>2019. 30</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">Single-path nas: Designing hardware-efficient convnets in less than 4 hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Stamoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Lymberopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodhi</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename></persName>
		</author>
		<idno>2019. 30</idno>
		<imprint>
			<date>Marculescu</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Billion-scale semi-supervised learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Zeki</forename><surname>Yalniz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<idno>2019. 30</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Adversarial examples improve image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title level="m" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<idno>2017. 31</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">Visformer: The vision-friendly transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengsu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longhui</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno>2021. 31</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">Model rubik&apos;s cube: Twisting resolution, depth and width for tinynets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiulin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1931" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Twins: Revisiting the design of spatial attention in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxia</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Learning a discriminative feature network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
		<idno>2018. 32</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title level="m" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno>2017. 32</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<title level="m" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Squeezenet: Alexnet-level accuracy with 50x fewer parameters and ?0.5mb model size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><forename type="middle">N</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Moskewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Ashraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<idno>2016. 32</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">On the limits of cross-domain generalization in automated x-ray prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Paul Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hashir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupert</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadrien</forename><surname>Bertrand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Yolov5</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ultralytics</surname></persName>
		</author>
		<idno>2020. 33</idno>
		<ptr target="https://github.com/ultralytics/yolov5" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
