<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DC-GNet: Deep Mesh Relation Capturing Graph Convolution Network for 3D Human Shape Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<postCode>361005</postCode>
									<settlement>Xiamen, Fujian Province</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxi</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<postCode>361005</postCode>
									<settlement>Xiamen, Fujian Province</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Cai</surname></persName>
							<email>sscai@stu.xmu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<postCode>361005</postCode>
									<settlement>Xiamen, Fujian Province</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Lei</surname></persName>
							<email>yqlei@xmu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<postCode>361005</postCode>
									<settlement>Xiamen, Fujian Province</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DC-GNet: Deep Mesh Relation Capturing Graph Convolution Network for 3D Human Shape Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>3D human shape reconstruction</term>
					<term>Graph Convo- lution Network</term>
					<term>Deep mesh relation capturing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we aim to reconstruct a full 3D human shape from a single image. Previous vertex-level and parameter regression approaches reconstruct 3D human shape based on a pre-defined adjacency matrix to encode positive relations between nodes. The deep topological relations for the surface of the 3D human body are not carefully exploited. Moreover, the performance of most existing approaches often suffer from domain gap when handling more occlusion cases in real-world scenes.</p><p>In this work, we propose a Deep Mesh Relation Capturing Graph Convolution Network, DC-GNet, with a shape completion task for 3D human shape reconstruction. Firstly, we propose to capture deep relations within mesh vertices, where an adaptive matrix encoding both positive and negative relations is introduced. Secondly, we propose a shape completion task to learn prior about various kinds of occlusion cases. Our approach encodes mesh structure from more subtle relations between nodes in a more distant region. Furthermore, our shape completion module alleviates the performance degradation issue in the outdoor scene. Extensive experiments on several benchmarks show that our approach outperforms the previous 3D human pose and shape estimation approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>3D human pose and shape estimation is a fundamental yet challenging task in computer vision. There are plenty of approaches proposed to accurately capture 2D pose and even 3D joint locations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>. Since sparse joints alone cannot provide enough information for analyzing humans <ref type="bibr" target="#b21">[22]</ref>, incremental recent works interest in recovering the 3D mesh of a human body, where the 3D surface is defined.</p><p>To obtain 3D mesh for a human being in an image, optimizationbased approaches generate a reliable human body fitting <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">Figure 1</ref>. Illustration of different strategies to reason local structure. (a) Previous popular approaches are based on a pre-defined adjacency matrix that encodes only positive relations with physically connected nodes. (b) Our approach learns deep relations (i.e., positive and negative) between nodes in a more distant region. The inference node, positively related node and negatively related node are shown in the black, red and blue circle, respectively. The solid line denotes a positive relationship, while the dashed line denotes a negative relationship. <ref type="bibr" target="#b24">25</ref>]. Unfortunately, their slow inference speed and sensitivity to initialization have shifted the focus to regressionbased approaches, which directly regresses mesh coordinates <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b50">51]</ref> or the parameters <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref> of the human body model (e.g., SCAPE <ref type="bibr" target="#b1">[2]</ref> and SMPL(-X) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40]</ref>). Although regression-based methods achieve clear performance improvement in constrained environments, there are still limitations hinders better performance under the real scenario.</p><p>Firstly, most of existing regression-based approaches including vertex-level regression approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22]</ref> and parameter regression approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b36">37]</ref> are based on a fixed adjacency matrix to encode the inherent shape nodes relations, which ignores deep relations between shape nodes and focus only on physically connected nodes, as shown in <ref type="figure">Figure 1(a)</ref>. As a result, models often can not fully explore the spatial relations within the human body, which owns a highly related structure.  <ref type="figure">Figure 2</ref>. Visualization of the different adjacency matrix. (a) A pre-defined adjacency matrix with encoding only positive relations between physically connected nodes. (b) Our adjacency matrix learns subtle relations (i.e., positive and negative) between nodes in a more distant region.</p><p>Previous works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b56">57]</ref> attempt to explore a joint-to-joint topological structure for skeleton joints in the 3D pose estimation task. However, compared to the 3D pose estimation task with skeleton representation, a full 3D human shape reconstruction task needs to infer node-to-surface relations rather than a simple joint-to-joint. Thus, these approaches cannot be applied directly to the 3D shape estimation. To the best of our knowledge, exploiting the deep topological relations for the surface of the 3D human body is an unexplored yet important problem to the current 3D human shape reconstruction approaches.</p><p>Secondly, the full human body information is usually difficult to obtain in real scenarios due to various occlusions. Existing 3D annotation datasets that are collected in the limited indoor environment not carefully simulate such cases of body partially missing, which forms a gap issue of appearance domain (i.e., the performance degradation in real-world scenes). Therefore, the generalization of existing shape reconstruction approaches trained on indoor 3D data are often poor when handling with more occlusion cases in real-world scenes, resulting in the performance degradation.</p><p>In this paper, to alleviate the above issues, we propose a Deep Mesh Relation Capturing Graph Convolution Network, namely DC-GNet, with a shape completion task. Firstly, to capture deep relation among mesh vertexes of body shape, we impose an adaptive adjacency matrix to learn both positive and negative relationships between nodes in a more distant region, as shown in <ref type="figure">Figure 2</ref>(b). Base on this learnable matrix, our network can aggregate subtle information from not only physically connected nodes but also nodes with long-distance, as shown in <ref type="figure">Figure 1</ref></p><formula xml:id="formula_0">(b).</formula><p>Secondly, we propose a shape completion task to alleviate the gap issue of appearance domain. Specifically, we first fabricate artificial holes on the surface of the training body shape data. Then, we force the network to recover a full body shape to learn prior about various kinds of human body part missing case. The overview of our approach is shown in <ref type="figure">Figure 3</ref>. Concretely, our network is started with the initial estimation, which is the feature extraction stage. In the pretrain process, the image features are inputted into DC-GNet with the proposed shape completion task, where the network learns the prior for occlusion cases. This network is further trained in the main inference process for the 3D human shape estimation.</p><p>Extensive evaluated experiments are conducted on several public benchmarks <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b30">31]</ref>, and the results show that our proposed approach outperforms the previous state-of-the-art 3D pose and shape estimation methods. Moreover, qualitative results on in-the-wild datasets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27]</ref> show that our approach has learned better representation and generalization ability through making better use of the topology structure of the human body.</p><p>We summarize our contributions as follows:</p><p>? We propose a Deep Mesh Relation Capturing Graph Convolution Network, DC-GNet, to reconstruct 3D human shape from a single RGB image. It is the first attempt to learn deep relations between nodes among human mesh vertices and consider reasoning from more than partial structure, which boosts the model capturing complex local deformation. ? We first propose a shape completion module as an auxiliary task to alleviate the appearance domain gap issue between indoor and outdoor scenes, and thus our model can benefit from the rich indoor data source to learn the inference paradigm that can be well applied in natural environments. ? Extensive experimental results across several benchmarks demonstrate the effectiveness of exploring deep relations among mesh vertices, through comparing with the previous state-of-the-art 3D human shape reconstruction methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Although numerous approaches have been proposed to boost the topic of 3D pose estimation in the form of a skeleton in the last few years <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b61">62]</ref>, we will focus on closely-related works reconstructing the whole shape and pose in this Section <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b46">47</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">3D Human Pose and Shape Estimation</head><p>Instead of a skeleton, recovering the shape of human body is a more challenging task. Bogo et al. <ref type="bibr" target="#b4">[5]</ref> firstly introduced the fully automatic model-based approach, SMPLify, to estimate 3D human shape and pose from 2D pose by fitting a classical human body model SMPL. After that, Lassner et al. <ref type="bibr" target="#b24">[25]</ref> applied SMPLify for building a dataset with fairly successful 3D fits. Beyond SMPLify, many different model-based approaches were proposed to explore including adversarial prior <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20]</ref>, temporal information <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18]</ref>, or even dealing with multiple humans <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b53">54]</ref>. More recently, instead of predicting parameters of the model, model-free methods <ref type="figure">Figure 3</ref>. Overview of DC-GNet. The workflow contains three parts, a feature extraction stage to generate the initial graph from a single image, a pretrain process to learn an adaptive graph with a shape completion task and the main inference phase to reconstruct the 3D mesh.</p><p>that directly regress each vertex were proposed to avoid representation issues <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b36">37]</ref>. Venkat et al. <ref type="bibr" target="#b49">[50]</ref> captured the local deformation by learning the "implicitly structure" of human mesh. Similarly, Kolotouros et al. <ref type="bibr" target="#b21">[22]</ref> directly regressed the vertices of a template mesh to explore the topological structure explicitly. Moon and Lee <ref type="bibr" target="#b31">[32]</ref> proposed an imageto-lixel network to model the prediction uncertainty for each mesh vertex. More interesting, many works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b60">61]</ref> tried to obtain clothed mesh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Convolution Network for 3D shape Reconstruction</head><p>Recently, there has been a surge of approaches considering Graph Convolution Network(GCN) for capturing the graph structure of mesh, due to the graph-like nature of human mesh. Choi et al. <ref type="bibr" target="#b6">[7]</ref> recovered 3D mesh from the 2D input with GCN in a coarse-to-fine fashion. Kolotouros et al. <ref type="bibr" target="#b21">[22]</ref> explored mesh structure and leveraged spatial locality via applying GCN to directly regress the vertices of the SMPL model. Hugo et al. <ref type="bibr" target="#b12">[13]</ref> proposed to generate 3D clothed human with graph convolution variational Auto-Encoder (GC-VAE). Simultaneously, some works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b49">50]</ref> intended to deal with mesh vertices as point clouds for capturing deformation.</p><p>Similarly, we also adopt GCN to process the mesh structure. Different from previous approaches, instead of simply applying convolution operation to aggregate information from direct neighbors, we incorporate an adaptive adjacent matrix to obtain local structure from both physically connected nodes and distant ones with deep relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relations Capture via Learnable Adjacency</head><p>Matrix The adjacency matrix is a necessary component in GCN. In the 3D shape Reconstruction task, existing regression-based approaches usually use a pre-defined adjacency matrix, in which only positive relations between physically connected nodes are encoded. Such a pre-defined adjacency matrix is not able to capture complex local surface deformation, as shown in <ref type="figure">Figure 1</ref>(a). Replacing a pre-defined adjacency matrix with learnable ones is a common strategy in the other GCN-based computer vision applications, such as skeleton estimation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b56">57]</ref> or action recognition task <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b52">53]</ref>. These works use different updating strategies to learn adjacency matrix for different purposes. Zhao et al. <ref type="bibr" target="#b56">[57]</ref> learns adjacent matrix for describing subtle semantic relations within human skeleton joints. Doosti et al. <ref type="bibr" target="#b7">[8]</ref> keeps the connectivity of the graph structure in joint hand and object pose estimation task. Against the action recognition task, Yan et al. <ref type="bibr" target="#b52">[53]</ref> captures the body skeletons dynamics information to meet the specific demands in skeleton modeling. Shi et al. <ref type="bibr" target="#b43">[44]</ref> learns the topology structure of the graph and skeleton samples for the flexibility of model.</p><p>These strategies only focus on joint-to-joint relations, which can not capture the node-to-surface relations existing in a full 3D human shape reconstruction task. In this paper, against the 3D shape reconstruction, we first propose a novel updating strategy for the learnable adjacency matrix to explore node-to-surface relations. network is applied as a feature extractor and outputs a 2048-D feature vector for every single vertex in the graph.</p><p>Our network is started with the initial estimation, which is the feature extraction stage shown in the <ref type="figure">Figure 3</ref>.</p><p>Previous approaches had already adopted GCN to process graph-like human mesh. The network is composed of basic graph convolution operations <ref type="bibr" target="#b18">[19]</ref>, which is defined as:</p><formula xml:id="formula_1">= ( ),<label>(1)</label></formula><p>where ? R ? is a pre-defined adjacency matrix of the graph,</p><formula xml:id="formula_2">= { } =1 ? R ? is the input feature matrix, ? R ?? is the trainable weight matrix,</formula><p>? R ?? is the output feature matrix, and is the activation function. Specifically, is nodes of the input graph, and ? are the input features and output features for each node, separately.</p><p>The graph convolution described in Eq. <ref type="formula" target="#formula_1">(1)</ref> is calculated based on a pre-defined adjacency matrix, which only encodes positive relations between physically connected nodes. As a result, the complex local structure can not be carefully captured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Approach</head><p>In this Section, we present our approach. First, in Subsection 4.1, we describe the proposed network for obtaining effectively local structure information.</p><p>Next, in Subsection 4.2, we describe our proposed shape completion task that alleviates the gap issue of appearance domain. Finally, Subsection 4.3 present the loss functions that we used for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Relations Capture for the 3D Shape</head><p>Reconstruction Instead of using a pre-defined adjacency matrix, we propose to use an adaptive adjacency matrix to learn subtle relationships between nonadjacent nodes. To achieve this, we rewrite Eq. (1) as:</p><formula xml:id="formula_3">= (^).<label>(2)</label></formula><p>where^= + is a learnable adjacency matrix. is the identity matrix. Based on Eq. (2), our network is able to infer local structure from nodes with subtle relations in a more distant region. Specifically, not only relations between <ref type="figure">Figure 5</ref>. Illustration of the proposed shape completion task.</p><p>With an initial mesh as input, we fabricate artificial holes on the surface of mesh. In order to recover the missing information, the network is forced to reason from the neighborhood in a more distant region. Moreover, we highlight the same part during different phases to show the effectiveness of this module.</p><p>nodes belong to the same semantic part (e.g., nodes on arm and elbow that belong to the same limb can be leveraged for inference), but nodes with far distance (e.g., one node on the left elbow can be related to the node on the right elbow) are encoded into the network. Moreover, following <ref type="bibr" target="#b5">[6]</ref>, we introduce a non-local block <ref type="bibr" target="#b51">[52]</ref> to facilitate a holistic processing of the full body. By training the network with Eq. (2), we can obtain a learnable adjacency matrix. However, such stacking of the convolution operation with adaptive adjacency matrix requires the expensive training computational cost. Therefore, we design a classical hierarchical U-shaped network architecture including encoder and decoder parts, to simplify the calculations and achieve our shape reconstruction pipeline.</p><p>In the encoder part, we introduce sampling operations <ref type="bibr" target="#b38">[39]</ref> to simplify the calculations. The process of the encoder part can be formulated as:</p><formula xml:id="formula_4">= ( ?1 ),<label>(3)</label></formula><p>where ? R?? ? is the processed feature matrix with? odes, and demonstrates a fully-connected layer. ? {1, 2, ... ? <ref type="table">Table 1</ref>. Comparison on Human3.6M (Protocol 1 and 2) of our proposed approach with different components (i.e., adaptive adjacency matrix and U-shaped Net, denoted as A and U separately). The numbers are MPJEP and mean reconstruct errors in mm. We conduct experiments with several models using CMR <ref type="bibr" target="#b21">[22]</ref> and HMR <ref type="bibr" target="#b16">[17]</ref> as the pretrained feature extractors. Best results are in bold. 1, , + 1, ..., ? 1, } is the -th layer of the network. Indeed, by downsampling the mesh data with a pre-defined factor, the high redundancy in the original scale and memory requirements are both dramatically reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In the decoder part, we combine the features to boost the understanding of human body in a coherent way. Similarly, we can denote the decoder part as:</p><formula xml:id="formula_5">+1 = ( [ ( ); ( ( 1 , ..., )); ? ]),<label>(4)</label></formula><p>where +1 is a linear combination of above three parts, ( 1 , ..., ) = =1 ( ) denotes the feature obtained from our feature fusion module, and ? is the previous feature in each level of the encoder part in symmetrical module of the decoder part. More specifically, represents concatenation connection, ? R???is the calculated attention coefficients matrix and ? R ?? is a shared linear transformation towards features for each node, which are detailed described in <ref type="bibr" target="#b48">[49]</ref>.</p><p>Essentially, the modeling of the decoder part formulated by Eq. (4) explicitly fuse multi-level topology information, which alleviates the semantic gap and different spatial resolution <ref type="bibr" target="#b37">[38]</ref>. In the process of the decoder part, the body shape is gradually refined when more features are fused, as visualized in <ref type="figure" target="#fig_1">Figure 4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Shape Completion Task</head><p>Due to various complex occlusions (e.g.,self-occlusion or be sheltered) in an in-the-wild scenario, the human body part information is often missing. Since the training data are collected from simple human actions in a clear indoor environment, the information missing issue is rare. In order to enable the network to learn a generic adjacency matrix for various occlusion cases, we propose a shape completion task in which a mask off and a reconstruction part are included, as shown in <ref type="figure">Figure 5</ref>.</p><p>In the mask off part, we simulate the occlusion cases by fabricating artificial holes on the surface of the initial human mesh. Specifically, we randomly mask the partial mesh information of a given full human mesh, which can be formulated as^=</p><formula xml:id="formula_6">? ,<label>(5)</label></formula><p>where^denotes a masked human mesh. ? R ? is a matrix of ones except row set zeros, and randomly shuffled before dot product.</p><p>Then, to force the network to recover the missing information for the masked human mesh, we replace the in Eq. (2) as a marked human mes? , = (^^).</p><p>Note that in Eq. (6), the output of the network is settled as the initial full human mesh .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Loss Functions</head><p>We use three loss functions to train our network. We first calculate per-vertex 1 loss between the estimated and ground truth shape, which is denoted as L . Additionally, we include joint-wise loss for further aligning mesh with keypoints. Specifically, we implement 1 losses between the projected coordinates and the ground truth keypoints in 2D and 3D space ( 2 and 3 ). Finally, the complete training objective is:</p><formula xml:id="formula_8">L = L + L 3 + L 2<label>(7)</label></formula><p>We provide a more detailed description of the loss function in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>In this Section, we concern with the experimental analysis of the proposed approach. First, we present the datasets that we  use for evaluation (Section 5.1) and the implementation details of the proposed pipeline (Section 5.2). Then, we discuss the comparison approaches (Section 5.3) and ablation studies (Section 5.4). Finally, comparison with the-state-of-the-art approaches (Section 5.5) and qualitative analysis (Section 5.6) are provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Evaluation Metrics</head><p>Datasets. In this paper, we present extensive experiments of our approach on several standard benchmarks including Hu-man3.6M <ref type="bibr" target="#b13">[14]</ref>, UP-3D <ref type="bibr" target="#b24">[25]</ref>, MPI-INF-3DHP <ref type="bibr" target="#b30">[31]</ref>, COCO <ref type="bibr" target="#b26">[27]</ref> and LSP <ref type="bibr" target="#b15">[16]</ref>. For training, we apply benchmarks with 3D annotations, including Human3.6M, UP-3D and MPI-INF-3DHP. Additionally, similar to <ref type="bibr" target="#b20">[21]</ref>, we incorporate other 2D datasets, i.e., COCO and LSP. For evaluation, we use MPI-INF-3DHP and Human3.6M. For the evaluation on Human3.6M, two popular evaluation protocols can be found. The first one, denoted as P1, includes the subjects S1, S5, S6, S7 and S8 for training, and the subjects S9 and S11 for testing. The second protocol, denoted as P2, tests only on the frontal camera with the same train/test sets. A more detailed description of the datasets can be found in the supplementary material. Evaluation Metrics. For the MPI-INF-3DHP and Hu-man3.6M datasets, following the evaluation in the most approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b54">55]</ref>, we report Mean Per Joint Position Error (MPJPE) and mean reconstruct error. MPJPE is defined as 3D joint errors, which are the projected coordinates from mesh data. While mean reconstruct error is the same calculation with MPJPE but with a rigid alignment. For MPI-INF-3DHP, in addition to MPJPE and mean reconstruct error, we further report Area Under the Curve (AUC) over a range of Percentage of Correct Keypoints (PCK) thresholds <ref type="bibr" target="#b30">[31]</ref>, which are also used in many approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b47">48]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>Our model is implemented with PyTorch <ref type="bibr" target="#b33">[34]</ref>. As shown in <ref type="figure">Figure 3</ref>, we first train our network with a shape completion task, and then in the second step we train the model in an end-to-end fashion. Noted the network trained with shape completion task shares the parameters with the model in the main inference process. In each stage, following <ref type="bibr" target="#b21">[22]</ref> we subsample original mesh by a factor of 4 and upsample it back at the end of the network with <ref type="bibr" target="#b38">[39]</ref>. For the training process, we utilize Adam optimizer with a mini-batch size of 16, where the learning set is set to 3e-4. In the pre-trained process, only Human3.6M dataset is used, while in the main inference process, we first train our model from Human3.6M and UP-3D for 30 epochs and then impose more data (i.e., COCO, MPI-INF-3DHP, etc.) for greater image diversity. We use a single NVIDIA RTX 2080 Ti GPU for training and our model inference for a single image takes 55ms (including time (33ms) for feature extractor), which is nearly real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison Approaches</head><p>Following the common-used comparison setting in the literature <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b54">55]</ref>, we first compare with two recent baselines for regression-based approaches (the vertex-level regression and parameter regression approaches, i.e. HMR <ref type="bibr" target="#b16">[17]</ref> and CMR <ref type="bibr" target="#b21">[22]</ref>). As mentioned earlier, both the above two approaches are based on a pre-defined adjacency matrix. Moreover, several of recent state-of-the-art methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>, are considered in the comparison, including vertex-level regression approaches <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b54">55]</ref> and parameter regression ones <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Studies</head><p>Firstly, to put our approach into perspective, we conduct ablation studies on our approach. Following the literature <ref type="bibr" target="#b19">[20]</ref>, we also use two pre-trained feature extractors CMR <ref type="bibr" target="#b21">[22]</ref> and HMR <ref type="bibr" target="#b16">[17]</ref>, respectively. We construct three different settings: (a) U-shaped network without adjacency matrix. (b) Only adaptive adjacency matrix (without sampling and features fusion operations). (c) U-shaped network with an adaptive adjacency matrix. These three settings are denoted as "U", "A", and "U+A" in the comparison. The ablation experiments results are reported in <ref type="table">Table 1</ref>, in which the results are organized into two groups in terms of two different feature extractors.</p><p>Since the adaptive adjacency matrix captures the topological structure of human body. It significantly improves the reconstruction performance, as we observed in the <ref type="table">Table 1</ref>. The proposed U-shaped network also boosts the performance due to the better understanding of human body in a coherent way. The best result is always achieved by "U+A" setting whichever feature extractor is used. <ref type="figure" target="#fig_3">Figure 6</ref> visualizes the learned adjacency matrix. It shows that deep relations between nodes (i.e., positive and negative) are encoded.  <ref type="figure">Figure 10</ref>. Comparison between our approach and other parameter regression methods.</p><p>Moreover, we also study the effectiveness of the proposed shape completion task. In the experiment, we train different networks with different number of nodes that are masked off on Human3.6M and UP-3D datasets, and evaluate on MPI-INF-3DHP. The results are obtained by using CMR <ref type="bibr" target="#b21">[22]</ref> as a feature extractor. Since the different number of masked nodes leads to different performance, we set the number of masked nodes as 0, 50, 100, 200, 400. As we clearly observed in <ref type="table" target="#tab_1">Table 2</ref>, with the number of masked nodes increases from 0 to 200, the performance also begins to increase, which demonstrates the effectiveness of the shape completion task. We observe degradation occurs when the number of masked nodes is settled at 400, which may exceed the ability to recover mesh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison to State-of-the-Art Results</head><p>We report MPJPE and mean reconstruct error of DC-GNet on Human3.6M, and additionally AUC over a range of 3D-PCK thresholds (150mm) on MPI-INF-3DHP. For the fair comparison, following the same setting in the literature <ref type="bibr" target="#b19">[20]</ref>, we use HMR as a feature extractor pretrained by <ref type="bibr" target="#b20">[21]</ref>.</p><p>We first conduct a comparable result on the challenging in-the-wild MPI-INF-3DHP dataset. As shown in <ref type="table" target="#tab_2">Table 3</ref>, comparing to the baseline methods, DC-GNet achieves more than 21% (HMR) and 36% (CMR) improvement on average MPJPE, respectively. Similarly, more than 30% (HMR) and 25% (CMR) improvements are achieved by ours on average reconstruct error. Compared to other considered approaches, we still achieve the best performance in all metrics. It seems that our model only achieves sightly performance improvement than <ref type="bibr" target="#b19">[20]</ref> under MPJPE, note that it exploits video temporal information while we use only a single image.</p><p>In the Human3.6M dataset, DC-GNet still shows its superiority. As shown in <ref type="table" target="#tab_2">Table 3</ref>, DC-GNet outperforms the baseline approaches with a wide margin (more than 25% (HMR) and 15% (CMR) improvement on reconstruction error metric). It seems that our approach is sightly inferior to approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b54">55]</ref>. Note that Human3.6M is an indoor dataset with pre-defined action categories in both train and test sets. As analyzed by <ref type="bibr" target="#b6">[7]</ref>, the performance drop (i.e., performs well on Human3.6M while meets degradation on the in-the-wild dataset) may be attributed to an overfitting issue.</p><p>Note that different methods are trained with different training data. Detailed training data comparisons can be found in the supplementary material. To show the superiority of our approach, we compare their best results reported in the original literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Qualitative Evaluation</head><p>This section presents qualitative evaluations. In the qualitative experiments, following the same strategy in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, we leverage Mosh <ref type="bibr" target="#b27">[28]</ref> and SPIN <ref type="bibr" target="#b20">[21]</ref> to generate pseudogroundtruth on Human3.6M and in-the-wild datasets, respectively.</p><p>Firstly, we conduct the qualitative results of our approach from different datasets. The success and failure cases are also reported, as shown in <ref type="figure" target="#fig_4">Figure 7</ref> and <ref type="figure" target="#fig_5">Figure 8</ref>, respectively. Typical failure cases may be caused by severe occlusions, rare view-point, or interactions among multiple people.</p><p>Moreover, we further provide a qualitative comparison with the recent competitive vertex-level regression approaches (i.e., CMR <ref type="bibr" target="#b21">[22]</ref> and DecoMR <ref type="bibr" target="#b54">[55]</ref>) and parameter regression approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref>, as shown in <ref type="figure" target="#fig_6">Figure 9</ref> and <ref type="figure">Figure 10</ref>, respectively. As shown in the <ref type="figure" target="#fig_6">Figure 9</ref>, compared to vertex-level regression approaches, DC-GNet generates much more pleasant mesh results that reconstruct details and retain the whole topological structure.</p><p>We further report qualitative comparisons with the parameter representation, as shown in <ref type="figure">Figure 10</ref>. We also achieve more reasonable reconstruction results. Note that CMR and our approach are vertex-level regression approaches while they can also be implemented as a parameter regression by using Multi-Layer Perceptron (MLP) <ref type="bibr" target="#b40">[41]</ref>.</p><p>More qualitative results can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The aim of this paper is to explore deep relation among mesh vertices for 3D human pose and shape reconstruction, by encoding both positive and negative relations. We incorporate these relations into a graph convolution network with a shape completion module for complex topological structure learning cross domain. Moreover, the comparison with a series of state-of-the-art approaches shows the superiority of our approach. More specifically, the extensive experiments conducted on wild datasets demonstrate that the proposed strategies are crucial to make our approach of practical use for in-the-wild scene. Future work may explore using denser cues (e.g., video input or optical flow) and consider extending our approach for multiple people.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2108.12384v1 [cs.CV] 27 Aug 2021</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of the mesh from different layers in the decoder part of the U-Net. The refining process generates the final prediction from a coarse graph by adding nodes (the green hollow circle).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Examples of the learned adjacency matrix. For each column, the images from top-to-bottom correspond to the visualization of the learned matrix, the surface plot of the matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Examples of successful reconstructions. COCO (row 1), H36M (row 2) and MPI-INF-3DHP (row 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Examples of erroneous reconstructions. Typical failure cases may be caused by severe occlusions, rare viewpoint, or interactions among multiple people.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Comparison between our approach and other vertex-level regression methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison on MPI-INF-3DHP of our proposed Shape Completion task with different configurations. The numbers are PCK, AUC, and MPJEP in mm. We conduct experiments with CMR<ref type="bibr" target="#b21">[22]</ref> as pretrained feature extractor. We report results with the different number of nodes that are masked off. Best results are in bold.</figDesc><table><row><cell>Method</cell><cell cols="3">Absolute PCK ? AUC ? MPJPE ?</cell></row><row><cell cols="2">w/o Shape Completion 62.2</cell><cell>25.0</cell><cell>136.2</cell></row><row><cell>Mask off -50</cell><cell>63.3</cell><cell>25.6</cell><cell>134.6</cell></row><row><cell>Mask off -100</cell><cell>64.0</cell><cell>27.9</cell><cell>131.3</cell></row><row><cell>Mask off -200</cell><cell>66.3</cell><cell>30.4</cell><cell>128.5</cell></row><row><cell>Mask off -400</cell><cell>64.6</cell><cell>28.7</cell><cell>129.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparison with state-of-the-art models on MPI-INF-3DHP and Human3.6M datasets (P2). The numbers are MPJEP and mean reconstruct errors in mm, and AUC. DC-GNet achieves a comparable result on Human3.6M dataset and beyond all state-of-the-art approaches on more challenging in-the-wild MPI-INF-3DHP dataset. "-" means the corresponding results are not available. ? indicates that extra temporal infromation is leveraged. Best results are in bold.</figDesc><table><row><cell>Method</cell><cell>AUC ?</cell><cell cols="2">MPI-INF-3DHP MPJPE ? Reconst.Error ?</cell><cell>MPJPE ?</cell><cell>Human3.6M Reconst.Error ?</cell></row><row><cell>HMR [17] (CVPR'18)</cell><cell>36.5</cell><cell>124.2</cell><cell>89.8</cell><cell>-</cell><cell>56.8</cell></row><row><cell>?HMMR [18] (CVPR'19)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>56.9</cell></row><row><cell>?Arnab et al. [3] (CVPR'19)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>77.8</cell><cell>54.3</cell></row><row><cell>CMR [22] (CVPR'19)</cell><cell>24.3</cell><cell>152.0</cell><cell>83.8</cell><cell>71.9</cell><cell>50.1</cell></row><row><cell>?TexturePose [36] (ICCV'19)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>49.7</cell></row><row><cell>SPIN [21] (ICCV'19)</cell><cell>37.1</cell><cell>105.2</cell><cell>67.5</cell><cell>-</cell><cell>41.1</cell></row><row><cell>DaNet [56] (ACM MM'19)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>61.5</cell><cell>48.6</cell></row><row><cell>Jiang et al. [15] (CVPR'20)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>52.7</cell></row><row><cell>Kundu et al. [24] (ECCV'20)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>48.1</cell></row><row><cell>Pose2Mesh [7] (ECCV'20)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>64.9</cell><cell>47.0</cell></row><row><cell>?VIBE [20] (CVPR'20)</cell><cell>-</cell><cell>97.7</cell><cell>63.4</cell><cell>65.9</cell><cell>41.5</cell></row><row><cell>DecoMR [55] (CVPR'20)</cell><cell>-</cell><cell>102.0</cell><cell>65.9</cell><cell>60.6</cell><cell>39.3</cell></row><row><cell>DC-GNet</cell><cell>40.7</cell><cell>97.2</cell><cell>62.5</cell><cell>63.9</cell><cell>42.4</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Problem SetupOur input is a cropped image, which is centered around a person. For each input image, an image-based convolutional</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the National Natural Science Foundation of China (Grant no 61671397).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human Pose Estimation: New Benchmark and State of the Art Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3686" to="3693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SCAPE: Shape Completion and Animation of People</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="408" to="416" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting temporal context for 3D human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename><surname>Anurag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">*</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3395" to="3404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Bharat Lal Bhatnagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting Spatial-Temporal Relationships for 3D Pose Estimation via Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2272" to="2281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsuk</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">HOPE-Net: A Graph-Based Model for Hand-Object Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bardia</forename><surname>Doosti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujon</forename><surname>Naha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Mirbagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6608" to="6617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compressed Volumetric Heatmaps for Multi-Person 3D Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Alletto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7204" to="7213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Moulding Humans: Nonparametric 3D Human Shape Estimation from Single Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Gabeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-S?bastien Franco</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2232" to="2241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">HoloPose: Holistic 3D Human Reconstruction In-The-Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10884" to="10894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DeepCap: Monocular Human Performance Capture Using Weak Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Habermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zollhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5052" to="5063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CLOTH3D: Clothed 3D Humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertiche</forename><surname>Hugo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madadi</forename><surname>Meysam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Escalera</forename><surname>Sergio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sminchisescu</surname></persName>
		</author>
		<title level="m">Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments. Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coherent Reconstruction of Multiple Humans From a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5579" to="5588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<idno>1-12.11</idno>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">End-to-end Recovery of Human Shape and Pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7122" to="7131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning 3D Human Dynamics From Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5607" to="5616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">VIBE: Video Inference for Human Body Pose and Shape Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5252" to="5262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2252" to="2261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Convolutional Mesh Regression for Single-Image Human Shape Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4501" to="4510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Depth Sweep Regression Forests for Estimating 3D Human Pose from Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Appearance Consensus Driven Self-Supervised Human Mesh Recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unite the People: Closing the Loop Between 3D and 2D Human Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4704" to="4713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating Multiple Hypotheses for 3D Human Pose Estimation With Mixture Density Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9887" to="9895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common Objects in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">MoSh: Motion and Shape Capture from Sparse Markers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2014-11" />
		</imprint>
	</monogr>
	<note>Article</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SMPL: A Skinned Multi-Person Linear Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2015-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Simple Yet Effective Baseline for 3d Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2659" to="2668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Monocular 3D Human Pose Estimation In The Wild Using Improved CNN Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">I2L-MeshNet: Imageto-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="484" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems Workshop</title>
		<imprint>
			<publisher>NIPSW</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Expressive Body Capture: 3D Hands, Face, and Body From a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10967" to="10977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tex-turePose: Supervising Human Mesh Estimation with Texture Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="803" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to Estimate 3D Human Pose and Shape from a Single Color Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuebin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masood</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osmar</forename><surname>Zaiane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">107404</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generating 3D Faces Using Convolutional Mesh Autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soubhik</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="725" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Embodied Hands: Modeling and Capturing Hands and Bodies Together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/3130800.3130883</idno>
		<idno>245:1-245:17</idno>
		<ptr target="http://doi.acm.org/10.1145/3130800.3130883" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning Internal Representations by Error Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="318" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">3D Human pose estimation: A review of the literature and analysis of covariates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Sarafianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Boteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><forename type="middle">A</forename><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2325" to="2334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12018" to="12027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Gaussian process guided particle filter for tracking 3D human pose in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sedai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="4286" to="4300" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep High-Resolution Representation Learning for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Human Mesh Recovery From Monocular Images via a Skeleton-Disentangled Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yili</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5349" to="5358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deeply Learned Compositional Models for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">HumanMeshNet: Polygonal Mesh Recovery of Humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbhinav</forename><surname>Venkat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yudhik</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshop</title>
		<imprint>
			<publisher>ICCVW</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2178" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sequential 3D Human Pose and Shape Estimation From Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7273" to="7282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Abhinav Gupta, and Kaiming He</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
	<note>Non-Local Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence(AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7444" to="7452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Monocular 3D Pose and Shape Estimation of Multiple People in Natural Scenes -The Importance of Multiple Scene Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2148" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">3D Human Mesh Regression With Dense Correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7052" to="7061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">DaNet: Decompose-and-Aggregate Network for 3D Human Shape and Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenan</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<publisher>ACM MM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="935" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Semantic Graph Convolutional Networks for 3D Human Pose Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3425" to="3435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">HEMlets Pose: Learning Part-Centric Heatmap Triplets for Accurate 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianjuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2344" to="2353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Towards Locality Similarity Preserving to 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qicong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ACCV 2020 Workshops</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="136" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">MonoCap: Monocular Human Motion Capture using a CNN Coupled with a Geometric Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="901" to="914" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Spyridon Leonardos, Konstantinos G Derpanis, and Kostas Daniilidis</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Detailed Human Shape Estimation From a Single Image by Hierarchical Mesh Deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4491" to="4500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The stitched puppet: A graphical model of 3D human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3537" to="3546" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
