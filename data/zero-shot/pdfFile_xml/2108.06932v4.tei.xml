<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Dong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinpeng</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huazhu</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
						</author>
						<title level="a" type="main">Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T11:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Polyp segmentation</term>
					<term>pyramid vision trans- former</term>
					<term>colonoscopy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most polyp segmentation methods use CNNs as their backbone, leading to two key issues when exchanging information between the encoder and decoder: 1) taking into account the differences in contribution between different-level features; and 2) designing an effective mechanism for fusing these features. Different from existing CNN-based methods, we adopt a transformer encoder, which learns more powerful and robust representations. In addition, considering the image acquisition influence and elusive properties of polyps, we introduce three novel modules, including a cascaded fusion module (CFM), a camouflage identification module (CIM), a and similarity aggregation module (SAM). Among these, the CFM is used to collect the semantic and location information of polyps from high-level features, while the CIM is applied to capture polyp information disguised in low-level features. With the help of the SAM, we extend the pixel features of the polyp area with high-level semantic position information to the entire polyp area, thereby effectively fusing cross-level features. The proposed model, named Polyp-PVT, effectively suppresses noises in the features and significantly improves their expressive capabilities. Extensive experiments on five widely adopted datasets show that the proposed model is more robust to various challenging situations (e.g.appearance changes, small objects) than existing methods, and achieves the new state-of-the-art performance. The proposed model is available at https://github.com/DengPingFan/Polyp-PVT.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Colonoscopy is the gold standard for detecting colorectal lesions, since it enables colorectal polyps to be identified and removed in time, thereby preventing further spread. Polyp segmentation, as a fundamental task in medical image analysis, aims to accurately locate polyps in the early stage, which is of great significance in the clinical prevention of rectal cancer. Traditional polyp segmentation methods mainly rely on low-level features, such as texture <ref type="bibr" target="#b0">[1]</ref>, geometric features <ref type="bibr" target="#b1">[2]</ref>, simple linear iterative clustering super-pixels <ref type="bibr" target="#b2">[3]</ref>, etcHowever, these methods tend to yield low-quality segmentation performance and suffer from poor generalization ability. With the development of deep learning in medical image analysis, polyp segmentation has achieved promising progress. In particular, the U-shaped <ref type="bibr" target="#b3">[4]</ref> has attracted significant attention due to its ability to adopt multi-level features for reconstructing <ref type="figure">Fig. 1</ref>.</p><p>The segmentation examples of our model and SANet <ref type="bibr" target="#b6">[7]</ref> with different challenge cases, e.g.camouflage (1 st and 2 nd rows) and image acquisition influence (3 rd row). The images from top to bottom are from ClinicDB <ref type="bibr" target="#b7">[8]</ref>, ETIS <ref type="bibr" target="#b8">[9]</ref>, and ColonDB <ref type="bibr" target="#b9">[10]</ref>, which show that our model has better generalization ability. high-resolution prediction results. PraNet <ref type="bibr" target="#b4">[5]</ref> employs a twostage segmentation approach, adopting a parallel decoder to predict rough regions, and an attention mechanism to restore the edges and internal structure of a polyp for fine-grained segmentation. ThresholdNet <ref type="bibr" target="#b5">[6]</ref> is a confidence-guided data enhancement method based on a hybrid manifold for solving the problems caused by limited annotated data and imbalanced data distributions.</p><p>Although these methods have greatly improved accuracy and generalization ability compared to traditional methods, it is still challenging for them to locate the boundaries of polyps, as shown as in <ref type="figure">Fig. 1</ref>, for several reasons: (1) Image noise. During the data collection process, the lens rotates in the intestine to obtain polyp images from different angles, which also causes motion blur and reflector problems. As a result, this greatly increases the difficulty of polyp detection;</p><p>(2) Camouflage. The color and texture of polyps are very similar to surrounding tissues, with low contrast, providing them with powerful camouflage properties <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, and making them difficult to identify; (3) Polycentric data. Current models struggle to generalize to multicenter (or unseen) data with different domains/distributions.</p><p>To address the above issues, our contributions in this paper are threefold: encoder for extracting more powerful and robust features. ? To support our framework, we use three simple modules.</p><p>Specifically, the cascaded fusion module (CFM) collects the semantic and location information of polyps from the high-level features through progressive integration. Meanwhile, the camouflage identification module (CIM) is applied to capture polyp cue disguised in low-level features, using an attention mechanism to pay more attention to potential polyps, which in turn reduces incorrect information in the lower features. We further introduce the similarity aggregation module (SAM) equipped with a non-local and a graph convolutional layer to mine local pixels and global semantic cues from the polyp area. ? Finally, we conduct extensive experiments on five challenging benchmark datasets, including Kvasir-SEG <ref type="bibr" target="#b12">[13]</ref>, ClinicDB <ref type="bibr" target="#b7">[8]</ref>, ColonDB <ref type="bibr" target="#b9">[10]</ref>, Endoscene <ref type="bibr" target="#b13">[14]</ref>, and ETIS <ref type="bibr" target="#b8">[9]</ref>, to evaluate the performance of the proposed Polyp-PVT. On ColonDB, our method achieves a mean Dice (mDic) of 0.808, which is 5.5% higher than existing state-of-the-art method SANet <ref type="bibr" target="#b6">[7]</ref>. On the ETIS dataset, our model achieves a mean Dice (mDic) of 0.787, which is 3.7% higher than SANet <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS A. Polyp Segmentation</head><p>Traditional Methods. Computer-aided detection is an effective alternative to manual detection, and a detailed survey has been conducted on the detection of ulcers, polyps, and tumors in wireless capsule endoscopy imaging <ref type="bibr" target="#b14">[15]</ref>. Early solutions for polyp segmentation were mainly based on lowlevel features, such as texture <ref type="bibr" target="#b1">[2]</ref>, geometric features <ref type="bibr" target="#b1">[2]</ref>, or simple linear iterative clustering superpixels <ref type="bibr" target="#b2">[3]</ref>. However, due to the high similarity between polyps and surrounding tissues, these methods have a high risk of missed or false detection.</p><p>Deep Learning-Based Methods. Deep learning techniques <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b19">[20]</ref> have greatly promoted the development of polyp segmentation tasks. Akbari et al. <ref type="bibr" target="#b20">[21]</ref> proposed a polyp segmentation model using a fully convolutional neural network, whose segmentation results are significantly better than traditional solutions. Brandao et al. <ref type="bibr" target="#b21">[22]</ref> used the shape from shading strategy to restore depth, merging the result into an RGB model to provide richer feature representations. More recently, encoder-decoder based models, such as U-Net <ref type="bibr" target="#b3">[4]</ref>, UNet++ <ref type="bibr" target="#b22">[23]</ref>, and ResUNet++ <ref type="bibr" target="#b23">[24]</ref>, have gradually come to dominate the field with excellent performance. Sun et al. <ref type="bibr" target="#b24">[25]</ref> introduced a dilated convolution to extract and aggregate highlevel semantic features with resolution retention for improving the encoder network. Psi-Net <ref type="bibr" target="#b25">[26]</ref> introduced a multi-task segmentation model that combines contour prediction and distance map estimation to assist segmentation mask prediction. Hemin et al. <ref type="bibr" target="#b26">[27]</ref> first attempted to use a deeper feature extractor to perform polyp segmentation based on Mask R-CNN <ref type="bibr" target="#b27">[28]</ref>.</p><p>Different from the methods based on U-Net <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref>, PraNet <ref type="bibr" target="#b4">[5]</ref> uses reverse attention modules to mine boundary information with a global feature map, which is generated by a parallel partial decoder from high-level features. Polyp-Net <ref type="bibr" target="#b29">[30]</ref> proposed a dual-tree wavelet pooling CNN with a local gradient weighted embedding level set, which effectively avoids erroneous information in high signal areas, thereby significantly reducing the false positive rate. Rahim et al. <ref type="bibr" target="#b30">[31]</ref> proposed to use different convolution kernels for the same hidden layer for deeper feature extraction with MISH and rectified linear unit activation functions for deep feature propagation and smooth non-monotonicity. In addition, they adopted joint generalized intersections, which overcomes scale invariance, rotation, and shape differences. Jha et al. <ref type="bibr" target="#b31">[32]</ref> designed a real-time polyp segmentation method called Colon-SNet. For the first time, Ahmed et al. <ref type="bibr" target="#b32">[33]</ref> applied the generative adversarial network to the field of polyp segmentation. Another interesting idea proposed by Thambawita et al. <ref type="bibr" target="#b33">[34]</ref> is introducing pyramid-based augmentation into the polyp segmentation task. Further, Tomar et al. <ref type="bibr" target="#b34">[35]</ref> designed a dual decoder attention network based on ResUNet++ for polyp segmentation. More recently, MSEG <ref type="bibr" target="#b35">[36]</ref> improved the PraNet and proposed a simple encoder-decoder structure. Specifically, they used Hardnet <ref type="bibr" target="#b36">[37]</ref> to replace the original backbone network Res2Net50 backbone network and removed the attention mechanism to achieve faster and more accurate polyp segmentation. As an early attempt, Transfuse <ref type="bibr" target="#b37">[38]</ref> was the first to employ a two-branch architecture combining CNNs and transformers in a parallel style. DCRNet <ref type="bibr" target="#b38">[39]</ref> uses external and internal context relations modules to separately estimate the similarity between each location and all other locations in the same and different images. MSNet <ref type="bibr" target="#b39">[40]</ref> introduced a multi-scale subtraction network to eliminate redundancy and complementary information between the multi-scale features. Providing a comprehensive review on polyp segmentation is beyond the scope of this paper. In Tab. I, however, we give a brief survey of representative works related to ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Vision Transformer</head><p>Transformers use multi-head self-attention (MHSA) layers to model long-term dependencies. Unlike the convolutional layer, the MHSA layer has dynamic weights and a global receptive field, making it more flexible and effective. The transformer <ref type="bibr" target="#b59">[60]</ref> was first proposed by Vaswani et al. for the machine translation task, and has since had extensive influence on the natural language processing field. To apply transformers to computer vision tasks, Dosovitskiy et al. <ref type="bibr" target="#b60">[61]</ref> proposed a vision transformer (ViT), which was the first pure transformer for image classification. ViT divides an image into multiple patches, which are sequentially sent to a transformer encoder after being encoded, and then an MLP is used to perform image classification. HVT <ref type="bibr" target="#b61">[62]</ref> is based on a hierarchical progressive pooling method to compress the sequence length of a token and reduce the redundancy and number of calculations in ViT. The pooling-based vision transformer <ref type="bibr" target="#b62">[63]</ref> draws on the principle of CNNs whereby, as the depth increases, the number of feature map channels increases, and the spatial dimension decreases. Yuan et al. <ref type="bibr" target="#b63">[64]</ref> pointed out that the simple token structure in ViT cannot capture important local features, such as edges and lines, which reduces the training efficiency and leads to redundant attention mechanisms. T2T ViT was thus proposed to use layer-by-layer tokens-to-token transformation  <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, ES = ENDOSCENE, DB = COLONDB, CV = CVC-VIDEOCLINICDB, C = COLON, ED = ENDOTECT 2020, KS = KVASIR-SEG, KCS = KVASIR CAPSULE-SEG, PRANET = SAME TO DATASETS USED IN PRANET <ref type="bibr" target="#b4">[5]</ref>, IS = IMAGE SEGMENTATION, VS = VIDEO SEGMENTATION, CF = CLASSFICATION, OD = OBJECT DETECTION, OWN = PRIVATE DATA. CSCPD <ref type="bibr" target="#b0">[1]</ref>, APD <ref type="bibr" target="#b1">[2]</ref>, SBCP <ref type="bibr" target="#b2">[3]</ref>, FCN <ref type="bibr" target="#b20">[21]</ref>, D-FCN <ref type="bibr" target="#b21">[22]</ref>, UNET++ <ref type="bibr" target="#b22">[23]</ref>, PSI-NET <ref type="bibr" target="#b25">[26]</ref>, MASK R-CNN <ref type="bibr" target="#b26">[27]</ref>, UDC <ref type="bibr" target="#b24">[25]</ref>, THRESHOLDNET <ref type="bibr" target="#b5">[6]</ref>, MI2GAN <ref type="bibr" target="#b42">[43]</ref>, ACSNET <ref type="bibr" target="#b43">[44]</ref>, PRANET <ref type="bibr" target="#b4">[5]</ref>, GAN <ref type="bibr" target="#b32">[33]</ref>, APS <ref type="bibr" target="#b44">[45]</ref>, PFA <ref type="bibr" target="#b33">[34]</ref>, MMT <ref type="bibr" target="#b45">[46]</ref>, U-NET-RESNET50 <ref type="bibr" target="#b28">[29]</ref>, SURVEY <ref type="bibr" target="#b14">[15]</ref>, POLYP-NET <ref type="bibr" target="#b29">[30]</ref>, DEEP CNN <ref type="bibr" target="#b30">[31]</ref>, EU-NET <ref type="bibr" target="#b46">[47]</ref>, DSAS <ref type="bibr" target="#b47">[48]</ref>, U-NET-MOBILENETV2 <ref type="bibr" target="#b48">[49]</ref>, DCRNET <ref type="bibr" target="#b38">[39]</ref>, MSEG <ref type="bibr" target="#b35">[36]</ref>, FSSNET <ref type="bibr" target="#b49">[50]</ref>, AG-CURESNEST <ref type="bibr" target="#b50">[51]</ref>, MPAPS <ref type="bibr" target="#b51">[52]</ref>, RESUNET++ <ref type="bibr" target="#b52">[53]</ref>, NANONET <ref type="bibr" target="#b53">[54]</ref>, COLONSEGNET <ref type="bibr" target="#b31">[32]</ref>, SEGTRAN <ref type="bibr" target="#b54">[55]</ref>, DDANET <ref type="bibr" target="#b34">[35]</ref>, UACANET <ref type="bibr" target="#b55">[56]</ref>, DIVERGENTNET <ref type="bibr" target="#b56">[57]</ref>, DWHIERASEG <ref type="bibr" target="#b57">[58]</ref>, TRANSFUSE <ref type="bibr" target="#b37">[38]</ref>, SANET <ref type="bibr" target="#b6">[7]</ref>, PNS-NET <ref type="bibr" target="#b58">[59]</ref> No.</p><p>Model To adapt to dense prediction tasks such as semantic segmentation, several methods [66]- <ref type="bibr" target="#b71">[72]</ref> have also introduced the pyramid structure of CNNs to the design of transformer backbones. For instance, PVT-based models <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b66">[67]</ref> use a hierarchical transformer with four stages, showing that a pure transformer backbone can be as versatile as its CNN counterparts, and performs better in detection and segmentation tasks. In this work, we design a new transformer-based polyp segmentation framework, which can accurately locate the boundaries of polyps even in extreme scenarios. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) PVT Encoder</head><p>Channel Spatial </p><formula xml:id="formula_0">1 ? 1 ? ? ? ? ? ? 1 ? /? ? ? ? ? ? ? ? ? ? ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overall Architecture</head><p>As shown in <ref type="figure" target="#fig_0">Fig. 2</ref>, the proposed Polyp-PVT consists of four key modules: namely, a pyramid vision transformer (PVT) encoder, cascaded fusion module (CFM), camouflage identification module (CIM), and similarity aggregation module (SAM). Specifically, the PVT is used to extract multi-scale long-range dependencies features from the input image. The CFM is employed to collect the semantic cues and locate polyps by aggregating high-level features in a progressive manner. The CIM is designed to remove noise and enhance low-level representation information of polyps, including texture, color, and edges. The SAM is adopted to fuse the low-and high-level features provided by the CIM and CFM, effectively transmitting the information from pixel-level polyp to the entire polyp area.</p><p>Given an input image I ? R H?W ?3 , we use the transformer-based backbone <ref type="bibr" target="#b65">[66]</ref> to extract four pyramid fea- . Finally, F is fed into a 1 ? 1 convolutional layer to predict the polyp segmentation result P 2 . We use the sum of P 1 and P 2 as the final prediction. During training, we optimize the model with a main loss L main and an auxiliary loss L aux . The main loss is calculated between the final segmentation result P 2 and the ground truth (GT), which is used to optimize the final polyp segmentation result. Similarly, the auxiliary loss is used to supervise the intermediate result P 1 generated by the CFM.</p><formula xml:id="formula_1">tures X i ? R H 2 i+1 ? W 2 i+1 ?Ci , where C i ? {64,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transformer Encoder</head><p>Due to uncontrolled factors in their acquisition, polyp images tend to contain significant noise, such as motion blur, rotation, and reflection. Some recent works <ref type="bibr" target="#b72">[73]</ref>, <ref type="bibr" target="#b73">[74]</ref> have found that the vision transformer <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b66">[67]</ref> demonstrates stronger performance and better robustness to input disturbances than CNNs <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>. Inspired by this, we use a vision transformer as our backbone network to extract more robust and powerful features for polyp segmentation. Different from <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b67">[68]</ref> that use fixed "columnar" structure or shifted windowing manner, the PVT [66] is a pyramid architecture whose representation is calculated with spatial-reduction attention operations, thus it enables reduce the resource consumption. Note that the proposed model is backbone-independent, other famous transformer backbones are feasible in our framework. Specifically, we adopt the PVTv2 <ref type="bibr" target="#b66">[67]</ref> which is the improved version of PVT with a more powerful feature extraction ability. To adapt PVTv2 to the polyp segmentation task, we remove the last classification layer, and design a polyp segmentation head on top of four multi-scale feature maps (i.e.X 1 , X 2 , X 3 , and X 4 ) generated by different stages. Among these feature maps, X 1 gives detailed appearance information of polyps, and X 2 , X 3 , and X 4 provide high-level features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Cascaded Fusion Module</head><p>To balance the accuracy and computational resources, we follow recent popular practices <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b74">[75]</ref> to implement the cascaded fuse module (CFM). Specifically, we define F(?) as a convolutional unit composed of a 3?3 convolutional layer with padding set to 1, batch normalization <ref type="bibr" target="#b75">[76]</ref> and ReLU <ref type="bibr" target="#b76">[77]</ref>. As shown in <ref type="figure" target="#fig_0">Fig. 2 (b)</ref>, the CFM mainly consists of two cascaded parts, as follows:</p><p>(1) In part one, we up-sample the highest-level feature map X 4 to the same size as X 3 and then pass the result through two convolutional units F 1 (?) and F 2 (?), yieldings: X 1 4 and X 2 4 . Then, we multiply X 1 4 and X 3 and concatenate the result with X 2 4 . Finally, we use a convolution unit F 3 (?) to smooth the concatenated feature, yielding fused feature map X 34 ? R H 16 ? W 16 ?32 . The process can be summarized as Eqn. 1.</p><formula xml:id="formula_2">X 34 = F 3 (Concat(F 1 (X 4 ) X 3 , F 2 (X 4 ))),<label>(1)</label></formula><p>where " " denotes the Hadamard product, and Concat(?) is the concatenation operation along the channel dimension.</p><p>(2) As shown Eqn. 2, the second part follows a similar process to part one. Firstly, we up-sample X 4 , X 3 , X 34 to the same size as X 2 , and smooth them using convolutional units F 4 (?), F 5 (?), and F 6 (?), respectively. Then, we multiply the smoothed X 4 and X 3 with X 2 , and concatenate the resulting map with up-sampled and smoothed X 34 . Finally, we feed the concatenated feature map into two convolutional units (i.e.F 7 (?) and F 8 (?)) to reduce the dimension, and obtain</p><formula xml:id="formula_3">T 1 ? R H 8 ? W 8 ?32</formula><p>, which is also the output of the CFM.</p><formula xml:id="formula_4">T 1 = F 8 (F 7 (Concat(F 4 (X 4 ) F 5 (X 3 ) X 2 , F 6 (X 34 )))),<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Camouflage Identification Module</head><p>Low-level features often contain rich detail information, such as texture, color, and edges. However, polyps tend to be very similar in appearance to the background. Therefore, we need a powerful extractor to identify the polyp details.</p><p>As shown in <ref type="figure" target="#fig_0">Fig. 2 (c)</ref>, we introduce a camouflage identification module (CIM) to capture the details of polyps from different dimensions of the low-level feature map X 1 . Specifically, the CIM consists of a channel attention operation <ref type="bibr" target="#b77">[78]</ref> Att c (?) and a spatial attention operation <ref type="bibr" target="#b78">[79]</ref> Att s (?), which can be formulated as:</p><formula xml:id="formula_5">T 2 = Att s (Att c (X 1 )) ,<label>(3)</label></formula><p>The channel attention operation Att c (?) can be written as follow:</p><formula xml:id="formula_6">Att c (x) = ? (H 1 (P max (x)) + H 2 (P avg (x))) x,<label>(4)</label></formula><p>where x is the input tensor and ?(?) is the Softmax function. P max (?) and P avg (?) denote adaptive maximum pooling and adaptive average pooling functions, respectively. H i (?), i ? {1, 2} shares parameters and consists of a convolutional layer with 1 ? 1 kernel size to reduce the channel dimension 16 times, followed by a ReLU layer and another 1 ? 1 convolutional layer to recover the original channel dimension. The spatial attention operation Att s (?) can be formulated as:</p><formula xml:id="formula_7">Att s (x) = ?(G(Concat(R max (x), R avg (x)))) x,<label>(5)</label></formula><p>where R max (?) and R avg (?) represent the maximum and average values obtained along the channel dimension, respectively. G(?) is a 7 ? 7 convolutional layer with padding set to 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Similarity Aggregation Module</head><p>To explore high-order relations between the lower-level local features from CIM and higher-level cues from CFM. We introduce the non-local <ref type="bibr" target="#b79">[80]</ref>, <ref type="bibr" target="#b80">[81]</ref> operation under graph convolution domain <ref type="bibr" target="#b81">[82]</ref> to implement our similarity aggregation module (SAM). As a result, SAM can inject detailed appearance features into high-level semantic features using global attention.</p><p>Given the feature map T 1 , which contains high-level semantic information, and T 2 with rich appearance details, we fuse them through self-attention. First, two linear mapping functions W ? (?) and W ? (?) are applied on T 1 to reduce the dimension and obtain feature maps Q ? R</p><formula xml:id="formula_8">H 8 ? W 8 ?16 and K ? R H 8 ? W 8 ?16 .</formula><p>Here, we take a convolution operation with a kernel size of 1 ? 1 as the linear mapping process. This process can be expressed as:</p><formula xml:id="formula_9">Q = W ? (T 1 ), K = W ? (T 1 ).<label>(6)</label></formula><p>For T 2 , we use a convolutional unit W g (?) to reduce the channel dimension to 32 and interpolate it to the same size as T 1 . Then, we apply a Softmax function on the channel dimension and choose the second channel 1 as the attention map, leading to T 2 ? R  <ref type="figure" target="#fig_1">Fig. 3</ref>. Next, we calculate the Hadamard product between K and T 2 . This operation assigns different weights to different pixels, increasing the weight of edge pixels. After that, we use an adaptive pooling operation to reduce the displacement of features, and apply a center crop on it to obtain the feature map V ? R 4?4?16 . In summary, the process can be formulated as follows:</p><formula xml:id="formula_10">V = AP(K F(W g (T 2 ))),<label>(7)</label></formula><p>where AP(?) denotes the pooling and crop operations. Then, we establish the correlation between each pixel in V and K through an inner product, which is written as follows:</p><formula xml:id="formula_11">f = ?(V ? K T ),<label>(8)</label></formula><p>where "?" denotes the inner product operation. K T is the transpose of K and f is the correlation attention map. After obtaining the correlation attention map f , we multiply it with the feature map Q, and the result features are fed to the graph convolutional layer <ref type="bibr" target="#b80">[81]</ref> GCN(?), leading to G ? R 4?4?16 . Same to <ref type="bibr" target="#b80">[81]</ref>, we calculate the inner product between f and G as Eqn. 9, reconstructing the graph domain features into the original structural features:</p><formula xml:id="formula_12">Y = f T ? GCN(f ? Q).<label>(9)</label></formula><p>The reconstructed feature map Y is adjusted to the same channel sizes with Y by a convolutional layer W z (?) with 1 ? 1 kernel size, and then combined with the feature T 1 to obtain the final output Z ? R </p><formula xml:id="formula_13">Z = T 1 + W z (Y ).<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Loss Function</head><p>Our loss function can be formulated as Eqn. 11:</p><formula xml:id="formula_14">L = L main + L aux ,<label>(11)</label></formula><p>where L main and L aux are the main loss and auxiliary loss, respectively. The main loss L main is calculated between the final segmentation result P 2 and ground truth G, which can be written as:</p><formula xml:id="formula_15">L main = L w IoU (P 2 , G) + L w BCE (P 2 , G).<label>(12)</label></formula><p>The auxiliary loss L aux is calculated between the intermediate result P 1 from the CFM and ground truth G, which can be formulated as:</p><formula xml:id="formula_16">L aux = L w IoU (P 1 , G) + L w BCE (P 1 , G).<label>(13)</label></formula><p>L w IoU (?) and L w BCE (?) are the weighted intersection over union (IoU) loss <ref type="bibr" target="#b82">[83]</ref> and weighted binary cross entropy (BCE) loss <ref type="bibr" target="#b82">[83]</ref>, which restrict the prediction map in terms of the global structure (object-level) and local details (pixel-level) perspectives. Unlike the standard BCE loss function, which treats all pixels equally, L w BCE (?) considers the importance of each pixel and assigns higher weights to hard pixels. Furthermore, compared to the standard IoU loss, L w IoU (?) pays more attention to the hard pixels.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Implementation Details</head><p>We implement our Polyp-PVT with the PyTorch framework and use a Tesla P100 to accelerate the calculations. Considering the differences in the sizes of each polyp image, we adopt a multi-scale strategy <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b35">[36]</ref> in the training stage. The hyperparameter details are as follows. To update the network parameters, we use the AdamW <ref type="bibr" target="#b83">[84]</ref> optimizer, which is widely used in transformer networks <ref type="bibr" target="#b65">[66]</ref>- <ref type="bibr" target="#b67">[68]</ref>. The learning rate is set to 1e-4 and the weight decay is adjusted to 1e-4 too. Further, we resize the input images to 352 ? 352 with a mini-batch size of 16 for 100 epochs. More details about the training loss cures, parameter setting, and network parameters are shown in <ref type="figure">Fig. 4</ref>, Tab. II and Tab. III, respectively. The total training time is nearly 3 hours to achieve the best (e.g.30 epochs) performance. For testing, we only resize the images to 352?352 without any post-processing optimization strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS A. Evaluation Metrics</head><p>We employ six widely-used evaluation metrics, including Dice <ref type="bibr" target="#b84">[85]</ref>, IoU, mean absolute error (MAE), weighted Fmeasure (F w ? ) <ref type="bibr" target="#b85">[86]</ref>, S-measure (S ? ) <ref type="bibr" target="#b86">[87]</ref>, and E-measure (E ? ) <ref type="bibr" target="#b87">[88]</ref>, <ref type="bibr" target="#b88">[89]</ref> to evaluate the model performances. Among these metrics, Dice and IoU are similarity measures at the regional level, which mainly focus on the internal consistency of segmented objects. Here, we report the mean value of Dice and IoU, denoted as mDic and mIoU, respectively. MAE is a pixelby-pixel comparison indicator that represents the average value of the absolute error between the predicted value and the true value. Weighted F-measure (F w ? ) comprehensively considers the recall and precision, and eliminates the effect of considering each pixel equally in conventional indicators. S-measure (S ? ) focuses on the structural similarity of target prospects at the region and object level. E-measure (E ? ) is used to evaluate the segmentation results at the pixel and image level. We report the mean and max value of E-measure, denoted as mE ? and maxE ? , respectively. The evaluation toolbox is derived from https://github.com/DengPingFan/PraNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets and Compared Models</head><p>Datasets. Following the experimental setups in PraNet <ref type="bibr" target="#b4">[5]</ref>, we adopt five challenging public datasets, including Kvasir-SEG <ref type="bibr" target="#b12">[13]</ref>, ClinicDB <ref type="bibr" target="#b7">[8]</ref>, ColonDB <ref type="bibr" target="#b9">[10]</ref>, Endoscene <ref type="bibr" target="#b13">[14]</ref> and ETIS <ref type="bibr" target="#b8">[9]</ref> to verify the effectiveness of our framework.</p><p>Models.</p><p>We collect several open source models from the field of polyp segmentation, for a total of nine comparative models, including U-Net <ref type="bibr" target="#b3">[4]</ref>, UNet++ <ref type="bibr" target="#b22">[23]</ref>, PraNet <ref type="bibr" target="#b4">[5]</ref>, SFA <ref type="bibr" target="#b89">[90]</ref>, MSEG <ref type="bibr" target="#b35">[36]</ref>, ACSNet <ref type="bibr" target="#b43">[44]</ref>, DCRNet <ref type="bibr" target="#b38">[39]</ref>, EU-Net <ref type="bibr" target="#b46">[47]</ref> and SANet <ref type="bibr" target="#b6">[7]</ref>. For fair comparison, we use their open source codes to evaluate on the same training and testing sets. Note that the SFA results are generated using the released test model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis of Learning Ability</head><p>Settings. We use the ClinicDB and Kvasir-SEG datasets to evaluate the learning ability of the proposed model. ClinicDB contains 612 images, which are extracted from 31 colonoscopy videos. Kvasir-SEG is collected from the polyp class in the Kvasir dataset, and includes 1,000 polyp images. Following to the settings in PraNet, we adopt the same 900 and 548 images from ClinicDB and Kvasir-SEG datasets as the training set, and the remaining 64 and 100 images are employed as the respective test sets.</p><p>Results. As can be seen in Tab. IV, our model is superior to the current methods, demonstrating that it has a better learning ability. On the Kvasir-SEG dataset, the mDic score of our model is 1.3% higher than that of the second-best model, SANet, and 1.9% higher than that of PraNet. On the ClinicDB dataset, the mDic score of our model is 2.1% higher than that of SANet, and 3.8% higher than that of PraNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Analysis of Generalization Ability</head><p>Settings. To verify the generalization performance of the model, we test it on three unseen (i.e.Polycentric) datasets, namely ETIS, ColonDB and EndoScene. There are 196 images in ETIS, 380 images in ColonDB and 60 images in EndoScene. It is worth noting that the images in these datasets belong to different medical centers. In other words, the model has not seen their training data, which is different from the verification methods of ClinicDB and Kvasir-SEG.</p><p>Results. The results are shown in Tab. V and Tab. VI. As can be seen, our Polyp-PVT achieves a good generalization performance compared with the existing models. On ColonDB, it is ahead of the second-best SANet and classical PraNet by 5.5% and 9.6%, respectively. On ETIS, we exceed the SANet and PraNet by 3.7% and 15.9%, respectively. In addition, on EndoScene, our model is better than SANet and PraNet by 1.2% and 2.9%, respectively. Moreover, to prove the generalization ability of Polyp-PVT, we present the max Dice results in <ref type="figure" target="#fig_5">Fig. 5</ref>, where our model shows a steady improvement on both ColonDB and ETIS. In addition, we show the standard deviation (SD) of the mean dice (mDic) between our model and others in Tab. VII. As seen, there is not much difference in SD between our model and the comparison model, and they are both stable and balanced.</p><p>Effectiveness of CIM. To demonstrate the ability of the CIM, we also remove it from Polyp-PVT, denoting this as "Polyp-PVT (w/o CIM)". As shown in Tab. VIII, this variant performs worse than the overall Polyp-PVT. Specifically, removing the CIM causes the mDic to decrease by 1.8% on Endoscene. Meanwhile, it is obvious that the lack of the CIM introduces significant noise (please refer to <ref type="figure">Fig. 9</ref>). Kvasir-SEG <ref type="bibr" target="#b12">[13]</ref> ClinicDB E. Qualitative Analysis <ref type="figure" target="#fig_6">Fig. 6</ref> and <ref type="figure" target="#fig_7">Fig. 7</ref> show the visualization results of our model and the compared models. We find that our results have two  advantages. 1) Our model is able to adapt to data under different conditions. That is, it maintains a stable recognition and segmentation ability under different acquisition environments, such as different lighting, contrast, reflection, motion blur, etc2) The model segmentation results have internal consistency, and predicted edges are closer to the ground-truth labels. We also provide FROC curves on ColonDB in <ref type="figure" target="#fig_8">Fig. 8</ref>, and our result is at the top, indicating that our effect achieves the best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Ablation Study</head><p>We describe in detail the effectiveness of each component on the overall model. The training, testing, and hyperparameter settings are the same as mentioned in Sec. III-G. The results are shown in Tab. VIII.</p><p>Components. We use PVTv2 <ref type="bibr" target="#b66">[67]</ref>   the variants with the standard version. The standard version is denoted as "Polyp-PVT (PVT+CFM+CIM+SAM)", where "CFM", "CIM" and "SAM" indicate the usage of the CFM, CIM and SAM, respectively.</p><p>Effectiveness of CFM. To analyze the effectiveness of the CFM, a version of "Polyp-PVT (w/o CFM)" is trained. Tab. VIII shows that the model without the CFM drops sharply on all five datasets compared to the standard Polyp-PVT. In particular, the mDic is reduced from 0.937 to 0.915 on ClinicDB.</p><p>Effectiveness of SAM. Similarly, we test the effectiveness of the SAM module by removing it from the overall Polyp-PVT and replacing it with an element-wise addition operation, which is denoted as "Polyp-PVT (w/o SAM)". The perfor- ColonDB. <ref type="figure">Fig. 9</ref> shows the benefits of SAM more intuitively. It is found that the lack of the SAM leads to more detailed errors or even missed inspections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Video Polyp Segmentation</head><p>To validate the superiority of the proposed model, we conduct experiments on the video polyp segmentation datasets. For fair comparison, we re-train our model with the same training datasets and use the same testing set as PNS-Net <ref type="bibr" target="#b58">[59]</ref>. We compare our model on three standard benchmarks (i.e.CVC-300-TV <ref type="bibr" target="#b90">[91]</ref>, CVC-612-T <ref type="bibr" target="#b7">[8]</ref>, and CVC-612-V <ref type="bibr" target="#b7">[8]</ref>) against six SOTA approaches, including U-Net <ref type="bibr" target="#b3">[4]</ref>, UNet++ <ref type="bibr" target="#b22">[23]</ref>, ResUNet++ <ref type="bibr" target="#b23">[24]</ref>, ACSNet <ref type="bibr" target="#b43">[44]</ref>, PraNet <ref type="bibr" target="#b4">[5]</ref>, PNS-Net <ref type="bibr" target="#b58">[59]</ref>, in Tab. IX and Tab. X. Note that all the prediction maps of the compared methods are provided by PNS-Net. As seen, our method is very competitive, and far ahead of the best existing model, PNS-Net, by 3.1% and 6.7% on CVC-612-V and CVC-300-TV, respectively, in terms of mDice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Limitations</head><p>Although the proposed Polyp-PVT model surpasses existing algorithms, it still performs poorly in certain cases. We present some failure cases in <ref type="figure">Fig. 10</ref>. As can be seen, one major limitation is the inability to detect accurate polyp boundaries with overlapping light and shadow (1 st row). Our model can identify the location information of polyps (green mask in 1 st row), but it regards the light and shadow part of the edge as the polyp (red mask in 1 st row). More deadly, our model incorrectly predicts the reflective point as a polyp (red mask in 2 nd and 3 rd rows). We notice that the reflective points are very salient in the image. Therefore, we speculate that the prediction may be based on only these points. More importantly, we believe that a simple way is to convert the input image into a gray image, which can eliminate the reflection and overlap of light and shadow to assist the model in the judgment.</p><p>V. CONCLUSION In this paper, we propose a new image polyp segmentation framework, named Polyp-PVT, which utilizes a pyramid vision transformer backbone as the encoder to explicitly extract more powerful and robust features. Extensive experiments show that Polyp-PVT consistently outperforms all current cutting-edge models on five challenging datasets without any pre-/post-processing. In particular, for the unseen ColonDB dataset, the proposed model reaches a mean Dice score of above 0.8 for the first time. Interestingly, we also surpass the current state-of-the-art PNS-Net in terms of video polyp segmentation task, demonstrating excellent learning ability. Specifically, we obtain the above-mention achievements by introducing three simple components, i.e.a cascaded fusion module (CFM), a camouflage identification module (CIM), and a similarity aggregation module (SAM), which effectively extract high and low-level cues separately, and effectively fuse them for the final output. We hope this research will stimulate more novel ideas for solving the polyp segmentation task. <ref type="bibr">Image</ref> GT Bas. w/o CFM w/o CIM w/o SAM Ours <ref type="figure">Fig. 9</ref>. Visualization of the ablation study results, which are converted from the output into heat maps. As can be seen, removing any module leads to missed or incorrectly detected results.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Framework of our Polyp-PVT, which consists of a pyramid vision transformer (PVT) (a) as the encoder network, (b) cascaded fusion module (CFM) for fusing the high-level feature, (c) camouflage identification module (CIM) to filter out the low-level information, and (d) similarity aggregation module (SAM) for integrating the high-and low-level features for the final output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Details of the SAM. The red arrow indicates a transpose. It is composed of GCN and non-local, which extend the pixel features of polyp regions with high-level semantic location cues to the entire region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>H 8 ? W 8</head><label>88</label><figDesc>?1 . These operations are represented as F(?) in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>H 8 ? W 8 ?32</head><label>88</label><figDesc>of the SAM. Eqn. 10 summarizes the details of this process:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 Fig. 4 .</head><label>14</label><figDesc>Loss curves under different training parameter settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Evaluation of model generalization ability. We provide the max Dice results on ColonDB and ETIS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>??Fig. 6 .</head><label>6</label><figDesc>S? mE ? maxE ? MAE mDic mIoU F w ? S? mE ? maxE ? MAE MICCAI'15 U-Net 0.818 0.746 0.794 0.858 0.881 0.893 0.055 0.823 0.755 0.811 0.889 0.913 0.954 0.019 DLMIA'18 UNet++ 0.821 0.743 0.808 0.862 0.886 0.909 0.048 0.794 0.729 0.785 0.873 0.891 0.931 0.022 MICCAI'19 SFA 0.723 0.611 0.670 0.782 0.834 0.849 0.075 0.700 0.607 0.647 0.793 0.840 0.885 0.042 arXiv'21 MSEG 0.897 0.839 0.885 0.912 0.942 0.948 0.028 0.909 0.864 0.907 0.938 0.961 0.969 0.007 arXiv'21 DCRNet 0.886 0.825 0.868 0.911 0.933 0.941 0.035 0.896 0.844 0.890 0.933 0.964 0.978 0.010 MICCAI'20 ACSNet 0.898 0.838 0.882 0.920 0.941 0.952 0.032 0.882 0.826 0.873 0.927 0.947 0.959 0.011 MICCAI'20 PraNet 0.898 0.840 0.885 0.915 0.944 0.948 0.030 0.899 0.849 0.896 0.936 0.963 0.979 0.009 CRV'21 EU-Net 0.908 0.854 0.893 0.917 0.951 0.954 0.028 0.902 0.846 0.891 0.936 0.959 0.965 0.011 MICCAI'21 SANet 0.904 0.847 0.892 0.915 0.949 0.953 0.028 0.916 0.859 0.909 0.939 0.971 0.976 0.012 Polyp-PVT (Ours) 0.917 0.864 0.911 0.925 0.956 0.962 0.023 0.937 0.889 0.936 0.949 0.985 0.989 0.006 TABLE V QUANTITATIVE RESULTS OF THE TEST DATASETS COLONDB AND ETIS. THE SFA RESULT IS GENERATED USING THE PUBLISHED CODE. S? mE ? maxE ? MAE mDic mIoU F w ? S? mE ? maxE ? MAE MICCAI'15 U-Net 0.512 0.444 0.498 0.712 0.696 0.776 0.061 0.398 0.335 0.366 0.684 0.643 0.740 0.036 DLMIA'18 UNet++ 0.483 0.410 0.467 0.691 0.680 0.760 0.064 0.401 0.344 0.390 0.683 0.629 0.776 0.035 MICCAI'19 SFA 0.469 0.347 0.379 0.634 0.675 0.764 0.094 0.297 0.217 0.231 0.557 0.531 0.632 0.109 MICCAI'20 ACSNet 0.716 0.649 0.697 0.829 0.839 0.851 0.039 0.578 0.509 0.530 0.754 0.737 0.764 0.059 arXiv'21 MSEG 0.735 0.666 0.724 0.834 0.859 0.875 0.038 0.700 0.630 0.671 0.828 0.854 0.890 0.015 arXiv'21 DCRNet 0.704 0.631 0.684 0.821 0.840 0.848 0.052 0.556 0.496 0.506 0.736 0.742 0.773 0.096 MICCAI'20 PraNet 0.712 0.640 0.699 0.820 0.847 0.872 0.043 0.628 0.567 0.600 0.794 0.808 0.841 0.031 CRV'21 EU-Net 0.756 0.681 0.730 0.831 0.863 0.872 0.045 0.687 0.609 0.636 0.793 0.807 0.841 0.067 MICCAI'21 SANet 0.753 0.670 0.726 0.837 0.869 0.878 0.043 0.750 0.654 0.685 0.849 0.881 0.897 0.015 Polyp-PVT (Ours) 0.808 0.727 0.795 0.865 0.913 0.919 0.031 0.787 0.706 0.750 0.871 0.906 0.910 0Visualization results with the current models. Green indicates a correct polyp. Yellow is the missed polyp. Red is the wrong prediction. As we can see, the proposed model can accurately locate and segment polyps, regardless of the number of size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Visualization results with the current models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>FROC curves of different methods on ColonDB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>IX THE RESULT OF VIDEO POLYP SEGMENTATION ON THE i.e.CVC-612-T AND CVC-612-V, WHERE THE BEST RESULTS ARE IN BOLDFACE. CVC-612-T [8] CVC-612-V [8] Model mDic mIoU F w ? S? mE ? maxE ? MAE mDic mIoU F w ? S? mE ? maxE ? MAE MICCAI'15 U-Net 0.711 0.618 0.694 0.810 0.836 0.853 0.058 0.709 0.597 0.680 0.826 0.855 0.872 0.023 TMI'19 UNet++ 0.697 0.603 0.688 0.800 0.817 0.865 0.059 0.668 0.557 0.642 0.805 0.830 0.846 0.025 ISM'19 ResUNet++ 0.616 0.512 0.604 0.727 0.758 0.760 0.084 0.750 0.646 0.717 0.829 0.877 0.879 0.023 MICCAI'20 ACSNet 0.780 0.697 0.772 0.838 0.864 0.866 0.053 0.801 0.710 0.765 0.847 0.887 0.890 0.054 MICCAI'20 PraNet 0.833 0.767 0.834 0.886 0.904 0.926 0.038 0.857 0.793 0.855 0.915 0.936 0.965 0.013 MICCAI'21 PNS-Net 0.837 0.765 0.838 0.903 0.903 0.923 0.038 0.851 0.769 0.836 0.923 0.944 0.962 0.012 Polyp-PVT (Ours) 0.846 0.776 0.850 0.895 0.908 0.926 0.037 0.882 0.810 0.874 0.924 0.963 0.967 0.012TABLE X VIDEO POLYP SEGMENTATION RESULTS ON THE CVC-300-TV.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I A</head><label>I</label><figDesc>SURVEY ON POLYP SEGMENTATION. CL = CVC-CLINIC, EL = ETIS-LARIB, C6 = CVC-612, AM = ASU-MAYO</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>128, 320, 512} and i ? {1, 2, 3, 4}. Then, we adjust the channel of three highlevel features X 2 , X 3 and X 4 to 32 through three convolutional units and feed them (i.e.X 2 , X 3 , and X 4 ) to CFM to fuse, leading a feature map T 1 ? R ?32 . Meanwhile, low-level features X 1 are converted to T 2 ? R ?64 by the CIM. After that, the T 1 and T 2 are aligned and fused by SAM, yielding the final feature map F ? R</figDesc><table><row><cell>H 8 ? W 8 H 4 ? W 4 H 8 ? W</cell></row></table><note>8 ?32</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II PARAMETER</head><label>II</label><figDesc>SETTING DURING THE TRAINING STAGE.</figDesc><table><row><cell>Optimizer</cell><cell>Learning Rate (lr)</cell><cell>Multi-scale</cell><cell>Clip</cell></row><row><cell>AdamW</cell><cell>1e-4</cell><cell>[0.75,1,1.25]</cell><cell>0.5</cell></row><row><cell>Decay rate</cell><cell>Weight decay</cell><cell>Epochs</cell><cell>Input Size</cell></row><row><cell>0.1</cell><cell>1e-4</cell><cell>100</cell><cell>352 ? 352</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III NETWORK</head><label>III</label><figDesc>PARAMETERS OF EACH MODULE. NOTE THAT THE ENCODER PARAMETERS ARE THE SAME AS PVT WITHOUT ANY CHANGES. BASICCONV2D AND CONV2D WITH THE PARAMETERS [IN CHANNEL, OUT CHANNEL, KERNEL SIZE, PADDING] AND GCN [NUM STATE, NUM NODE].</figDesc><table><row><cell cols="2">Encoder</cell><cell cols="2">SAM</cell></row><row><cell>patch size</cell><cell>[4]</cell><cell>AvgPool2d</cell><cell>[6]</cell></row><row><cell cols="3">embed dims [64, 128, 320, 512] Conv2d</cell><cell>[32,16,1,1]</cell></row><row><cell>num heads</cell><cell>[1, 2, 5, 8]</cell><cell>Conv2d</cell><cell>[32,16,1,1]</cell></row><row><cell>mlp ratios</cell><cell>[8, 8, 4, 4]</cell><cell>Conv2d</cell><cell>[16,32,1,1]</cell></row><row><cell>depths</cell><cell>[3, 4, 18, 3]</cell><cell>GCN</cell><cell>[16,16]</cell></row><row><cell>sr ratios</cell><cell>[8, 4, 2, 1]</cell><cell cols="2">BasicConv2d [64,32,1,0]</cell></row><row><cell>drop rate</cell><cell>[0]</cell><cell></cell><cell></cell></row><row><cell>drop path rate</cell><cell>[0.1]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>CFM</cell><cell cols="2">CIM</cell></row><row><cell>BasicConv2d</cell><cell>[32,32,3,1]</cell><cell>AvgPool2d</cell><cell>[1]</cell></row><row><cell>BasicConv2d</cell><cell>[32,32,3,1]</cell><cell>AvgPool2d</cell><cell>[1]</cell></row><row><cell>BasicConv2d</cell><cell>[32,32,3,1]</cell><cell>Conv2d</cell><cell>[64,4,1,0]</cell></row><row><cell>BasicConv2d</cell><cell>[32,32,3,1]</cell><cell>ReLU</cell><cell></cell></row><row><cell>BasicConv2d</cell><cell>[64,64,3,1]</cell><cell>Conv2d</cell><cell>[4,64,1,0]</cell></row><row><cell>BasicConv2d</cell><cell>[64,64,3,1]</cell><cell>Sigmoid</cell><cell></cell></row><row><cell>BasicConv2d</cell><cell>[96,96,3,1]</cell><cell>Conv2d</cell><cell>[2,1,7,3]</cell></row><row><cell>BasicConv2d</cell><cell>[96,32,3,1]</cell><cell>Sigmoid</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV QUANTITATIVE</head><label>IV</label><figDesc>RESULTS OF THE TEST DATASETS, i.e.KVASIR-SEG AND CLINICDB. THE BEST RESULTS ARE IN BOLDFACE.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI QUANTITATIVE</head><label>VI</label><figDesc>RESULTS OF THE TEST DATASET ENDOSCENE. THE SFARESULT IS GENERATED USING THE PUBLISHED CODE.</figDesc><table><row><cell></cell><cell cols="2">Endoscene [14]</cell></row><row><cell>Model</cell><cell>mDic mIoU F w ?</cell><cell>S? mE ? maxE ? MAE</cell></row><row><cell>U-Net</cell><cell cols="2">0.710 0.627 0.684 0.843 0.847 0.875 0.022</cell></row><row><cell>UNet++</cell><cell cols="2">0.707 0.624 0.687 0.839 0.834 0.898 0.018</cell></row><row><cell>SFA</cell><cell cols="2">0.467 0.329 0.341 0.640 0.644 0.817 0.065</cell></row><row><cell>MSEG</cell><cell cols="2">0.874 0.804 0.852 0.924 0.948 0.957 0.009</cell></row><row><cell>ACSNet</cell><cell cols="2">0.863 0.787 0.825 0.923 0.939 0.968 0.013</cell></row><row><cell>DCRNet</cell><cell cols="2">0.856 0.788 0.830 0.921 0.943 0.960 0.010</cell></row><row><cell>PraNet</cell><cell cols="2">0.871 0.797 0.843 0.925 0.950 0.972 0.010</cell></row><row><cell>EU-Net</cell><cell cols="2">0.837 0.765 0.805 0.904 0.919 0.933 0.015</cell></row><row><cell>SANet</cell><cell cols="2">0.888 0.815 0.859 0.928 0.962 0.972 0.008</cell></row><row><cell cols="3">Polyp-PVT 0.900 0.833 0.884 0.935 0.973 0.981 0.007</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>as our baseline (Bas.) and evaluate module effectiveness by removing or replacing components from the complete Polyp-PVT and comparing</figDesc><table><row><cell></cell><cell></cell><cell>FROC performence on the test set of ColonDB</cell></row><row><cell></cell><cell>1.0</cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell></row><row><cell>True Positive Rate</cell><cell>0.0 0.2 0.4 0.6</cell><cell>Average number of false positives per image 2500 5000 7500 10000 12500 15000 17500 20000 ACSNet DCRNet EU-Net MSEG PraNet SANet SFA UNet UNet++ PolypPVT</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VII THE</head><label>VII</label><figDesc>STANDARD DEVIATION (SD) OF THE MEAN DICE (MDIC) OF OUR MODEL AND THE COMPARISON MODELS.</figDesc><table><row><cell cols="2">Datasets</cell><cell>Kvasir-SEG</cell><cell></cell><cell>ClinicDB</cell><cell>ColonDB</cell><cell>ETIS</cell><cell>Endoscene</cell></row><row><cell cols="2">Metrics</cell><cell>mDic ? SD</cell><cell></cell><cell>mDic ? SD</cell><cell>mDic ? SD</cell><cell>mDic ? SD</cell><cell>mDic ? SD</cell></row><row><cell>U-Net</cell><cell></cell><cell>.818 ? .039</cell><cell></cell><cell>.823 ? .047</cell><cell>.483 ? .034</cell><cell>.398 ? .033</cell><cell>.710 ? .049</cell></row><row><cell cols="2">UNet++</cell><cell>.821 ? .040</cell><cell></cell><cell>.794 ? .044</cell><cell>.456 ? .037</cell><cell>.401 ? .057</cell><cell>.707 ? .053</cell></row><row><cell>SFA</cell><cell></cell><cell>.723 ? .052</cell><cell></cell><cell>.701 ? .054</cell><cell>.444 ? .037</cell><cell>.297 ? .025</cell><cell>.468 ? .050</cell></row><row><cell cols="2">MSEG</cell><cell>.897 ? .041</cell><cell></cell><cell>.910 ? .048</cell><cell>.735 ? .039</cell><cell>.700 ? .039</cell><cell>.874 ? .051</cell></row><row><cell cols="2">ACSNet</cell><cell>.898 ? .045</cell><cell></cell><cell>.882 ? .048</cell><cell>.716 ? .040</cell><cell>.578 ? .035</cell><cell>.863 ? .055</cell></row><row><cell cols="2">DCRNet</cell><cell>.886 ? .043</cell><cell></cell><cell>.896 ? .049</cell><cell>.704 ? .039</cell><cell>.556 ? .039</cell><cell>.857 ? .052</cell></row><row><cell cols="2">PraNet</cell><cell>.898 ? .041</cell><cell></cell><cell>.899 ? .048</cell><cell>.712 ? .038</cell><cell>.628 ? .036</cell><cell>.871 ? .051</cell></row><row><cell cols="2">EU-Net</cell><cell>.908 ? .042</cell><cell></cell><cell>.902 ? .048</cell><cell>.756 ? .040</cell><cell>.687 ? .039</cell><cell>.837 ? .049</cell></row><row><cell cols="2">SANet</cell><cell>.904 ? .042</cell><cell></cell><cell>.916 ? .049</cell><cell>.752 ? .040</cell><cell>.750 ? .047</cell><cell>.888 ? .054</cell></row><row><cell>Ours</cell><cell></cell><cell>.917 ? .042</cell><cell></cell><cell>.937 ? .050</cell><cell>.808 ? .043</cell><cell>.787 ? .044</cell><cell>.900 ? .052</cell></row><row><cell></cell><cell></cell><cell>TABLE VIII</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">QUANTITATIVE RESULTS FOR ABLATION STUDIES.</cell><cell></cell></row><row><cell>Dataset</cell><cell cols="4">Metric Bas. w/o CFM w/o CIM w/o SAM Final</cell><cell></cell></row><row><cell>Endoscene</cell><cell cols="2">mDic 0.869 0.892 mIoU 0.792 0.826</cell><cell>0.882 0.808</cell><cell>0.874 0.900 0.801 0.833</cell><cell></cell></row><row><cell>ClinicDB</cell><cell cols="2">mDic 0.903 0.915 mIoU 0.847 0.865</cell><cell>0.930 0.881</cell><cell>0.930 0.937 0.877 0.889</cell><cell></cell></row><row><cell>ColonDB</cell><cell cols="2">mDic 0.796 0.802 mIoU 0.707 0.721</cell><cell>0.805 0.724</cell><cell>0.779 0.808 0.696 0.727</cell><cell></cell></row><row><cell>ETIS</cell><cell cols="2">mDic 0.759 0.771 mIoU 0.668 0.690</cell><cell>0.785 0.711</cell><cell>0.778 0.787 0.693 0.706</cell><cell></cell></row><row><cell>Kvasir-SEG</cell><cell cols="2">mDic 0.910 0.922 mIoU 0.856 0.872</cell><cell>0.910 0.858</cell><cell>0.910 0.917 0.853 0.864</cell><cell></cell></row><row><cell cols="5">mance of the complete Polyp-PVT shows an improvement of</cell><cell></cell></row><row><cell cols="5">2.9% and 3.1% in terms of mDic and mIoU respectively, on</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The design choice is the same at<ref type="bibr" target="#b80">[81]</ref>; however, other channels are also feasible if we only update the weight of the selected channel.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A complete system for candidate polyps detection in virtual colonoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mus?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJPRAI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">07</biblScope>
			<biblScope unit="page">1460014</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automated polyp detection in colon capsule endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Mamonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">N</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><forename type="middle">R</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1488" to="1502" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Superpixel based segmentation and classification of polyps in wireless capsule endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Maghsoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pranet: Parallel reverse attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learn to threshold: Thresholdnet with confidence-guided manifold mixup for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1134" to="1146" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Shallow attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilari?o</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CMIG</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Granado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCARS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automated polyp detection in colonoscopy videos using shape and context information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="630" to="644" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Concealed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Camouflaged object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Kvasir-seg: A segmented polyp dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MMM</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A benchmark for endoluminal scene segmentation of colonoscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>V?zquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drozdzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JHE</title>
		<imprint>
			<biblScope unit="volume">2017</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey on contemporary computer-aided tumor, polyp, and ulcer detection methods in wireless capsule endoscopy imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CMIG</title>
		<imprint>
			<biblScope unit="page">101767</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Selective kernel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mixed link networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Green indicates a correct polyp. Yellow is the missed polyp. Red is the wrong prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Akbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohrekesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nasr-Esfahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Soroushmehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; N</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE EMBC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Polyp segmentation in colonoscopy images using fully convolutional network</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards a computed-aided diagnosis system in colonoscopy: automatic polyp segmentation using convolution neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brandao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zisimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mazomenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ciuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Visentini-Scarzanella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menciassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koulaouzidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arezzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMRR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page">1840002</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unet++: A nested u-net architecture for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M R</forename><surname>Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<editor>DLMIA</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Resunet++: An advanced architecture for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ISM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Colorectal polyp segmentation by u-net with dilation convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICMLA</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Psi-net: Shape and boundary aware joint multi-task deep network for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Murugesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sarveswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Shankaranarayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sivaprakasam</surname></persName>
		</author>
		<editor>IEEE EMBC</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Polyp detection and segmentation using mask r-cnn: Does a deeper feature extractor cnn always perform better?&quot; in ISMICT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Solhusvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergsland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Aabakken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Balasingham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Automatic polyp segmentation using u-net-resnet50</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rauniyar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MediaEvalW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Polyp-net: A multimodel fusion network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nasipuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Krejcar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIM</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A deep convolutional neural network for the detection of polyps in colonoscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BSPC</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">102654</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Real-time polyp detection, localization and segmentation in colonoscopy using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="40" to="496" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Generative adversarial networks for automatic polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M A</forename><surname>Ahmed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MediaEvalW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Pyramidfocus-augmentation: Medical image segmentation with step-wise focus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MediaEvalW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ddanet: Dual decoder attention network for automatic polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICPRW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Hardnet-mseg: A simple encoder-decoder polyp segmentation neural network that achieves over 0.9 mean dice and 86 fps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.07172</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hardnet: A low memory traffic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Transfuse: Fusing transformers and cnns for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Duplex contextual relation network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06725</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Automatic polyp segmentation via multi-scale subtraction network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiaoqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lihe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huchuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Finetuning convolutional neural networks for biomedical image analysis: actively and incrementally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gotway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for medical image analysis: Full training or fine tuning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Gotway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1312" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mi 2 gan: Generative adversarial network for medical image domain adaptation using mutual information constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Adaptive context selection for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Automatic polyp segmentation using fully convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MediaEvalW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Medico multimedia task at mediaeval 2020: Automatic polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Emanuelsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MediaEvalW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Enhanced u-net: A feature enhancement network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CRV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Deep ensembles based on stochastic activation selection for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lumini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maguolo</surname></persName>
		</author>
		<editor>MIDL</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Polyp segmentation in colonoscopy images using u-net-mobilenetv2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Branch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Carvalho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15715</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Few-shot segmentation of medical images based on meta-learning with implicit gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Khadga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03223</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Ag-curesnest: A novel method for colon polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Thuy</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in IEEE RIVF, 2021</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mutual-prototype adaptation for cross-domain polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ibragimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JBHI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A comprehensive study on colorectal polyp segmentation with resunet++, conditional random field and testtime augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JBHI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2029" to="2040" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Nanonet: Real-time polyp segmentation in video capsule endoscopy and colonoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in IEEE CBMS, 2021</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Medical image segmentation using squeeze-and-expansion transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S M</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Uacanet: Uncertainty augmented context attention for polyp semgnetaion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Divergentnets: Medical image segmentation by network ensemble</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISBI &amp; EndoCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Dynamic-weighting hierarchical segmentation network for medical images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xiaoqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yixuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">102196</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">MIA</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Pns-net: Progressively normalized self-attention network for video polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Scalable visual transformers with hierarchical pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Rethinking spatial dimensions of vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Tokens-to-token vit: Training vision transformers from scratch on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">E</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Transformer in transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00112</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13797</idno>
		<title level="m">Pvtv2: Improved baselines with pyramid vision transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Cvt: Introducing convolutions to vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Co-scale conv-attentional image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Twins: Revisiting the design of spatial attention in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13840</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Levit: a vision transformer in convnet&apos;s clothing for faster inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>El-Nouby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Understanding robustness of transformers for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.15203</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cascaded partial decoder for fast and accurate salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Cbam: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y.</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>So Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Edge-aware graph representation learning and reasoning for face parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Te</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Graph-fcn for image semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">F 3 net: Fusion, feedback and focus for salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Ahmadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">How to evaluate foreground maps?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">in CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Structure-measure: A new way to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="2622" to="2638" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Cognitive vision inspired object segmentation metric and loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>SSI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Enhanced-alignment measure for binary foreground map evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Selective feature aggregation network with area-boundary constraints for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Towards automatic polyp detection with a polyp appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilarino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3166" to="3182" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
