<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficiently Modeling Long Sequences with Structured State Spaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
							<email>albertgu@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Efficiently Modeling Long Sequences with Structured State Spaces</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T19:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) x (t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t), and showed that for appropriate choices of the state matrix A, this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning A with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60? faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A central problem in sequence modeling is efficiently handling data that contains long-range dependencies (LRDs). Real-world time-series data often requires reasoning over tens of thousands of time steps, while few sequence models address even thousands of time steps. For instance, results from the long-range arena (LRA) benchmark <ref type="bibr" target="#b39">[40]</ref> highlight that sequence models today perform poorly on LRD tasks, including one (Path-X) where no model performs better than random guessing.</p><p>Since LRDs are perhaps the foremost challenge for sequence models, all standard model families such as continuous-time models (CTMs), RNNs, CNNs, and Transformers include many specialized variants designed to address them. Modern examples include orthogonal and Lipschitz RNNs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13]</ref> to combat vanishing gradients, dilated convolutions to increase context size <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref>, and an increasingly vast family of efficient Transformers that reduce the quadratic dependence on sequence length <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref>. Despite being designed for LRDs, these solutions still perform poorly on challenging benchmarks such as LRA <ref type="bibr" target="#b39">[40]</ref> or raw audio classification <ref type="bibr" target="#b17">[18]</ref>.</p><p>An alternative approach to LRDs was recently introduced based on the state space model (SSM) <ref type="figure">(Fig. 1</ref>). SSMs are a foundational scientific model used in fields such as control theory, computational neuroscience, and many more, but have not been applicable to deep learning for concrete theoretical reasons. In particular, Gu et al. <ref type="bibr" target="#b17">[18]</ref> showed that deep SSMs actually struggle even on simple tasks, but can perform exceptionally </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continuous State Space Fast Discrete Representations</head><p>Long-Range Dependencies <ref type="figure">Figure 1</ref>: (Left) State Space Models (SSM) parameterized by matrices A, B, C, D map an input signal u(t) to output y(t) through a latent state x(t). (Center) Recent theory on continuous-time memorization derives special A matrices that allow SSMs to capture LRDs mathematically and empirically. (Right) SSMs can be computed either as a recurrence (left) or convolution (right). However, materializing these conceptual views requires utilizing different representations of its parameters (red, blue, green) which are very expensive to compute. S4 introduces a novel parameterization that efficiently swaps between these representations, allowing it to handle a wide range of tasks, be efficient at both training and inference, and excel at long sequences.</p><p>well when equipped with special state matrices A recently derived to solve a problem of continuous-time memorization <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b44">45]</ref>. Their Linear State Space Layer (LSSL) conceptually unifies the strengths of CTM, RNN and CNN models, and provides a proof of concept that deep SSMs can address LRDs in principle.</p><p>Unfortunately, the LSSL is infeasible to use in practice because of prohibitive computation and memory requirements induced by the state representation. For state dimension N and sequence length L, computing the latent state requires O(N 2 L) operations and O(N L) space -compared to a ?(L + N ) lower bound for both. Thus for reasonably sized models (e.g. N = 256 in Gu et al. <ref type="bibr" target="#b17">[18]</ref>), the LSSL uses orders of magnitude more memory than comparably-sized RNNs or CNNs. Although theoretically efficient algorithms for the LSSL were proposed, we show that these are numerically unstable. In particular, the special A matrix is highly non-normal in the linear algebraic sense, which prevents the application of conventional algorithmic techniques. Consequently, although the LSSL showed that SSMs have strong performance, they are currently computationally impractical as a general sequence modeling solution.</p><p>In this work, we introduce the Structured State Space (S4) sequence model based on the SSM that solves the critical computational bottleneck in previous work. Technically, S4 reparameterizes the structured state matrices A appearing in Gu et al. <ref type="bibr" target="#b15">[16]</ref>, Voelker et al. <ref type="bibr" target="#b44">[45]</ref> by decomposing them as the sum of a low-rank and normal term. Additionally, instead of expanding the standard SSM in coefficient space, we compute its truncated generating function in frequency space, which can be simplified into a multipole-like evaluation. Combining these two ideas, we show that the low-rank term can be corrected by the Woodbury identity while the normal term can be diagonalized stably, ultimately reducing to a well-studied and theoretically stable Cauchy kernel <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>. This results in?(N + L) computation and O(N + L) memory usage, which is essentially tight for sequence models. Compared to the LSSL, S4 is up to 30? faster with 400? less memory usage, while exceeding the LSSL's performance empirically.</p><p>Empirically, S4 significantly advances the state-of-the-art for LRD. On the LRA benchmark for efficient sequence models, S4 is as fast as all baselines while outperforming them by 20+ points on average. S4 is the first model to solve the difficult LRA Path-X task (length-16384), achieving 88% accuracy compared to 50% random guessing for all prior work. On speech classification with length-16000 sequences, S4 halves the test error (1.7%) of specialized Speech CNNs -by contrast, all RNN and Transformer baselines fail to learn (? 70% error).</p><p>Towards a general-purpose sequence model. Beyond LRD, a broad goal of machine learning is to develop a single model that can be used across a wide range of problems. Models today are typically specialized to solve problems from a particular domain (e.g. images, audio, text, time-series), and enable a narrow range of capabilities (e.g. efficient training, fast generation, handling irregularly sampled data). This specialization is typically expressed via domain-specific preprocessing, inductive biases, and architectures. Sequence models provide a general framework for solving many of these problems with reduced specialization -e.g. Vision Transformers for image classification with less 2D information <ref type="bibr" target="#b11">[12]</ref>. However, most models such as Transformers generally still require substantial specialization per task to achieve high performance.</p><p>Deep SSMs in particular have conceptual strengths that suggest they may be promising as a general sequence modeling solution. These strengths include a principled approach to handling LRDs, as well as the ability to move between continuous-time, convolutional, and recurrent model representations, each with distinct capabilities <ref type="figure">(Fig. 1</ref>). Our technical contributions enable SSMs to be applied successfully to a varied set of benchmarks with minimal modification:</p><p>? Large-scale generative modeling. On CIFAR-10 density estimation, S4 is competitive with the best autoregressive models (2.85 bits per dim). On WikiText-103 language modeling, S4 substantially closes the gap to Transformers (within 0.8 perplexity), setting SoTA for attention-free models.</p><p>? Fast autoregressive generation. Like RNNs, S4 can use its latent state to perform 60? faster pixel/token generation than standard autoregressive models on CIFAR-10 and WikiText-103.</p><p>? Sampling resolution change. Like specialized CTMs, S4 can adapt to changes in time-series sampling frequency without retraining, e.g. at 0.5? frequency on speech classification.</p><p>? Learning with weaker inductive biases. With no architectural changes, S4 surpasses Speech CNNs on speech classification, outperforms the specialized Informer model on time-series forecasting problems, and matches a 2-D ResNet on sequential CIFAR with over 90% accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">State Space Models: A Continuous-time Latent State Model</head><p>The state space model is defined by the simple equation <ref type="bibr" target="#b0">(1)</ref>. It maps a 1-D input signal u(t) to an N -D latent state x(t) before projecting to a 1-D output signal y(t).</p><formula xml:id="formula_0">x (t) = Ax(t) + Bu(t) y(t) = Cx(t) + Du(t)<label>(1)</label></formula><p>SSMs are broadly used in many scientific disciplines and related to latent state models such as Hidden Markov Models (HMM). Our goal is to simply use the SSM as a black-box representation in a deep sequence model, where A, B, C, D are parameters learned by gradient descent. For the remainder of this paper, we will omit the parameter D for exposition (or equivalently, assume D = 0) because the term Du can be viewed as a skip connection and is easy to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Addressing Long-Range Dependencies with HiPPO</head><p>Prior work found that the basic SSM (1) actually performs very poorly in practice. Intuitively, one explanation is that linear first-order ODEs solve to an exponential function, and thus may suffer from gradients scaling exponentially in the sequence length (i.e., the vanishing/exploding gradients problem <ref type="bibr" target="#b31">[32]</ref>). To address this problem, the LSSL leveraged the HiPPO theory of continuous-time memorization <ref type="bibr" target="#b15">[16]</ref>. HiPPO specifies a class of certain matrices A ? R N ?N that when incorporated into (1), allows the state x(t) to memorize the history of the input u(t). The most important matrix in this class is defined by equation <ref type="formula" target="#formula_1">(2)</ref>, which we will call the HiPPO matrix. For example, the LSSL found that simply modifying an SSM from a random matrix A to equation (2) improved its performance on the sequential MNIST benchmark from 60% to 98%.</p><formula xml:id="formula_1">(HiPPO Matrix) A nk = ? ? ? ? ? ? (2n + 1) 1/2 (2k + 1) 1/2 if n &gt; k n + 1 if n = k 0 if n &lt; k .<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Discrete-time SSM: The Recurrent Representation</head><p>To be applied on a discrete input sequence (u 0 , u 1 , . . . ) instead of continuous function u(t), (1) must be discretized by a step size ? that represents the resolution of the input. Conceptually, the inputs u k can be viewed as sampling an implicit underlying continuous signal u(t), where u k = u(k?).</p><p>To discretize the continuous-time SSM, we follow prior work in using the bilinear method <ref type="bibr" target="#b42">[43]</ref>, which converts the state matrix A into an approximation A . The discrete SSM is</p><formula xml:id="formula_2">x k = Ax k?1 + Bu k A = (I ? ?/2 ? A) ?1 (I + ?/2 ? A) y k = Cx k B = (I ? ?/2 ? A) ?1 ?B C = C.<label>(3)</label></formula><p>Equation <ref type="formula" target="#formula_2">(3)</ref> is now a sequence-to-sequence map u k ? y k instead of function-to-function. Moreover the state equation is now a recurrence in x k , allowing the discrete SSM to be computed like an RNN. Concretely,</p><p>x k ? R N can be viewed as a hidden state with transition matrix A.</p><p>Notationally, throughout this paper we use A, B, . . . to denote discretized SSM matrices defined by <ref type="bibr" target="#b2">(3)</ref>. Note that these matrices are a function of both A as well as a step size ?; we suppress this dependence for notational convenience when it is clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training SSMs: The Convolutional Representation</head><p>The recurrent SSM <ref type="formula" target="#formula_2">(3)</ref> is not practical for training on modern hardware due to its sequentiality. Instead, there is a well-known connection between linear time-invariant (LTI) SSMs such as (1) and continuous convolutions. Correspondingly, (3) can actually be written as a discrete convolution.</p><p>For simplicity let the initial state be x ?1 = 0. Then unrolling (3) explicitly yields</p><formula xml:id="formula_3">x 0 = Bu 0 x 1 = ABu 0 + Bu 1 x 2 = A 2 Bu 0 + ABu 1 + Bu 2 . . . y 0 = CBu 0 y 1 = CABu 0 + CBu 1 y 2 = CA 2 Bu 0 + CABu 1 + CBu 2 . . .</formula><p>This can be vectorized into a convolution (4) with an explicit formula for the convolution kernel <ref type="bibr" target="#b4">(5)</ref>.</p><formula xml:id="formula_4">y k = CA k Bu 0 + CA k?1 Bu 1 + ? ? ? + CABu k?1 + CBu k y = K * u. (4) K ? R L := K L (A, B, C) := CA i B i?[L] = (CB, CAB, . . . , CA L?1 B).<label>(5)</label></formula><p>In other words, equation <ref type="formula">(4)</ref> is a single (non-circular) convolution and can be computed very efficiently with FFTs, provided that K is known. However, computing K in (5) is non-trivial and is the focus of our technical contributions in Section 3. We call K the SSM convolution kernel or filter. Section 3.1 motivates our approach, which is based on the linear algebraic concepts of conjugation and diagonalization, and discusses why the naive application of this approach does not work. Section 3.2 gives an overview of the key technical components of our approach and formally defines the S4 parameterization. Section 3.3 sketches the main results, showing that S4 is asymptotically efficient (up to log factors) for sequence models. Proofs are in Appendices B and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation: Diagonalization</head><p>The fundamental bottleneck in computing the discrete-time SSM (3) is that it involves repeated matrix multiplication by A. For example, computing (5) naively as in the LSSL involves L successive multiplications by A, requiring O(N 2 L) operations and O(N L) space.</p><p>To overcome this bottleneck, we use a structural result that allows us to simplify SSMs.</p><formula xml:id="formula_5">Lemma 3.1. Conjugation is an equivalence relation on SSMs (A, B, C) ? (V ?1 AV , V ?1 B, CV ).</formula><p>Proof. Write out the two SSMs with state denoted by x andx respectively:</p><formula xml:id="formula_6">x = Ax + Bux = V ?1 AVx + V ?1 Bu y = Cx y = CVx</formula><p>After multiplying the right side SSM by V , the two SSMs become identical with x = Vx. Therefore these compute the exact same operator u ? y, but with a change of basis by V in the state x.</p><p>Lemma 3.1 motivates putting A into a canonical form by conjugation 2 , which is ideally more structured and allows faster computation. For example, if A were diagonal, the resulting computations become much more tractable. In particular, the desired K (equation <ref type="formula">(4)</ref>) would be a Vandermonde product which theoretically only needs O((N + L) log 2 (N + L)) arithmetic operations <ref type="bibr" target="#b28">[29]</ref>.</p><p>Unfortunately, the naive application of diagonalization does not work due to numerical issues. Werive the explicit diagonalization for the HiPPO matrix (2) and show it has entries exponentially large in the state size N , rendering the diagonalization numerically infeasible (e.g. CV in Lemma 3.1 would not be computable). We note that Gu et al. <ref type="bibr" target="#b17">[18]</ref> proposed a different (unimplemented) algorithm to compute K faster than the naive algorithm. In Appendix B, we prove that it is also numerically unstable for related reasons.</p><formula xml:id="formula_7">Lemma 3.2. The HiPPO matrix A in equation (2) is diagonalized by the matrix V ij = i+j i?j . In particular, V 3i,i = 4i 2i ? 2 4i</formula><p>. Therefore V has entries of magnitude up to 2 4N/3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The S4 Parameterization: Normal Plus Low-Rank</head><p>The previous discussion implies that we should only conjugate by well-conditioned matrices V . The ideal scenario is when the matrix A is diagonalizable by a perfectly conditioned (i.e., unitary) matrix. By the Spectral Theorem of linear algebra, this is exactly the class of normal matrices. However, this class of matrices is restrictive; in particular, it does not contain the HiPPO matrix <ref type="bibr" target="#b1">(2)</ref>.</p><p>We make the observation that although the HiPPO matrix is not normal, it can be decomposed as the sum of a normal and low-rank matrix. However, this is still not useful by itself: unlike a diagonal matrix, powering up this sum (in (5)) is still slow and not easily optimized. We overcome this bottleneck by simultaneously applying three new techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 S4 Convolution Kernel (Sketch)</head><p>Input: S4 parameters ?, P , Q, B, C ? C N and step size ? Output: SSM convolution kernel K = K L (A, B, C) for A = ? ? P Q * (equation <ref type="formula" target="#formula_4">(5)</ref>)</p><formula xml:id="formula_8">1: C ? I ? A L * C Truncate SSM generating function (SSMGF) to length L 2: k 00 (?) k 01 (?) k 10 (?) k 11 (?) ? C Q * 2 ? 1?? 1+? ? ? ?1 [B P ] Black-box Cauchy kernel 3:K(?) ? 2 1+? k 00 (?) ? k 01 (?)(1 + k 11 (?)) ?1 k 10 (?) Woodbury Identity 4:K = {K(?) : ? = exp(2?i k L )} Evaluate SSMGF at all roots of unity ? ? ? L 5: K ? iFFT(K) Inverse Fourier Transform</formula><p>? Instead of computing K directly, we compute its spectrum by evaluating its truncated generating function L?1 j=0 K j ? j at the roots of unity ?. K can then be found by applying an inverse FFT. ? This generating function is closely related to the matrix resolvent, and now involves a matrix inverse instead of power. The low-rank term can now be corrected by applying the Woodbury identity which reduces (A + P Q * ) ?1 in terms of A ?1 , truly reducing to the diagonal case.</p><p>? Finally, we show that the diagonal matrix case is equivalent to the computation of a Cauchy kernel 1 ?j ?? k , a well-studied problem with stable near-linear algorithms <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>Our techniques apply to any matrix that can be decomposed as Normal Plus Low-Rank (NPLR).</p><p>Theorem 1. All HiPPO matrices from <ref type="bibr" target="#b15">[16]</ref> have a NPLR representation</p><formula xml:id="formula_9">A = V ?V * ? P Q = V (? ? (V * P ) (V * Q) * ) V *<label>(6)</label></formula><p>for unitary V ? C N ?N , diagonal ?, and low-rank factorization P , Q ? R N ?r . These matrices HiPPO-LegS,</p><p>LegT, LagT all satisfy r = 1 or r = 2. In particular, equation <ref type="formula" target="#formula_1">(2)</ref> is NPLR with r = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">S4 Algorithms and Computational Complexity</head><p>By equation <ref type="bibr" target="#b5">(6)</ref>, note that NPLR matrices can be conjugated into diagonal plus low-rank (DPLR) form (now over C instead of R). Theorems 2 and 3 describe the complexities of SSMs where A is in DPLR form. S4 is optimal or near-optimal for both recurrent and convolutional representations.</p><p>Theorem 2 (S4 Recurrence). Given any step size ?, computing one step of the recurrence (3) can be done in O(N ) operations where N is the state size.</p><p>Theorem 2 follows from the fact that the inverse of a DPLR matrix is also DPLR (e.g. also by the Woodbury identity). This implies that the discretized matrix A is the product of two DPLR matrices and thus has O(N ) matrix-vector multiplication. Appendix C.2 computes A in closed DPLR form. Appendix C, Definition 3 formally defines Cauchy matrices, which are related to rational interpolation problems. Computing with Cauchy matrices is an extremely well-studied problem in numerical analysis, with both fast arithmetic and numerical algorithms based on the famous Fast Multipole Method (FMM) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. The computational complexities of these algorithms under various settings are described in Appendix C, Proposition 5.</p><p>We reiterate that Theorem 3 is our core technical contribution, and its algorithm is the very motivation of the NPLR S4 parameterization. This algorithm is formally sketched in Algorithm 1. Note that the core S4 module is a linear transformation, but the addition of non-linear transformations through the depth of the network makes the overall deep SSM non-linear. This is analogous to a vanilla CNN, since convolutional layers are also linear. The broadcasting across H hidden features described in this section is also analogous to depthwise-separable convolutions. Thus, the overall deep S4 model is closely related to a depthwise-separable CNN but with global convolution kernels.</p><p>Finally, we note that follow-up work found that this version of S4 can sometimes suffer from numerical instabilities when the A matrix has eigenvalues on the right half-plane <ref type="bibr" target="#b13">[14]</ref>. It introduced a slight change to the NPLR parameterization for S4 from ? ? P Q * to ? ? P P * that corrects this potential problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">S4 Efficiency Benchmarks</head><p>We benchmark that S4 can be trained quickly and efficiently, both compared to the LSSL, as well as efficient Transformer variants designed for long-range sequence modeling. As outlined in Section 3, S4 is theoretically much more efficient than the LSSL, and <ref type="table" target="#tab_4">Table 2</ref> confirms that the S4 is orders of magnitude more speed-and memory-efficient for practical layer sizes. In fact, S4's speed and memory use is competitive with the most    </p><formula xml:id="formula_10">Performer 1.23? 0.43? 3.79? 0.086? Linear Trans. 1.58? 0.37? 5.35? 0.067? S4 1.58? 0.43? 5.19? 0.091?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning Long Range Dependencies</head><p>As described in Sections 2.2 and 3.1, S4 uses a principled approach to address LRDs based on the HiPPO theory of continuous-time memorization. Our goal in this section is to validate that S4 achieves high performance on difficult tasks that require long-range reasoning. We focus here on two problems: (i) the Long-Range Arena, a well-known benchmark designed to test efficient sequence models on LRDs, and (ii) a speech classification problem as a real-world test of LRDs.</p><p>Long Range Arena (LRA). LRA <ref type="bibr" target="#b39">[40]</ref> contains 6 tasks with lengths 1K-16K steps, encompassing modalities and objectives that require similarity, structural, and visuospatial reasoning. <ref type="table" target="#tab_6">Table 4</ref> compares S4 against the 11 Transformer variants from Tay et al. <ref type="bibr" target="#b39">[40]</ref> as well as follow-up work. S4 substantially advances the SoTA, outperforming all baselines on all tasks and averaging 80.48% compared to less than 60% for every baseline. Notably, S4 solves the Path-X task, an extremely challenging task that involves reasoning about LRDs over sequences of length 128 ? 128 = 16384. All previous models have failed (i.e. random guessing) due to memory or computation bottlenecks, or simply being unable to learn such long dependencies.</p><p>We analyze S4's performance on Path-X by visualizing its learned representations, in particular 1-D convolution kernels K which are the focus of our technical results in Section 3. <ref type="figure" target="#fig_2">Fig. 2</ref> shows that S4 learns a variety of filters that display spatially consistent structure and demonstrate awareness of the 2-D nature of the data. In particular, the lower layers learn simple kernels that extract features from just a few rows of local context while ignoring the rest of the image. On the other hand, higher layers aggregate information globally across full columns of the image at varying spatial frequencies. Filters in these higher layers span the entire context (16384 pixels), confirming S4's ability to learn LRDs.</p><p>Raw Speech Classification. Speech is a typical real-world time series domain, involving signals sampled from an underlying physical process at high frequency. We perform speech classification using the SC10 subset of the Speech Commands dataset <ref type="bibr" target="#b46">[47]</ref> (see Appendix D.5). While most sequence models for speech rely on extensive preprocessing (e.g. to MFCC features), we classify raw speech (length-16000) following Romero et al. <ref type="bibr" target="#b34">[35]</ref>. S4 achieves 98.3% accuracy, higher than all baselines that use the 100? shorter MFCC features, and validates that a powerful LRD model is able to extract more information from the raw data and outperform hand-crafted pre-processing. Additionally, we include a baseline CNN specifically designed for raw speech, the discriminator from the WaveGAN model <ref type="bibr" target="#b10">[11]</ref>, which performs worse than S4 while having 90? more parameters and incorporating many more architectural heuristics (Appendix D.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">S4 as a General Sequence Model</head><p>A key goal of sequence modeling research is to develop a single model that can be applied in many domains (e.g. images, audio, text, time-series) with a broad range of capabilities (e.g. efficient training, fast generation, handling irregularly sampled data). As a fundamental scientific model, SSMs are a promising candidate that come with a range of capabilities, and S4's strong results on LRD benchmarks spanning images, text, and speech are evidence of S4's potential as a general sequence model. In this section, we focus on understanding this question in more depth by highlighting key strengths of S4 in settings that usually require specialized    Large-scale generative modeling. We investigate two well-studied image and text benchmarks to validate the scalability, flexibility, and efficiency of S4. These tasks require much larger models than our previous tasks -up to 250M parameters.</p><p>First, CIFAR density estimation is a popular benchmark for autoregressive models, where images are flattened into a sequence of 3072 RGB subpixels that are predicted one by one. <ref type="table" target="#tab_9">Table 7</ref> shows that with no 2D inductive bias, S4 is competitive with the best models designed for this task.</p><p>Second, WikiText-103 is an established benchmark for language modeling, an important task for large-scale sequence models where tokens are predicted sequentially based on past context. Although RNNs were the model of choice for many years, Transformers are now the dominant model in such applications that contain data that is inherently discrete. We show that alternative models to Transformers can still be competitive in these settings. By simply taking a strong Transformer baseline <ref type="bibr" target="#b1">[2]</ref> and replacing the self-attention layers, S4 substantially closes the gap to Transformers (within 0.8 ppl), setting SoTA for attention-free models by over 2 ppl.</p><p>Fast autoregressive inference. A prominent limitation of autoregressive models is inference speed (e.g. generation), since they require a pass over the full context for every new sample. Several methods have been specifically crafted to overcome this limitation such as the Linear Transformer, a hybrid Transformer/RNN that switches to a stateful, recurrent view at inference time for speed.</p><p>As a stateful model, SSMs automatically have this ability ( <ref type="figure">Fig. 1</ref>). By switching to its recurrent representation (Section 2.3), S4 requires constant memory and computation per time step -in contrast to standard autoregressive models which scale in the context length. On both CIFAR-10 and WikiText-103, we report the throughput of various models at generation time, with S4 around 60? faster than a vanilla Transformer on both tasks (details in Appendix D.3.3).</p><p>Sampling resolution change. As a continuous-time model, S4 automatically adapts to data sampled at different rates, a challenging setting for time series with a dedicated line of work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>. Without re-training, S4 achieves 96.3% accuracy at 0.5? the frequency on Speech Commands 10 ( <ref type="table" target="#tab_7">Table 5)</ref>, simply by changing its internal step size ? (Section 2.3).</p><p>Learning with weaker inductive bias. Beyond our results on speech (Section 4.2), we further validate that S4 can be applied with minimal modifications on two domains that typically require specialized domainspecific preprocessing and architectures. First, we compare S4 to the Informer <ref type="bibr" target="#b49">[50]</ref>, a new Transformer architecture that uses a complex encoder-decoder designed for time-series forecasting problems. A simple application of S4 that treats forecasting as a masked sequence-to-sequence transformation ( <ref type="figure" target="#fig_7">Fig. 5</ref>) outperforms the Informer and other baselines on 40/50 settings across 5 forecasting tasks. Notably, S4 is better on the longest setting in each task, e.g. reducing MSE by 37% when forecasting 30 days of weather data <ref type="table" target="#tab_12">(Table 9</ref>).</p><p>Finally, we evaluate S4 on pixel-level sequential image classification tasks <ref type="table" target="#tab_8">(Table 6)</ref>, popular benchmarks which were originally LRD tests for RNNs <ref type="bibr" target="#b0">[1]</ref>. Beyond LRDs, these benchmarks point to a recent effort of the ML community to solve vision problems with reduced domain knowledge, in the spirit of models such as Vision Transformers <ref type="bibr" target="#b11">[12]</ref> and MLP-Mixer <ref type="bibr" target="#b40">[41]</ref>  As a simple testbed, all experiments in this section were performed on the sequential CIFAR-10 task, whicih we found transferred well to other settings. Models were constrained to at most 100K trainable parameters and trained with a simple plateau learning rate scheduler and no regularization.</p><p>Unconstrained SSMs. We first investigate generic SSMs with various initializations. We consider a random Gaussian initialization (with variance scaled down until it did not NaN), and the HiPPO initialization. We also consider a random diagonal Gaussian matrix as a potential structured method; parameterizing A as a diagonal matrix would allow substantial speedups without going through the complexity of S4's NPLR parameterization. We consider both freezing the A matrix and training it. Second, a large generalization gap exists between the initializations. In particular, note that when A is trained, all initializations are able to reach perfect training accuracy. However, their validation accuracies are separated by over 15%.</p><p>NPLR SSMs. The previous experiment validates the importance of HiPPO in SSMs. This was the main motivation of the NPLR algorithm in S4, which utilizes structure of the HiPPO matrix (2) to make SSMs computationally feasible. <ref type="figure">Fig. 4a</ref> shows that random NPLR matrices still do not perform well, which validates that S4's effectiveness primarily comes from the HiPPO initialization, not the NPLR parameterization.</p><p>Finally, <ref type="figure">Fig. 4b</ref> considers the main ablations considered in this section (with trainable SSMs) and adds minor regularization. With 0.1 Dropout, the same trends still hold, and the HiPPO initialization-in other words, the full S4 method-achieves 84.27% test accuracy with just 100K parameters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We introduce S4, a sequence model that uses a new parameterization for the state space model's continuoustime, recurrent, and convolutional views to efficiently model LRDs in a principled manner. Results across established benchmarks evaluating a diverse range of data modalities and model capabilities suggest that S4 has the potential to be an effective general sequence modeling solution.</p><p>the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of NIH, ONR, or the U.S. Government.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Discussion</head><p>Related Work. Our work is most closely related to a line of work originally motivated by a particular biologically-inspired SSM, which led to mathematical models for addressing LRDs. Voelker et al. <ref type="bibr" target="#b44">[45]</ref>, Voelker <ref type="bibr" target="#b45">[46]</ref> derived a non-trainable SSM motivated from approximating a neuromorphic spiking model, and Chilkuri and Eliasmith <ref type="bibr" target="#b6">[7]</ref> showed that it could be sped up at train time with a convolutional view. Gu et al. <ref type="bibr" target="#b15">[16]</ref> extended this special case to a general continuous-time function approximation framework with several more special cases of A matrices designed for long-range dependencies. However, instead of using a true SSM, all of these works fixed a choice of A and built RNNs around it. Most recently, Gu et al. <ref type="bibr" target="#b17">[18]</ref> used the full (1) explicitly as a deep SSM model, exploring new conceptual views of SSMs, as well as allowing A to be trained. As mentioned in Section 1, their method used a naive instantiation of SSMs that suffered from an additional factor of N in memory and N 2 in computation.</p><p>Beyond this work, our technical contributions (Section 3) on the S4 parameterization and algorithms are applicable to a broader family of SSMs including these investigated in prior works, and our techniques for working with these models may be of independent interest.</p><p>Implementation. The computational core of S4's training algorithm is the Cauchy kernel discussed in Sections 3.2 and 3.3 and Appendix C.3. As described in Appendix C.3 Proposition 5, there are many algorithms for it with differing computational complexities and sophistication. Our current implementation of S4 actually uses the naive O(N L) algorithm which is easily parallelized on GPUs and has more easily accessible libraries allowing it to be implemented; we leverage the pykeops library for memory-efficient kernel operations. However, this library is a much more general library that may not be optimized for the Cauchy kernels used here, and we believe that a dedicated CUDA implementation can be more efficient.</p><p>Additionally, as discussed in this work, there are asymptotically faster and numerically stable algorithms for the Cauchy kernel (Proposition 5). However, these algorithms are currently not implemented for GPUs due to a lack of previous applications that require them. We believe that more efficient implementations of these self-contained computational kernels are possible, and that S4 (and SSMs at large) may have significant room for further improvements in efficiency.</p><p>Limitations and Future Directions. In this work, we show that S4 can address a wide variety of data effectively. However, it may not necessarily be the most suitable model for all types of data. For example, <ref type="table" target="#tab_10">Table 8</ref> still found a gap compared to Transformers for language modeling. An interesting future direction is exploring combinations of S4 with other sequence models to complement their strengths. We are excited about other directions, including continuing to explore the benefits of S4 on audio data (e.g. pre-training or generation settings), and generalizing HiPPO and S4 to higher-dimensional data for image and video applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Numerical Instability of LSSL</head><p>This section proves the claims made in Section 3.1 about prior work. We first derive the explicit diagonalization of the HiPPO matrix, confirming its instability because of exponentially large entries. We then discuss the proposed theoretically fast algorithm from <ref type="bibr" target="#b17">[18]</ref> (Theorem 2) and show that it also involves exponentially large terms and thus cannot be implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 HiPPO Diagonalization</head><p>Proof of Lemma 3.2. The HiPPO matrix (2) is equal, up to sign and conjugation by a diagonal matrix, to</p><formula xml:id="formula_11">A = ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ?1 2 1 ?3 3 ?1 3 ?5 4 1 ?3 5 ?7 5 ?1 3 ?5 7 ?9 6 1 ?3 5 ?7 9 ?11 7 ?1 3 ?5 7 ?9 11 ?13 8 . . . . . . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? A nk = ? ? ? ? ? (?1) n?k (2k + 1) n &gt; k k + 1 n = k 0 n &lt; k .</formula><p>Our goal is to show that this A is diagonalized by the matrix </p><formula xml:id="formula_12">V = i + j i ? j ij = ? ? ? ? ? ? ? ? ? ? ?</formula><formula xml:id="formula_13">? ? ? ? ? ? ? ? ? ? ? ,</formula><p>or in other words that columns of this matrix are eigenvectors of A.</p><p>Concretely, we will show that the j-th column of this matrix v (j) with elements v (j) i</p><formula xml:id="formula_14">= 0 i &lt; j i+j i?j = i+j 2j i ? j</formula><p>is an eigenvector with eigenvalue j + 1. In other words we must show that for all indices k ? [N ],</p><formula xml:id="formula_15">(Av (j) ) k = i A ki v (j) i = (j + 1)v (j) k .<label>(7)</label></formula><p>If k &lt; j, then for all i inside the sum, either k &lt; i or i &lt; j. In the first case A ki = 0 and in the second case v (j) i = 0, so both sides of equation <ref type="formula" target="#formula_15">(7)</ref> are equal to 0.</p><p>It remains to show the case k ? j, which proceeds by induction on k. Expanding equation <ref type="formula" target="#formula_15">(7)</ref> using the formula for A yields (Av)</p><formula xml:id="formula_16">(j) k = i A ki v (j) i = k?1 i=j (?1) k?i (2i + 1) i + j 2j + (k + 1) k + j 2j .</formula><p>In the base case k = j, the sum disappears and we are left with (Av (j) ) j = (j + 1) 2j 2j = (j + 1)v (j) j , as desired.</p><p>Otherwise, the sum for (Av) (j) k is the same as the sum for (Av) (j) k?1 but with sign reversed and a few edge terms. The result follows from applying the inductive hypothesis and algebraic simplification: There are several reasons for the instability of this algorithm, but most directly we can pinpoint a particular intermediate quantity that they use.</p><formula xml:id="formula_17">(Av) (j) k = ?(Av) (j) k?1 ? (2k ? 1) k ? 1 + j 2j + k k ? 1 + j 2j + (k + 1) k + j 2j = ?(j + 1) k ? 1 + j 2j ? (k ? 1) k ? 1 + j 2j + (k + 1) k + j 2j = ?(j + k) k ? 1 + j 2j + (k + 1) k + j 2j = ?(j + k) (k ? 1 + j)! (k ? 1 ? j)!(2j)! + (k + 1) k + j 2j = ? (k + j)! (k ? 1 ? j)!(2j)! + (k + 1) k + j 2j = ?(k ? j) (k + j)! (k ? j)!(2j)! + (k + 1) k + j 2j = (j ? k)(k + 1) k + j 2j + (k + 1) k + j 2j = (j + 1)v (j) k .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Fast but Unstable LSSL Algorithm</head><p>Definition 1. The fast LSSL algorithm computes coefficients of p(x), the characteristic polynomial of A, as an intermediate computation. Additionally, it computes the coefficients of its inverse, p(x) ?1 (mod x L ).</p><p>We now claim that this quantity is numerically unfeasible. We narrow down to the case when A = I is the identity matrix. Note that this case is actually in some sense the most typical case: when discretizing the continuous-time SSM to discrete-time by a step-size ?, the discretized transition matrix A is brought closer to the identity. For example, with the Euler discretization A = I + ?A, we have A ? I as the step size ? ? 0.</p><p>Lemma B.1. When A = I, the fast LSSL algorithm requires computing terms exponentially large in N .</p><p>Proof. The characteristic polynomial of I is</p><formula xml:id="formula_18">p(x) = det |I ? xI| = (1 ? x) N .</formula><p>These coefficients have size up to N N 2</p><formula xml:id="formula_19">? 2 N ? ?N/2 .</formula><p>The inverse of p(x) has even larger coefficients. It can be calculated in closed form by the generalized binomial formula:</p><formula xml:id="formula_20">(1 ? x) ?N = ? k=0 N + k ? 1 k x k .</formula><p>Taking this (mod x L ), the largest coefficient is</p><formula xml:id="formula_21">N + L ? 2 L ? 1 = N + L ? 2 N ? 1 = (L ? 1)(L ? 2) . . . (L ? N + 1) (N ? 1)! . When L = N ? 1 this is 2(N ? 1) N ? 1 ? 2 2N ? ?N</formula><p>already larger than the coefficients of (1 ? x) N , and only increases as L grows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C S4 Algorithm Details</head><p>This section proves the results of Section 3.3, providing complete details of our efficient algorithms for S4.</p><p>Appendices C.1 to C.3 prove Theorems 1 to 3 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 NPLR Representations of HiPPO Matrices</head><p>We first prove Theorem 1, showing that all HiPPO matrices for continuous-time memory fall under the S4 normal plus low-rank (NPLR) representation.</p><p>Proof of Theorem 1. We consider each of the three cases HiPPO-LagT, HiPPO-LegT, and HiPPO-LegS separately. Note that the primary HiPPO matrix defined in this work (equation <ref type="formula" target="#formula_1">(2)</ref>) is the HiPPO-LegT matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HiPPO-LagT. The HiPPO-LagT matrix is simply</head><formula xml:id="formula_22">A nk = ? ? ? ? ? 0 n &lt; k ? 1 2 n = k ?1 n &gt; k A = ? ? ? ? ? ? ? ? 1 2 . . . 1 1 2 1 1 1 2 1 1 1 1 2 . . . . . . ? ? ? ? ? ? ? .</formula><p>Adding the matrix of all 1 2 , which is rank 1, yields</p><formula xml:id="formula_23">? ? ? ? ? ? 1 2 ? 1 2 ? 1 2 1 2 ? 1 2 ? 1 2 1 2 1 2 ? 1 2 1 2 1 2 1 2 ? ? ? ? .</formula><p>This matrix is now skew-symmetric. Skew-symmetric matrices are a particular case of normal matrices with pure-imaginary eigenvalues.</p><p>Gu et al. <ref type="bibr" target="#b15">[16]</ref> also consider a case of HiPPO corresponding to the generalized Laguerre polynomials that generalizes the above HiPPO-LagT case. In this case, the matrix A (up to conjugation by a diagonal matrix) ends up being close to the above matrix, but with a different element on the diagonal. After adding the rank-1 correction, it becomes the above skew-symmetric matrix plus a multiple of the identity. Thus after diagonalization by the same matrix as in the LagT case, it is still reduced to diagonal plus low-rank (DPLR) form, where the diagonal is now pure imaginary plus a real constant.</p><p>HiPPO-LegS. We restate the formula from equation <ref type="formula" target="#formula_1">(2)</ref> for convenience.</p><formula xml:id="formula_24">A nk = ? ? ? ? ? ? (2n + 1) 1/2 (2k + 1) 1/2 if n &gt; k n + 1 if n = k 0 if n &lt; k . Adding 1 2 (2n + 1) 1/2 (2k + 1) 1/2 to the whole matrix gives ? ? ? ? ? ? 1 2 (2n + 1) 1/2 (2k + 1) 1/2 if n &gt; k 1 2 if n = k ? 1 2 (2n + 1) 1/2 (2k + 1) 1/2 if n &lt; k</formula><p>Note that this matrix is not skew-symmetric, but is 1 2 I + S where S is a skew-symmetric matrix. This is diagonalizable by the same unitary matrix that diagonalizes S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HiPPO-LegT.</head><p>Up to the diagonal scaling, the LegT matrix is</p><formula xml:id="formula_25">A = ? ? ? ? ? ? ? ? 1 ?1 1 ?1 . . . 1 1 ?1 1 1 1 1 ?1 1 1 1 1 . . . . . . ? ? ? ? ? ? ? .</formula><p>By adding ?1 to this matrix and then the matrix</p><formula xml:id="formula_26">? ? ? ? 2 2 2 2 ? ? ? ? the matrix becomes ? ? ? ? ?2 ?2 2 ?2 2 2 ? ? ? ?</formula><p>which is skew-symmetric. In fact, this matrix is the inverse of the Chebyshev Jacobi.</p><p>An alternative way to see this is as follows. The LegT matrix is the inverse of the matrix</p><formula xml:id="formula_27">? ? ? ? ?1 1 0 ?1 1 ?1 1 ?1 ?1 ? ? ? ?</formula><p>This can obviously be converted to a skew-symmetric matrix by adding a rank 2 term. The inverses of these matrices are also rank-2 differences from each other by the Woodbury identity.</p><formula xml:id="formula_28">A final form is ? ? ? ? ?1 1 ?1 1 ?1 ?1 1 ?1 ?1 ?1 ?1 1 ?1 ?1 ?1 ?1 ? ? ? ? + ? ? ? ? 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 ? ? ? ? = ? ? ? ? 0 1 0 1 ?1 0 1 0 0 ?1 0 1 ?1 0 ?1 0 ? ? ? ?</formula><p>This has the advantage that the rank-2 correction is symmetric (like the others), but the normal skewsymmetric matrix is now 2-quasiseparable instead of 1-quasiseparable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Computing the S4 Recurrent View</head><p>We prove Theorem 2 showing the efficiency of the S4 parameterization for computing one step of the recurrent representation (Section 2.3).</p><p>Recall that without loss of generality, we can assume that the state matrix A = ? ? P Q * is diagonal plus low-rank (DPLR), potentially over C. Our goal in this section is to explicitly write out a closed form for the discretized matrix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall from equation (3) that</head><formula xml:id="formula_29">A = (I ? ?/2 ? A) ?1 (I + ?/2 ? A) B = (I ? ?/2 ? A) ?1 ?B.</formula><p>We first simplify both terms in the definition of A independently.</p><p>Forward discretization. The first term is essentially the Euler discretization motivated in Section 2.3.</p><formula xml:id="formula_30">I + ? 2 A = I + ? 2 (? ? P Q * ) = ? 2 2 ? I + (? ? P Q * ) = ? 2 A 0</formula><p>where A 0 is defined as the term in the final brackets.</p><p>Backward discretization. The second term is known as the Backward Euler's method. Although this inverse term is normally difficult to deal with, in the DPLR case we can simplify it using Woodbury's Identity (Proposition 4).</p><formula xml:id="formula_31">I ? ? 2 A ?1 = I ? ? 2 (? ? P Q * ) ?1 = 2 ? 2 ? ? ? + P Q * ?1 = 2 ? D ? DP (I + Q * DP ) ?1 Q * D = 2 ? A 1</formula><p>where D = 2 ? ? ? ?1 and A 1 is defined as the term in the final brackets. Note that (1 + Q * DP ) is actually a scalar in the case when the low-rank term has rank 1.</p><p>S4 Recurrence. Finally, the full bilinear discretization can be rewritten in terms of these matrices as</p><formula xml:id="formula_32">A = A 1 A 0 B = 2 ? A 1 ?B = 2A 1 B.</formula><p>The discrete-time SSM (3) becomes</p><formula xml:id="formula_33">x k = Ax k?1 + Bu k = A 1 A 0 x k?1 + 2A 1 Bu k y k = Cx k .</formula><p>Note that A 0 , A 1 are accessed only through matrix-vector multiplications. Since they are both DPLR, they have O(N ) matrix-vector multiplication, showing Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Computing the Convolutional View</head><p>The most involved part of using SSMs efficiently is computing K. This algorithm was sketched in Section 3.2 and is the main motivation for the S4 parameterization. In this section, we define the necessary intermediate quantities and prove the main technical result.</p><p>The algorithm for Theorem 3 falls in roughly three stages, leading to Algorithm 1. Assuming A has been conjugated into diagonal plus low-rank form, we successively simplify the problem of computing K by applying the techniques outlined in Section 3.2.</p><p>Remark C.1. We note that for the remainder of this section, we transpose C to be a column vector of shape C N or C N ?1 instead of matrix or row vector C 1?N as in <ref type="bibr" target="#b0">(1)</ref>. In other words the SSM is</p><formula xml:id="formula_34">x (t) = Ax(t) + Bu(t) y(t) = C * x(t) + Du(t).<label>(8)</label></formula><p>This convention is made so that C has the same shape as B, P , Q and simplifies the implementation of S4.</p><p>Reduction 0: Diagonalization By Lemma 3.1, we can switch the representation by conjugating with any unitary matrix. For the remainder of this section, we can assume that A is (complex) diagonal plus low-rank (DPLR).</p><p>Note that unlike diagonal matrices, a DPLR matrix does not lend itself to efficient computation of K. The reason is that K computes terms C * A i B which involve powers of the matrix A. These are trivially computable when A is diagonal, but is no longer possible for even simple modifications to diagonal matrices such as DPLR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reduction 1: SSM Generating Function</head><p>To address the problem of computing powers of A, we introduce another technique. Instead of computing the SSM convolution filter K directly, we introduce a generating function on its coefficients and compute evaluations of it.</p><p>Definition 2 (SSM Generating Function). We define the following quantities:</p><p>? The SSM convolution function is K(A, B, C) = (C * B, C * AB, . . . ) and the (truncated) SSM filter of</p><formula xml:id="formula_35">length L K L (A, B, C) = (C * B, C * AB, . . . , C * A L?1 B) ? R L<label>(9)</label></formula><p>? The SSM generating function at node z i?</p><formula xml:id="formula_36">K(z; A, B, C) ? C := ? i=0 C * A i Bz i = C * (I ? Az) ?1 B<label>(10)</label></formula><p>and the truncated SSM generating function at node z i?</p><formula xml:id="formula_37">K L (z; A, B, C) * ? C := L?1 i=0 C * A i Bz i = C * (I ? A L z L )(I ? Az) ?1 B<label>(11)</label></formula><p>? The truncated SSM generating function at nodes ? ? C M i? K L (?; A, B, C) ? C M := K L (? k ; A, B, C)</p><formula xml:id="formula_38">k?[M ]<label>(12)</label></formula><p>Intuitively, the generating function essentially converts the SSM convolution filter from the time domain to frequency domain. Importantly, it preserves the same information, and the desired SSM convolution filter can be recovered from evaluations of its generating function. Proof. For convenience define <ref type="figure">(z; A, B, C)</ref>.</p><formula xml:id="formula_39">K = K L (A, B, C) K =K L (?; A, B, C) K(z) =K L</formula><formula xml:id="formula_40">Note thatK j = L?1 k=0 K k exp ?2?i jk L .</formula><p>Note that this is exactly the same as the Discrete Fourier Transform (DFT):</p><formula xml:id="formula_41">K = F L K.</formula><p>Therefore K can be recovered fromK with a single inverse DFT, which requires O(L log L) operations with the Fast Fourier Transform (FFT) algorithm.</p><p>Reduction 2: Woodbury Correction The primary motivation of Definition 2 is that it turns powers of A into a single inverse of A (equation <ref type="formula" target="#formula_0">(10)</ref>). While DPLR matrices cannot be powered efficiently due to the low-rank term, they can be inverted efficiently by the well-known Woodbury identity.</p><p>Proposition 4 (Binomial Inverse Theorem or Woodbury matrix identity <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b47">48]</ref>). Over a commutative ring</p><formula xml:id="formula_42">R, let A ? R N ?N and U , V ? R N ?p . Suppose A and A + U V * are invertible. Then I p + V * A ?1 U ? R p?p is invertible and (A + U V * ) ?1 = A ?1 ? A ?1 U (I p + V * A ?1 U ) ?1 V * A ?1</formula><p>With this identity, we can convert the SSM generating function on a DPLR matrix A into one on just its diagonal component.</p><p>Lemma C.3. Let A = ? ? P Q * be a diagonal plus low-rank representation. Then for any root of unity z ? ?, the truncated generating function satisfie?</p><formula xml:id="formula_43">K(z) = 2 1 + z C * R(z)B ?C * R(z)P (1 + Q * R(z)P ) ?1 Q * R(z)B C = (I ? A L ) * C R(z; ?) = 2 ? 1 ? z 1 + z ? ? ?1 .</formula><p>Proof. Directly expanding Definition 2 yields</p><formula xml:id="formula_44">K L (z; A, B, C) = C * B + C * ABz + ? ? ? + C * A L?1 Bz L?1 = C * I ? A L I ? Az ?1 B =C * I ? Az ?1 B whereC * = C * I ? A L .</formula><p>We can now explicitly expand the discretized SSM matrices A and B back in terms of the original SSM parameters A and B. Lemma C.4 provides an explicit formula, which allows further simplifying</p><formula xml:id="formula_45">C * I ? Az ?1 B = 2 1 + zC * 2 ? 1 ? z 1 + z ? A ?1 B = 2 1 + zC * 2 ? 1 ? z 1 + z ? ? + P Q * ?1 B = 2 1 + z C * R(z)B ?C * R(z)P (1 + Q * R(z)P ) ?1 Q * R(z)B .</formula><p>The last line applies the Woodbury Identity (Proposition 4) where R(z) = 2</p><formula xml:id="formula_46">? 1?z 1+z ? ? ?1 .</formula><p>The previous proof used the following self-contained result to back out the original SSM matrices from the discretization.</p><p>Lemma C.4. Let A, B be the SSM matrices A, B discretized by the bilinear discretization with step size ?. Then</p><formula xml:id="formula_47">C * I ? Az ?1 B = 2? 1 + z C * 2 1 ? z 1 + z ? ?A ?1 B</formula><p>Proof. Recall that the bilinear discretization that we use (equation <ref type="formula" target="#formula_2">(3)</ref>) is</p><formula xml:id="formula_48">A = I ? ? 2 A ?1 I + ? 2 A B = I ? ? 2 A ?1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?B</head><p>The result is proved algebraic manipulations.</p><formula xml:id="formula_49">C * I ? Az ?1 B = C * I ? ? 2 A ?1 I ? ? 2 A ? I ? ? 2 A ?1 I + ? 2 A z ?1 B = C * I ? ? 2 A ? I + ? 2 A z ?1 I ? ? 2 A B = C * I(1 ? z) ? ? 2 A(1 + z) ?1 ?B = ? 1 ? z C * I ? ?A 2 1?z 1+z ?1 B = 2? 1 + z C * 2 1 ? z 1 + z I ? ?A ?1 B</formula><p>Note that in the S4 parameterization, instead of constantly computingC = I ? A L * C, we can simply reparameterize our parameters to learnC directly instead of C, saving a minor computation cost and simplifying the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reduction 3: Cauchy Kernel</head><p>We have reduced the original problem of computing K to the problem of computing the SSM generating functionK L (?; A, B, C) in the case that A is a diagonal matrix. We show that this is exactly the same as a Cauchy kernel, which is a well-studied problem with fast and stable numerical algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3.</head><p>A Cauchy matrix or kernel on nodes ? = (? i ) ? C M and ? = (? j ) ? C N is</p><formula xml:id="formula_50">M ? C M ?N = M (?, ?) = (M ij ) i?[M ],j?[N ] M ij = 1 ? i ? ? j .</formula><p>The computation time of a Cauchy matrix-vector product of size M ? N is denoted by C(M, N ).</p><p>Computing with Cauchy matrices is an extremely well-studied problem in numerical analysis, with both fast arithmetic algorithms and fast numerical algorithms based on the famous Fast Multipole Method (FMM) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. Proof. For any fixed ? ? ?, we want to compute j q * j pj ???j . Computing this over all ? i is therefore exactly a Cauchy matrix-vector multiplication.</p><p>This completes the proof of Theorem 3. In Algorithm 1, note that the work is dominated by Step 2, which has a constant number of calls to a black-box Cauchy kernel, with complexity given by Proposition 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Experiment Details and Full Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Benchmarking</head><p>Benchmarking results from <ref type="table" target="#tab_4">Table 2</ref> and <ref type="table" target="#tab_5">Table 3</ref> were tested on a single A100 GPU.</p><p>Benchmarks against LSSL For a given dimension H, a single LSSL or S4 layer was constructed with H hidden features. For LSSL, the state size N was set to H as done in <ref type="bibr" target="#b17">[18]</ref>. For S4, the state size N was set to parameter-match the LSSL, which was a state size of N 4 due to differences in the parameterization. <ref type="table" target="#tab_4">Table 2</ref> benchmarks a single forward+backward pass of a single layer. Benchmarks against Efficient Transformers Following <ref type="bibr" target="#b39">[40]</ref>, the Transformer models had 4 layers, hidden dimension 256 with 4 heads, query/key/value projection dimension 128, and batch size 32, for a total of roughly 600k parameters. The S4 model was parameter tied while keeping the depth and hidden dimension constant (leading to a state size of N = 256).</p><p>We note that the relative orderings of these methods can vary depending on the exact hyperparameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Long-Range Dependencies</head><p>This section includes information for reproducing our experiments on the Long-Range Arena and Speech Commands long-range dependency tasks.</p><p>Long Range Arena <ref type="table" target="#tab_2">Table 10</ref> contains extended results table with all 11 methods considered in <ref type="bibr" target="#b39">[40]</ref>.</p><p>For the S4 model, hyperparameters for all datasets are reported in <ref type="table" target="#tab_2">Table 11</ref>. For all datasets, we used the AdamW optimizer with a constant learning rate schedule with decay on validation plateau. However, the learning rate on HiPPO parameters (in particular ?, P , Q, B, C, ?) were reduced to a maximum starting LR of 0.001, which improves stability since the HiPPO equation is crucial to performance.</p><p>The S4 state size was always fixed to N = 64.</p><p>As S4 is a sequence-to-sequence model with output shape (batch, length, dimension) and LRA tasks are classification, mean pooling along the length dimension was applied after the last layer.</p><p>We note that most of these results were trained for far longer than what was necessary to achieve SotA results (e.g., the Image task reaches SotA in 1 epoch). Results often keep improving with longer training times.</p><p>Updated results. The above hyperparameters describe the results reported in the original paper, shown in <ref type="table" target="#tab_2">Table 10</ref>, which have since been improved. See Appendix D.5.</p><p>Hardware. All models were run on single GPU. Some tasks used an A100 GPU (notably, the Path-X experiments), which has a larger max memory of 40Gb. To reproduce these on smaller GPUs, the batch size can be reduced or gradients can be accumulated for two batches. Speech Commands We provide details of sweeps run for baseline methods run by us-numbers for all others method are taken from Gu et al. <ref type="bibr" target="#b17">[18]</ref>. The best hyperparameters used for S4 are included in <ref type="table" target="#tab_2">Table 11</ref>. LipschitzRNN <ref type="bibr" target="#b12">[13]</ref> For MFCC, we swept hidden sizes {256, 512} and learning rates {0.001, 0.002, 0.0005}. Training was run for 150 epochs, with a single layer model using a batch size of 100. For Raw, we found that LipschitzRNN was too slow to train on a single GPU (requiring a full day for 1 epoch of training alone).</p><p>WaveGAN Discriminator <ref type="bibr" target="#b10">[11]</ref> The WaveGAN-D in <ref type="table" target="#tab_7">Table 5</ref> is actually our improved version of the discriminator network from the recent WaveGAN model for speech <ref type="bibr" target="#b10">[11]</ref>. This CNN actually did not work well out-of-the-box, and we added several features to help it perform better. The final model is highly specialized compared to our model, and includes:</p><p>? Downsampling or pooling between layers, induced by strided convolutions, that decrease the sequence length between layers.</p><p>? A global fully-connected output layer; thus the model only works for one input sequence length and does not work on MFCC features or the frequency-shift setting in <ref type="table" target="#tab_7">Table 5</ref>.</p><p>? Batch Normalization is essential, whereas S4 works equally well with either Batch Normalization or Layer Normalization.</p><p>? Almost 90? as many parameters as the S4 model (26.3M vs. 0.3M).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 General Sequence Modeling</head><p>This subsection corresponds to the experiments in Section 4.3. Because of the number of experiments in this section, we use subsubsection dividers for different tasks to make it easier to follow: CIFAR-10 density estimation (Appendix D. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.1 CIFAR Density Estimation</head><p>This task used a different backbone than the rest of our experiments. We used blocks of alternating S4 layers and position-wise feed-forward layers (in the style of Transformer blocks). Each feed-forward intermediate dimension was set to 2? the hidden size of the incoming S4 layer. Similar to Salimans et al. <ref type="bibr" target="#b38">[39]</ref>, we used a UNet-style backbone consisting of B identical blocks followed by a downsampling layer. The downsampling rates were 3, 4, 4 (the 3 chosen because the sequence consists of RGB pixels). The base model had B = 8 with starting hidden dimension 128, while the large model had B = 16 with starting hidden dimension 192.</p><p>We experimented with both the mixture of logistics from <ref type="bibr" target="#b38">[39]</ref> as well as a simpler 256-way categorical loss. We found they were pretty close and ended up using the simpler softmax loss along with using input embeddings.</p><p>We used the LAMB optimizer with learning rate 0.005. The base model had no dropout, while the large model had dropout 0.1 before the linear layers inside the S4 and FF blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.2 WikiText-103 Language Modeling</head><p>The RNN baselines included in <ref type="table" target="#tab_10">Table 8</ref> are the AWD-QRNN <ref type="bibr" target="#b26">[27]</ref>, an efficient linear gated RNN, and the LSTM + Cache + Hebbian + MbPA <ref type="bibr" target="#b32">[33]</ref>, the best performing pure RNN in the literature. The CNN baselines are the CNN with GLU activations <ref type="bibr" target="#b8">[9]</ref>, the TrellisNet <ref type="bibr" target="#b3">[4]</ref>, Dynamic Convolutions <ref type="bibr" target="#b48">[49]</ref>, and TaLK Convolutions <ref type="bibr" target="#b25">[26]</ref>.</p><p>The Transformer baseline is <ref type="bibr" target="#b1">[2]</ref>, which uses Adaptive Inputs with a tied Adaptive Softmax. This model is a standard high-performing Transformer baseline on this benchmark, used for example by Lioutas and Guo <ref type="bibr" target="#b25">[26]</ref> and many more.</p><p>Our S4 model uses the same Transformer backbone as in <ref type="bibr" target="#b1">[2]</ref>. The model consists of 16 blocks of S4 layers alternated with position-wise feedforward layers, with a feature dimension of 1024. Because our S4 layer has around 1/4 the number of parameters as a self-attention layer with the same dimension, we made two modifications to match the parameter count better: (i) we used a GLU activation after the S4 linear layer (Section 3.4) (ii) we used two S4 layers per block. Blocks use Layer Normalization in the pre-norm position. The embedding and softmax layers were the Adaptive Embedding from <ref type="bibr" target="#b1">[2]</ref> with standard cutoffs 20000, 40000, 200000.</p><p>Evaluation was performed similarly to the basic setting in <ref type="bibr" target="#b1">[2]</ref>, <ref type="table" target="#tab_7">Table 5</ref>, which uses sliding non-overlapping windows. Other settings are reported in <ref type="bibr" target="#b1">[2]</ref> that include more context at training and evaluation time and improves the score. Because such evaluation protocols are orthogonal to the basic model, we do not consider them and report the base score from <ref type="bibr" target="#b1">[2]</ref>  <ref type="table" target="#tab_7">Table 5</ref>.</p><p>Instead of SGD+Momentum with multiple cosine learning rate annealing cycles, our S4 model was trained with the simpler AdamW optimizer with a single cosine learning rate cycle with a maximum of 800000 steps. The initial learning rate was set to 0.0005. We used 8 A100 GPUs with a batch size of 1 per gpu and context size 8192. We used no gradient clipping and a weight decay of 0.1. Unlike <ref type="bibr" target="#b1">[2]</ref> which specified different dropout rates for different parameters, we used a constant dropout rate of 0.25 throughout the network, including before every linear layer and on the residual branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.3 Autoregressive Generation Speed</head><p>Protocol. To account for different model sizes and memory requirements for each method, we benchmark generation speed by throughput, measured in images per second <ref type="table" target="#tab_9">(Table 7)</ref> or tokens per second <ref type="table" target="#tab_10">(Table 8)</ref>. Each model generates images on a single A100 GPU, maximizing batch size to fit in memory. (For CIFAR-10 generation we limited memory to 16Gb, to be more comparable to the Transformer and Linear Transformer results reported from <ref type="bibr" target="#b21">[22]</ref>.) Baselines. The Transformer and Linear Transformer baselines reported in <ref type="table" target="#tab_9">Table 7</ref> are the results reported directly from Katharopoulos et al. <ref type="bibr" target="#b21">[22]</ref>. Note that the Transformer number is the one in their Appendix, which implements the optimized cached implementation of self-attention.</p><p>For all other baseline models, we used open source implementations of the models to benchmark generation speed. For the PixelCNN++, we used the fast cached version by Ramachandran et al. <ref type="bibr" target="#b33">[34]</ref>, which sped up generation by orders of magnitude from the naive implementation. This code was only available in TensorFlow, which may have slight differences compared to the rest of the baselines which were implemented in PyTorch.</p><p>We were unable to run the Sparse Transformer <ref type="bibr" target="#b5">[6]</ref> model due to issues with their custom CUDA implementation of the sparse attention kernel, which we were unable to resolve.</p><p>The Transformer baseline from <ref type="table" target="#tab_10">Table 8</ref> was run using a modified GPT-2 backbone from the HuggingFace repository, configured to recreate the architecture reported in <ref type="bibr" target="#b1">[2]</ref>. These numbers are actually slightly favorable to the baseline, as we did not include the timing of the embedding or softmax layers, whereas the number reported for S4 is the full model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.4 Pixel-Level Sequential Image Classification</head><p>Our models were trained with the AdamW optimizer for up to 200 epochs. Hyperparameters for the CIFAR-10 model is reported in <ref type="table" target="#tab_2">Table 11</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.5 Time Series Forecasting compared to Informer</head><p>We include a simple figure <ref type="figure" target="#fig_7">(Fig. 5</ref>) contrasting the architecture of S4 against that of the Informer <ref type="bibr" target="#b49">[50]</ref>.</p><p>In <ref type="figure" target="#fig_7">Fig. 5</ref>, the goal is to forecast a contiguous range of future predictions (Green, length F ) given a range of past context (Blue, length C ). We simply concatenate the entire context with a sequence of masks set to the length of the forecast window. This input is a single sequence of length C + F that is run through the same simple deep S4 model used throughout this work, which maps to an output of length C + F . We then use just the last F outputs as the forecasted predictions. <ref type="table" target="#tab_2">Tables 13 and 14</ref> contain full results on all 50 settings considered by Zhou et al. <ref type="bibr" target="#b49">[50]</ref>. S4 sets the best results on 40 out of 50 of these settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Visualizations</head><p>We visualize the convolutional filterK learned by S4 for the Pathfinder and CIFAR-10 tasks in Appendix D.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 Reproduction</head><p>Since the first version of this paper, several experiments have been updated. Please read the corresponding paragraph below before citing LRA or SC results.</p><p>Long Range Arena Follow-ups to this paper expanded the theoretical understanding of S4 while improving some results. The results reported in <ref type="table" target="#tab_6">Table 4</ref> have been updated to results from the papers <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. More specifically, the method S4-LegS in those works refers to the same model presented in this paper, with the   "-LegS" suffix referring to the initialization defined in equation <ref type="bibr" target="#b1">(2)</ref>. As such, results from the original <ref type="table" target="#tab_6">Table 4</ref> have been directly updated.</p><p>The updated results have only minor hyperparameter changes compared to the original results. The original results and hyperparameters are shown in <ref type="table" target="#tab_2">Table 10</ref> (Appendix D.2). Appendix B of <ref type="bibr" target="#b18">[19]</ref> describes the changes in hyperparameters, which are also documented from the experiment configuration files in the publically available code at https://github.com/HazyResearch/state-spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech Commands</head><p>The Speech Commands (SC) dataset <ref type="bibr" target="#b46">[47]</ref> is originally a 35-class dataset of spoken English words. However, this paper was part of a line of work starting with Kidger et al. <ref type="bibr" target="#b22">[23]</ref> that has used a smaller 10-class subset of SC <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>. In an effort to avoid dataset fragmentation in the literature, we have since moved to the original dataset. We are now calling this 10-class subset SC10 to distinguish it from the full 35-class SC dataset. To cite S4 as a baseline for Speech Commands, please use <ref type="table" target="#tab_2">Table 11</ref> from <ref type="bibr" target="#b18">[19]</ref> instead of <ref type="table" target="#tab_7">Table 5</ref> from this paper. In addition to using the full SC dataset, it also provides a number of much stronger baselines than the ones used in this work.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 3 (</head><label>3</label><figDesc>S4 Convolution). Given any step size ?, computing the SSM convolution filter K can be reduced to 4 Cauchy multiplies, requiring only O(N + L) operations and O(N + L) space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Visualizations of a trained S4 model on LRA Path-X. SSM convolution kernels K ? R 16384 are reshaped into a 128 ? 128 image. (Left) Example from the Path-X task, which involves deducing if the markers are connected by a path (Top) Filters from the first layer (Bottom) Filters from the last layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>shows both training and validation curves, from which we can make several observations. First, training the SSM improved all methods, particularly the randomly initialized ones. For all methods, training the SSM led to improvements in both training and validation curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>CIFAR-10 classification with unconstrained, real-valued SSMs with various initializations. (Left) Train accuracy. (Right) Validation accuracy. CIFAR-10 validation accuracy of SSMs with different initializations and parameterizations. (Left) NPLR parameterization with random versus HiPPO initialization. (Right) All methods considered in this section, including minor Dropout regularization. S4 achieves SotA accuracy on sequential CIFAR-10 with just 100K parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Instead of diagonalization, Gu et al.<ref type="bibr" target="#b17">[18,</ref> Theorem 2]  proposed a sophisticated fast algorithm to computeK L (A, B, C) = (CB, CAB, . . . , CA L?1 B).This algorithm runs in O(N log 2 N + L log L) operations and O(N + L) space. However, we now show that this algorithm is also numerically unstable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma C. 2 .</head><label>2</label><figDesc>The SSM function K L (A, B, C) can be computed from the SSM generating functionK L (?; A, B, C) at the roots of unity ? = {exp(?2?i k L : k ? [L]} stably in O(L log L) operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Proposition 5 (O</head><label>5</label><figDesc>Cauchy). A Cauchy kernel requires O(M + N ) space, and operation count C(M, N ) = (M N ) naively O (M + N ) log 2 (M + N ) in exact arithmetic O (M + N ) log(M + N ) log 1 ? numerically to precision ?. Corollary C.5. Evaluating Q * R(?; ?)P (defined in Lemma C.3) for any set of nodes ? ? C L , diagonal matrix ?, and vectors P , Q can be computed in C(L, N ) operations and O(L + N ) space, where C(L, N ) = O(L + N ) is the cost of a Cauchy matrix-vector multiplication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>This section contains full experimental procedures and extended results and citations for our experimental evaluation in Section 4. Appendix D.1 corresponds to benchmarking results in Section 4.1, Appendix D.2 corresponds to LRD experiments (LRA and Speech Commands) in Section 4.2, and Appendix D.3 corresponds to the general sequence modeling experiments (generation, image classification, forecasting) in Section 4.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>3.1), WikiText-103 language modeling (Appendix D.3.2), autoregressive generation (Appendix D.3.3), sequential image classification (Appendix D.3.4), and time-series forecasting (Appendix D.3.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :</head><label>5</label><figDesc>Comparison of S4 and specialized time-series models for forecasting tasks. (Top Left) The forecasting task involves predicting future values of a time-series given past context. (Bottom Left) We perform simple forecasting using a sequence model such as S4 as a black box. (Right) Informer uses an encoder-decoder architecture designed specifically for forecasting problems involving a customized attention module (figure taken from Zhou et al. [50]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>0.514 0.454 0.529 1.671 1.587 0.723 0.655 0.315 0.436 1.032 0.833 2.725 1.273 336 0.328 0.422 0.489 0.528 0.501 0.552 0.514 0.563 3.528 2.196 1.212 0.898 0.414 0.519 1.136 0.876 2.246 3.077 720 0.428 0.494 0.540 0.571 0.543 0.578 0.558 0.609 4.891 4.047 1.511 0.966 0.563 0.595 1.251 0.933 4.243 1.415 960 0.432 0.497 0.582 0.608 0.594 0.638 0.624 0.645 7.019 5.105 1.545 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 6 :</head><label>6</label><figDesc>(Convolutional filters on Pathfinder) A random selection of filters learned by S4 in the first layer (top 2 rows) and last layer (bottom 2 rows) of the best model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>3 Method: Structured State Spaces (S4)Our technical results focus on developing the S4 parameterization and showing how to efficiently compute all views of the SSM (Section 2): the continuous representation (A, B, C) (1), the recurrent representation (A, B, C) (3), and the convolutional representation K (4).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Complexity of various sequence models in terms of sequence length (L), batch size (B), and hidden dimension (H); tildes denote log factors. Metrics are parameter count, training computation, training space requirement, training parallelizability, and inference computation (for 1 sample and time-step). For simplicity, the state size N of S4 is tied to H. Bold denotes model is theoretically best for that metric. Convolutions are efficient for training while recurrence is efficient for inference, while SSMs combine the strengths of both.</figDesc><table><row><cell></cell><cell>Convolution 3</cell><cell cols="2">Recurrence Attention</cell><cell>S4</cell></row><row><cell cols="2">Parameters LH</cell><cell>H 2</cell><cell>H 2</cell><cell>H 2</cell></row><row><cell cols="3">TrainingLH(B + H) BLH 2</cell><cell cols="2">B(L 2 H + LH 2 ) BH(H +L) + BLH</cell></row><row><cell>Space</cell><cell>BLH</cell><cell>BLH</cell><cell>B(L 2 + HL)</cell><cell>BLH</cell></row><row><cell>Parallel</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Inference</cell><cell>LH 2</cell><cell>H 2</cell><cell>L 2 H + H 2 L</cell><cell>H 2</cell></row><row><cell cols="4">3.4 Architecture Details of the Deep S4 Layer</cell><cell></cell></row><row><cell cols="5">Concretely, an S4 layer is parameterized as follows. First initialize a SSM with A set to the HiPPO matrix</cell></row><row><cell cols="5">(2). By Lemma 3.1 and Theorem 1, this SSM is unitarily equivalent to some (? ? P Q  *  , B, C) for some diagonal ? and vectors P , Q, B, C ? C N ?1 . These comprise S4's 5N trainable parameters.</cell></row><row><cell cols="5">The overall deep neural network (DNN) architecture of S4 is similar to prior work. As defined above, S4 defines a map from R L ? R L , i.e. a 1-D sequence map. Typically, DNNs operate on feature maps of size H</cell></row><row><cell cols="5">instead of 1. S4 handles multiple features by simply defining H independent copies of itself, and then mixing</cell></row><row><cell cols="5">the H features with a position-wise linear layer for a total of O(H 2 ) + O(HN ) parameters per layer. Nonlinear</cell></row><row><cell cols="5">activation functions are also inserted between these layers. Overall, S4 defines a sequence-to-sequence map of</cell></row><row><cell cols="5">shape (batch size, sequence length, hidden dimension), exactly the same as related sequence models such as</cell></row><row><cell cols="2">Transformers, RNNs, and CNNs.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 compares</head><label>1</label><figDesc></figDesc><table /><note>the complexities of the most common deep sequence modeling mechanisms.4 Experiments Section 4.1 benchmarks S4 against the LSSL and efficient Transformer models. Section 4.2 validates S4 on LRDs: the LRA benchmark and raw speech classification. Section 4.3 investigates whether S4 can be used as a general sequence model to perform effectively and efficiently in a wide variety of settings including image classification, image and text generation, and time series forecasting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Deep SSMs: The S4 parameterization with Algorithm 1 is asymptotically more efficient than the LSSL. Ratio 1.9? 6.7? 29.6? 42.0? 133? 392?</figDesc><table><row><cell></cell><cell cols="6">Training Step (ms) Memory Alloc. (MB)</cell></row><row><cell>Dim.</cell><cell>128</cell><cell>256</cell><cell>512</cell><cell>128</cell><cell>256</cell><cell>512</cell></row><row><cell cols="2">LSSL 9.32</cell><cell>20.6</cell><cell>140.7</cell><cell>222.1</cell><cell>1685</cell><cell>13140</cell></row><row><cell>S4</cell><cell>4.77</cell><cell>3.07</cell><cell>4.75</cell><cell>5.3</cell><cell>12.6</cell><cell>33.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Benchmarks vs. efficient Transformers</figDesc><table><row><cell></cell><cell cols="2">Length 1024</cell><cell cols="2">Length 4096</cell></row><row><cell></cell><cell>Speed</cell><cell>Mem.</cell><cell>Speed</cell><cell>Mem.</cell></row><row><cell>Transformer</cell><cell>1?</cell><cell>1?</cell><cell>1?</cell><cell>1?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>Model</cell><cell cols="7">ListOps Text Retrieval Image Pathfinder Path-X Avg</cell></row><row><cell>Transformer</cell><cell>36.37</cell><cell>64.27</cell><cell>57.46</cell><cell>42.44</cell><cell>71.40</cell><cell></cell><cell>53.66</cell></row><row><cell>Reformer</cell><cell>37.27</cell><cell>56.10</cell><cell>53.40</cell><cell>38.07</cell><cell>68.50</cell><cell></cell><cell>50.56</cell></row><row><cell>BigBird</cell><cell>36.05</cell><cell>64.02</cell><cell>59.29</cell><cell>40.83</cell><cell>74.87</cell><cell></cell><cell>54.17</cell></row><row><cell>Linear Trans.</cell><cell>16.13</cell><cell>65.90</cell><cell>53.09</cell><cell>42.34</cell><cell>75.30</cell><cell></cell><cell>50.46</cell></row><row><cell>Performer</cell><cell>18.01</cell><cell>65.40</cell><cell>53.82</cell><cell>42.77</cell><cell>77.05</cell><cell></cell><cell>51.18</cell></row><row><cell>FNet</cell><cell>35.33</cell><cell>65.11</cell><cell>59.61</cell><cell>38.67</cell><cell>77.80</cell><cell></cell><cell>54.42</cell></row><row><cell cols="2">Nystr?mformer 37.15</cell><cell>65.52</cell><cell>79.56</cell><cell>41.58</cell><cell>70.94</cell><cell></cell><cell>57.46</cell></row><row><cell>Luna-256</cell><cell>37.25</cell><cell>64.57</cell><cell>79.29</cell><cell>47.38</cell><cell>77.72</cell><cell></cell><cell>59.37</cell></row><row><cell>S4</cell><cell>59.60</cell><cell cols="2">86.82 90.90</cell><cell>88.65</cell><cell>94.20</cell><cell>96.35</cell><cell>86.09</cell></row></table><note>(Long Range Arena) (Top) Original Transformer variants in LRA. Full results in Appendix D.2. (Bottom) Other models reported in the literature. Please read Appendix D.5 before citing this table.efficient Transformer variants benchmarked by Tay et al. [40]-Linear Transformer [22] and Performer [8]-in a parameter-matched setting (Table 3, following the protocol of Tay et al. [40]).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>(SC10 classification) Transformer, CTM, RNN, CNN, and SSM models. (MFCC ) Standard preprocessed MFCC features (length 161). (Raw ) Unprocessed signals (length 16000). (0 .5 ?) Frequency change at test time. denotes not applicable or computationally infeasible on single GPU. Please read Appendix D.5 before citing this table.</figDesc><table><row><cell></cell><cell cols="2">MFCC Raw</cell><cell>0.5?</cell></row><row><cell>Transformer</cell><cell>90.75</cell><cell></cell><cell></cell></row><row><cell>Performer</cell><cell>80.85</cell><cell>30.77</cell><cell>30.68</cell></row><row><cell>ODE-RNN</cell><cell>65.9</cell><cell></cell><cell></cell></row><row><cell>NRDE</cell><cell>89.8</cell><cell>16.49</cell><cell>15.12</cell></row><row><cell>ExpRNN</cell><cell>82.13</cell><cell>11.6</cell><cell>10.8</cell></row><row><cell cols="2">LipschitzRNN 88.38</cell><cell></cell><cell></cell></row><row><cell>CKConv</cell><cell>95.3</cell><cell>71.66</cell><cell>65.96</cell></row><row><cell>WaveGAN-D</cell><cell></cell><cell>96.25</cell><cell></cell></row><row><cell>LSSL</cell><cell>93.58</cell><cell></cell><cell></cell></row><row><cell>S4</cell><cell>93.96</cell><cell cols="2">98.32 96.30</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>(Pixel-level 1-D image classification) Comparison against reported test accuracies from prior works (Transformer, RNN, CNN, and SSM models). Extended results and citations in Appendix D.</figDesc><table><row><cell></cell><cell cols="3">sMNIST pMNIST sCIFAR</cell></row><row><cell>Transformer</cell><cell>98.9</cell><cell>97.9</cell><cell>62.2</cell></row><row><cell>LSTM</cell><cell>98.9</cell><cell>95.11</cell><cell>63.01</cell></row><row><cell>r-LSTM</cell><cell>98.4</cell><cell>95.2</cell><cell>72.2</cell></row><row><cell>UR-LSTM</cell><cell>99.28</cell><cell>96.96</cell><cell>71.00</cell></row><row><cell>UR-GRU</cell><cell>99.27</cell><cell>96.51</cell><cell>74.4</cell></row><row><cell>HiPPO-RNN</cell><cell>98.9</cell><cell>98.3</cell><cell>61.1</cell></row><row><cell>LMU-FFT</cell><cell>-</cell><cell>98.49</cell><cell>-</cell></row><row><cell cols="2">LipschitzRNN 99.4</cell><cell>96.3</cell><cell>64.2</cell></row><row><cell>TCN</cell><cell>99.0</cell><cell>97.2</cell><cell>-</cell></row><row><cell>TrellisNet</cell><cell>99.20</cell><cell>98.13</cell><cell>73.42</cell></row><row><cell>CKConv</cell><cell>99.32</cell><cell>98.54</cell><cell>63.74</cell></row><row><cell>LSSL</cell><cell>99.53</cell><cell>98.76</cell><cell>84.65</cell></row><row><cell>S4</cell><cell>99.63</cell><cell>98.70</cell><cell>91.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>(CIFAR-10 density estimation) As a generic sequence model, S4 is competitive with previous autoregressive models (in bits per dim.) while incorporating no 2D inductive bias, and has fast generation through its recurrence mode.</figDesc><table><row><cell>Model</cell><cell>bpd</cell><cell>2D bias</cell><cell>Images / sec</cell></row><row><cell>Transformer</cell><cell>3.47</cell><cell>None</cell><cell>0.32 (1?)</cell></row><row><cell>Linear Transf.</cell><cell>3.40</cell><cell>None</cell><cell>17.85 (56?)</cell></row><row><cell>PixelCNN</cell><cell>3.14</cell><cell>2D conv.</cell><cell>-</cell></row><row><cell cols="2">Row PixelRNN 3.00</cell><cell>2D BiLSTM</cell><cell>-</cell></row><row><cell>PixelCNN++</cell><cell>2.92</cell><cell>2D conv.</cell><cell>19.19 (59.97?)</cell></row><row><cell>Image Transf.</cell><cell>2.90</cell><cell>2D local attn.</cell><cell>0.54 (1.7?)</cell></row><row><cell>PixelSNAIL</cell><cell>2.85</cell><cell cols="2">2D conv. + attn. 0.13 (0.4?)</cell></row><row><cell>Sparse Transf.</cell><cell cols="2">2.80 2D sparse attn.</cell><cell>-</cell></row><row><cell>S4 (base)</cell><cell>2.92</cell><cell>None</cell><cell>20.84 (65.1?)</cell></row><row><cell>S4 (large)</cell><cell>2.85</cell><cell>None</cell><cell>3.36 (10.5?)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>(WikiText-103 language modeling) S4 approaches the performance of Transformers with much faster generation. (Top) Transformer baseline which our implementation is based on, with attention replaced by S4. (Bottom) Attention-free models (RNNs and CNNs).</figDesc><table><row><cell>Model</cell><cell cols="3">Params Test ppl. Tokens / sec</cell></row><row><cell>Transformer</cell><cell>247M</cell><cell>20.51</cell><cell>0.8K (1?)</cell></row><row><cell>GLU CNN</cell><cell>229M</cell><cell>37.2</cell><cell>-</cell></row><row><cell>AWD-QRNN</cell><cell>151M</cell><cell>33.0</cell><cell>-</cell></row><row><cell cols="2">LSTM + Hebb. -</cell><cell>29.2</cell><cell>-</cell></row><row><cell>TrellisNet</cell><cell>180M</cell><cell>29.19</cell><cell>-</cell></row><row><cell cols="2">Dynamic Conv. 255M</cell><cell>25.0</cell><cell>-</cell></row><row><cell>TaLK Conv.</cell><cell>240M</cell><cell>23.3</cell><cell>-</cell></row><row><cell>S4</cell><cell>249M</cell><cell>20.95</cell><cell>48K (60?)</cell></row></table><note>models. The tasks we focus on (generative modeling, image classification, time-series forecasting) are considered as LRD tasks in the literature, and serve as additional validation that S4 handles LRDs efficiently.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>which involve patch-based models that without 2-D inductive bias. Sequential CIFAR is a particularly challenging dataset where outside of SSMs, all sequence models have a gap of over 25% to a simple 2-D CNN. By contrast, S4 is competitive with a larger ResNet18 (7.9M vs. 11.0M parameters), both with (93.16% vs. 95.62%) or without (91.12% vs. 89.46%) data augmentation. Moreover, it is much more robust to other architectural choices (e.g. 90.46% vs. 79.52% when swapping BatchNorm for LayerNorm).4.4 SSM Ablations: the Importance of HiPPOA critical motivation of S4 was the use of the HiPPO matrices to initialize an SSM. We consider several simplifications of S4 to ablate the importance of each of these components, including: (i) how important is the HiPPO initialization? (ii) how important is training the SSM on top of HiPPO? (iii) are the benefits of S4 captured by the NPLR parameterization without HiPPO?</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Univariate long sequence time-series forecasting results. Full results in Appendix D.3.5.</figDesc><table><row><cell>S4</cell><cell>Informer</cell><cell>LogTrans</cell><cell>Reformer</cell><cell>LSTMa</cell><cell>DeepAR</cell><cell>ARIMA</cell><cell>Prophet</cell></row><row><cell>MSE MAE</cell><cell cols="7">MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE</cell></row><row><cell>ETTh</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>1 0.116 0.271 0.269 0.435 0.273 0.463 2.112 1.436 0.683 0.768 0.658 0.707 0.659 0.766 2.735 3.253 ETTh2 0.187 0.358 0.277 0.431 0.303 0.493 2.030 1.721 0.640 0.681 0.429 0.580 2.878 1.044 3.355 4.664 ETTm 1 0.292 0.466 0.512 0.644 0.598 0.702 1.793 1.528 1.064 0.873 2.437 1.352 0.639 0.697 2.747 1.174 Weather 0.245 0.375 0.359 0.466 0.388 0.499 2.087 1.534 0.866 0.809 0.499 0.596 1.062 0.943 3.859 1.144 ECL 0.432 0.497 0.582 0.608 0.624 0.645 7.019 5.105 1.545 1.006 0.657 0.683 1.370 0.982 6.901 4.264</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Full results for the Long Range Arena (LRA) benchmark for long-range dependencies in sequence models. (Top): Original Transformer variants in LRA. (Bottom): Other models reported in the literature.</figDesc><table><row><cell>Model</cell><cell cols="7">ListOps Text Retrieval Image Pathfinder Path-X Avg</cell></row><row><cell>Random</cell><cell>10.00</cell><cell>50.00</cell><cell>50.00</cell><cell>10.00</cell><cell>50.00</cell><cell>50.00</cell><cell>36.67</cell></row><row><cell>Transformer</cell><cell>36.37</cell><cell>64.27</cell><cell>57.46</cell><cell>42.44</cell><cell>71.40</cell><cell></cell><cell>53.66</cell></row><row><cell cols="2">Local Attention 15.82</cell><cell>52.98</cell><cell>53.39</cell><cell>41.46</cell><cell>66.63</cell><cell></cell><cell>46.71</cell></row><row><cell>Sparse Trans.</cell><cell>17.07</cell><cell>63.58</cell><cell>59.59</cell><cell>44.24</cell><cell>71.71</cell><cell></cell><cell>51.03</cell></row><row><cell>Longformer</cell><cell>35.63</cell><cell>62.85</cell><cell>56.89</cell><cell>42.22</cell><cell>69.71</cell><cell></cell><cell>52.88</cell></row><row><cell>Linformer</cell><cell>35.70</cell><cell>53.94</cell><cell>52.27</cell><cell>38.56</cell><cell>76.34</cell><cell></cell><cell>51.14</cell></row><row><cell>Reformer</cell><cell>37.27</cell><cell>56.10</cell><cell>53.40</cell><cell>38.07</cell><cell>68.50</cell><cell></cell><cell>50.56</cell></row><row><cell cols="2">Sinkhorn Trans. 33.67</cell><cell>61.20</cell><cell>53.83</cell><cell>41.23</cell><cell>67.45</cell><cell></cell><cell>51.23</cell></row><row><cell>Synthesizer</cell><cell>36.99</cell><cell>61.68</cell><cell>54.67</cell><cell>41.61</cell><cell>69.45</cell><cell></cell><cell>52.40</cell></row><row><cell>BigBird</cell><cell>36.05</cell><cell>64.02</cell><cell>59.29</cell><cell>40.83</cell><cell>74.87</cell><cell></cell><cell>54.17</cell></row><row><cell>Linear Trans.</cell><cell>16.13</cell><cell>65.90</cell><cell>53.09</cell><cell>42.34</cell><cell>75.30</cell><cell></cell><cell>50.46</cell></row><row><cell>Performer</cell><cell>18.01</cell><cell>65.40</cell><cell>53.82</cell><cell>42.77</cell><cell>77.05</cell><cell></cell><cell>51.18</cell></row><row><cell>FNet</cell><cell>35.33</cell><cell>65.11</cell><cell>59.61</cell><cell>38.67</cell><cell>77.80</cell><cell></cell><cell>54.42</cell></row><row><cell>Nystr?mformer</cell><cell>37.15</cell><cell>65.52</cell><cell>79.56</cell><cell>41.58</cell><cell>70.94</cell><cell></cell><cell>57.46</cell></row><row><cell>Luna-256</cell><cell>37.25</cell><cell>64.57</cell><cell>79.29</cell><cell>47.38</cell><cell>77.72</cell><cell></cell><cell>59.37</cell></row><row><cell>S4 (original)</cell><cell>58.35</cell><cell>76.02</cell><cell>87.09</cell><cell>87.26</cell><cell>86.05</cell><cell>88.10</cell><cell>80.48</cell></row><row><cell>S4 (updated)</cell><cell>59.60</cell><cell cols="2">86.82 90.90</cell><cell>88.65</cell><cell>94.20</cell><cell>96.35</cell><cell>86.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>The values of the best hyperparameters found for classification datasets; LRA (Top) and images/speech (Bottom). LR is learning rate and WD is weight decay. BN and LN refer to Batch Normalization and Layer Normalization.</figDesc><table><row><cell></cell><cell cols="6">Depth Features H Norm Pre-norm Dropout LR</cell><cell cols="4">Batch Size Epochs WD Patience</cell></row><row><cell>ListOps</cell><cell>6</cell><cell>128</cell><cell>BN</cell><cell>False</cell><cell>0</cell><cell>0.01</cell><cell>100</cell><cell>50</cell><cell cols="2">0.01 5</cell></row><row><cell>Text</cell><cell>4</cell><cell>64</cell><cell>BN</cell><cell>True</cell><cell>0</cell><cell>0.001</cell><cell>50</cell><cell>20</cell><cell>0</cell><cell>5</cell></row><row><cell>Retrieval</cell><cell>6</cell><cell>256</cell><cell>BN</cell><cell>True</cell><cell>0</cell><cell>0.002</cell><cell>64</cell><cell>20</cell><cell>0</cell><cell>20</cell></row><row><cell>Image</cell><cell>6</cell><cell>512</cell><cell>LN</cell><cell>False</cell><cell>0.2</cell><cell>0.004</cell><cell>50</cell><cell>200</cell><cell cols="2">0.01 20</cell></row><row><cell>Pathfinder</cell><cell>6</cell><cell>256</cell><cell>BN</cell><cell>True</cell><cell>0.1</cell><cell>0.004</cell><cell>100</cell><cell>200</cell><cell>0</cell><cell>10</cell></row><row><cell>Path-X</cell><cell>6</cell><cell>256</cell><cell>BN</cell><cell>True</cell><cell>0.0</cell><cell cols="2">0.0005 32</cell><cell>100</cell><cell>0</cell><cell>20</cell></row><row><cell>CIFAR-10</cell><cell>6</cell><cell>1024</cell><cell>LN</cell><cell>False</cell><cell>0.25</cell><cell>0.01</cell><cell>50</cell><cell>200</cell><cell cols="2">0.01 20</cell></row><row><cell cols="2">Speech Commands (MFCC) 4</cell><cell>256</cell><cell>LN</cell><cell>False</cell><cell>0.2</cell><cell>0.01</cell><cell>100</cell><cell>50</cell><cell>0</cell><cell>5</cell></row><row><cell>Speech Commands (Raw)</cell><cell>6</cell><cell>128</cell><cell>BN</cell><cell>True</cell><cell>0.1</cell><cell>0.01</cell><cell>20</cell><cell>150</cell><cell>0</cell><cell>10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Transformer<ref type="bibr" target="#b43">[44]</ref> For MFCC, we swept the number of model layers {2, 4}, dropout {0, 0.1} and learning rates {0.001, 0.0005}. We used 8 attention heads, model dimension 128, prenorm, positional encodings, and trained for 150 epochs with a batch size of 100. For Raw, the Transformer model's memory usage made training impossible. For MFCC, we swept the number of model layers {2, 4}, dropout {0, 0.1} and learning rates {0.001, 0.0005}. We used 8 attention heads, model dimension 128, prenorm, positional encodings, and trained for 150 epochs with a batch size of 100. For Raw, we used a model dimension of 128, 4 attention heads, prenorm, and a batch size of 16. We reduced the number of model layers to 4, so the model would fit on the single GPU. We trained for 100 epochs with a learning rate of 0.001 and no dropout.ExpRNN<ref type="bibr" target="#b23">[24]</ref> For MFCC, we swept hidden sizes {256, 512} and learning rates {0.001, 0.002, 0.0005}. Training was run for 200 epochs, with a single layer model using a batch size of 100. For Raw, we swept hidden sizes {32, 64} and learning rates {0.001, 0.0005} (however, ExpRNN failed to learn).</figDesc><table><row><cell>Performer [8]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>(Pixel-level image classification.) Citations refer to the original model; additional citation indicates work from which this baseline is reported.</figDesc><table><row><cell>Model</cell><cell cols="3">sMNIST pMNIST sCIFAR</cell></row><row><cell cols="2">Transformer [42, 44] 98.9</cell><cell>97.9</cell><cell>62.2</cell></row><row><cell>CKConv [35]</cell><cell>99.32</cell><cell>98.54</cell><cell>63.74</cell></row><row><cell>TrellisNet [4]</cell><cell>99.20</cell><cell>98.13</cell><cell>73.42</cell></row><row><cell>TCN [3]</cell><cell>99.0</cell><cell>97.2</cell><cell>-</cell></row><row><cell>LSTM [17, 21]</cell><cell>98.9</cell><cell>95.11</cell><cell>63.01</cell></row><row><cell>r-LSTM [42]</cell><cell>98.4</cell><cell>95.2</cell><cell>72.2</cell></row><row><cell>Dilated GRU [5]</cell><cell>99.0</cell><cell>94.6</cell><cell>-</cell></row><row><cell>Dilated RNN [5]</cell><cell>98.0</cell><cell>96.1</cell><cell>-</cell></row><row><cell>IndRNN [25]</cell><cell>99.0</cell><cell>96.0</cell><cell>-</cell></row><row><cell>expRNN [24]</cell><cell>98.7</cell><cell>96.6</cell><cell>-</cell></row><row><cell>UR-LSTM</cell><cell>99.28</cell><cell>96.96</cell><cell>71.00</cell></row><row><cell>UR-GRU [17]</cell><cell>99.27</cell><cell>96.51</cell><cell>74.4</cell></row><row><cell>LMU [45]</cell><cell>-</cell><cell>97.15</cell><cell>-</cell></row><row><cell>HiPPO-RNN [16]</cell><cell>98.9</cell><cell>98.3</cell><cell>61.1</cell></row><row><cell>UNIcoRNN [38]</cell><cell>-</cell><cell>98.4</cell><cell>-</cell></row><row><cell>LMUFFT [7]</cell><cell>-</cell><cell>98.49</cell><cell>-</cell></row><row><cell>LipschitzRNN [13]</cell><cell>99.4</cell><cell>96.3</cell><cell>64.2</cell></row><row><cell>S4</cell><cell>99.63</cell><cell>98.70</cell><cell>91.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>For our comparisons against ResNet-18, the main differences between the base models are that S4 uses LayerNorm by default while ResNet uses BatchNorm. The last ablation in Section 4.3 swaps the normalization type, using BatchNorm for S4 and LayerNorm for ResNet, to ablate this architectural difference. The experiments with augmentation take the base model and train with mild data augmentation: horizontal flips and random crops (with symmetric padding).</figDesc><table><row><cell>Context</cell><cell>Forecast</cell></row><row><cell></cell><cell>Forecast</cell></row><row><cell>S4 S4 S4</cell><cell></cell></row><row><cell>Context</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 13 :</head><label>13</label><figDesc>Univariate long sequence time-series forecasting results on four datasets (five cases).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>WikiText-103 The original version of this paper used an S4 model with batch size 8, context size 1024 which achieved a validation perplexity of 20.88 and test perplexity of 21.28. It was later retrained with a batch size of 1 and context size 8192 which achieved a validation perplexity of 19.69 and test perplexity of 20.95, and a model checkpoint is available in the public repository. The rest of the model is essentially identical, so the results from the original table have been updated.</figDesc><table><row><cell cols="2">Methods</cell><cell>S4</cell><cell></cell><cell cols="2">Informer</cell><cell cols="2">Informer  ?</cell><cell>LogTrans</cell><cell>Reformer</cell><cell>LSTMa</cell><cell>LSTnet</cell></row><row><cell cols="2">Metric</cell><cell>MSE</cell><cell>MAE</cell><cell>MSE</cell><cell>MAE</cell><cell>MSE</cell><cell>MAE</cell><cell>MSE MAE MSE MAE MSE MAE MSE MAE</cell></row><row><cell>ETTh1</cell><cell>24 48 168 336</cell><cell cols="2">0.525 0.542 0.641 0.615 0.980 0.779 1.407 0.910</cell><cell cols="2">0.577 0.685 0.931 0.752 0.549 0.625 1.128 0.873</cell><cell cols="3">0.620 0.692 0.947 1.094 0.813 1.362 0.952 2.117 1.280 1.424 0.994 2.655 1.369 0.577 0.686 0.604 0.991 0.754 0.650 0.624 1.293 0.901 0.671 0.766 0.757 1.313 0.906 0.702 0.675 1.456 0.960 0.797 1.002 0.846 1.824 1.138 1.212 0.867 1.997 1.214</cell></row><row><cell></cell><cell cols="3">720 1.162 0.842</cell><cell>1.215</cell><cell>0.896</cell><cell>1.241</cell><cell>0.917</cell><cell>1.397 1.291 2.415 1.520 1.960 1.322 2.143 1.380</cell></row><row><cell>ETTh2</cell><cell cols="3">24 48 168 2.580 1.255 0.871 0.736 1.240 0.867 336 1.980 1.128</cell><cell cols="2">0.720 0.665 1.457 1.001 3.489 1.515 2.723 1.340</cell><cell>0.753 1.461 3.485 2.626</cell><cell>0.727 1.077 1.612 1.285</cell><cell>0.828 0.750 1.531 1.613 1.143 0.813 2.742 1.457 1.806 1.034 1.871 1.735 1.671 1.221 3.567 1.687 4.070 1.681 4.660 1.846 4.117 1.674 3.242 2.513 3.875 1.763 4.028 1.688 3.434 1.549 2.544 2.591</cell></row><row><cell></cell><cell cols="3">720 2.650 1.340</cell><cell>3.467</cell><cell>1.473</cell><cell>3.548</cell><cell>1.495</cell><cell>3.913 1.552 5.381 2.015 3.963 1.788 4.625 3.709</cell></row><row><cell>ETTm1</cell><cell cols="3">24 48 96 288 0.824 0.674 0.426 0.487 0.580 0.565 0.699 0.649 672 0.846 0.709</cell><cell>0.323 0.494 0.678 1.056 1.192</cell><cell cols="4">0.369 0.306 0.503 0.465 0.470 0.507 0.583 1.098 0.777 1.392 0.939 1.999 1.215 0.371 0.419 0.412 0.724 0.607 0.621 0.629 1.968 1.170 0.614 0.681 0.612 0.768 0.792 1.433 0.945 1.339 0.913 2.762 1.542 0.786 1.162 0.879 1.462 1.320 1.820 1.094 1.740 1.124 1.257 2.076 0.926 1.231 1.103 1.669 1.461 2.187 1.232 2.736 1.555 1.917 2.941</cell></row><row><cell>Weather</cell><cell cols="3">24 48 168 0.525 0.527 0.334 0.385 0.406 0.444 336 0.531 0.539 720 0.578 0.578</cell><cell>0.335 0.395 0.608 0.702 0.831</cell><cell>0.381 0.459 0.567 0.620 0.731</cell><cell cols="3">0.349 0.386 0.433 0.426 0.495 0.729 0.666 0.829 0.677 0.660 0.589 0.397 0.435 0.477 0.655 0.583 0.546 0.570 0.615 0.545 0.613 0.582 0.727 0.671 1.318 0.855 1.038 0.835 0.748 0.647 0.707 0.634 0.754 0.670 1.930 1.167 1.657 1.059 0.782 0.683 0.834 0.741 0.885 0.773 2.726 1.575 1.536 1.109 0.851 0.757</cell></row><row><cell></cell><cell>48</cell><cell cols="2">0.255 0.352</cell><cell>0.344</cell><cell>0.393</cell><cell>0.334</cell><cell>0.399</cell><cell>0.355 0.418 1.404 0.999 0.486 0.572 0.369 0.445</cell></row><row><cell>ECL</cell><cell cols="3">168 0.283 0.373 336 0.292 0.382 720 0.289 0.377</cell><cell>0.368 0.381 0.406</cell><cell>0.424 0.431 0.443</cell><cell>0.353 0.381 0.391</cell><cell>0.420 0.439 0.438</cell><cell>0.368 0.432 1.515 1.069 0.574 0.602 0.394 0.476 0.373 0.439 1.601 1.104 0.886 0.795 0.419 0.477 0.409 0.454 2.009 1.170 1.676 1.095 0.556 0.565</cell></row><row><cell></cell><cell cols="3">960 0.299 0.387</cell><cell>0.460</cell><cell>0.548</cell><cell>0.492</cell><cell>0.550</cell><cell>0.477 0.589 2.141 1.387 1.591 1.128 0.605 0.599</cell></row><row><cell cols="2">Count</cell><cell>18</cell><cell></cell><cell>5</cell><cell></cell><cell>6</cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 14 :</head><label>14</label><figDesc>Multivariate long sequence time-series forecasting results on four datasets (five cases).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code is publicly available at https://github.com/HazyResearch/state-spaces.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that although we ultimately require A, conjugation commutes with discretization so we refer to A.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Refers to global (in the sequence length) and depthwise-separable convolutions, similar to the convolution version of S4.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Aditya Grover and Chris Cundy for helpful discussions about earlier versions of the method. We thank Simran Arora, Sabri Eyuboglu, Bibek Paudel, and Nimit Sohoni for valuable feedback on earlier drafts of this work. This work was done with the support of Google Cloud credits under HAI proposals 540994170283 and 578192719349. We gratefully acknowledge the support of NIH under No. U54EB020405 (Mobilize), NSF under Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); ONR under No. N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-2480: Understanding and Applying Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); the Moore Foundation, NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, the Okawa Foundation, American Family Insurance, Google Cloud, Salesforce, Total, the HAI-AWS Cloud Credits for Research program, the Stanford Data Science Initiative (SDSI), and members of the Stanford DAWN project: Facebook, Google, and VMWare. The Mobilize Center is a Biomedical Technology Resource Center, funded by the NIH National Institute of Biomedical Imaging and Bioengineering through Grant P41EB027060. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. Any opinions, findings, and conclusions or recommendations expressed in this material are those of</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unitary evolution recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amar</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1120" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10853</idno>
		<title level="m">Adaptive input representations for neural language modeling</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01271</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Trellis networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dilated recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parallelizing legendre memory unit training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narsimha</forename><surname>Chilkuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Eliasmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rethinking attention with performers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerii</forename><surname>Likhosherstov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyou</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreea</forename><surname>Gane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamas</forename><surname>Sarlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afroz</forename><surname>Mohiuddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gru-ode-bayes: Continuous modeling of sporadically-observed time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaak</forename><surname>Edward De Brouwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Arany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adversarial audio synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miller</forename><surname>Puckette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lipschitz recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>N Benjamin Erichson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Azencot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Queiruga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Hodgkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">It&apos;s raw! audio generation with state-space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.09729</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">F</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix computations</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2013" />
			<publisher>JHU press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hippo: Recurrent memory with optimal polynomial projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving the gating mechanism of recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">Le</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combining recurrent, convolutional, and continuous-time models with the structured learnable linear state space layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isys</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khaled</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On the parameterization and initialization of diagonal state space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.11893</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">How to train your hippo: State space models with generalized basis projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isys</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aman</forename><surname>Timalsina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.12037</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transformers are rnns: Fast autoregressive transformers with linear attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Katharopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5156" to="5165" />
		</imprint>
	</monogr>
	<note>Nikolaos Pappas, and Fran?ois Fleuret</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Neural controlled differential equations for irregular time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Lyons</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.08926</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cheap orthogonal constraints in neural networks: A simple parametrization of the orthogonal and unitary group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lezcano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Casado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mart?nez-Rubio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Independently recurrent neural network (IndRNN): Building a longer and deeper RNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbo</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5457" to="5466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Time-aware large kernel convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Lioutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6172" to="6183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">Scalable language modeling: Wikitext-103 on a single gpu in 12 hours. SysML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">Wavenet: A generative model for raw audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Structured matrices and polynomials: unified superfast algorithms</title>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">Fast approximate computations with cauchy matrices and polynomials. Mathematics of Computation</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2799" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Transformations of matrix structures work again</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra and Its Applications</title>
		<imprint>
			<biblScope unit="volume">465</biblScope>
			<biblScope unit="page" from="107" to="138" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast parametric learning with activation memorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">Le</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pooya</forename><surname>Khorrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06001</idno>
		<title level="m">Fast generation for convolutional autoregressive models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ckconv: Continuous kernel convolution for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>David W Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>Kuzina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoogendoorn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.02611</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Flexconv: Continuous kernel convolutions with differentiable kernel sizes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert-Jan</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bruintjes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">C</forename><surname>Hoogendoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gemert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Latent ordinary differential equations for irregularly-sampled time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Tian Qi Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5321" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unicornn: A recurrent model for learning very long time dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Rusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Mishra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05517</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Long range arena : A benchmark for efficient transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=qVyeW-grC2k" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Mlp-mixer: An all-mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.01601</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning longer-term dependencies in RNNs with auxiliary losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A method of analysing the behaviour of linear systems in terms of time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Tustin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Institution of Electrical Engineers-Part IIA: Automatic Regulators and Servo Mechanisms</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="130" to="142" />
			<date type="published" when="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Legendre memory units: Continuous-time representation in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Voelker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Kaji?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Eliasmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15544" to="15553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dynamical systems in spiking neuromorphic hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">Russell</forename><surname>Voelker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Warden</surname></persName>
		</author>
		<idno>abs/1804.03209</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Inverting modified matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woodbury</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">106</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Memorandum report</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pay less attention with lightweight and dynamic convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Informer: Beyond efficient transformer for long sequence time-series forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieqi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wancai</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Virtual Conference</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
