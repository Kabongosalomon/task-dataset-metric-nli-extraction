<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Scholak</surname></persName>
							<email>torsten.scholak@servicenow.com</email>
							<affiliation key="aff0">
								<orgName type="institution">ElementAI, a ServiceNow company</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schucher</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ElementAI, a ServiceNow company</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
							<email>dzmitry.bahdanau@servicenow.com</email>
							<affiliation key="aff0">
								<orgName type="institution">ElementAI, a ServiceNow company</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T22:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD 1 , a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into stateof-the-art solutions. arXiv:2109.05093v1 [cs.CL] 10 Sep 2021</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While there have been many successes in applying large pre-trained language models to downstream tasks, our ability to control and constrain the output of these models is still very limited. Many enterprise applications are out of reach because they require a degree of rigour and exactitude that language models are not able to deliver yet. If the target is a formal language like SQL, then we would like the model to adhere exactly and provably to the SQL specification with all its lexical, grammatical, logical, and semantical constraints. Unfortunately, with pre-training alone, language models may not satisfy these correctness requirements.</p><p>For text-to-SQL translation, the most widespread solution to constrained decoding is to make invalid SQL unrepresentable. For a while now it has been possible to restrict auto-regressive decoding to only those token sequences that correctly parse to SQL abstract syntax trees <ref type="bibr" target="#b14">(Yin and Neubig, 2018;</ref><ref type="bibr" target="#b12">Wang et al., 2020)</ref>. More recently, semi-auto-regressive improvements to this parsing <ref type="bibr">1</ref> The PICARD code is available at https://github. com/ElementAI/picard.  <ref type="figure">Figure 1</ref>: Exact-set-match accuracy of the highestscoring prediction as a function of beam size on the Spider text-to-SQL development set. With PICARD turned on, token predictions had to pass PICARD checking at every decoding step. Only the top-2, -4, and -8 token predictions of each hypothesis were considered in the beam search. With PICARD turned off (none), all token predictions were considered and none were checked. The models, T5-Base, -Large, and -3B, did not have access to any database content, only to the database schemas.</p><p>paradigm have been proposed <ref type="bibr" target="#b7">(Rubin and Berant, 2021)</ref>. However, while effective, these approaches have in common that they are achieved at the expense of using a custom vocabulary of special control tokens or a custom model architecture, or both. Unfortunately, this makes them incompatible with generic pre-trained language model decoders. A less invasive and more compatible approach is to not constrain the generation process, but instead to filter finalized beam hypotheses by validity <ref type="bibr" target="#b11">(Suhr et al., 2020;</ref><ref type="bibr" target="#b4">Lin et al., 2020)</ref>. Yet, such filtering is at the expense of a very large beam size. We address the expenses of these approaches with a novel incremental parsing method for constrained decoding called PICARD, which stands for "Parsing Incrementally for Constrained Auto-Regressive Decoding." PICARD is compatible with any existing auto-regressive language model de- <ref type="figure">Figure 2</ref>: Illustration of constrained beam search with beam size 2 and PICARD. Each vertical column represents three token predictions for a hypothesis from top to bottom in descending order by probability. In this example, PICARD is configured to only check the top-2 highest ones. The rest is automatically dismissed by setting their score to ??. Tokens rejected by PICARD (red, ?) are also assigned a score of ??. Accepted tokens (green, ) keep their original score. coder and vocabulary-including, but not limited to, those of large pre-trained transformers-and it does not require very large beam sizes. PICARD is entirely absent from pre-training or fine-tuning of the model, and can be easily and optionally enabled at inference time. PICARD operates directly on the output of the language model which, in the case of text-to-SQL translation, is the readable surface form of the SQL code.</p><p>In our experiments, we find that PICARD can significantly improve the performance of a large pre-trained language model <ref type="bibr" target="#b6">(Raffel et al., 2020)</ref> after it is fine-tuned on the text-to-SQL task. On the Spider text-to-SQL dataset <ref type="bibr" target="#b17">(Yu et al., 2018)</ref>, we find that a T5-Base model with PICARD can outperform a T5-Large model without it, and likewise for a T5-Large and a T5-3B model. Significantly, with the help of PICARD, a T5-3B model can be raised to state-of-the-art performance on the Spider and CoSQL datasets <ref type="bibr" target="#b15">(Yu et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The PICARD Method</head><p>PICARD warps model prediction scores and integrates trivially with existing algorithms for greedy and beam search used in auto-regressive decoding from language models. Its arguments are the token ids of the current hypothesis and, for each vocabulary token, the log-softmax scores predicted by the model's language modeling head. PICARD also has access to SQL schema information, in particular, information about the names of tables and columns and about which column resides in which <ref type="table">table.</ref> At each generation step, PICARD first restricts prediction to the top-k highest probability tokens and then assigns a score of ?? to those that fail PICARD's numerous checks (see <ref type="figure">Figure 2</ref>). These checks are enabled by fast incremental parsing (O'Sullivan and Gamari, 2021) based on monadic combinators <ref type="bibr" target="#b2">(Leijen and Meijer, 2001)</ref>. There are four PICARD mode settings that control their comprehensiveness: off (no checking), lexing, parsing without guards, and parsing with guards-the highest mode. A prediction that passes a higher mode will always pass a lower mode but not necessarily vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lexing</head><p>In lexing mode, PICARD checks the output on a lexical level only. It attempts to convert the partial, detokenized model output to a white-space delimited sequence of individual SQL keywords like select, punctuation like (), operators like + and -, literals like string and number values in SQL conditions, and identifiers like aliases, tables, and columns-without being sensitive to the order in which these lexical items appear. By making it so, PICARD can detect spelling errors in keywords or reject table and column names that are invalid for the given SQL schema. For instance, consider the question "What are the email, cell phone and home phone of each professional?" from Spider's development set on the dog_kennels database. Our fine-tuned T5-Large model predicts select email_address, cell_phone, home_phone from professionals while the ground truth selects cell_number instead of the invalid cell_phone column. This mistake is caught and avoided by PICARD in lexing mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parsing without Guards</head><p>In the lowest parsing mode above lexing-referred to as parsing without guards-PICARD checks the output on a grammatical level. PICARD attempts to parse the detokenized model output to a data structure that represents the abstract syntax tree (AST) of the predicted SQL query. Contrary to lexing mode, the order in which keywords and clauses appear now matters. PICARD can reject invalid query structures, e.g. find missing from clauses or incorrect orders of clauses and keywords. It can also detect a range of issues with compositions of SQL expressions: Number one, if PICARD matches on a tid.cid pattern, but the table with the id tid does not contain a column with id cid, then that parse is rejected. Secondly, if PICARD first matches on an alias.cid pattern and then later matches on the tid as alias pattern but tid does not contain cid, then that parse is also rejected. An equivalent rule also exists for sub-queries bound to table aliases. Lastly, PICARD prohibits duplicate binding of a table alias in the same select scope, but permits shadowing of aliases defined in a surrounding scope. This can happen in nested SQL queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Parsing with Guards</head><p>In its highest parsing mode, PICARD engages in additional analyses-called guards-while assembling the SQL AST. If PICARD matches on tid.cid or alias.cid, then guards require that the table tid or the alias alias, respectively, is eventually brought into scope by adding it to the from clause. Moreover, the alias alias is constrained to resolve to a table or a sub-query that has the column cid in it. If PICARD matches on the pattern cid, then another guard requires that exactly one table is eventually brought into scope that contains a column with that id. These guards are enforced eagerly in order to fail fast and to eject invalid hypotheses from the beam at the earliest possible time. The first time this is happening is after parsing the from clause.</p><p>Only with these guards, PICARD is able to reject a wrong prediction from our fine-tuned T5-Large model like select maker, model from car_makers for the question "What are the makers and models?" Here, the correct table to use would have been model_list, since it is the only one in Spider's car_1 schema that contains both a maker and a model column.</p><p>Additional checks and guards are conceivable, for instance, checking that only expressions of the same type are compared or that column types selected by union, except, or intersect queries match. We leave these additional checks to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Our experiments are mainly focused on Spider <ref type="bibr" target="#b17">(Yu et al., 2018)</ref>, a large multi-domain and crossdatabase dataset for text-to-SQL parsing. We train on the 7,000 examples in the Spider training set and evaluate on Spider's development set and its hidden test set. We also report results on the CoSQL SQL-grounded dialog state tracking task <ref type="bibr" target="#b15">(Yu et al., 2019)</ref>, where we predict a SQL query for each question given previous questions in an interaction context. For this task, we train on both the Spider text-to-SQL training data and the CoSQL dialog state tracking training data, and evaluate on the CoSQL development and test sets.</p><p>Spider and CoSQL are both zero-shot settings. There is no overlap between questions or databases between the respective training, development, and test sets.</p><p>On Spider, we determine model performance based on three metrics: exact-set-match accuracy, execution accuracy, and test-suite execution accuracy <ref type="bibr" target="#b18">(Zhong et al., 2020)</ref>. Exact-set-match accuracy compares the predicted and the ground-truth SQL query by parsing both into a normalized data structure. This comparison is not sensitive to literal query values and can decrease under semanticpreserving SQL query rewriting. Execution accuracy compares the results of executing the predicted and ground-truth SQL queries on the database contents shipped with the Spider dataset. This metric is sensitive to literal query values, but suffers from a high false positive rate <ref type="bibr" target="#b18">(Zhong et al., 2020)</ref>. Lastly, test-suite execution accuracy extends execution to multiple database instances per SQL schema. The contents of these instances are optimized to lower the number of false positives and to provide the best approximation of semantic accuracy.</p><p>On CoSQL, we measure model performance in terms of the question match accuracy and the interaction match accuracy. Both metrics are based on exact-set-match accuracy. Interaction match accuracy is the joint accuracy over all questions in an interaction.</p><p>We are encouraged by results by <ref type="bibr" target="#b8">Shaw et al. (2021)</ref>, who showed that a pre-trained T5-Base or T5-3B model can not only learn the text-to-SQL task, but also generalize to unseen databases, and even that T5-3B can be competitive with the then-state-of-the-art <ref type="bibr" target="#b1">(Choi et al., 2021;</ref><ref type="bibr" target="#b12">Wang et al., 2020</ref>)-all without modifications to the model. We therefore use T5 as the baseline for all our experiments.</p><p>In order to allow for generalization to unseen databases, we encode the schema together with the questions. We use the same serialization scheme used by <ref type="bibr" target="#b8">Shaw et al. (2021)</ref>. In experiments using database content, we detect and attach the database values to the column names in a fashion similar to the BRIDGE model by <ref type="bibr" target="#b4">Lin et al. (2020)</ref>. When fine-tuning for the CoSQL dialog state tracking task, we append the previous questions in the interaction in reverse chronological order to the input. Inputs exceeding the 512-token limit of T5 are truncated. The target is the SQL from the Spider and/or CoSQL training sets, unmodified except for a conversion of keywords and identifiers to lower case. We fine-tune T5 for up to 3072 epochs using Adafactor <ref type="bibr" target="#b9">(Shazeer and Stern, 2018)</ref>, a batch size of 2048, and a learning rate of 10 ?4 .</p><p>Results Our findings on the Spider dataset are summarized in <ref type="table" target="#tab_4">Table 1</ref> and <ref type="figure">Figure 1</ref>. Our reproductions of <ref type="bibr" target="#b8">Shaw et al. (2021)</ref>'s results with T5 cannot compete with the current state of the art on Spider. The issue is that these models predict a lot of invalid SQL. For instance, 12% of the SQL queries generated by the T5-3B model on Spider's development set result in an execution error. However, when these same models are augmented with PICARD, we find substantial improvements. First, invalid SQL predictions become rare. For T5-3B with PICARD, only 2% of the predictions are unusable. In these cases, beam search exited without finding a valid SQL prediction. Second, and most significantly, by using PICARD, the T5-3B model is lifted to state-of-the-art performance. We measure an exact-set-match accuracy of 75.5% on the development set and 71.9% on the test set. The execution accuracy results are 79.3% and 75.1%, respectively. These numbers are on par or higher than those of the closest competitor, LGESQL + ELECTRA ) (see <ref type="table" target="#tab_4">Table 1</ref>). Furthermore, we achieve a test-suite execution accuracy of 71.9% on Spider's development set.</p><p>Our findings on the CoSQL dialog state tracking dataset (see <ref type="table" target="#tab_5">Table 2</ref>) are similar to those for Spider. PICARD significantly improves the performance, and our fine-tuned T5-3B model achieves state-ofthe-art performance.</p><p>PICARD is not only improving performance, it is also fast. During evaluation of the T5-3B model on Spider, the decoding speed with beam size 4 on an NVIDIA A100-SXM4-40GB GPU was, on average, 2.5 seconds per sample without PICARD and 3.1 seconds per sample with PICARD.</p><p>Beam Size <ref type="figure">Figure 1</ref> shows results on Spider without and with PICARD when parsing with guards for different beam sizes and sizes of T5. For each model size, PICARD increases performance  <ref type="figure">Figure 3</ref>: Exact-set-match accuracy on the Spider development set as a function of beam size for top-4 PICARD on T5-Large (schema only) and for different operation modes: turned off, lexing, parsing without guards, and parsing with guards. In each mode, PI-CARD is either used incrementally at each step or only when finalizing a hypothesis.</p><p>with increasing beam size. These increases are the strongest for the step from beam size 1 to 2, less pronounced from 2 to 4, and then saturating for beam sizes above 4. Even with greedy search (beam size 1), PICARD allows for some modest improvements. Note that, without PICARD, these models do not benefit from beam search. The number, k, of highest-probability tokens that are processed by PICARD at each decoding step has a modest to negligible impact on performance. It is the largest for T5-Base, smaller for T5-Large, and almost undetectable for T5-3B. We do not study the case k = 1, because it reduces the beam search to constrained greedy search.</p><p>Ablations In <ref type="figure">Figure 3</ref>, we have condensed our ablation analysis for PICARD. We show results for our T5-Large model in all four PICARD checking modes and for four different beam sizes on the Spider development set. When checking incrementally at each decoding step, lexing shows a small improvement over the unconstrained T5 model. The results without PICARD and with PICARD in lexing mode are largely independent of the beam size. This is different when PICARD is switched into the more sophisticated parsing modes. Both, with and without guards, improvements from PICARD increase rapidly for increasing beam sizes, where parsing with guards clearly has a strong lead over parsing without them. In order to compare PICARD with the filteringby-validity approach of <ref type="bibr" target="#b11">Suhr et al. (2020)</ref>   <ref type="bibr">(Shi et al., 2021)</ref> 71.8 -69.7 -DT-Fixup SQL-SP + ROBERTA ? <ref type="bibr" target="#b13">(Xu et al., 2021)</ref> 75.0 -70.9 -LGESQL + ELECTRA ?  75.1 -72.0 -T5-Base <ref type="bibr" target="#b8">(Shaw et al., 2021)</ref> 57.1 ---T5-3B <ref type="bibr" target="#b8">(Shaw et al., 2021)</ref> 70.0 ---    <ref type="formula">(2020)</ref>, we have studied also what happens when PICARD is only checking hypotheses when the model predicts their finalization with the end-ofsequence token. 2 In this restrained mode, PICARD is still effective, but much less so compared to normal incremental operation. The gap between these two modes of operation only begins to shrink for large beam sizes. This is understandable since <ref type="bibr" target="#b4">Lin et al. (2020)</ref> used beam sizes of at least 16 and up to 64 to reach optimal results with filtering while <ref type="bibr" target="#b11">Suhr et al. (2020)</ref> used a beam of size 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose and evaluate a new method, PICARD, for simple and effective constrained decoding with large pre-trained language models. On both, the Spider cross-domain and cross-database text-to-SQL dataset and the CoSQL SQL-grounded dialog state tracking dataset, we find that the PICARD decoding method not only significantly improves the performance of fine-tuned but otherwise unmodified T5 models, it also lifts a T5-3B model to stateof-the-art results on the established exact-match and execution accuracy metrics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Our results (bottom) and relevant prior art (top) on the Spider text-to-SQL task. Shown are the exact-setmatch accuracy (EM) and execution accuracy (EX) percentages on Spider's development and test sets. Our results are for a beam of size 4, and PICARD is parsing with guards for the top-2 token predictions. A dagger ( ?) indicates use of database content, otherwise schema only.</figDesc><table><row><cell></cell><cell cols="2">Development</cell><cell>Test</cell><cell></cell></row><row><cell>System</cell><cell cols="4">QM% IM% QM% IM%</cell></row><row><cell>RATSQL + SCORE (Yu et al., 2021)</cell><cell>52.1</cell><cell>22.0</cell><cell>51.6</cell><cell>21.2</cell></row><row><cell>T5-3B</cell><cell>53.8</cell><cell>21.8</cell><cell>51.4</cell><cell>21.7</cell></row><row><cell>T5-3B+PICARD</cell><cell>56.9</cell><cell>24.2</cell><cell>54.6</cell><cell>23.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Our results (bottom) and relevant prior art (top) on the CoSQL dialog state tracking task. Shown are the question match accuracy (QM) and interaction match accuracy (IM) percentages on CoSQL's development and test sets. Our results are for a beam of size 4, and PICARD is parsing with guards for the top-2 token predictions.</figDesc><table /><note>et al.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This is not exactly equivalent to filtering a completely finalized beam, because the hypotheses rejected by PICARD never enter it and never take up any space.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Lee Zamparo for his contributions to the experiments on the CoSQL dataset. Further, we would like to thank Pete Shaw for his input on the reproduction of the T5 results on Spider. We would also like to extend our gratitude to Tao Yu and Yusen Zhang for their efforts in evaluating our model on the test split of the Spider and CoSQL datasets. Finally, we thank our anonymous reviewers for their time and valuable suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LGESQL: Line graph enhanced text-to-SQL model with mixed local and nonlocal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruisheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.198</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2541" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeong Cheol</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunggyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong Ryeol</forename><surname>Shin</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00403</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="332" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parsec: Direct style monadic parser combinators for the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Leijen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Meijer</surname></persName>
		</author>
		<idno>UU-CS-2001-27</idno>
	</analytic>
	<monogr>
		<title level="m">11th International Conference</title>
		<meeting><address><addrLine>UM; Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>User Modeling</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Grammar-based neural text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Jonathan Berant, and Matt Gardner</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bridging textual and tabular data for crossdomain text-to-sql semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.438</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gamari</surname></persName>
		</author>
		<title level="m">attoparsec: Fast combinator parsing for bytestrings and text. Software available on the Haskell package repository</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SmBoP: Semi-autoregressive bottom-up semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="311" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compositional generalization and natural language variation: Can a semantic parsing approach handle both?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.75</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="922" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adafactor: Adaptive learning rates with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4596" to="4604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cicero Nogueira dos Santos, and Bing Xiang. 2021. Learning contextual representations for semantic parsing with generation-augmented pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">Hanbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13806" to="13814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploring unexplored generalization challenges for cross-database semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alane</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.742</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8372" to="8388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimizing deeper transformers on small datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanshuai</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.163</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2089" to="2102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tranx: A transition-based neural abstract syntax parser for semantic parsing and code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-2002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CoSQL: A conversational text-to-SQL challenge towards crossdomain natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyang</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Chern Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1204</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1962" to="1979" />
		</imprint>
	</monogr>
	<note>Walter Lasecki, and Dragomir Radev. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Score: Pretraining for context representation in conversational semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic evaluation for text-to-sql with distilled test suites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
