<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Sequence-to-Sequence Approach to Dialogue State Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Feng</surname></persName>
							<email>?yue.feng.20@ucl.ac.uk?wangyang.127</email>
							<affiliation key="aff0">
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">ByteDance AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">ByteDance AI Lab</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Sequence-to-Sequence Approach to Dialogue State Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper is concerned with dialogue state tracking (DST) in a task-oriented dialogue system. Building a DST module that is highly effective is still a challenging issue, although significant progresses have been made recently. This paper proposes a new approach to dialogue state tracking, referred to as Seq2Seq-DU, which formalizes DST as a sequence-tosequence problem. Seq2Seq-DU employs two BERT-based encoders to respectively encode the utterances in the dialogue and the descriptions of schemas, an attender to calculate attentions between the utterance embeddings and the schema embeddings, and a decoder to generate pointers to represent the current state of dialogue. Seq2Seq-DU has the following advantages. It can jointly model intents, slots, and slot values; it can leverage the rich representations of utterances and schemas based on BERT; it can effectively deal with categorical and non-categorical slots, and unseen schemas. In addition, Seq2Seq-DU can also be used in the NLU (natural language understanding) module of a dialogue system. Experimental results on benchmark datasets in different settings (SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, M2M, SNIPS, and ATIS) show that Seq2Seq-DU outperforms the existing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A task-oriented dialogue system usually consists of several modules: natural language understanding (NLU), dialogue state tracking (DST), dialogue policy (Policy), and natural language generation (NLG). We consider DST and also NLU in this paper. In NLU, a semantic frame representing the content of user utterance is created in each turn</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User System State</head><p>Service: "Flight":</p><p>Find your next flight.</p><p>Schema <ref type="figure">Figure 1</ref>: An example of dialogue state tracking. Given a dialogue history that contains user utterances and system utterances, and descriptions of schema that contain all possible intents and slot-value pairs, a dialogue state for the current turn is created which is represented by intents and slot-value pairs. There are slot values obtained from the schema (categorical) as well as slot values extracted from the utterances (non-categorical). #4, #6, etc denote pointers.</p><p>of dialogue. In DST, several semantic frames representing the 'states' of dialogue are created and updated in multiple turns of dialogue. Domain knowledge in dialogues is represented by a representation referred to as schema, which consists of possible intents, slots, and slot values. Slot values can be in a pre-defined set, with the corresponding slot being referred to as categorical slot, and they can also be from an open set, with the corresponding slot being referred to as non-categorical slot. <ref type="figure">Figure 1</ref> shows an example of DST. We think that a DST module (and an NLU module) should have the following abilities. (1) Global, the model can jointly represent intents, slots, and slot values. (2) Represenable, it has strong capa-arXiv:2011.09553v2 [cs.CL] 29 May 2021 bility to represent knowledge for the task, on top of a pre-trained language model like BERT. (3) Scalable, the model can deal with categorical and non-categorical slots and unseen schemas.</p><p>Many methods have been proposed for DST <ref type="bibr" target="#b37">Zhong et al., 2018;</ref><ref type="bibr" target="#b18">Mrk?i? et al., 2017;</ref><ref type="bibr" target="#b9">Goo et al., 2018)</ref>. There are two lines of relevant research. (1) To enhance the scalability of DST, a problem formulation, referred to as schemaguided dialogue, is proposed. In the setting, it is assumed that descriptions on schemas in natural language across multiple domains are given and utilized. Consequently, a number of methods are developed to make use of schema descriptions to increase the scalability of DST <ref type="bibr" target="#b24">(Rastogi et al., 2019;</ref><ref type="bibr" target="#b34">Zang et al., 2020;</ref><ref type="bibr" target="#b19">Noroozi et al., 2020)</ref>. The methods regard DST as a classification and/or an extraction problem and independently infer the intent and slot value pairs for the current turn. Therefore, the proposed models are generally representable and scalable, but not global.</p><p>(2) There are also a few methods which view DST as a sequence to sequence problem. Some methods sequentially infer the intent and slot value pairs for the current turn on the basis of dialogue history and usually employ a hierarchical structure (not based on BERT) for the inference <ref type="bibr" target="#b16">(Lei et al., 2018;</ref><ref type="bibr" target="#b25">Ren et al., 2019;</ref><ref type="bibr" target="#b5">Chen et al., 2020b)</ref>. Recently, a new approach is proposed which formalizes the tasks in dialogue as sequence prediction problems using a unified language model (based on GPT-2) <ref type="bibr">(Hosseini-Asl et al., 2020)</ref>. The method cannot deal with unseen schemas and intents, however, and thus is not scalable.</p><p>We propose a novel approach to DST, referred to as Seq2Seq-DU (sequence-to-sequence for dialogue understanding), which combines the advantages of the existing approaches. To the best of our knowledge, there was no previous work which studied the approach. We think that DST should be formalized as a sequence to sequence or 'translation' problem in which the utterances in the dialogue are transformed into semantic frames. In this way, the intents, slots, and slot values can be jointly modeled. Moreover, NLU can also be viewed as a special case of DST and thus Seq2Seq-DU can also be applied to NLU. We note that very recently the effectiveness of the sequence to sequence approach has also been verified in other language understanding tasks <ref type="bibr">(Paolini et al., 2021)</ref>.</p><p>Seq2Seq-DU comprises a BERT-based encoder to encode the utterances in the dialogue, a BERT based encoder to encode the schema descriptions, an attender to calculate attentions between the utterance embeddings and schema embeddings, and a decoder to generate pointers of items representing the intents and slots-value pairs of state.</p><p>Seq2Seq-DU has the following advantages. (1) Global: it relies on the sequence to sequence framework to simultaneously model the intents, slots, and slot-values. (2) Representable: It employs BERT <ref type="bibr" target="#b7">(Devlin et al., 2019)</ref> to learn and utilize better representations of not only the current utterance but also the previous utterances in the dialogue. If schema descriptions are available, it also employs BERT for the learning and utilization of their representations. (3) Scalable: It uses the pointer generation mechanism, as in the Pointer Network <ref type="bibr" target="#b29">(Vinyals et al., 2015)</ref>, to create representations of intents, slots, and slot-values, no matter whether the slots are categorical or non-categorical, and whether the schemas are unseen or not.</p><p>Experimental results on benchmark datasets show that Seq2Seq-DU 1 performs much better than the baselines on SGD, MultiWOZ2.2, and Multi-WOZ2.1 in multi-turn dialogue with schema descriptions, is superior to BERT-DST on WOZ2.0, DSTC2, and M2M, in multi-turn dialogue without schema descriptions, and works equally well as Joint BERT on ATIS and SNIPS in single turn dialogue (in fact, it degenerates to Joint BERT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There has been a large amount of work on task-oriented dialogue, especially dialogue state tracking and natural language understanding (eg., <ref type="bibr" target="#b2">Chen et al., 2017)</ref>). <ref type="table" target="#tab_0">Table 1</ref> makes a summary of existing methods on DST. We also indicate the methods on which we make comparison in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dialogue State Tracking</head><p>Previous approaches mainly focus on encoding of the dialogue context and employ deep neural networks such as CNN, RNN, and LSTM-RNN to independently infer the values of slots in DST <ref type="bibr" target="#b18">(Mrk?i? et al., 2017;</ref><ref type="bibr" target="#b32">Xu and Hu, 2018;</ref><ref type="bibr" target="#b37">Zhong et al., 2018;</ref><ref type="bibr" target="#b23">Rastogi et al., 2017;</ref><ref type="bibr" target="#b21">Ramadan et al., 2018;</ref><ref type="bibr" target="#b35">Zhang et al., 2019;</ref><ref type="bibr" target="#b11">Heck et al., 2020)</ref>. The approaches Model Characteristics</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Sets Comparison</head><p>FastSGD <ref type="bibr" target="#b19">(Noroozi et al., 2020)</ref> BERT-based model, employs two carry-over procedures and multi-head attentions to model schema descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGD Yes</head><p>SGD Baseline <ref type="bibr" target="#b24">(Rastogi et al., 2019)</ref> BERT-based model, predictions are made over a dynamic set of intents and slots, using their descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGD and MultiWOZ2.2 Yes</head><p>TripPy <ref type="bibr" target="#b11">(Heck et al., 2020)</ref> BERT-based model, make use of various copy mechanisms to fill slots with values.</p><p>MultiWOZ2.2 Yes TRADE  Generate dialogue states from utterances using a copy mechanism, facilitating knowledge transfer for new schema elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiWOZ2.2 Yes</head><p>DS-DST <ref type="bibr" target="#b35">(Zhang et al., 2019)</ref> BERT-based model, to classify over a candidate list or find values from text spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MultiWOZ2.2 Yes</head><p>BERT-DST <ref type="bibr" target="#b1">(Chao and Lane, 2019)</ref> Use BERT as dialogue context encoder and makes parameter sharing across slots.</p><p>DSTC2, WOZ2.0, and M2M Yes</p><p>StateNet  Independent of number of values, shares parameters across slots and uses pre-trained word vectors.</p><p>DSTC2 and WOZ2.0 Yes GLAD <ref type="bibr" target="#b37">(Zhong et al., 2018)</ref> Use global modules to share parameters across slots and uses local modules to retrain slot-specific parameters. cannot deal with unseen schemas in new domains, however. To cope with the problem, a new direction called schema-guided dialogue is proposed recently, which assumes that natural language descriptions of schemas are provided and can be used to help transfer knowledge across domains. As such, a number of methods are developed in the recent dialogue competition SGD <ref type="bibr" target="#b24">(Rastogi et al., 2019;</ref><ref type="bibr" target="#b34">Zang et al., 2020;</ref><ref type="bibr" target="#b19">Noroozi et al., 2020;</ref><ref type="bibr" target="#b3">Chen et al., 2020a)</ref>. Our work is partially motivated by the SGD initiative. Our model Seq2Seq-DU is unique in that it formalizes schema-guided DST as a sequence-to-sequence problem using BERT and pointer generation.</p><p>In fact, sequence-to-sequence models are also utilized in DST. Sequicity <ref type="bibr" target="#b16">(Lei et al., 2018</ref>) is a two-step sequence to sequence model which first encodes the dialogue history and generates a belief span, and then generates a language response from the belief span. COMER <ref type="bibr" target="#b25">(Ren et al., 2019)</ref> and CREDIT <ref type="bibr" target="#b5">(Chen et al., 2020b)</ref> are hierarchical sequence-to-sequence models which represent the intents and slot-value pairs in a hierarchical way, and employ a multi-stage decoder. Simple-TOD (Hosseini-Asl et al., 2020) is a unified approach to task-oriented dialogue which employs a single and causal language model to perform sequence prediction in DST, Policy, and NLG. Our proposed approach also uses a sequence-tosequence model. There are significant differences between our model Seq2Seq-DU and the existing models. First, there is no hierarchy in decoding of Seq2Seq-DU. A flat structure on top of BERT appears to be sufficient for jointly capturing the intents, slots, and values. Second, the decoder in Seq2Seq-DU generates pointers instead of tokens, and thus can easily and effectively handle categorical slots, non-categorical slots, as well as unseen schemas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Natural Language Understanding</head><p>Traditionally the problem of NLU is decomposed into two independent issues, namely classification of intents and sequence labeling of slot-value pairs <ref type="bibr" target="#b17">(Liu and Lane, 2016;</ref><ref type="bibr" target="#b10">Hakkani-T?r et al., 2016)</ref>. For example, deep neural network combined with conditional random field is employed for the task <ref type="bibr" target="#b33">(Yao et al., 2014)</ref>. Recently the pretrained language model BERT <ref type="bibr" target="#b4">(Chen et al., 2019</ref>) is exploited to further enhance the accuracy. Methods are also proposed which can jointly train and utilize classification and sequence labeling models (Chen </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>Our approach Seq2Seq-DU formalizes dialogue state tracking as a sequence to sequence problem using BERT and pointer generation. As shown in <ref type="figure">Figure 2</ref>, Seq2Seq-DU consists of an utterance encoder, a schema encoder, an utterance schema attender, and a state decoder. In each turn of dialogue, the utterance encoder transforms the current user utterance and the previous utterances in the dialogue into a sequence of utterance embeddings using BERT; the schema encoder transforms the schema descriptions into a set of schema embeddings also using BERT; the utterance schema attender calculates attentions between the utterance embeddings and the schema embeddings to create attended utterance and schema representations; finally, the state decoder sequentially generates a state representation on the basis of the attended representations using LSTM and pointer generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Utterance Encoder</head><p>The utterance encoder takes the current user utterance as well as the previous utterances (user and system utterances) in the dialogue (a sequence of tokens) as input and employs BERT to construct a sequence of utterance embeddings. The relations between the current utterance and the previous utterances are captured by the encoder. The input of the encoder is a sequence of tokens with length N , denoted as X = (x 1 , ..., x N ). The first token x 1 is [CLS], followed by the tokens of the current user utterance and the tokens of the previous utterances, separated by <ref type="bibr">[SEP]</ref>. The output is a sequence of embeddings also with length N , denoted as D = (d 1 , ..., d N ) and referred to as utterance embeddings, with one embedding for each token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Schema Encoder</head><p>The schema encoder takes the descriptions of intents, slots, and categorical slot values (a set of combined sequences of tokens) as input and employs BERT to construct a set of schema embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schema</head><p>Sequence 1 Sequence 2 Intent service description intent description Slot service description slot description Value slot description value Suppose that there are I intents, S slots, and V categorical slot values in the schemas. Each schema element is described by two descriptions as outlined in <ref type="table" target="#tab_2">Table 2</ref>. The input is a set of combined sequences of tokens, denoted as Y = {y 1 , ..., y M }. Note that M = I + S + V . Each combined sequence starts with [CLS], followed by the tokens of the two descriptions with [SEP] as a separator. The final representation of [CLS] is used as the embedding of the input intent, slot, or slot value. The output is a set of embeddings, and all the embeddings are called schema embeddings E = {e 1 , ..., e M }.</p><p>The schema encoder in fact adopts the same approach of schema encoding as in <ref type="bibr" target="#b24">(Rastogi et al., 2019)</ref>. There are two advantages with the approach. First, the encoder can be trained across different domains. Schema descriptions in different domains can be utilized together. Second, once the encoder is fine-tuned, it can be used to process unseen schemas with new intents, slots, and slot values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Utterance-Schema Attender</head><p>The utterance-schema attender takes the sequence of utterance embeddings and the set of schema embeddings as input and calculates schema-attended utterance representations and utterance-attended schema representations. In this way, information from the utterances and information from the schemas are fused.</p><p>First, the attender constructs an attention matrix, indicating the similarities between utterance embeddings and schema embeddings. Given the i-th utterance token embedding d i and j-th schema embedding e j , it calculates the similarity as follows,</p><formula xml:id="formula_0">A(i, j) = r tanh(W 1 d i + W 2 e j ),<label>(1)</label></formula><p>where r, W 1 , W 2 are trainable parameters. The attender then normalizes each row of matrix A as a probability distribution, to obtain matrix A. Each row represents the attention weights of schema elements with respect to an utterance token. Then the schema-attended utterance representations are calculated as D a = EA . The attender also normalizes each column of matrix A as a probability distribution, to obtain matrix A. Each column represents the attention weights of utterance tokens with respect to a schema element. Then the utterance-attended schema representations are calculated as E a = D A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">State Decoder</head><p>The state decoder sequentially generates a state representation (semantic frame) for the current turn, which is represented as a sequence of pointers to elements of the schemas and tokens of the utterances (cf., <ref type="figure">Figure 1</ref>). The sequence can then be either re-formalized as a semantic frame in dialogue state tracking 2 , [intent; (slot 1 , value 1 ); (slot 2 , value 2 ); ...], or a sequence of labels in NLU (intent-labeling and slot-filling). The pointers point to the elements of intents, slots, and slot values in the schema descriptions (categorical slot values), as well as the tokens in the utterances (non-categorical slot values). The elements in the schemas can be either words or phrases, and the tokens in the utterances form spans for extraction of slot values.</p><p>The state decoder is an LSTM using pointer <ref type="bibr" target="#b29">(Vinyals et al., 2015)</ref> and attention <ref type="bibr" target="#b0">(Bahdanau et al., 2015)</ref>. It takes the two representations D a and E a as input. At each decode step t, the decoder receives the embedding of the previous item w t?1 , the utterance context vector u t , the schema context vector s t , and the previous hidden state h t?1 , and produces the current hidden state h t :</p><formula xml:id="formula_1">h t = LSTM(w t?1 , h t?1 , u t , s t ).<label>(2)</label></formula><p>We adopt the attention function in <ref type="bibr" target="#b0">(Bahdanau et al., 2015)</ref> to calculate the context vectors as follows,</p><formula xml:id="formula_2">u t = attend(h t?1 , D a , D a ),<label>(3)</label></formula><formula xml:id="formula_3">s t = attend(h t?1 , E a , E a ).<label>(4)</label></formula><p>The decoder then generates a pointer from the set of pointers in the schema elements and the tokens of the utterances on the basis of the hidden state h t . Specifically, it generates a pointer of item w according to the following distribution,</p><formula xml:id="formula_4">z w = q tanh(U 1 h t + U 2 k w ), (5) P (#w) = softmax(z w ),<label>(6)</label></formula><p>where #w is the pointer of item w, k w is the representation of item w either in the utterance representations D a or in the schema representations E a , q, U 1 , and U 2 are trainable parameters, and softmax is calculated over all possible pointers. During decoding, the decoder employs beam search to find the best sequences of pointers in terms of probability of sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>The training of Seq2Seq-DU follows the standard procedure of sequence-to-sequence. The only difference is that it is always conditioned on the schema descriptions. Each instance in training consists of the current utterance and the previous utterances, and the state representation (sequence of pointers) for the current turn. Two pre-trained  BERT models are used for representations of utterances and schema descriptions respectively. The BERT models are then fine-tuned in the training process. Cross-entropy loss is utilized to measure the loss of generating a sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conduct experiments using the benchmark datasets on task-oriented dialogue. SGD <ref type="bibr" target="#b24">(Rastogi et al., 2019)</ref> and MultiWOZ2.2 <ref type="bibr" target="#b34">(Zang et al., 2020)</ref> are datasets for DST; they include schemas with categorical slots and non-categorical slots in multiple domains and natural language descriptions on the schemas, as shown in <ref type="table" target="#tab_2">Table 2</ref>. In particular, SGD includes unseen schemas in the test set. Mul-tiWOZ2.1 <ref type="bibr" target="#b8">(Eric et al., 2020)</ref> is the previous version of MultiWOZ2.2, which only has categorical slots in multiple domains. WOZ2.0 (Wen et al., 2017) and DSTC2 <ref type="bibr" target="#b12">(Henderson et al., 2014)</ref> are datasets for DST; they contain schemas with only categorical slots in a single domain. M2M <ref type="bibr" target="#b27">(Shah et al., 2018</ref>) is a dataset for DST and it has span annotations for slot values in multiple domains. ATIS <ref type="bibr" target="#b28">(Tur et al., 2010)</ref> and SNIPS <ref type="bibr" target="#b6">(Coucke et al., 2018)</ref> are datasets for NLU in single-turn dialogues in a single domain. <ref type="table" target="#tab_4">Table 3</ref> gives the statics of datasets in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines and Variants</head><p>We make comparison between our approach and the state-of-the-art methods on the datasets. SGD, MultiWOZ2.2 and MultiWOZ2.1: We compare Seq2SeqDU with six state-of-the-art methods on SGD, MultiWOZ2.2 and MultiWOZ2.1, which utilize schema descriptions, span-based and candidate-based methods, unified seq2seq model and BERT: FastSGT <ref type="bibr" target="#b19">(Noroozi et al., 2020)</ref>, SGDbaseline <ref type="bibr" target="#b24">(Rastogi et al., 2019)</ref>, TripPy <ref type="bibr" target="#b11">(Heck et al., 2020)</ref>, SimpleTOD (Hosseini-Asl et al., 2020), TRADE , and DS-DST <ref type="bibr" target="#b35">(Zhang et al., 2019)</ref>. WOZ2.0 and DSTC2: Our approach is compared against the state-of-the-art methods on WOZ2.0 and DSTC2, including those using a hierarchical seq2seq model and BERT: COMER <ref type="bibr" target="#b25">(Ren et al., 2019)</ref>, BERT-DST <ref type="bibr" target="#b1">(Chao and Lane, 2019)</ref>, StateNet , GLAD <ref type="bibr" target="#b37">(Zhong et al., 2018</ref><ref type="bibr">), Belief Tracking (Ramadan et al., 2018</ref>, and Neural Belief Tracker <ref type="bibr" target="#b18">(Mrk?i? et al., 2017)</ref>. M2M: We evaluate our approach and the stateof-the-art methods on M2M, which respectively employ a BERT-based architecture and a jointlytrained language understanding model, BERT-DST <ref type="bibr" target="#b1">(Chao and Lane, 2019)</ref> and DST+LU . ATIS and SNIPS: We make comparison between our approach and the state-of-the-art methods on ATIS and SNIPS for NLU within the sequence labeling framework, including Joint BERT <ref type="bibr" target="#b4">(Chen et al., 2019)</ref>, <ref type="bibr">Slot-Gated (Goo et al., 2018)</ref>, Atten.-BiRNN <ref type="bibr" target="#b17">(Liu and Lane, 2016)</ref>, and RNN-LSTM <ref type="bibr" target="#b10">(Hakkani-T?r et al., 2016)</ref>. We also include two variants of Seq2Seq-DU. The differences are whether to use the schema descriptions, and the formation of dialogue state. Seq2Seq-DU-w/oSchema: It is used for datasets that do not have schema descriptions. It only contains utterance encoder and state decoder. Seq2Seq-DU-SeqLabel: It is used for NLU in a single-turn dialogue. It views the problem as sequence labeling, and only contains the utterance encoder and state decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Measures</head><p>We make use of the following metrics in evaluation. Intent Accuracy: percentage of turns in dialogue for which the intent is correctly identified. Joint Goal Accuracy: percentage of turns for which all the slots are correctly identified. For non-categorical slots, a fuzzy matching score is used on SGD and exact match are used on the other datasets to keep the numbers comparable with other works. Slot F1: F1 score to evaluate accuracy of slot sequence labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training</head><p>We use the pre-trained BERT model ([BERT-Base, Uncased]), which has 12 hidden layers of 768 units and 12 self-attention heads to encode utterances and schema descriptions. The hidden size of LSTM decoder is also 768. The dropout probability is 0.1. We also use beam search for decoding, with a beam size of 5. The batch size is set to 8. Adam <ref type="bibr" target="#b15">(Kingma and Ba, 2014)</ref> is used for optimization with an initial learning rate of 1e-4. Hyper parameters are chosen using the validation dataset in all cases.</p><p>The training curves of all models are shown in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results</head><p>Tables 4, 5, 6, and 7 show the results. One can see that Seq2Seq-DU performs significantly better than the baselines in DST and performs equally well as the baselines in NLU.</p><p>DST is carried out in different settings in SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, and M2M. In all cases, Seq2Seq-DU works significantly better than the baselines. The results indicate that Seq2Seq-DU is really a general and effective model for DST, which can be applied to multiple settings. Specifically, Seq2Seq-DU can leverage the schema descriptions for DST when they are available (SGD and MultiWOZ2.2, Multi-WOZ2.1) 3 . It can work well in zero-shot learning to deal with unseen schemas (SGD). It can also effectively handle categorical slots (MultiWOZ2.1, WOZ2.0 and DSTC2) and non-categorical slots (M2M). It appears that the success of Seq2Seq-DU is due to its suitable architecture design with a sequence-to-sequence framework, BERT-based encoders, utterance-schema attender, and pointer generation decoder.</p><p>NLU is formalized as sequence labeling in ATIS and SNIPS. Seq2Seq-DU is degenerated to Seq2Seq-DU-SeqLabel, which is equivalent to the baseline of Joint Bert. The results suggest that it is the case. Specially, the performances of Seq2Seq-DU are comparable with Joint BERT, indicating that Seq2Seq-DU can also be employed in NLU.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Ablation Study</head><p>We also conduct ablation study on Seq2Seq-DU. We validate the effects of three factors: BERTbased encoder, utterance-schema attention, and pointer generation decoder. The results indicate that all the components of Seq2Seq-DU are indispensable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of BERT</head><p>To investigate the effectiveness of using BERT in the utterance encoder and schema encoder, we replace BERT with Bi-directional LSTM and run the model on SGD and MultiWOZ2.2. As shown in <ref type="figure" target="#fig_0">Figure 3</ref>, the performance of the BiLSTM-based model Seq2Seq-DU-w/oBert in terms of Joint GA and Int. Acc decreases significantly compared with Seq2Seq-DU. It indicates that the BERT-based encoders can create and utilize more accurate representations for dialogue understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Attention</head><p>To investigate the effectiveness of using attention, we compare Seq2Seq-DU with Seq2Seq-DUw/oAttention which eliminates the attention mechanism, Seq2Seq-DU-w/SchemaAtt which only contains the utterance-attended schema representations, and Seq2Seq-DU-w/UtteranceAtt which only contains the schema-attended utterance representations. <ref type="figure" target="#fig_0">Figure 3</ref> shows the results on SGD and MultiWOZ2.2 in terms of Joint GA and Int. Acc. One can observe that without attention the performances deteriorate considerably. In addition, the performances of unidirectional attentions are inferior to the performance of bidirectional attention. Thus, utilization of bidirectional attention between utterances and schema descriptions is desriable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Pointer Generation</head><p>To investigate the effectiveness of the pointer generation mechanism, we directly generate words from the vocabulary instead of generating pointers in the decoding process. <ref type="figure" target="#fig_0">Figure 3</ref> also shows the results of Seq2Seq-DU-w/oPointer on SGD and MultiWOZ2.2 in terms of Joint GA and Int. Acc. From the results we can see that pointer generation is crucial for coping with unseen schemas.</p><p>In SGD which contains a large number of unseen schemas in the test set, there is significant performance degradation without pointer generation. The results on MultiWOZ2.2, which does not have unseen schemas in the test set, show pointer generation can also make significant improvement on already seen schemas by making full use of schema descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study</head><p>We make qualitative analysis on the results of Seq2Seq-DU and SGD-baseline on SGD and Mul-tiWOZ2.2. We find that Seq2Seq-DU can make more accurate inference of dialogue states by leveraging the relations existing in the utterances and schema descriptions. For example, in the first case in <ref type="table">Table 8</ref>, the user wants to find a cheap guesthouse. Seq2Seq-DU can correctly infer that the hotel type is "guesthouse" by referring to the relation between "hotel-pricerange" and "hotel-type". In the second case, the user wants to rent a room with in-unit laundry. In the dataset, a user who intends to rent a room will care more about the laundry property. Seq2Seq-DU can effectively extract the relation between "intent" and "in-unit-laundry", yielding a correct result. In contrast, SGD-baseline does not model the relations in the schemas, and thus it cannot properly infer the values of "hoteltype" and "in-unit-laundry".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dealing with Unseen Schemas</head><p>We analyze the zero-shot learning ability of Seq2Seq-DU. One bedroom is fine. It also needs in-unit laundry.</p><p>"area": Campbell; "in-unit-laundry": True; "intent": rent; "numberof-baths": 1; "number-ofbeds": 1; "active-intent": FindHomeByArea;</p><p>"area": Campbell; "in-unitlaundry": -; "intent": rent; "number-of-baths": 1; "number-of-beds": 1; "active-intent": FindHome-ByArea;</p><p>"area": Campbell; "inunit-laundry": True; "intent": rent; "number-ofbaths": 1; "number-ofbeds": 1; "active-intent": FindHomeByArea; 2 User: The location isn't really important. It does need to be cheap though, and preferably a guesthouse.</p><p>"hotel-area": dontcare ; "hotel-pricerange": cheap; " hotel-type": guesthouse; "active intent": find-hotel;</p><p>"hotel-area": dontcare ; "hotel-pricerange": cheap; "hotel-type": hotel; "active intent": find-hotel;</p><p>"hotel-area": dontcare; "hotel-pricerange": cheap; "hotel-type": guesthouse; "active intent": find-hotel; <ref type="table">Table 8</ref>: Case study on Seq2Seq-DU and SGD-baseline on SGD and MultiWOZ2.2. The first example is from SGD and the second is from MultiWOZ2.2. The underlined slot-value pairs represent the ground truth states. The slot-value pairs in blue are correctly predicted ones, while the slot-value pairs in red are incorrectly predicted ones.</p><p>in the domains with all seen schemas. The domains that have more partially seen schemas achieve higher accuracies, such as "Hotels", "Movies", "Services". The accuracies decline in the domains with more unseen schemas, such as "Messaging" and "RentalCars". We conclude that Seq2Seq-DU can perform zero-shot learning across domains. However, the ability still needs enhancement.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categorical Slots and Non-categorical Slots</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have proposed a new approach to dialogue state tracking. The approach, referred to as Seq2Seq-DU, takes dialogue state tracking (DST) as a problem of transforming all the utterances in a dialogue into semantic frames (state representations) on the basis of schema descriptions. Seq2Seq-DU is unique in that within the sequence to sequence framework it employs BERT in encoding of utterances and schema descriptions respectively and generates pointers in decoding of dialogue state. Seq2Seq-DU is a global, reprentable, and scalable model for DST as well as NLU (natural language understanding). Experimental results show that Seq2Seq-DU significantly outperforms the state-ofthe-arts methods in DST on the benchmark datasets of SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, M2M, and performs as well as the stateof-the-arts in NLU on the benchmark datasets of ATIS and SNIPS.</p><p>A Training Curves <ref type="figure">Figure 4</ref> shows the training losses of Seq2Seq-DU on the training datasets, while <ref type="figure" target="#fig_1">Figure 5</ref> shows the accuracies of Seq2Seq-DU on the test sets during training. We regard training convergence when the fluctuation of loss is less than 0.01 for consecutive 20 thousand steps. Seq2Seq-DU converges at the 180k-th step on SGD, MultiWOZ2.2, and Multi-WOZ2.1. Seq2Seq-DU-w/oSchema converges at the 150k-th step on WOZ2.0 and at the 140k-th step on DSTC2, and M2M. Furthermore, Seq2Seq-DU-SeqLabel converges at the 130k-th step on ATIS and SNIPS. These are consistent with the general trends in machine learning that more complex models are more difficult to train. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Ablation study results of Seq2Seq-DU with respect to BERT, attention, and pointer generation on SGD and MultiWOZ2.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Accuracies of Seq2Seq-DU in terms of Join GA / Slot F1 on all test sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>DSTC2 and WOZ2.0</cell><cell>Yes</cell></row></table><note>: Summary of existing methods on DST.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Utterance-Schema Attender</head><label></label><figDesc></figDesc><table><row><cell cols="3">Utterance Encoder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>d1</cell><cell>d2</cell><cell>d3</cell><cell>?</cell><cell>dn-1</cell><cell>dN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">BERT-Based Utterance Encoder</cell><cell>d1</cell><cell>da1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>d2</cell><cell>da2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dialogue</cell><cell>CLS</cell><cell>x1</cell><cell>x2</cell><cell>SEP</cell><cell>x3</cell><cell>x4</cell><cell>d3 ?</cell><cell>da3 ?</cell><cell cols="5">State Decoder</cell><cell></cell></row><row><cell></cell><cell cols="4">Current User Utterance</cell><cell cols="2">Previous Utterances</cell><cell>dN</cell><cell>daN</cell><cell cols="2">&lt;intent&gt;</cell><cell></cell><cell cols="2">&lt;slot1&gt;</cell><cell cols="2">&lt;value1&gt;</cell><cell>&lt;slot2&gt;</cell><cell>&lt;value2&gt;</cell><cell>&lt;EOS&gt;</cell></row><row><cell cols="3">ej Schema Encoder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>D</cell><cell>Da</cell><cell></cell><cell cols="2">? "</cell><cell></cell><cell>? #</cell><cell></cell><cell>? $</cell><cell>? %</cell><cell>? &amp;</cell><cell>? '</cell></row><row><cell></cell><cell cols="6">BERT-Based Schema Encoder</cell><cell></cell><cell></cell><cell>. " / "</cell><cell>LSTM</cell><cell>. # / #</cell><cell>LSTM</cell><cell cols="2">. $ / $</cell><cell>LSTM</cell><cell>. % / %</cell><cell>LSTM</cell><cell>. &amp; / &amp;</cell><cell>LSTM</cell><cell>. ' / '</cell><cell>LSTM</cell></row><row><cell>Intent</cell><cell>CLS</cell><cell>x1</cell><cell>x2</cell><cell>SEP</cell><cell>x3</cell><cell>x4</cell><cell>E</cell><cell>Ea</cell><cell></cell><cell cols="3">( )*+,-</cell><cell>( "</cell><cell></cell><cell>( #</cell><cell>( $</cell><cell>( %</cell><cell>( &amp;</cell></row><row><cell></cell><cell cols="3">Service Description</cell><cell></cell><cell cols="2">Intent Description</cell><cell>e1</cell><cell>ea1</cell><cell></cell><cell>&lt;BOS&gt;</cell><cell></cell><cell cols="2">&lt;intent&gt;</cell><cell></cell><cell>&lt;slot1&gt;</cell><cell>&lt;value1&gt;</cell><cell>&lt;slot2&gt;</cell><cell>&lt;value2&gt;</cell></row><row><cell>Slot</cell><cell>CLS</cell><cell>x1</cell><cell>x2</cell><cell>SEP</cell><cell>x3</cell><cell>x4</cell><cell>e2</cell><cell>ea2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>e3</cell><cell>ea3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Service Description</cell><cell></cell><cell cols="2">Slot Description</cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Value</cell><cell>CLS</cell><cell>x1</cell><cell>x2</cell><cell>SEP</cell><cell>x3</cell><cell>x4</cell><cell>eM</cell><cell>eaM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Slot Description</cell><cell></cell><cell>Value</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="16">Figure 2: The architecture of Seq2Seq-DU, containing utterance encoder, schema encoder, utterance-schema atten-</cell></row><row><cell cols="3">der, and state decoder.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">et al., 2019; Goo et al., 2018). In this paper, we</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">view NLU as special case of DST and employ our</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">model Seq2Seq-DU to perform NLU. Seq2Seq-DU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">can degenerate to a BERT based NLU model.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Descriptions for a dialogue schema. Two combined descriptions are used for describing an intent, a slot, or a value in the schema.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Statistics of datasets in experiments. Numbers are those of training datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">: Accuracies of Seq2Seq-DU and baselines</cell></row><row><cell cols="3">on SGD, MultiWOZ2.2 and MultiWOZ2.1 datasets.</cell></row><row><cell cols="3">Seq2Seq-DU outperforms baselines in terms of all met-</cell></row><row><cell>rics.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="2">WOZ2.0 DSTC2 Joint GA Joint GA</cell></row><row><cell>Neural Belief Tracker</cell><cell>0.842</cell><cell>0.734</cell></row><row><cell>Belief Tracking</cell><cell>0.855</cell><cell>-</cell></row><row><cell>GLAD</cell><cell>0.881</cell><cell>0.745</cell></row><row><cell>StateNet</cell><cell>0.889</cell><cell>0.755</cell></row><row><cell>BERT-DST</cell><cell>0.877</cell><cell>0.693</cell></row><row><cell>COMER</cell><cell>0.886</cell><cell>-</cell></row><row><cell>Seq2Seq-DU-w/oSchema</cell><cell>0.912</cell><cell>0.850</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">: Accuracies of Seq2Seq-DU and baselines</cell></row><row><cell cols="3">on WOZ2.0 and DSTC2 datasets. Seq2Seq-DU-</cell></row><row><cell cols="3">w/oSchema performs significantly better than the base-</cell></row><row><cell>lines.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="2">M2M Joint GA Int Acc</cell></row><row><cell>DST+LU</cell><cell>0.767</cell><cell>-</cell></row><row><cell>BERT-DST</cell><cell>0.869</cell><cell>-</cell></row><row><cell>Seq2Seq-DU-w/oSchema</cell><cell>0.909</cell><cell>0.997</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Accuracies of Seq2Seq-DU and baselines on M2M dataset. Seq2Seq-DU-w/oSchema significantly outperforms the baselines.</figDesc><table><row><cell>Model</cell><cell cols="4">ATIS Slot F1 Int Acc Slot F1 Int Acc SNIPS</cell></row><row><cell>RNN-LSTM</cell><cell>0.943</cell><cell>0.926</cell><cell>0.873</cell><cell>0.969</cell></row><row><cell>Atten.-BiRNN</cell><cell>0.942</cell><cell>0.911</cell><cell>0.878</cell><cell>0.967</cell></row><row><cell>Slot-Gated</cell><cell>0.952</cell><cell>0.941</cell><cell>0.888</cell><cell>0.970</cell></row><row><cell>Joint BERT</cell><cell>0.961</cell><cell>0.975</cell><cell>0.970</cell><cell>0.986</cell></row><row><cell cols="2">Seq2Seq-DU-SeqLabel 0.955</cell><cell>0.968</cell><cell>0.965</cell><cell>0.990</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table /><note>Accuracies of Seq2Seq-DU and baselines on ATIS and SNIPS datasets. Seq2Seq-DU-SeqLabel per- forms comparably with Joint BERT.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9</head><label>9</label><figDesc>presents the accuracies of Seq2Seq-DU in different domains on SGD. (Note that only SGD has unseen schemas in test set.) We observe that the best performances can be obtained User: One bath is fine. Sys: How many bedrooms? User:</figDesc><table><row><cell cols="2">ID Dialogue Utterance</cell><cell>Dialogue State</cell><cell>State Predictions of</cell><cell>State Predictions of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>SGD-baseline</cell><cell>Seq2Seq-DU</cell></row><row><cell>1</cell><cell>User: I wanna rent a place in</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Campbell. Sys: How many</cell><cell></cell><cell></cell></row><row><cell></cell><cell>baths?</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Accuracy of Seq2Seq-DU in each domain on SGD test set. Domains marked with '*' are those for which the schemas in the test set are not present in the training set. Domains marked with '**' have both the unseen and seen schemas. For other domains, the schemas in the test set are also seen in the training set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10</head><label>10</label><figDesc>shows the accuracies of Seq2Seq-DU and the baselines with respect to categorical and noncategorical slots on SGD and MultiWOZ2.2. (We did not compare with FastSGT on SGD dataset due to unavailability of the codes.) One can see that Seq2Seq-DU can effectively deal with both categorical and non-categorical slots. Furthermore, Seq2Seq-DU demonstrates higher accuracies on categorical slots than non-categorical slots. We conjecture that it is due to the co-occurrences of categorical slot values in both the dialogue history and the schema descriptions. The utterance-schema attention can more easily capture the relations between the values.</figDesc><table><row><cell>Model</cell><cell>Categorical-</cell><cell>SGD Noncategorical-</cell><cell cols="2">MultiWOZ2.2 Categorical-Noncategorical-</cell></row><row><cell></cell><cell>Joint-GA</cell><cell>Joint-GA</cell><cell>Joint-GA</cell><cell>Joint-GA</cell></row><row><cell>TRADE</cell><cell>-</cell><cell>-</cell><cell>0.628</cell><cell>0.666</cell></row><row><cell cols="2">SGD-baseline 0.513</cell><cell>0.361</cell><cell>0.570</cell><cell>0.661</cell></row><row><cell>DS-DST</cell><cell>-</cell><cell>-</cell><cell>0.706</cell><cell>0.701</cell></row><row><cell>FastSGT</cell><cell>not available</cell><cell>not available</cell><cell>-</cell><cell>-</cell></row><row><cell>TripPy</cell><cell>-</cell><cell>-</cell><cell>0.684</cell><cell>0.733</cell></row><row><cell cols="2">Seq2Seq-DU 0.578</cell><cell>0.393</cell><cell>0.758</cell><cell>0.711</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Accuracies of Seq2Seq-DU and baselines with respect to categorical and non-categorical slots on SGD and MultiWOZ2.2.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code is available at https://github.com/ sweetalyssum/Seq2Seq-DU.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For simplicity, we assume here that there is only one semantic frame in each turn. In principle, there can be multiple frames.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">There are better performing systems in the SGD competition. The systems are not based on single methods and thus are not directly comparable with our method.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bert-dst: Scalable end-to-end dialogue state tracking with bidirectional encoder representations from transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guan-Lin</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on dialogue systems: Recent advances and new frontiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigkdd Explorations Newsletter</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Schema-guided multi-domain dialogue state tracking with graph attention neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boer</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bert for joint intent classification and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10909</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Credit: Coarse-to-fine sequence generation for dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10435</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaa</forename><surname>Saade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Th?odore</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Caulier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Doumouro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Gisselbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Caltagirone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In CoRR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiwoz 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shachi</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanchit</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adarsh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuj</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Slot-gated modeling for joint slot filling and intent prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Chih-Wen Goo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Kai</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Li</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Chieh</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keng-Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-domain joint semantic frame parsing using bi-directional rnn-lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?khan</forename><surname>T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TripPy: A triple copy strategy for value independent neural dialog state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nurul</forename><surname>Carel Van Niekerk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsien-Chin</forename><surname>Geishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Moresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ga?i?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00796</idno>
		<title level="m">Semih Yavuz, and Richard Socher. 2020. A simple language model for task-oriented dialogue</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Challenges in building intelligent open-domain dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TOIS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In CoRR</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention-based recurrent neural network models for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>S?aghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A fast and robust bert-based dialogue state tracker for schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelina</forename><surname>Bakhturina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Kornuta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.12335</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cicero Nogueira dos Santos, Bing Xiang, and Stefano Soatto. 2021. Structured prediction as translation between augmented natural languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Paolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Krone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishita</forename><surname>Anubhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large-scale multi-domain belief tracking with knowledge sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawe?</forename><surname>Osman Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ga?i?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-task learning for joint language understanding and dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scalable multi-domain dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASRU</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Khaitan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05855</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scalable and accurate dialogue state tracking via hierarchical sequence generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liliang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards universal dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liliang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaige</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Building a conversational agent overnight with dialogue self-play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pararth</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neha</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04871</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What is left to be understood in atis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<title level="m">Pointer networks. In NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Transferable multi-domain state generator for task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An end-to-end approach for handling unknown slot values in dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Recurrent conditional random field for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multiwoz 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03544</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Recent advances and challenges in task-oriented dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Technological Sciences</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Global-locally self-attentive encoder for dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
