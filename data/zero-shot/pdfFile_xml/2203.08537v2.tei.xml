<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scribble-Supervised LiDAR Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Unal</surname></persName>
							<email>ozan.unal@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Informatics</orgName>
								<address>
									<postCode>3 KU</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
							<email>dai@vision.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Informatics</orgName>
								<address>
									<postCode>3 KU</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><forename type="middle">Van</forename><surname>Gool</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Informatics</orgName>
								<address>
									<postCode>3 KU</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zurich</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Informatics</orgName>
								<address>
									<postCode>3 KU</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scribble-Supervised LiDAR Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Densely annotating LiDAR point clouds remains too expensive and time-consuming to keep up with the ever growing volume of data. While current literature focuses on fully-supervised performance, developing efficient methods that take advantage of realistic weak supervision have yet to be explored. In this paper, we propose using scribbles to annotate LiDAR point clouds and release ScribbleKITTI, the first scribble-annotated dataset for LiDAR semantic segmentation. Furthermore, we present a pipeline to reduce the performance gap that arises when using such weak annotations. Our pipeline comprises of three stand-alone contributions that can be combined with any LiDAR semantic segmentation model to achieve up to 95.7% of the fully-supervised performance while using only 8% labeled points. Our scribble annotations and code are available at github.com/ouenal/scribblekitti.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the increase of LiDAR's popularity on autonomous vehicles, data acquisition has significantly ramped up. However, it is very hard to keep pace with the volume of data, as the dense data annotation process is very expensive and time-consuming for large scale datasets, especially in 3D where the navigation of the annotation tool is not trivial. Even with powerful annotation tools <ref type="bibr" target="#b4">[5]</ref> that allow labeling of superimposed LiDAR frames, a single 100m by 100m tile can take up to 4.5 hours for an experienced annotator <ref type="bibr" target="#b4">[5]</ref>.</p><p>In stark contrast to the 2D cases <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31]</ref>, current efforts in 3D semantic segmentation mainly focus on designing networks for densely annotated data (e.g. <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b56">57]</ref>), as opposed to developing efficient methods for creating more labels or learning from cheap/weak supervision. It is clear that only by doing the latter, the scaling of 3D semantic segmentation can keep up with the growth of applications and data volume. In this paper, we present a method for this very purpose, by firstly introducing a new annotation strategy and later developing a pipeline to directly exploit such annotations. Using scribbles as annotations has proven to be a popular and effective method for 2D semantic segmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>. The weak annotation method allows annotators to simply mark object centers, avoiding the time consuming task of determining class boundaries.</p><p>We adopt this idea for LiDAR point clouds to supervise 3D semantic segmentation. As opposed to 2D images, 3D point clouds preserve the metric space and therefore things and stuff follow highly geometric structures. To accompany this, we propose using the more geometric line-scribble to annotate LiDAR point clouds. Compared to free-formed scribbles, annotators only need to determine the start and end points of a line annotation. This allows faster labeling of classes that span large distances (e.g. roads, buildings, fences), while also providing as sufficient information for smaller object classes (e.g. cars, trucks), as short lines and free-formed scribbles become less distinguishable.</p><p>We provide scribble-annotations for the train-split of Se-manticKITTI <ref type="bibr" target="#b4">[5]</ref> for 19 classes. The resulting scribbleannotated data, which we call ScribbleKITTI, contains 189 million labeled points corresponding to 8.06% of the total point count. <ref type="figure" target="#fig_0">Fig. 1</ref> shows an example from ScribbleKITTI. Furthermore, in this paper we develop a novel learning method for 3D semantic segmentation that directly exploits scribble annotated LiDAR data. Learning from scribble annotations provides a unique challenge as no supervision/regularization is available from unlabeled points, which form the majority of the training data. A performance gap between scribble-supervised and fully supervised training could be very large if no special methods are designed for the former. To tackle this issue, we introduce three stand-alone contributions that can be combined with any 3D LiDAR segmentation model: a teacher-student consistency loss on unlabeled points, a self-training scheme designed for outdoor LiDAR scenes, and a novel descriptor that improves pseudo-label quality.</p><p>Specifically, we first introduce a weak form of supervision from unlabeled points via a consistency loss. Secondly, we strengthen this supervision by fixing the confident predictions of our model on the unlabeled points and employing self-training with pseudo-labels. The standard self-training strategy is however very prone to confirmation bias due to the long-tailed distribution of classes inherent in autonomous driving scenes and the large variation of point density across different ranges inherent in LiDAR data. To combat these, we develop a class-range-balanced pseudolabeling strategy to uniformly sample target labels across all classes and ranges. Finally, to improve the quality of our pseudo-labels, we augment the input point cloud by using a novel descriptor that provides each point with the semantic prior about its local surrounding at multiple resolutions. In summary, our contributions are as follows:</p><p>? We present ScribbleKITTI, the first scribble-annotated LiDAR semantic segmentation dataset. ? We propose class-range-balanced self-training to combat the inherent bias towards dominant classes and close ranged dense regions in pseudo-labels. ? We further improve the pseudo-labeling quality by augmenting the input point cloud with a pyramid local semantic-context descriptor. ? Putting these two contributions along with the mean teacher framework, our scribble-based pipeline achieves up to 95.7% relative performance of fully supervised training while using only 8% labeled points. Our contributions remain orthogonal to the development of better neural network architectures and can be combined with any 3D LiDAR segmentation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>LiDAR Semantic Segmentation: As point clouds are irregular geometric data structures, current literature for 3D semantic segmentation mainly focuses on identifying and understanding various representation strategies amongst: operating directly on point coordinates <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref>, projecting the LiDAR scene onto images and employ 2D architectures <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref>, utilizing sparse 3D voxel grids <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57]</ref>, or utilizing multiple representations <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>. All of these models are developed under the fully-supervised framework, which requires densely annotated LiDAR point clouds that are time-consuming and tedious to acquire. In this work, our focus is different and our contributions are complementary. Our developed pipeline can be used with any such network in order to reduce the performance gap between fully-supervised and scribble-supervised training.</p><p>2D Scribble-supervised Semantic Segmentation: To alleviate the strenuous task of dense data annotation, two training methods can be used: weakly-supervised <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37]</ref>, where only a subset of points are labeled on every frame, and semi-supervised <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">33]</ref>, where only a subset of frames are labeled within the dataset. Scribbles have been adopted as a user-friendly form of weak supervision <ref type="bibr" target="#b23">[24]</ref>. The common approach when dealing with such weak annotations is to either employ online labeling through a consistency check using mean teacher <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b53">54]</ref>, or to employ a self-training scheme where data is iteratively processed by generating offline target pseudolabels and retraining <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b37">38]</ref>. However, the naive approach of self-training on all predictions can introduce confirmation bias <ref type="bibr" target="#b3">[4]</ref>. To combat this, threshold-based filtering can help reduce possible errors by only sampling confident predictions <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b57">58]</ref>. When facing long tailed distributions, CB-ST <ref type="bibr" target="#b58">[59]</ref> uses class-balanced sampling to avoid the domination of head classes in the pseudo labels. DARS <ref type="bibr" target="#b15">[16]</ref> extends CB-ST by re-distributing biased pseudo labels after thresholding. We extend the previously available methods to also include balancing against range to avoid undersampling points from distant, sparser regions of the LiDAR point cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incomplete Supervision in 3D Semantic Segmentation:</head><p>In contrast to 2D, incomplete supervision for point clouds have remained underexplored.</p><p>When tackling semisupervised segmentation on LiDAR point clouds, Semisup <ref type="bibr" target="#b17">[18]</ref> implements a pseudo-label guided point contrastive loss to extend supervision to unlabeled frames. Li et al. <ref type="bibr" target="#b22">[23]</ref> and SSPC <ref type="bibr" target="#b9">[10]</ref> employ self-training to achieve the same goal. Xu et al. <ref type="bibr" target="#b51">[52]</ref> compares semi-supervised training to weakly-supervised on point clouds and argues that under a fixed labelling budget, weak supervision performs better for semantic segmentation. PSD <ref type="bibr" target="#b55">[56]</ref> uses consistency check across perturbed branches to utilize unlabeled points in weakly supervised learning. However, the weak labels from existing methods <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b55">56]</ref> are generated through offline uniform sampling from dense annotations which cannot be easily adopted during the dense labeling itself. In this work, we tackle a form of weakly-supervised segmentation based on line-scribbles. Instead of using simulated weak labels, we provide a human annotated dataset to realistically validate our method. Compared to uniform sampled labels, scribbles vitally do not provide any information on class boundaries and appear only in scribble-clusters, i.e. are much less spatially distributed within a scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The ScribbleKITTI Dataset</head><p>While LiDAR point cloud semantic segmentation has gained popularity over the past years, the number of largescale datasets still remains low due to the complexity and time consumption of the data annotation process. Inspired by 2D scribble annotations <ref type="bibr" target="#b23">[24]</ref> that are efficient and easy to generate, we propose using line-scribbles to annotate Li-DAR point clouds for semantic segmentation and release ScribbleKITTI, the first scribble-annotated LiDAR point cloud dataset.</p><p>We annotate the train-split of SemanticKITTI [5] based on KITTI <ref type="bibr" target="#b14">[15]</ref> which consists of 10 sequences, 19130 scans, 2349 million points. ScribbleKITTI contains 189 million labeled points corresponding to only 8.06% of the total point count. We choose SemanticKITTI for its current wide use and established benchmark. We retain the same 19 classes to encourage easy transitioning towards research into scribble-supervised LiDAR semantic segmentation. The class-wise label distribution is visualized in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>When annotating, we use line-scribbles rather than freeforming scribbles. LiDAR point clouds preserve the metric space and therefore things (e.g. car, truck) and stuff (e.g. terrain, road) mostly follow highly geometric structures. While both drawings are valid approaches, we found that line scribbles allow faster labeling of such geometric classes that span large distances (e.g. roads, sidewalks, buildings, fences), as annotators only need to provide two clicks (start and end) to annotate an entire segment. We illustrate this by showcasing an example annotated tile in <ref type="figure">Fig. 3</ref>. Data Annotation: We use the help of student annotators. Following Behley et al. <ref type="bibr" target="#b4">[5]</ref>, we initially screen the annotators until they are comfortable navigating within the 3D space to ensure good results. We subdivide a sequence of superimposed point clouds into 100m by 100m tiles and label on a per-tile basis. We generate scribble annotations through line drawings using an adapted point labeling <ref type="figure">Figure 3</ref>. Line-annotation process illustrated on a 100m by 100m tile. Classes that span large distances such as building (yellow) and road (pink) can be annotated with only two clicks. As the tile is annotated using 2D lines projected onto the 3D surface, scribbles may become indistinguishable once the viewing angle changes (e.g. bottom right). tool 1 <ref type="bibr" target="#b4">[5]</ref>. We overlap neighboring tiles to allow labeling consistency across the entire sequence. Finally, we do a comparison to SemanticKITTI to stay consistent with their class definitions. We provide further information in the supplementary materials on the labeling process.</p><p>An annotator needs on average 10-25 minutes per tile depending on the contents (e.g. highway vs. city) as opposed to the reported 1.5-4.5 hours for full annotations <ref type="bibr" target="#b4">[5]</ref>. This corresponds to roughly a 90% time saving, which can account to over a thousands hours for large scale datasets <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Scribble-Supervised LiDAR Segmentation</head><p>The naive approach of tackling scribble-supervised semantic segmentation is to treat the problem similarly to any fully supervised task and employ a loss H (typically crossentropy) on the available labeled points.</p><p>We define a LiDAR point cloud P as the set of points P = {p | p = (x, y, z, I) ? R 4 } with (x, y, z) denoting the 3D coordinates and I the reflectance intensity. We further define S ? P as the set of labeled points. The objective function over F frames can therefore be formulated as:</p><formula xml:id="formula_0">min ? F f =1 |P f | i=1 1(p f,i ? S) H(? f,i | ? , y f,i ) (1)</formula><p>with? f,i | ? denoting the predicted class distribution for the point p f,i ? P f of frame f given the network parameters ?, and y f,i denoting the ground truth label.  During training, we preform pyramid local semantic-context (PLS) augmentation before training the mean teacher model on the available scribble-annotations. During pseudo-labeling, we generate target labels in a class-range-balanced (CRB) manner. Finally during distillation, we retrain the mean teacher on the generated pseudo-labels. LS and LU denote the losses applied to the supervised-and unsupervised set of points respectively. Gray arrows propagate label information.</p><p>In this baseline approach the unlabeled points which contain vital boundary information are not used. Furthermore due to the sheer lack of labeled data points, performance degradation is unavoidable, as confidence on long tailed object classes suffer due to the reduced supervision.</p><p>In the following sections, we address these issues by introducing three stand-alone methods that utilize unlabeled points and expand the annotated dataset: partial consistency loss with mean teacher (Sec </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Partial Consistency Loss with Mean Teacher</head><p>Firstly, we introduce further weak supervision to the unlabeled set of points via a consistency loss applied using mean teacher. The mean teacher framework is formed of two models, namely the student, parametrized by ?, and the teacher, parametrized by ? EMA <ref type="bibr" target="#b42">[43]</ref>. Unlike the student network, which is traditionally trained using gradient descent, the teacher weights are computed as the exponential moving average (EMA) of successive student weights, resulting in the update function:</p><formula xml:id="formula_1">? EMA t = ?? EMA t?1 + (1 ? ?)? t<label>(2)</label></formula><p>for time step t, with ? denoting the smoothing coefficient which determines the update speed. Stochastic averaging of weights has been shown to yield more accurate models than using the final training weights directly <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b42">43]</ref>, allowing the teacher predictions to be used as a form of weak supervision for the student under varying small perturbations. We further define U as the set of unlabeled points, i.e. P \ S. We introduce a consistency loss between the student and teacher networks, but unlike Tan et al. <ref type="bibr" target="#b39">[40]</ref>, we restrict the consistency loss to only unlabeled points p ? U . This allows a sharper supervision on labeled points in S by eliminating the teacher injected uncertainties, while retaining the unlabeled supervision that takes advantage of the more accurate teacher predictions. This restriction is more in alignment with the applications of the mean teacher framework in semi-supervised tasks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>We extend our objective function (Eq. 1) to include supervision on unlabeled points as:</p><formula xml:id="formula_2">min ? F f =1 |P f | i=1 G i,f = H(? f,i | ? , y f,i ) if p f,i ? S log(? f,i | ? )? f,i | ? EMA if p f,i ? U</formula><p>(3) with? f,i | ? denoting the predicted class distribution for the point p f,i given the network parameters ?, y denoting the ground truth label. To reduce the Shannon mutual information, i.e. to increase the training signal from the consistency loss, we apply a heavier augmentation the student input in the form of global rotation, translation, random flip and white Gaussian noise <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>While mean teacher introduces supervision on unlabeled points, the information gain is limited by the teachers performance. Even if the teacher predicts the correct label for a point, due to the soft pseudo-labeling, the confidences on other classes will continue to guide the student's output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Class-range-balanced Self-training (CRB-ST)</head><p>To combat this uncertainty injection and more directly utilize the confident predictions of unlabeled points, we expand the annotated dataset and employ self-training. Our goal by introducing self-training alongside mean teacher, is to keep the soft pseudo-label guidance of the mean teacher for uncertain predictions while hardening the pseudo-labels of certain predictions. Using the teacher's most confident predictions, we generate target labels for a subset of unlabeled points. We define this set of pseudo-labeled points as L and later retrain our network on S ? L.</p><p>Formally, we extend our objective function (Eq. 3) to also learn target labels as hidden variables:</p><formula xml:id="formula_3">min ?,? F f =1 |P f | i=1 G i,f ? (log(? f,i | ? EMA ) + k)? f,i G i,f = H(? f,i | ? , y f,i ) if p f,i ? S ? L log(? f,i | ? )? f,i | ? EMA if p f,i ? U \ L (4) where? f,i = [? (1) f,i , . . . ,? (C) f,i ] ? {{e|e ? R C } ? 0} is</formula><p>the pseudo-label vector, e denoting a one-shot vector, C denoting the number of classes and k denoting the negative log-confidence threshold. The generated pseudo-label set is given by L = {p f,i |? f,i ? = 0, ?f, i}. To exploit the increased performance generated from stochastic weight averaging, we sample labels from the teacher's output (? EMA ).</p><p>We initialize the optimization of Eq. 4 by setting the latent variable? = 0 for all points, i.e. by only selecting the scribble-annotation (L = ?). The self-training protocol from pseudo-labels can then be summarised in two steps:</p><p>1. Training: We fix? and optimize the objective function with respect to ?. 2. Pseudo-labeling: We fix ? (and effectively ? EMA ) and optimize the objective function with respect to?. We update L given?. The two steps can be repeated to take advantage of the improved representation capability of the model through pseudo-labeling.</p><p>While self-training with pseudo-labels has been proven to be an effective strategy in scribble-supervised semantic segmentation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38]</ref>, the class distribution in autonomous driving scenes are inherently long tailed, which may result in the gradual dominance of large and easy-to-learn classes on generated pseudo-labels. CB-ST <ref type="bibr" target="#b58">[59]</ref> proposes to sample labels while retaining the overall class distribution by setting thresholds in a class-wise manner. While this is sufficient in the 2D setting, we observe that 3D LiDAR data presents an additional unique challenge.</p><p>Due to the nature of the LiDAR sensor, the local point density varies based on the beam radius, as sparsity increases with distance. This results in sampling of pseudolabels mainly from denser regions, which tend to show a higher estimation confidence. To reduce this bias in the pseudo-label generation, we propose a revised self-training scheme that not only balances based on the overall classwise distribution, but also on range. We call our method class-range-balanced (CRB) pseudo-labeling and provide a visual sample in <ref type="figure">Fig. 5</ref> comparing it to CB-ST.</p><p>We initially coarsely divide the transverse plane into R annuli of width B centered around the ego-vehicle. In a b <ref type="figure">Figure 5</ref>. Visual comparison of (50%) (a) class-balanced pseudolabeling <ref type="bibr" target="#b58">[59]</ref> and (b) proposed CRB. As seen right, generated pseudo-labels lack distant sparse region representation when balancing solely on class. Red lines For the quantitative analysis, see Tab. 4. <ref type="figure">Fig. 5</ref>.b we illustrate the first three in red dashed lines. Each annulus contains points that fall between a range of distances, from which we pseudo-label the globally highest confident predictions on a per-class basis. This ensures that we obtain reliable labels while distributing them proportionally across varying ranges and across all classes.</p><p>We redefine the self-training objective function (Eq.4) to include CRB as:</p><formula xml:id="formula_4">min ?,? F f =1 |P f | i=1 G i,f ? C c=1 R r=1 F i,f,c,r F i,f,c,r = ? ? ? ? ? (log(? (c) f,i | ? EMA ) + k (c,r) )? (c) f,i , if r = ?||(p x,y ) f,i ||/B? 0, otherwise<label>(5)</label></formula><p>with k (c,r) denoting the negative log-threshold for a classannulus pairing. To solve the nonlinear integer optimization task, we employ the following solver:</p><formula xml:id="formula_5">y (c) * f,i = ? ? ? ? ? ? ? ? ? 1, if c = argmax? f,i | ? EMA , y f,i | ? &gt; exp(?k (c,r) ) with r = ?||(p x,y ) f,i ||/B? 0, otherwise<label>(6)</label></formula><p>When determining k (c,r) , we take the maximum output probability of each point, i.e. the networks confidence for the predicted label, and store the confidence values of all points in all frames for each class-annulus pairing in a global vector. Each vector is then sorted in descending order. We define a hyperparameter ? which determines the percentage of pseudo-labels to be sampled, and find a threshold confidence for each vector by taking the value at index ? times the vectors length. k (c,r) is set as the negative logarithm of the threshold confidence. The process is summarized in Algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Pyramid Local Semantic-context (PLS)</head><p>With self-training, the performance of the final network (Sec. 4.2, training) is highly reliant on the pseudo-label quality. To ensure higher quality pseudo-labels, we further introduce a novel descriptor to enrich the features of the initial points by utilizing available scribbles.</p><p>We make the following two observations for the distribution of semantic classes in 3D space: (1) There exists a spatial smoothness constraint, i.e. a point in space is likely have the same class label as at least one of its neighbors since objects have nonzero dimensions; (2) There exists a semantic pattern constraint, i.e. a set of complex high-level rules governing inter-class spatial relations. For example, in outdoor autonomous driving scenes, vehicles lie on ground classes such as roads and parking areas, pedestrians often appear on sidewalks, buildings and vegetation outline roads.</p><p>We therefore argue that a local semantic prior can be used as a rich point descriptor to encapsulate the two stated cues. We propose using local semantic-context at scaling resolutions to reduce the ambiguity when propagating information between the labeled-unlabeled point sets and to improve pseudo-labeling quality. We identify that the distribution of class labels over global coordinates is a robust, compact semantic descriptor, especially for unlabeled points.</p><p>We initially discretize the space into coarse voxels. This step is crucial as to avoid over-descriptive features that cause the network to overfit to the scribble annotations, reducing its capability to generalize well and understand meaningful geometric relations. We use multiple sizes of bins in cylindrical coordinates in order to follow the inherent point distribution of the LiDAR sensor at different resolutions. For each bin b i we compute a coarse histogram:</p><formula xml:id="formula_6">h i = [h (1) i , . . . , h (C) i ] ? R C h (c) i = #{y j = c ? j| p j ? b i }<label>(7)</label></formula><p>as illustrated in <ref type="figure" target="#fig_5">Fig. 6</ref>. The pyramid local semantic-context (PLS) of all points p j ? b i is then defined as the concatenation of the normalized histograms:</p><formula xml:id="formula_7">PLS = [h 1 i / max(h 1 i ), . . . , h s i / max(h s i )] ? R sC (8) for s resolutions.</formula><p>We append PLS to the input features and redefine the input LiDAR point cloud as the augmented set of points P aug = {p | p = (x, y, z, I, PLS) ? R 4+sC }. When optimizing Eq. 5, during the training step (Sec. 4.2) we substitute P with P aug such that we generate better quality pseudo-labels during pseudo-labeling.</p><p>At the end of the self-training pipeline, we require one extra distillation stage because PLS augmentation cannot be used during test-time as the scribble-information is not available. During distillation, we again set the input point cloud to P . The resulting three stages of the overall pipeline is illustrated in <ref type="figure" target="#fig_2">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We carry out our experiments using Cylinder3D <ref type="bibr" target="#b56">[57]</ref> but forego the applied test-time-augmentation (TTA) and test the performance on the fully annotated SemanticKITTI <ref type="bibr" target="#b4">[5]</ref> valid-set unless stated otherwise. Alongside the mean-Intersection-over-Union (mIoU), we also provide the relative performance of scribble-supervised (SS) training to the fully supervised upper-bound (FS) in percentages (SS/FS).</p><p>Implementation Details: For MT we set ? = 0.99. For CRB, we define R = 10 annuli. For PLS, we divide (r, ?) into <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b39">40)</ref>, <ref type="bibr" target="#b39">(40,</ref><ref type="bibr">80)</ref> and (80, 120) voxels. We only apply one iteration of self-training (? = 50%) as we don't observe a significant increase in performance in consecutive steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results</head><p>We present the 3D semantic segmentation results from the SemanticKITTI valid-set in Tab. 1 for three state-ofthe-art networks (Cylinder3D <ref type="bibr" target="#b56">[57]</ref>, MinkowskiNet <ref type="bibr" target="#b10">[11]</ref>, SPVCNN <ref type="bibr" target="#b40">[41]</ref>) to demonstrate the model independence of our approach. For the training schedule and architecture details, please refer to the respective publications. In <ref type="figure" target="#fig_6">Fig. 7</ref> we present visual results using Cylinder3D.</p><p>Due to the lack of available supervision, the three presented models trained on scribble-annotations show a relative performances (SS/FS) of 88.6%, 90.0% and 89.2% compared to their respective fully supervised upper-bound. While the reduction in the number of supervised points reduce the class-wise performance across the board, this effect is further amplified for long tailed classes such as bicycle, truck and other-vehicle.</p><p>By applying our proposed pipeline for scribblesupervised LiDAR semantic segmentation, we are able to reduce the gap between the two training strategies significantly, reaching 95.3%, 95.7%, 95.3% relative performance for all three models. As observed, the major performance gains originate from the same long tailed classes that initially show a deficit against their respective baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Ablation Studies</head><p>Scribbles as Annotations: We compare our proposed labeling strategy of weakly labeling all frames to fully labeling partial frames under a fixed labeling budget in Tab. 2 and present the results for both Cylinder3D <ref type="bibr" target="#b56">[57]</ref> and Sup-only, the baseline U-Net model employed in Semi-sup <ref type="bibr" target="#b17">[18]</ref>. As seen, both models perform significantly better using scribble annotations compared to having full annotations on 10% of the train-set by up to +10.2% and +11.1% mIoU. Furthermore in Tab. 2, we also compare the current state-of-the-art on semi-supervised LiDAR semantic segmentation with our proposed scribble-supervised approach. Semi-sup <ref type="bibr" target="#b17">[18]</ref> which further makes use of the 90% unlabeled frames still shows a 5.1% lower mIoU performance than a its baseline Semi-sup trained on scribble-annotations. Moreover, the same baseline model trained with our proposed pipeline further increases the gap to 8.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Network Components:</head><p>We perform ablation studies to investigate the effects of the different components of our proposed pipeline for scribble-supervised LiDAR semantic segmentation. We report the performance on the Se-manticKITTI train-set for intermediate steps, as this metric provides an indication of the pseudo-labeling quality, and on the valid-set to assess the performance benefits of each individual component. As seen in Tab. 3, by adding a weak form of supervision to the unlabeled point set via MT, we observe a 2.3% increase in mIoU, which alone reduces the relative performance drop of scribble-supervised training below 10%. However the fully labeled training performance does not increase significantly. Applying CRB-ST at this point yields an mIoU of 60.6%. Using PLS, we can further increase the training mIoU by 8.0%, which has the benefit of boosting pseudo-labeling accuracy from 98.1% to 99.0% and improving mIoU performance in the subsequent step of the self-training protocol. Self-training with CRB pseudolabeling now yields a further 0.6% increase in mIoU. Pseudo-label Filtering for Self-training: We perform further ablation studies on the pseudo-labeling strategy used in the proposed self-training (ST) protocol and report the results in Tab. 4. We replace our proposed CRB pseudolabeling module with naive sampling (where all predictions are taken as pseudo-labels), threshold-based sampling <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b57">58]</ref>, class-balanced sampling (CB) <ref type="bibr" target="#b58">[59]</ref> and DARS <ref type="bibr" target="#b15">[16]</ref>. For all given strategies we use the same input predictions generated from the PLS augmented MT.</p><p>Due to the long-tailed nature of outdoor LiDAR scenes for semantic segmentation, CB and DARS show great improvements over naive and threshold based sampling strategies with improvements of up to +1.7%. Here we observe that in 3D semantic segmentation, the confidence overlapping is not as prevalent as in 2D. Applying DARS on CB generated pseudo-labels results in a reduction of only 1.8% data points on the entire train-set with ? = 50% (at most 2.4% for head classes). Therefore both CB and DARS per-  <ref type="bibr" target="#b17">[18]</ref> 10% frames fully 43.9 Sup-only <ref type="bibr" target="#b17">[18]</ref> 8% points scribbles 55.0 Semi-sup <ref type="bibr" target="#b17">[18]</ref> 10% frames fully ? 49.9 Sup-only+Ours 8% points scribbles ? 58.5  <ref type="table">Table 3</ref>. Ablation study on proposed methods. PLS results are given after the first iteration, while CRB-ST results are given after the last iteration. Performances are reported on the Se-manticKITTI trainand valid-sets respectively, along with the relative performance against fully supervised (SS/FS).</p><p>form similarly at 60.8% on the valid-set. After applying further balancing on range with our proposed CRB, we observe an improvement of +0.5% over CB, reaching a relative performance of 95.3% to fully-supervised. Consistency-loss within Mean Teacher: We perform further ablation studies on the consistency loss within the mean teacher framework and compare our partial application on unlabeled points to the application on all points <ref type="bibr" target="#b51">[52]</ref>. As seen in Tab. 5, the difference between the two losses is negligible when training with scribble annotations. Scribbles only account for roughly 8% of the total point count, therefore the loss is mainly dominated by the unsupervised points in either setting. However, when training on generated pseudo-labels, we observe that the teacher network  <ref type="table">Table 5</ref>. Compared is the application of the consistency-loss on all points <ref type="bibr" target="#b51">[52]</ref> to our proposed partial application on only unlabeled points. We conduct experiments using the mean teacher pipeline with scribble annotations (8%) and CRB pseudo-labels (50%).</p><p>can inject uncertainties to labeled points, weakening the introduced supervision from the pseudo-labels and causing a decrease in mIoU of 0.9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented a weakly-supervised pipeline for Li-DAR semantic segmentation based on scribble annotations. Our pipeline comprises of three stand-alone contributions that can be combined with any LiDAR semantic segmentation model to reduce the gap between fully-supervised and scribble-supervised training. Limitations: We only annotate the train-split of Se-manticKITTI <ref type="bibr" target="#b4">[5]</ref>. We haven't applied our method to different datasets and LiDAR sensors due to annotation cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">The ScribbleKITTI Dataset</head><p>The goal of generating scribble-annotations is to to be fast and efficient while retaining as much information as possible to allow relatively high performance when compared to fully-supervised training. To this end, we formulate a set of guidelines for our annotators that also allows us to remain consistent across the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Process:</head><p>We modify the point labeler <ref type="bibr" target="#b4">[5]</ref> to include line annotations. An example of the labeler GUI can be seen in <ref type="figure">Fig. 8</ref>. As seen, the annotator draws lines on the LiDAR scene by determining its start and end points. The tool also allows multi-segment lines (when providing more than two points) to allow easier labeling of curved surfaces. As Li-DAR point clouds are inherently sparse, we add a thickness to the drawn line. All points, who's projections fall onto the thickened line, are labeled. At 25m height we set the line thickness to 4 pixels. We adjust the thickness proportionally to the zoom settings to remain consistent throughout the labeling.</p><p>Guidelines: During labeling, each object in a scene (e.g. vehicle, person, sign, trunk) is marked with a single line. To ease the process and eliminate any spillage to the ground points, the annotators can use a threshold based filter for the z-axis (which was already implemented in the point labeler <ref type="bibr" target="#b4">[5]</ref>) to hide ground points. An example can be see in <ref type="figure">Fig. 8</ref> bottom-right. However, unlike the dense annotated case, annotators do not need to later remove the filter in order to determine difficult border points between objects and ground classes.</p><p>For classes that cover large distances, e.g ground classes (e.g. road, sidewalk, parking) and structure fa?ades (e.g. building, fence), we try to annotate each segment using the least amount of scribbles. For example, given a north-south facing road segment that later turns right, the annotator draws two line-scribbles: 1) a north-south facing scribble that extends from the tile edge to junction, and 2) a westeast facing scribble that extends from the junction to the corresponding tile edge. If object interfere with the linescribble (e.g. a car is in the middle of the road) the annotator can chose to scribble on either side of the object. For vegetation, each patch of greenery is annotated once. When periodically placed trees or bushes have similar heights, the threshold based filter can be used to isolate them, allowing a single annotation line to cover multiple individual trees. This also holds for sparse vegetation clusters in empty space (see main text <ref type="figure">Fig. 3 -bottom right)</ref>. As 2D lines are projected onto the 3D surface to generate annotations, such scribbles may become indistinguishable once the viewing angle changes. <ref type="figure">Figure 8</ref>. Screenshot of the labeling GUI and illustration of the process. As seen, the labeling tool <ref type="bibr" target="#b4">[5]</ref> has been modified to be able to generate line annotations. The annotator needs to only select the starting and ending positions of the line.</p><p>? mIoU SS/FS 30% 60.9 94.7 50% 61.3 95.3 70% 60.8 94.6 <ref type="table">Table 6</ref>. Investigating the effect of ? for CRB-ST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Ablation Studies</head><p>Semi-supervised dataset: Our line-scribbles label roughly 8% of the total point count and take 10% of the time to acquire compared to their fully labeled counterpart (based on the reported times of SemanticKITTI <ref type="bibr" target="#b4">[5]</ref>). Under a fixed labeling budget, we show that scribble-annotating all frames enables better representation capabilities compared to fully labeling partial frames (see main text Sec. 5.2). For these experiments, when simulating the semi-labeled setting, we follow the data generation process of Semi-sup <ref type="bibr" target="#b17">[18]</ref> with 10% labeling. Labeling Percentage for CRB-ST: We further investigate the effect of the labeling percentage ? for CRB-ST. In Tab. 6 we compare results for three beta values at 30%, 50%, 70%. As seen, the mIoU performance does depend on the percentage of predictions selected as pseudo-labels. ? = 50% outperforms 30% and 70% by 0.4% and 0.5% respectively, achieving a better balance between the introduction of more supervision through pseudo-labeling, and the reduction of errors propagating from pseudo-labeling to distillation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Example of scribble-annotated LiDAR point cloud scenes of a single frame (top) and superimposed frames (bottom). Compared are the proposed ScribbleKITTI (left) with the fully labeled counterpart from SemanticKITTI [5] (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Number of points labeled in ScribbleKITTI (? = 1) visualized against SemanticKITTI (? = 0.5) in log-scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of the proposed pipeline for scribble-supervised LiDAR semantic segmentation comprising of three steps: training, pseudo-labeling, distillation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>. 4.1), class-range-balanced self-training (Sec. 4.2), and pyramid local semantic-context (Sec. 4.3). Our overall pipeline can be seen in Fig. 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 : 3 B 9 M 10 M</head><label>13910</label><figDesc>Determination of k in CRB Input: Dataset containing F point clouds, trained neural network ?, annulus count R, portion ? of selected pseudo-labels 1 for f = 1 : F do 2 value, class = max(?(P f ), axis=0) = max( P f [:, 0] 2 + P f [:, 1] 2 ) / R 4 range = P f [:, 0] 2 + P f [:, 1] 2 // B 5 for c = 1 : C do 6 mask c = (class == c) 7 for r = 1 : R do 8 mask r = (range == r) (c,r,f ) = value[mask c &amp; mask r ] (c,r) = [M (c,r) , M (c,r,f ) ] 11 for c = 1 : C do 12 for r = 1 : R do 13 M (c,r) = sort(M (c,r) , order=descending) 14 thresh = ?? length(M (c,r) ) 15 k (c,r) = -log(M (c,r) [:thresh]) Return: k = [k (0,0) , . . . , k (c,r) ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Illustration of pyramid local semantic-context (PLS) augmentation based on scribble ground-truth (not to scale). As seen, the semantic-context can provide highly descriptive information about the local neighborhood of a point at scaling resolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Example results from the SemanticKITTI valid-set comparing (a) the ground truth frame; to Cylinder3D [57] trained (b) scribble-supervised, and (c) scribble-supervised using our proposed pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>49.8 69.4 84.3 50.6 71.9 88.0 0.0 94.4 39.4 80.9 0.1 90.5 58.9 88.1 68.1 75.5 63.2 50.2 Cylinder3D [57] scribble 57.0 88.6 88.5 39.9 58.0 58.4 48.1 68.6 77.0 0.5 84.4 30.4 72.2 2.5 89.4 48.4 81.9 64.6 59.8 61.2 48.3D semantic segmentation results evaluated on the SemanticKITTI valid-set. Alongside the per-class metrics we show the relative performance of the scribble supervised approach against the fully supervised (SS/FS).</figDesc><table><row><cell>Model</cell><cell cols="4">Supervision Ours mIoU SS/FF</cell><cell>car</cell><cell>bicycle</cell><cell>motorcycle</cell><cell>truck</cell><cell>other vehicle</cell><cell>person</cell><cell>bicyclist</cell><cell>motorcyclist</cell><cell>road</cell><cell>parking</cell><cell>sidewalk</cell><cell>other ground</cell><cell>building</cell><cell>fence</cell><cell>vegetation</cell><cell>trunk</cell><cell>terrain</cell><cell>pole</cell><cell>traffic sign</cell></row><row><cell></cell><cell>fully</cell><cell></cell><cell>64.3</cell><cell>-</cell><cell cols="17">96.3 7</cell></row><row><cell></cell><cell>scribble</cell><cell>?</cell><cell cols="19">61.3 95.3 91.0 41.1 58.1 85.5 57.1 71.7 80.9 0.0 87.2 35.1 74.6 3.3 88.8 51.5 86.3 68.0 70.7 63.4 49.5</cell></row><row><cell></cell><cell>fully</cell><cell></cell><cell>61.1</cell><cell>-</cell><cell cols="17">95.7 20.4 63.9 70.3 45.5 65.0 78.5 0.0 93.5 49.6 81.0 0.2 91.1 63.8 87.2 68.5 72.3 64.4 49.1</cell></row><row><cell cols="2">MinkowskiNet [11] scribble</cell><cell></cell><cell cols="19">55.0 90.0 88.1 13.2 55.1 72.3 36.9 61.3 77.1 0.0 83.4 32.7 71.0 0.3 90.0 50.0 84.1 66.6 65.8 61.6 35.2</cell></row><row><cell></cell><cell>scribble</cell><cell>?</cell><cell cols="19">58.5 95.7 91.1 23.8 59.0 66.3 58.6 65.2 75.2 0.0 83.8 36.1 72.4 0.7 90.2 51.8 86.7 68.5 72.5 62.5 46.6</cell></row><row><cell></cell><cell>fully</cell><cell></cell><cell>63.8</cell><cell>-</cell><cell cols="17">97.1 35.2 64.6 72.7 64.3 69.7 82.5 0.2 93.5 50.8 81.0 0.3 91.1 63.5 89.2 66.1 77.2 64.1 49.4</cell></row><row><cell>SPVCNN [41]</cell><cell>scribble</cell><cell></cell><cell cols="19">56.9 89.2 88.6 25.7 55.9 67.4 48.8 65.0 78.2 0.0 82.6 30.4 70.1 0.3 90.5 49.6 84.4 67.6 66.1 61.6 48.7</cell></row><row><cell></cell><cell>scribble</cell><cell>?</cell><cell cols="19">60.8 95.3 91.1 35.3 57.2 71.1 63.8 70.0 81.3 0.0 84.6 37.9 72.9 0.0 90.0 54.0 87.4 71.1 73.0 64.0 50.5</cell></row><row><cell></cell><cell cols="3">Labeled</cell><cell cols="4">Unlabeled Valid</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Volume</cell><cell></cell><cell>Type</cell><cell></cell><cell>Used</cell><cell></cell><cell>mIoU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Cylinder3D [57] 10% frames fully</cell><cell></cell><cell></cell><cell></cell><cell>46.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Cylinder3D [57] 8% points scribbles</cell><cell></cell><cell></cell><cell>57.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sup-only</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Compared are different annotation strategies for incomplete supervision. Sup-only refers to the baseline sparse U-Net model employed by Semi-sup<ref type="bibr" target="#b17">[18]</ref>. 10% frames fully labeled correspond to 10.06% annotated points.</figDesc><table><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell>Train</cell><cell>Valid</cell></row><row><cell cols="7">Baseline MT CRB-ST PLS mIoU mIoU SS/FS</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell cols="3">77.6 57.0 88.6</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell cols="3">78.0 59.3 92.2</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>-</cell><cell cols="2">60.6 94.2</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell cols="2">? 86.0</cell><cell>-</cell><cell>-</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>-</cell><cell cols="2">61.3 95.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on the pseudo-labeling strategies comparing naive (all predictions), threshold-based, class-balanced labeling and DARS with our proposed CRB. ? determines the percentage of labeled points. Performances are reported on the Se-manticKITTI valid-set. All methods use the same initial labels.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Labeling</cell><cell>Valid</cell></row><row><cell cols="2">Pseudo-labeling Method</cell><cell cols="2">? Acc mIoU SS/FS</cell></row><row><cell>Naive</cell><cell></cell><cell cols="2">-86.3 59.4 92.4</cell></row><row><cell cols="4">Threshold-based [8, 49, 58] 50% 99.0 59.1 91.9</cell></row><row><cell>Class-balanced [59]</cell><cell></cell><cell cols="2">50% 99.4 60.8 94.6</cell></row><row><cell>DARS [16]</cell><cell></cell><cell cols="2">50% 99.3 60.8 94.6</cell></row><row><cell>CRB (Ours)</cell><cell></cell><cell cols="2">50% 99.0 61.3 95.3</cell></row><row><cell></cell><cell cols="2">Scribble</cell><cell>CRB-PL (50%)</cell></row><row><cell cols="4">Consistency-loss mIoU SS/FS mIoU SS/FS</cell></row><row><cell>All points [52]</cell><cell cols="3">59.1 91.9 60.4</cell><cell>93.9</cell></row><row><cell>Partial (Ours)</cell><cell cols="3">59.3 92.2 61.3</cell><cell>95.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/jbehley/point labeler, MIT License</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: Special thanks to Zeynep Demirkol and Tim Br?dermann for their efforts during annotation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi projection fusion for real-time semantic segmentation of 3d lidar point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yara</forename><surname>Ali Alnaggar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Afifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhelw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1800" to="1809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3d-mininet: Learning a 2d representation from point clouds for fast and efficient 3d lidar semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inigo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Riazuelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Montesano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><forename type="middle">C</forename><surname>Murillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5432" to="5439" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pseudo-labeling and confirmation bias in deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantickitti: A dataset for semantic scene understanding of lidar sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Garbade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Milioto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>Sven Behnke, Cyrill Stachniss, and Jurgen Gall</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to segment medical images with scribblesupervision alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Yigit B Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">M</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ender</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">F</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baumgartner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Curriculum labeling: Revisiting pseudolabeling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Cascante-Bonilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuwen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06001</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Seminar learning for click-level weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongjun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Cai Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
		<idno>Oc- tober 2021. 2</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="6920" to="6929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sspc-net: Semi-supervised semantic 3d point cloud segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07861</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">4d spatio-temporal convnets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3075" to="3084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Salsanext: Fast, uncertainty-aware semantic segmentation of lidar point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Cortinhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tzelepis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eren</forename><forename type="middle">Erdal</forename><surname>Aksoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Visual Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="207" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi-supervised brain lesion segmentation with an adapted mean teacher model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanlin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menghao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianle</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangzhu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuyang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="554" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1635" to="1643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset. The International</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1231" to="1237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Re-distributing biased pseudo labels for semi-supervised semantic segmentation: A baseline investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6930" to="6940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11108" to="11117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Guided point contrastive learning for semi-supervised point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Structured consistency loss for semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04647,2020.4</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Kprnet: Improving projection-based lidar semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyvid</forename><surname>Kochanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Fatemeh Karimi Nejadasl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Booij</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12668</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Seed, expand and constrain: Three principles for weakly-supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="695" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scribble2label: Scribblesupervised cell segmentation via self-generating pseudolabels with consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonsoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Won-Ki</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="14" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-supervised point cloud segmentation using selftraining with label confidence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youcheng</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="237" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Amvnet: Assertion-based multi-view fusion network for lidar semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venice</forename><forename type="middle">Erin</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thi Ngoc Tho</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergi</forename><surname>Widjaja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhananjai</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang Jie</forename><surname>Chong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04934</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Weakly supervised segmentation of covid19 infection with scribble annotation on ct images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaozong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinshan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinggang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">108341</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Unbiased teacher for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wen</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09480</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pixmatch: Unsupervised domain adaptation via pixelwise consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Melas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Kyriazi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun K</forename><surname>Manrai</surname></persName>
		</author>
		<idno>2021. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="page" from="12435" to="12445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised 3d object detection from lidar point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rangenet++: Fast and accurate lidar semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Milioto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Vizzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrill</forename><surname>Stachniss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4213" to="4220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Weaklyand semi-supervised learning of a dcnn for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02734.1</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Constrained convolutional neural networks for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1796" to="1804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Deep semisupervised segmentation with weight-averaged consistency targets. In Deep learning in medical image analysis and multimodal learning for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen-Adad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="12" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Acceleration of stochastic approximation by averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoli B Juditsky</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on control and optimization</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="838" to="855" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Point-net++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02413</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scribble supervised annotation algorithms of panoptic segmentation for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Guthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyundai</forename><surname>Mobis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Ben Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS Workshop Mach. Learn. Auton. Driving</title>
		<meeting>NeurIPS Workshop Mach. Learn. Auton. Driving</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Scribblebased 3d shape segmentation via weakly-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqing</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingjun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieqing</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ladislav</forename><surname>Kavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation with mean teacher learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenfeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Conference on Intelligent Science and Big Data Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Searching efficient 3d architectures with sparse point-voxel convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename><surname>Haotian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename><surname>Zhijian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanrui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On regularized losses for weakly-supervised cnn segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schroers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="507" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01780</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6411" to="6420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Improving point cloud semantic segmentation by learning 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Unal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2950" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Changxin Gao, and Nong Sang. Self-supervised learning for semi-supervised temporal action proposal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Qing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjie</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1905" to="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1887" to="1893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4376" to="4382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="10687" to="10698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Squeeze-segv3: Spatially-adaptive convolution for efficient pointcloud segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zining</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Rpvnet: A deep and efficient range-pointvoxel fusion network for lidar point cloud segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Pu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12978</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic point cloud segmentation: Towards 10x fewer labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Sparse single sweep lidar point cloud segmentation via learning contextual shape priors from scene completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiantao</forename><surname>Xu Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03762</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Weaklysupervised teacher-student network for liver tumor segmentation from non-enhanced images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaron</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102005</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep fusionnet for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feihu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference, Glasgow</title>
		<meeting><address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="644" to="663" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIV 16</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Perturbed self-distillation: Weakly supervised large-scale point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yachao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyun</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuihua</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="15520" to="15528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Cylindrical and asymmetrical 3d convolution networks for lidar segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhou</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.10033</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Rethinking pre-training and self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06882</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
