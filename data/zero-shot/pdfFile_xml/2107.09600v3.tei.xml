<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation KEYWORDS unsupervised learning, semantic segmentation, convolutional neu- ral networks, domain adaptation ACM Reference Format</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Virtual Event</publisher>
				<availability status="unknown"><p>Copyright Virtual Event</p>
				</availability>
				<date>October 20-24, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">China</forename><forename type="middle">Jing</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Australia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">China</forename><forename type="middle">Dacheng</forename><surname>Tao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>jing.zhang1@sydney.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
							<email>zhanglefei@whu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
							<email>taodacheng@jd.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">JD Explore Academy</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation KEYWORDS unsupervised learning, semantic segmentation, convolutional neu- ral networks, domain adaptation ACM Reference Format</title>
					</analytic>
					<monogr>
						<title level="m">MM &apos;21</title>
						<imprint>
							<publisher>Virtual Event</publisher>
							<date type="published">October 20-24, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3474085.3475186</idno>
					<note>Code is available at https://github.com/GaoLii/DSP. CCS CONCEPTS ? Computing methodologies ? Computer vision problems. * This work was done during Li Gao&apos;s internship at JD Explore Academy. ? Corresponding author. 2021. DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation. In Pro-ceedings of the 29th ACM International Conference on Multimedia (MM &apos;21), October 20-24, 2021, Virtual Event, China. ACM, New York, NY, USA, 9 pages.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation (UDA) for semantic segmentation aims to adapt a segmentation model trained on the labeled source domain to the unlabeled target domain. Existing methods try to learn domain invariant features while suffering from large domain gaps that make it difficult to correctly align discrepant features, especially in the initial training phase. To address this issue, we propose a novel Dual Soft-Paste (DSP) method in this paper. Specifically, DSP selects some classes from a source domain image using a long-tail class first sampling strategy and softly pastes the corresponding image patch on both the source and target training images with a fusion weight. Technically, we adopt the mean teacher framework for domain adaptation, where the pasted source and target images go through the student network while the original target image goes through the teacher network. Output-level alignment is carried out by aligning the probability maps of the target fused image from both networks using a weighted crossentropy loss. In addition, feature-level alignment is carried out by aligning the feature maps of the source and target images from student network using a weighted maximum mean discrepancy loss. DSP facilitates the model learning domain-invariant features from the intermediate domains, leading to faster convergence and better performance. Experiments on two challenging benchmarks demonstrate the superiority of DSP over state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As one of the fundamental tasks in computer vision, semantic segmentation can be used as a preliminary step for many multimedia applications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40]</ref>, including image/video captioning, image-to-image translation, video content analysis. Training a wellperformed deep semantic segmentation model usually requires a large amount of pixel-level labeled data, which is indeed very laborious and expensive to manually annotate. Alternatively, since it is much easier to generate synthetic images with dense pixel labels, . ., via a 3D game engine, there are a lot of works focusing on training the segmentation model using synthetic labeled images. However, due to the appearance discrepancy between synthetic images and real images, which is also known as the domain shift, the model trained on synthetic images usually generalizes poorly on real images.</p><p>To address this issue, unsupervised domain adaptation (UDA) methods have been proposed to mitigate the domain shift between the source and target domains as shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>. In the context of semantic segmentation, there are three categories of methods which perform domain adaptation at different levels, such as input level <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b32">33]</ref>, feature level <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>, and output level <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14]</ref>. Inputlevel UDA methods aim to perform statistical matching at the input level to achieve uniformity in the visual appearance of the input images from different domains, . ., style transfer <ref type="bibr" target="#b12">[13]</ref>. Featurelevel UDA methods aim to align the distribution of latent features (usually embedded by CNNs) in both domains to extract domaininvariant features, . ., Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b18">[19]</ref>, adversarial learning <ref type="bibr" target="#b8">[9]</ref>. Besides, since the predicted probability maps are in low-dimension and highly structured, it is effective to perform alignment of the probability maps from different domains, . ., output-level UDA <ref type="bibr" target="#b1">[2]</ref>. Recently, the mean teacher framework <ref type="bibr" target="#b30">[31]</ref> has been used by some methods for unsupervised domain adaptive semantic segmentation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>. These kinds of UDA methods perform output-level alignment by employing the consistency constraint on the target predictions from the student model and the teacher model, respectively. Though effective, they suffer from training instability and slow convergence due to inaccurate predictions on the unlabeled target domain, especially in the initial training phase. To address this issue, DACS <ref type="bibr" target="#b32">[33]</ref> proposes to paste part of a source domain image onto the unlabeled target domain image, which leads to certain parts of the pseudo-labeled map always being injected with the ground truth semantic map, ensuring the accuracy of the target prediction. Although DACS benefits from the intermediate mixed target domain as shown in <ref type="figure" target="#fig_0">Figure 1</ref>(b), which helps to pull the target domain closer to the source domain, its performance is still limited due to the large gap between the two domains, incomplete structure, and inconsistent spatial layout issue by hard-paste, as well as the class imbalance issue.</p><p>In this paper, we go a step further and propose a novel paste method named dual soft-paste (DSP) for unsupervised domain adaptive semantic segmentation, which can create two new intermediate domains to facilitate aligning both source and target domains effectively, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Specifically, DSP adopts a long-tail class first sampling strategy to select the candidate classes from a source domain template image and paste the corresponding image patch on both the source and target training images in a soft weightedsum manner. It creates two new intermediate domains of fused images, which are used to perform domain alignment under the mean teacher framework. Technically, the pasted source and target images go through the student network while the original target image goes through the teacher network. Output-level alignment is carried out by aligning the probability maps of the fused target image from both networks using a weighted cross-entropy loss.</p><p>Feature-level alignment is also performed by aligning the feature maps of the fused source and target image from student networks using a weighted maximum mean discrepancy loss. The dual paste strategy guarantees that the same patch is shared by both domain images serving as an intermediate to bridge both domains and the soft-paste strategy preserves the original domain information by maintaining its structure layout, complete objects, as well as appearance styles. Consequently, DSP facilitates the model learning domain-invariant features from the intermediate domains, leading to faster convergence and better performance.</p><p>The contributions of this work can be summarized as follows:</p><p>? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Mean Teacher-based Methods</head><p>Since our work is built upon the mean teacher framework, we briefly review related methods in this section. For other UDA methods for semantic segmentation, such as style transfer and adversarial learning, we recommend the excellent survey <ref type="bibr" target="#b31">[32]</ref>. Mean teacher is a widely used framework in the field of semi-supervised learning, which is based on the simple idea that under the supervision of labeled data, unlabeled data should produce consistent predictions under different perturbations. It consists of two models, a student model and a teacher model, where the teacher model is an exponential moving average (EMA) of the student model. The teacher model transfers the learned knowledge to the student <ref type="bibr" target="#b30">[31]</ref> by aligning the two domains at the output level with a consistency regularization. SEANET <ref type="bibr" target="#b33">[34]</ref> firstly introduced the mean teacher framework for unsupervised domain adaptive semantic segmentation, which adopted an attention mechanism to generate attention-aware features to guide the calculation of consistency loss in the target domain. Zhou et al. <ref type="bibr" target="#b43">[44]</ref> proposed an uncertainty-aware consistency regularization method by exploiting the latent uncertainty information of the target samples. Recently, DACS <ref type="bibr" target="#b32">[33]</ref> proposed to paste source image patches onto the target domain images to create a mixed domain, where the labels of the pasted patches can be used for supervised learning and the prediction consistency between the student model and teacher model in the mean teacher framework is also exploited. Although DACS has achieved promising results, it still suffers from several problems, including the large gap between two domains, the incomplete structure and inconsistent spatial layout problem by hard-paste, as well as the class imbalance problem, resulting in limited performance. Different from DACS, we propose a novel dual soft-paste method to solve the aforementioned problems. First, our dual paste strategy can create two intermediate domains by pasting same source image patches on both the source and target images, which indeed serves as a bridge to reduce the gap between the two domains. Second, our soft-paste strategy can preserve the original domain information by keeping its structure layout, complete objects, as well as appearance styles. Third, we perform both feature-level and output-level alignment to learn domain-invariant features from the intermediate domains, leading to faster convergence and better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Copy-and-Paste Strategies</head><p>There is a wide spectrum of work to improve the performance of deep models by using copy-and-paste methods for data augmentation in the supervised training setting. For example, CutMix <ref type="bibr" target="#b37">[38]</ref> cut and pasted patches among training images where the labels are also mixed to the area of the patches. Remez et al. learned object masks by cutting-and-pasting with adversarial learning <ref type="bibr" target="#b25">[26]</ref>. However, all these methods adopted the hard-paste strategy, which loses the original layout and semantic information of the original image when creating new images. MixUp <ref type="bibr" target="#b38">[39]</ref> trained the network on convex combinations of image pairs and their labels with a mixing weight to address the aforementioned issue. Dwibedi et al. proposed to automatically cut object instances and paste them on random backgrounds to make detectors ignore these artifacts during training and generate data that gives competitive performance on real data <ref type="bibr" target="#b6">[7]</ref>. FMix <ref type="bibr" target="#b10">[11]</ref> proposed to use random binary masks obtained by applying a threshold to low frequency images sampled from fourier space. These random masks can take on a wide range of shapes and can be generated for use with one, two, and three dimensional data. In this paper, we also explore the soft-paste idea but specifically tailor it to the unsupervised domain adaptive semantic segmentation setting by handling the class imbalance issue and reducing the domain gap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Self-Training</head><p>Self-training is a widely used strategy for semi/unsupervised learning by generating pseudo labels of the unlabeled data. For the semantic segmentation task, CBST <ref type="bibr" target="#b45">[46]</ref> proposed an iterative self-training method that alternatively generated pseudo labels on target data via latent variable loss minimization and retrained the model using these labels. DAST <ref type="bibr" target="#b36">[37]</ref> presented a discriminator attention-based self-training method to adaptively improve the decision boundary of the model for the target domain. IAST <ref type="bibr" target="#b22">[23]</ref> developed a pseudo-label generation strategy, which uses an instance adaptive selector and a region-guided regularization to smooth the pseudolabel region and sharpen the non-pseudo-label region. Zheng et al. explicitly estimated the prediction uncertainty during training to rectify the pseudo label learning <ref type="bibr" target="#b42">[43]</ref>. MetaCorrection <ref type="bibr" target="#b9">[10]</ref> proposed to model the noise distribution of pseudo labels in the target domain to advance domain-aware meta learning. We also leverage the self-training idea but implement it together with the proposed DSP method under the mean teacher framework, where the target pseudo labels are generated by the teacher model, mixed with the pasted source patch labels, and updated during training. ? set of classes appearing in ; <ref type="bibr">2:</ref> ? randomly select | |/2 classes from ; <ref type="bibr">3:</ref> for each , do 4: </p><formula xml:id="formula_0">( , ) = 1,<label>( , )</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD 3.1 Preliminaries</head><p>Denoting the source domain by , it contains images and pixellevel labels , while the target domain only contains unlabeled images . The goal of UDA-based semantic segmentation is training a model on { , , } that can predict accurate semantic labels for . To this end, we proposed a novel DSP model under the mean teacher framework as illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. It has two segmentation networks, . ., a student network with learnable parameters and a teacher network ? with parameters ? calculated by the exponential moving average (EMA) of ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dual Soft-Paste</head><p>3.2.1 Long-Tail Class First Sampling. Given the images from source domain , we first calculate the frequency distribution of their classes as { 1 , 2 , ..., }, . .,</p><formula xml:id="formula_1">= =1 ,<label>(1)</label></formula><p>where represents the number of categories, indicates whether ? ? source image contains class , and denotes the total number of images in . Then, we choose the least frequent categories as the long-tail categories and record those images containing these classes as a dataset to facilitate the subsequent sampling process. In this paper, we set to 5 for the GTA5 dataset, including rider, bus, train, motorbike, bike. And = 4 for the SYNTHIA dataset, including wall, light, bus, bike. During training, we randomly choose long-tail classes and select images from , each of which contains at least one of the chosen long-tail classes. is set to 2 in this paper. A hyper-parameter study of is conducted in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.2</head><p>The Algorithm of Dual Soft-Paste. During training, we first randomly choose a source image from and select half of its classes and corresponding image patch as the candidate patch used for subsequent pasting. Then, we choose long-tail classes and candidate  images as described above. Next, we merge the candidate patch with the patches of long-tail classes to form the final candidate patch. In this way, we can guarantee that the candidate patches have both frequent classes and long-tail classes. Then, we paste this patch on a source image and target image via a soft weighted-sum manner using an opacity parameter . Specifically, given a source image , a target image , and the source template image with the corresponding binary mask , the mixed source image can be obtained by:</p><formula xml:id="formula_2">= ? + (1 ? ) ? .<label>(2)</label></formula><p>Similarly, the mixed target image can be obtained as follows:</p><formula xml:id="formula_3">= ? + (1 ? ) ? .<label>(3)</label></formula><p>For simplicity, we reuse to represent by assigning the opacity value to those positive pixels in . A hyper-parameter study of is conducted in Section 4.4, which is set to 0.8 by default. The algorithm of DSP is presented in Algorithm 1. In addition, we show a visual example of DSP in <ref type="figure" target="#fig_3">Figure 3</ref>.</p><p>It is noteworthy that DSP has the following merits: First, it creates two mixed images that share an identical source template image patch at the same location, which can serve as a bridge to effectively reduce the domain gap between both domains. Second, it preserves the original domain information by keeping its structure layout, complete objects, as well as appearance style. Third, the ground truth labels of pasted source image patches can be leveraged for output-level alignment.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mean Teacher-based Domain Adaptation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and</head><p>) are fed into the student network , while the original target image ( ) is fed into the teacher network ? . While the parameters of the student network are optimized via gradient back-propagation, the parameters ? of the teacher network at training step are updated using EMA as follows:</p><formula xml:id="formula_4">? = ? ? ?1 + (1 ? ) ? ,<label>(4)</label></formula><p>where denotes the EMA decay coefficient. After obtaining the predict semantic map of , a cross-entropy based semantic segmentation loss is used for training the network:</p><formula xml:id="formula_5">L = ? ? ?? =1 ?? =1 ? ? ? ? ,<label>(5)</label></formula><p>where , , represent the height and width of the image, and number of classes, respectively. denotes the ground truth semantic labels.</p><p>Similarly, after obtaining the predict semantic map of from , we use a weighted cross-entropy based soft semantic segmentation loss to train the network, . .,</p><formula xml:id="formula_6">L _ = ? ? ?? =1 ?? =1 ? ? ? ? ? ? ? ?? =1 ?? =1 ? ? ? ? ? (1 ? ),<label>(6)</label></formula><p>where is the ground truth semantic label of the pasted source image patch. From the teacher model ? , the pseudo label of the original target image can be obtained as?= ? ( ). Meanwhile, we can obtain the predict semantic map of from . Since these two models are assumed to produce a same prediction for a same image under different perturbations, so we adopt a prediction consistency loss to train the network, . .,</p><formula xml:id="formula_7">L = ? ? ?? =1 ?? =1 ? ? ? ? ? ? ? ?? =1 ?? =1?? ? ? ? ? (1 ? ).<label>(7)</label></formula><p>3.3.2 DSP-induced Feature-level Alignment. Since the source mixed image and target mixed image have the same pasted source image patch, the features extracted in this region from and should be as similar as possible. To this end, we adopt Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b18">[19]</ref> to learn transferable features by minimizing the MMD of their kernel embeddings. This paste-patch feature alignment loss can be formulated as:</p><formula xml:id="formula_8">L = ( ( ) ? ) ? ( ( ) ? ) 2 H ,<label>(8)</label></formula><p>where (?) denotes the kernel mean embedding, represents the feature extractor of the student model ( . ., the network before  <ref type="table">Table 2</ref>: Results of different domain adaptation methods for the SYNTHIA ? Cityscapes task. mIoU* denotes the mean IoU of 13 classes, excluding the classes marked by the asterisk.</p><p>the ASPP module), and H denotes the reproducing kernel Hilbert space (RKHS). Note that since the pasted patches in and have different context of source and target domain information, which may be embedded in the extracted features, the paste-patch alignment loss can reduce the domain gap implicitly.</p><p>In addition, we try to minimize the MMD of the image features of and to align the feature distributions of both domains. This global feature alignment loss is:</p><formula xml:id="formula_9">L = ( ( )) ? ( ( )) 2 H .<label>(9)</label></formula><p>An illustration of these two losses is shown in <ref type="figure" target="#fig_4">Figure 4</ref>. The overall training objective can be defined as:</p><formula xml:id="formula_10">L = L + L _ + L + (L + L ),<label>(10)</label></formula><p>where is a hyper-parameter to balance different losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Datasets and Evaluation Metrics</head><p>We evaluate the performance of the proposed method for two challenging UDA tasks: GTA5 <ref type="bibr" target="#b26">[27]</ref> to Cityscapes <ref type="bibr" target="#b4">[5]</ref> and SYNTHIA <ref type="bibr" target="#b27">[28]</ref> to Cityscapes. GTA5 is a synthetic dataset created using a photo-realistic open-world computer game engine. Dense pixellevel semantic annotations are provided for 24,966 urban landscape images with a resolution of 1, 914 ? 1, 052. 19 common classes in the Cityscapes dataset are chosen in our experiments. SYNTHIA is another synthetic collection of 9,400 diverse urban images with a resolution of 1, 280 ? 760. We consider 16 common categories in the Cityscapes dataset for evaluation while the results on 13 common classes are also reported following a common practice. Cityscapes is a large-scale real-world urban scenes benchmark for semantic segmentation, which provides 5,000 densely annotated images with a resolution of 2, 048 ? 1, 024. We use 2,975 unlabeled training images during training and 500 validation images for testing. In all experiments, we use the mIoU metric for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>The proposed model is implemented using PyTorch on a single NVIDIA Tesla V100 GPU with 16 GB memory. Following previous work, we adopt ResNet-101 <ref type="bibr" target="#b11">[12]</ref> pre-trained on ImageNet <ref type="bibr" target="#b5">[6]</ref> and on MSCOCO <ref type="bibr" target="#b17">[18]</ref> as the backbone network to extract features, and ASPP [1] is adopted to be the classifier to predict semantic maps. We use Stochastic Gradient Descent (SGD) with Nesterov acceleration as the optimizer, an initial learning rate of 2.5 ? 10 ?3 for the feature extractor, and an initial learning rate of 2.5 ? 10 ?4 for the classifier, which are then decreased based on a polynomial decay policy with an exponent of 0.9. Weight decay is set to 5?10 ?4 and momentum is set to 0.9. During training, we resize images in Cityscapes, GTA5, and SYNTHIA to 1, 024 ? 512, 1, 280 ? 720, and 1, 280?760, respectively, after which the input images are randomly cropped into patches with a size of 512 ? 512. We also apply color jittering and Gaussian blurring for data augmentation. The model is trained for a total of 250,000 iterations with a batch size of 2. We set to 0.005, the EMA decay coefficient to 0.99, opacity to 0.8, and the number of long-tail classes selected at each training iteration to 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with State-of-the-art Methods</head><p>In this section, we evaluate our DSP model on the two challenging UDA semantic segmentation tasks and compare it with several state-of-the-art methods. <ref type="table" target="#tab_1">Table 1</ref> shows the results of different methods for the GTA5 to Cityscapes task over 19 common classes. Our DSP model achieves the best mIoU score of 55.0%, significantly outperforming stateof-the-art methods by large margins from 2.8% to 11.4%. Besides, our method shows its effectiveness in predicting long-tail classes, Moreover, DSP outperforms the source-only segmentation model by 18.4% mIoU, showing a good cross-domain generalization ability. As for another SYNTHIA to Cityscapes task, we report the mIoU results of both 13 and 16 classes in <ref type="table">Table 2</ref>. As can be seen, DSP achieves the best performance in terms of mIoU of 16 and 13 classes, . ., 51.0% mIoU and 59.9% mIoU*, respectively. It also outperforms all existing methods, and achieves a significant improvement over the source-only model by 17.5% and 21.3 % over 16 and 13 classes in terms of mIoU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Analysis and Ablation Study</head><p>To investigate the impact of different components in our DSP model, we conduct an ablation study on the GTA5 to Cityscapes setting as shown in <ref type="table">Table 3</ref>. "Source Only" denotes the model without domain adaptation. "Mean Teacher" (MT) denotes the vanilla mean teacher framework. "Single Paste" denotes the pasting strategy proposed in DACS <ref type="bibr" target="#b32">[33]</ref> that only pasting source image patches to the target domain images. "Dual Paste" denotes the dual paste strategy based on hard-paste while "Dual Soft-Paste" denotes the proposed dual paste strategy based on soft-paste. "Feature Alignment" denotes the DSP-induced feature-level alignment. As can be seen, the source only model obtains 36.6 mIoU on the target domain. After using the mean teacher framework, a gain of 5.7% mIoU can be observed. The single paste strategy (DACS) brings another 9.8% mIoU improvement, 15.5% mIoU in total. By contrast, our dual soft-paste strategy achieves a gain of 17.9% mIoU over the source only baseline model. Compared with hard-paste, the proposed soft-paste strategy is more effective. After using the proposed DSP-induced feature-level alignment, our DSP model improves the baseline model by a significant margin, . ., 18.4% mIoU.</p><p>The training losses and mIoU results of DACS <ref type="bibr" target="#b32">[33]</ref>, . ., single hard-paste, Dual Hard-Paste (a variant of the proposed DSP based on hard-paste), and the proposed DSP on the GTA5 to Cityscapes setting are plotted in <ref type="figure" target="#fig_5">Figure 5</ref>. In the early training phase, DACS suffers from the large domain gap and may produce incorrect predictions, especially for those long-tail classes. Consequently, these incorrect predictions may mislead the adaptation process, leading to a slow convergence speed and limited performance. By contrast, our model adopts a dual soft-paste strategy and a long-tail class first sampling strategy to create intermediate domains having smaller domain gaps, thereby facilitating the domain adaptation. In addition, it can be seen that the dual paste strategy contributes to the faster convergence speed while the soft-paste strategy matters for better cross-domain generalization performance.  <ref type="table">Table 3</ref>: Ablation study of the proposed DSP model. <ref type="table">Table 4</ref> shows the results of different hyper-parameter settings of the opacity . When = 0.8, the model achieves the best performance, . ., 55.0% mIoU. When = 0, the model is the vanilla mean teacher model, which only obtains 42.3% mIoU. And when = 1, the model becomes the mean teacher model using the dual hardpaste strategy, obtaining a better mIoU of 53.6%. Besides, when is less than 0.7, the weight of the pasted source image patch is too small, which may result in inaccurate predictions of target images, especially in the early training phase, thereby affecting the final performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GTAV ? Cityscapes</head><p>GTAV ? Cityscapes 0 0.5 0.6 0.7 0.8 0.9 1 mIoU 42.3 51.0 52.2 54.5 55.0 54.9 53.6 <ref type="table">Table 4</ref>: Hyper-parameter study of opacity .  <ref type="figure">Figure 6</ref>: Some visual segmentation results for the GTA5 to Cityscapes task. <ref type="table">Table 5</ref> shows the results of using different numbers of longtailed classes during pasting. As can be seen, the performance peaks at = 2. When = 0, the performance drops by a margin of 1.8% mIoU, implying the proposed long-tail class first sampling strategy matters for mitigating the class imbalance issue. Besides, when becomes larger, the sampled patches from different images may overlap each other and also result in inconsistent spatial layouts in the pasted patch, which will affect the performance.</p><p>GTAV ? Cityscapes long-tail classes to choose 0 1 2 3 mIoU 53.2 54.3 55.0 53.7 <ref type="table">Table 5</ref>: Hyper-parameter study of the number of longtailed classes .</p><p>In <ref type="figure">Figure 6</ref>, we present some visual segmentation results of the source only model and our DSP model. As can be seen, the source only model has limited cross-domain generalization ability without any domain adaptation. There are large areas of incorrect predictions, such as road and trees. By contrast, our DSP model shows a fairly good cross-domain generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we investigate the unsupervised domain adaptive semantic segmentation problem from the perspective of image manipulation. Specifically, we propose a novel Dual Soft-Paste (DSP) method to create new intermediate domains with smaller domain gaps. Based on the mean teacher framework, DSP-induced outputlevel alignment and feature-level alignment are performed, which help to learn domain-invariant features. Besides, the long-tail class first sampling strategy used in DSP shows its effectiveness in addressing the class-imbalance issue. Experiments on two challenging benchmarks demonstrate the superiority of DSP over state-of-theart methods. In the future, we plan to investigate the impact of DSP in other domain adaptation frameworks as well as develop an adaptive sampling strategy using reinforcement learning, which can actively sample both normal and long-tail classes during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">ACKNOWLEDGMENTS</head><p>This work was supported by the Science and Technology Major Project of Hubei Province (Next-Generation AI Technologies) under Grant 2019AEA170 and the Fundamental Research Funds for the Central Universities under Grant 2042021kf0196. The numerical calculations in this paper had been supported by the supercomputing system in the Supercomputing Center of Wuhan University.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of different domain alignment paradigms. (a) Alignment on the original domains. (b) Alignment on the source domain and a mixed target domain, . ., DACS [33]. (c) The proposed alignment method on two intermediate mixed domains by DSP. "SMD" and "TMD" refer to the source-mixed domain and target-mixed domain obtained by pasting source domain patches on the source and target domain images, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Overview of the proposed DSP model based on the mean teacher framework. The source image, source mixed image, and target mixed image are fed into the student network, while the target image is fed into the teacher network. DSP-induced output-level alignment and feature-level alignment are used to perform domain adaptation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Source Soft Mixed Image (f) Target Soft Mixed Image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Visual demonstration of the DSP algorithm. Note that we show the binary DSP mask instead of the soft one by integrating the opacity for better illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of DSP-induced feature alignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Convergence analysis of DACS [33], Dual Hard-Paste (a variant of the proposed DSP based on hard-paste), and the proposed DSP on the GTA5 to Cityscapes setting. (a) Training losses. (b) mIoU results. DSP converges faster, . ., achieving better performance in the same training steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1</head><label>1</label><figDesc>The proposed dual soft-paste algorithm Input: Source template image and its label , source image , target image , pre-defined long-tail dataset , opacity ; Output: The DSP mask , mixed source image</figDesc><table><row><cell></cell><cell>, mixed target</cell></row><row><cell>image</cell><cell>;</cell></row><row><cell>1:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Mixed Image Target Mixed Image Global Feature Alignment Pasting-Patch Feature Alignment</head><label></label><figDesc>16.8 77.2 12.5 21.0 25.5 30.1 20.1 81.3 24.6 70.3 53.8 26.4 49.9 17.2 25.9 6.5 25.3 36.0 36.6 WeakSeg(ECCV20)[25] 91.6 47.4 84.0 30.4 28.3 31.4 37.4 35.4 83.9 38.3 83.9 61.2 28.2 83.7 28.8 41.3 8.8 24.7 46.4 48.2 LSE(ECCV20)[30] 90.2 40.0 83.5 31.9 26.4 32.6 38.7 37.5 81.0 34.2 84.6 61.6 33.4 82.5 32.8 45.9 6.7 29.1 30.6 47.5 IAST(ECCV20)[23] 94.1 58.8 85.4 39.7 29.2 25.1 43.1 34.2 84.8 34.6 88.7 62.7 30.3 87.6 42.3 50.3 24.7 35.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">GTA5 ? Cityscapes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>light</cell><cell>sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>trunk</cell><cell>bus</cell><cell>train</cell><cell>motorbike</cell><cell>bike</cell><cell>mIoU</cell></row><row><cell>Source Only</cell><cell cols="19">75.8 2 40.2</cell><cell>52.2</cell></row><row><cell>CrCDA(ECCV20)[15]</cell><cell cols="19">92.4 55.3 82.3 31.2 29.1 32.5 33.2 35.6 83.5 34.8 84.2 58.9 32.2 84.7 40.6 46.1 2.1 31.1 32.7</cell><cell>48.6</cell></row><row><cell>LTIR(CVPR20)[16]</cell><cell cols="19">92.9 55.0 85.3 34.2 31.1 34.9 40.7 34.0 85.2 40.1 87.1 61.0 31.1 82.5 32.3 42.9 0.3 36.4 46.1</cell><cell>50.2</cell></row><row><cell>UIDA(CVPR20)[24]</cell><cell cols="19">90.6 37.1 82.6 30.1 19.1 29.5 32.4 20.6 85.7 40.5 79.7 58.7 31.1 86.3 31.5 48.3 0.0 30.2 35.8</cell><cell>46.3</cell></row><row><cell>PIT(CVPR20)[22]</cell><cell cols="19">87.5 43.4 78.8 31.2 30.2 36.3 39.9 42.0 79.2 37.1 79.3 65.4 37.5 83.2 46.0 45.6 25.7 23.5 49.9</cell><cell>50.6</cell></row><row><cell>STAR(CVPR20)[20]</cell><cell cols="19">88.4 27.9 80.8 27.3 25.6 26.9 31.6 20.8 83.5 34.1 76.6 60.5 27.2 84.2 32.9 38.2 1.0 30.2 31.2</cell><cell>43.6</cell></row><row><cell>ASA(TIP21)[45]</cell><cell cols="19">89.2 27.8 81.3 25.3 22.7 28.7 36.5 19.6 83.8 31.4 77.1 59.2 29.8 84.3 33.2 45.6 16.9 34.5 30.8</cell><cell>45.1</cell></row><row><cell>CLAN(TPAMI21)[21]</cell><cell cols="19">88.7 35.5 80.3 27.5 25.0 29.3 36.4 28.1 84.5 37.0 76.6 58.4 29.7 81.2 38.8 40.9 5.6 32.9 28.8</cell><cell>45.5</cell></row><row><cell>DACS(WACV21)[33]</cell><cell cols="19">89.9 39.7 87.9 39.7 39.5 38.5 46.4 52.8 88.0 44.0 88.8 67.2 35.8 84.5 45.7 50.2 0.0 27.3 34.0</cell><cell>52.1</cell></row><row><cell>RPLL(IJCV21)[43]</cell><cell cols="19">90.4 31.2 85.1 36.9 25.6 37.5 48.8 48.5 85.3 34.8 81.1 64.4 36.8 86.3 34.9 52.2 1.7 29.0 44.6</cell><cell>50.3</cell></row><row><cell>DAST(AAAI21)[37]</cell><cell cols="19">92.2 49.0 84.3 36.5 28.9 33.9 38.8 28.4 84.9 41.6 83.2 60.0 28.7 87.2 45.0 45.3 7.4 33.8 32.8</cell><cell>49.6</cell></row><row><cell>ConTrans(AAAI21)[17]</cell><cell cols="19">95.3 65.1 84.6 33.2 23.7 32.8 32.7 36.9 86.0 41.0 85.6 56.1 25.9 86.3 34.5 39.1 11.5 28.3 43.0</cell><cell>49.6</cell></row><row><cell>CIRN(AAAI21)[8]</cell><cell cols="19">91.5 48.7 85.2 33.1 26.0 32.3 33.8 34.6 85.1 43.6 86.9 62.2 28.5 84.6 37.9 47.6 0.0 35.0 36.0</cell><cell>49.1</cell></row><row><cell cols="20">MetaCorrect(CVPR21)[10] 92.8 58.1 86.2 39.7 33.1 36.3 42.0 38.6 85.5 37.8 87.6 62.8 31.7 84.8 35.7 50.3 2.0 36.8 48.0</cell><cell>52.1</cell></row><row><cell>ESL(CVPR21)[29]</cell><cell cols="19">90.2 43.9 84.7 35.9 28.5 31.2 37.9 34.0 84.5 42.2 83.9 59.0 32.2 81.8 36.7 49.4 1.8 30.6 34.1</cell><cell>48.6</cell></row><row><cell>Our DSP</cell><cell cols="20">92.4 48.0 87.4 33.4 35.1 36.4 41.6 46.0 87.7 43.2 89.8 66.6 32.1 89.9 57.0 56.1 0.0 44.1 57.8 55.0</cell></row><row><cell>Source</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>3.3.1 DSP-induced Output-level Alignment. During training, the original source image ( ), the mixed source and target image (Table 1: Results of different domain adaptation methods for the GTA5 ? Cityscapes task.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Crdoco: Pixel-Level Domain Transfer with Cross-Domain Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen</forename><forename type="middle">Yu</forename><surname>Yun Chun Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">Hsuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1791" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Progressive lidar adaptation for road detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA Journal of Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="693" to="702" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Self-Ensembling with GAN-Based Data Augmentation for Domain Adaptation in Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taekyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changick</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6829" to="6839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Cityscapes Dataset for Semantic Urban Scene Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Im-ageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debidatta</forename><surname>Dwibedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1301" to="1310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Addressing Domain Gap via Content Invariant Representation for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7528" to="7536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2661</idno>
		<title level="m">Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">MetaCorrection : Domain-Aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baopu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Understanding and Enhancing Mixed Sample Data Augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Painter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesan</forename><surname>Niranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Pr?gel-Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12047</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02649</idno>
		<title level="m">FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contextual-Relation Consistent Domain Adaptation for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="705" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning Texture Invariant Representation for Domain Adaptation of Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12972" to="12981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhyuk</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongje</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Euntai</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning Transferable Features with Deep Adaptation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stochastic Classifiers for Unsupervised Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihe</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><forename type="middle">Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9108" to="9117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Category-Level Adversarial Adaptation for Semantic Segmentation using Purified Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2021" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cross-Domain Semantic Segmentation via Domain-Invariant Interactive Relation Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4333" to="4342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Instance Adaptive Self-Training for Unsupervised Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="415" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised Intra-Domain Adaptation for Semantic Segmentation through Self-Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Rameau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3763" to="3772" />
		</imprint>
	</monogr>
	<note>Seokju Lee, and In So Kweon</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain Adaptive Semantic Segmentation Using Weak Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujoy</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><forename type="middle">Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="571" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to Segment via Cut-and-Paste</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Playing for Data: Ground Truth from Computer Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3234" to="3243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ESL: Entropy-Guided Self-Supervised Learning for Domain Adaptation in Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Saporta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Patrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning from Scale-Invariant Examples for Domain Adaptation in Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naseer</forename><surname>Subhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="290" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mean Teachers are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-supervised Deep Learning Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>eeding of the Advances in Neural Information essing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1196" to="1205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Maracani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umberto</forename><surname>Michieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Zanuttigh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10876</idno>
		<title level="m">Unsupervised Domain Adaptation in Semantic Segmentation: A Review</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DACS: Domain Adaptation via Cross-Domain Mixed Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1379" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Self-Ensembling Attention Networks: Addressing Domain Shift for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoli</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 33th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5581" to="5588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03348</idno>
		<title level="m">Vision Transformer Advanced by Exploring Intrinsic Inductive Bias</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TextFuseNet: Scene Text Detection with Richer Fused Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="516" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DAST : Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10754" to="10762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412v2</idno>
		<title level="m">Mixup: Beyond Empirical Risk Minimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="7789" to="7817" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Category Anchor-Guided Unsupervised Domain Adaptation for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems (NIPS</title>
		<meeting>the Advances in Neural Information Processing Systems (NIPS</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rectifying Pseudo Label Learning via Uncertainty Estimation for Domain Adaptive Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="1106" to="1120" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08878v3</idno>
		<title level="m">Uncertainty-Aware Consistency Regularization for Cross-Domain Semantic Segmentation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Affinity Space Adaptation for Semantic Segmentation Across Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajia</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiehua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2549" to="2561" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B V K Vijaya</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="289" to="305" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
