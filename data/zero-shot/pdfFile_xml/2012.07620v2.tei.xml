<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Image Retrieval Re-Ranking: A Graph Neural Network Perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanmeng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ReLER</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyue</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ReLER</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Tan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ReLER</orgName>
								<orgName type="institution" key="instit2">University of Technology Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding Image Retrieval Re-Ranking: A Graph Neural Network Perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The re-ranking approach leverages high-confidence retrieved samples to refine retrieval results, which have been widely adopted as a post-processing tool for image retrieval tasks. However, we notice one main flaw of re-ranking, i.e., high computational complexity, which leads to an unaffordable time cost for real-world applications. In this paper, we revisit re-ranking and demonstrate that re-ranking can be reformulated as a high-parallelism Graph Neural Network (GNN) function. In particular, we divide the conventional re-ranking process into two phases, i.e., retrieving high-quality gallery samples and updating features. We argue that the first phase equals building the k-nearest neighbor graph, while the second phase can be viewed as spreading the message within the graph. In practice, GNN only needs to concern vertices with the connected edges. Since the graph is sparse, we can efficiently update the vertex features. On the Market-1501 dataset, we accelerate the re-ranking processing from 89.2s to 9.4ms with one K40m GPU, facilitating the real-time post-processing. Similarly, we observe that our method achieves comparable or even better retrieval results on the other four image retrieval benchmarks, i.e., VeRi-776, Oxford-5k, Paris-6k and University-1652, with limited time cost. Our code is publicly available. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Re-ranking leverages high-confidence retrieved samples to rank the initial retrieval result again <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28]</ref>, which is usually viewed as a post-processing tool. It has been widely adopted in various of image retrieval tasks, such as person re-identification <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b50">51]</ref>, vehicle re-identification <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b47">48]</ref> and localization <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b48">49]</ref>. Re-ranking methods can be divided into two categories according to similarity criteria, i.e., feature similarity <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29]</ref> and neighbor similar-1 https://github.com/Xuanmeng-Zhang/gnn-re-ranking ity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b51">52]</ref>. Given a pair of images, feature similarity is evaluated based on the Euclidean distance in the feature space. In contrast, neighbor similarity measures the number of common neighbors. For instance, if two samples share more neighbors, they will obtain a higher neighbor similarity value. Generally, the neighbor-based methods outperform the feature-based methods. It is because the neighborbased method is robust to the hard negative ("outliers"), which usually shares one different neighbor set with the true-matches. Considering the robustness to false-matches, we mainly study the neighbor-based re-ranking methods. However, one challenging problem remains. Despite the effectiveness of neighbor-based algorithms, high computation complexity makes this line of approaches unaffordable for real-world applications. For instance, the k-reciprocal re-ranking method <ref type="bibr" target="#b51">[52]</ref> adopts a reciprocal-neighbor rule, which demands the consideration of the neighbors' neighbor and introduces extra computations.</p><p>To address the problem of unaffordable high complexity, we consider the feasibility of the parallel inference. In this paper, inspired by the effectiveness and efficiency of graph neural network (GNN) with the structured data, we argue that the re-ranking methods can be reformulated as a highparallelism GNN function <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b3">4]</ref> to efficiently conduct the re-ranking operation, e.g., neighbor calculation and query expansion. Graph neural network (GNN) draws wide attention in the last few years <ref type="bibr" target="#b31">[32]</ref>. The increasing interest is due to two main factors: the dominance of data with topology structures in real-world applications, and the limited performance of convolutional neural network (CNN) when dealing with such data. Different from the convolution operation of CNN that computation can only take place within local regions, the GNN propagates the features of nodes and edges over the entire graph.</p><p>In particular, the re-ranking process can be divided into two phases, i.e., retrieving high-confidence gallery samples and updating features. In the first phase, the conventional re-ranking is to find the high-confidence samples according to the similarity score. For the second phase, the high-confidence samples, e.g., k-nearest neighbors, are leveraged to conduct the query expansion by aggregating the feature of these samples. Following the spirit of conventional reranking, our work first builds the k-nearest neighbors (k-NN) graph, capturing the topology structure among data. Secondly, we employ the GNN to propagate the message among the whole graph. GNN only needs to update vertices with the connected edges. Due to the sparseness of the k-NN graph, we can efficiently update the vertex features. On the Market-1501 dataset <ref type="bibr" target="#b46">[47]</ref>, we accelerate the re-ranking processing from 89.2s to 9.4ms on GPU, facilitating the real-time post-processing for image retrieval tasks. Furthermore, we observe similar acceleration results on other benchmarks while maintaining competitive performance. Overall, the main contributions of this work are summarized as follows:</p><p>1. We identify the challenging problem, i.e., large time cost due to high computation complexity, in applying the re-ranking approaches to the real-world scenarios. To address this limitation, we revisit re-ranking methods and demonstrate that the re-ranking process can be re-formulated as high-parallelism Graph Neural Network (GNN), which facilitates the real-time postprocessing for image retrieval tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Extensive experiments on five datasets, i.e., Market-1501 <ref type="bibr" target="#b46">[47]</ref>, VeRi-776 <ref type="bibr" target="#b20">[21]</ref>, Oxford-5k <ref type="bibr" target="#b25">[26]</ref>, Paris-6k <ref type="bibr" target="#b26">[27]</ref> and University-1652 <ref type="bibr" target="#b48">[49]</ref>, show the proposed method can significantly accelerate the re-ranking process, while achieving competitive re-ranking results with other conventional re-ranking methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Re-ranking for Image Retrieval</head><p>The re-ranking method is one of the common postprocessing methods for image retrieval, which can be divided into two categories according to similarity criteria, i.e., feature similarity and neighbor similarity. By taking the nearest samples with similar features into consideration, feature similarity-based methods enrich the query feature by aggregating the features of neighbors. The average query expansion(AQE) <ref type="bibr" target="#b5">[6]</ref> directly averages the top-k similar gallery features as the new query feature. Radenovic et al. <ref type="bibr" target="#b28">[29]</ref> propose ?-weighted query expansion, which assigns different weights to the gallery samples. Lin et al. <ref type="bibr" target="#b17">[18]</ref> propose a Bayesian model to predict true matches in the gallery. In contrast, several researchers resort to mine the robust neighbor information to improve the accuracy of image retrieval <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b38">39]</ref>. Sparse contextual activation (SCA) <ref type="bibr" target="#b0">[1]</ref> is proposed to encode the local contextual distribution of images under the generalized Jaccard metric. <ref type="bibr" target="#b51">[52]</ref> design an effective k-reciprocal re-ranking method, which inherits the advantages of k-reciprocal nearest neighbors <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref> and SCA <ref type="bibr" target="#b0">[1]</ref>. Besides, another line of approaches needs extra annotations. Some of these algorithms require human interaction <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19]</ref> or label supervision <ref type="bibr" target="#b1">[2]</ref>. Furthermore, several methods are based on the ensemble of different ranking metrics to refine the final list. For instance, multiple distance measure fusion <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref>, rank aggregation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b23">24]</ref> and ranking list comparison <ref type="bibr" target="#b41">[42]</ref> also have achieved great success in the retrieval tasks. In general, most re-ranking algorithms pay attention to the ranking performance but neglect the computation efficiency for real-world applications. Different from existing methods, we mainly study the efficiency of re-ranking approaches and intend to simultaneously achieve competitive performance and high computation efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Graph Neural Networks</head><p>Graph Neural Networks (GNNs) are introduced by <ref type="bibr" target="#b9">[10]</ref> to study the structured data. Gori et al. <ref type="bibr" target="#b9">[10]</ref> extend GNNs from recursive neural networks (RNNs) to process graphs without losing topological information. There are two kinds of graph constructions <ref type="bibr" target="#b3">[4]</ref>, one based upon a hierarchical clustering of the domain, and the other based on the spectrum of the graph Laplacian. Kipf et al. <ref type="bibr" target="#b14">[15]</ref> propose to encode the graph structure and features of nodes directly by a Graph Convolutional Network (GCN). Gilmer et al. <ref type="bibr" target="#b8">[9]</ref> reformulate several existing graph models as a single common framework: Message Passing Neural Networks (MPNNs). Other graph models, such as Graph Attention Network(GAT) <ref type="bibr" target="#b36">[37]</ref>, EdgeConv <ref type="bibr" target="#b39">[40]</ref> and Graph-SAGE <ref type="bibr" target="#b10">[11]</ref>, are proposed to tackle the graph tasks. In recent years, GNNs are also applied to many computer vision fields, including face clustering <ref type="bibr" target="#b40">[41]</ref>, 3D person reidentification <ref type="bibr" target="#b49">[50]</ref> and point cloud classification <ref type="bibr" target="#b39">[40]</ref>. Some researchers have also applied graph models to the image retrieval tasks. For instance, similarity-Guided graph neural network (SGGNN) <ref type="bibr" target="#b34">[35]</ref> is proposed to obtain similarity estimations and refine feature representations by incorporating graph computation in both training and testing stages. The group shuffling random walk (GSRW) layer <ref type="bibr" target="#b33">[34]</ref> is integrated into deep neural networks for fully utilizing the affinity information between gallery images. Spectral feature transformation (SFT) <ref type="bibr" target="#b21">[22]</ref> incorporates spectral clustering technique into existing convolutional neural network (CNN) pipeline. To exploit the training data into the learning process, these graph-based methods integrate GNN into both the training and testing processes to utilize the relations between nodes. However, their performance is not as good as traditional re-ranking algorithms. The major limitation lies in the graph is build on a small set of data points, which discards massive contextual information in the total dataset. Therefore, the messages propagated by GNN are restricted in the local region and unable to make use of global information. Different from existing methods, we propose a GNN-based re-ranking method building on the entire dataset, capturing the topology structure of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>Problem Definition. Given a query image q and a gallery set with n g images G = {g i |i = 1, 2, ..., n g }, content-based image retrieval is to find relevant images among a large number of candidate images. Generally, we map images to a semantic feature space and sort gallery images according to the feature similarity with the query feature. The re-ranking approach is to further refine the initial retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Conventional Re-Ranking</head><p>Re-ranking methods usually depend on additional criteria, such as neighbor similarity, to leverage the extra information between images. For example, <ref type="bibr" target="#b51">[52]</ref> employ kreciprocal nearest neighbors to re-rank samples, which pull the relevant samples closer to each other. In this section, we briefly review this typical neighbor-based re-ranking method, which consists of two main steps. In the first step, it encodes the weighted k-reciprocal neighbor set into a kreciprocal feature. In the second step, the k-reciprocal feature is improved by the local query expansion, fusing feature representation of neighbor samples. The final distance is calculated as the weighted sum of the original distance and the Jaccard distance. Construction of k-reciprocal Neighbors. We define N (q, k) as the k-nearest neighbors (top-k samples in the initial ranking list) of the query image q. R(q, k) is denoted as the k-reciprocal nearest neighbors of q in the gallery, which can be formulated as:</p><formula xml:id="formula_0">R(q, k) = {g i |(g i ? N (q, k)) ? (q ? N (g i , k))}. (1)</formula><p>R(q, k) explicitly considers the neighbor of the nearest samples, enabling the cross-check of neighbor relations. Therefore, the k-reciprocal nearest neighbors can effectively reduce the noisy false-matches in the high-confidence candidates. To avoid the ambiguity, here we denote the number of the nearest neighbor for k-reciprocal calculation as k 1 . Considering the severe visual appearance changes due to the pose and the occlusion, <ref type="bibr" target="#b51">[52]</ref> further introduce a refined expansion set R * (q, k 1 ) by adding the 1 2 k 1 -reciprocal nearest neighbors of each candidate in R(q, k 1 ) as:</p><formula xml:id="formula_1">R * (q, k 1 ) ? R(q, k 1 ) ? R(g, 1 2 k 1 ) s.t.|R(q, k 1 ) ? R(g, 1 2 k 1 )| ? 2 3 |R(g, 1 2 k 1 )| ?g ? R(q, k 1 ),<label>(2)</label></formula><p>where |?| denotes the number of candidates in the set. Given the refined nearest neighbor set R * (q, k 1 ), the neighbor information can be encoded as one k-reciprocal feature vector F q = [F q,g1 , F q,g2 , ..., F q,gn g ], where:</p><formula xml:id="formula_2">F q,gi = exp(?d(q, g i )) if g i ? R * (q, k 1 ) 0 otherwise ,<label>(3)</label></formula><p>and d(q, g i ) represents the Mahalanobis distance <ref type="bibr" target="#b6">[7]</ref> between query image q and gallery image g i . Different neighbors are treated distinctively based on neighbor relations and original pairwise similarities. Local Query Expansion. Now we obtain the k-reciprocal feature vector for every image. We could apply the local query expansion <ref type="bibr" target="#b5">[6]</ref> to further aggregate the similar features within N (q, k 2 ). It is worth noting that k 2 is different from k 1 . k 2 represents the number of the nearest k-reciprocal feature neighbors for expansion. The final feature after the local query expansion can be formulated as:</p><formula xml:id="formula_3">F q = 1 k 2 gi?N (q,k2) F gi .<label>(4)</label></formula><p>We note that each neighbor is treated equally during aggregating process. After the expansion of k-reciprocal feature, the general Jaccard distance is defined as:</p><formula xml:id="formula_4">d J (q, g i ) = 1 ? ng n j=1 min(F q,gj , F gi,gj ) ng n j=1 max(F q,gj , F gi,gj ) .<label>(5)</label></formula><p>Finally, distance d * combines the original distance and Jaccard distance to revise the initial ranking list:</p><formula xml:id="formula_5">d * (q, g i ) = (1 ? ?)d J (q, g i ) + ?d(q, g i ),<label>(6)</label></formula><p>where ? ? [0, 1] denotes the penalty factor. The refined final distance is subsequently used to acquire the re-ranking list. The k-reciprocal re-ranking significantly improves the mean average precision (mAP). It becomes a common post-processing component in image retrieval tasks. However, the k-reciprocal re-ranking is time-consuming since the massive set comparison operations in Eq. 2 are required to expand k-reciprocal neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">GNN-based Re-Ranking</head><p>In this section, we introduce the GNN-based re-ranking, which reduces the large time cost of complicated operations in conventional re-ranking methods. The key idea is that the similarity between images can be represented as a relation graph. Set comparison operations can be replaced by building a simple but discriminative graph, while features can be updated by the message propagation in GNN. The proposed approach consists of the following two stages. In the first  <ref type="figure">Figure 1</ref>. The pipeline of our approach. In the first phase (left), we build the k-NN graph, capturing the topology structure among data. For the second phase (right), we employ the GNN to aggregate features from high-confidence samples (nodes inside the dotted circle). The colored nodes represent the aggregated features.</p><p>stage, based on the entire image group (query images and gallery images), we construct a graph and encode local information in edges. In the second stage, the proposed GNN propagates messages by aggregating neighbor features with edge weights. The re-ranked retrieval list can be calculated by comparing the similarity of refined node features. The pipeline of our approach is shown in <ref type="figure">Figure 1</ref>.</p><p>Construction of Graph. Formally, we denote X q , X g and X u as original features of query set, gallery set and the union of query and gallery set, respectively. There are n images in query and gallery set in total. Let G = (V, E) denote the graph where V = {v 1 , ..., v n } are the vertices and E ? V ? V are the edges. Each image is a vertex on the graph and connected edges represent the similarity between vertices. First of all, cosine similarity matrix S is calculated:</p><formula xml:id="formula_6">S ij = cos(x i , x j ), where x i , x j ? X u , X u = X q ? X g .<label>(7)</label></formula><p>Secondly, the features of neighbor relations are calculated.</p><p>In k-reciprocal re-ranking, <ref type="bibr" target="#b51">[52]</ref> encode k-reciprocal feature by selecting candidates from a expansion of k-reciprocal neighbors. Masses of set intersection and comparison operations are required when selecting candidates, leading to huge time cost. We overcome this drawback by adopting a simple but effective strategy to obtain the contextual information of the whole image group. Corresponding to the k-reciprocal feature in re-ranking, we aim to encode node features by extracting neighbor information from S on the entire graph. Specifically, we first define the adjacent matrix A as</p><formula xml:id="formula_7">A i,j = 1 if j ? N (i, k 1 ) 0 otherwise ,<label>(8)</label></formula><p>where N (i, k 1 ) is the k 1 most similar candidates according to similarity matrix S. Generally, an ideal adjacent matrix should be symmetric. Further, the symmetric adjacent matrix A * is introduced as:</p><formula xml:id="formula_8">A * = A + A T 2 .<label>(9)</label></formula><p>The value of A * ij is derived as:</p><formula xml:id="formula_9">A * i,j = ? ? ? ? ? 1 if j ? N (i, k 1 ) ? i ? N (j, k 1 ) 0 if j / ? N (i, k 1 ) ? i / ? N (j, k 1 ) 0.5 otherwise .<label>(10)</label></formula><p>We note that A * encodes more adjacent information. It is because more neighbors are included and adaptive weights are assigned to high-confidence candidates. The experimental results in ablation study also show A * performs better than A. More importantly, due to the simplicity, symmetry and sparsity of A * , the calculation process can be highly parallelizable and efficient.</p><p>Here we define h i as the feature of vertex v i , which can be extracted from the i-th row of the symmetric adjacent matrix A * :</p><formula xml:id="formula_10">h i = [A * i,0 , ..., A * i,n ].<label>(11)</label></formula><p>Such neighbor encoding feature performs better than the original feature because the hard negative images usually share one different neighbor set with the true-matches. Hence we construct node features based on neighbor similarity rather than directly adopting the original features. The comparison between different features can be found in the ablation study. Finally, we build a k-NN graph by connecting highconfidence edges to aggregate the feature of neighbors. Top-k 2 edges in S for each vertex are connected and the weights of edges are defined as:</p><formula xml:id="formula_11">e ij = S i,j , j ? N (i, k 2 ).<label>(12)</label></formula><p>Message Propagation. In the second phase, a feature aggregating process is required to further improve the retrieval performance, which is achieved by a local query expansion in conventional re-ranking methods. Similarly, in our GNN formulation, this process can be achieved by the message propagating approach [9] on the graph. The key formula of this approach is described as below:</p><formula xml:id="formula_12">h (l+1) i = h (l) i + aggregate({f ? (e ij ) ? h (l) j }),<label>(13)</label></formula><p>where h (l)</p><p>i represents the feature of v i in the l-th layer, f ? is the function to compute the weight of propagating message and aggregate represents the aggregator types: sum, mean or max.</p><p>We expect to find a suitable function f ? , which can capture the relation between nodes by edge weights. With message propagation, high-confidence node features are enhanced and the unreliable node features are weakened. Inspired by ?-weighted query expansion(?-QE) <ref type="bibr" target="#b28">[29]</ref>, we adopt f ? (e ij ) = e ? ij , where ? is a fixed value. Then the formula of our modified GNN can be refined as below:</p><formula xml:id="formula_13">h (l+1) i = h (l) i + aggregate({e ? ij ? h (l) j , j ? N (i, k 2 )}).<label>(14)</label></formula><p>Besides, h (l) i is regularized with L 2 norm after every message propagation on the graph. The last GNN layer will output the transformed node features h (l)</p><p>i . Finally, we derive the final ranking list according to the cosine similarity of refined features. Since the high-parallelism GNN propagates the message on the sparse graph efficiently, we can update all vertex features simultaneously. The whole algorithm is summarized in Algorithm 1.</p><p>Algorithm 1 Framework of our approach. Require: The union of query and gallery features X u ;</p><p>hyper-parameters k 1 and k 2 Ensure: Final ranking list L 1: Calculating the similarity matrix S according X u 2: Calculating adjacent matrix A using k 1 and S 3: Calculating A * accoding to Eq. 9 <ref type="bibr">4:</ref> Deriving h i and e ij according to Eq. 11 and Eq. 12 <ref type="bibr">5:</ref> Building k-NN graph using k 2 6: Propagating message with GNN 7: Calculating final ranking list L according to the cosine similarity of refined node features 8: return L;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Relation to Existing Methods</head><p>Our approach is related to two classes of approaches, reranking and GNN. The k-reciprocal re-ranking <ref type="bibr" target="#b51">[52]</ref> can be viewed as a special case of our approach. We argue that the first phase equals to building the neighbor graph, while the second phase can be viewed as spreading message within the graph.</p><p>In the first phase, the k-reciprocal feature is essential to calculate Jaccard distance in conventional re-ranking. However, the k-reciprocal feature requires to select the kreciprocal neighbors of query as candidates, and then expand the candidates set by adding the common neighbors of query and candidates. The set comparison operations are not hardware acceleration friendly. It is due to the crosscheck operation and a different number of k-reciprocal candidates during expanding the neighbor sets. In contrast, our method performs relation modeling by building a k-NN graph. It is natural to implement by matrix operations, which can be deployed on GPU easily.</p><p>In the second phase, local query expansion equals to one layer GNN with ? = 0 (in Eq. 14) and the aggregator type sets to mean. The conventional query expansion message spreads with equal weights in a local region. In contrast, our approach spreads node features along with edge weights, combining both global and local information. We also enable different aggregate functions. In addition, as shown in experiments, the features of nodes can be further improved by aggregating features with the number of layers (i.e., twolayer GNN) increasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head><p>We conduct experiments on five image retrieval datasets of different application scenarios, including a person reidentification dataset Market-1501 <ref type="bibr" target="#b46">[47]</ref>, a vehicle reidentification dataset VeRi-776 <ref type="bibr" target="#b20">[21]</ref>, two popular landmark retrieval datasets, i.e., Oxford-5k <ref type="bibr" target="#b25">[26]</ref> and Paris-6k <ref type="bibr" target="#b26">[27]</ref>, and a drone-based geo-localization dataset University-1652 <ref type="bibr" target="#b48">[49]</ref>. More details can be found in Section 4.1. Besides, we provide an ablation study about the effect of different components, GNN layer number and hyperparameters in Section 4.2. Finally, we discuss the retrieval results on five datasets in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Settings</head><p>Market-1501. Market-1501 <ref type="bibr" target="#b46">[47]</ref> is collected in front of a supermarket in Tsinghua University by six cameras. It contains 32,668 images of 1,501 identities in total. Specifically, it consists of 12,936 training images with 751 identities and 19,732 testing images with 750 identities. 3,368 images in the test set are selected as the query set. The images are detected by the DPM detector <ref type="bibr" target="#b7">[8]</ref>. VeRi-776. VeRi-776 <ref type="bibr" target="#b20">[21]</ref> is collected in a real-world unconstrained traffic scene with various attribute annotations. Specifically, it contains 49,360 vehicle images of 776 vehicles captured by 20 cameras. 37,781 images of 576 vehicles are divided into the train set while 11,579 images of 200 vehicles are employed as the test set. The query set consists of 1,678 images. Oxford-5k. Oxford-5k <ref type="bibr" target="#b25">[26]</ref> is one of the widely-used landmark retrieval datasets. It contains 5,062 images collected from Flickr by searching particular Oxford landmark names. The collected images are manually annotated for 11 different landmarks. There are 55 query images, and the rest images are leverages as the gallery. Paris-6k. Similarly, Paris-6k <ref type="bibr" target="#b26">[27]</ref> consists of 6,412 high resolution (1024 ? 768) images collected from Flickr by searching particular Paris landmark names. There are 12 images in the query set. University-1652. University-1652 <ref type="bibr" target="#b48">[49]</ref> contains 1,652 buildings of 72 universities around the world. There are 701 buildings of 33 universities in the training set, 701 buildings of the rest 39 universities in the test set, and 250 extra buildings serving as distractors in the gallery set. In particular, there are 37,855 drone-based images in the query set, and 951 satellite-based images in the gallery set. Evaluation Metrics. We mainly use mean average precision (mAP) <ref type="bibr" target="#b46">[47]</ref> to evaluate the performance. For each query, the average precision (AP) is calculated according to the area under the Precision-Recall curve. Then we calculate the mean value of APs of all queries, i.e.,mAP, which takes both the precision and recall rate into consideration. The Recall@K <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b37">38]</ref> denotes whether the top-K images contain a true match. The value of Recall@K equals to 1 if the first matched image has appeared before the K-th image, which is sensitive to the position of the first matched image. On Market-1501 and VeRi-776, we also report the mean Recall@1 accuracy of all query images. For University-1652, according to the previous work <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b37">38]</ref>, we add the Recall@1, Recall@5 and Re-call@10 of the retrieval results. Implementation Details. When testing, we use a two-layer GNN and set the aggregator as sum function. The parameter ? in Eq. 14 is fixed as 2. For a fair comparison, we adopt the open-source baseline models to verify the effectiveness of the proposed method. In particular, we employ a popular open-source person re-identification networks 2 as the Market-1501 baseline, which adopts a strong backbone, i.e., ResNet-50-ibn <ref type="bibr" target="#b22">[23]</ref>, and fuses multi-branch information to enhance the feature representation. The final feature dimension is 1536. For VeRi-776, we deploy a vehicle reidentification model <ref type="bibr" target="#b2">3</ref> , which extracts the 2048-dimension feature. For Oxford-5k and Paris-6k, we similarly extract 2048-dimension visual feature from the open-source ResNet101-GeM 4 <ref type="bibr" target="#b28">[29]</ref> as the baseline. For University-1652, we follow the official implementation of <ref type="bibr" target="#b48">[49]</ref> as the baseline model <ref type="bibr" target="#b4">5</ref> and extract 512-dim visual feature. We note that all experiments are conducted on the same machine with one Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10Ghz, 164GB memory and one K40m GPU with 12GB memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Studies</head><p>Effect of Different Components. We study the mechanism of the proposed method on the Market-1501 dataset. We gradually add different components and choose different input node features to analyze the contribution of each part. As shown in the first two columns of <ref type="table" target="#tab_0">Table 1</ref>, we can see that the symmetric adjacent matrix A * brings an improvement of 3.07% in mAP from 88.26% to 91.33%. With the help of message propagation, we achieve 2.87% improvement in mAP and 1.97% improvement in Recall@1 because the relevant samples are pulled much closer. Moreover, we observe that introducing edge weights improve the mAP from 94.20% to 94.53% and the Recall@1 from 95.64% to 96.29%, since nodes are treated differently according to the similarity. Besides, using two-layer GNN further increases the mAP accuracy by 0.12%. This suggests that aggregating more node features appropriately can improve the performance. Finally, we study different input features in the last three columns. It shows that node features derived from A * outperform A and original features x i . It is because  the symmetric adjacent matrix feature contains the neighbor similarity instead of the original feature, which is more robust to the hard-negative. Effect of the GNN Layer Number. To take one step further, we study the impact of the different GNN layer numbers on the Market-1501 dataset. In <ref type="table">Table 2</ref>, we report the Recall@1 and mAP with GNN from 1 layer to 256 layers. With the number of layers increasing, the node feature gradually moves to the mean value of the local connected neighbors, compromising the ranking performance. As a result, the Recall@1 reduces from 96.29% to 93.91%, and the mAP increases from 94.53% to 93.21% then reduces to 94.58%. As shown in <ref type="table">Table 2</ref>, the mAP converges to 93.21%, when the number of the GNN layers is 256. In this case, the proposed method is approximately equal to the average query expansion (AQE) <ref type="bibr" target="#b5">[6]</ref>. Because messages propagate again and again, yielding the over-smoothing result. In contrast, our method achieves the highest Recall@1 and mAP with one and two GNN layers. Effect of Hyper-parameter. To analyze the impact of two hyper-parameters (k 1 and k 2 ), we conduct experiments on Market-1501 and VeRi-776 datasets. The hyper-parameter k 1 is used to calculate the adjacent matrix A * , while k 2 is the number of neighbors in message passing. Increasing the value of k 1 moderately introduces more neighbors. k 2 is much smaller than k 1 because a large value may bring noisy nodes. According to the previous work <ref type="bibr" target="#b35">[36]</ref>, the average number of images per class can be empirically estimated by [ n C ] (C represents the number of classes, [?] indicates round down operation) and it is reasonable to construct neighbor relations based on this value, thus we set:</p><formula xml:id="formula_14">k 1 = [ n C ].<label>(15)</label></formula><p>k 2 is estimated by a much smaller number than k 1 because a large value may bring noisy nodes. This selection rule is used in all following experiments. We first study the effect (a) (b) <ref type="figure">Figure 2</ref>. The hyper-parameter analysis on k1 and k2. We analyze hyper-parameters on Market-1501 and VeRi-776. For Market-1501, we, following the previous work <ref type="bibr" target="#b35">[36]</ref>, empirically fix k2 = 7 in (a) to study k1, and fix k1 = 26 in (b) to study k2. Similarly, for VeRi-776, we fix k2 = 10 in (a) and k1 = 60 in (b) to study the impact of hyper-parameters.</p><p>of k 1 by fixing the value of k 2 . k 2 is set to 7 and 10 on Market-1501 and VeRi-776 respectively. As shown in <ref type="figure">Figure 2 (a)</ref>, our approach is insensitive to k 1 in a wide range from 20 to 40 on Market-1501. For VeRi-776, the proposed  <ref type="table">Table 3</ref>. Two-phase running time. We provide the running time of each phase and compare the proposed GNN-based method with the k-reciprocal method. The one-layer GNN is used to make a comparison with k-reciprocal re-ranking, and we finally employ the two-layer GNN to achieve better performance. We observe that our method performs better and is faster than k-reciprocal re-ranking on CPU. We also report the time cost of our method operating on GPU with a high parallelism.</p><p>method maintains a relatively high performance when k 1 changes from 50 to 70. To evaluate the influence of parameter k 2 , we fix k 1 to 26 and 60 on Market-1501 and VeRi-776 separately. <ref type="figure">Figure 2 (b)</ref> shows the proformance of our approach is stable on Market-1501 when k 2 changes from 5 to 10. Similar results can be achieved on VeRi-776 when keeping k 1 as 60 on VeRi-776 and changing k 2 from 10 to 15. In general, the proposed method can achieve comparable results and is relatively robust to a large range of k 1 and k 2 . Time Cost Comparison. We evaluate the efficiency of our method. We analyze the time cost of two phases on the Market-1501 dataset and compare our method with the conventional k-reciprocal re-ranking. Here we adopt the official implementation <ref type="bibr" target="#b5">6</ref> . As shown in <ref type="table">Table 3</ref>, we test the running time and performance of two methods on CPU.</p><p>We can see that both the one-layer and two-layer GNN are faster than k-reciprocal re-ranking in terms of the total time cost. To further reduce the time cost, we extend the GPUversion of our method, which can accelerate the re-ranking process to 9.4ms. To the best of our knowledge, there is no available GPU implementation of k-reciprocal re-ranking due to the sequential operations. Therefore, we do not include the GPU comparison with <ref type="bibr" target="#b51">[52]</ref> but other methods <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b28">[29]</ref>. As shown in <ref type="table">Table 4</ref> and <ref type="table">Table 5</ref>, the proposed method finds one balance point between speed and performance. In general, our method achieves better performance on most datasets. In terms of the time cost on CPU, it is worth noting that proposed re-ranking method achieves the similar speed with SCA <ref type="bibr" target="#b0">[1]</ref>. As for the GPU version, our method achieves a competitive speed with the vanilla methods including alpha-QE <ref type="bibr" target="#b28">[29]</ref> and AQE <ref type="bibr" target="#b5">[6]</ref>, while we yield a better performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Retrieval Performance</head><p>Experiments on Market-1501 and VeRi-776. As shown in <ref type="table">Table 5</ref>, we compare the proposed method with other post-  <ref type="table">Table 4</ref>. Time cost. We compare the proposed method with various post-processing methods on Market-1501, VeRi-776, Oxford-5k, Paris-6k and University-1652. We observe that our method finds one balance between speed and performance. For time cost on CPU, it is worth noting that proposed re-ranking method costs the same time as SCA. Besides, our method achieves a similar speed with alpha-QE <ref type="bibr" target="#b28">[29]</ref> and AQE <ref type="bibr" target="#b5">[6]</ref> but with large performance improvement on GPU.  <ref type="table">Table 5</ref>. Retrieval performance. We compare the proposed method with various post-processing methods on Market-1501, VeRi-776, Oxford-5k, Paris-6k and University-1652. mAP (%) means average precision. We observe that the proposed method achieves the best or second-best performance on most datasets.</p><p>processing approaches on the two re-identification dataset, i.e., Market-1501 and VeRi-776. There are two main observations. On the one hand, our method can improve mAP and Recall@1 by a large margin on the baseline. Specifically, our approach increases mAP by 6.39% and Recall@1 by 0.83% on Market-1501. On VeRi-776, we observe that the proposed approach gains 9.67% improvement on mAP and 0.83% improvement on the Recall@1. On the other hand, we compare our approach with a variety of postprocessing methods, including two feature similarity-based methods: AQE <ref type="bibr" target="#b5">[6]</ref>, ?-QE <ref type="bibr" target="#b28">[29]</ref>, two neighbor similar-based methods: SCA <ref type="bibr" target="#b0">[1]</ref> and k-reciprocal <ref type="bibr" target="#b51">[52]</ref>. Results show that our approach outperforms all other methods both in mAP (94.65%) and Recall@1 (96.11%) on Market-1501. As for VeRi-776, our approach has achieved the highest mAP of 88.61% and second-best Recall@1 of 96.42%. Besides, we also compare the time cost of different post-processing methods both on CPU and GPU platforms in <ref type="table">Table 4</ref>. The AQE <ref type="bibr" target="#b5">[6]</ref> and ?-QE <ref type="bibr" target="#b28">[29]</ref> are implemented on GPU, while SCA <ref type="bibr" target="#b0">[1]</ref> and k-reciprocal re-ranking <ref type="bibr" target="#b51">[52]</ref> operate on CPU due to the restriction of complex operations. The proposed method only takes about 9.4ms and 5.2ms to update Market-1501 and VeRi-776 respectively, which is significantly better than the traditional neighbor-based re-ranking method, and competitive to the method based on feature similarity. Experiments on Oxford-5k and Paris-6k. The proposed method is further evaluated on two small-scale landmark retrieval datasets, i.e., Oxford-5k and Paris-6k. The performances of different post-processing methods on ResNet101-GeM <ref type="bibr" target="#b28">[29]</ref> are reported in <ref type="table">Table 5</ref>. The feature dimension is 2048. Our approach has achieved the highest mAP accuracy of 92.95% on Oxford-5k, and competitive results 96.21% mAP accuracy on Paris-6k. The experiment verifies the scalability of the method on smallscale datasets. As shown in <ref type="table">Table 4</ref>, the re-ranking process only consumes 5.2ms, which is faster than other re-ranking methods, i.e., SCA and k-reciprocal, and achieves a similar speed with the vanilla query expansion methods. Experiments on University-1652. We also provide experimental results on the drone-based geo-localization dataset <ref type="bibr" target="#b48">[49]</ref>. Given one drone-view image, the droneview target localization task aims to find the corresponding satellite-view image to localize the target building in the satellite platform. From <ref type="table">Table 5</ref>, we observe that our method can increase Recall@1 by 11.81%, Recall@5 by 8.86%, Recall@10 by 5.98%, and mAP by 10.98%. Comparing to other methods, our approach achieves the highest performance on Recall@5, Recall@10 and mAP with 87.53%, 91.21%, and 74.11% respectively. From <ref type="table">Table 4</ref>, we can see that the proposed method only consumes 10.2ms on GPU and 85.5s on CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we revisit re-ranking methods and identify the main challenge, i.e., high complexity. We re-formulate the re-ranking process as a graph neural network (GNN) function. Specifically, we explore the neighbor representation and deploy a two-layer GNN to aggregate the neighbor information of the entire data. The inherent attributes of GNN facilitate the parallelizable implementation and make it a hardware-friendly acceleration approach. Extensive experiments on five datasets demonstrate that our method is competitive to existing arts in terms of both retrieval precision and running time. We hope this work can contribute to the future study of image retrieval tasks in real-world scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2</head><label></label><figDesc>https://github.com/douzi0248/Re-ID 3 https://github.com/BravoLu/open-VehicleReID 4 https://github.com/filipradenovic/cnnimageretrieval-pytorch 5 https://github.com/layumi/University1652-Baseline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Ablation study. We study different feature inputs, i.e., original feature xi, adjacent matrix feature Ai and symmetric adjacent matrix feature A * i . Message propagation means aggregating the feature of neighbor nodes by Eq 13. Edge weights represent the weights of propagating message in Eq 14. Two-layer GNN denotes the number of layers is 2.</figDesc><table><row><cell>Components</cell><cell>Performance</cell></row><row><cell>Node features (xi)</cell><cell></cell></row><row><cell>Node features (Ai)</cell><cell></cell></row><row><cell>Node features (A  *  i )</cell><cell></cell></row><row><cell>Message propagation</cell><cell></cell></row><row><cell>Edge weights</cell><cell></cell></row><row><cell>Two-layer GNN</cell><cell></cell></row><row><cell>mAP (%)</cell><cell>88.26 91.33 94.20 94.53 93.83 94.51 94.65</cell></row><row><cell>Recall@1 (%)</cell><cell>95.28 93.97 95.64 96.29 95.81 95.56 96.11</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sparse contextual activation for efficient visual re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1056" to="1069" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scalable person reidentification on supervised smoothed manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2530" to="2539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning context-sensitive shape similarity by graph transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Longin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Le-Cun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Group consistent similarity learning via deep crf for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8649" to="8658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Total recall: Automatic query expansion with a generative feature model for object retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The mahalanobis distance. Chemometrics and intelligent laboratory systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delphine</forename><surname>Roy De Maesschalck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D?sir? L</forename><surname>Jouan-Rimbaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Massart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
		<title level="m">Neural message passing for quantum chemistry. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2005 IEEE International Joint Conference on Neural Networks</title>
		<meeting>2005 IEEE International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-view vehicle re-identification using temporal attention model and metadata re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Min</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenq-Neng</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A contextual dissimilarity measure for accurate and efficient image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Harzallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Accurate image search using the contextual dissimilarity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Harzallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="11" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Beyond pairwise shape similarity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="655" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Person re-identification with content and context re-ranking. Multimedia Tools and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yimin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="6989" to="7014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bayesian query expansion for multicamera person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenqiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="284" to="292" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pop: Person re-identification post-rank optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guijin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="441" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lending orientation to neural networks for cross-view geo-localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5624" to="5633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A deep learning-based approach to progressive vehicle reidentification for urban surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huadong</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="869" to="884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spectral feature transformation for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4976" to="4985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Two at once: Enhancing learning and generalization capacities via ibn-net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="464" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised manifold learning using reciprocal knn graphs in image re-ranking and rank aggregation tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Carlos Guimar?es Pedronette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Ot?vio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo Da S</forename><surname>Penatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image re-ranking and rank aggregation based on similarity of ranked lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guimar?es</forename><surname>Pedronette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2350" to="2360" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Object retrieval with large vocabularies and fast spatial matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lost in quantization: Improving particular object retrieval in large scale image databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfeng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gammeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Bossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Till</forename><surname>Quack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="777" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finetuning cnn image retrieval with no human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ond?ej</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1655" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A novel approach for reranking of search results using collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rohini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 International Conference on Computing: Theory and Applications (ICCTA&apos;07)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="491" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A pose-sensitive embedding for person re-identification with expanded cross neighborhood reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Saquib Sarfraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Eberle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ah</forename><surname>Chung Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Object retrieval and localization with spatiallyconstrained similarity measure and k-nn re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3013" to="3020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep group-shuffling random walk for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yantao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2265" to="2274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Person re-identification with deep similarity-guided graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yantao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="486" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>accepted as poster</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Localizing and orienting street views using overhead imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="494" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">From one graph to many: Ensemble transduction for content-based database retrieval. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim Jing-Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="31" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Linkage based face clustering via graph convolution network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongdao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1117" to="1125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A similarity measure for indefinite rankings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rerank-by-example: Efficient browsing of web search results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehiro</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumi</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database and Expert Systems Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="801" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Predicting ground-level scene layout from aerial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menghua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Bessinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Workman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="867" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic image annotation and retrieval using group sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="838" to="849" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Part B (Cybernetics)</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Query specific rank fusion for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothee</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="803" to="815" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyue</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Vehiclenet: Learning robust visual representation for vehicle re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TMM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">University-1652: A multi-view multi-source benchmark for dronebased geo-localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ACM Multimedia</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Parameter-efficient person re-identification in the 3d space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04569</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pedestrian alignment network for large-scale person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3037" to="3045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Reranking person re-identification with k-reciprocal encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1318" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
