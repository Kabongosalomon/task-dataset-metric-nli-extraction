<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Few-shot Learning with Retrieval Augmented Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
							<email>gizacard@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Inria</orgName>
								<orgName type="institution">? University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
							<email>plewis@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Lomeli</surname></persName>
							<email>marialomeli@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
							<email>fabiopetroni@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
							<email>schick@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Dwivedi-Yu</surname></persName>
							<email>janeyu@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
							<email>ajoulin@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
							<email>sriedel@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
							<email>egrave@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Meta AI Research, ? ENS</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Few-shot Learning with Retrieval Augmented Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models have shown impressive few-shot results on a wide range of tasks. However, when knowledge is key for such results, as is the case for tasks such as question answering and fact checking, massive parameter counts to store knowledge seem to be needed. Retrieval augmented models are known to excel at knowledge intensive tasks without the need for as many parameters, but it is unclear whether they work in few-shot settings. In this work we present Atlas, a carefully designed and pre-trained retrieval augmented language model able to learn knowledge intensive tasks with very few training examples. We perform evaluations on a wide range of tasks, including MMLU, KILT and NaturalQuestions, and study the impact of the content of the document index, showing that it can easily be updated. Notably, Atlas reaches over 42% accuracy on Natural Questions using only 64 examples, outperforming a 540B parameters model by 3% despite having 50x fewer parameters. * equal contribution</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large language models (LLMs) are impressive few-shot learners <ref type="bibr" target="#b2">Rae et al., 2021;</ref><ref type="bibr" target="#b25">Hoffmann et al., 2022;</ref><ref type="bibr" target="#b7">Chowdhery et al., 2022)</ref>. They are able to learn new tasks with very few examples or even from instructions alone. For this generalization ability to emerge, the key ingredients are scaling both the parameter count of the model, and the size of the training data. Large language models owe this improvement to both a larger computational budget, enabling more complex reasoning, and the ability to memorize more information related to downstream tasks from the larger training data. While it is intuitive to assume that increased reasoning abilities lead to better generalisation, and hence few-shot learning, the same is not true for in-parameter memorisation. Specifically, it is unclear to what extent effective few-shot learning requires vast knowledge in the parameters of the model.</p><p>In this paper, we investigate whether few-shot learning requires models to store a large amount of information in their parameters, and if memorization can be decoupled from generalization. To do so, we leverage the fact that memory can be outsourced and replaced by an external non-parametric knowledge source by employing a retrieval-augmented architecture. These models employ a non-parametric memory, e.g. a neural retriever over a large, external, potentially non-static knowledge source to enhance a parametric language model. In addition to their memorization abilities, such architectures are attractive due to a number of other established advantages in terms of adaptability, interpretability and efficiency <ref type="bibr" target="#b21">(Guu et al., 2020;</ref><ref type="bibr">Borgeaud et al., 2021, inter alia)</ref>. However, retrieval-augmented models have yet to ? ? <ref type="figure">Figure 1</ref>: We introduce Atlas, a retrieval-augmented language model that exhibits strong few-shot performance on knowledge tasks, and uses retrieval during both pre-training and fine-tuning.</p><p>demonstrate compelling few-shot learning capabilities. In this work we address this gap, and present Atlas, a retrieval-augmented language model capable of strong few-shot learning, despite having lower parameter counts than other powerful recent few-shot learners.</p><p>Atlas retrieves relevant documents based on the current context by using a general-purpose dense retriever using a dual-encoder architecture, based on the Contriever . The retrieved documents are processed, along with the current context, by a sequence-to-sequence model using the Fusion-in-Decoder architecture <ref type="bibr" target="#b28">(Izacard &amp; Grave, 2020</ref>) that generates the corresponding output. We study the impact of different techniques to train Atlas on its few-shot performance on a range of downstream tasks, including question answering and fact checking. We find that jointly pre-training the components is crucial for few-shot performance, and we carefully evaluate a number of existing and novel pre-training tasks and schemes for this purpose. Atlas achieves strong downstream performance in both few-shot and resource-rich settings. For example, with only 11B parameters, Atlas achieves an accuracy of 42.4% on NaturalQuestions using 64 training examples, outperforming PaLM <ref type="bibr" target="#b7">(Chowdhery et al., 2022)</ref>, a 540B parameters model by almost 3 points, and 64.0% in a full-dataset setting, establishing a new state of the art by 8.1 points.</p><p>In summary we make the following contributions:</p><p>? A thorough study on how to design and train retrieval-augmented language models, with a focus on downstream few-shot learning and sample efficiency.</p><p>? The findings of this study lead to a retrieval-augmented language model, called Atlas, that exhibits few-shot abilities that emerge at lower scale than standard LLM.</p><p>? We provide an exploration of fine-tuning strategies to efficiently adapt both the retriever and the language model to the task at hand.</p><p>? Thorough downstream experiments in few-shot settings, demonstrating state-of-the-art results on few-shot NaturalQuestions (+2.8%), TriviaQA (+3.3%), FEVER (+5.1%), and results on par or stronger than models with 15? more parameters on MMLU.</p><p>? Experiments investigating full-dataset finetuning, setting new state-of-the-art results in NaturalQuestions (+8.1%), TriviaQA (+9.3%) and 5 KILT Tasks.</p><p>? Experiments demonstrating the updatability and interpretability characteristics of Atlas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Our approach follows the text-to-text framework <ref type="bibr" target="#b60">(Raffel et al., 2019)</ref>. This means that all the tasks are framed as follows: the system gets a text query as input, and generates a text output. For example, in the case Cross-platform software of question answering, the query corresponds to the question and the model needs to generate the answer.</p><p>In the case of classification tasks, the query corresponds to the textual input, and the model generates the lexicalized class label, i.e. the word corresponding to the label. We give more examples of downstream tasks, from the KILT benchmark in <ref type="figure" target="#fig_0">Figure 2</ref>. As many natural language processing tasks require knowledge, our goal is to enhance standard text-to-text models with retrieval, which, as we hypothesise in the introduction, may be crucial to endow models with few-shot capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Architecture</head><p>Our model is based on two sub-models: the retriever and the language model. When performing a task, from question answering to generating Wikipedia articles, our model starts by retrieving the top-k relevant documents from a large corpus of text with the retriever. Then, these documents are fed to the language model, along with the query, which in turns generates the output. Both the retriever and the language model are based on pre-trained transformer networks, which we describe in more detail below.</p><p>Retriever. Our retriever module is based on the Contriever , an information retrieval technique based on continuous dense embeddings. The Contriever uses a dual-encoder architecture, where the query and documents are embedded independently by a transformer encoder <ref type="bibr" target="#b27">(Huang et al., 2013;</ref>. Average pooling is applied over the outputs of the last layer to obtain one vector representation per query or document. A similarity score between the query and each document is then obtained by computing the dot product between their corresponding embeddings. The Contriever model is pre-trained using the MoCo contrastive loss <ref type="bibr" target="#b22">(He et al., 2020)</ref>, and uses unsupervised data only. As shown in the following section, an advantage of dense retrievers is that both query and document encoders can be trained without document annotation, using standard techniques such as gradient descent and distillation.</p><p>Language model. For the language model, we rely on the T5 sequence-to-sequence architecture <ref type="bibr" target="#b60">(Raffel et al., 2019)</ref>. We rely on the Fusion-in-Decoder modification of sequence-to-sequence models, and process each document independently in the encoder <ref type="bibr" target="#b28">(Izacard &amp; Grave, 2020)</ref>. We then concatenate the outputs of the encoder corresponding to the different documents, and perform cross-attention over this single sequence in the decoder. Following <ref type="bibr" target="#b28">Izacard &amp; Grave (2020)</ref>, we concatenate the query to each document in the encoder. Another way to process the retrieved documents in the language model would be to concatenate the query and all the documents, and to use this long sequence as input of the model. Unfortunately, this approach does not scale with the number of documents, since the self-attention in the encoder results in a quadratic complexity with respect to the number of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training objectives for the retriever</head><p>In this section, we discuss four different loss functions to train the retriever jointly with the language model. We consider loss functions that leverage the language model to provide supervisory signal to train the retriever. In other words, if the language model finds a document useful when generating the output, the retriever objective should encourage the retriever to rank said document higher. This allows us to train models using only query and output pairs from the task of interest, without relying on document annotations. For example, in the case of fact checking, a model only requires pairs of claims and corresponding verdicts but no documents containing the evidence to back up the verdict. In practice, we can apply this approach on any task, including self-supervised pre-training. As shown in the experimental section, pre-training is critical for obtaining models that exhibit few-shot learning abilities.</p><p>Attention Distillation (ADist). The first loss that we consider is based on the attention scores of the language model, and is heavily inspired by . The main idea is that the cross-attention scores between the input documents and the output, can be used as a proxy of the importance of each input document when generating the output. In particular,  showed that these scores can be aggregated across attention heads, layers and tokens for a given document to obtain a single score for each document. Then, these scores can be distilled into the retriever by minimizing the KL-divergence with the probability distribution p retr over the top-K documents {d k } 1,...,K obtained from the retriever:</p><formula xml:id="formula_0">p retr (d | q) = exp(s(d, q)/?) K k=1 exp(s(d k , q)/?) ,<label>(1)</label></formula><p>where s is the dot-product between the query and documents vectors and ? is a temperature hyper-parameter.</p><p>In the original paper, it was proposed to use the pre-softmax scores from the decoder cross-attentions, and average across heads, layers and tokens. Here, we propose an alternative which gives slightly stronger results, which relies on the following observation. In the attention mechanism, as defined by</p><formula xml:id="formula_1">y = N n=1 ? n v n ,</formula><p>the contribution to the output y of a particular token n cannot be evaluated from the attention score ? n alone, but should also take the norm of the value v n into account. Hence, we use the quantity ? n v n 2 as the measure of relevance for token n. Following , we average these scores over all attention heads, layers, and tokens to obtain a score for each document. We apply the Softmax operator over the resulting scores, to obtain a distribution p attn (d k ) over the top-K retrieved documents. We then minimize the KL-divergence between p attn (d k ), and the distribution p retr from the retriever defined in Equation 1:</p><formula xml:id="formula_2">KL(p attn p retr ) = K k=1 p attn (d k ) log p attn (d k ) p retr (d k ) .</formula><p>Here, this loss is only used to optimize the parameters of the retriever, and not the language model. When using recent deep learning frameworks, this is achieved by applying a StopGradient operator on p attn .</p><p>End-to-end training of Multi-Document Reader and Retriever (EMDR 2 ). Next, we consider the method introduced by Sachan et al. <ref type="bibr">(2021)</ref>, which is inspired by the expectation-maximization algorithm, treating retrieved documents as latent variables. Given a query q, the corresponding output a and the set D K of top-K retrieved documents with the current retriever, the EMDR 2 loss to train the retriever is</p><formula xml:id="formula_3">log K k=1 p lm (a | q, d k )p retr (d k | q) ,</formula><p>where p retr is again the probability over the top-K documents obtained with the retriever, as defined by Equation 1. Again, only the parameters of the retriever are updated by applying a StopGradient operator around p lm . One should note that the probability distribution over documents that maximizes this loss function is an indicator of the document corresponding to the highest probability of the output according to the language model. Finally, in practice, the EMDR 2 loss function is applied at the token level, and not at the sequence level.</p><p>Perplexity Distillation (PDist). Third, we discuss a simpler loss function which is loosely inspired by the objectives from the attention distillation and EMDR 2 methods <ref type="bibr" target="#b65">Sachan et al., 2021)</ref>. More precisely, we want to train the retriever to predict how much each document would improve the language model perplexity of the output, given the query. To this end, we minimize the KL-divergence between the documents distribution of the retriever (Eqn. 1), and the documents posterior distribution according to the language model, using a uniform prior:</p><formula xml:id="formula_4">p k ? p LM (a | d k , q).</formula><p>Using the Softmax operator, we have that</p><formula xml:id="formula_5">p k = exp(log p LM (a | d k , q)) K i=1 exp(log p LM (a | d i , q))</formula><p>.</p><p>Leave-one-out Perplexity Distillation (LOOP). Finally, we propose an objective based on how much worse the prediction of the language model gets, when removing one of the top-k retrieved documents. To do so, we compute the log probability of the output for each subset of k-1 documents, and use the negative value as relevance score for each document. Following the previous loss function, we use the softmax operator to obtain a probability distribution over documents:</p><formula xml:id="formula_6">p loop (d k ) = exp(? log p LM (a | D K \ {d k }, q)) K i=1 exp(? log p LM (a | D K \ {d i }, q))</formula><p>.</p><p>As before, we then minimize the KL-divergence between this distribution, and the one obtained with retriever. This loss is more expensive to compute than PDist and EMDR, but, like ADist, employs the language model more closely to the way it is trained i.e. the LM is trained to be conditioned on a set of K documents. For LOOP, the language model is conditioned on (K ? 1) documents, rather than a single document as in EMDR 2 and PDist.</p><p>For all losses, we can also use a temperature hyper-parameter when computing the target or retriever distributions to control the distribution's peakiness of, which might be important for some tasks or losses. Indeed, for PDist and LOOP, the perplexity of the output may not vary much when conditioning on different documents, especially in the case of long outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pretext tasks</head><p>In this section, we describe pretext tasks that can be used to jointly pre-train the retriever and the language model using only unsupervised data.</p><p>Prefix language modeling. First, we consider a standard language modeling task as potential pre-training objective. To cast language modeling in the text-to-text framework, we consider a chunk of N words, and split this chunk in two sub-sequences of equal length N/2. Then, the first sub-sequence is used as the query, and the second corresponds to the output. We thus retrieve relevant documents by using the first sub-sequence of N/2 tokens, to generate the output.</p><p>Masked language modeling. Second, we consider masked language modeling, as formulated by <ref type="bibr" target="#b60">Raffel et al. (2019)</ref>. Again, starting from a chunk of N words, we sample k spans of average length 3 tokens, leading to a masking ratio of 15%. We then replace each span by a different special token. The model is then trained to generate the masked spans, each span beginning with the special sentinel mask token that was inserted in the input sequence. We retrieve documents using the masked query, but replace the special mask tokens with a mask token supported by the retriever vocabulary.</p><p>Title to section generation. Finally, we consider a more abstractive generation task, generating sections from Wikipedia articles, given the article and section title. Here, the query corresponds to the title of the article, together with the title of the section, and the output corresponds to the text of the section. We exclude sections "See also", "References", "Further reading" and "External links".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Efficient retriever fine-tuning</head><p>Retrieval is facilitated by using a document index, which is a pre-computed collection of the document embeddings for all the documents in the retrieval corpus. When jointly training the retriever and language model, the index needs to be updated regularly, otherwise, the embeddings of the documents stored in the index become stale relative to the updated retriever. This means that we need to recompute the embeddings for the full collection of documents regularly during training to keep the index fresh, which can be computationally expensive for large indices. This is particularly true at fine-tuning time, where the number of training examples could be small relative to the number of documents in the index. Training the retriever could thus add an important computational overhead compared to standard language model finetuning. In this section, we analyse strategies that might make this process more efficient, alleviating the need to re-compute the embeddings of all the documents too often.</p><p>Full index update. Let us start by analysing the overhead due to updating the index, compared to using a fixed retriever. To compare the computation time of different models, we will make the following assumption: the time required to perform a forward pass on a document with a model of P parameters is O(P ). While this computation model may seem naive, the main assumption is that document sizes are constant. 1 Since we split long documents into passages with similar number of words, and use padding when processing documents of different sizes, this assumption is reasonable in practice. Let K be the number of documents that are retrieved and processed by the language model, P lm be the number of parameters of the language model and B the batch size. Each training step has a complexity of 4 ? B ? K ? P lm . 2</p><p>Next, let N be the number of documents in the index, and P retr be the number of parameters of the retriever. Then, re-computing the full index has a complexity of N ? P retr . If we refresh the index every R training steps, we obtain the following overhead:</p><formula xml:id="formula_7">N ? P retr 4 ? B ? K ? P lm ? R .</formula><p>If we use the BERT-base architecture for our retriever and T5-XL for our language model, we get Pretr Plm ? 1 25 , lading to the overhead:</p><formula xml:id="formula_8">N 100 ? B ? K ? R .</formula><p>If we use an index containing 37M documents (the size of our Wikipedia index), train with a batch size of 64 with 20 retrieved documents and refresh the index every 1000 steps, this results in an overhead of ? 30%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-ranking.</head><p>A second strategy is to retrieve a larger number of documents L with the retriever, and to re-embed and rerank these documents with the up-to-date retriever, and pass the resulting top-K to the language model. In that case, the overhead of reranking the top-L documents is equal to B ? L ? P retr . Since we perform this operation at every time step, the overhead is equal to</p><formula xml:id="formula_9">L ? P retr 4 ? K ? P lm .</formula><p>Using the same assumption as before, we finally get that the overhead is of the order of L 100?K . If we re-rank 10x more documents than what the language model processes (i.e., L = 10 ? K), we get an overhead of 10%. However, note that if many updates are performed on the retriever, the index might still need to be fully updated, as the true top-k documents may not be retrieved in the top-L results from the stale index. In practice, it is possible to track the positions of the top-K re-ranked documents in the top-L, and estimate when the index needs to be updated.</p><p>Query-side fine-tuning. Finally, the last strategy is to decouple the encoding of the queries and documents. In this case, we fix the parameters corresponding to the document encoder, and only train the parameters corresponding to the query encoder. Thus, the embeddings of documents are fixed, and we do not need to refresh the index, and thus there is no computational overhead. As we will see in practice, the impact of fixing the documents encoder varies greatly for different tasks when a large training dataset is available. For most of the few-shot settings that we consider, query-side finetuning does not have large performance impact, and sometimes even slightly improves performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work 3.1 Retrieval in natural language processing</head><p>Retrieval for knowledge intensive tasks. Previous work has shown that retrieval improves performance across a variety of tasks such as question answering <ref type="bibr" target="#b79">(Voorhees et al., 1999;</ref><ref type="bibr" target="#b6">Chen et al., 2017;</ref><ref type="bibr" target="#b39">Kwiatkowski et al., 2019)</ref>, fact checking <ref type="bibr" target="#b76">(Thorne et al., 2018)</ref>, dialogue <ref type="bibr" target="#b12">(Dinan et al., 2019)</ref> or citation recommendation . Historically, this information retrieval step was implemented using term-matching methods, such as TF-IDF or BM25 <ref type="bibr" target="#b32">(Jones, 1972;</ref><ref type="bibr" target="#b64">Robertson et al., 1995)</ref>. For open-domain question answering <ref type="bibr" target="#b79">(Voorhees et al., 1999)</ref>, documents are often retrieved from Wikipedia <ref type="bibr" target="#b6">(Chen et al., 2017)</ref>. Recently, dense retrievers based on neural networks have become popular. These usually follow a dual-encoder architecture <ref type="bibr" target="#b86">(Yih et al., 2011;</ref><ref type="bibr" target="#b27">Huang et al., 2013;</ref><ref type="bibr" target="#b69">Shen et al., 2014)</ref>, where queries and passages are encoded independently as vectors, and relevance is computed using the inner product or Euclidean distance. Popular supervised retrievers include DPR , which is trained to discriminate the relevant passage among negative passages, and extensions such as ANCE <ref type="bibr" target="#b83">(Xiong et al., 2020)</ref> which improved the hard negatives mining process. We refer the reader to <ref type="bibr">Yates et al. (2021)</ref> for a survey of dense retrieval techniques.</p><p>After retrieval, relevant documents are processed to produce the final output. In open-domain QA, models can extract a span of text from retrieved documents as the answer <ref type="bibr" target="#b6">(Chen et al., 2017;</ref><ref type="bibr" target="#b8">Clark &amp; Gardner, 2018;</ref><ref type="bibr" target="#b80">Wang et al., 2019;</ref>, a method inspired by reading comprehension <ref type="bibr" target="#b63">(Richardson, 2013;</ref><ref type="bibr" target="#b61">Rajpurkar et al., 2016)</ref>. Recently, generating the answer as free-form text, using a seq2seq model conditioned on retrieved documents have become prevalent <ref type="bibr" target="#b28">Izacard &amp; Grave, 2020;</ref>. These architectures have also been shown to reduce hallucination in dialogue agents <ref type="bibr" target="#b71">(Shuster et al., 2021)</ref>.</p><p>Retriever training. The need for expensive query-document annotations for training the retriever can be bypassed, by leveraging signals from the language model, or using unsupervised learning. REALM <ref type="bibr" target="#b21">(Guu et al., 2020)</ref> and RAG  jointly train the retriever and language model by modelling documents as latent variable, and minimizing the objective with gradient descent. REALM pre-trains end-to-end with an MLM approach but uses an extractive BERT-style model . <ref type="bibr" target="#b21">Guu et al. (2020)</ref> also explore a query-side finetuning at finetuning time to avoid index refreshes. <ref type="bibr" target="#b28">Izacard &amp; Grave (2020)</ref>    both employ salient span masking to pre-train retrievers, leveraging the perplexity and attention scores from the language model. The inverse cloze task was proposed by  to pre-train dense retrievers in an unsupervised way.  propose a method to train retrieval-augmented generators using a second "informed" retriever with access to the output, which the test-time retriever can be distilled from, <ref type="bibr" target="#b26">and Hofst?tter et al. (2022)</ref> recently proposed a training set filtering/weighting approach to train stronger retrieval-augmented generators.  explored different contrastive learning methods to train retrievers, while <ref type="bibr" target="#b62">Ram et al. (2022)</ref> used recurring spans within a document to create pseudo-positive query-document pairs.</p><p>Retrieval-augmented language models. Continuous cache models <ref type="bibr" target="#b20">(Grave et al., 2017b</ref>) defines a probability distribution over recent tokens, by computing the similarity between previous and current representations of tokens. This distribution is then interpolated with the distribution of the language model, to improve predictions. Later, the amount of tokens used to compute this distribution was extended to a much larger memory by leveraging approximate nearest neighbors search <ref type="bibr" target="#b19">(Grave et al., 2017a)</ref>. The related kNN-LM model <ref type="bibr" target="#b36">(Khandelwal et al., 2020)</ref> replaced LSTMs by transformer networks, and scaled the memory to billions of tokens, leading to strong performance improvements. More recently, RETRO <ref type="bibr" target="#b59">(Borgeaud et al., 2021)</ref> extended these by scaling the retrieval memory to trillions of tokens, and changing the model architecture to take retrieved documents as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval-Augmentation with Search Engines.</head><p>Recently, different works have proposed to train large language models to interact with a search engine, by generating text queries, and using the retrieved documents as additional context <ref type="bibr" target="#b53">(Nakano et al., 2021;</ref><ref type="bibr">Thoppilan et al., 2022;</ref><ref type="bibr">Shuster et al., 2022)</ref>. In the context of few-shot question answering, <ref type="bibr" target="#b41">Lazaridou et al. (2022)</ref> used the question to perform a search query, and retrieved documents are added to the prompt of a large language model performing in-context learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Few-shot learning</head><p>Few-shot learning, the task of learning from very few examples, has been studied for decades <ref type="bibr" target="#b77">(Thrun &amp; Pratt, 1998;</ref><ref type="bibr" target="#b16">Fink, 2005;</ref><ref type="bibr" target="#b78">Vinyals et al., 2016)</ref>, but has recently seen an explosion of interest in NLP with the arrival of large pre-trained models, which exhibit emergent few-shot learning abilities <ref type="bibr" target="#b81">(Wei et al., 2022)</ref>.</p><p>In-context Learning with large Language models. Providing language models with natural language descriptions of tasks, as proposed by <ref type="bibr" target="#b58">Radford et al. (2019)</ref> has led to significant developments in few-shot learning. GPT-3  demonstrated the ability of large language models to perform few-shot predictions, where the model is given a description of the task in natural language with few examples. Scaling model size, data and compute is crucial to enable this learning ability, leading to the further development of large models <ref type="bibr" target="#b49">(Lieber et al., 2021;</ref><ref type="bibr" target="#b2">Rae et al., 2021;</ref><ref type="bibr" target="#b73">Smith et al., 2022;</ref><ref type="bibr" target="#b7">Chowdhery et al., 2022;</ref><ref type="bibr" target="#b73">Smith et al., 2022)</ref>. <ref type="bibr" target="#b25">Hoffmann et al. (2022)</ref> revisited the scaling law from , suggesting that training on more data with a smaller model may be more effective, resulting in Chinchilla, a 70B parameter model with improved parameter efficiency.</p><p>Few-shot finetuning and prompt-based learning. The above models perform few-shot learning with in-context instructions without training the parameters of the language model. Few-shot learning can also be accomplished by combining textual templates ("prompts") and various forms of model finetuning, either fully updating a model's parameters, e.g. for classification <ref type="bibr" target="#b67">(Schick &amp; Sch?tze, 2021a;</ref><ref type="bibr" target="#b66">Schick &amp; Schutze, 2021;</ref><ref type="bibr" target="#b17">Gao et al., 2021;</ref><ref type="bibr" target="#b74">Tam et al., 2021)</ref> or generation <ref type="bibr" target="#b68">(Schick &amp; Sch?tze, 2021b)</ref>. Prompts themselves can be optimized, for example by search <ref type="bibr" target="#b31">(Jiang et al., 2020;</ref><ref type="bibr" target="#b70">Shin et al., 2020)</ref> or by only updating parts of the model (Logan et al., 2021), or learning "soft-prompts" <ref type="bibr">(Lester et al., 2021;</ref><ref type="bibr" target="#b48">Li &amp; Liang, 2021)</ref>. Due to its simplicity, in this work we either employ simple prompts or simply feed in inputs without preprocessing, and perform full-model finetuning, a method similar to Le Scao &amp; Rush (2021).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we report empirical evaluations of our language models on few-shot learning. We start by introducing our experimental setup, describing our evaluation benchmarks in section 4.1, and giving the training details of our models in section 4.2. Then, we perform an ablation study to compare the different technical choices leading to our main model. We finally evaluate this model, called Atlas, on different natural language understanding tasks in few-shot and full dataset settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benchmarks</head><p>To evaluate our retrieval-augmented language models we consider the following benchmarks, which include different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge-Intensive Language Tasks (KILT).</head><p>First, we use the KILT evaluation suite , containing 11 datasets corresponding to 5 tasks: fact checking, question answering, dialog generation, entity linking and slot-filling. These different tasks require knowledge about the world to be solved, which can be found in Wikipedia. We evaluate our model on the following tasks and datasets included in KILT: question answering: NaturalQuestions <ref type="bibr" target="#b39">(Kwiatkowski et al., 2019)</ref>, TriviaQA <ref type="bibr" target="#b33">(Joshi et al., 2017)</ref> and HotpotQA <ref type="bibr" target="#b84">(Yang et al., 2018)</ref>; slot filling: Zero Shot RE <ref type="bibr" target="#b46">(Levy et al., 2017)</ref> and T-REx <ref type="bibr" target="#b14">(Elsahar et al., 2018)</ref>; entity linking: AIDA CoNLL-YAGO <ref type="bibr" target="#b24">(Hoffart et al., 2011)</ref>; dialogue: Wizard of Wikipedia <ref type="bibr" target="#b12">(Dinan et al., 2019)</ref>; and fact checking: FEVER <ref type="bibr" target="#b76">(Thorne et al., 2018)</ref>. The KILT versions of these datasets differ from their original versions, as instances requiring knowledge not present in the August 2019 Wikipedia dump have been removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Massively-Multitask Language Understanding (MMLU).</head><p>Our second main evaluation benchmark is MMLU <ref type="bibr">(Hendrycks et al., 2021)</ref>, which contains 57 multi-choice question answering datasets (referred to as domains), sourced from real examinations designed for humans. These cover a very broad range of topics, e.g. high school mathematics, professional law, logical fallacies and clinical knowledge and can be broadly categorized in four subsets: humanities, social sciences, STEM and "other". We focus on few-shot learning, and the authors of the benchmarks suggest to use 5 training examples per domain. Beyond the 5-shot setting, We also consider three additional settings. The first is a zero-shot setting, with no training data at all. The second, which we call multi-task few-shot, is where we train a single model on the 6-shot data from all tasks, hence leading to a training set of 285 examples. The last, which we call transfer learning, leverages additional training examples from other multiple-choice QA tasks provided by the MMLU authors, namely MCTest <ref type="bibr" target="#b63">(Richardson, 2013)</ref>, RACE <ref type="bibr" target="#b40">(Lai et al., 2017)</ref>, ARC  and OBQA <ref type="bibr" target="#b51">(Mihaylov et al., 2018)</ref> leading to a training set of 95k examples.</p><p>Additional benchmarks. Additionally, we report results on the original open-domain versions of the popular NaturalQuestions <ref type="bibr" target="#b39">(Kwiatkowski et al., 2019)</ref>, and TriviaQA <ref type="bibr" target="#b33">(Joshi et al., 2017)</ref> datasets. We also evaluate our model on the original version of FEVER <ref type="bibr" target="#b76">(Thorne et al., 2018)</ref>, which presents fact checking as a three-way classification problem for textual claims (either "Supported": the text is supported by evidence in Wikipedia, "refuted": the claim is not consistent with evidence in Wikipedia, or "not enough info", where there is insufficient evidence to make a judgement). We also perform experiments to assess temporal sensitivity of our models. Here, we construct a dataset from TempLAMA <ref type="bibr" target="#b11">(Dhingra et al., 2022)</ref>, consisting of a set of time-sensitive cloze questions on a range of topics, where the answer changes from 2017 to 2020. We assess the accuracy of our models when supplied with a index from 2017 vs 2020 to assess to what degree models faithfully reflect the content of the index supplied to them at test time, and how effective updating the index is as a continual learning or model updateability method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Technical details</head><p>We now describe the procedure for pre-training and fine-tuning our models. We focus on the setting used for the ablation studies performed in Section 4.3 and Section 4.4. We give more details about the hyperparameters used for our final model later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training.</head><p>For the pre-training, we initialize the retriever module using the unsupervised contriever model, which uses the BERT-base architecture. We initialize the language model with the T5 pre-trained weight. As the original T5 pre-trained model included supervised data in the training set, we use the version 1.1 models which were trained on unlabeled text only. Specifically, we initialize from the T5-lm-adapt variants due to their improved stability.</p><p>For the ablation studies performed in Section 4.3 and Section 4.4, we use T5-XL which contains 3B weights. We pre-train all our models for 10,000 iterations, using AdamW with a batch size of 64 and a learning rate of 10 ?4 for the reader and 10 ?5 for the retriever with linear decay and 1,000 warmup steps. We refresh the index every 1,000 steps. This means that the index is recomputed 10 times during the pre-training, leading to an overhead of around 30%, compared to training with a fixed retriever. We set the number of retrieved documents to 20. We detail the hyperparameters used for the training of our final model at the beginning of Section 4.5.</p><p>Fine-tuning. When performing a downstream task, either in a few-shot setting or with a large training set, we employ fine-tuning to adapt our models to these tasks. For the few-shot KILT ablation experiments, we perform a fixed number of fine-tuning iterations, instead of using early-stopping. More precisely, we decided to use 50 iterations for the 64-shot setting and 200 iterations in the 1024-shot setting. In both cases, we use <ref type="table">Table 1</ref>: Retriever loss ablation. We compare different loss functions to pre-train the retriever jointly with the language model. We use the prefix MLM task, and the December 2021 Wikipedia dump for both the index and pre-training data. Fine-tuning is performed with query-side fine-tuning and the loss used for pre-training. Best result is bold, second highest underlined. Unlabeled datasets. Finally, we discuss the unlabeled text datasets that we use to train our models, which form the retrieval index. First, we consider the Dec. 20, 2021 Wikipedia dump, for which we keep the lists and infoboxes, which are linearized by adding a semi-colon separator between the entries. We split articles by section, and split long sections into passages of equal sizes and containing less than 200 words. This leads to a total of 37M passages, containing 78 words in average. We also use documents from the 2020-10 common crawl dump, preprocessed with the CCNet pipeline <ref type="bibr" target="#b82">(Wenzek et al., 2020)</ref>. We perform additional document filtering, in a similar fashion to Gopher . More precisely, we filter documents based on document length, average word length, ratio of alphanumeric characters and number of repeated tokens. This leads to a total of 350M passages. The same passages are used for the index and model pre-training. During pre-training, we ensure the passage we are training on is filtered out from the retrieved documents, to prevent the model from simply retrieving the passage it is de-nosing/generating, and trivially using it to solve the pre-training task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pre-training loss and tasks</head><p>We start our ablation study by comparing different pre-training tasks, and objective functions to jointly train the retriever and the language model. Our goal here is to answer the following research questions:</p><p>(RQ 1) Does jointly pre-training the whole model lead to better few-shot performance?</p><p>(RQ 2) What is the best objective function for the retriever, and the best pretext task?</p><p>We start by comparing the training objectives of the retriever, introduced in Section 2.2, by pre-training models using the masked language modelling task. We evaluate these models on a subset of the 64-shot and 1024-shot KILT benchmark: NaturalQuestions, FEVER and Wizard of Wikipedia, along with two baselines: a 'closed-book" (i.e. non-augmented T5) baseline, pre-trained on the same data, and initialized from Contriever and T5-lm-adapt. We report results in <ref type="table">Table 1</ref>. First, we note the poor performance of the closed-book baseline, indicating the importance of augmentation. Next, we observe that pre-training our model with retrieval is important to obtain good performance on few-shot tasks. Indeed, all models that include retrieval during pre-training strongly outperform the baseline without joint pre-training. Next, we compare a model that was pre-trained with a fixed retriever, and models using the various retriever training objectives. On the MLM validation metric corresponding to the pre-training objective, we observe that jointly training the retriever leads to strong improvements. This effect tends to be less marked on 64-shot downstream tasks, and almost non-existent for 1024-shot. We believe that this is evidence that the  biggest impact of pre-training is on the language model, which learns to use and aggregate information from the retrieved documents. Lastly, we do not observe significant systematic differences between the different retriever training objectives. We thus decide adopt use Perplexity Distillation for subsequent experiments, as it tends to be more stable than EMDR 2 or ADist, and more computationally efficient than LOOP.</p><p>Next, we compare the different self-supervised pretext tasks introduced in Section 2.3 in <ref type="table" target="#tab_2">Table 2</ref>. Here we observe similar results for all three tasks, with a small advantage for masked language modelling. Thus, in what follows, we adopt masked language modelling for pre-training.</p><p>Finally, we consider different combinations of data sources-Wikipedia and common crawl-for the index and training data during pre-training. In all cases, we use the Wikipedia 2021 dump as the index when performing few-shot fine-tuning. We report results in <ref type="table" target="#tab_3">Table 3</ref>. First, we observe that using a Wikipedia-based index leads to better downstream performance. There could be two explanations for this: first, as we use Wikipedia for the few-shot tasks, the model might be better adapted when trained using the same data. Another explanation might be that Wikipedia is a higher-quality and denser source of knowledge than common crawl. Second, when using a common crawl index, we observe that pre-training on Wikipedia data leads to lower performance than using common crawl data. We believe that the primary reason is that the distribution mismatch between the two domains leads to generally-less relevant retrieved documents. In turn, this probably means that the pre-training is less efficient, because the language model does not leverage as much information from the documents. In the following, we thus decide to combine the data from both domains for both the index and the pre-training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fine-tuning</head><p>In this section, we perform an ablation study on how to apply our models on downstream tasks, which relies on fine-tuning. In particular, we want to investigate the following research question:</p><p>(RQ 3) How to efficiently fine-tune Atlas on tasks with limited training data?</p><p>To answer this question, we compare the different strategies to fine-tune the retriever module, described in Section 2.4. We report results in <ref type="table" target="#tab_4">Table 4</ref>. First, as for pre-training, we observe that keeping the retriever fixed during fine-tuning leads to a significant performance drops, for both 64-and 1024-shot settings. Second,  the re-ranking strategy (row 2) leads to very similar results to fully updating the index (row 1), while being significantly more efficient. Lastly, fine-tuning only the query encoder also leads to strong results: in particular, in the 64-shot setup, this is slightly stronger than performing full fine-tuning, which we attribute to there being less opportunity for over-fitting. On the other hand, on the 1024-shot setting, performing a full fine-tuning leads to stronger results, especially on NaturalQuestions. In the following, we thus use query-side fine-tuning for experiments with small numbers of examples, and standard fine-tuning for larger datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Training and evaluating Atlas</head><p>In this section, we apply the findings from the ablations of the previous sections to train a family of Atlas models, ranging from 770M to 11B parameters. More specifically, we use the Perplexity Distillation objective function, along with the masked language modelling pretext task. We pre-train these models using a mix of Wikipedia and Common Crawl data, for both the training data and content of the index. We retrieve 20 documents, and update the index every 2,500 steps and perform re-ranking of the top-100 documents. We pre-train models for 10,000 iterations using AdamW with a batch size of 128.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">MMLU Results</head><p>As mentioned in section 4.1, we consider four setting for MMLU: 1) a zero-shot setting where we directly apply the pretrained model with no few-shot finetuning 2) a 5-shot setting, where we finetune a model using 5 training examples for each of the 57 domains 3) a 5-shot multitask setting, where, rather than finetuning a model independently for each domain, we train a single model to perform all tasks and 4) a setting with access to a number of auxiliary datasets, with 95K total training examples. We train the models to generate the letter corresponding to the correct answer option ('A', 'B', 'C' or 'D'), and pick the answer with the most likely of the 4 letters at test time. Full technical details can be found in appendix A.1.</p><p>Performance vs Parameters. We start by comparing Atlas to closed-book models of different sizes for 5-shot, 5-shot multitask and the full setting, and report results in <ref type="table" target="#tab_5">Table 5</ref>. Across these settings, Atlas outperforms the closed-book baselines by between 6.6 and 15.6 points, demonstrating consistent utility of retrieval for few-shot language understanding across 57 domains. The closed-book T5 struggles to perform significantly better than random (25%) in few-shot settings with 770M parameters, whereas the equivalent Atlas achieves around 40%, significantly better than random, despite its small size. All models improve with more data, but interestingly, the 770M models do not benefit as much from few-shot multitask learning compared to larger models (for closed-book, it actually loses 3 points) suggesting smaller models struggle to grasp the synergies between the tasks in the few-shot setting. Larger models exploit the multi-task setting well, with Atlas improving more than closed-book. For example, Atlas-11B improves by 13 points (43.4 ? 56.4), but equivalent closed-book only improves by 7 (36.1 ? 43.5). Finally, on the transfer learning setting, all models improve, but the relative gaps between closed-book at Atlas models remain similar.</p><p>De-biasing. When finetuning, we permute which answer option appears with which answer letter to reduce over-fitting and encourage a uniform prior over answer letters. However, the model may still exhibit a bias towards some letters, especially in few-shot settings, so we also include a second 'de-biased' inference mode in addition the standard inference used above. Here, we run 4 forward passes, one for each cyclic permutation of the answer letter-answer option assignment in the question, e.g. the answer option assigned to letter 'A' becomes 'B', what was 'B' becomes 'C' etc. <ref type="bibr">3</ref> We then sum the 4 probabilities to obtain the final prediction, which reduces spurious bias towards one of the answer letters (further details in appendix A.1). The results are shown in <ref type="table" target="#tab_6">Table 6</ref>. We find that in zero-shot and 5-shot settings, de-biasing is very effective, improving results by 10.3 and 4.5 points respectively. When more training data is available, the need for de-biasing decreases, leading to only 0.2 point improvement in the multi-task and full data settings.</p><p>Comparison to published works Next, we compare our Atlas-11B results with de-biasing to recently reported results with state-of-the-art large language models such as GPT-3 or Chinchilla, which required significantly more amount of computation to train. We report results in <ref type="table" target="#tab_7">Table 7</ref>. We find that Atlas is able to perform significantly better than random in zero-shot, and in conjunction with de-biased inference, achieves zero-shot scores that exceed 5-shot results reported with GPT3 in the literature (47.1% vs 43.9%) <ref type="bibr">(Hendrycks et al., 2021)</ref>. For the 5-shot setting, Atlas outperforms GPT-3 by 4%, while using 15? less parameters, and 10? less pre-training compute. 4 When multitask-training on the combined 5-shot data, Atlas improves to 56.6% close to the 5-shot performance of Gopher (60.0%). Finally, on the full data setting, where we train on auxiliary data recommended by the MMLU authors, Atlas reaches an overall accuracy of 65.6%, close to the state-of-the-art. Interestingly, in this setup, Atlas significantly outperforms GPT-3, while on the 5-shot setting, their performance is similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Open-domain Question Answering Results</head><p>Next we evaluate Atlas on two open-domain question answering benchmarks: NaturalQuestions and TriviaQA. We compare to prior work, both in a few-shot setting using 64 examples, and using the full training set, and report results in <ref type="table" target="#tab_8">Table 8</ref>. On these benchmarks, which require high-degree of memorization, we clearly see the benefits of retrieval-augmentation. Atlas-11B obtains state-of-the-art results on 64-shot question answering, for both NaturalQuestions and TriviaQA. In particular, it outperforms significantly larger models, such as PaLM, or models that required significantly more training compute such as Chinchilla. When using the full training set, Atlas also obtains state-of-the-art results, for example improving the accuracy on NaturalQuestions from 55.9% to 60.4%. This result is obtained using an index comprised of CCNet and the December 2021 Wikipedia corpora, our default setting for the index. In section 5.2 we consider using indexes composed of Wikipedia corpus archived at different dates, and demonstrate an additional +3.6%  on NaturalQuestions when using an index which is temporally matched to NaturalQuestions. We report performance as a function of model size as well as detailed hyperparameters in Appendix A.2.</p><p>Atlas also compares favorably to recent work exploring retrieval-augmented few-shot question answering with very large models. <ref type="bibr" target="#b41">Lazaridou et al. (2022)</ref> explore NaturalQuestions in a 15-shot setup using Gopher, augmenting questions with 50 passages retrieved using Google Search. This method consists of generating 4 candidate answers from each retrieved passages, and then re-ranking using either a score inspired by RAG   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">FEVER Results</head><p>We report results on the original 3-class FEVER fact checking test set in <ref type="table" target="#tab_10">Table 9</ref>. We consider a 64-shot setting, with training examples uniformly sampled from the full training set. Unlike the development and test sets, the train set is imbalanced, with more positive labels than negative, posing a challenge for few-shot learning. In this setting, we achieve an accuracy of 64.3%. We also report a 15-shot setting, with 5 examples uniformly sampled from each class to compare with published results from Gopher , where </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15-shot 65-shot Full dataset</head><p>Gopher  51.1 --ProoFVer <ref type="bibr" target="#b38">(Krishna et al., 2021)</ref> --79.5 Atlas 56.2 64.3 78.0 / 80.1 ? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.4">KILT Results</head><p>Finally we evaluate Atlas on KILT, a benchmark composed of several different knowledge intensive tasks, which was described in section 4.1. We report results on test sets in <ref type="table" target="#tab_11">Table 10</ref> for which evaluation is available online 5 . The KILT versions of datasets are filtered, and thus results for datasets we have evaluated elsewhere are not directly comparable on KILT (i.e. FEVER, NQ and TQA). We consider both a 64-shot setting and a full fine-tuning setting, in both cases we train Atlas individually on each dataset. More details on the hyperparameters and development set results are reported in Appendix A.3. For 64-shot, we greatly exceed random performance, and are even competitive with some fully-finetuned models on the leaderboard, such as for FEVER, where our 64-shot Atlas is only 2-2.5 points behind Sphere, SEAL and Re2G, and outperforms Sphere and SEAL on zero-shot RE. In the full dataset setting, Atlas is within 3% to the state-of-the-art for 3 datasets, and sets the state-of-the-art in the remaining five datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Interpretability and Leakage</head><p>An advantage of semi-parametric models like Atlas is the ability to inspect retrieved items to aid interpretability. To better understand how well Atlas retrieves, and how it uses retrieved passages, we examine the retrieved passages for multi-task few-shot MMLU. As shown in the left panel of <ref type="figure" target="#fig_2">Figure 3</ref>, the model retrieves the Wikipedia makes up about 15% of retrieved passages, which is higher than we would expect under a uniform prior, given Wikipedia only makes up about 10% of the index. The fraction of Wikipedia retrieval varies between MMLU domains, with the model using Wikipedia to a greater extent for STEM domains, and least for social sciences. The domain making the greatest use of Wikipedia is "abstract algebra" (73%), and the least is "moral scenarios" (3%). We also note that the MMLU-finetuned Atlas does not make significant use of Wikipedia infobox passages.</p><p>We can also analyse the content of passages to assess how they may useful for accomplishing the downstream task. The middle panel of <ref type="figure" target="#fig_2">Figure 3</ref> shows how often retrieved documents contain the text of the correct answer option. There being at least one mention of the correct answer choice in 30% of test questions in the top 25 passages. <ref type="bibr">6</ref> The right panel shows that the accuracy on MMLU increases when the correct answer option text occurs more frequently in retrieved passages, rising from 55% for questions when the answer option does not appear, to 77% for questions mentioned more than 15 times.</p><p>A human analysis of retrieved documents revealed that documents are helpful for answering questions in a number of different ways. Manual inspection of a sample of 50 correctly-answered questions revealed that 44% contained at least partially useful background information. These are documents that would improve the likelihood of a non-expert human answering correctly, such as contextual clues surrounding a quotation from a question, or helpful numerical figures for quantity-based questions, which help to narrow down the answer options to a smaller range. In a further 26% of cases, a passage contained all the necessary information to answer the question, stated in a straightforward way. If read competently, such passages make the question simple to answer, and often include information such as canonical definitions, or the exact numerical answer requested in the question. 28% of retrieval sets did not contain obvious information which would make the question easier. Finally, 2% contained the verbatim question in a passage, together with its answer.</p><p>Given that MMLU has been created from pre-existing exams, it is possible that these questions appear on the open web. Models trained on web data (or, in our case, retrieving from it) run the risk of answering correctly not through generalization, but by verbatim memorization, which could lead to misleadingly high scores. In some very large language models, which can verbatim memorize and recall large parts of their pre-training data <ref type="bibr" target="#b5">(Carlini et al., 2021)</ref>, efforts have sometimes been made to filter occurrences of downstream instances from pre-training data, but this has not been performed for MMLU in the literature. In order to assess the prevalence of MMLU leakage in our index, we manually checked retrieval results for questions where the longest n-gram overlap between the question (without answer options) and a passage was at least 75% the length of the question. This resulted in an estimate of leakage of 2.8% of questions from our CC-Net corpus.</p><p>A benefit of retrieval-augmented models such as Atlas is the editability of its knowledge (see section 5.2 for additional analysis). To estimate pure, non-leaked performance, we can filter out any potentially-leaked passages from retrieved results and rerun the language model. The MMLU score drops slightly when controlling for this leakage from 56.4 to 55.8% (-.5%).We note that our CC-net corpus is relatively small compared to the pre-trained corpora of recent very large models, which are trained on up to 1.4 trillion tokens <ref type="bibr" target="#b25">(Hoffmann et al., 2022)</ref>, 35x the size of our index, making it likely that models trained on corpora of that size would observe more MMLU leaked examples, but detecting such leakage is challenging in non-retrieval augmented models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Temporal Sensitivity and Updateability</head><p>A benefit of retrieval-augmented models is that they can be kept up-to-date without retraining, by updating or swapping their index at test time. To assess the effectiveness of this mechanism in Atlas, we first construct a dataset of time-sensitive questions derived from TempLAMA <ref type="bibr" target="#b11">(Dhingra et al., 2022)</ref>. TempLAMA is a collection of templated cloze questions derived from Wikidata and Wikidata where the correct answer changes over time. We select a subset of questions from this dataset which have a different answer in 2017 and 2020, for example, Question: Theo Walcott plays for ___ Answer: Arsenal F.C. (2017), Everton F.C. (2020), and form a small training set of 248 training, 112 development and 806 test questions.</p><p>Using this dataset, we finetune closed-book T5-XXL and Atlas using the questions and the 2017 answers, supplying Atlas with a 2017 Wikipedia index, and then measure exact match accuracy on the 2017 test set. The results can be found in the first row and first two columns of <ref type="table" target="#tab_12">Table 11</ref>. We first observe that, as expected, Atlas greatly outperforms T5 (57.7% c.f. 12.1%). We also note that, as desired, both T5 and Atlas almost never generate an answer from 2020 when trained with the 2017 answers, scoring 2.8% and 1.5% respectively (first row, second two columns of <ref type="table" target="#tab_12">Table 11</ref>). However, as shown in row 2, we can swap the Atlas index to a 2020 Wikipedia index, without retraining, and find that Atlas updates its predictions accordingly, with 2020 accuracy rising to a similar level to its 2017 performance (53.1%), whereas the purely parametric T5 has no such updateability mechanism.</p><p>This demonstrates that Atlas can be faithful and condition strongly on its supplied index. Furthermore, this zero-shot updateability mechanism has the useful property of staying up-to-date without requiring up-to-date annotated data, or continuous, lifelong pre-training, as would be may required for a large parametric-only model. Rows 3 and 4 of <ref type="table" target="#tab_12">Table 11</ref> complete the picture, where this time we train with 2020 answers, and demonstrate Atlas can zero-shot transfer backwards in time to 2017 effectively too (50.1%). Interestingly, T5 is unable answer questions from 2020 well, even when trained with 2020 answers (3.6%), likely because it was pre-trained on data pre-dating 2020 <ref type="bibr" target="#b13">(Dodge et al., 2021)</ref>.</p><p>We also examine temporal effects for NaturalQuestions. NaturalQuestions is a dataset composed of search queries collected via the Google search engine in a short period of time. Thus data have a strong temporal bias, with a lot of questions about the 2018 World Cup for example. Moreover some questions are ambiguous without specification of the temporal context. For instance, for the question "when did ireland last beat england at twickenham", the expected answer is 2018 in NaturalQuestions, while Ireland also beat England at Twickenham in 2022 as well as many other times before. In <ref type="table" target="#tab_2">Table 12</ref>, we report results obtained by finetuning Atlas using different Wikipedia dumps for the index. We observe that the 2018 December Wikipedia dump, which is close to the date of data collection, leads to the best results for both few-shot and full fine-tuning.</p><p>In particular, it leads to a new state-of-the-art of 64 EM on NaturalQuestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this paper, we introduce Atlas, a large retrieval-augmented language model. By jointly pre-training the retriever module and the language model, we show that Atlas has strong few-shot learning capabilities on a wide range of knowledge intensive tasks, including NaturalQuestions, TriviaQA, FEVER, 8 KILT tasks and 57 MMLU tasks. For example, Atlas-11B reaches more than 42% accuracy on NaturalQuestions and 84.7% on TriviaQA when training on 64 examples, which is an improvement of almost 3 points compared to PaLM, a 540B parameters model, which required 50x more pre-training compute. We also provided detailed ablations and analyses for what factors are important when training such retrieval-augmented models, and demonstrated Atlas's updateability, interpretability and controlability capabilities. Lastly, we demonstrated that Atlas is also powerful in full-dataset settings obtaining a new state-of-the-art results on NaturalQuestions, TriviaQA, FEVER, and 5 KILT tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training details and additional results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 MMLU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 Training Details</head><p>Featurization MMLU consists of multiple choice questions with four possible lexicalized answer options. We represent the input using the following template: and train the model to generate the mask token followed by the letter of the correct answer:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[MASK_0] {correct answer option letter}</head><p>This format closely matches the format of MLM pre-training objective, aiding few-shot learning. When training, we permute the order of the answer options, i.e. shuffling which answer option appears as letter A etc. This helps reduce overfitting, and encourages a uniform prior on the letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard inference</head><p>Once trained we obtain predictions from the model by selecting the pre-softmax logits for the tokens A, B, C and D, and performing a softmax over them to obtain a distribution over the 4 answer options. For standard inference, we then simply return the answer corresponding to the argmax of this distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>De-biased Inference</head><p>As mentioned in the main text, even though our model is finetuned with data that encourages a uniform prior over answer letters (by permuting which answer option letter is used with which lexical answer option text in training data), this may not be enough to ensure the model has no residual bias towards specific letters. Consider answers a, questions q and a nuisance variable z ? Z, which represents the ordering of the answer options or, equivalently, which answer letter gets assigned to which answer option text.</p><p>There are 4 answer options in MMLU, and thus |Z| = 24 unique ways they can be ordered, or assigned to given letters. Running our model with our standard inference for a question q, corresponds to calculating p(a|q = q, z = z) for the answer ordering z that happens to appear in the dataset. We can control for z by running the model with all possible answer orderings in the input, and marginalizing: p(a|q = q) = z ?Z p(a|q = q, z = z )p(z = z |q = q), and assuming p(z = z |q = q) is uniform (no answer ordering is more likely than another), this reduces to simply p(a|q = q) = z ?Z p(a|q = q, z = z ). This procedure requires 24 forward passes, one for each answer ordering, so is 24? slower than standard inference. <ref type="table" target="#tab_3">Table 13</ref> shows the result of applying the full permutation de-biasing, which leads to an 12% improvement zero-shot and 6% in 5-shot performance overall. Empirically, using only the cyclic permutations of the answer order provided in the original dataset (of which there are 4) works nearly as well, which is what we report in the main paper, and only increases inference compute by a factor of 4, rather than 24. Cyclic permutation de-biasing improves over standard inference by 10% in zero-shot and 5% in 5-shot. Empirically, de-biased inference is largely unnecessary when training in the 5-shot multitask or full dataset setting, as there is enough data for the model to learn a more uniform prior over the letters. Evaluation We evaluate by following the method of <ref type="bibr">Hendrycks et al. (2021)</ref>, namely, micro-averaging across all 57 domains to obtain overall accuracy. We quote the results of GPT3  and UnifiedQA <ref type="bibr" target="#b37">(Khashabi et al., 2020)</ref> from the MMLU leaderboard at https://github.com/hendrycks/test. For Chinchilla and Gopher, we calculate the scores on the categories using the full MMLU results from <ref type="bibr" target="#b25">Hoffmann et al. (2022)</ref>.</p><p>Index The index used for MMLU for all MMLU experiments in the main paper comprised of concatenation of the Wikipedia passages, Wikipedia info boxes and Common Crawl indices, for a total of 387M passages. We can assess the importance of the index by running a model without the common crawl data, leading to a 5-shot multitask result of 52.8%, compared to 56.4% for the full model, a drop of 3.6%. This indicates that whilst the Wikipedia data is sufficient do well on the task, the addition of the CC data improves results further.</p><p>Hyperparameters and development data Selecting hyperparameters is challenging in few-shot settings. We do not assume access to an in-domain development set for the 5-shot task. Instead, we determine a set of hyperparameters for the 5-shot task using data from RACE, one of the auxiliary datasets provided by MMLU. Here, we sample 5 sets of 5-shot training data, and for each model size, we explore batch size {32, 64}, learning rates for the language model and retriever {(5e-5, 1e-5), (4e-5, 4e-5)}, retriever temperature {0.1, 0.01} and a fixed number of training steps {16, 32, 64, 128}, picking the setting that achieves strongest RACE validation scores. Having determined these hyperparameters, we apply them directly to the 5-shot MMLU task. For the 5-shot multi-task and full/transfer settings, we use the same batch size, temperatures and learning rates as the 5-shot task, but use a set of 285 MMLU validation examples (5 per domain) in order to determine the total number of training steps and for early stopping. The hyperparameters selected in the MMLU experiments can be found in table 14. We use query-side finetuning for the 5-shot and 5-shot multitask settings, and top-128 reranking for the full setting. For all MMLU runs we retrieve 30 documents</p><p>Inter-run Variance few-shot learning is well-known to suffer from high variance. In the main paper, we quote the result obtained with our first run. In order to assess the effect of noise and variance, we ran the 5-shot experiment with Atlas 5 times. <ref type="bibr">7</ref> We observe high variance for individual domains, sometimes as high as 20%, however, once aggregated across all 57 domains, the inter-run variance is low. The overall scores for these different runs, when using the same hyperparameters are shown in table 15. Due the effects of averaging over the many domains that comprise MMLU, the inter-run variance is quite modest on the aggregated metrics, with a std deviation of 0.5 in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Closed-Book Baselines</head><p>The closed book baselines we compare Atlas to in table 5 are initialized from the same T5 model as their respective Atlas, and then pre-trained with MLM for the same number of steps (10K) using the same pre-training data as Atlas, for fairer comparison. The same procedure as for Atlas was used to determine hyperparameters for MMLU for the closed-book model.s Ave:</p><p>45.0 ? 0.5 40.5 ? 0.6 53.6 ? 1.6 37.4 ? 0.5 51.1 ? 0.8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 Full results</head><p>Tables 16 and 17 shows the full MMLU scores for each domain for Atlas and the closed book T5 respectively. The full results for the cyclic-permutation-de-biased Atlas-XXL can be found in <ref type="table" target="#tab_8">Table 18</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Question answering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Training Details</head><p>For question answering, similarly to the MMLU experiments, we format the input using the following template:</p><p>question: {question text} answer: <ref type="bibr">[MASK_0]</ref> and train the model to generate the mask token followed by the answer:</p><p>[MASK_0] {answer}.</p><p>We generate answers using greedy decoding. For both training and testing, we retrieve 40 passages, and truncate the result of the concatenation between the query and the passages to 384 tokens.</p><p>For few-shot fine-tuning we train Atlas for 30 steps using 64 random samples from the train sets. The retriever is trained using query-side fine-tuning. We select the model after 30 training steps. We use AdamW with a batch size of 32 and a learning rate of 4 ? 10 ?5 with linear decay and 5 iterations of warmup for both the language model and the retriever.</p><p>For the fine-tuning on the full datasets, we train the model for 5k gradient steps and refresh the index every 500 steps for the first 1,000 training steps and every 2k training steps afterwards. We use AdamW with a batch size of 64 and a learning rate of 4 ? 10 ?5 with linear decay and 5 iterations of warmup for both the language model and the retriever. We evaluate models every 500 steps and select the best one on the validation set based on the exact match score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Impact of scaling</head><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 KILT</head><p>For the results on KILT reported in <ref type="table" target="#tab_11">Table 10</ref> we fine-tune Atlas individually on each dataset. We format the input using a template similar to the one used for question answering:    and train the model to generate the mask token followed by the expected output:</p><p>[MASK_0] {output}.</p><p>We retrieve 20 passages and generate answer using greedy decoding. In KILT, FEVER is a two-way classification task of claims. We lexicalize the "SUPPORTS" (resp. 'REFUTES") label into "true" (respectively "false").</p><p>For few-shot fine-tuning we train Atlas for 30 steps using 64 random samples from the train sets. The retriever is trained using query-side fine-tuning. We evaluate models every 5 steps and select the best one on the development set based on the reported metric. We use AdamW with a batch size of 32 and a learning rate of 4 ? 10 ?5 with linear decay and 5 iterations of warmup for both the language model and the retriever.</p><p>For the fine-tuning on the full datasets, the model is trained for 5k gradient steps. We evaluate models every 500 steps and select the best one on the development set based on the reported metric. The index is refreshed every 500 step for the first 1000 iterations, and every 2k steps afterwards. We use AdamW with a batch size of 64 and a learning rate of 4 ? 10 ?5 with linear decay and 500 iterations of warmup for both the language model and the retriever.</p><p>We report results on the development sets in <ref type="table" target="#tab_2">Table 20</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Examples of query and output pairs for different tasks from KILT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>proposed to use cross-attention scores as supervision with knowledge distillation. Sachan et al. (2021) perform joint training of the reader and the retriever by leveraging the perplexity of the output generated by the reader. Sachan et al. (2021) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>1) [1, 2) [2, 4) [4, 8) [8, 16) [16, ?) Answer frequency in retrieved docs (interval) MMLU Retrieval Analysis. Left: Fraction of sources of top 30 retrieved passages for MMLU from CCNet, Wikipedia passages and info boxes for the 5-shot multitask Atlas. Center: How often the text of the correct MMLU answer option appears in retrieved passages, as a function of the number of retrieved passages. Right: MMLU accuracy as a function of answer occurrence frequency in retrieved passages set majority of its passages from CCNet (85% on average).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>question: {question text} options: (A) {answer 1 text} (B) {answer 2 text} (C) {answer 3 text} (D) {answer 4 text} answer: [MASK_0]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Task Query Output</head><label></label><figDesc>Checking Bermuda Triangle is in the western part of the Himalayas. False Question Answering who is playing the halftime show at super bowl 2016 Coldplay Entity Linking NTFS-3G is an open source &lt;E&gt;cross-platform&lt;/E&gt; implementation of the Microsoft Windows NTFS file system with read-write support.</figDesc><table><row><cell>Fact</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Pretext task ablation. We compare different pretext tasks, used to jointly pre-train our models. Examples are randomly sampled from the training set of the KILT version of the dataset. We report the exact match on NaturalQuestions, the F1 score on Wizard of Wikipedia and the accuracy on FEVER.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">64-shot</cell><cell></cell><cell></cell><cell cols="2">1024-shot</cell></row><row><cell></cell><cell cols="4">NQ WoW FEVER Avg.</cell><cell cols="4">NQ WoW FEVER Avg.</cell></row><row><cell>Prefix Language Modelling</cell><cell>41.0</cell><cell>14.5</cell><cell>64.9</cell><cell cols="2">40.1 44.7</cell><cell>17.9</cell><cell>86.0</cell><cell>49.5</cell></row><row><cell cols="3">Masked Language Modelling 42.7 14.9</cell><cell>69.7</cell><cell cols="3">42.4 44.7 18.3</cell><cell>88.8</cell><cell>50.6</cell></row><row><cell>Title-to-section generation</cell><cell>41.1</cell><cell>15.2</cell><cell>66.1</cell><cell cols="2">40.8 45.4</cell><cell>17.9</cell><cell>84.6</cell><cell>49.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Index content ablation. In this table, we report results for models where the content of the index was changed between the pre-training and the fine-tuning.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">64-shot</cell><cell></cell><cell></cell><cell cols="2">1024-shot</cell></row><row><cell cols="6">Index Training data NQ WoW FEVER Avg.</cell><cell cols="4">NQ WoW FEVER Avg.</cell></row><row><cell>Wiki</cell><cell>Wiki</cell><cell>42.7</cell><cell>14.9</cell><cell>69.7</cell><cell cols="2">42.4 44.7</cell><cell>18.3</cell><cell>88.8</cell><cell>50.6</cell></row><row><cell>Wiki</cell><cell>CC</cell><cell>40.9</cell><cell>15.3</cell><cell>67.3</cell><cell cols="3">41.2 44.8 18.4</cell><cell>88.1</cell><cell>50.4</cell></row><row><cell>CC</cell><cell>Wiki</cell><cell>32.9</cell><cell>14.5</cell><cell>72.1</cell><cell cols="2">39.8 37.8</cell><cell>17.1</cell><cell>85.8</cell><cell>46.9</cell></row><row><cell>CC</cell><cell>CC</cell><cell>38.4</cell><cell>14.9</cell><cell>70.1</cell><cell cols="2">41.1 42.0</cell><cell>17.3</cell><cell>88.9</cell><cell>49.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Retriever fine-tuning ablation. Here, we compare different strategies to fine-tune the retriever in a few-shot setting.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">64-shot</cell><cell></cell><cell></cell><cell cols="2">1024-shot</cell></row><row><cell></cell><cell cols="4">NQ WoW FEVER Avg.</cell><cell cols="4">NQ WoW FEVER Avg.</cell></row><row><cell>Standard fine-tuning</cell><cell>44.3</cell><cell>14.9</cell><cell>73.2</cell><cell cols="2">44.1 47.0</cell><cell>18.4</cell><cell>89.7</cell><cell>51.7</cell></row><row><cell>Top-100 re-ranking</cell><cell>44.2</cell><cell>14.6</cell><cell>75.4</cell><cell cols="3">44.7 47.1 18.7</cell><cell>88.9</cell><cell>51.6</cell></row><row><cell cols="3">Query-side fine-tuning 45.0 15.0</cell><cell>77.0</cell><cell cols="2">45.7 44.9</cell><cell>17.9</cell><cell>90.2</cell><cell>51.0</cell></row><row><cell>Fixed retriever</cell><cell>36.8</cell><cell>14.5</cell><cell>72.0</cell><cell cols="2">41.1 38.0</cell><cell>17.7</cell><cell>89.3</cell><cell>48.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 : Performance on MMLU as a function of model size.</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>5-shot</cell><cell></cell><cell cols="3">5-shot (multi-task)</cell><cell cols="3">Full / Transfer</cell></row><row><cell></cell><cell>770M</cell><cell>3B</cell><cell cols="2">11B 770M</cell><cell>3B</cell><cell>11B</cell><cell>770M</cell><cell>3B</cell><cell>11B</cell></row><row><cell>Closed-book T5</cell><cell>29.2</cell><cell cols="2">35.7 36.1</cell><cell>26.5</cell><cell>40.0</cell><cell>43.5</cell><cell>42.4</cell><cell>50.4</cell><cell>54.0</cell></row><row><cell>Atlas</cell><cell>38.9</cell><cell cols="2">42.3 43.4</cell><cell>42.1</cell><cell>48.7</cell><cell>56.4</cell><cell>56.3</cell><cell>59.9</cell><cell>65.8</cell></row><row><cell>?</cell><cell cols="9">+9.8 +6.6 +7.3 +15.6 +8.7 +12.9 +13.9 +9.5 +11.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Standard vs de-biased inference for MMLU These results are reported for Atlas-11B, using cyclic permutations for de-biasing, which increases inference costs by a factor of 4?.</figDesc><table><row><cell></cell><cell cols="4">Zero-shot 5-shot 5-shot (multi-task) Full / Transfer</cell></row><row><cell>Standard Inference</cell><cell>36.8</cell><cell>43.4</cell><cell>56.4</cell><cell>65.8</cell></row><row><cell>De-biased Inference</cell><cell>47.1</cell><cell>47.9</cell><cell>56.6</cell><cell>66.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>For the 5-shot setting, Atlas uses fine-tuning, while previous works use in-context learning. The Atlas model uses de-biased inference. Train FLOPS refers to total the amount of computation necessary to train the model, including pre-training and/or fine-tuning.</figDesc><table><row><cell>Setting</cell><cell>Model</cell><cell cols="2">Params Train FLOPS</cell><cell>All</cell><cell cols="4">Hum. Soc. Sci. STEM Other</cell></row><row><cell>zero-shot</cell><cell>Atlas</cell><cell>11B</cell><cell>3.5e22</cell><cell>47.1</cell><cell>43.6</cell><cell>54.1</cell><cell>38.0</cell><cell>54.4</cell></row><row><cell></cell><cell>GPT-3</cell><cell>175B</cell><cell>3.1e23</cell><cell>43.9</cell><cell>40.8</cell><cell>50.4</cell><cell>36.7</cell><cell>48.8</cell></row><row><cell>5-shot</cell><cell>Gopher Chinchilla</cell><cell>280B 70B</cell><cell>5.0e23 5.0e23</cell><cell>60.0 67.5</cell><cell>56.2 63.6</cell><cell>71.9 79.3</cell><cell>47.4 55.0</cell><cell>66.1 73.9</cell></row><row><cell></cell><cell>Atlas  *</cell><cell>11B</cell><cell>3.5e22</cell><cell>47.9</cell><cell>46.1</cell><cell>54.6</cell><cell>38.8</cell><cell>52.8</cell></row><row><cell cols="2">5-shot (multi-task) Atlas</cell><cell>11B</cell><cell>3.5e22</cell><cell>56.6</cell><cell>50.1</cell><cell>66.4</cell><cell>46.4</cell><cell>66.2</cell></row><row><cell></cell><cell>UnifiedQA</cell><cell>11B</cell><cell>3.3e22</cell><cell>48.9</cell><cell>45.6</cell><cell>56.6</cell><cell>40.2</cell><cell>54.6</cell></row><row><cell>Full / Transfer</cell><cell>GPT-3</cell><cell>175B</cell><cell>3.1e23</cell><cell>53.9</cell><cell>52.5</cell><cell>63.9</cell><cell>41.4</cell><cell>57.9</cell></row><row><cell></cell><cell>Atlas</cell><cell>11B</cell><cell>3.5e22</cell><cell>66.0</cell><cell>61.1</cell><cell>77.2</cell><cell>53.2</cell><cell>74.4</cell></row></table><note>Comparison to state-of-the-art on MMLU.*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table><row><cell>NQ</cell><cell>TriviaQA filtered TriviaQA unfiltered</cell></row></table><note>Comparison to state-of-the-art on question answering. We report results on NaturalQues- tions, and on TriviaQA for both the filtered set, commonly used for open-domain question answering and the unfiltered hidden set for which evaluation is accessible online: https://competitions.codalab.org/ competitions/17208. For the 64-shot setting, our model uses fine-tuning, while the other models use prompting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>280B per test-time question. Atlas, using the same 15 training examples and 50 passages achieves 38.7 EM, despite having 25? fewer parameters, and requiring comparatively negligible compute.</figDesc><table><row><cell>or a more expensive approach. This method (not shown in our tables) achieves</cell></row><row><cell>exact match scores of 32.7% (RAG) and 38.4% (Ensemble), requiring 50 (RAG) or 450 (Ensemble) forward</cell></row><row><cell>passes of Gopher-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Comparison We report accuracy on FEVER test set, for which evaluation is available here: https://competitions.codalab.org/competitions/18814. For the few-shot settings, our model uses fine-tuning while other models use prompting. ? uses an index composed of the FEVER Wikipedia corpus.</figDesc><table /><note>to state-of-the-art on FEVER.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 : Downstream results on the KILT hidden test sets</head><label>10</label><figDesc>Atlas scores 56.2%, outperforming Gopher by 5.1 points. Lastly we fine-tune our model on the full training set, and achieve a score of 78%, within 1.5% of the ProoFVer, which uses a specialized architecture, a retriever trained with sentence-level annotations, and is supplied with the Wikipedia corpus released with FEVER, whereas Atlas retrieves from CCNet and the December 2021 Wikipedia dump. If we give Atlas an index comprised of the FEVER Wikipedia corpus, we set a new state-of-the-art of 80.1%</figDesc><table><row><cell>Downstream metrics are accuracy (AIDA</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Results on our TempLAMA-derived dataset. We report performance for a static, closed-book T5-11B, as well as Atlas-11B supplied with a test-time Wikipedia index from 2017 or 2020. We evaluate models finetuned on a small training set of 248 time-sensitive cloze-question-answer pairs, using answers either from 2017 or 2020. Good models should score highly when the test set year matches the year of the test-time index, and score low otherwise.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">2017 Test Set Acc.</cell><cell cols="2">2020 Test Set Acc.</cell></row><row><cell>Train Set</cell><cell cols="5">Test-time Index Closed-book Atlas Closed-book Atlas</cell></row><row><cell>2017 answers</cell><cell>2017 2020</cell><cell>12.1 12.1</cell><cell>57.7 10.2</cell><cell>2.9 2.9</cell><cell>1.5 53.1</cell></row><row><cell>2020 answers</cell><cell>2017 2020</cell><cell>4.8 4.8</cell><cell>50.1 3.5</cell><cell>3.6 3.6</cell><cell>4.2 60.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Impact of index data temporality on NaturalQuestions. We report exact match performance on NaturalQuestions using different Wikipedia dumps in the index. We observe that the dump from December 2018, commonly used for NaturalQuestions, leads to the best result.</figDesc><table><row><cell></cell><cell cols="5">Dec. 2017 Dec. 2018 Aug. 2019 Dec. 2020 Dec. 2021</cell></row><row><cell>64-shot</cell><cell>44.7</cell><cell>45.1</cell><cell>44.1</cell><cell>44.0</cell><cell>41.3</cell></row><row><cell>Full</cell><cell>63.2</cell><cell>64.0</cell><cell>62.4</cell><cell>61.1</cell><cell>59.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13 :</head><label>13</label><figDesc>MMLU scores with de-biasing:</figDesc><table><row><cell>Setting</cell><cell>Model</cell><cell>All</cell><cell cols="4">Hum. Soc. Sci. STEM Other</cell></row><row><cell></cell><cell>Standard</cell><cell>36.8</cell><cell>37.5</cell><cell>39.0</cell><cell>30.2</cell><cell>39.7</cell></row><row><cell>zero-shot</cell><cell>All permutations</cell><cell>48.5</cell><cell>45.7</cell><cell>55.2</cell><cell>39.4</cell><cell>54.4</cell></row><row><cell></cell><cell>Cyclic Permutations</cell><cell>47.1</cell><cell>43.6</cell><cell>54.1</cell><cell>38.0</cell><cell>54.9</cell></row><row><cell></cell><cell>Standard</cell><cell>43.39</cell><cell>41.8</cell><cell>49.3</cell><cell>33.9</cell><cell>48.8</cell></row><row><cell>5-shot</cell><cell>All permutations</cell><cell>49.0</cell><cell>46</cell><cell>56.1</cell><cell>40.5</cell><cell>54.6</cell></row><row><cell></cell><cell>Cyclic Permutations</cell><cell>47.9</cell><cell>46.1</cell><cell>54.6</cell><cell>38.8</cell><cell>52.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 14</head><label>14</label><figDesc></figDesc><table><row><cell cols="3">: Hyperparameters for MMLU</cell><cell></cell></row><row><cell></cell><cell>770M</cell><cell>3B</cell><cell>11B</cell></row><row><cell>Batch size</cell><cell>64</cell><cell>64</cell><cell>64</cell></row><row><cell>Learning rate</cell><cell cols="3">(5e-5, 1e-5) (5e-5, 1e-5) (5e-5, 1e-5)</cell></row><row><cell>Retriever Temperature</cell><cell>0.1</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>5-shot train steps</cell><cell>64</cell><cell>32</cell><cell>16</cell></row><row><cell>5-shot (multitask) max train steps</cell><cell>2000</cell><cell>500</cell><cell>250</cell></row><row><cell>Full / transfer max train steps</cell><cell>5000</cell><cell>2000</cell><cell>2000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 15 :</head><label>15</label><figDesc>Interrun Variance for 5-shot MMLU using Atlas-11B</figDesc><table><row><cell>Run #</cell><cell>All</cell><cell>Hum.</cell><cell>Soc. Sci.</cell><cell>STEM</cell><cell>Other</cell></row><row><cell>1</cell><cell>45.2</cell><cell>40.6</cell><cell>54.1</cell><cell>37.1</cell><cell>51.1</cell></row><row><cell>2</cell><cell>45.1</cell><cell>39.8</cell><cell>54.4</cell><cell>37.1</cell><cell>52.0</cell></row><row><cell>3</cell><cell>45.0</cell><cell>40.0</cell><cell>54.1</cell><cell>37.7</cell><cell>51.1</cell></row><row><cell>4</cell><cell>45.6</cell><cell>41.3</cell><cell>54.7</cell><cell>37.0</cell><cell>51.6</cell></row><row><cell>5</cell><cell>44.3</cell><cell>40.6</cell><cell>50.7</cell><cell>38.1</cell><cell>49.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 19</head><label>19</label><figDesc>, we report performance on NaturalQuestions and TriviaQA as a function of the number of parameters in the reader module. Both for few-shot learning and full fine-tuning we observe strong improvements by scaling the size of the reader module. However we can notice sign of saturation when finetuning on full datasets, with limited gains when scaling from 3B to 11B parameters (+0.6% on NaturalQuestions, +0.5% on TriviaQA). While performance improves substantially when scaling from 3B to 11B parameters with 64 training samples, with +3.7% and 1.2% improvement on NaturalQuestions and TriviaQA respectively. For these experiments we use a setup similar to the one use inTable 8, except that we use an index composed of the December 2018 Wikipedia dump processed as described in section 4.2.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 16 :</head><label>16</label><figDesc>MMLU Test set scores for Atlas for each model size and each of the 57 domains</figDesc><table><row><cell></cell><cell></cell><cell>5-shot</cell><cell></cell><cell cols="3">5-shot (multi-task)</cell><cell>Full / Transfer</cell></row><row><cell></cell><cell cols="2">770M 3B</cell><cell cols="3">11B 770M 3B</cell><cell cols="2">11B 770M 3B</cell><cell>11B</cell></row><row><cell>All</cell><cell>38.9</cell><cell cols="2">42.3 43.4</cell><cell>42.1</cell><cell cols="2">48.7 56.4</cell><cell>56.3</cell><cell>59.9 65.8</cell></row><row><cell>Humanities</cell><cell>37.3</cell><cell cols="2">40.0 41.9</cell><cell>37.7</cell><cell cols="2">46.4 50.0</cell><cell>50.9</cell><cell>53.0 60.3</cell></row><row><cell>Social Sciences</cell><cell>41.7</cell><cell cols="2">46.8 49.3</cell><cell>47.5</cell><cell cols="2">53.7 65.6</cell><cell>66.0</cell><cell>70.8 77.2</cell></row><row><cell>STEM</cell><cell>32.3</cell><cell cols="2">35.0 33.9</cell><cell>34.4</cell><cell cols="2">39.4 46.2</cell><cell>44.8</cell><cell>50.7 53.4</cell></row><row><cell>Other</cell><cell>44.9</cell><cell cols="2">48.1 48.8</cell><cell>50.4</cell><cell cols="2">55.9 66.6</cell><cell>65.5</cell><cell>68.1 74.4</cell></row><row><cell>abstract algebra</cell><cell>30.0</cell><cell cols="2">27.0 28.0</cell><cell>27.0</cell><cell cols="2">31.0 30.0</cell><cell>22.0</cell><cell>27.0 33.0</cell></row><row><cell>anatomy</cell><cell>28.9</cell><cell cols="2">50.4 45.2</cell><cell>44.4</cell><cell cols="2">57.8 64.4</cell><cell>57.8</cell><cell>68.9 69.6</cell></row><row><cell>astronomy</cell><cell>55.3</cell><cell cols="2">59.9 59.2</cell><cell>52.6</cell><cell cols="2">66.4 67.8</cell><cell>69.1</cell><cell>78.3 79.6</cell></row><row><cell>business ethics</cell><cell>49.0</cell><cell cols="2">51.0 48.0</cell><cell>50.0</cell><cell cols="2">62.0 60.0</cell><cell>51.0</cell><cell>70.0 68.0</cell></row><row><cell>clinical knowledge</cell><cell>41.9</cell><cell cols="2">44.9 40.0</cell><cell>46.8</cell><cell cols="2">54.3 64.9</cell><cell>64.2</cell><cell>72.5 74.0</cell></row><row><cell>college biology</cell><cell>38.2</cell><cell cols="2">45.8 50.0</cell><cell>36.8</cell><cell cols="2">52.1 63.2</cell><cell>63.2</cell><cell>72.2 78.5</cell></row><row><cell>college chemistry</cell><cell>32.0</cell><cell cols="2">29.0 29.0</cell><cell>31.0</cell><cell cols="2">33.0 38.0</cell><cell>45.0</cell><cell>39.0 45.0</cell></row><row><cell>college computer science</cell><cell>33.0</cell><cell cols="2">35.0 30.0</cell><cell>23.0</cell><cell cols="2">29.0 30.0</cell><cell>43.0</cell><cell>48.0 47.0</cell></row><row><cell>college mathematics</cell><cell>31.0</cell><cell cols="2">31.0 28.0</cell><cell>29.0</cell><cell cols="2">27.0 34.0</cell><cell>32.0</cell><cell>29.0 36.0</cell></row><row><cell>college medicine</cell><cell>31.2</cell><cell cols="2">35.8 38.2</cell><cell>50.3</cell><cell cols="2">40.5 52.0</cell><cell>60.1</cell><cell>59.5 63.6</cell></row><row><cell>college physics</cell><cell>20.6</cell><cell cols="2">26.5 31.4</cell><cell>21.6</cell><cell cols="2">28.4 39.2</cell><cell>27.5</cell><cell>44.1 42.2</cell></row><row><cell>computer security</cell><cell>53.0</cell><cell cols="2">50.0 55.0</cell><cell>49.0</cell><cell cols="2">61.0 64.0</cell><cell>69.0</cell><cell>71.0 76.0</cell></row><row><cell>conceptual physics</cell><cell>34.9</cell><cell cols="2">41.7 37.4</cell><cell>40.9</cell><cell cols="2">43.4 57.0</cell><cell>53.2</cell><cell>58.3 59.6</cell></row><row><cell>econometrics</cell><cell>28.9</cell><cell cols="2">21.1 27.2</cell><cell>26.3</cell><cell cols="2">25.4 34.2</cell><cell>28.9</cell><cell>37.7 36.8</cell></row><row><cell>electrical engineering</cell><cell>26.9</cell><cell cols="2">31.7 31.7</cell><cell>38.6</cell><cell cols="2">44.1 51.7</cell><cell>61.4</cell><cell>60.7 67.6</cell></row><row><cell>elementary mathematics</cell><cell>25.9</cell><cell cols="2">28.8 29.4</cell><cell>29.6</cell><cell cols="2">30.2 32.8</cell><cell>29.6</cell><cell>35.5 33.9</cell></row><row><cell>formal logic</cell><cell>34.9</cell><cell cols="2">33.3 33.3</cell><cell>23.0</cell><cell cols="2">30.2 29.4</cell><cell>34.1</cell><cell>38.9 34.1</cell></row><row><cell>global facts</cell><cell>28.0</cell><cell cols="2">34.0 34.0</cell><cell>36.0</cell><cell cols="2">40.0 49.0</cell><cell>50.0</cell><cell>49.0 52.0</cell></row><row><cell>high school biology</cell><cell>24.8</cell><cell cols="2">37.7 27.7</cell><cell>48.7</cell><cell cols="2">57.1 66.5</cell><cell>66.5</cell><cell>76.8 81.9</cell></row><row><cell>high school chemistry</cell><cell>34.5</cell><cell cols="2">31.0 31.0</cell><cell>31.5</cell><cell cols="2">36.5 48.3</cell><cell>44.8</cell><cell>52.2 52.2</cell></row><row><cell>high school computer science</cell><cell>31.0</cell><cell cols="2">39.0 28.0</cell><cell>37.0</cell><cell cols="2">42.0 42.0</cell><cell>50.0</cell><cell>59.0 57.0</cell></row><row><cell>high school european history</cell><cell>42.4</cell><cell cols="2">49.7 53.3</cell><cell>50.9</cell><cell cols="2">58.2 69.7</cell><cell>70.9</cell><cell>73.9 80.0</cell></row><row><cell>high school geography</cell><cell>38.9</cell><cell cols="2">42.4 50.0</cell><cell>46.5</cell><cell cols="2">56.6 69.2</cell><cell>74.2</cell><cell>80.8 82.8</cell></row><row><cell>high school gov. and pol.</cell><cell>57.5</cell><cell cols="2">60.6 60.1</cell><cell>52.9</cell><cell cols="2">64.8 76.7</cell><cell>80.8</cell><cell>85.5 91.7</cell></row><row><cell>high school macroeconomics</cell><cell>32.8</cell><cell cols="2">39.7 44.9</cell><cell>39.0</cell><cell cols="2">45.6 57.2</cell><cell>55.1</cell><cell>63.1 66.7</cell></row><row><cell>high school mathematics</cell><cell>30.7</cell><cell cols="2">33.0 35.6</cell><cell>28.1</cell><cell cols="2">27.8 37.0</cell><cell>30.7</cell><cell>34.8 37.0</cell></row><row><cell>high school microeconomics</cell><cell>34.5</cell><cell cols="2">42.9 45.4</cell><cell>44.1</cell><cell cols="2">51.7 68.9</cell><cell>63.4</cell><cell>70.2 81.1</cell></row><row><cell>high school physics</cell><cell>18.5</cell><cell cols="2">24.5 22.5</cell><cell>25.8</cell><cell cols="2">25.8 33.1</cell><cell>27.2</cell><cell>30.5 39.7</cell></row><row><cell>high school psychology</cell><cell>52.8</cell><cell cols="2">61.1 59.8</cell><cell>56.7</cell><cell cols="2">67.2 79.4</cell><cell>76.3</cell><cell>84.0 87.0</cell></row><row><cell>high school statistics</cell><cell>39.8</cell><cell cols="2">29.6 34.7</cell><cell>27.3</cell><cell cols="2">34.7 38.0</cell><cell>37.0</cell><cell>43.1 45.8</cell></row><row><cell>high school us history</cell><cell>43.6</cell><cell cols="2">49.0 55.9</cell><cell>46.1</cell><cell cols="2">57.8 59.8</cell><cell>62.7</cell><cell>72.5 76.5</cell></row><row><cell>high school world history</cell><cell>48.1</cell><cell cols="2">52.7 59.9</cell><cell>48.1</cell><cell cols="2">66.2 65.4</cell><cell>70.0</cell><cell>78.5 79.7</cell></row><row><cell>human aging</cell><cell>46.2</cell><cell cols="2">44.8 39.5</cell><cell>48.0</cell><cell cols="2">55.2 60.1</cell><cell>56.1</cell><cell>68.2 73.1</cell></row><row><cell>human sexuality</cell><cell>41.2</cell><cell cols="2">43.5 27.5</cell><cell>46.6</cell><cell cols="2">51.1 59.5</cell><cell>77.1</cell><cell>72.5 81.7</cell></row><row><cell>international law</cell><cell>54.5</cell><cell cols="2">57.9 60.3</cell><cell>55.4</cell><cell cols="2">72.7 73.6</cell><cell>81.8</cell><cell>82.6 85.1</cell></row><row><cell>jurisprudence</cell><cell>38.9</cell><cell cols="2">55.6 32.4</cell><cell>53.7</cell><cell cols="2">60.2 73.1</cell><cell>76.9</cell><cell>73.1 81.5</cell></row><row><cell>logical fallacies</cell><cell>43.6</cell><cell cols="2">54.0 57.1</cell><cell>44.2</cell><cell cols="2">58.3 70.6</cell><cell>64.4</cell><cell>73.0 76.7</cell></row><row><cell>machine learning</cell><cell>36.6</cell><cell cols="2">34.8 28.6</cell><cell>31.3</cell><cell cols="2">37.5 46.4</cell><cell>36.6</cell><cell>47.3 50.9</cell></row><row><cell>management</cell><cell>45.6</cell><cell cols="2">51.5 52.4</cell><cell>48.5</cell><cell cols="2">52.4 81.6</cell><cell>78.6</cell><cell>75.7 87.4</cell></row><row><cell>marketing</cell><cell>59.4</cell><cell cols="2">67.1 70.5</cell><cell>66.7</cell><cell cols="2">74.4 83.8</cell><cell>83.8</cell><cell>83.3 91.9</cell></row><row><cell>medical genetics</cell><cell>50.0</cell><cell cols="2">53.0 58.0</cell><cell>56.0</cell><cell cols="2">61.0 75.0</cell><cell>68.0</cell><cell>78.0 81.0</cell></row><row><cell>miscellaneous</cell><cell>63.0</cell><cell cols="2">64.2 68.8</cell><cell>64.0</cell><cell cols="2">72.4 84.3</cell><cell>85.4</cell><cell>83.9 90.9</cell></row><row><cell>moral disputes</cell><cell>37.0</cell><cell cols="2">41.3 41.3</cell><cell>40.8</cell><cell cols="2">50.3 60.1</cell><cell>61.9</cell><cell>66.2 73.7</cell></row><row><cell>moral scenarios</cell><cell>24.7</cell><cell cols="2">24.7 26.5</cell><cell>21.9</cell><cell cols="2">26.9 26.6</cell><cell>23.8</cell><cell>23.8 35.8</cell></row><row><cell>nutrition</cell><cell>40.9</cell><cell cols="2">45.1 45.1</cell><cell>49.0</cell><cell cols="2">52.3 67.0</cell><cell>64.7</cell><cell>68.6 76.8</cell></row><row><cell>philosophy</cell><cell>48.6</cell><cell cols="2">50.5 56.3</cell><cell>49.8</cell><cell cols="2">59.2 69.5</cell><cell>70.4</cell><cell>73.0 77.8</cell></row><row><cell>prehistory</cell><cell>45.7</cell><cell cols="2">50.0 52.8</cell><cell>54.9</cell><cell cols="2">64.8 74.4</cell><cell>69.8</cell><cell>75.0 80.6</cell></row><row><cell>professional accounting</cell><cell>28.4</cell><cell cols="2">33.0 34.0</cell><cell>35.1</cell><cell cols="2">34.0 45.7</cell><cell>43.6</cell><cell>46.1 51.8</cell></row><row><cell>professional law</cell><cell>32.4</cell><cell cols="2">33.5 34.8</cell><cell>30.4</cell><cell cols="2">37.6 39.1</cell><cell>41.5</cell><cell>41.5 50.5</cell></row><row><cell>professional medicine</cell><cell>29.4</cell><cell cols="2">26.1 27.6</cell><cell>34.6</cell><cell cols="2">40.8 52.2</cell><cell>47.8</cell><cell>43.4 59.6</cell></row><row><cell>professional psychology</cell><cell>37.7</cell><cell cols="2">43.0 50.2</cell><cell>45.1</cell><cell cols="2">51.0 60.6</cell><cell>59.5</cell><cell>62.4 74.0</cell></row><row><cell>public relations</cell><cell>40.0</cell><cell cols="2">46.4 44.5</cell><cell>51.8</cell><cell cols="2">54.5 66.4</cell><cell>63.6</cell><cell>66.4 68.2</cell></row><row><cell>security studies</cell><cell>35.1</cell><cell cols="2">33.5 38.8</cell><cell>44.1</cell><cell cols="2">39.6 57.6</cell><cell>60.8</cell><cell>61.6 72.2</cell></row><row><cell>sociology</cell><cell>45.3</cell><cell cols="2">51.2 51.2</cell><cell>52.7</cell><cell cols="2">60.2 69.2</cell><cell>74.1</cell><cell>78.6 85.1</cell></row><row><cell>us foreign policy</cell><cell>58.0</cell><cell cols="2">70.0 73.0</cell><cell>63.0</cell><cell cols="2">63.0 74.0</cell><cell>80.0</cell><cell>80.0 83.0</cell></row><row><cell>virology</cell><cell>34.3</cell><cell cols="2">34.3 32.5</cell><cell>38.0</cell><cell cols="2">42.8 45.2</cell><cell>47.6</cell><cell>49.4 53.0</cell></row><row><cell>world religions</cell><cell>65.5</cell><cell cols="2">69.0 71.9</cell><cell>70.2</cell><cell cols="2">82.5 80.1</cell><cell>83.6</cell><cell>83.6 87.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 17 :</head><label>17</label><figDesc>MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57 domains</figDesc><table><row><cell></cell><cell></cell><cell>5-shot</cell><cell></cell><cell cols="3">5-shot (multi-task)</cell><cell>Full / Transfer</cell></row><row><cell></cell><cell cols="2">770M 3B</cell><cell cols="3">11B 770M 3B</cell><cell cols="2">11B 770M 3B</cell><cell>11B</cell></row><row><cell>All</cell><cell>29.2</cell><cell cols="2">35.7 36.1</cell><cell>26.5</cell><cell cols="2">40.0 43.5</cell><cell>42.4</cell><cell>50.4 54.0</cell></row><row><cell>Humanities</cell><cell>30.5</cell><cell cols="2">35.4 35.5</cell><cell>27.3</cell><cell cols="2">38.5 41.6</cell><cell>41.0</cell><cell>48.6 51.3</cell></row><row><cell>Social Sciences</cell><cell>29.7</cell><cell cols="2">38.0 39.4</cell><cell>24.8</cell><cell cols="2">43.8 48.9</cell><cell>48.6</cell><cell>57.8 64.7</cell></row><row><cell>STEM</cell><cell>29.0</cell><cell cols="2">31.4 30.8</cell><cell>26.5</cell><cell cols="2">32.8 35.8</cell><cell>33.4</cell><cell>40.6 41.7</cell></row><row><cell>Other</cell><cell>26.7</cell><cell cols="2">37.7 38.6</cell><cell>27.0</cell><cell cols="2">45.0 48.5</cell><cell>46.8</cell><cell>55.2 59.1</cell></row><row><cell>abstract algebra</cell><cell>26.0</cell><cell cols="2">23.0 21.0</cell><cell>29.0</cell><cell cols="2">30.0 26.0</cell><cell>23.0</cell><cell>29.0 26.0</cell></row><row><cell>anatomy</cell><cell>21.5</cell><cell cols="2">40.0 40.7</cell><cell>27.4</cell><cell cols="2">39.3 45.9</cell><cell>35.6</cell><cell>43.7 42.2</cell></row><row><cell>astronomy</cell><cell>37.5</cell><cell cols="2">38.8 37.5</cell><cell>27.6</cell><cell cols="2">39.5 41.4</cell><cell>36.2</cell><cell>50.7 55.3</cell></row><row><cell>business ethics</cell><cell>29.0</cell><cell cols="2">54.0 42.0</cell><cell>26.0</cell><cell cols="2">47.0 55.0</cell><cell>53.0</cell><cell>64.0 60.0</cell></row><row><cell>clinical knowledge</cell><cell>32.5</cell><cell cols="2">33.6 40.0</cell><cell>28.7</cell><cell cols="2">44.2 47.9</cell><cell>45.3</cell><cell>52.8 57.7</cell></row><row><cell>college biology</cell><cell>29.9</cell><cell cols="2">34.7 34.0</cell><cell>29.9</cell><cell cols="2">34.7 40.3</cell><cell>38.2</cell><cell>46.5 52.1</cell></row><row><cell>college chemistry</cell><cell>37.0</cell><cell cols="2">22.0 32.0</cell><cell>20.0</cell><cell cols="2">35.0 33.0</cell><cell>36.0</cell><cell>34.0 36.0</cell></row><row><cell>college computer science</cell><cell>28.0</cell><cell cols="2">35.0 34.0</cell><cell>28.0</cell><cell cols="2">27.0 36.0</cell><cell>31.0</cell><cell>44.0 35.0</cell></row><row><cell>college mathematics</cell><cell>31.0</cell><cell cols="2">29.0 27.0</cell><cell>22.0</cell><cell cols="2">34.0 27.0</cell><cell>30.0</cell><cell>33.0 32.0</cell></row><row><cell>college medicine</cell><cell>24.3</cell><cell cols="2">34.7 34.1</cell><cell>27.2</cell><cell cols="2">40.5 40.5</cell><cell>35.8</cell><cell>41.6 48.6</cell></row><row><cell>college physics</cell><cell>33.3</cell><cell cols="2">23.5 23.5</cell><cell>22.5</cell><cell cols="2">19.6 26.5</cell><cell>22.5</cell><cell>32.4 24.5</cell></row><row><cell>computer security</cell><cell>36.0</cell><cell cols="2">42.0 46.0</cell><cell>31.0</cell><cell cols="2">49.0 52.0</cell><cell>50.0</cell><cell>65.0 61.0</cell></row><row><cell>conceptual physics</cell><cell>26.4</cell><cell cols="2">35.7 30.2</cell><cell>23.4</cell><cell cols="2">30.6 32.8</cell><cell>34.5</cell><cell>37.4 43.8</cell></row><row><cell>econometrics</cell><cell>26.3</cell><cell cols="2">21.9 28.9</cell><cell>17.5</cell><cell cols="2">19.3 24.6</cell><cell>29.8</cell><cell>25.4 29.8</cell></row><row><cell>electrical engineering</cell><cell>31.0</cell><cell cols="2">33.1 31.7</cell><cell>31.0</cell><cell cols="2">31.0 36.6</cell><cell>41.4</cell><cell>47.6 51.7</cell></row><row><cell>elementary mathematics</cell><cell>26.2</cell><cell cols="2">27.5 28.0</cell><cell>27.0</cell><cell cols="2">31.2 33.3</cell><cell>25.9</cell><cell>31.2 35.5</cell></row><row><cell>formal logic</cell><cell>34.1</cell><cell cols="2">34.1 31.7</cell><cell>15.1</cell><cell cols="2">34.9 31.0</cell><cell>31.7</cell><cell>38.1 42.1</cell></row><row><cell>global facts</cell><cell>32.0</cell><cell cols="2">30.0 25.0</cell><cell>34.0</cell><cell cols="2">34.0 27.0</cell><cell>28.0</cell><cell>34.0 30.0</cell></row><row><cell>high school biology</cell><cell>22.6</cell><cell cols="2">31.9 29.7</cell><cell>27.1</cell><cell cols="2">41.6 50.0</cell><cell>43.5</cell><cell>57.7 60.6</cell></row><row><cell>high school chemistry</cell><cell>27.1</cell><cell cols="2">26.6 27.6</cell><cell>28.6</cell><cell cols="2">31.5 29.1</cell><cell>30.5</cell><cell>36.5 38.9</cell></row><row><cell>high school computer science</cell><cell>26.0</cell><cell cols="2">32.0 25.0</cell><cell>33.0</cell><cell cols="2">37.0 45.0</cell><cell>45.0</cell><cell>55.0 48.0</cell></row><row><cell>high school european history</cell><cell>34.5</cell><cell cols="2">43.0 42.4</cell><cell>24.2</cell><cell cols="2">60.0 59.4</cell><cell>58.2</cell><cell>69.1 76.4</cell></row><row><cell>high school geography</cell><cell>31.3</cell><cell cols="2">40.4 36.9</cell><cell>24.7</cell><cell cols="2">45.5 50.5</cell><cell>56.1</cell><cell>66.7 74.2</cell></row><row><cell>high school gov. and pol.</cell><cell>28.0</cell><cell cols="2">49.2 51.3</cell><cell>19.2</cell><cell cols="2">56.0 59.6</cell><cell>55.4</cell><cell>70.5 75.6</cell></row><row><cell>high school macroeconomics</cell><cell>25.6</cell><cell cols="2">37.7 32.1</cell><cell>26.7</cell><cell cols="2">42.3 43.6</cell><cell>41.0</cell><cell>51.5 56.4</cell></row><row><cell>high school mathematics</cell><cell>35.9</cell><cell cols="2">35.2 35.9</cell><cell>28.1</cell><cell cols="2">26.7 31.1</cell><cell>27.8</cell><cell>36.7 31.9</cell></row><row><cell>high school microeconomics</cell><cell>27.3</cell><cell cols="2">29.8 36.1</cell><cell>20.6</cell><cell cols="2">35.7 42.9</cell><cell>42.9</cell><cell>50.8 60.5</cell></row><row><cell>high school physics</cell><cell>21.9</cell><cell cols="2">25.2 22.5</cell><cell>24.5</cell><cell cols="2">28.5 29.1</cell><cell>27.8</cell><cell>31.1 27.8</cell></row><row><cell>high school psychology</cell><cell>26.1</cell><cell cols="2">46.4 51.0</cell><cell>24.8</cell><cell cols="2">54.3 60.2</cell><cell>56.3</cell><cell>67.3 76.1</cell></row><row><cell>high school statistics</cell><cell>27.8</cell><cell cols="2">33.3 33.3</cell><cell>17.6</cell><cell cols="2">30.6 33.8</cell><cell>32.9</cell><cell>33.3 37.0</cell></row><row><cell>high school us history</cell><cell>30.4</cell><cell cols="2">39.7 45.6</cell><cell>27.5</cell><cell cols="2">46.1 58.3</cell><cell>51.0</cell><cell>63.2 72.5</cell></row><row><cell>high school world history</cell><cell>42.6</cell><cell cols="2">50.6 41.8</cell><cell>29.1</cell><cell cols="2">54.0 64.6</cell><cell>66.7</cell><cell>72.2 73.8</cell></row><row><cell>human aging</cell><cell>28.3</cell><cell cols="2">37.2 29.6</cell><cell>26.0</cell><cell cols="2">45.3 46.2</cell><cell>46.6</cell><cell>57.0 62.8</cell></row><row><cell>human sexuality</cell><cell>29.8</cell><cell cols="2">34.4 41.2</cell><cell>25.2</cell><cell cols="2">42.0 44.3</cell><cell>51.1</cell><cell>58.0 59.5</cell></row><row><cell>international law</cell><cell>57.9</cell><cell cols="2">57.9 41.3</cell><cell>44.6</cell><cell cols="2">57.9 58.7</cell><cell>62.8</cell><cell>71.9 71.1</cell></row><row><cell>jurisprudence</cell><cell>30.6</cell><cell cols="2">33.3 34.3</cell><cell>32.4</cell><cell cols="2">49.1 52.8</cell><cell>55.6</cell><cell>67.6 74.1</cell></row><row><cell>logical fallacies</cell><cell>40.5</cell><cell cols="2">55.8 46.6</cell><cell>25.8</cell><cell cols="2">51.5 62.0</cell><cell>43.6</cell><cell>69.3 71.2</cell></row><row><cell>machine learning</cell><cell>33.0</cell><cell cols="2">34.8 36.6</cell><cell>29.5</cell><cell cols="2">35.7 37.5</cell><cell>32.1</cell><cell>37.5 42.9</cell></row><row><cell>management</cell><cell>21.4</cell><cell cols="2">29.1 40.8</cell><cell>24.3</cell><cell cols="2">47.6 50.5</cell><cell>60.2</cell><cell>69.9 70.9</cell></row><row><cell>marketing</cell><cell>38.9</cell><cell cols="2">58.5 60.7</cell><cell>31.2</cell><cell cols="2">67.9 75.6</cell><cell>69.2</cell><cell>79.9 85.9</cell></row><row><cell>medical genetics</cell><cell>26.0</cell><cell cols="2">36.0 36.0</cell><cell>29.0</cell><cell cols="2">43.0 44.0</cell><cell>40.0</cell><cell>54.0 50.0</cell></row><row><cell>miscellaneous</cell><cell>24.5</cell><cell cols="2">45.2 46.4</cell><cell>27.1</cell><cell cols="2">52.2 58.2</cell><cell>51.3</cell><cell>64.6 72.7</cell></row><row><cell>moral disputes</cell><cell>32.4</cell><cell cols="2">37.3 38.7</cell><cell>28.6</cell><cell cols="2">43.4 43.4</cell><cell>49.7</cell><cell>64.7 64.7</cell></row><row><cell>moral scenarios</cell><cell>24.7</cell><cell cols="2">24.7 24.7</cell><cell>23.0</cell><cell cols="2">23.9 24.7</cell><cell>23.8</cell><cell>24.0 23.8</cell></row><row><cell>nutrition</cell><cell>30.1</cell><cell cols="2">33.0 34.6</cell><cell>25.8</cell><cell cols="2">42.5 44.1</cell><cell>50.3</cell><cell>55.6 61.1</cell></row><row><cell>philosophy</cell><cell>28.6</cell><cell cols="2">32.5 37.3</cell><cell>31.2</cell><cell cols="2">38.9 45.0</cell><cell>44.1</cell><cell>56.6 59.2</cell></row><row><cell>prehistory</cell><cell>33.6</cell><cell cols="2">37.0 41.4</cell><cell>27.5</cell><cell cols="2">39.8 50.6</cell><cell>41.0</cell><cell>51.5 57.7</cell></row><row><cell>professional accounting</cell><cell>21.3</cell><cell cols="2">28.0 30.5</cell><cell>25.9</cell><cell cols="2">35.5 34.0</cell><cell>37.2</cell><cell>41.5 42.2</cell></row><row><cell>professional law</cell><cell>28.2</cell><cell cols="2">33.4 34.0</cell><cell>27.6</cell><cell cols="2">35.4 35.5</cell><cell>38.3</cell><cell>43.0 45.6</cell></row><row><cell>professional medicine</cell><cell>19.5</cell><cell cols="2">26.5 24.3</cell><cell>20.2</cell><cell cols="2">32.0 37.9</cell><cell>38.6</cell><cell>40.8 46.0</cell></row><row><cell>professional psychology</cell><cell>27.8</cell><cell cols="2">32.8 32.8</cell><cell>26.6</cell><cell cols="2">39.5 43.6</cell><cell>38.4</cell><cell>48.0 58.3</cell></row><row><cell>public relations</cell><cell>22.7</cell><cell cols="2">43.6 40.0</cell><cell>21.8</cell><cell cols="2">47.3 56.4</cell><cell>50.0</cell><cell>55.5 60.0</cell></row><row><cell>security studies</cell><cell>37.6</cell><cell cols="2">26.1 31.0</cell><cell>20.4</cell><cell cols="2">34.7 44.1</cell><cell>56.3</cell><cell>61.6 66.9</cell></row><row><cell>sociology</cell><cell>43.3</cell><cell cols="2">41.8 38.8</cell><cell>30.8</cell><cell cols="2">45.8 52.7</cell><cell>60.2</cell><cell>66.7 72.1</cell></row><row><cell>us foreign policy</cell><cell>49.0</cell><cell cols="2">57.0 66.0</cell><cell>38.0</cell><cell cols="2">56.0 61.0</cell><cell>59.0</cell><cell>75.0 76.0</cell></row><row><cell>virology</cell><cell>29.5</cell><cell cols="2">26.5 34.3</cell><cell>30.1</cell><cell cols="2">36.1 39.8</cell><cell>44.0</cell><cell>46.4 41.6</cell></row><row><cell>world religions</cell><cell>24.0</cell><cell cols="2">40.9 47.4</cell><cell>32.7</cell><cell cols="2">49.1 57.3</cell><cell>48.0</cell><cell>63.7 70.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 18 :</head><label>18</label><figDesc>MMLU Test set scores for the de-biased Atlas-XXL using cyclic permutations for each of the 57 domains for zero-shot, 5 shot, 5-shot-multitask and the transfer setting</figDesc><table><row><cell>Domain</cell><cell>zero-shot</cell><cell>5-shot</cell><cell cols="2">5-shot (multi-task) Full / Transfer</cell></row><row><cell>All</cell><cell>47.1</cell><cell>47.9</cell><cell>56.6</cell><cell>66.0</cell></row><row><cell>Humanities</cell><cell>43.6</cell><cell>46.1</cell><cell>50.1</cell><cell>61.1</cell></row><row><cell>Social Sciences</cell><cell>54.1</cell><cell>54.6</cell><cell>66.4</cell><cell>77.2</cell></row><row><cell>STEM</cell><cell>38.0</cell><cell>38.8</cell><cell>46.4</cell><cell>53.2</cell></row><row><cell>Other</cell><cell>53.9</cell><cell>52.8</cell><cell>66.2</cell><cell>74.4</cell></row><row><cell>abstract algebra</cell><cell>22.0</cell><cell>26.0</cell><cell>31.0</cell><cell>31.0</cell></row><row><cell>anatomy</cell><cell>48.9</cell><cell>47.4</cell><cell>62.2</cell><cell>70.4</cell></row><row><cell>astronomy</cell><cell>61.8</cell><cell>62.5</cell><cell>68.4</cell><cell>81.6</cell></row><row><cell>business ethics</cell><cell>60.0</cell><cell>57.0</cell><cell>62.0</cell><cell>70.0</cell></row><row><cell>clinical knowledge</cell><cell>50.6</cell><cell>49.4</cell><cell>66.4</cell><cell>72.8</cell></row><row><cell>college biology</cell><cell>51.4</cell><cell>53.5</cell><cell>61.1</cell><cell>77.8</cell></row><row><cell>college chemistry</cell><cell>36.0</cell><cell>39.0</cell><cell>39.0</cell><cell>45.0</cell></row><row><cell>college computer science</cell><cell>32.0</cell><cell>32.0</cell><cell>33.0</cell><cell>49.0</cell></row><row><cell>college mathematics</cell><cell>30.0</cell><cell>35.0</cell><cell>35.0</cell><cell>34.0</cell></row><row><cell>college medicine</cell><cell>44.5</cell><cell>41.0</cell><cell>52.6</cell><cell>67.6</cell></row><row><cell>college physics</cell><cell>24.5</cell><cell>26.5</cell><cell>37.3</cell><cell>42.2</cell></row><row><cell>computer security</cell><cell>59.0</cell><cell>59.0</cell><cell>68.0</cell><cell>76.0</cell></row><row><cell>conceptual physics</cell><cell>37.0</cell><cell>41.3</cell><cell>57.0</cell><cell>60.0</cell></row><row><cell>econometrics</cell><cell>20.2</cell><cell>20.2</cell><cell>36.8</cell><cell>37.7</cell></row><row><cell>electrical engineering</cell><cell>37.9</cell><cell>40.0</cell><cell>50.3</cell><cell>65.5</cell></row><row><cell>elementary mathematics</cell><cell>31.2</cell><cell>28.0</cell><cell>30.7</cell><cell>36.5</cell></row><row><cell>formal logic</cell><cell>27.8</cell><cell>27.0</cell><cell>32.5</cell><cell>35.7</cell></row><row><cell>global facts</cell><cell>41.0</cell><cell>43.0</cell><cell>51.0</cell><cell>53.0</cell></row><row><cell>high school biology</cell><cell>53.2</cell><cell>56.5</cell><cell>68.7</cell><cell>83.2</cell></row><row><cell>high school chemistry</cell><cell>41.9</cell><cell>41.4</cell><cell>49.3</cell><cell>51.2</cell></row><row><cell>high school computer science</cell><cell>40.0</cell><cell>36.0</cell><cell>46.0</cell><cell>60.0</cell></row><row><cell>high school european history</cell><cell>56.4</cell><cell>58.8</cell><cell>68.5</cell><cell>80.6</cell></row><row><cell>high school geography</cell><cell>57.1</cell><cell>59.6</cell><cell>71.2</cell><cell>81.3</cell></row><row><cell>high school gov. and pol.</cell><cell>67.9</cell><cell>67.9</cell><cell>77.2</cell><cell>90.2</cell></row><row><cell>high school macroeconomics</cell><cell>46.9</cell><cell>48.5</cell><cell>57.9</cell><cell>65.9</cell></row><row><cell>high school mathematics</cell><cell>28.1</cell><cell>28.9</cell><cell>34.1</cell><cell>31.5</cell></row><row><cell>high school microeconomics</cell><cell>51.7</cell><cell>51.7</cell><cell>68.9</cell><cell>82.4</cell></row><row><cell>high school physics</cell><cell>26.5</cell><cell>25.8</cell><cell>32.5</cell><cell>41.1</cell></row><row><cell>high school psychology</cell><cell>66.2</cell><cell>65.5</cell><cell>78.9</cell><cell>86.8</cell></row><row><cell>high school statistics</cell><cell>31.5</cell><cell>30.1</cell><cell>43.1</cell><cell>45.8</cell></row><row><cell>high school us history</cell><cell>57.8</cell><cell>54.9</cell><cell>64.7</cell><cell>77.5</cell></row><row><cell>high school world history</cell><cell>59.1</cell><cell>62.9</cell><cell>65.4</cell><cell>79.3</cell></row><row><cell>human aging</cell><cell>48.4</cell><cell>50.7</cell><cell>60.5</cell><cell>70.4</cell></row><row><cell>human sexuality</cell><cell>55.7</cell><cell>54.2</cell><cell>61.8</cell><cell>84.0</cell></row><row><cell>international law</cell><cell>66.1</cell><cell>72.7</cell><cell>71.9</cell><cell>84.3</cell></row><row><cell>jurisprudence</cell><cell>61.1</cell><cell>64.8</cell><cell>72.2</cell><cell>81.5</cell></row><row><cell>logical fallacies</cell><cell>54.6</cell><cell>57.7</cell><cell>71.2</cell><cell>77.9</cell></row><row><cell>machine learning</cell><cell>37.5</cell><cell>39.3</cell><cell>43.8</cell><cell>44.6</cell></row><row><cell>management</cell><cell>56.3</cell><cell>56.3</cell><cell>79.6</cell><cell>89.3</cell></row><row><cell>marketing</cell><cell>72.2</cell><cell>73.1</cell><cell>84.6</cell><cell>91.9</cell></row><row><cell>medical genetics</cell><cell>55.0</cell><cell>58.0</cell><cell>71.0</cell><cell>81.0</cell></row><row><cell>miscellaneous</cell><cell>69.7</cell><cell>67.8</cell><cell>83.8</cell><cell>90.4</cell></row><row><cell>moral disputes</cell><cell>45.1</cell><cell>46.8</cell><cell>60.1</cell><cell>72.3</cell></row><row><cell>moral scenarios</cell><cell>24.5</cell><cell>30.3</cell><cell>25.8</cell><cell>38.5</cell></row><row><cell>nutrition</cell><cell>56.5</cell><cell>53.9</cell><cell>67.0</cell><cell>77.1</cell></row><row><cell>philosophy</cell><cell>56.3</cell><cell>57.6</cell><cell>70.7</cell><cell>77.2</cell></row><row><cell>prehistory</cell><cell>59.3</cell><cell>60.5</cell><cell>71.6</cell><cell>78.7</cell></row><row><cell>professional accounting</cell><cell>35.1</cell><cell>33.0</cell><cell>42.2</cell><cell>50.7</cell></row><row><cell>professional law</cell><cell>36.3</cell><cell>38.4</cell><cell>39.4</cell><cell>51.7</cell></row><row><cell>professional medicine</cell><cell>35.7</cell><cell>33.1</cell><cell>52.2</cell><cell>60.7</cell></row><row><cell>professional psychology</cell><cell>47.7</cell><cell>49.3</cell><cell>60.9</cell><cell>74.0</cell></row><row><cell>public relations</cell><cell>54.5</cell><cell>53.6</cell><cell>68.2</cell><cell>68.2</cell></row><row><cell>security studies</cell><cell>47.3</cell><cell>45.7</cell><cell>59.2</cell><cell>73.9</cell></row><row><cell>sociology</cell><cell>62.2</cell><cell>62.7</cell><cell>71.6</cell><cell>84.6</cell></row><row><cell>us foreign policy</cell><cell>64.0</cell><cell>68.0</cell><cell>73.0</cell><cell>83.0</cell></row><row><cell>virology</cell><cell>39.8</cell><cell>40.4</cell><cell>44.6</cell><cell>51.8</cell></row><row><cell>world religions</cell><cell>77.2</cell><cell>74.9</cell><cell>80.7</cell><cell>87.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 19 :</head><label>19</label><figDesc>Impact of model size on question answering datasets. We report exact match performance on the test sets of NaturalQuestions and TriviaQA filtered depending on the number of parameters in the reader module. For these experiments the index contains the December 2018 Wikipedia dump.</figDesc><table><row><cell cols="2">Number of parameters</cell><cell cols="3">220M 770M 3B</cell><cell>11B</cell></row><row><cell cols="2">NaturalQuestions 64-shot</cell><cell>27.0</cell><cell>35.4</cell><cell>41.3 45.0</cell></row><row><cell cols="2">NaturalQuestions full</cell><cell>54.1</cell><cell>60.8</cell><cell>63.4 64.0</cell></row><row><cell cols="2">TriviaQA 64-shot</cell><cell>55.3</cell><cell>65.0</cell><cell>70.2 71.4</cell></row><row><cell cols="2">TriviaQA full</cell><cell>71.8</cell><cell>74.9</cell><cell>77.5 78.0</cell></row><row><cell cols="5">Table 20: Downstream results on KILT dev sets.</cell></row><row><cell>Model</cell><cell cols="4">AIDA FEV T-REx zsRE NQ HoPo TQA WoW acc acc acc acc em em em f1</cell></row><row><cell>Atlas 64-shot</cell><cell>69.0 88.1</cell><cell>58.5</cell><cell cols="2">60.2 44.2 34.1 77.1 15.4</cell></row><row><cell cols="2">Atlas full dataset 92.7 94.4</cell><cell>84.8</cell><cell cols="2">80.9 63.4 51.4 84.4 21.0</cell></row><row><cell cols="2">question: {query text} answer: [MASK_0]</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1"> See Hoffmann et al. (2022)  for more details about the computation of the FLOPS corresponding to the forward and backward passes of transformer networks.2 There is a factor 4 to account for the backward pass and activation checkpointing.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Exploring all answer option permutations would involve 24 forward passes, which improves results by an additional ?1% over the 4 cyclic permutations, but requires much more compute, so we exclude it here, see Appendix A.1 4 Atlas's pre-training compute is dominated by the T5 pre-training. The computational requirements for the retrieval-augmented pre-train is orders of magnitude lower</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://eval.ai/web/challenges/challenge-page/689</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Note: Depending on the question, it may not be important or useful to retrieve the exact text of the answer in MMLU, and as such, a hits@k value of 30% does not imply that retrieval fails to surface useful information in 70% of cases</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">This experiment was performed with a slightly different index to the main experiments, which achieves a stronger result</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Autoregressive search engines: Generating substrings as document identifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Ottaviano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.10628.15" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diego de Las Casas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<publisher>Simon Osindero</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Improving language models by retrieving from trillions of tokens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sifre</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.04426.1" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Ilya Sutskever, and Dario Amodei. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2005.14165.1,8" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">27</biblScope>
			<pubPlace>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Autoregressive entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=5k8F6UU39V.15" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extracting training data from large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting.16" />
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2633" to="2650" />
		</imprint>
	</monogr>
	<note>?lfar Erlingsson, Alina Oprea, and Colin Raffel</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Palm: Scaling language modeling with pathways</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensen</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodkumar</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lim</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.02311.1,2" />
		<editor>Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern</editor>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">14</biblScope>
			<pubPlace>Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick; Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno>abs/1803.05457</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Time-aware language models as temporal knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><forename type="middle">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><forename type="middle">Martin</forename><surname>Eisenschlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00459</idno>
		<ptr target="https://aclanthology.org/2022.tacl-1.15.9" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1l73iRqKm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Documenting large webtext corpora: A case study on the colossal clean crawled corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Marasovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Agnew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.98</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.98.17" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="1286" to="1305" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A large scale alignment of natural language with knowledge base triples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlos</forename><surname>Vougiouklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslen</forename><surname>Remaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederique</forename><surname>Laforest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Simperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">. T-Rex</forename></persName>
		</author>
		<ptr target="https://aclanthology.org/L18-1544.9" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">R2-D2: A modular baseline for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fajcik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Docekal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ondrej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Smrz</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.73</idno>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.73.14" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="854" to="870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Object classification from a single example utilizing class relevance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fink</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2004/file/ef1e491a766ce3127556063d49bc2f98-Paper.pdf.8" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>L. Saul, Y. Weiss, and L. Bottou</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.295</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.295.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Md Faisal Mahbub Chowdhury, Ankita Rajaram Naik, Pengshan Cai, and Alfio Gliozzo. Re2g: Retrieve, rerank, generate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaetano</forename><surname>Rossiello</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2207.06300.15" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Unbounded cache model for online language modeling with open vocabulary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.02604.7" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving neural language models with a continuous cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B184E5qee.7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08909</idno>
		<title level="m">Realm: Retrieval-augmented language model pre-training</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Measuring massive multitask language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR), 2021. 9</title>
		<meeting>the International Conference on Learning Representations (ICLR), 2021. 9</meeting>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D11-1072.9" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simonyan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.15556" />
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">27</biblScope>
			<pubPlace>Erich Elsen, Jack W. Rae</pubPlace>
		</imprint>
	</monogr>
	<note>. 1, 6, 8, 14</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-task retrieval-augmented text generation with relevance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hofst?tter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiecao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<idno>abs/2207.03030</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</title>
		<meeting>the 22nd ACM international conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Leveraging passage retrieval with generative models for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01282</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distilling knowledge from reader to retriever for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=NTEz-6wysdb.4" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Unsupervised dense information retrieval with contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.09118.2" />
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How can we know what language models know?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00324</idno>
		<ptr target="https://aclanthology.org/2020.tacl-1.28.8" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of documentation</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Scaling laws for neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2001.08361.8" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>O?uz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generalization through memorization: Nearest neighbor language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HklBjCEKvH.8" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">UNIFIEDQA: Crossing format boundaries with a single QA system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.171</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.171.27" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<meeting><address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1896" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Proofver: Natural logic theorem proving for fact verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.11357.15" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
		<ptr target="https://aclanthology.org/Q19-1026" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">RACE: Large-scale ReAding comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1082</idno>
		<ptr target="https://aclanthology.org/D17-1082.9" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Internet-augmented language models through few-shot prompting for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Stokowiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolai</forename><surname>Grigorev</surname></persName>
		</author>
		<idno>abs/2203.05115</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How many data points is a prompt worth?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.208</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.208.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="2627" to="2636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">You only need one model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haejun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akhil</forename><surname>Kedia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung-Gu</forename><surname>Woo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.07381.7" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning. CoRR, abs/2104.08691, 2021</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.08691.8" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K17-1034</idno>
		<ptr target="https://aclanthology.org/K17-1034.9" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Retrieval-augmented generation for knowledgeintensive nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11401</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.353</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.353.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Jurassic-1: Technical details and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Opher</forename><surname>Lieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barak</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Shoham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>AI21 Labs</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cutting down on prompts and parameters: Simple few-shot learning with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Iv Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Balavzevi&amp;apos;c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedel</surname></persName>
		</author>
		<idno>abs/2106.13353</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1260</idno>
		<ptr target="https://aclanthology.org/D18-1260" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="2381" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10645</idno>
		<title level="m">Ambigqa: Answering ambiguous open-domain questions</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Arun</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyna</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<idno>abs/2112.09332</idno>
	</analytic>
	<monogr>
		<title level="m">Browser-assisted question-answering with human feedback</title>
		<editor>Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Hindsight: Posterior-guided training of retrievers for improved open-ended generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.07752.7" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">How context affects language models&apos; factual predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04611</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Improving wikipedia verifiability with ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Emmanuel</forename><surname>Mazar?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2207.06220.7" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The web is your oysterknowledge-intensive nlp against a very large web corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Okhonko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>O?uz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.09924.15" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Technical Report</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhant</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esme</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donato</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.11446.1,8,10" />
		<title level="m">Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling language models: Methods, analysis &amp; insights from training gopher</title>
		<editor>Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d&apos;Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero</editor>
		<meeting><address><addrLine>Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning to retrieve passages without supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ori</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Shachaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Globerson</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.naacl-main.193.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-07" />
			<biblScope unit="page" from="2687" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<ptr target="https://www.microsoft.com/en-us/research/publication/mctest-challenge-dataset-open-domain-machine-comprehension-text/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Emprical Methods in Natural Language Processing (EMNLP 2013)</title>
		<meeting>the 2013 Conference on Emprical Methods in Natural Language Processing (EMNLP 2013)</meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Okapi at TREC-3. NIST Special Publication Sp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">End-to-end training of multi-document reader and retriever for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devendra</forename><surname>Singh Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.05346.4" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<idno>abs/2009.07118</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.20</idno>
		<ptr target="https://aclanthology.org/2021.eacl-main.20.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Few-shot text generation with natural language instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.32</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.32.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="390" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning semantic representations using convolutional neural networks for web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gr?goire</forename><surname>Mesnil</surname></persName>
		</author>
		<idno type="DOI">10.1145/2567948.2577348</idno>
		<ptr target="https://doi.org/10.1145/2567948.2577348.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on World Wide Web</title>
		<meeting>the 23rd International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.346</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.346.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="4222" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Retrieval augmentation reduces hallucination in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.07567.7" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Language models that seek for knowledge: Modular search &amp; generation for dialogue and prompt completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><forename type="middle">D</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>abs/2203.13224, 2022. 8</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaden</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Legresley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrimai</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Korthikanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elton</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><forename type="middle">Yazdani</forename><surname>Aminabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Bernauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.11990.8" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Improving and simplifying pattern exploiting training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Rakesh R Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno>abs/2103.11955</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongrae</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaixiu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Ghafouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Menegali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Ching</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willard</forename><forename type="middle">James</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Rusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">S</forename><surname>Pickett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meier-Hellstern</surname></persName>
		</author>
		<editor>Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravindran Rajakumar, Alena Butryna, Matthew Lamm, V. O. Kuzmina, Joseph Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc Le</editor>
		<imprint>
			<pubPlace>Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Hartz S?raker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark D?az, Ben Hutchinson</pubPlace>
		</imprint>
	</monogr>
	<note>Lamda: Language models for dialog applications. ArXiv, abs/2201.08239, 2022. 8</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Fever: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Learning to Learn: Introduction and Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<idno>0792380479. 8</idno>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="3" to="17" />
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf.8" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The TREC-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A globally normalized BERT model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1599</idno>
		<ptr target="https://aclanthology.org/D19-1599.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Emergent abilities of large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.07682.8" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">CCNet: Extracting high quality monolingual datasets from web crawl data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00808</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1809.09600.9" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Pretrained Transformers for Text Ranking: BERT and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3437963.3441667</idno>
		<ptr target="https://doi.org/10.1145/3437963.3441667.event-place:VirtualEvent" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Web Search and Data Mining, WSDM &apos;21</title>
		<meeting>the 14th ACM International Conference on Web Search and Data Mining, WSDM &apos;21<address><addrLine>New York, NY, USA, 2021; Israel</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="1154" to="1156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Learning Discriminative Projections for Text Similarity Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
		<idno>978-1-932432-92-3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning, CoNLL &apos;11</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning, CoNLL &apos;11<address><addrLine>USA; Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Adaptive semiparametric language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyprien</forename><surname>De Masson D&amp;apos;autume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00371</idno>
		<ptr target="https://aclanthology.org/2021.tacl-1.22.1" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="362" to="373" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
