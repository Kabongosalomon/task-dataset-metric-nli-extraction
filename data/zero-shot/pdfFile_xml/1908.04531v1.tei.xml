<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-08-13">13 Aug 2019 August 14, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gudbjartur</forename><forename type="middle">Ingi</forename><surname>Sigurbergsson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science IT</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>2300</postCode>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science IT</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>2300</postCode>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-08-13">13 Aug 2019 August 14, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>offensive language ? hate speech detection ? natural language processing ? Danish</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. Given the enormous amount of content created every day, automatic methods are required to detect and deal with this type of content. Until now, most of the research has focused on solving the problem for the English language, while the problem is multilingual. We construct a Danish dataset containing user-generated comments from Reddit and Facebook. It contains user generated comments from various social media platforms, and to our knowledge, it is the first of its kind. Our dataset is annotated to capture various types and target of offensive language. We develop four automatic classification systems, each designed to work for both the English and the Danish language. In the detection of offensive language in English, the best performing system achieves a macro averaged F1-score of 0.74, and the best performing system for Danish achieves a macro averaged F1-score of 0.70. In the detection of whether or not an offensive post is targeted, the best performing system for English achieves a macro averaged F1-score of 0.62, while the best performing system for Danish achieves a macro averaged F1-score of 0.73. Finally, in the detection of the target type in a targeted offensive post, the best performing system for English achieves a macro averaged F1-score of 0.56, and the best performing system for Danish achieves a macro averaged F1-score of 0.63. Our work for both the English and the Danish language captures the type and targets of offensive language, and present automatic methods for detecting different kinds of offensive language such as hate speech and cyberbullying.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Offensive language in user-generated content on online platforms and its implications has been gaining attention over the last couple of years. This interest is sparked by the fact that many of the online social media platforms have come under scrutiny on how this type of content should be detected and dealt with. It is, however, far from trivial to deal with this type of language directly due to the gigantic amount of user-generated content created every day. For this reason, automatic methods are required, using natural language processing (NLP) and machine learning techniques.</p><p>Given the fact that the research on offensive language detection has to a large extent been focused on the English language, we set out to explore the design of models that can successfully be used for both English and Danish. To accomplish this, an appropriate dataset must be constructed, annotated with the guidelines described in <ref type="bibr" target="#b0">[1]</ref>. We, furthermore, set out to analyze the linguistic features that prove hard to detect by analyzing the patterns that prove hard to detect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Offensive language varies greatly, ranging from simple profanity to much more severe types of language. One of the more troublesome types of language is hate speech and the presence of hate speech on social media platforms has been shown to be in correlation with hate crimes in real life settings <ref type="bibr" target="#b1">[2]</ref>. It can be quite hard to distinguish between generally offensive language and hate speech as few universal definitions exist <ref type="bibr" target="#b2">[3]</ref>. There does, however, seem to be a general consensus that hate speech can be defined as language that targets a group with the intent to be harmful or to cause social chaos. This targeting is usually done on the basis of some characteristics such as race, color, ethnicity, gender, sexual orientation, nationality or religion <ref type="bibr" target="#b3">[4]</ref>. In section 2, hate speech is defined in more detail. Offensive language, on the other hand, is a more general category containing any type of profanity or insult. Hate speech can, therefore, be classified as a subset of offensive language. <ref type="bibr" target="#b0">[1]</ref> propose guidelines for classifying offensive language as well as the type and the target of offensive language. These guidelines capture the characteristics of generally offensive language, hate speech and other types of targeted offensive language such as cyberbullying. However, despite offensive language detection being a burgeoning field, no dataset yet exists for Danish <ref type="bibr" target="#b4">[5]</ref> despite this phenomenon being present <ref type="bibr" target="#b5">[6]</ref>.</p><p>Many different sub-tasks have been considered in the literature on offensive and harmful language detection, ranging from the detection of general offensive language to more refined tasks such as hate speech detection <ref type="bibr" target="#b2">[3]</ref>, and cyberbullying detection <ref type="bibr" target="#b6">[7]</ref>.</p><p>A key aspect in the research of automatic classification methods for language of any kind is having substantial amount of high quality data that reflects the goal of the task at hand, and that also contains a decent amount of samples belonging to each of the classes being considered. To approach this problem as a supervised classification task the data needs to be annotated according to a well-defined annotation schema that clearly reflects the problem statement. The quality of the data is of vital importance, since low quality data is unlikely to provide meaningful results.</p><p>Cyberbullying is commonly defined as targeted insults or threats against an individual <ref type="bibr" target="#b0">[1]</ref>. Three factors are mentioned as indicators of cyberbullying <ref type="bibr" target="#b6">[7]</ref>: intent to cause harm, repetitiveness, and an imbalance of power. This type of online harassment most commonly occurs between children and teenagers, and cyberbullying acts are prohibited by law in several countries, as well as many of the US states <ref type="bibr" target="#b7">[8]</ref>.</p><p>[9] focus on classifying cyberbullying events in Dutch. They define cyberbullying as textual content that is published online by an individual and is aggressive or hurtful against a victim. The annotation-schema used consists of two steps. In the first step, a three-point harmfulness score is assigned to each post as well as a category denoting the authors role (i.e. harasser, victim, or bystander). In the second step a more refined categorization is applied, by annotating the posts using the the following labels: Threat/Blackmail, Insult, Curse/Exclusion, Defamation, Sexual Talk, Defense, and Encouragement to the harasser.</p><p>Hate Speech. As discussed in Section 1, hate speech is generally defined as language that is targeted towards a group, with the intend to be harmful or cause social chaos. This targeting is usually based on characteristics such as race, color, ethnicity, gender, sexual orientation, nationality or religion <ref type="bibr" target="#b3">[4]</ref>. Hate speech is prohibited by law in many countries, although the definitions may vary. In article 20 of the International Covenant on Civil and Political Rights (ICCPR) it is stated that "Any advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence shall be prohibited by law" <ref type="bibr" target="#b9">[10]</ref>. In Denmark, hate speech is prohibited by law, and is formally defined as public statements where a group is threatened, insulted, or degraded on the basis of characteristics such as nationality, ethnicity, religion, or sexual orientation <ref type="bibr" target="#b10">[11]</ref>. Hate speech is generally prohibited by law in the European Union, where it is defined as public incitement to violence or hatred directed against a group defined on the basis of characteristics such as race, religion, and national or ethnic origin <ref type="bibr">[12]</ref>. Hate speech is, however, not prohibited by law in the United States. This is due to the fact that hate speech is protected by the freedom of speech act in the First Amendment of the U.S. Constitution <ref type="bibr" target="#b11">[13]</ref>.</p><p>[3] focus is on classifying hate speech by distinguishing between general offensive language and hate speech. They define hate speech as "language that is used to express hatred towards a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group". They argue that the high use of profanity on social media makes it vitally important to be able to effectively distinguish between generally offensive language and the more severe hate speech. The dataset is constructed by gathering data from Twitter, using a hate speech lexicon to query the data with crowdsourced annotations.</p><p>Contradicting definitions. It becomes clear that one of the key challenges in doing meaningful research on the topic are the differences in both the annotation-schemas and the definitions used, since it makes it difficult to effectively compare results to existing work, as pointed out by several authors ( <ref type="bibr" target="#b12">[14]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b13">[15]</ref>, <ref type="bibr" target="#b0">[1]</ref>). These issues become clear when comparing the work of <ref type="bibr" target="#b6">[7]</ref>, where racist and sexist remarks are classified as a subset of insults, to the work of <ref type="bibr" target="#b14">[16]</ref>, where similar remarks are split into two categories; hate speech and derogatory language. Another clear OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH example of conflicting definitions becomes visible when comparing <ref type="bibr" target="#b15">[17]</ref>, where hate speech is considered without any consideration of overlaps with the more general type of offensive language, to <ref type="bibr" target="#b2">[3]</ref> where a clear distinction is made between the two, by classifying posts as either Hate speech, Offensive or Neither. This lack of consensus led <ref type="bibr" target="#b13">[15]</ref> to propose annotation guidelines and introduce a typology. <ref type="bibr" target="#b16">[18]</ref> argue that these proposed guidelines do not effectively capture both the type and target of the offensive language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>In this section we give a comprehensive overview of the structure of the task and describe the dataset provided in <ref type="bibr" target="#b0">[1]</ref>. Our work adopts this framing of the offensive language phenomenon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Classification Structure</head><p>Offensive content is broken into three sub-tasks to be able to effectively identify both the type and the target of the offensive posts. These three sub-tasks are chosen with the objective of being able to capture different types of offensive language, such as hate speech and cyberbullying (section 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-task A -Offensive language identification</head><p>In sub-task A the goal is to classify posts as either offensive or not. Offensive posts include insults and threats as well as any form of untargeted profanity <ref type="bibr" target="#b16">[18]</ref>. Each sample is annotated with one of the following labels:</p><p>Not Offensive (NOT). In English this could be a post such as #TheNunMovie was just as scary as I thought it would be. Clearly the critics don't think she is terrifyingly creepy. I like how it ties in with #TheConjuring series. In Danish this could be a post such as Kim Larsen var god, men hans d?d blev alt for hyped.</p><p>Offensive (OFF) . In English this could be a post such as USER is a #pervert himself!. In Danish this could be a post such as Kalle er faggot...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-task B -Automatic categorization of offensive language types</head><p>In sub-task B the goal is to classify the type of offensive language by determining if the offensive language is targeted or not. Targeted offensive language contains insults and threats to an individual, group, or others <ref type="bibr" target="#b16">[18]</ref>. Untargeted posts contain general profanity while not clearly targeting anyone <ref type="bibr" target="#b16">[18]</ref>. Only posts labeled as offensive (OFF) in sub-task A are considered in this task. Each sample is annotated with one of the following labels:</p><p>? Targeted Insult (TIN). In English this could be a post such as @USER Please ban this cheating scum. In Danish this could be e.g. Hun skal da selv have 99 ?r, den smatso. ? Untargeted (UNT). In English this could be a post such as 2 weeks of resp done and I still don't know shit my ass still on vacation mode. In Danish this could e.g. Dumme svin...</p><p>Sub-task C -Offensive language target identification In sub-task C the goal is to classify the target of the offensive language. Only posts labeled as targeted insults (TIN) in sub-task B are considered in this task <ref type="bibr" target="#b16">[18]</ref>. Samples are annotated with one of the following:</p><p>? Individual (IND): Posts targeting a named or unnamed person that is part of the conversation. In English this could be a post such as @USER Is a FRAUD Female @USER group paid for and organized by @USER. In Danish this could be a post such as USER du er sku da syg i hoved. These examples further demonstrate that this category captures the characteristics of cyberbullying, as it is defined in section 2. ? Group (GRP): Posts targeting a group of people based on ethnicity, gender or sexual orientation, political affiliation, religious belief, or other characteristics. In English this could be a post such as #Antifa are mentally unstable cowards, pretending to be relevant. In Danish this could be e.g. ?h nej! Svensk lorteret! ? Other (OTH): The target of the offensive language does not fit the criteria of either of the previous two categories. <ref type="bibr" target="#b16">[18]</ref>. In English this could be a post such as And these entertainment agencies just gonna have to be an ass about it.. In Danish this could be a post such as Netto er jo et tempel over lort.</p><p>One of the main concerns when it comes to collecting data for the task of offensive language detection is to find high quality sources of user-generated content that represent each class in the annotation-schema to some extent. In our exploration phase we considered various social media platforms such as Twitter, Facebook, and Reddit.  We consider three social media sites as data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</head><p>Twitter. Twitter has been used extensively as a source of user-generated content and it was the first source considered in our initial data collection phase. The platform provides excellent interface for developers making it easy to gather substantial amounts of data with limited efforts. However, Twitter was not a suitable source of data for our task. This is due to the fact that Twitter has limited usage in Denmark, resulting in low quality data with many classes of interest unrepresented.</p><p>Facebook. We next considered Facebook, and the public page for the Danish media company Ekstra Bladet. We looked at user-generated comments on articles posted by Ekstra Bladet, and initial analysis of these comments showed great promise as they have a high degree of variation. The user behaviour on the page and the language used ranges from neutral language to very aggressive, where some users pour out sexist, racist and generally hateful language. We faced obstacles when collecting data from Facebook, due to the fact that Facebook recently made the decision to shut down all access to public pages through their developer interface. This makes computational data collection approaches impossible. We faced restrictions on scraping public pages with Facebook, and turned to manual collection of randomly selected user-generated comments from Ekstra Bladet's public page, yielding 800 comments of sufficient quality.</p><p>Reddit. Given that language classification tasks in general require substantial amounts of data, our exploration for suitable sources continued and our search next led us to Reddit. We scraped Reddit, collecting the top 500 posts from the Danish sub-reddits r/DANMAG and r/Denmark, as well as the user comments contained within each post.</p><p>We published a survey on Reddit asking Danish speaking users to suggest offensive, sexist, and racist terms for a lexicon. Language and user behaviour varies between platforms, so the goal is to capture platform-specific terms. This gave 113 offensive and hateful terms which were used to find offensive comments. The remainder of comments in the corpus were shuffled and a subset of this corpus was then used to fill the remainder of the final dataset. The resulting dataset contains 3600 user-generated comments, 800 from Ekstra Bladet on Facebook, 1400 from r/DANMAG and 1400 from r/Denmark.</p><p>In light of the General Data Protection Regulations in Europe (GDPR) and the increased concern for online privacy, we applied some necessary pre-processing steps on our dataset to ensure the privacy of the authors of the comments that were used. Personally identifying content (such as the names of individuals, not including celebrity names) was removed. This was handled by replacing each name of an individual (i.e. author or subject) with @USER, as presented in both <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b2">[3]</ref>. All comments containing any sensitive information were removed. We classify sensitive information as any information that can be used to uniquely identify someone by the following characteristics; racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, genetic data, and biometric data.</p><p>We base our annotation procedure on the guidelines and schemas presented in <ref type="bibr" target="#b0">[1]</ref>, discussed in detail in section 3.1. As a warm-up procedure, the first 100 posts were annotated by two annotators (the author and the supervisor) and the results compared. This was used as an opportunity to refine the mutual understanding of the task at hand and to discuss the mismatches in these annotations for each sub-task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</head><p>We used a Jaccard index <ref type="bibr" target="#b17">[19]</ref> to assess the similarity of our annotations. In sub-task A the Jaccard index of these initial 100 posts was 41.9%, 39.1% for sub-task B , and 42.8% for sub-task C. After some analysis of these results and the posts that we disagreed on it became obvious that to a large extent the disagreement was mainly caused by two reasons:</p><p>1. Guesswork of the context where the post itself was too vague to make a decisive decision on whether it was offensive or not without more context. An example of this is a post such as Skal de hjaelpes hjem, nae nej de skal sendes hjem, where one might conclude, given the current political climate, that this is an offensive post targeted at immigrants. The context is, however, lacking so we cannot make a decisive decision. This post should, therefore, be labeled as non-offensive, since the post does not contain any profanity or a clearly stated group.</p><p>2. Failure to label posts containing some kind of profanity as offensive (typically when the posts themselves were not aggressive, harmful, or hateful). An example could be a post like @USER sgu da ikke hans skyld at hun ikke han finde ud af at koge fucking pasta, where the post itself is rather mild, but the presence of fucking makes this an offensive post according to our definitions.</p><p>In light of these findings our internal guidelines were refined so that no post should be labeled as offensive by interpreting any context that is not directly visible in the post itself and that any post containing any form of profanity should automatically be labeled as offensive. These stricter guidelines made the annotation procedure considerably easier while ensuring consistency. The remainder of the annotation task was performed by the author, resulting in 3600 annotated samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Final Dataset</head><p>In <ref type="table" target="#tab_0">Table 1</ref> the distribution of samples by sources in our final dataset is presented. Although a useful tool, using the hate speech lexicon as a filter only resulted in 232 comments. The remaining comments from Reddit were then randomly sampled from the remaining corpus.</p><p>The fully annotated dataset was split into a train and test set, while maintaining the distribution of labels from the original dataset. The training set contains 80% of the samples, and the test set contains 20%. <ref type="table" target="#tab_1">Table 2</ref> presents the distribution of samples by label for both the train and test set. The dataset is skewed, with around 88% of the posts labeled as not offensive (NOT). This is, however, generally the case when it comes to user-generated content on online platforms, and any automatic detection system needs be able to handle the problem of imbalanced data in order to be truly effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>One of the most important factors to consider when it comes to automatic classification tasks the the feature representation. This section discusses various representations used in the abusive language detection literature.</p><p>Top-level features. In <ref type="bibr" target="#b3">[4]</ref> information comes from top-level features such as bag-of-words, uni-grams and more complex n-grams, and the literature certainly supports this. In their work on cyberbullying detection, <ref type="bibr" target="#b8">[9]</ref> use word ngrams, character n-grams, and bag-of-words. They report uni-gram bag-of-word features as most predictive, followed by character tri-gram bag-of-words. Later work finds character n-grams are the most helpful features <ref type="bibr" target="#b14">[16]</ref>, underlying the need for the modeling of un-normalized text. these simple top-level feature approaches are good but not without their limitations, since they often have high recall but lead to high rate of false positives <ref type="bibr" target="#b2">[3]</ref>. This is due to the fact that the presence of certain terms can easily lead to misclassification when using these types of features. Many words, however, do not clearly indicate which category the text sample belongs to, e.g. the word gay can be used in both neutral and offensive contexts.</p><p>Linguistic Features <ref type="bibr" target="#b14">[16]</ref> use a number of linguistic features, including the length of samples, average word lengths, number of periods and question marks, number of capitalized letters, number of URLs, number of polite words, number of unknown words (by using an English dictionary), and number of insults and hate speech words. Although these features have not proven to provide much value on their own, they have been shown to be a good addition to the overall feature space <ref type="bibr" target="#b14">[16]</ref>.</p><p>Word Representations. Top-level features often require the predictive words to occur in both the training set and the test sets, as discussed in <ref type="bibr" target="#b3">[4]</ref>. For this reason, some sort of word generalization is required. <ref type="bibr" target="#b14">[16]</ref> explore three types of embedding-derived features. First, they explore pre-trained embeddings derived from a large corpus of news samples. Secondly, they use word2vec <ref type="bibr" target="#b18">[20]</ref> to generate word embeddings using their own corpus of text samples. We OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH use both approaches. Both the pre-trained and word2vec models represent each word as a 200 dimensional distributed real number vector. Lastly, they develop 100 dimensional comment2vec model, based on the work of <ref type="bibr" target="#b19">[21]</ref>. Their results show that the comment2vec and the word2vec models provide the most predictive features <ref type="bibr" target="#b14">[16]</ref>. In <ref type="bibr" target="#b20">[22]</ref> they experiment with pre-trained GloVe embeddings <ref type="bibr" target="#b21">[23]</ref>, learned FastText embeddings <ref type="bibr" target="#b22">[24]</ref>, and randomly initialized learned embeddings. Interestingly, the randomly initialized embeddings slightly outperform the others <ref type="bibr" target="#b20">[22]</ref>.</p><p>Sentiment Scores. Sentiment scores are a common addition to the feature space of classification systems dealing with offensive and hateful speech. In our work we experiment with sentiment scores and some of our models rely on them as a dimension in their feature space. To compute these sentiment score features our systems use two Python libraries: VADER <ref type="bibr" target="#b23">[25]</ref> and AFINN <ref type="bibr" target="#b24">[26]</ref>.Our models use the compound attribute, which gives a normalized sum of sentiment scores over all words in the sample. The compound attribute ranges from ?1 (extremely negative) to +1 (extremely positive).</p><p>Reading Ease. As well as some of the top-level features mentioned so far, we also use Flesch-Kincaid Grade Level and Flesch Reading Ease scores. The Flesch-Kincaid Grade Level is a metric assessing the level of reading ability required to easily understand a sample of text.</p><p>Pre-trained Embeddings. The pre-trained FastText <ref type="bibr" target="#b22">[24]</ref> embeddings are trained on data from the Common Crawl project and Wikipedia, in 157 languages (including English and Danish). FastText also provides trained models that can be used to predict word embeddings for out-of-vocabulary (OOV) words. This is a major advantage since challenges can arise when using pre-trained word embeddings depending on how often words in the data are not found in the pre-trained corpus.</p><p>Randomly Initialized Learned Embeddings. Some of our models use randomly initialized embeddings, that are updated during training. In this case, the embedding matrix for the embedding layer is initialized using a uniform distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models</head><p>We introduce a variety of models in our work to compare different approaches to the task at hand. First of all, we introduce naive baselines that simply classify each sample as one of the categories of interest (based on <ref type="bibr" target="#b0">[1]</ref>). Next, we introduce a logistic regression model based on the work of <ref type="bibr" target="#b2">[3]</ref>, using the same set of features as introduced there. Finally, we introduce three deep learning models: Learned-BiLSTM, Fast-BiLSTM, and AUX-Fast-BiLSTM. The logistic regression model is built using Scikit Learn <ref type="bibr" target="#b25">[27]</ref> and the deep learning models are built using Keras <ref type="bibr" target="#b26">[28]</ref>. The following sections describe these model architectures in detail, the algorithms they are based on, and the features they use.</p><p>Baselines Following the work of <ref type="bibr" target="#b0">[1]</ref>, we create simple baseline prediction models that simply classify all samples as the class containing the largest amount of samples. This allows us to investigate the properties and distribution of the samples in the datasets, and to evaluate how well our classifiers are performing. The baseline models are the following:</p><p>Logistic Regression One of our model architecture uses a Logistic Regression as the classification algorithm. Logistic regression predicts the probability of events by using a logit function. This logit function is usually a Sigmoid function, mapping continues variables to discrete values. A logistic regression is computed by applying the Sigmoid function to the linear regression. Here, y is the dependent variable, X 1 , . . . , X n are the explanatory variables, and ? 0 , . . . , ? n are the constants we are trying to estimate.</p><p>? Sub-Task A: All NOT for both languages.</p><p>? Sub-Task B: All TIN for both languages.</p><p>? Sub-Task C: All IND for English and All GRP for Danish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logistic Regression Classifier</head><p>We base one of our models on <ref type="bibr" target="#b2">[3]</ref>, where the objective is to distinguish between neutral, offensive and hateful language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learned-BiLSTM Classifier</head><p>The Learned-BiLSTM model consists of four parts; a randomly initialized embedding layer, a bi-directional long short memory (BiLSTM) layer, a fully connected hidden layer, and a fully connected output layer. The BiLSTM layer consists of two parts; a forward and a backward LSTM, each of size 20. This vector is then used as input to the fully connected hidden layer, which contains 16 hidden units. The output is a single node for OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH  sub-tasks A and B and 3 nodes in sub-task C. The activation function used in the LSTM layers is tanh and ReLU is used in the hidden layer. For sub-tasks A and B, the activation function for the output layer is Sigmoid, and Softmax is used for sub-task C. Loss is calculated using Binary Crossentropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast-BiLSTM Classifier</head><p>The Fast-BiLSTM model is built using the same layers and the same set of hyperparameters as the Learned-BiLSTM model. With this the embedding layer is initialized with the FastText embeddings. These embeddings stay fixed and are not updated during the training of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUX-Fast-BiLSTM Classifier</head><p>To experiment with a wider combination of features, we extend the Fast-BiLSTM model to AUX-Fast-BiLSTM, which accepts auxiliary features, namely: sentiment scores, n-grams weighted by their TF-IDF scores, n-gram POS-tags, counters for the number of characters, count of: syllables; words; Twitter hashtags; URLs; Twitter mentions; and re-tweets, and Flesch reading ease and grade level.</p><p>Hyper-Parameter Tuning We perform Grid Search Cross Validation to determine the optimal dropout amount, the batch size, the optimizer and the learning rate. The best set of hyper-parameters for all of our models are the following: batch size of 128, Adam <ref type="bibr" target="#b27">[29]</ref> as the optimization algorithm with a learning rate of 0.001, and a dropout rate of 0.2 between all layers. To tackle imbalance in our dataset we use class weights. Each class is given a weight equal to the inverse of the number of samples it contains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Analysis</head><p>For each sub-task (A, B, and C, Section 3.1) we present results for all methods in each language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A -Offensive language identification:</head><p>English. For English <ref type="table" target="#tab_2">(Table 3</ref>) Fast-BiLSTM performs best, trained for 100 epochs, using the OLID dataset. The model achieves a macro averaged F1-score of 0.735. This result is comparable to the BiLSTM based methods in OffensEval.</p><p>Additional training data from HSAOFL <ref type="bibr" target="#b2">[3]</ref> does not consistently improve results. For the models using word embeddings results are worse with additional training data. On the other hand, for models that use a range of additional features (Logistic Regression and AUX-Fast-BiLSTM), the additional training data helps.   Danish. Results are in <ref type="table" target="#tab_3">Table 4</ref>. Logistic Regression works best with an F1-score of 0.699. This is the second best performing model for English, though the best performing model for English (Fast-BiLSTM) is worst for Danish.</p><p>Best results are given in The effect that this under represented class has on the Danish classification task can be seen in more detail in <ref type="table" target="#tab_4">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B -Categorization of offensive language type</head><p>English. In <ref type="table" target="#tab_5">Table 6</ref> the results are presented for sub-task B on English. The Learned-BiLSTM model trained for 60 epochs performs the best, obtaining a macro F1-score of 0.619.</p><p>Recall and precision scores are lower for UNT than TIN <ref type="table" target="#tab_4">(Table 5</ref>). One reason is skew in the data, with only around 14% of the posts labeled as UNT. The pre-trained embedding model, Fast-BiLSTM, performs the worst, with a macro averaged F1-score of 0.567. This indicates this approach is not good for detecting subtle differences in offensive samples in skewed data, while more complex feature models perform better.</p><p>Danish. <ref type="table" target="#tab_6">Table 7</ref> presents the results for sub-task B and the Danish language. The best performing system is the AUX-Fast-BiLSTM model (section 5) trained for 100 epochs, which obtains an impressive macro F1-score of 0.729. This suggests that models that only rely on pre-trained word embeddings may not be optimal for this task. This is be considered alongside the indication in Section 3.2 that relying on lexicon-based selection also performs poorly.</p><p>The limiting factor seems to be recall for the UNT category ( <ref type="table">Table 8</ref>). As mentioned in Section 2, the best performing system for sub-task B in OffensEval was a rule-based system, suggesting that more refined features, (e.g. lexica) may improve performance on this task. The better performance of models for Danish over English can most likely be explained by the fact that the training set used for Danish is more balanced, with around 42% of the posts labeled as UNT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C -Offensive language target identification</head><p>English. The results for sub-task C and the English language are presented in <ref type="table" target="#tab_9">Table 9</ref>. The best performing system is the Learned-BiLSTM model (section 5) trained for 10 epochs, obtaining a macro averaged F1-score of 0.557. This is an improvement over the models introduced in <ref type="bibr" target="#b0">[1]</ref>, where the BiLSTM based model achieves a macro F1-score of 0.470.</p><p>The main limitations of our model seems to be in the classification of OTH samples, as seen in <ref type="table" target="#tab_0">Table 11</ref>. This may be explained by the imbalance in the training data. It is interesting to see that this imbalance does not effect the GRP category as much, which only constitutes about 28% of the training samples. One cause for the differences in these, <ref type="table">Table 8</ref>: Recall (R), precision (P), and F1 score by class for our best performing models in sub-task B.   Danish. <ref type="table" target="#tab_0">Table 10</ref> presents the results for sub-task C and the Danish language. The best performing system is the same as in English, the Learned-BiLSTM model (section 5), trained for 100 epochs, obtaining a macro averaged F1-score of 0.629. Given that this is the same model as the one that performed the best for English, this further indicates that task specific embeddings are helpful for more refined classification tasks.</p><p>It is interesting to see that both of the models using the additional set of features (Logistic Regression and AUX-Fast-BiLSTM) perform the worst. This indicates that these additional features are not beneficial for this more refined sub-task in Danish. The amount of samples used in training for this sub-task is very low. Imbalance does have as much effect for Danish as it does in English, as can be seen in <ref type="table" target="#tab_0">Table 11</ref>. Only about 14% of the samples are labeled as OTH in the data <ref type="table" target="#tab_1">(table 2)</ref>, but the recall and precision scores are closer than they are for English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis</head><p>We perform analysis of the misclassified samples in the evaluation of our best performing models. To accomplish this, we compute the TF-IDF scores for a range of n-grams. We then take the top scoring n-grams in each category and try to discover any patterns that might exist. We also perform some manual analysis of these misclassified samples. The goal of this process is to try to get a clear idea of the areas our classifiers are lacking in. The following sections describe this process for each of the sub-tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A -Offensive language identification</head><p>The classifier struggles to identify obfuscated offensive terms. This includes words that are concatenated together, such as barrrysoetorobullshit. The classifier also seems to associate she with offensiveness, and samples containing she are misclassified as offensive in several samples while he is less often associated with offensive language.</p><p>There are several examples where our classifier labels profanity-bearing content as offensive that are labeled as nonoffensive in the test set. Posts such as Are you fucking serious? and Fuck I cried in this scene are labeled non-offensive in the test set, but according to annotation guidelines should be classified as offensive.</p><p>The best classifier is inclined to classify longer sequences as offensive. The mean character length of misclassified offensive samples is 204.7, while the mean character length of the samples misclassified not offensive is 107.9. This may be due to any post containing any form of profanity being offensive in sub-task A, so more words increase the likelihood of &gt; 0 profane words. <ref type="table" target="#tab_0">Table 11</ref>: Recall (R), precision (P), and F1 score by class for our best performing models in sub-task C. Baselines also included to get an idea of the class distribution. The classifier suffers from the same limitations as the classifier for English when it comes to obfuscated words, misclassifying samples such as Hahhaaha laer det biiiiiaaaatch as non-offensive. It also seems to associate the occurrence of the word svensken with offensive language, and quite a few samples containing that word are misclassified as offensive. This can be explained by the fact that offensive language towards Swedes is common in the training data, resulting in this association. From this, we can conclude that the classifier relies too much on the presence of individual keywords, ignoring the context of these keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B -Categorization of offensive language type</head><p>Obfuscation prevails in sub-task B. Our classifier misses indicators of targeted insults such as WalkAwayFromA-llDemocrats. It seems to rely too highly on the presence of profanity, misclassifying samples containing terms such as bitch, fuck, shit, etc. as targeted insults.</p><p>The issue of the data quality is also concerning in this sub-task, as we discover samples containing clear targeted insults such as HillaryForPrison being labeled as untargeted in the test set.</p><p>Our Danish classifier also seems to be missing obfuscated words such as kidsarefuckingstupid in the classification of targeted insults. It relies to some extent to heavily on the presence of profanity such as pikfjaes, lorte and fucking, and misclassifies untargeted posts containing these keywords as targeted insults.</p><p>C -Offensive language target identification Misclassification based on obfuscated terms as discussed earlier also seems to be an issue for sub-task C. This problem of obfuscated terms could be tackled by introducing character-level features such as character level n-grams.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Model R IND R GRP R OTH P IND P GRP P OTH F1 IND F1 GRP F1 OTH Learned-BiLSTM EN 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The distribution of samples by sources in our final dataset. 'w off. terms" represents that the samples were retrieved using offensive words in the Danish hate speech lexicon as a filter.</figDesc><table><row><cell>Data Source</cell><cell cols="2"># Comments % of all</cell></row><row><cell>Facebook -Ekstra Bladet Reddit; r/Denmark w off. term Reddit; r/Denmark, no off. term Reddit; r/DANMAG w off. term Reddit; r/DANMAG</cell><cell>800 200 1,200 32 1,368</cell><cell>22.2 5.6 33.3 0.9 38.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The distribution of labels in the annotated Danish dataset for both the train and test set.</figDesc><table><row><cell cols="5">Task A Task B Task C Train Test Total</cell></row><row><cell>OFF OFF OFF OFF NOT</cell><cell>TIN TIN TIN UNT</cell><cell>IND OTH GRP</cell><cell>77 30 98 147 2,527</cell><cell>18 6 23 42 632 3,159 95 36 121 189</cell></row><row><cell>ALL</cell><cell></cell><cell></cell><cell>2,879</cell><cell>721 3,600</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results from sub-task A in English. ?=epochs.</figDesc><table><row><cell>Model</cell><cell>Data</cell><cell>F1macro</cell></row><row><cell>All NOT Logistic Regression Learned-BiLSTM ? = 10</cell><cell>-OLID[1] OLID</cell><cell>0.419 0.724 0.707</cell></row><row><cell cols="2">Fast-BiLSTM ? = 100 AUX-Fast-BiLSTM ? = 10 Logistic Regression Learned-BiLSTM ? = 10 Fast-BiLSTM ? = 100 AUX-Fast-BiLSTM ? = 20 OLID+HSAOFL OLID OLID OLID+HSAOFL OLID+HSAOFL OLID+HSAOFL</cell><cell>0.735 0.692 0.728 0.704 0.688 0.712</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Results from sub-task A in Danish.</figDesc><table><row><cell>Model</cell><cell cols="2">Data Macro F1</cell></row><row><cell>All NOT</cell><cell>-</cell><cell>0.467</cell></row><row><cell>Logistic Regression Learned-BiLSTM (10 Epochs) Fast-BiLSTM (100 Epochs) AUX-Fast-BiLSTM (50 Epochs)</cell><cell>DA DA DA DA</cell><cell>0.699 0.658 0.630 0.675</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell>Model</cell><cell cols="6">R NOT R OFF P NOT P OFF F1 NOT F1 OFF</cell></row><row><cell>Fast BiLSTM EN Logistic Regression DA</cell><cell>0.835 0.913</cell><cell>0.646 0.506</cell><cell>0.859 0.929</cell><cell>0.603 0.450</cell><cell>0.847 0.921</cell><cell>0.624 0.476</cell></row></table><note>Recall (R), precision (P), and F1 score by class for our best performing models in sub-task A.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Results from sub-task B in English.</figDesc><table><row><cell>Model</cell><cell>Data</cell><cell>Macro F1</cell></row><row><cell>All TIN Logistic Regression</cell><cell>-OLID</cell><cell>0.470 0.593</cell></row><row><cell cols="2">Learned-BiLSTM (60 Epochs) OLID Fast-BiLSTM (10 Epochs) OLID AUX-Fast-BiLSTM (50 Epochs) OLID</cell><cell>0.619 0.567 0.595</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Results from sub-task B in Danish.</figDesc><table><row><cell>Model</cell><cell cols="2">Data Macro F1</cell></row><row><cell>All TIN Logistic Regression Learned-BiLSTM (40 Epochs) Fast-BiLSTM (100 Epochs)</cell><cell>-DA DA DA</cell><cell>0.346 0.594 0.643 0.681</cell></row><row><cell>AUX-Fast-BiLSTM (100 Epochs)</cell><cell>DA</cell><cell>0.729</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>The low scores for Danish compared to English may be explained by the low amount of data in the Danish dataset. The Danish training set contains 2, 879 samples (table 2) while the English training set contains 13, 240 sample.Futher, in the English dataset around 33% of the samples are labeled offensive while in the Danish set this rate is only at around 12%.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Results for sub-task C in English.</figDesc><table><row><cell>Model</cell><cell>Data</cell><cell>Macro F1</cell></row><row><cell>All IND Logistic Regression</cell><cell>-OLID</cell><cell>0.213 0.458</cell></row><row><cell cols="2">Learned-BiLSTM (10 Epochs) OLID Fast-BiLSTM (50 Epochs) OLID AUX-Fast-BiLSTM (40 Epochs) OLID</cell><cell>0.557 0.516 0.536</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Results from sub-task C in Danish. that the definitions of the OTH category are vague, capturing all samples that do not belong to the previous two.</figDesc><table><row><cell>Model</cell><cell cols="2">Data Macro F1</cell></row><row><cell>All GRP Logistic Regression</cell><cell>-DA</cell><cell>0.219 0.438</cell></row><row><cell>Learned-BiLSTM (100 Epochs) Fast-BiLSTM (60 epochs) AUX-Fast-BiLSTM (100 Epochs)</cell><cell>DA DA DA</cell><cell>0.629 0.579 0.401</cell></row><row><cell>is the fact</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Offensive language on online social media platforms is harmful. Due to the vast amount of user-generated content on online platforms, automatic methods are required to detect this kind of harmful content. Until now, most of the research on the topic has focused on solving the problem for English. We explored English and Danish hate speed detection and categorization, finding that sharing information across languages and platforms leads to good models for the task.</p><p>The resources and classifiers are available from the authors under CC-BY license, pending use in a shared task; a data statement <ref type="bibr" target="#b28">[30]</ref> is included in the appendix. Extended results and analysis are given in <ref type="bibr" target="#b29">[31]</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Fanning the flames of hate: Social media and hate crime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Schwarz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Available at SSRN 3082972</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on hate speech detection using natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Fifth International Workshop on Natural Language Processing for Social Media</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Lacunae of Danish Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kirkedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nordic Conference on Computational Linguistics (NODALIDA). Northern European Association for Language Technology</title>
		<meeting>the Nordic Conference on Computational Linguistics (NODALIDA). Northern European Association for Language Technology</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Kvinder nedg?res oftere end maend i politiske debatter p? sociale medier. TjekDet / Mandag Morgen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Guidelines for the fine-grained analysis of cyberbullying</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Van Hee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>De Pauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V?ronique</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Language and Translation Technology Team, Ghent University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Cyberstalking: Dangers on the information superhighway. National Center for Victims of crime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gregorie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detection and fine-grained classification of cyberbullying events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Van Hee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Mennes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><forename type="middle">De</forename><surname>Pauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V?ronique</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference recent advances in natural language processing</title>
		<meeting>the international conference recent advances in natural language processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="672" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The international covenant on civil and political rights: cases, materials, and commentary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Castan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Straffeloven</surname></persName>
		</author>
		<ptr target="https://danskelove.dk/straffeloven/266b" />
		<imprint>
			<date type="published" when="2019-05-29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Regulating hate speech online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Review of Law, Computers &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="239" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Abusive language detection in online user content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikashi</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achint</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on world wide web</title>
		<meeting>the 25th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding abuse: A typology of abusive language detection subtasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Abusive language detection in online user content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikashi</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achint</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on world wide web</title>
		<meeting>the 25th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hateful symbols or hateful people? Predictive features for hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL student research workshop</title>
		<meeting>the NAACL student research workshop</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Similarity measures in scientometric research: The jaccard index versus salton&apos;s cosine formula</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieve</forename><surname>Hamers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="315" to="333" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning for hate speech detection in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinkesh</forename><surname>Badjatiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
		<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="759" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Advances in pretraining distributed word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international AAAI conference on weblogs and social media (ICWSM)</title>
		<meeting>the international AAAI conference on weblogs and social media (ICWSM)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A new anew: Evaluation of a word list for sentiment analysis in microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finn ?rup Nielsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1103.2903</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ga?l</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Data statements for natural language processing: Toward mitigating system bias and enabling better science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Batya</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION FOR DANISH</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">OFFENSIVE LANGUAGE AND HATE SPEECH DETECTION hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gu?bjartur Ingi Sigurbergsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Danish Language variety Danish, BCP-47: da-DK Speaker demographic ? Danish Reddit and Facebook users ? Age: Unknown -mixed. ? Gender: Unknown -mixed</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>IT University of Copenhagen</orgName>
		</respStmt>
	</monogr>
	<note>Offensive &amp; hate speech detection</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Race</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Ethnicity</surname></persName>
		</author>
		<title level="m">Unknown -mixed. ? Native language: Unknown; Danish speakers. ? Socioeconomic status: Unknown -mixed</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<title level="m">? Different speakers represented: Unknown; upper bound is the number of posts</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">? Presence of disordered speech: Some presences</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Annotator Demographic ? Age</surname></persName>
		</author>
		<title level="m">Gender: male. ? Race/ethnicity: white northern European. ? Native language: Icelandic, English. ? Socioeconomic status: higher education student / university faculty</title>
		<imprint>
			<biblScope unit="page" from="25" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Provenance Originally taken from Reddit and Facebook</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>details given in Section 3</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
