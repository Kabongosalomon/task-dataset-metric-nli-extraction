<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FCGEC: Fine-Grained Corpus for Chinese Grammatical Error Correction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lvxiaowei</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwang</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Fu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Base Station Platform Software Development Dept</orgName>
								<orgName type="institution">Huawei Co</orgName>
								<address>
									<settlement>Ltd</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FCGEC: Fine-Grained Corpus for Chinese Grammatical Error Correction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Grammatical Error Correction (GEC) has been broadly applied in automatic correction and proofreading system recently. However, it is still immature in Chinese GEC due to limited high-quality data from native speakers in terms of category and scale. In this paper, we present FCGEC, a fine-grained corpus to detect, identify and correct the grammatical errors. FCGEC is a human-annotated corpus with multiple references, consisting of 41,340 sentences collected mainly from multi-choice questions in public school Chinese examinations. Furthermore, we propose a Switch-Tagger-Generator (STG) baseline model to correct the grammatical errors in low-resource settings. Compared to other GEC benchmark models, experimental results illustrate that STG outperforms them on our FCGEC. However, there exists a significant gap between benchmark models and humans that encourages future models to bridge it. Our annotation corpus and codes are available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Grammatical error correction (GEC) is a complex task, aiming at detecting, identifying and correcting various grammatical errors in a given sentence. GEC has recently attracted more attention due to its ability to correct and proofread the text, which can serve a variety of industries such as education, media and publishing <ref type="bibr" target="#b2">(Wang et al., 2021b)</ref>.</p><p>However, Chinese GEC (CGEC) is still confronted with the following three obstacles: (1) Lack of data. The major obstacle in CGEC is that the high-quality manually annotated data is limited compared to other languages <ref type="bibr">(Dahlmeier et al., 2013;</ref><ref type="bibr">Napoles et al., 2017;</ref><ref type="bibr">Rozovskaya and Roth, 2019;</ref><ref type="bibr">Bryant et al., 2019;</ref><ref type="bibr">Flachs et al., 2020;</ref><ref type="bibr">Trinh and Rozovskaya, 2021)</ref>. There are only five publicly accessible datasets in CGEC: NLPCC18 <ref type="bibr" target="#b5">(Zhao et al., 2018)</ref> , <ref type="bibr">CGED (Rao et al., 2020)</ref>, CTC-Qua, YACLC <ref type="bibr" target="#b1">(Wang et al., 2021a)</ref> and MuCGEC <ref type="bibr" target="#b4">(Zhang et al., 2022)</ref>. (2) Data sources are nonnative speakers. The sentences in NLPCC18, CGED, YACLC and MuCGEC are all collected from Chinese as a Foreign Language (CFL) learner sources. However, massive errors from native speakers rarely arise in these sources. Therefore, the native speaker errors are more challenging with the inclusion of pragmatic data. Though CTC-Qua covers grammatical errors in native speakers, it has insufficient scale with 972 sentences. (3) Limited multiple references. For an erroneous sentence, there tends to be different correction methods. The sentences revised by the model may be correct, but different from the ground truth. This may cause unexpected performance degradation <ref type="bibr">(Bryant and Ng, 2015)</ref>. Besides, more references can offer various correction schemas enabling the model to accommodate more scenarios. Among CGEC, only MuCGEC and YACLC provide rich references.</p><p>To tackle aforementioned obstacles, we present FCGEC, a large-scale fine-grained GEC corpus with multiple references. The sentences in FCGEC are mainly collected from multi-choice questions in public school Chinese examinations. Therefore, our FCGEC is more challenging since it involves more pragmatic data in the examinations of native speakers. As for multiple references, we assign 2 to 4 annotators on each sentence, thus more references can be attained in this way. Moreover, we generate more references in the annotation process through techniques with synonym substitution.</p><p>In order to correct the grammatical errors, recent works are mostly based on two categories of benchmark models. Sequence-to-sequence (Seq2Seq) approaches regard GEC as a generation task that straightforward converts an erroneous sentence to the correct one <ref type="bibr" target="#b3">(Yuan and Briscoe, 2016;</ref><ref type="bibr" target="#b6">Zhao and Wang, 2020;</ref><ref type="bibr">Fu et al., 2018)</ref>. However, training such a generation model requires more computational resources due to the autoregressive decoder. Moreover, the generated style of Seq2Seq models is more arbitrary, which is not well applicable for GEC task. More recently, sequence-to-edit (Seq2Edit) approaches gain interests which take GEC as a token-level labeling task <ref type="bibr">(Awasthi et al., 2019;</ref><ref type="bibr">Omelianchuk et al., 2020)</ref> via different edits, such as insert, delete, etc. Nevertheless, previous work falls short on altering the word order and correcting errors simultaneously with iterating.</p><p>To fill these gaps, we propose Switch-Tagger-Generator (STG) model as an effective baseline to correct grammatical errors in low-resource settings inspired by <ref type="bibr">Mallinson et al. (2020)</ref>. Our STG can be decomposed into three modules: Switch module determines the permutation of characters while Tagger module identifies the operation tags of each character in the sequence. Notably, benefiting from carefully designed compound tags, we eliminate the necessity for iteration. As for Generator module, we adopt non-autoregressive approach to fill in the characters that do not appear in the source.</p><p>In summary, our contributions are as follows:</p><p>1. We present FCGEC, a large-scale fine-grained corpus with multiple references and more challenging errors for CGEC.</p><p>2. We propose a STG model and then conduct experiments to compare with two categories of benchmark models (Seq2Seq and Seq2Edit). Experimental results illustrate that our STG model outperforms these models on FCGEC.</p><p>3. We find a significant gap between human performance and benchmark models that encourage future models to bridge it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus Construction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Collection</head><p>We collect raw sentences mainly from two resources to obtain various Chinese grammatical error corpus from native speakers.</p><p>(1) Public examination websites. We crawl the multi-choice grammatical error problems (More erroneous sentences than correct sentences) through public websites which contain exercises and exams designed by teachers and experts. These problems cover public school examinations for native students from elementary to high school.</p><p>(2) News aggregator sites. To balance the quantity of erroneous sentences and correct sentences, we attain a diverse range of high quality sentences without grammatical error in news aggregator sites. In total, we collect 54,026 raw sentences from these resources. After removing duplicated or incomplete sentences, there are 41,340 sentences in our FCGEC corpus. We describe in detail the data sources and data structures in Appendix A &amp; B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fine-grained Data Format</head><p>To facilitate model for grammatical error detection and correction, we designate three-tier hierarchical levels of golden labels in FCGEC as follows:</p><p>Detection Level. As a preliminary procedure to correcting grammatical errors, we require the binary classification of a given sentence according to whether it contains grammatical errors or not.</p><p>Identification Level. The labels in this level could be regarded as necessary for a multi-class categorization problem. As the examples shown in <ref type="table" target="#tab_1">Table 1</ref>, we group grammatical errors into seven categories based on the error hierarchy. The definition of error types are as follows: Incorrect Word Collocation (IWC) is a word-level grammatical error in which the related words are combined in the improper pattern. Component Missing (CM) and Component Redundancy (CR) are also wordlevel errors that some components (e.g., subject and object) of the sentence are missing or redundant. Structure Confusion (SC) is a syntax-level grammatical error that combines two similar grammatical structures into a single incorrect one. Incorrect Word Order (IWO) covers grammatical errors in word-level and pragmatic-level. Compared to the previous work <ref type="bibr" target="#b4">(Zhang et al., 2022)</ref>, we also take into account the errors that require logic, common sense on top of syntax (e.g., recursive relationships). Illogical (ILL) and Ambiguity (AM) are pragmatic errors. The former comprises contradictory statements, while the latter includes expressions with indeterminate meanings.</p><p>Correction Level. In the correction level, we propose an operation-oriented paradigm to construct GEC labels instead of the error-coded or rewriting paradigms utilized in previous works <ref type="bibr">(Ng et al., 2014;</ref><ref type="bibr">Sakaguchi et al., 2016)</ref>. In rewriting paradigms, the annotators directly rewrite the raw sentences to the correct sentences without grammatical errors. However, it is difficult for annotators  to rewrite in a consistent style, which leads to a drop in annotation quality. As for the error-coded paradigm, the annotators may diverge in determining the boundaries of the erroneous spans, thus raising the complexity of the procedure. In contrast, the operation-oriented paradigm is on the basis of four fundamental correction operations : Insert, Delete, Modify and Switch. As an example shown in <ref type="figure" target="#fig_0">Figure 1</ref>, this paradigm is more compatible with the conventions of the annotator when correcting errors. Meanwhile, annotators only need to consider what operations are required to correct the sentences, instead of paying attention to the erroneous span (e.g., the selection of the words is left to post-processing for unified optimization). In addition, we have a large amount of correction prompts (explanations of grammatical error problems) developed by teachers and experts based on these four operations that can be utilized to accelerate annotation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Annotation Procedure</head><p>The annotators are asked to follow the given prompts to complete the three levels of labeling. Notably, we allow annotators to add unlimited references to sentences with grammatical errors based on the four operations in error correction level.</p><p>In order to improve annotation efficiency, we have developed a visual online tool to support the annotation procedure. In addition, we applied pattern matching and rule-based scripts to automatically convert a large amount (72.3%) of prompts into operation labels. We show the interface of our visual annotation tool in Appendix C.</p><p>As for annotation process, we hire 20 undergraduate students and 4 expert examiners to annotate and verify the GEC labels. We follow the annotation procedure in SuperGLUE <ref type="bibr">(Wang et al., 2019a)</ref> Type Example IWC ??????????????????? You have smart hands to do everything.</p><p>(Tips: "hands" cannot be combined with "smart") CM ??????????? Plants have (the ability) to produce oxygen.</p><p>(Tips: Lack of object "the ability" )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????</head><p>We had walked about 10 miles or so.</p><p>(Tips: "about" and "or so" are redundant) SC ??????????????????? Traffic accidents are caused by (because) looking at cell phones while driving.</p><p>(Tips: the structure of "because" and "caused by"</p><p>cannot appear together in one sentence) IWO ????????????? I corrected and realized my fault.</p><p>(Tips: realize the fault first and correct it later)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ILL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????</head><p>We should prevent accidents from not occurring.</p><p>(Tips: double negation causes illogical errors)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????????</head><p>As the door opened, the doctor/patient came in.</p><p>(Tips: there is an ambiguity about who comes in) that each annotator should work on test data first. After that, they can compare their labels with the gold ones. We encourage them to discuss their mistakes, questions and standards with other annotators and experts. To attain high-quality annotation with multiple references, we duplicate the sentences in our corpus 2 to 4 times. Furthermore, it is guaranteed that the redundant sentences are annotated by different annotators. Then experts are asked to review data that the annotators could not in agreement on the labels and add reasonable references. It is worth mentioning that we search for possible synonyms of the characters generated by Insert and Modify operations in annotation. We believe that supplying more word choices to annotators can improve the multi-reference rate. Moreover, we set up a weekly communication meeting to discuss common issues in annotation and adapt the labeling criteria. In total, the entire annotation procedure lasted for more than 4 months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Quality Control</head><p>To ensure the high-quality of our FCGEC, we adopt the following five criteria: (1) Each sentence is in-   spected by two specialized annotators to correct spelling and punctuation errors before annotation. Meanwhile, they have to eliminate the incomplete sentences (due to unexpected text truncation).</p><p>(2) The specialized annotators were also asked to tag the sentences from news aggregator source that might have grammatical problems while checking spelling errors. Then these potential sentences will be discussed in weekly communication meeting.</p><p>(3) We ask the annotators to read our guidelines and annotate twenty test instances. Then experts check their accuracy of the annotation. The annotators that meet the accuracy (90%) could continue to label the official data. (4) We assign 2x to 4x annotators per sentence for the corpus. In case their annotations are different, the experts will determine the correct labels. After that, annotators can also learn from these mistakes to achieve selfimprovement. (5) After annotation, we unify the annotated labels under the minimal operation criteria inspired by Dahlmeier and Ng (2012) which applies fewer operations during correcting grammatical errors. More details about minimal operation algorithm is described in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Data Statistics and Comparison</head><p>We compare our corpus with other Chinese grammatical error datasets in <ref type="table" target="#tab_3">Table 2</ref>. Moreover, the concrete statistics of FCGEC are shown in <ref type="table" target="#tab_4">Table 3</ref> Figure 2: Correlation between types and operations.</p><p>and Appendix D. We summarize the advantages of our FCGEC in the following three aspects:</p><p>Multiple References. As discussed in <ref type="bibr">Bryant and Ng (2015)</ref> and <ref type="bibr" target="#b4">Zhang et al. (2022)</ref>, the training and evaluation of GEC models can benefit from multiple references. In order to obtain more references, we ask the annotators to submit different reasonable operations for correcting errors. Meanwhile, we specifically provide several choices of synonyms for the generated text during annotation. We search for synonyms using both fine and coarse granularity. The fine-grained approach is to obtain synonyms from electronic dictionaries, while the coarse-grained way relies on similarity of the word vectors. It enhances the ratio of multiple references.</p><p>More Pragmatic Data. Pragmatic data involves errors in logic, common sense, ambiguity, etc. We increase the proportion of pragmatic data <ref type="table" target="#tab_12">(Table 6)</ref> compared to other CGEC datasets, thus rendering the data more complex and challenging. Notably, we fix the ambiguity errors by providing references to correct them from different semantics.</p><p>Effective Error Types. We assign more refined error types to the grammatical errors, and these types are closely related to the correction operations. As shown in <ref type="figure">Figure 2</ref>, error types are always highly relevant to particular operations (e.g., CM and CR rely on Insert and Delete operations respectively). We believe that error types can be utilized as auxiliary data to improve the performance of the GEC models to correct grammatical errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Benchmark Models</head><p>We divide the GEC task into a classification task and a correction task. The classification task involves the error detection and error type identification. We adopt the pre-trained language models (PLMs) based approaches for these tasks. As for the correction task, we propose a STG model to correct errors. Meanwhile, two categories of mainstream GEC models (Seq2Seq and Seq2Edit) are applied as benchmark models for our FCGEC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baselines for Classification Task</head><p>In error detection subtask, the model needs to determine whether a given sentence contains grammatical errors. Therefore, it is a binary classification task while the type identification subtask can be regarded as a multi-class classification task. The model should predict which of the seven error types the given erroneous sentences belong to. Note that some sentences may have multiple error types.</p><p>Recently, PLMs are proved to be effective and achieve success in various fields, such as BERT  <ref type="bibr" target="#b0">(Wang et al., 2019b)</ref>. Therefore, we adopt different PLMs enhanced models as the benchmark models for these classification tasks. Specifically, we treat multiple PLMs as the backbone network and apply fully-connected layers on top of it for detection and identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proposed STG Model</head><p>To correct grammatical errors, we propose an effective benchmark model, STG, which tackles error correction in the low-resource settings. <ref type="figure" target="#fig_2">Figure 3</ref> gives an overview of our model. STG decomposes the error correction task into three processing modules: Switch , Tagger and Generator. The Switch module determines the order of characters that appear in the output on the basis of pointer network <ref type="bibr">(Vinyals et al., 2015)</ref>. Our Tagger module predicts the operation tags of each character and the number of characters that need to be generated in sequence. As for the Generator module, it fills in the characters that are not present in source sentence. Notably, each module can be trained independently. Switch Module. The input to Switch module for character i is the hidden representation h i ? R d from PLM, where d denotes the dimension of hidden representations. Then Switch module determines the next position index for character i based on the pointer network. We apply the self-attention to predict which possible character e(i) would be pointed to. It can be formulated as:</p><formula xml:id="formula_0">! " # $ % &amp; ' ( ) ! * ! ' ( $ % &amp; " # ) ! * TAGGER Module I revised and realized my shortcomings ! ' ( $ % &amp; " # ) ! * K K K K M M GENERATOR Module K K K K K ! ' ( $ % &amp; # + )</formula><formula xml:id="formula_1">p (e(i)|h i ) = attention h i , h e(i)<label>(1)</label></formula><p>The self-attention with scaled dot-product can be computed as below:</p><formula xml:id="formula_2">A = Attention (Q, K) = softmax QK T ? d</formula><p>(2) where A is attention score matrices, Q and K are both linear projections of h. More details about our Switch module can be found in H.1.</p><p>Tagger Module. We first define five tags corresponding to the three operations (except Switch operation) as follows: the KEEP (K) tag is utilized to maintain the source character while the DEL (D) tag is assigned to remove character from source sequence. The tag of INS_t (I_t) represents the insertion of t words after the current character. The substituted character is marked as MOD (M) tag for Modify operation. As for the special case where the character is both substituted and required to insert other characters, we set the tag of MINS_t (MI_t) similar to I_t. Modification tags can perform a combination of multiple operations on a single character at the same time, thus eliminating the need to correct the sentence via iterations as other edit-based methods. Limited by space, we provide some concrete examples in the Appendix H.2.</p><p>We take the prediction of tags and the number t of characters to be inserted or substituted for each character as classification task. Therefore, we apply two fully-connected layers to obtain tags and the number t. They can be written as:</p><formula xml:id="formula_3">T = ? (W h s i + b)<label>(3)</label></formula><p>where T denotes the tag or number t while h s i is the hidden representations of character i. And ? stands for the softmax function. W and b are the learned weights and bias.</p><p>Generator Module. As we can leverage the masked language modeling (MLM) task (Devlin et al., 2018) of BERT-style PLMs for generating the characters which do not appear in the source sequence, Generator module inserts or substitutes the character with a certain number t of [MASK] token according to their tags. Then it predicts which characters are suitable to fill into the masked places.</p><p>Training and Testing. During the training process, we utilize cross-entropy loss L switch , L tag and L gen for the three modules. The STG model can be trained in two paradigms: independent and joint. The difference between them is whether each module is trained separately and thus they cannot utilize the shared encoder. We combine the loss in joint paradigm as follows:</p><formula xml:id="formula_4">L(?) = ? 1 L switch + ? 2 L tag + ? 3 L gen + ?? ? 2</formula><p>(4) where ? ? is the coupling co-efficiency that regulates the three losses.? represents all trainable parameters in STG model and ? denotes the coefficient of L 2 -regularization. L tag is always larger than the other two losses, thus we generally set it one order of magnitude smaller. Furthermore, we train STG model with type identification (TTI) task to utilize auxiliary type data to improve model performance.</p><p>As for testing phase, we feed the erroneous sentence into each module in a pipeline fashion to correct errors. Specifically, we adopt constrained beam search to decode the sequence order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Other Baselines for Correction Task</head><p>In order to present mainstream error correction models on our corpus, we take two categories of approaches as benchmark models: Seq2Edit Models. Recent works also focus on the Seq2Edit models, which correct errors by labeling manipulations of each character. <ref type="bibr">LaserTagger (Malmi et al., 2019)</ref> is applied to modify the sequence with three types of edits: insertion, deletion and substitution. PIE (Awasthi et al., 2019) presents iterative edit with custom inflection operations to correct the grammatical errors. GECToR <ref type="bibr">(Omelianchuk et al., 2020)</ref> is an iterative sequence tagging framework with custom g-transformations that we adapt it to CGEC follow the efforts of <ref type="bibr" target="#b4">Zhang et al. (2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>Classification Task. We regard the error detection task and error type identification task as classification tasks. Therefore, we adopt four common metrics, i.e., Accuracy, Precision, Recall and Macro F 1 score to evaluate the model performance.</p><p>Correction Task. As for correction task, we employ two different metrics : (1) Exact Match metric is obtained by calculating the percentage of corrected sentences for model outputs that exactly matched with the golden references. <ref type="formula">(2)</ref> The character-level edit metrics proposed by MuCGEC <ref type="bibr" target="#b4">(Zhang et al., 2022)</ref> are utilized to compute finegrained model performance. After obtaining the optimal sequence for character-level editing, they merge consecutive edits of the same type into spanlevel for both model outputs and golden references. Then MuCGEC calculates the highest Precision, Recall and F 0.5 score by comparing the edits of model outputs with each golden reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>We conduct detailed experiments for fairly comparing benchmark approaches on our FCGEC. In classification tasks, we adopt officially released PLM  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Human Evaluation Results</head><p>We hire 25 annotators from the crowd-sourcing platform of NetEase with a wide range of degrees and occupations. Specifically, annotators are restricted to be native speakers. We require them to annotate 10 instances for familiarization with the task requirements. Then they annotate 7,500 pieces of data (we randomly select 1,500 sentences from the test set and duplicate them 5 times), which is used to evaluate our human performance. As shown in <ref type="table" target="#tab_6">Table 4</ref> and 5, the error detection task is relatively easy for humans while error type identification task is harder due to the fact that it has more categories. As for correction task, it is also challenging for humans to correct grammatical errors. We further discuss the human performance based on the model performance in Section 4.4.</p><p>1 https://huggingface.co/models</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Overall Performance</head><p>The results of the classification tasks on FCGEC are shown in <ref type="table" target="#tab_6">Table 4</ref> for different PLMs from which several observations can be derived. First, the largesize variant PLMs perform better than other basesize models on the both detection and identification tasks as they can represent richer semantic information. To illustrate this observation, we roughly divide the error types into semantic and syntactic groups. We find that the average accuracy improvement for larger PLMs is significantly higher on the semantic group (7.6%) compared to the syntactic group (2.8%). Second, StructBERT-Large outperforms all PLMs on detection task while RoBERTa-Large achieves better performance on identification task, demonstrating two strong baselines at FCGEC. Moreover, there is an interesting observation on identification task that the humans have a lower performance of Recall than all PLMs, while the Precision is significantly better than them.</p><p>In terms of the correction task, <ref type="table" target="#tab_8">Table 5</ref> demonstrates the results of benchmark models on FCGEC. The overall performances of Seq2Edit-based models are better than the Seq2Seq-based models. Furthermore, our STG-series models substantially outperform them on FCGEC, which proves the effectiveness of STG architecture. Finally, there is still a significant gap comparing best-performing models with humans in all tasks. Moreover, the difficulty of the task also increases gradually on the detection, identification and correction, which are reflected on the difference of gap between models and humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Comparative Analysis</head><p>Independent training vs. Joint training. As we describe in Section 3.2, the Switch, Tagger, Generator modules in our STG can be trained flexibly either independently or jointly. In <ref type="table" target="#tab_8">Table 5</ref>, STG with joint training (STG-Joint) brings gains of 4.17% in EM score and 4.86% in F 0.5 score compared with independent training STG (STG-Indep). The results indicate that the performance of correction can be enhanced during joint training since each module of STG can share more information and complement each other under a unified optimization objective.</p><p>Investigate the benefit of error type identification to correction. In <ref type="figure">Figure 2</ref>, we illustrate the correlation between error types and the operations of correction. We observe a significant association among error types and operations, which motivates  us to treat error type identification as an auxiliary task (TTI) for training STG model. As shown in <ref type="table" target="#tab_8">Table 5</ref>, STG-Indep+TTI indicates that the three modules of STG are trained independently with the TTI task incorporated. Our STG achieves better performance after integrating the TTI task compared with STG-Indep, which demonstrates the efficient error type data can be utilized as auxiliary data to enhance model correction performance. Moreover, STG-Indep+TTI can also obtain an accuracy improvement of 1.78 points on the error type identification task compared to RoBERTa.</p><p>Fine-grained performance analysis. In <ref type="figure">Figure 4</ref>, we demonstrate the fine-grained performance based on grammatical error types for identification task with RoBERTa-Large and correction task with STG-Joint. Notably, the dark sectors in the pie chart of the identification task indicate the proportion of errors for visual comparison. First, we observe the minimum error rate on SC, indicating that the PLM is more sensitive to syntactic structure errors. Second, the PLM performs weakly in terms of word-level errors, especially CR. After analyzing the error scenarios, we discover that the PLM may easily treat CR and CM errors as IWC errors. Furthermore, the PLM fails to determine the error types at the pragmatic level (i.e., ILL and AM), which illustrates the challenge of FCGEC. As for correction task, it is clear that the performance on CM and IWC is inferior. We consider this potentially due to the fact that CM and IWC always require the generation of characters, increasing the difficulty of correction. Moreover, the model encounters trouble with AM due to the inclusion of  <ref type="figure">Figure 4</ref>: The fine-grained performance on identification and correction tasks. The numbers in the sectors of the pie chart indicate the error rate and EM / F 0.5 score on identification task and correction task, respectively.</p><p>pragmatic data such as ambiguity. It is hard for the model to distinguish the semantics in the sentences and correct it. In addition, we present more comparisons and fine-grained analyses in Appendix I.</p><p>Influence of the three modules in STG. The correction performance of our STG model is affected by three modules simultaneously. Thus we further investigate the impact of these modules on the STG-Joint. As shown in <ref type="figure" target="#fig_4">Figure 5</ref>, we analyze the char-level and sentence-level accuracy of each module. We ignore the Keep tag when calculating the char-level accuracy in Tagger module.</p><p>Tagger-t Acc. is computed for the number t of I_t and MI_t tags. The first observation is that the performance of model is mainly constrained by Tagger module, while it fails to predict tags and number t precisely. Secondly, the performance of the Generator module illustrates that it is possible to achieve acceptable performance via only utilizing non-autoregressive approach with fine-tuning. Furthermore, despite the high performance of the Switch module, its role as the first module in the pipeline has a significant impact on the Tagger and Generator modules. Therefore a more robust performance of the Switch module is needed.   <ref type="bibr" target="#b4">(Zhang et al., 2022)</ref> are four publicly available non-native speaker resources for CGEC community, which encourage us to construct a high-quality CGEC corpus derived from native speakers. As for the progress of GEC approaches, Seq2Seq and Seq2Edit are two mainstream approaches that achieve competitive results. Most of the work is based on Seq2Seq framework that generates the correct sentences directly <ref type="bibr" target="#b7">(Zhou et al., 2019;</ref><ref type="bibr">Wan et al., 2020;</ref><ref type="bibr" target="#b6">Zhao and Wang, 2020;</ref><ref type="bibr">Kaneko et al., 2020)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we construct a large-scale corpus for Chinese grammatical error detection, identification and correction. Compared to previous CGEC corpus, our FCGEC is more complicated and challenging with pragmatic data. Furthermore, we provide multiple references so that the models can be evaluated for better performance. Furthermore, we propose a STG model to correct grammatical errors. Extensive experiments demonstrate that our STG outperforms the baselines and achieves the state-ofthe-art performance. However, experiments show that there exists a notable gap between cutting-edge models and humans. Therefore, it encourages the future GEC models to bridge the gap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The limitations of our work can be categorized into two main aspects: our corpus and model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of FCGEC.</head><p>In our FCGEC, a small number of sentences can be considered as different types of grammatical errors depending on correction methods. We do not provide a finer distinction between error types in this version. However, such fine-grained labels may supply more benefit in correction tasks (employing TTI as a auxiliary task).</p><p>Limitations of STG. The major limitation of our STG is that although no iteration is required, it corrects the errors via a pipeline paradigm with each modules in inference stage, thus it takes more time in the inference stage. Moreover, we consider that better performance may be achieved if the Generator module is pre-trained with a massively parallel corpus such as Lang-8 <ref type="bibr" target="#b5">(Zhao et al., 2018)</ref>, which we do not conduct in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Licensing Issues. FCGEC is a CGEC dataset collected from public examination websites and news aggregator sites. We collect the original grammatical error data or news data under the license of these sites or request for their permission. Meanwhile, the full attribution for original source of the data is cited in our FCGEC. In addition, we also commit not to use the corpus for commercial purposes, but only for the research studies.</p><p>Annotator Compensation. In our annotation procedure, we hire two categories of annotators. The first type is the annotators who annotate or examine the data for our FCGEC. We estimate that a skillful annotator requires about 1 to 2 minutes for each sentence to identify the error types and correct errors. On this basis, we pay the annotator 7 yuan (about 1 dollar) for 10 sentences. The second category is annotators from the crowd-sourcing platform of NetEase for computing human performances on FCGEC. Since they only require to do the measurement of the data, we set the compensation to 4 yuan (about 0.6 dollar) per 10 sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Source of Data Collection</head><p>For the source of public examination websites, we collect the practice exercises from KS5U (http: //5utk.ks5u.com/main.aspx), which are accessible online for public usage. As for the news aggregator sites (e.g., ZAKER, IT Home etc.), we randomly collect the titles or topic sentences from these sites. After that, we manually check and correct the sentences as we describe in Section 2.4 to ensure the quality of our corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Data Structure</head><p>We employ the JSON format to construct our FCGEC, as illustrated below: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Visual Interface of Annotation Tool</head><p>As shown in <ref type="figure" target="#fig_7">Figure 6</ref>, we develop a visual annotation tool for the annotation process. Given an erro-neous sentence, annotators are able to utilize this tool for easily identifying the error types and correcting the errors via four operations, i.e., Switch, Delete, Insert and Modify. Concretely, the annotators only need to drag or click on the small blocks which represent each character at the bottom of the main form to complete the corresponding operation. In order to support multiple references of the correction task, we provide a button for adding a reference up to five. Moreover, the small form on the right side displays correction prompts from teachers and experts to inform the annotators of the correction. Our tool can automatically convert these prompts to operations via rules. In addition, the real-time correction labels are displayed on the bottom of this small form. Furthermore, our tool enables convenient comparison of multiple annotation operations of a sentence by different annotators, so that expert examiners can select the reasonable references. In practice, this flexible annotation tool has greatly accelerated our annotation procedure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D More Statistics of FCGEC</head><p>We conduct more statistics on our corpus, including the length distribution of sentences, the proportion of error types in each category and the distribution of the number of reference numbers.</p><p>Length distribution of sentences. We compute the distribution of sentence lengths in our corpus. As shown in <ref type="figure" target="#fig_8">Figure 7</ref>, the length of the longest sentence is 359, while the shortest only contains 9 characters. Furthermore, the average sentence length is 53.06. Based on this, we can use various types of PLMs to encode sentences from the corpus without having to deal with exceeding the length.</p><p>Distribution of error types. In <ref type="table" target="#tab_12">Table 6</ref>, we calculate the proportion of grammatical errors in the seven error categories on train set, validation set   and test set. We can observe that the error types are split as closely as possible with a similar distribution. Moreover, we can notice that the pragmatic type of error (ILL, AM and part of the IWO) also accounts for a significant proportion. Therefore our corpus tends to be more challenging.</p><p>The distribution of references. For the erroneous sentences, we allow the annotators to correct them through a variety of references. Thus the distribution of sentences with respect to the number of references is shown in <ref type="figure" target="#fig_9">Figure 8</ref>. First, we analyze sentences with a single reference and find that most of them are due to two scenarios: (1) The sentence is short or the grammatical error is very simple and obvious.</p><p>(2) Some categories of errors often have only one way to correct them, such as IWO and ILL. Second, for sentences that contain two references, the errors of SC play a significant role in them. This is due to the fact that SC errors are always corrected by removing one of the two similar grammatical structures. More references for correcting sentences often indicate the need to insert or modify characters. Furthermore, we consider that the number of references could be increased via an enhanced and more refined annotation process and   by assigning more annotators to each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Algorithm of Minimal Edit</head><p>Given a pair containing the incorrect sentence and the corrected sentence, we design an algorithm to generate the operation labels under the minimal operation criteria from such pair. The algorithm is illustrated in Algorithm 1. It is mainly utilized in the following two scenarios: (1) Automatically convert the prompts of teachers and experts into operation labels for our visual annotation tool.</p><p>(2) Based on this algorithm, we can unify the operation labels after annotation procedure to ensure that fewer operations are adopted during correcting grammatical errors for quality control. Besides, this can also help us to check for mistakes and guarantee the consistency of the data in the annotation. In addition, we can convert the data from other formats (i.e., rewriting and error-coded paradigm) to our operation labels through this algorithm. Thus we can apply our STG model to other datasets.</p><p>Algorithm 1 Attain the operation labels via minimum edit distance.</p><p>Input: Source sentence S and target sentence T . Output: The operation labels L that convert S to T . 1: if S == T then 2:</p><p>return [{}] 3: end if 4: L = [{}] 5: tags = ["Copy", "Modify", "Delete", "Insert"] 6: mov = [(?1, ?1), (?1, ?1), (?1, 0), (0, ?1)] 7: Calculate the character frequency fS of S, and fT of T . 8: if fS == fT then 9:</p><p>Calculate the longest common substring s1 and second longest one s2 between S and T . 10:</p><p>Swap the positions of s1 and s2 with their indexes pori in S. Then the swapped sentence Sswap and indexes pswap can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>if Sswap == T then 12: L = [{"Switch" : pswap}] 13: else 14:</p><p>goto <ref type="formula" target="#formula_1">17</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F The Demographic of Humans</head><p>In order to evaluate human performance on our FCGEC, we employ 25 annotators from the crowdsourcing platform of NetEase. Moreover, with the aim of measuring human performance as completely as possible, we hire a diverse range of annotators with different aspects (Education, occupation, age, etc.). As shown in the <ref type="table" target="#tab_14">Table 7</ref>, the platform of NetEase provides us with their non-private demographic information about the annotators.</p><p>It is worth mentioning that we ask the annotators to label more data (randomly sampling 50% of the test set and then duplicating them 5 times) compared to other work as a way to attain more precise human performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Details of Pre-trained Language Models</head><p>We enhance the performance of the model with PLMs for both the classification and correction tasks. In order to enable better reproduction of our results, we provide the details and links to officially released pre-trained parameters in the <ref type="table">Table 8</ref>. In Seq2Seq models, we adopt CPT as the Chinese BART model. In particular, since some Chinese punctuation is missing in the vocabulary of the BART model (e.g., Chinese quotation marks), we avoid performance degradation by substituting the punctuation with their English counterparts during pre-processing stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Details of Our STG Model</head><p>To better illustrate the details of our STG model, we present additional input samples and the processing for the three modules in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.1 Switch Module</head><p>As we describe in Appendix B, the labels of Switch indicate the order of the original character index after swapping. However, the index of the next character is predicted for each character in our Switch module. Therefore, we need to fill this gap by converting these labels. We demonstrate the differences between these two label types in <ref type="figure" target="#fig_10">Figure 9</ref>. In Switch module, we utilize pointer network with self-attention mechanism to predict which character will be pointed to of each character. Furthermore, we adopt cross-entropy as the loss function to measure the margin between attention score matrix A and the golden labels for optimizing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2 Tagger Module</head><p>In section 3.2, we introduce five tags (K, D, INS_t, M and MI_t) that correspond to the three operations (i.e., Delete, Insert and Modify) in Tagger module. For better understand our tags, we present some concrete examples in <ref type="figure" target="#fig_0">Figure 10</ref>. With this well-designed tagging criterion, our STG model can perform arbitrary manipulations of the sequence without iteration. During the training stage, we employ two classification layers to determine the tags and the number t of INS_t and MI_t, separately. Meanwhile, The cross-entropy is also applied to compute the loss. We optimize both of the parameters in the two classification layers simultaneously by combining the loss of them. Generater Module</p><formula xml:id="formula_5">A B C D K J E F G H I</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X Y</head><p>Output Characters: <ref type="figure" target="#fig_0">Figure 11</ref>: An example about the model input of generator module.</p><p>In particular, we try a small trick (Note that the trick is not adopted for the results of our STG models in <ref type="table" target="#tab_8">Table 5</ref>, for fair comparison) that can further improve the performance of the model, which is to utilize the weighted cross-entropy loss. As the majority of tags in a sentence are Keep, it is intuitive to increase the weight of other tags to solve this typical category imbalance problem. After we conduct experiment on STG-Joint with this trick, we observe a 0.72% performance improvement in Exact Match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.3 Generator Module</head><p>In Generator module, we exploit the features of BERT-style PLMs to predict the characters which  do not appear in the source sentence. The outputs of Tagger module are utilized to generate the input sequence with [MASK] tokens. We present an example of the input sequence in <ref type="figure" target="#fig_0">Figure 11</ref>. After that, the Generator module predicts the indexes of the characters in vocabulary list that should be filled in at <ref type="bibr">[MASK]</ref>. Similarly, the crossentropy loss is adopted for optimizing the parameters in Generator module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I More Comparisons and Analysis</head><p>To further investigate the differences in the ability of the correction models, we present more comparisons and analyses in this section.</p><p>Performance on four operations of correction. <ref type="table" target="#tab_18">Table 9</ref> illustrates another perspective of the finegrained results that we calculate the performance of correction models on different operations. More specifically, we split the entire test set into four small subsets that contain only one operation for incorrect sentences. Then we compare our STG-Joint model with the best performing models in the Seq2Seq and Seq2Edit categories, respectively.</p><p>First, we can observe that our STG-Joint is significantly outperforms the other two models in terms of Switch operation. This is due to the fact that we design a special Switch module to efficiently handle such operation. Secondly, the performance of STG-Joint and LaserTagger is comparable in terms of Delete operation. However, Seq2Seq model behaves relatively weakly, due to its arbitrary modifications that often tend to delete more characters. Lastly, we discover that all models have poor performances on Insert and Modify operations, indicating that the task of generating new characters is more challenging.</p><p>Original performance of MuCGEC. In Section 4.4, we substitute the original backbone of the Seq2Seq and Seq2Edit models in MuCGEC <ref type="bibr" target="#b4">(Zhang et al., 2022)</ref> for a fair comparison. We</p><formula xml:id="formula_6">Model P R F 0.5</formula><p>Seq2Seq+CPT   conduct additional experiments to demonstrate the original performance of models in MuCGEC. They employ the PLMs of Chinese-BART-Large 2 and StructBERT-Large 3 for Seq2Seq and Seq2Edit (GECToR) model, respectively.</p><p>We present the results of MuCGEC in <ref type="table" target="#tab_1">Table 10</ref>. It is clear that the performances of models with large-size PLMs are better than those of the basesize PLMs. Specifically, Seq2Seq model is greatly improved after applying BART-Large as the backbone. Moreover, it is close to the results of our STG-series models. However, there is only a slight improvement of F 0.5 for the Seq2Edit model. After we further observe the error examples of Seq2Seq and Seq2Edit on the test set, we discover that the results of Switch operation are the critical limitation for Seq2Edit model. This also illustrates the necessity of the Switch module in our STG.</p><p>Performances on the validation set. In order to evaluate the distribution of our split dataset, we show the results of the best performing models on the corresponding validation set for the three tasks (detection, identification and correction) in <ref type="table" target="#tab_1">Table 11</ref>. It is reasonable to observe that the performance on the validation set is slightly better than on the test set. Therefore, we keep the data distribution on the validation set close to the test set,   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Case Study</head><p>In order to explore the performance of the models on the correction task, we conduct analyses on case examples. Similarly, we compare STG-Joint with the best performing models in the Seq2Seq and Seq2Edit categories (MuCGEC and LaserTagger). We present the cases in <ref type="table" target="#tab_1">Table 13</ref>. Meanwhile, the English version of the cases can be seen in <ref type="table" target="#tab_1">Table 14.</ref> In particular, since the ground truth contains multiple references, we represent one of them as an illustration due to space constraints. Note that the results of the models in <ref type="table" target="#tab_1">Table 13</ref> are based on the multiple references.</p><p>We can derive several observations from these case examples. First, in the category of word order errors (IWO), both Seq2Seq and Seq2Edit models can correct the elementary errors (Example 10). However, they fail to solve the more difficult order errors (progressive relationship problem in Example 9). Since our STG model is specifically equipped with the Switch module, it is possible to correct for these errors. Secondly, in the case of error categories that require the generation of new characters (e.g. CM and IWC), more improvements are required for all models. Finally, the pragmatic errors are the most difficult to correct (especially for AM). We encourage future models to pay more attention to these types of errors.  <ref type="table" target="#tab_1">Table 13</ref>: The case study for comparing the performances of models. The characters in red denote the differences between erroneous sentences and ground truth. We demonstrate the English version in <ref type="table" target="#tab_1">Table 14</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type Erroneous Sentence</head><p>Ground Truth Tips IWC 1. In recent years, we have struggled to cut down cancer mortality by improving cancer screening, clinical care and the supply of drugs.</p><p>In recent years, we have struggled to reduce cancer mortality by improving cancer screening, clinical care and the supply of drugs.</p><p>In general, "cut down" cannot be collocated with "cancer mortality", and "reduce" should be used. 2. We have industrious people and favourable natural resources.</p><p>We have industrious people and abundant natural resources.</p><p>Usually, we pair "abundant" with "resources". CM 3. Laptops demonstrate the speed, stability and convenience and become an important tool for news coverage of various events.</p><p>Laptops demonstrate the characteristics of speed, stability and convenience and become an important tool for news coverage of various events.</p><p>In Chinese, the incorrect sentence is missing the object "characteristics".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>We should develop of reading, especially reading classics and masterpieces, so that the fragrance of books can overflow the campus.</p><p>We should develop the habit of reading, especially reading classics and masterpieces, so that the fragrance of books can overflow the campus.</p><p>Similarly, the erroneous sentence misses the object "habbit" in Chinese.</p><p>CR 5. In order to reduce the word count, this article had to be slightly redacted some.</p><p>In order to reduce the word count, this article had to be slightly redacted.</p><p>The word "some" is redundant and can be deleted. 6. From the bottom of our hearts, we thank our teachers sincerely for their quiet dedication over the years.</p><p>From the bottom of our hearts, we thank our teachers for their quiet dedication over the years.</p><p>In Chinese, the word "sincerely" is superfluous and should be removed. SC 7. The crucial thing for a person to become good or bad is that the inner reasons play a role in determining it.</p><p>For a person to become good or bad, the inner reasons play a role in determining it.</p><p>The structure of "the crucial thing for" and "play a role in" are confusing. 8. Insomnia and irritability before exams are caused by due to the excessive psychological burden with caring too much about exam results.</p><p>Insomnia and irritability before exams are caused by the excessive psychological burden with caring too much about exam results.</p><p>We can not apply the structure of "caused by" and "due to" in a sentence simultaneously. IWO 9. Olympic athletes understand that winning or losing a race is not only about the honor of the country, but also about the dignity of themselves.</p><p>Olympic athletes understand that winning or losing a race is not only about the dignity of themselves, but also about the honor of the country. "Honor of the country" and "dignity of themselves" should be swapped due to progressive relationship. 10. The school since introduced the research study, students have participated enthusiastically and their creative awareness and ability have been greatly enhanced.</p><p>Since the school introduced the research study, students have participated enthusiastically and their creative awareness and ability have been greatly enhanced.</p><p>"Since" should be placed at the beginning of the sentence ILL 11. Before the holiday, teachers emphasized over and over again to prevent accidents from not happening.</p><p>Before the holiday, teachers emphasized over and over again to prevent accidents from happening.</p><p>The double negation causes logical errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12.</head><p>When faced with difficulties, we need to think first. More thinking will avoid less troubles and mistakes.</p><p>When faced with difficulties, we need to think first. More thinking can lead to less troubles and mistakes.</p><p>More thinking leads to less errors in commonsense, while "avoid" causes errors. AM 13. Many people think that scientists engage in research and do not communicate with others, yet the facts are the best illustration of this prejudice.</p><p>Many people think that scientists engage in research and do not communicate with others, yet the facts are the best rebuttal to this prejudice.</p><p>The semantic meaning is rather ambiguous that we cannot infer the role of facts on prejudice. 14.He decided to carry (not to tell) his mother (he was going) to the hospital.</p><p>He decided not to tell his mother he was going to the hospital.</p><p>There is an ambiguity in Chinese. 15. Yi Zhang and Qiang Wang talked in class and was called to the office by the teacher.</p><p>Yi Zhang and Qiang Wang talked in class and the two were called to the office by the teacher.</p><p>There is ambiguity on who was called to the office. <ref type="table" target="#tab_1">Table 14</ref>: The English version of erroneous sentences and ground truth in case study. Furthermore, we provide tips for better understanding the grammatical errors in Chinese.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of operation-oriented paradigm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>Devlin et al., 2018), RoBERTa (Liu et al., 2019), BERT-WWM (Cui et al., 2021), MacBERT (Cui et al., 2020) and StructBERT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The architecture of our STG model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Seq2Seq Models. A portion of the works adopt Transformer-based (Vaswani et al., 2017) encoderdecoder architecture as Seq2Seq fashion for correcting grammatical errors. The neural machine translation (NMT) based method is adopted in Fu et al. (2018) to tackle CGEC. Besides, Kaneko et al. (2020) utilize BERT-fuse to incorporate BERT into an encoder-decoder model for GEC. Meanwhile, MuCGEC (Zhang et al., 2022) presents a benchmark model based on Seq2Seq architecture with the Chinese BART (Shao et al., 2021).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>The performances of three modules inSTG.    in an online web platform and then manually annotates them for GEC. By contrast, the errors in LOCNESS(Bryant et al., 2019)  are acquired from essays written by native English students. Unlike the previous dataset, CWEB(Flachs et al., 2020)   focuses on grammatical errors in low error density domains from websites. However, the scale of the data is relatively insufficient in CGEC. NLPCC<ref type="bibr" target="#b5">(Zhao et al., 2018)</ref>,CGED (Rao et al., 2020), YA-CLC<ref type="bibr" target="#b1">(Wang et al., 2021a)</ref> and MuCGEC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Furthermore, after Malmi et al. (2019) first apply the Seq2Edit approach, PIE (Awasthi et al., 2019) and GECToR (Zhang et al., 2022) are proposed to correct errors with iterating. After that, Tarnavskyi et al. (2022) employ an ensembling approach on GECToR for better performances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>{ "id(The global id of the instance)": { "sentence": The original sentence, "error_flag": Whether sentence contains errors, "error_type": The error types of sentence, "operation" : [ { The operation of the first reference }, { The operation of the second reference }, of four operations, we define each of the operations as follows: ? Suppose the given sentence is "A B C D E". 1. Switch operation {"Switch":[0,2,1,3,4]} ("A B C D E" ? "A C B D E") // The values in the list indicate the order of the original character index after the swap (Index starts from 0). 2. Delete operation {"Delete":[3]} ("A B C D E" ? "A B C E") // The characters indexed in the list will be deleted. 3. Insert operation {"Insert":[{"pos":1,"tag":"INS_1","label":["F"]}]} ("A B C D E" ? "A B F C D E") // Insert a "F" after the character indexed by "pos". 4. Modify operation {"Modify":[{"pos":2,"tag":"MOD_1","label":["F"]}]} ("A B C D E" ? "A B F D E") // Modify the character with index "pos" to "F".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>The screenshot of our annotation tool.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>The length distribution of sentences in the whole corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>?Figure 8 :</head><label>8</label><figDesc>ReferencesThe distribution of the sentences in terms of references in our FCGEC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Comparison of the differences in the two types of Switch labels. Ori. Label and Sw. Label indicate the annotated labels and the processed labels in Switch module, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Examples of the tags for five typical cases in Tagger module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>[Delete]? [Modify]????? ????????? ? ? ?? ???? To prevent the tragedy of the earthquake from not emer-[Delete] not [Modify] emerging ? happening [Switch] ??? ?? ?[Insert] ??? ?? ?? ? ?? ?</figDesc><table><row><cell cols="2">ging again, we should fortify and build .</cell></row><row><cell>[Switch] fortify? build</cell><cell>?[Insert] shelters</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Examples of different types of errors.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The comparison of different Chinese grammatical error correction corpus. Numbers in row #Error mean the percentage of incorrect sentences in the corpus. #Refs indicates the average number of references contained in each sentence on average while #Length stands for the average number of characters in each sentence. Note that CGED is a combined corpus from 2016 to<ref type="bibr" target="#b5">2018</ref>  (Rao et al., 2018<ref type="bibr" target="#b6">, 2020</ref>.</figDesc><table><row><cell cols="2">Subset Sent. Err. #S</cell><cell>#D</cell><cell>#I</cell><cell>#M</cell></row><row><cell cols="5">Train 36340 19761 3930 10468 8705 7459</cell></row><row><cell>Valid</cell><cell>2000 1102 262</cell><cell>465</cell><cell>553</cell><cell>453</cell></row><row><cell>Test</cell><cell>3000 1654 421</cell><cell cols="2">1496 919</cell><cell>746</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Some statistics of FCGEC, including the num-</cell></row><row><cell>ber of sentences, the number of erroneous sentences,</cell></row><row><cell>and the number of four operations (#S, #D, #I, #M de-</cell></row><row><cell>note Switch, Delete, Insert, Modify, respectively).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Average performance comparison on baselines among 10 independent runs for classification tasks. parameters from HuggingFace website 1 . Then we fine-tune the different PLMs on our FCGEC for 4 epochs with batch size of 64. As for the correction task, we employ RoBERTa as the backbone PLM of our STG model and other benchmark models for training 100 epochs. Notably, the BART PLM (Lewis et al., 2019) utilized in Seq2Seq models is substituted byCPT (Shao et al., 2021). We set maximum t to 6 in Tagger module (It can cover 98% of the cases). In addition, we apply AdamW (Kingma and Ba, 2014) optimizer with a learning rate of 2e-5 and weight decay of 1e-2 for all tasks.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Performance comparison for error correction tasks. Notably, EM indicates the metric of Exact Match.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>36.70% 46.08% 25.70% 49.26% 39.33% 51.46% 47.73% AM IWO IWC SC ILL CM CR Identification Task (Error Rate) Correction Task (EM / F 0.5 score)</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>(17.94%)</cell></row><row><cell>22.22/ 33.14</cell><cell>33.67/ 47.31</cell><cell>(18.49%)</cell></row><row><cell>50.00/ 60.49</cell><cell>13.6 4/18 .04 40.78/5 7.92</cell><cell>(17.16%) (12.27%)</cell></row><row><cell>44.33/ 53.27</cell><cell>27.82/ 36.89</cell><cell>(25.20%) (6.22%)</cell></row><row><cell></cell><cell></cell><cell>(2.66%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>The proportion (%) of error types in Train, Validation and Test set, respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>The demographic information of annotators.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 9 :</head><label>9</label><figDesc>The metric (%) of Exact Match and F 0.5 score for each operation on the subset of test set. The first row (i.e., Ratio) represents the proportion of each operation to the total.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 10 :</head><label>10</label><figDesc>Performance comparison for different PLM backbones for models in MuCGEC. The suffix of B represents base size, while L stands for large size.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell cols="2">: Corresponding validation performance for</cell></row><row><cell cols="2">reported test result of the best performing models on</cell></row><row><cell>three tasks.</cell><cell></cell></row><row><cell cols="2">which facilitates the model to search for the best</cell></row><row><cell cols="2">hyperparameters on the validation set. Thus we can</cell></row><row><cell cols="2">obtain better performance on the test set.</cell></row><row><cell cols="2">Computing resources and times. In Table 12,</cell></row><row><cell cols="2">we show the detailed computing resources and hy-</cell></row><row><cell cols="2">perparameters for training our STG-Joint model.</cell></row><row><cell cols="2">Meanwhile, we also record the training time con-</cell></row><row><cell cols="2">sumed under these hyperparameters and devices.</cell></row><row><cell>Configuration</cell><cell>Value</cell></row><row><cell>Device</cell><cell>1 GeForce RTX 3090 (24G RAM)</cell></row><row><cell>PLM model</cell><cell>RoBERTa-Base-wwm-ext (Liu</cell></row><row><cell></cell><cell>et al., 2019)</cell></row><row><cell>Number of epochs</cell><cell>100</cell></row><row><cell>Batch size</cell><cell>32</cell></row><row><cell>Beam size</cell><cell>5 / [1, 5, 10, 20]</cell></row><row><cell>Sequence Length</cell><cell>150 / [50, 100, 150]</cell></row><row><cell>Learning Rate</cell><cell>1e-5 / [5e-6, 1e-5, 2e-5, 5e-5]</cell></row><row><cell>Optimizer</cell><cell>Adam</cell></row><row><cell>Dropout</cell><cell>0.1</cell></row><row><cell>Weight Decay</cell><cell>1e-2</cell></row><row><cell>Total training time</cell><cell>About 12 hours</cell></row><row><cell>Hyperparameters Se-</cell><cell>Best performance on the valida-</cell></row><row><cell>lection</cell><cell>tion set with the minimum loss</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 12 :</head><label>12</label><figDesc>Computing device, hyperparamters and training time for STG-Joint model. For hyperparameters of beam size, sequence length and learning rate, the left side of / is the best hyperparameter while the right side is the set for hyperparameter search.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported by the Science and Technology Project of Zhejiang Province (2022C01044) and the National Natural Science Foundation of China (51775496).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Structbert: Incorporating language structures into pre-training for deep language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuyi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangnan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunliang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liner</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaorong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renfen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhong</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.15043</idno>
		<title level="m">Yaclc: A chinese learner corpus with multidimensional annotation</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comprehensive survey of grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuelin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Grammatical error correction using neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="380" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mucgec: a multi-reference multi-source evaluation dataset for chinese grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuyi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of the nlpcc 2018 shared task: Grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF International Conference on Natural Language Processing and Chinese Computing (NLPCC)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="439" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maskgec: improving neural grammatical error correction via dynamic masking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1226" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving grammatical error correction with machine translation pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangchunshu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
