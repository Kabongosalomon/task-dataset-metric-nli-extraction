<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model CNNs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodol?</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Intel Perceptual Computing 4 Nnaisense</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usi</forename><surname>Lugano</surname></persName>
						</author>
						<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model CNNs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclideanstructured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graphand 3D shape analysis and show that it consistently outperforms previous approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, increasingly more fields have to deal with geometric non-Euclidean structured data such as manifolds or graphs. Social networks are perhaps the most prominent example of such data; additional examples include transportation networks, sensor networks, functional networks representing anatomical and functional structure of the brain, and regulatory networks modeling gene expressions. In computer graphics, 3D objects are traditionally modeled as Riemannian manifolds. The success of deep learning methods in many fields has recently provoked a * Equal contribution keen interest in geometric deep learning <ref type="bibr" target="#b10">[11]</ref> attempting to generalize such methods to non-Euclidean structure data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related works</head><p>Image processing. Classical deep learning algorithms build on top of traditional signal processing that has been developed primarily for linear shift-invariant systems, naturally arising when dealing with signals on Euclidean spaces. In this framework, basic filtering operations are represented as convolutions. A significant paradigm shift in image processing came with the pioneering work of Perona and Malik <ref type="bibr" target="#b34">[35]</ref>, suggesting the use of non-shift-invariant image filtering preserving the edge structures. This work was the precursor of a whole new class of PDE-based methods for image processing. Sochen et al. <ref type="bibr" target="#b49">[50]</ref> brought geometric models into image processing, considering images as manifolds and employing tools from differential geometry for their processing and analysis. More recent graph-based image processing methods relying on spectral graph theory <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b28">29]</ref> can be traced back to these works.</p><p>Manifold learning. A similar trend of employing geometric models can also be observed in the machine learning community in the past decade. Modelling data as low-dimensional manifolds is the core of manifold learning techniques such as Laplacian eigenmaps <ref type="bibr" target="#b2">[3]</ref> for non-linear dimensionality reduction, spectral clustering <ref type="bibr" target="#b33">[34]</ref> or spectral hashing <ref type="bibr" target="#b56">[57]</ref>.</p><p>Signal processing on graphs. More recent works tried to generalize signal processing methods to graph-based data <ref type="bibr" target="#b46">[47]</ref>. Spectral analysis techniques were extended to graphs considering the orthogonal eigenfunctions of the Laplacian operator as a generalization of the Fourier basis. Constructions such as wavelets <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b44">45]</ref> or algorithms such as dictionary learning <ref type="bibr" target="#b61">[62]</ref>, Lasso <ref type="bibr" target="#b8">[9]</ref>, PCA <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>, or matrix completion <ref type="bibr" target="#b22">[23]</ref> originally developed for the Euclidean domain, were also applied to graph-structured data.</p><p>Deep learning on graphs. The earliest attempts to generalize neural networks to graphs we are aware of are due to Scarselli et al. <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41]</ref>. This work remained practically unnoticed and has been rediscovered only recently <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b51">52]</ref>. The interest in non-Euclidean deep learning has recently surged in the computer vision and machine learning communities after the seminal work of Bruna et al. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22]</ref>, in which the authors formulated CNN-like <ref type="bibr" target="#b27">[28]</ref> deep neural architectures on graphs in the spectral domain, employing the analogy between the classical Fourier transforms and projections onto the eigenbasis of the graph Laplacian operator <ref type="bibr" target="#b46">[47]</ref>. In a follow-up work, Defferrard et al. <ref type="bibr" target="#b14">[15]</ref> proposed an efficient filtering scheme that does not require explicit computation of the Laplacian eigenvectors by using recurrent Chebyshev polynomials. Kipf and Welling <ref type="bibr" target="#b25">[26]</ref> further simplified this approach using simple filters operating on 1-hop neighborhoods of the graph. Similar methods were proposed in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b16">[17]</ref>. Finally, in the network analysis community, several works constructed graph embeddings <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b59">60]</ref> methods inspired by the Word2Vec technique <ref type="bibr" target="#b32">[33]</ref>.</p><p>A key criticism of spectral approaches such as <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b14">15]</ref> is the fact that the spectral definition of convolution is dependent on the Fourier basis (Laplacian eigenbasis), which, in turn is domain-dependent. It implies that a spectral CNN model learned on one graph cannot be trivially transferred to another graph with a different Fourier basis, as it would be expressed in a 'different language'.</p><p>Deep learning on manifolds. In the computer graphics community, we can notice a parallel effort of generalizing deep learning architectures to 3D shapes modeled as manifolds (surfaces). Masci et al. <ref type="bibr" target="#b31">[32]</ref> proposed the first intrinsic version of convolutional neural networks on manifolds applying filters to local patches represented in geodesic polar coordinates <ref type="bibr" target="#b26">[27]</ref>. Boscaini et al. <ref type="bibr" target="#b6">[7]</ref> used anisotropic heat kernels as an alternative way of extracting intrinsic patches on manifolds. In <ref type="bibr" target="#b5">[6]</ref>, the same authors proposed a CNN-type architecture in the spatio-frequency domain using the windowed Fourier transform formalism <ref type="bibr" target="#b47">[48]</ref>. Sinha et al. <ref type="bibr" target="#b48">[49]</ref> used geometry images representation to obtain Euclidean parametrization of 3D shapes on which standard CNNs can be applied.</p><p>The key advantage of spatial techniques is that they generalize across different domains, which is a crucial property in computer graphics applications (where a CNN model can be trained on one shape and applied to another one). However, while spatial constructions such as anisotropic heat kernels have a clear geometric interpretation on manifolds, their interpretation on general graphs is somewhat elusive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Main contribution</head><p>In this paper, we present mixture model networks (MoNet), a general framework allowing to design convolutional deep architectures on non-Euclidean domains such as graphs and manifolds. Our approach follows the general philosophy of spatial-domain methods such as <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b1">2]</ref>, formulating convolution-like operations as template matching with local intrinsic 'patches' on graphs or manifolds.</p><p>The key novelty is in the way in which the patch is extracted: while previous approaches used fixed patches, e.g. in geodesic or diffusion coordinates, we use a parametric construction. In particular, we show that patch operators can be constructed as a function of local graph or manifolds pseudo-coordinates, and study a family of functions represented as a mixture of Gaussian kernels. Such a construction allows to formulate previously proposed Geodesic CNN (GCNN) <ref type="bibr" target="#b31">[32]</ref> and Anisotropic CNN (ACNN) <ref type="bibr" target="#b6">[7]</ref> on manifolds or GCN <ref type="bibr" target="#b25">[26]</ref> and DCNN <ref type="bibr" target="#b1">[2]</ref> on graphs as particular instances of our approach.</p><p>Among applications on which we exemplify our approach are classical problems from the realms of image-, graph-and 3D-shape analysis. In the first class of problems, the task is to classify images, treated as adjacency graphs of superpixels. In the second class of problems, we perform vertex-wise classification on a graph representing a citation network of scientific papers. Finally, we consider the problem of finding dense intrinsic correspondence between 3D shapes, treated as manifolds. In all the above problems, we show that our approach consistently outperforms previously proposed non-Euclidean deep learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Deep learning on graphs</head><p>Let G = ({1, . . . , n}, E, W) be an undirected weighted graph, represented by the adjacency matrix W = (w ij ), where w ij = w ji , w ij = 0 if (i, j) / ? E and w ij &gt; 0 if (i, j) ? E. The (unnormalized) graph Laplacian is an n?n symmetric positive-semidefinite matrix ? = D?W, where D = diag j =i w ij is the degree matrix. The Laplacian has an eigendecomposition ? = ??? , where ? = (? 1 , . . . ? n ) are the orthonormal eigenvectors and ? = diag(? 1 , . . . , ? n ) is the diagonal matrix of corresponding eigenvalues. The eigenvectors play the role of Fourier atoms in classical harmonic analysis and the eigenvalues can be interpreted as frequencies. Given a signal f = (f 1 , . . . , f n ) on the vertices of graph G, its graph Fourier transform is given byf = ? f . Given two signals f , g on the graph, their spectral convolution can be defined as the element-wise product of the Fourier transforms,</p><formula xml:id="formula_0">f g = ?(? f ) ? (? g) = ? diag(? 1 , . . . ,? n )f ,<label>(1)</label></formula><p>which corresponds to the property referred to as the Convolution Theorem in the Euclidean case.</p><p>Spectral CNN. Bruna et al. <ref type="bibr" target="#b11">[12]</ref> used the spectral definition of convolution (1) to generalize CNNs on graphs, with a spectral convolutional layer of the form</p><formula xml:id="formula_1">f out l = ? p l =1 ? k?l,l ? k f in l .</formula><p>(2)</p><p>Here the n ? p and n ? q matrices F in = (f in 1 , . . . , f in p ) and F out = (f out 1 , . . . , f out q ) represent respectively the pand q-dimensional input and output signals on the vertices of the graph, ? = (? 1 , . . . , ? k ) is an n ? k matrix of the first eigenvectors,? l,l = diag(? l,l ,1 , . . . ,? l,l ,k ) is a k ? k diagonal matrix of spectral multipliers representing a learnable filter in the frequency domain, and ? is a nonlinearity (e.g. ReLU) applied on the vertex-wise function values. The analogy of pooling in this framework is a graph coarsening procedure, which, given a graph with n vertices, produces a graph with n &lt; n vertices and transfers signals from the vertices of the fine graph to those of the coarse one.</p><p>While conceptually important, this framework has several major drawbacks. First, the spectral filter coefficients are basis dependent, and consequently, a spectral CNN model learned on one graph cannot be applied to another graph. Second, the computation of the forward and inverse graph Fourier transform incurs expensive O(n 2 ) multiplication by the matrices ?, ? , as there is no FFT-like algorithms on general graphs. Third, there is no guarantee that the filters represented in the spectral domain are localized in the spatial domain; assuming k = O(n) eigenvectors of the Laplacian are used, a spectral convolutional layer requires pqk = O(n) parameters to train.</p><p>Smooth Spectral CNN. In a follow-up work, Henaff et al. <ref type="bibr" target="#b21">[22]</ref> argued that smooth spectral filter coefficients result in spatially-localized filters and used parametric filters of the form?</p><formula xml:id="formula_2">i = r j=1 ? j ? j (? i ),<label>(3)</label></formula><p>where ? 1 (?), . . . , ? r (?) are some fixed interpolation kernels, and ? = (? 1 , . . . , ? r ) are the interpolation coefficients. In matrix notation, the filter is expressed as</p><formula xml:id="formula_3">diag(?) = B?, where B = (b ij ) = (? j (? i ))</formula><p>is a k?r matrix. Such a parametrization results in filters with a number of parameters constant in the input size n.</p><p>Chebyshev Spectral CNN (ChebNet). In order to alleviate the cost of explicitly computing the graph Fourier transform, Defferrard et al. <ref type="bibr" target="#b14">[15]</ref> used an explicit expansion in the Chebyshev polynomial basis to represent the spectral filters</p><formula xml:id="formula_4">g ? (?) = r?1 j=0 ? j T j (?) = r?1 j=0 ? j ?T j (?)? ,<label>(4)</label></formula><formula xml:id="formula_5">where? = 2? ?1 n ? ? I is the rescaled Laplacian such that its eigenvalues? = 2? ?1 n ? ? I are in the interval [?1, 1],</formula><p>? is the r-dimensional vector of polynomial coefficients parametrizing the filter, and</p><formula xml:id="formula_6">T j (?) = 2?T j?1 (?) ? T j?2 (?),<label>(5)</label></formula><p>denotes the Chebyshev polynomial of degree j defined in a recursive manner with T 1 (?) = ? and T 0 (?) = 1.</p><p>Such an approach has several important advantages. First, it does not require an explicit computation of the Laplacian eigenvectors. Due to the recursive definition of the Chebyshev polynomials, the computation of the filter g ? (?)f entails applying the Laplacian r times, resulting in O(rn) operations. Second, since the Laplacian is a local operator affecting only 1-hop neighbors of a vertex and accordingly its (r ? 1)st power affects the r-hop neighborhood, the resulting filters are localized.</p><p>Graph convolutional network (GCN). Kipf and Welling <ref type="bibr" target="#b25">[26]</ref> considered the construction of <ref type="bibr" target="#b14">[15]</ref> with r = 2, which, under the additional assumption of ? n ? 2, and ? = ? 0 = ?? 1 yields single-parametric filters of the form g ? (f ) = ?(I + D ?1/2 WD ?1/2 )f . Such a filter is numerically unstable since the maximum eigenvalue of the matrix</p><formula xml:id="formula_7">I + D ?1/2 WD ?1/2 is 2; a renormalization g ? (f ) = ?D ?1/2WD?1/2 f ,<label>(6)</label></formula><formula xml:id="formula_8">withW = W + I andD = diag( j =iw ij )</formula><p>is introduced by the authors in order to cure such problem and allow multiple convolutional levels to be casted one after the other.</p><p>Diffusion CNN (DCNN). A different spatial-domain method was proposed by Atwood and Towsley <ref type="bibr" target="#b1">[2]</ref>, who considered a diffusion (random walk) process on the graph. The transition probability of a random walk on a graph is given by P = D ?1 W. Different features are produced by applying diffusion of different length (the powers P 0 , . . . , P r?1 ),</p><formula xml:id="formula_9">f out l,j = ?(w lj P j f in l ), where the n ? p and n ? pr matrices F in = (f in 1 , . . . , f in p ) and F out = (f out 1,1 , .</formula><p>. . , f out p,r ) represent the pand prdimensional input and output signals on the vertices of the graph and W = (w lj ) is the p ? r matrix of weights. <ref type="table">Table 1</ref>. Several CNN-type geometric deep learning methods on graphs and manifolds can be obtained as a particular setting of the proposed framework with an appropriate choice of the pseudo-coordinates and weight functions in the definition of the patch operator. x denotes the reference point (center of the patch) and y a point within the patch. x denotes the Euclidean coordinates on a regular grid. ?,??,? ? and?j,?j, j = 1, . . . , J denote fixed parameters of the weight functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Pseudo-coordinates u(x, y) Weight function w j (u), j = 1, . . . , J</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN [28]</head><p>Local Euclidean</p><formula xml:id="formula_10">x(x, y) = x(y) ? x(x) ?(u ?? j ) GCNN [32] Local polar geodesic ?(x, y), ?(x, y) exp(? 1 2 (u ?? j ) ? 2 ?? 2 ? ?1 (u ?? j )) ACNN [7] Local polar geodesic ?(x, y), ?(x, y) exp(? 1 2 u R? j (? 1 ) R ? j u) GCN [26] Vertex degree deg(x), deg(y) 1 ? |1 ? 1 ? u1 | 1 ? |1 ? 1 ? u2 | DCNN [2]</formula><p>Transition probability in r hops p 0 (x, y), . . . ,</p><formula xml:id="formula_11">p r?1 (x, y) id(u j )</formula><p>Geodesic CNN (GCNN). Masci et al. <ref type="bibr" target="#b31">[32]</ref> introduced a generalization of CNNs on 2-dimensional manifolds, based on the definition of a local charting procedure in geodesic polar coordinates <ref type="bibr" target="#b26">[27]</ref>. Such a construction, named the patch operator can be thought of as matching a template g(?, ?) with the extracted patch at each point, where the maximum is taken over all possible rotations of the template in order to resolve the origin ambiguity in the angular coordinate. The geodesic convolution is used to define an analogy of a traditional convolutional layer in GCNN, where the templates g are learned.</p><formula xml:id="formula_12">(D(x)f )(?, ?) = X w ?,? (x,</formula><p>Anisotropic CNN (ACNN). Boscaini et al. <ref type="bibr" target="#b6">[7]</ref> considered the anisotropic diffusion equation on the manifold</p><formula xml:id="formula_13">f t (x, t) = ?div X (A(x)? X f (x, t)) ,<label>(7)</label></formula><p>where ? X and div X denote the intrinsic gradient and divergence, respectively, f (x, t) is the temperature at point x and time t, and the conductivity tensor A(x) (operating on the gradient vectors in the tangent space T x X ) allows to model heat flow that is position-and direction-dependent.</p><p>In particular, they used the 2 ? 2 tensor</p><formula xml:id="formula_14">A ?? (x) = R ? (x) ? 1 R ? (x) ,<label>(8)</label></formula><p>where matrix R ? is a rotation by ? in the tangent plane w.r.t. the maximal curvature direction, and the parameter ? &gt; 0 controls the degree of anisotropy (isotropic diffusion is obtained for ? = 1). Using as initial condition f (x, 0) a point source of heat at x, the solution to the heat equation <ref type="formula" target="#formula_13">(7)</ref> is given by the anisotropic heat kernel h ??t (x, y), representing the amount of heat that is transferred from point x to point y at time t. By varying the parameters ?, ? and t (controlling respectively the elongation, orientation, and scale of the kernel) one obtains a collection of kernels that can be used as weighting functions in the construction of the patch operator (see examples in <ref type="figure" target="#fig_1">Figure 1</ref>). This gives rise to an alternative charting to the geodesic patches of GCNN, more robust to geometric noise, and more efficient to compute. Both GCNN and ACNN operate in the spatial domain and thus do not suffer from the inherent inability of spectral methods to generalize across different domains. These methods were shown to outperform all the known handcrafted approaches for finding intrinsic correspondence between deformable shapes <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b6">7]</ref>, a notoriously hard problem in computer graphics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our approach</head><p>The main contribution of this paper is a generic spatialdomain framework for deep learning on non-Euclidean domains such as graphs and manifolds. We use x to denote, depending on context, a point on a manifold or a vertex of a graph, and consider points y ? N (x) in the neighborhood of x. With each such y, we associate a d-dimensional vector of pseudo-coordinates u(x, y). In these coordinates, we define a weighting function (kernel) w ? (u) = (w 1 (u), . . . , w J (u)), which is parametrized by some learnable parameters ?. The patch operator can therefore be written in the following general form</p><formula xml:id="formula_15">D j (x)f = y?N (x)</formula><p>w j (u(x, y))f (y), j = 1, . . . , J, <ref type="bibr" target="#b8">(9)</ref> where the summation should be interpreted as an integral in the case we deal with a continuous manifold, and J represents the dimensionality of the extracted patch. A spatial generalization of the convolution on non-Euclidean domains is then given by a template-matching procedure of the form</p><formula xml:id="formula_16">(f g)(x) = J j=1 g j D j (x)f.<label>(10)</label></formula><p>The two key choices in our construction are the pseudocoordinates u and the weight functions w(u). <ref type="table" target="#tab_1">Table 3</ref> shows that other deep learning methods (including the classical CNN on Euclidean domains, DCN and DCNN on graphs, and GCNN and ACNN on manifolds) can be obtained as particular settings of our framework with appropriate definition of u and w(u). For example, GCNN and ACNN boil down to using Gaussian kernels on local polar geodesic coordinates ?, ? on a manifold, and GCN can be interpreted as applying a triangular kernel on pseudocoordinates given by the degree of the graph vertices.</p><p>In this paper, rather than using fixed handcrafted weight functions we consider parametric kernels with learnable parameters. In particular, a convenient choice is</p><formula xml:id="formula_17">w j (u) = exp(? 1 2 (u ? ? j ) ? ?1 j (u ? ? j )),<label>(11)</label></formula><p>where ? j and ? j are learnable d ? d and d ? 1 covariance matrix and mean vector of a Gaussian kernel, respectively. Formulae (9-10) can thus be interpreted as a gaussian mixture model (GMM). We further restrict the covariances to have diagonal form, resulting in 2d parameters per kernel, and a total of 2Jd parameters for the patch operator. While extremely simple, we show in the next section that these additional degrees of freedom afford our architecture sufficient complexity allowing it to outperform existing approaches. More complex versions of the weighting functions could include additional non-linear transformation of the pseudo-coordinates u before feeding them to the Gaussian kernel, or even more general network-in-a-network architectures <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Images</head><p>In our first experiment, we applied the proposed method on a classical task of handwritten digit classification in the MNIST dataset <ref type="bibr" target="#b27">[28]</ref>. While almost trivial by todays standards, we nevertheless use this example to visualize an important advantage of our approach over spectral graph CNN methods. Our experimental setup followed <ref type="bibr" target="#b14">[15]</ref>. The 28 ? 28 images were represented as graphs, where vertices correspond to (super)pixels and edges represent their spatial relations. We considered two constructions: all images represented on the same graph (regular grid) and each image represented as a different graph <ref type="figure">(Figure 2</ref> left and right, respectively). Furthermore, we varied the graph size: the full and 1 4 grids contained 728 and 196 vertices, respectively, while the superpixel-based graphs contained 300, 150, and 75 vertices.</p><p>Three methods were compared: classical CNN LeNet5 architecture <ref type="bibr" target="#b27">[28]</ref> (containing two convolutional, two maxpooling, and one fully-connected layer, applied on regular grids only), spectral ChebNet <ref type="bibr" target="#b14">[15]</ref> and the proposed MoNet. We used a standard splitting of the MNIST dataset into training-, testing-, and validation sets of sizes 55K, 10K, and 5K images, respectively. LeNet used 2?2 max-pooling; in ChebNet and MoNet we used three convolutional layers, interleaved with pooling layers based on the Graclus method <ref type="bibr" target="#b15">[16]</ref> to coarsen the graph by a factor of four.</p><p>For MoNet, we used polar coordinates u = (?, ?) of pixels (respectively, of superpixel barycenters) to produce the patch operator; as the weighting functions of the patch operator, 25 Gaussian kernels (initialized with random means and variances) were used. Training was done with 350K iterations of Adam method <ref type="bibr" target="#b24">[25]</ref>, initial learning rate 10 ?4 , regularization factor 10 ?4 , dropout probability 0.5, and batch size of 10. <ref type="table">Table 2</ref> summarizes the performance of different algorithms. On regular grids, all the methods perform approximately equally well. However, when applying ChebNet on superpixel-based representations, the performance drops dramatically (by up to almost 25%). The reason lies in the key drawback of spectral CNN models, wherein the definition of the filters is basis-and thus domain-dependent. Since in this case each image is represented as a different Regular grid Superpixels <ref type="figure">Figure 2</ref>. Representation of images as graphs. Left: regular grid (the graph is fixed for all images). Right: graph of superpixel adjacency (different for each image). Vertices are shown as red circles, edges as red lines. graph, the model fails to generalize well. The effect is most pronounced on smaller graphs (150 and 75 superpixels) that vary strongly among each other. In contrast, the proposed MoNet approach manifests consistently high accuracy, and only a light performance degradation is observed when the image presentation is too coarse (75 superpixels). <ref type="table">Table 2</ref>. Classification accuracy of classical Euclidean CNN (LeNet5), spectral CNN (ChebNet) and the proposed approach (MoNet) on different versions of the MNIST dataset. The setting of all the input images sharing the same graph is marked with *.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>LeNet5 <ref type="bibr" target="#b27">[28]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Graphs</head><p>In the second experiment, we address the problem of vertex classification on generic graphs. We used the popular Cora and PubMed <ref type="bibr" target="#b41">[42]</ref> citation graphs as our datasets. In each dataset, a vertex represents a scientific publication (2708 vertices in Cora and 19717 in PubMed, respectively), and an undirected unweighted edge represents a citation (5429 and 44338 edges in Cora and PubMed). For each vertex, a feature vector representing the content of the pa- per is given (1433-dimensional binary feature vectors in Cora, and 500-dimensional tf-idf weighted word vectors in PubMed). The task is to classify each vertex into one of the groundtruth classes (7 in Cora and 3 in PubMed). We followed verbatim the experimental settings presented in <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b25">26]</ref>. The training sets consisted of 20 samples per class; the validation and test sets consisted of 500 and 1000 disjoint vertices. The validation set was chosen in order to reflect the probability distribution of the various classes over the entire dataset. We compared our approach to all the methods compared in <ref type="bibr" target="#b25">[26]</ref>.</p><p>For MoNet, we used the degrees of the nodes as the input pseudo-coordinates u(x, y)</p><formula xml:id="formula_18">= ( 1 ? deg(x) , 1 ? deg(y)</formula><p>) ; these coordinates underwent an additional transformation in the form of a fully-connected neural network layer?(x, y) = tanh(Au(x, y) + b), where the r ? 2 matrix A and r ? 1 vector b were also learned (we used r = 2 for Cora and r = 3 for PubMed). The Gaussian kernels were applied on coordinates?(x, y) yielding patch operators of the form</p><formula xml:id="formula_19">D j (x)f l = y?N (x) e ? 1 2 (?(x,y)?? j ) ? ?1 j (?(x,y)?? j ) f l (y),</formula><p>where ? j , ? j , j = 1, . . . , J are the r ? r and r ? 1 covariance matrices and mean vectors of the Gaussian kernels, respectively. DCNN, GCN and MoNet were trained in the same way in order to give a fair comparison (see training details in <ref type="table" target="#tab_1">Table 3</ref>). The L 2 -regularization weights for MoNet were ? = 10 ?2 and 5?10 ?2 for Cora and PubMed, respectively; for DCNN and GCN we used the values suggested by the authors in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b25">[26]</ref>. The vertex classification results of different methods are summarized in <ref type="table">Table 4</ref> and visualized in <ref type="figure" target="#fig_2">Figure 3</ref>. MoNet compares favorably to other approaches. The tuning of the network hyper-parameters has been fundamental in this case for avoiding overfitting, due to a very small size of the training set. Being more general, our architecture is more complex compared to GCN and DCNN and requires an appropriate regularization to be used in such settings. At the same time, the greater complexity of our framework might prove advantageous when applied to larger and more complex data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Manifolds</head><p>The last application we consider is learning dense intrinsic correspondence between collections of 3D shapes represented as discrete manifolds. For this purpose, correspondence is cast as a labelling problem, where one tries to label each vertex of a given query shape X with the index of a corresponding point on some reference shape Y <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b6">7]</ref>. Let n and m denote the number of vertices in X and Y, respectively. For a point x on a query shape, the last layer of the network is soft-max, producing an m-dimensional output f (x) that is interpreted as a probability distribution on Y (the probability of x mapped to y). Learning is done by minimizing the standard logistic regression cost <ref type="bibr" target="#b6">[7]</ref>.</p><p>Meshes. We reproduced verbatim the experiments of <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b6">7]</ref> on the FAUST humans dataset <ref type="bibr" target="#b4">[5]</ref>, comparing to the methods reported therein. The dataset consisted of 100 watertight meshes representing 10 different poses for 10 different subjects with exact ground-truth correspondence. Each shape was represented as a mesh with 6890 vertices; the first subject in first pose was used as the reference. For all the shapes, point-wise 544-dimensional SHOT descriptors (local histogram of normal vectors) <ref type="bibr" target="#b53">[54]</ref> were used as input data. We used MoNet architecture with 3 convolutional layers, replicating the architectures of <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b6">7]</ref>. First 80 subjects <ref type="table">Table 4</ref>. Vertex classification accuracy on the Cora and PubMed datasets following the splitting suggested in <ref type="bibr" target="#b59">[60]</ref>. Learning methods (DCNN, GCNN and MoNet) were trained and tested fifty times for showing their average behavior with different initializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Cora PubMed</p><p>ManiReg <ref type="bibr" target="#b3">[4]</ref> 59.5% 70.7% SemiEmb <ref type="bibr" target="#b57">[58]</ref> 59.0% 71.1% LP <ref type="bibr" target="#b62">[63]</ref> 68.0% 63.0% DeepWalk <ref type="bibr" target="#b35">[36]</ref> 67.2% 65.3% Planetoid <ref type="bibr" target="#b59">[60]</ref> 75.7% 77.2%</p><p>DCNN <ref type="bibr" target="#b1">[2]</ref> 76.80 ? 0.60% 73.00 ? 0.52% GCN <ref type="bibr" target="#b25">[26]</ref> 81.59 ? 0.42% 78.72 ? 0.25% MoNet 81.69 ? 0.48% 78.81 ? 0.44% in all the poses were used for training (800 shapes in total); the remaining 20 subjects were used for testing. The output of the network was refined using the intrinsic Bayesian filter <ref type="bibr" target="#b54">[55]</ref> in order to remove some local outliers. Correspondence quality was evaluated using the Princeton benchmark <ref type="bibr" target="#b23">[24]</ref>, plotting the percentage of matches that are at most r-geodesically distant from the groundtruth correspondence on the reference shape. For comparison, we report the performance of blended maps <ref type="bibr" target="#b23">[24]</ref>, random forests <ref type="bibr" target="#b37">[38]</ref>, GCNN <ref type="bibr" target="#b31">[32]</ref>, ADD <ref type="bibr" target="#b7">[8]</ref>, and ACNN <ref type="bibr" target="#b6">[7]</ref>. <ref type="figure" target="#fig_1">Figure 1</ref> shows the weighting functions of the patch operator that are fixed in GCNN and ACNN architectures, and part of the learnable parameters in the proposed MoNet. The patch operators of GCNN and ACNN can be obtained as a particular configuration of MoNet, implying that if trained correctly, the new model can only improve w.r.t. the previous ones. <ref type="figure" target="#fig_4">Figure 4</ref> depicts the evaluation results, showing that MoNet significantly outperforms the competing approaches. In particular, close to 90% of points have zero error, and for 99% of the points the error is below 4cm. <ref type="figure" target="#fig_5">Figure 6</ref> shows the point-wise geodesic correspondence error of our method, and <ref type="figure">Figure 7</ref> visualizes the obtained correspondence using texture transfer.</p><p>Range maps. Finally, we repeated the shape correspondence experiment on range maps synthetically generated from FAUST meshes. For each subject and pose, we produced 10 rangemaps in 100?180 resolution, covering shape rotations around the z-axis with increments of 36 degrees (total of 1000 range maps), keeping the groundtruth correspondence. We used MoNet architecture with 3 convolutional layers and local SHOT descriptors as input data. Training and testing set splitting was done as previously. <ref type="figure">Figure 5</ref> shows the quality of correspondence computed using the Princeton protocol. For comparison, we show the performance of a standard Euclidean CNN in equivalent architecture (3 convolutional layers) applied on raw depth values and on SHOT descriptors. Our approach clearly shows   <ref type="figure">Figure 5</ref>. Shape correspondence quality obtained by different methods on FAUST range maps. For comparison, we show the performance of a Euclidean CNN with a comparable 3-layer architecture. The raw performance is shown as dotted curve. a superior performance. <ref type="figure">Figure 8</ref> shows the point-wise geodesic correspondence error. <ref type="figure" target="#fig_7">Figure 9</ref> shows a qualitative visualization of correspondence using similar color code for corresponding vertices. We also show correspondence on shapes from SCAPE <ref type="bibr" target="#b0">[1]</ref> and TOSCA <ref type="bibr" target="#b9">[10]</ref> datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We proposed a spatial-domain model for deep learning on non-Euclidean domains such as manifolds and graphs. Our approach generalizes several previous techniques that can be obtained as particular instances thereof. Extensive experimental results show that our model is applicable to different geometric deep learning tasks, achieving state-ofthe-art results. In deformable 3D shape analysis applications, the key advantage of our approach is that it is intrinsic and thus deformation-invariant by construction, as opposed to Euclidean models <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b36">37]</ref> that in general require significantly higher complexity and huge training sets to learn the deformation invariance. In future works, we will study additional promising applications of our model, for example in the domain of computational social sciences.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>y)f (y)dy maps the values of the function f at a neighborhood of the point x ? X into the local polar coordinates ?, ?. Here dy denotes the area element induced by the Riemannian metric, and w ?,? (x, y) is a weighting function localized around ?, ? (see examples in Figure 1). D(x)f can be regarded as a patch on the manifold; the geodesic convolution (f g)(x) ?+??)(D(x)f )(?, ?)d?d?,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>MoNetFigure 1 .</head><label>1</label><figDesc>Left: intrinsic local polar coordinates ?, ? on manifold around a point marked in white. Right: patch operator weighting functions wi(?, ?) used in different generalizations of convolution on the manifold (hand-crafted in GCNN and ACNN and learned in MoNet). All kernels are L?-normalized; red curves represent the 0.5 level set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Predictions obtained applying MoNet over the Cora dataset. Marker fill color represents the predicted class; marker outline color represents the groundtruth class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Shape correspondence quality obtained by different methods on the FAUST humans dataset. The raw performance of MoNet is shown in dotted curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Pointwise error (geodesic distance from groundtruth) of different correspondence methods on the FAUST humans dataset. For visualization clarity, the error values are saturated at 7.5% of the geodesic diameter, which corresponds to approximately 15 cm. Hot colors represent large errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Examples of correspondence on the FAUST humans dataset obtained by the proposed MoNet method. Shown is the texture transferred from the leftmost reference shape to different subjects in different poses by means of our correspondence. Pointwise error (geodesic distance from groundtruth) of different methods on FAUST range maps. For visualization clarity, the error values are saturated at 7.5% of the geodesic diameter, which corresponds to approximately 15 cm. Hot colors represent large errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Visualization of correspondence on FAUST range maps as color code (corresponding points are shown in the same color). Full reference shape is shown on the left. Bottom row show examples of additional shapes from SCAPE and TOSCA datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Learning configuration used for Cora and PubMed experiments.</figDesc><table><row><cell></cell><cell>Cora</cell><cell>PubMed</cell></row><row><cell>Learning Algorithm</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>Number of epochs</cell><cell>3000</cell><cell>1000</cell></row><row><cell cols="2">Validation frequency 0.01</cell><cell>0.04</cell></row><row><cell>Learning rate</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>Decay rate</cell><cell>10 ?1</cell><cell>-</cell></row><row><cell>Decay epochs</cell><cell cols="2">1500, 2500 -</cell></row><row><cell>Early stopping</cell><cell>No</cell><cell>No</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">. Deep learning on manifoldsLet X be a d-dimensional differentiable manifold, possibly with boundary ?X . Around point x ? X , the manifold is homeomorphic to a d-dimensional Euclidean space referred to as the tangent space and denoted by T x X . An inner product ?, ? TxX : T x X ? T x X ? R depending smoothly on x is called the Riemannian metric. In the following, we denote by f : X ? R smooth real functions (scalar fields) on the manifold. In shape analysis, 3D shapes are modeled as 2-dimensional manifolds (surfaces), representing the boundaries of 3D volumes.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported in part by the ERC Starting Grant No. 307047 (COMET), a Google Faculty Research Award, and Nvidia equipment grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SCAPE: shape completion and animation of people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOG</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="408" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02136v2</idno>
		<title level="m">Diffusion-convolutional neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">FAUST: Dataset and evaluation for 3D mesh registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Melzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Castellani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning shape correspondence with anisotropic convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Anisotropic diffusion descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="441" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enhanced lasso recovery on graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Von Brecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
		<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Numerical geometry of non-rigid shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<title level="m">Spectral networks and locally connected networks on graphs. Proc. ICLR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GraRep: Learning graph representations with global structural information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IKM</title>
		<meeting>IKM</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<title level="m">Diffusion wavelets. Applied and Computational Harmonic Analysis</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="53" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weighted graph cuts without eigenvectors: a multilevel approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1944" to="1957" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiscale wavelets on trees, graphs and high dimensional data: Theory and applications to semi supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gavish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN</title>
		<meeting>IJCNN</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wavelets on graphs via spectral graph theory. Applied and Comp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Harmonic Analysis</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="129" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.1717</idno>
	</analytic>
	<monogr>
		<title level="j">Matrix completion on graphs</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Blended intrinsic maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Intrinsic shape context descriptors for deformable shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Image processing and analysis with graphs: theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>L?zoray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05493</idno>
		<title level="m">Gated graph sequence neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno>abs/1312.4400</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Geodesic convolutional neural networks on Riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DRR</title>
		<meeting>3DRR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">DeepWalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view CNNs for object classification on 3D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dense non-rigid shape correspondence using random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Windheuser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vestner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wavelets on graphs via deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rustamov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="998" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph-based representations and techniques for image processing and image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanfeliu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Robust principal component analysis on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fast robust PCA on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Perraudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Puy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="740" to="756" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A class of Laplacian multiwavelets bases for high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Comp. Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="420" to="451" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sig. Proc. Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Vertexfrequency analysis on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ricaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">App. and Comp. Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="291" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep learning 3D shape surfaces using geometry images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A general framework for low level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="310" to="318" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multiview convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Learning multiagent communication with backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07736</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">LINE: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unique signatures of histograms for local surface description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vestner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.03425</idno>
		<title level="m">Bayesian inference of bijective non-rigid shape correspondence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dense human body correspondences using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vouga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<title level="m">Spectral hashing</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Proc. NIPS</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">3D shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08861</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Graph spectral image smoothing using the heat kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3328" to="3342" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning of structured graph dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
