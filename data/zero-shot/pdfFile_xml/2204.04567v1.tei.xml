<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Long</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot classification is a challenging problem as only very few training examples are given for each new task. One of the effective research lines to address this challenge focuses on learning deep representations driven by a similarity measure between a query image and few support images of some class. Statistically, this amounts to measure the dependency of image features, viewed as random vectors in a high-dimensional embedding space. Previous methods either only use marginal distributions without considering joint distributions, suffering from limited representation capability, or are computationally expensive though harnessing joint distributions. In this paper, we propose a deep Brownian Distance Covariance (DeepBDC) method for few-shot classification. The central idea of DeepBDC is to learn image representations by measuring the discrepancy between joint characteristic functions of embedded features and product of the marginals. As the BDC metric is decoupled, we formulate it as a highly modular and efficient layer. Furthermore, we instantiate DeepBDC in two different few-shot classification frameworks. We make experiments on six standard few-shot image benchmarks, covering general object recognition, fine-grained categorization and cross-domain classification. Extensive evaluations show our DeepBDC significantly outperforms the counterparts, while establishing new state-of-the-art results. The source code is available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Few-shot classification <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref> is concerned with a task where a classifier can be adapted to distinguish classes unseen previously, given only a very limited number of examples of these classes. This is a challenging problem as scarcely labeled examples are far from sufficient for learning abundant knowledge and also likely lead to overfitting. One practical solution is based on the technique of * Equal contribution. ? Corresponding author, peihuali@dlut.edu.cn. The work was supported by National Natural Science Foundation of China (61971086, 61806140), and CCF-Baidu Open Fund (2021PP15002000). meta-learning or learning to learn <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39]</ref>, in which the episodic training is formulated to transfer the knowledge obtained on a massive meta-training set spanning a large number of known classes to the few-shot regime of novel classes. Among great advances that have been made, the line of metric-based methods attracts considerable research interest <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>, achieving state-of-the-art performance <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b46">47]</ref> in recent years.</p><p>The primary idea of the metric-based few-shot classification is to learn representations through deep networks, driven by the similarity measures between a query image and few support images of some class <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b46">47]</ref>. Statistically, the features of a query image (resp., support images) can be viewed as observations of a random vector X (resp., Y ) in a high-dimensional embedding space. Therefore, the similarity between images can be measured by means of probability distributions. However, modeling distributions of highdimensional (and often few) features is hard and a common method is to model statistical moments. ProtoNet <ref type="bibr" target="#b32">[33]</ref> and its variants (e.g., <ref type="bibr" target="#b25">[26]</ref>) represent images by first moment (mean vector) and use Euclidean distance or cosine similarity for metric learning. To capture richer statistics, several works study second moment (covariance matrix) <ref type="bibr" target="#b43">[44]</ref> or combination of first and second moments in the form of Gaussians <ref type="bibr">[20]</ref> for image representations, while adopting Frobenius norm or Kullback-Leiberler (KL) divergence as similarity measures. However, these methods only exploit marginal distributions while neglecting joint distributions, limiting the performance of learned models. In addition, the covariances can only model linear relations.</p><p>In general, the dependency between X and Y should be measured in light of their joint distribution f XY (x, y) <ref type="bibr" target="#b5">[6]</ref>. Earth Mover's Distance (EMD) is an effective method for measuring such dependency. As described in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr">Sec. 2.3]</ref>, EMD seeks an optimal joint distribution f XY (x, y), whose marginals are constrained to be given f X (x) and f Y (y), so that the expectation of transportation cost is minimal. In few-shot classification, DeepEMD <ref type="bibr" target="#b46">[47]</ref> proposes differential EMD for optimal matching of image regions. Though achieving state-of-the-art performance, DeepEMD is computationally expensive <ref type="bibr" target="#b44">[45]</ref>, due to inherent linear program- <ref type="table">Table 1</ref>. Comparison between our DeepBDC and the counterparts. To quantify the dependency between random vectors X and Y , moments based methods [20, <ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">44]</ref> only model marginal distributions, suffering from limited representation capability; though achieving state-ofthe-art performance by considering joint distributions, DeepEMD <ref type="bibr" target="#b46">[47]</ref> is computationally expensive. Our DeepBDC measures discrepancy between joint characteristic function and product of the marginals, which can be efficiently computed in closed-form, and model non-linear relations and fully characterizes independence. Note that for a random vector its characteristic function and probability distribution are equivalent in that they form a Fourier transform pair. Here we report accuracies of 5-way 1-shot/5-shot classification on miniImageNet; our result is obtained by Meta DeepBDC and results of the counterparts are duplicated from respective papers. ming algorithm. Mutual information (MI) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref> is a wellknown measure, which can quantify the dependency of two random variables by KL-divergence between their joint distribution and product of the marginals. Unfortunately, computation of MI is difficult in real-valued, high-dimensional setting <ref type="bibr" target="#b1">[2]</ref>, and often involves difficult density modeling or lower-bound estimation of KL-divergence <ref type="bibr" target="#b13">[14]</ref>.</p><p>In this paper, we propose a deep Brownian Distance Covariance (DeepBDC) method for few-shot classification. The BDC metric, first proposed in <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, is defined as the Euclidean distance between the joint characteristic function and product of the marginals. It can naturally quantify the dependency between two random variables. For discrete observations (features), the BDC metric is decoupled so that we can formulate BDC as a pooling layer, which can be seamlessly inserted into a deep network, accepting feature maps as input and outputting a BDC matrix as an image representation. In this way, the similarity between two images is computed as the inner product between the corresponding two BDC matrices. Therefore, the core of our DeepBDC is highly modular and plug-and-play for different methodologies of few-shot image classification. Specifically, we instantiate our DeepBDC in meta-learning framework (Meta DeepBDC), and in the simple transfer learning framework relying non-episodic training (STL DeepBDC). Contrary to covariance matrices, our DeepBDC can freely handle nonlinear relations and fully characterize independence. Compared to EMD, it also considers joint distribution and above all, can be computed analytically and efficiently. Unlike MI, the BDC requires no density modeling. We present differences between our BDC and the counterparts in Tab. 1.</p><p>Our contributions are summarized as follows. (1) For the first time, we introduce Brownian distance covariance (BDC), a fundamental but largely overlooked dependency modeling method, into deep network-based few-shot classification. Our work suggests great potential and future applications of BDC in deep learning. <ref type="bibr" target="#b1">(2)</ref> We formulate DeepBDC as a highly modular and efficient layer, suitable for different few-shot learning frameworks. Furthermore, we propose two instantiations for few-shot classification, i.e., Meta DeepBDC based on the meta-learning framework with ProtoNet as a blue print, and STL DeepBDC based on simple transfer learning framework without episodic training. (3) We perform thorough ablation study on our methods and conduct extensive experiments on six few-shot classification benchmarks. The experimental results demonstrate that both of our two instantiations achieve superior performance and meanwhile set new state-of-the-arts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Representation learning in few-shot classification The image representation and the similarity measure play important roles in few-shot classifications where only limited labeled examples are available. In light of the image representation, we can roughly divide the few-shot classification methods into two categories. In the first category, the image representations are based on distribution modeling. They use either first moment (mean vector) <ref type="bibr" target="#b32">[33]</ref>, second moment (covariance matrix) <ref type="bibr" target="#b43">[44]</ref> , Gaussian distribution <ref type="bibr">[20]</ref> or discrete probability <ref type="bibr" target="#b46">[47]</ref>, and, accordingly, adopts Euclidean distance (or cosine similarity), Frobenious norm, KL-divergence or Earther Mover's Distance as dissimilarity measures. The second category is concerned with feature reconstruction between the query image and the support images, by means of either directly linear reconstruction through Ridge regression <ref type="bibr" target="#b44">[45]</ref> or attention mechanism <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b45">46]</ref>, or concerned with designing relational module to learn a transferable deep metric <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b47">48]</ref>. Our methods belong to the first category, and the biggest difference from existing works is that we use Brownian Distance Covariance for representation learning in the few-shot regime. Meta-learning versus simple transfer learning Metalearning is a de facto framework for few-shot classification <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39]</ref>. It involves a family of tasks (episodes) split into disjoint meta-training and meta-testing sets. Typically, each task is formulated as a N -way K-shot classification, which spans N classes each provided with K support images and some query images. The meta-training and meta-testing sets share the episodic training strategy that facilitates generalization ability across tasks. Most of the methods, either optimization-based <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref> or metricbased <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>, follow this methodology. A lot of studies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref> have shown that, rather than meta-training from scratch, pre-training on the whole meta-training set is helpful for meta-learning. Recently, it has been found that simple transfer learning (STL) framework, which does not rely on episodic training at all, achieves very competitive performance <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b36">37]</ref>. For STL methods, during metatraining a deep network is trained for a common classification problem via standard cross-entropy loss on the whole meta-training set spanning all classes; during meta-testing, the trained model is used as an embedding model for feature extraction, then a linear model, such as a soft-max classifier <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref> or logistic regression model <ref type="bibr" target="#b36">[37]</ref>, is constructed and trained for the few-shot classification.</p><p>Finally, we mention that scarce works have ever used BDC in machine learning or computer vision, and so far we find one BDC-based dimension reduction method <ref type="bibr" target="#b6">[7]</ref> which is not concerned with deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section, we first introduce Brownian distance covariance (BDC). Then we formulate our DeepBDC in the convolutional networks. Finally, we instantiate our DeepBDC for few-shot image classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Brownian Distance Covariance (BDC)</head><p>The theory of BDC is first established in <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> in light of characteristic function. The characteristic function of a random vector is equivalent to its probability density function (PDF), as they form a Fourier transform pair.</p><p>Let X ? R p , Y ? R q be random vectors of dimension p and q, respectively, and let f XY (x, y) be their joint PDF. The joint characteristic function of X and Y is defined as</p><formula xml:id="formula_0">? XY (t, s) = R p R q exp(i(t T x+s T y))f XY (x, y)dxdy (1)</formula><p>where i is the imaginary unit. Clearly, the marginal distributions of X and Y are respectively ? X (t)=? XY (t, 0) and ? Y (s)=? XY (0, s) where 0 is a vector whose elements are all zero. From theory of probability, we know X and Y are independent if and only if ? XY (t, s)=? X (t)? Y (s). Provided X and Y have finite first moments, the BDC metric is defined as</p><formula xml:id="formula_1">?(X, Y ) = R p R q |? XY (t, s) ? ? X (t)? Y (s)| 2 c p c q t 1+p s 1+q dtds (2)</formula><p>where ? denotes Euclidean norm, c p = ? (1+p)/2 /?((1 + p)/2) and ? is the complete gamma function.</p><p>For the set of m observations {(x 1 , y 1 ), . . . , (x m , y m )} which are independent and identically distributed (i.i.d.), a natural approach is to define the BDC metric in light of the empirical characteristic functions:</p><formula xml:id="formula_2">? XY (t, s) = 1 m m k=1 exp(i(t T x k + s T y k ))<label>(3)</label></formula><p>Though Eq. (2) seems complicated, the BDC metric has a closed form expression for discrete observations. Let A = ( a kl ) ? R m?m where a kl = x k ?x l be an Euclidean distance matrix computed between the pairs of observations of X. Similarly, we compute the Euclidean distance matrix</p><formula xml:id="formula_3">B = ( b kl ) ? R m?m where b kl = y k ?y l .</formula><p>Then the BDC metric has the following form <ref type="bibr" target="#b34">[35]</ref> 1 :</p><formula xml:id="formula_4">?(X, Y ) = tr A T B<label>(4)</label></formula><p>where tr(?) denotes matrix trace, T denotes matrix transpose, and A = (a kl ) is dubbed BDC matrix. Here a kl = a kl ? 1 m l=1 a kl , where the last three terms indicate means of the l-th column, k-th row and all entries of A, respectively. The matrix B can be computed in a similar manner from B. As a BDC matrix is symmetric, ?(X, Y ) can also be written as the inner product of two BDC vectors a and b, i.e.,</p><formula xml:id="formula_5">?(X, Y ) = a, b = a T b<label>(5)</label></formula><p>where a (resp., b) is obtained by extracting the upper triangular portion of A (resp., B) and then performing vectorization. The metric ?(X, Y ) has some desirable properties. (1) It is non-negative, and is equal to 0 if and only if X and Y are independent. (2) It can characterize linear and nonlinear dependency between X and Y . (3) It is invariant to individual translations and orthonormal transformations of X and Y , and equivariant to their individual scaling factors. That is, for any vectors c 1 ? R p , c 2 ? R q , scalars s 1 , s 2 and orthonormal matrices</p><formula xml:id="formula_6">R 1 ? R p?p , R 2 ? R q?q , ?(c 1 + s 1 R 1 X, c 2 + s 2 R 2 Y ) = |s 1 s 2 |?(X, Y ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Formulation of DeepBDC as a Pooling Layer</head><p>In terms of Eq. (4) and Eq. (5), we can see that the BDC metric is decoupled in the sense that we can independently compute the BDC matrix for every input image. Specifically, we design a two-layer module suitable for a convolutional network, which performs dimension reduction and computation of the BDC matrix, respectively. As the size of a BDC matrix increases quadratically with respect to the number of channels (feature maps) in the network, we insert a 1 ? 1 convolution layer for dimension reduction right after the last convolution layer of the network backbone.</p><p>Suppose the network (including the dimension reduction layer) is parameterized by ? which embeds a color image z ? R 3 into a feature space. The embedding of the image is a h ? w ? d tensor, where h and w are spatial height and width while d is the number of channels. We reshape the tensor to a matrix X ? R hw?d , and can view either each column ? k ? R hw or each row (after transpose) x j ? R d as an observation of random vector X. We mention that in practice, for either case the i.i.d. assumption may not hold, and comparison of the two options is given in Sec. <ref type="bibr">4.2.</ref> In what follows, we take for example ? k as a random observation. We develop three operators, which successively compute the squared Euclidean distance matrix A = (? kl ) where? kl is squared Euclidean distance between the k-th column and l-th column of X, the Euclidean distance matrix A = ( ? a kl ), and the BDC matrix A obtained by subtracting from A its row mean, column mean and mean of all of its elements. That is,</p><formula xml:id="formula_7">A = 2 1(X T X ? I) sym ? 2X T X (6) A = a kl A = A ? 2 d 1 A sym + 1 d 2 1 A1</formula><p>Here 1 ? R d?d is a matrix each element of which is 1, I is the identity matrix, and ? indicates the Hadamard product. We denote (U) sym = 1 2 (U + U T ). Hereafter, we use A ? (z) to indicate that the BDC matrix is computed from the network parameterized by ? with an input image z.</p><p>As such, we formulate DeepBDC as a parameter-free, spatial pooling layer. It is highly modular, suitable for varying network architectures and for different frameworks of few-shot classification. The BDC matrix mainly involves standard matrix operations, appropriate for parallel computation on GPU. From Eq. (6), it is clear that the BDC matrix models non-linear relations among channels through Euclidean distance. The covariance matrices can be interpreted similarly, which, however, models linear relations among channels through inner product [49, Sec. 4.1]. Theoretically, they are quite different as the BDC matrices consider the joint distributions, while the covariance matrices only consider the marginal ones.  <ref type="figure" target="#fig_3">Figure 1</ref>. Two instantiations of our DeepBDC for few-shot classification. Meta DeepBDC (a) is based on the idea of meta learning which depends on episodic training; here we take a 3-way 2-shot classification as an example for illustration. In STL DeepBDC (b), we train a network with a conventional softmax classifier and cross-entroy loss on the whole meta-training spanning all classes; during meta-testing, we use the trained network as an embedding model for feature extraction, constructing and training a logistic regression model for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Instantiating DeepBDC for Few-shot Learning</head><p>We instantiate our DeepBDC based on meta-learning framework and on simple transfer learning framework, and the resulting Meta DeepBDC and STL DeepBDC are shown in <ref type="figure" target="#fig_3">Fig. 1a</ref> and <ref type="figure" target="#fig_3">Fig. 1b</ref>, respectively.</p><p>Meta DeepBDC Standard few-shot learning is performed in an episodic manner on a multitude of tasks. A task is often formulated as a N -way K-shot classification problem, which spans N classes each with K support images and Q query images, on a support set D sup = {(z j , y j )} N K j=1 and a query set D que = {(z j , y j )} N Q j=1 . A learner is trained on D sup and makes predictions on D que .</p><p>We instantiate Meta DeepBDC with ProtoNet <ref type="bibr" target="#b32">[33]</ref> as a blue print. It learns a metric space where classification is performed by computing distances to the prototype of every class. On one task (D sup , D que ), we feed image z j to the network to produce the BDC matrix A ? (z j ). The prototype of the support class k is the average (Avg) of the BDC matrices belonging to its class:</p><formula xml:id="formula_8">P k = 1 K (zj ,yj )?S k A ? (z j )<label>(7)</label></formula><p>where S k is the set of examples in D sup labeled with class k. We produce a distribution over classes based on a softmax over distances to the prototypes of the support classes, and then formulate the following loss function:</p><formula xml:id="formula_9">arg min ? ? (zj ,yj )?D que log exp(? tr(A ? (z j ) T P yj )) k exp(? tr(A ? (z j ) T P k ))<label>(8)</label></formula><p>where ? is a learnable scaling parameter <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>. We train the learner by sampling tasks from a massive meta-training set C train where the number of classes is far larger than N . Then, we sample tasks from a held-out metatesting set C test on which we evaluate the performance of the learner. The episodic training ensures consistency between meta-training and meta-testing, which is crucial for the meta-learning methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b38">39]</ref>. STL DeepBDC This instantiation is based on a widely used simple transfer learning (STL) framework <ref type="bibr" target="#b9">[10]</ref>, in which a deep network is trained on a large dataset and is then used as an embedding model to extract features for downstream tasks with few labeled examples.</p><p>We train a conventional image classification task on the whole meta-training set C train spanning all classes. The cross-entropy loss between prediction and ground-truth labels is used for training a learner from scratch:</p><formula xml:id="formula_10">arg min ?,W k ? (zj ,yj )?C train log exp(? tr(A ? (z j ) T W yj )) k exp(? tr(A ? (z j ) T W k ))<label>(9)</label></formula><p>where W k ? R d?d is the k-th weight matrix and ? is a learnable scaling parameter. For a task (D sup , D que ) sampled from meta-testing set C test , we build and train a new linear classifier for K classes on D sup , using the trained model as a feature extractor. Following <ref type="bibr" target="#b36">[37]</ref>, we adopt the logistic regression model for classification, and, instead of directly using the trained model for meta-testing tasks, a sequential self-distillation technique is used to distill knowledge from the trained model on the meta-training set. By referring to Eq. (8) and Eq. (9), we can interpret W k as the prototype of class k, a dummy BDC matrix learned through training. Note that similar interpretations are given in DeepEMD <ref type="bibr" target="#b46">[47]</ref> and FRN <ref type="bibr" target="#b44">[45]</ref>. It is worth mentioning that, by vectorization operation as described in Eq. (5) for both the BDC matrices and the weight matrices, the softmax function in Eq. (9) can be implemented via a standard fullyconnected (FC) layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Relation with Previous Methods</head><p>Let {x j } n j=1 be features of a query image, viewed as the observations of a random vector X. One can compute the mean vector ? X = 1 n n j=1 x j , covariance matrix</p><formula xml:id="formula_11">? X = 1 n n j=1 (x j ? ? X )(x j ? ? X ) T or Gaussian distri- bution N ? X ,? X ,</formula><p>as image representations. Note that these representations have been extensively studied outside of the few-shot learning regime, where they are deemed global average pooling <ref type="bibr" target="#b12">[13]</ref>, bilinear <ref type="bibr" target="#b21">[22]</ref> or covariance pooling <ref type="bibr" target="#b41">[42]</ref>, and Gaussian pooling <ref type="bibr" target="#b40">[41]</ref>, respectively. The corresponding prototypes of the support class, ? Y , ? Y or N ? Y ,? Y , can be computed using the features of K support images. ProtoNet <ref type="bibr" target="#b32">[33]</ref> represents the images with the mean vector and measures the difference using Euclidean dis-</p><formula xml:id="formula_12">tance ? ProtoNet (X, Y ) = ? X ?? Y 2 or cosine similarity ? T X ? Y /( ? X ? Y ) for metric learning.</formula><p>CovNet <ref type="bibr" target="#b43">[44]</ref> adopts the covariance matrices as image representations for improving the first-order representation. The covariance matrices are subject to signed square-root normalization and then are compared with the Euclidean distance in the matrix space (i.e., the Frobenius norm)</p><formula xml:id="formula_13">? CovNet (X, Y ) = ? X ? ? Y 2 .</formula><p>ADM [20] proposes to use an asymmetric distribution measure (ADM) to evaluate the dis-similarity between the query image and the support class. The distributions of images are represented by multivariate Gaussians whose differences are measured by KL-divergence</p><formula xml:id="formula_14">? ADM (X, Y ) = D KL (N ? X ,? X ||N ? Y ,? Y ).</formula><p>DeepEMD <ref type="bibr" target="#b46">[47]</ref> uses discrete distributions as image representations. Specifically, the discrete PDF of the query image is f X (x) = n j=1 f xj ? x,xj , where f xj denotes the probability of x j and ? x,xj is the Kronecker delta which is equal to 1 if x = x j and zero otherwise. Let the PDF of a support image be f Y (y) = n j=1 f yj ? y,yj . The distance between f X (x) and f Y (y) is formulated as EMD, i.e., ? EMD (X, Y ) = min fx j ,y l ?0 n j=1 n l=1 f xj ,y l c xj ,y l with constraints n l=1 f xj ,y l = f xj and n j=1 f xj ,y l = f y l for j, l = 1, . . . , n. Here c xj ,y l is the transport cost. Thus, EMD seeks an optimal joint distribution f XY (x j , y l ) = f xj ,y l such that the expectation of transportation cost is minimal <ref type="bibr" target="#b28">[29,</ref><ref type="bibr">Sec. 2.3]</ref>. DeepEMD proposes a cross-reference mechanism to define f xj and f y l , and a structured FC layer to handle K-shot classification (K&gt;1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We first describe briefly the experimental settings. Next, we perform ablation study on our two instantiations (i.e., Meta DeepBDC and STL DeepBDC) and make comparisons to the counterparts. Finally, we compare with state-ofthe-art methods on six few-shot datasets, covering general object recognition, fine-grained categorization and cross-  domain classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Datasets We experiment on two general object recognition benchmarks, i.e., miniImageNet <ref type="bibr" target="#b38">[39]</ref> and tieredImageNet <ref type="bibr" target="#b30">[31]</ref>, and one fine-grained image classification dataset, i.e., CUB-200-2011 <ref type="bibr" target="#b39">[40]</ref> (CUB for short). We also evaluate domain transfer ability of models by training on miniImageNet and then test on CUB <ref type="bibr" target="#b39">[40]</ref>, Aircraft <ref type="bibr" target="#b23">[24]</ref> and Cars <ref type="bibr" target="#b15">[16]</ref>.</p><p>Backbone network For fair comparisons with previous methods, we use two kinds of networks as backbones, i.e., ResNet-12 <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37]</ref> and ResNet-18 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b33">34]</ref>. Same as commonly used practice, the input resolution of images is 84?84 for ResNet-12 and 224?224 for ResNet-18, respectively. Moreover, we adopt deeper models with higher capacity, i.e., ResNet-34 <ref type="bibr" target="#b12">[13]</ref> with input images of 224?224 and a variant of ResNet-34 fit for input images of 84?84. Similar to <ref type="bibr" target="#b8">[9,</ref><ref type="bibr">20]</ref>, we remove the last down-sampling of backbones to obtain more convolutional features.</p><p>Training Our Meta DeepBDC is based on meta-learning framework, depending on episodic training. Each episode (task) concerns standard 5-way 1-shot or 5-way 5-shot classification, uniformly sampled from meta-training or metatesting set; following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref>, before episodic training, we pre-train the models whose weights are used as initialization. Contrary to Meta DeepBDC, our STL DeepBDC is based on simple transfer learning framework, requiring non-episodic training. Following <ref type="bibr" target="#b36">[37]</ref>, we train a network as an embedding model with cross-entropy loss on the whole meta-training set spanning all classes; for each meta-testing task, we train a new logistic regression classifier using the features extracted by the embedding model. In supplement (Supp.) S1, we provide statistics of datasets and the splits of meta training/validation/test sets, as well as details on network architectures, optimizers, hyperparameters, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study</head><p>We perform ablation analysis of our two instantiations and compare to the counterparts on miniImageNet for 5way task, with ResNet-12 as the backbone. Additional details on implementation of the counterparts and extra experiments are respectively given in Supp. S-2 and Supp. S-3. Ablation analysis of Meta DeepBDC As the sizes of BDC matrices are quadratic in the number of channels, we introduce a 1?1 convolution (conv) layer, decreasing the channel number to d. In our implementation, each BDC matrix is vectorized as in Eq. (5), thus is of size d(d+1)/2. Tab. 2a (top) shows the effect of varying d on accuracy and on metatesting time per episode. We can see that the highest accuracy is achieved when d = 640; meanwhile, the meta-testing time only increases moderately as d enlarges. We also experiment by directly attaching BDC module to the backbone without the additional 1 ? 1 conv layer; we achieve 67.10?0.43 and 84.50?0.28 for 1-shot and 5-shot, respectively, comparable to the best result obtained by using the additional 1 ? 1 conv layer. Besides the inner product as depicted in Eq. (5), we can also use Euclidean distance or cosine similarity as metric, and the corresponding results are given in Tab. 2a (bottom). It can be seen that the inner product performs best for 1-shot task, while the Euclidean  distance achieves the highest accuracy for 5-shot. The optimal setting achieved here is used throughout the remaining paper. Finally, we note that Meta DeepBDC has much better performance than the baseline (i.e., ProtoNet), regardless of the value of d, while increase of latency is small. Ablation analysis of STL DeepBDC For each meta-testing task of STL DeepBDC, we need to build and train a new linear classifier which introduces parameters and computations. As the size of BDC matrix is quadratic in d, the number of parameters is considerable relative to that of training examples, particularly for larger d. Therefore, with increase of d, there exist greater risk of overfitting, which may explain why overall the accuracy becomes lower when d is larger for both 1-shot and 5-shot tasks, as shown in <ref type="table">Tab</ref>  <ref type="figure" target="#fig_3">128)</ref>, respectively, much lower than the accuracies of spatial pooling. Note that the i.i.d. assumption may not hold for either spatial or channel pooling; our comparison suggests the spatial pooling is a better option.</p><p>Comparison to the counterparts Here we compare with the counterparts whose representations are based on distribution modeling. Like our DeepBDC, both ADM and CovNet need to estimate second moments, which leads to quadratic increase of representations. Therefore, for a fair comparison with them, we also add a 1?1 convolution with d channels for dimension reduction, obtaining the best results for them by tuning d. The comparion results are presented in Tab. 3. Regarding the accuracy, we have several observations. (1) ProtoNet is inferior to CovNet and ADM, suggesting that second moments have better capability to model marginal distributions than first moment. (2) DeepEMD outperforms CovNet and ADM, which indicates that joint distribution modeling via EMD is superior to modeling of marginal distributions. (3) Both our two instantiations outperform the counterparts by large margins. We attribute this to that BDC has stronger capability of statistical dependency modeling by effectively harnessing joint distributions. As to the latency, our two instantiations both take a little longer time than ProtoNet and CovNet, while being <ref type="table">Table 5</ref>. Comparison with state-of-the-art methods for 5-way 5-shot classification in cross-domain scenarios. The best results are in bold black and second-best ones are in red. ? Reproduced with our setting. comparable to ADM. Notably, DeepEMD is computationally expensive, ? 2 times and 50 times slower than the other methods for 1-shot and 5-shot tasks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with State-of-the-art Methods</head><p>General object recognition According to Tab. 4a, on miniImageNet, for 1-shot task Meta DeepBDC is on par with state-of-the-art MELR while STL DeepBDC is better than it; for 5-shot task, Meta DeepBDC and STL DeepBDC outperform BML, which previously achieved the best result, by 0.83 percentage points (abbreviated as pp hereafter) and 1.82 pp, respectively. Our Meta DeepBDC can be further improved by combining Image-to-Class Measure (DN4) following the idea introduced in [20]; accordingly, we achieve 67.86?0.41/85.14?0.29 for 1-shot/5-shot tasks, outperforming ADM+DN4 (66.53?0.43/82.61?0.30). On tieredImageNet, for 1-shot task Meta DeepBDC is slightly better than state-of-the-art IEPT while STL DeepBDC outperforms it by 1.58 pp; for 5-shot task, Meta DeepBDC achieves slight gains (0.3 pp) over state-of-the-art MELR while STL DeepBDC has much larger gains (?2.0 pp). Cross-domain classification Finally, we evaluate 5-way 5shot classification in cross-domain scenarios, by training on miniImageNet and testing on three widely used fine-grained datasets. Except DeepEMD which is computationally prohibitive for us, we implement all counterparts based on distribution modeling, and Good-Embed on the three datasets, as well as Baseline and Baseline++ <ref type="bibr" target="#b3">[4]</ref> on Aircraft and Cars. The results are shown in Tab. 5. On miniImageNet?CUB, CovNet is very competitive, only slightly inferior to FRN, and both of them are much better than the other methods except ours. Meta DeepBDC and STL DeepBDC outperform the high-performing FRN by 0.8 pp and 3.1 pp, respectively. On miniImageNet?Aircraft, our two instantiations improve over all the other compared methods by more than 3.2 pp. On miniImageNet?Cars, ADM is superior among our competitors; compared to it, Meta DeepBDC and STL DeepBDC achieve 0.7 pp and 4.2 pp higher accuracies, respectively. These comparisons demonstrate that our models have stronger domain transfer capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-grained categorization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose a deep Brownian Distance Covariance (DeepBDC) method for few-shot classification. DeepBDC can effectively learn image representations by measuring, for the query and support images, the discrepancy between the joint distribution of their embedded features and product of the marginals. The core of DeepBDC is formulated as a modular and efficient layer, which can be flexibly inserted into deep networks, suitable not only for meta-learning framework based on episodic training, but also for the simple transfer learning framework that relies on non-episodic training. Extensive experiments have shown that our DeepBDC method performs much better than the counterparts, and furthermore, sets new state-ofthe-art results on multiple general, fine-grained and crossdomain few-shot classification tasks. Our work shows great potential of BDC, a fundamental but overlooked technique, and encourages its future applications in deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>In this supplement, we present details on the implementations of our DeepBDC and the counterparts. Besides, we conduct experiments providing additional ablation study and comparison. We finally show BDC's ability to characterize non-linear dependence. S1 Implementations S1-1 Benchmarks miniImageNet The miniImageNet [S-22] is a few-shot benchmark constructed from ImageNet [S-6] for general object recognition. It consists of 100 classes each of which contains 600 images. Following previous works [S-4, S-25, S-26], we use the splits provided by <ref type="bibr">[S-18]</ref>, which involves 64 classes for meta-training, 16 classes for metavalidation and the remaining 20 classes for meta-testing.</p><p>tieredImageNet The tieredImageNet [S-19] is also a fewshot benchmark for general object recognition. It is constructed from ImageNet [S-6] as well, which, different from miniImageNet, considers the hierarchical structure of Ima-geNet. This dataset contains 608 classes from 34 superclasses and a total of 779,165 images. Among these classes, 20 super-classes (351 classes) are used for meta-training, 6 super-classes (97 classes) for meta-validation and the remaining 8 super-classes (160 classes) for meta-testing. miniImageNet ? Cars Stanford Cars [S-10] (Cars) contains 196 classes and a total 16,185 images. We follow the splits of [S-13] to build the meta-validation set <ref type="bibr">(17 classes)</ref> and meta-testing set <ref type="bibr">(49 classes)</ref>. Similar to the other crossdomain benchmarks, the full miniImageNet is used as metatraining set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1-2 Architectures</head><p>For fair comparisons with previous methods, we use two kinds of networks as backbones, i.e., ResNet-12 and ResNet-18. Following previous practice, the input resolution of images is 84?84 for ResNet-12, and 224?224 for ResNet-18, respectively. Besides, we use higher capacity models, i.e., ResNet-34 with input images of 224?224 and its variant fit for input images of 84?84.</p><p>As </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1-3 Training and Evaluation Protocols</head><p>Training During training, following [S-4, S-25, S-27], we use standard data augmentation including random resized crop, color jittering and random horizontal flip on all benchmarks. We adopt the SGD algorithm with a momentum of 0.9 and a weight decay of 5e-4 to train our proposed DeepBDC networks. For ResNet-12, we apply Drop-Block [S-7] regularization during training as in [S-26, S-11, S-5]. We tune the number of epochs and the scheduling of learning rate (LR) on different benchmarks.</p><p>For our Meta DeepBDC which is based on meta-learning framework, we train the model by uniformly sampling episodes (tasks) from the meta-training set. Following previous works [S-5, S-25, S-27], right before performing the episodic training, we pre-train the networks on the full meta-training set whose weights are used as initialization.</p><p>To sample a 5-way 1-shot task, we randomly pick up 5 classes each with 1 support image and 16 query images selected at random. Similarly, every 5-way 5-shot task contains 5 support images and 16 query images. Tab. S-1 (upper part) shows the hyper-parameter settings for training Meta DeepBDC on all benchmarks. Let us take miniImageNet as an example: the initial learning rate (LR) is 1e-4, which is divided by 10 at epoch 40 and 80, respectively, and training proceeds until epoch 100. We adopt the model achieving highest accuracy on the meta-validation for evaluation on the meta-testing set.</p><p>Our  which falls into simple transfer learning framework, not requiring episodic training. In practice, we train the network for a common multi-way classification task, using a softmax classifier via a standard cross-entropy loss on the whole meta-training set spanning all classes. We set the batch size to 64 across all benchmarks. Furthermore, following [S-21], we conduct sequential self-distillation to distill knowledge from the trained model. The networks thus obtained are used as embedding models for extracting features (i.e., outputs of the last convolution layer of one network). The hyper-parameter settings for STL DeepBDC are shown in Tab. S-1 (bottom part).</p><p>Evaluation We uniformly sample episodes (tasks) from the meta-testing set to evaluate the models' performance. Following [S-4], we build 5-way 1-shot or 5-shot setting, respectively, both with 15 query images. We report mean accuracy of 2,000 episodes with 95% confidence intervals. Our Meta DeepBDC does not require additional training, so we directly performing testing. Our STL DeepBDC needs to train a linear classifier for each episode using the trained model for feature extraction. We implement the logistic regression via L-BFGS-B algorithm and linear SVM via LIB-SVM based on scikit-learn software package <ref type="bibr">[S-17]</ref>. We perform L2 normalization for the features in logistic regression and SVM; furthermore, we standardize the normalized features before fed to SVM. Implementation of the soft-max classifier is based on PyTorch, where we adopt SGD algorithm with a batch size of 4, a momentum of 0.9, a weight decay of 1e-3 and a learning rate of 1e-2.  <ref type="bibr" target="#b2">3</ref> . Practically, we have two differences: (1) we introduce a 1?1 convolution for dimension reduction, and (2) for 5-way 1-shot classification, we use the inner product as the metric, rather than the Frobenious norm which produces poor results. For all of the aforementioned methods, we remove the last down-sampling of the backbones. Following the previous practice [S-25, S-5, S-28], we employ the weights of pre-trained models as initialization before performing episodic training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2 Implementation of the Counterparts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3 Additional Experiments</head><p>This section introduces additional experiments to ablate our DeepBDC and to compare with the counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3-1 On prototype in Meta DeepBDC</head><p>In Meta DeepBDC, for the 5-shot setting, the prototype of a support class is computed as the average of BDC matrices of 5 support images belonging to this class. Here, we evaluate two other options for computing the prototype.</p><p>(1) We average features of 5 support images, and then the averaged features are used to compute the BDC matrix as the prototype. (2) We concatenate features of 5 support images for computing the BDC matrix as the prototype. These two methods achieve accuracies (%) of 82.36 and 83.74 on miniImageNet, respectively, which are lower than the accuracy obtained by averaging 5 support BDC matrices (84.46).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3-2 Effect of Higher Capacity Models</head><p>To evaluate the effect of higher capacity models, we conduct experiments on CUB using the ResNet-34 with 224?224 input images, and on miniImageNet using the variant of ResNet-34 with input images of 84?84. We compare our Meta DeepBDC and STL DeepBDC with their respective baselines, i.e., ProtoNet and Good-Embed. The comparison on miniImageNet is shown in Tab. S-2. It can be seen that, for every method with either setting, the accuracy obtained by using high-capacity ResNet-34 is higher than that using ResNet-12. Among them, the improvements of ProtoNet and Good-Embed for 1-shot task are significant (over 1 percentage points). Despite the improvements, our Meta DeepBDC and STL DeepBDC outperform their corresponding baselines by large margins. According to Tab. S-3 which presents results on CUB, we can see that overall all methods improve when using highercapacity ResNet-34, while the improvements of ProtoNet are not significant. Again, we observe that our methods are significantly superior to their baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3-3 Effect of Feature Number on DeepBDC</head><p>To obtain more convolutional features, CTX [S-3] removes the last down-sampling in the backbone networks, while ADM [S-12] removes the last two. Similar to them, we also remove down-sampling. On miniImageNet, we evaluate the effect of down-sampling on our DeepBDC. As the input resolution is 84 ? 84 for ResNet-12, the spatial size of feature maps outputted by the original backbone is 5 ? 5 and thus we have a total of 25 features; the spatial sizes become 10 ? 10 and 21 ? 21 if the last down-sampling and the last two are eliminated, respectively.</p><p>Tab. S-4 summarize the results. We first notice that variation of feature number has minor effect on our STL DeepBDC for either 1-shot or 5-shot task. Regarding our Meta DeepBDC, it can be seen that for both 1-shot and 5- shot tasks, the accuracy increases slightly when the number of features is 100, but then decreases when provided with 441 features. At last, we note that ProtoNet and Good-Embed achieves individual best results when the feature number is 100 and 25, respectively. Throughout the main paper, we report results with removal of the last downsampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3-4 Comparison of Latency of Meta-training Task</head><p>In the main paper, we compare the latency of metatesting task. Here, we give additional comparison for metatraining task, which is also important in practice. The latency is measured on miniImageNet with the backbone of ResNet-12. Following the setting of DeepEMD [S-27], we adopt QPTH solver [S-2] in meta-training and OpenCV solver in meta-testing, using the code released by the authors <ref type="bibr" target="#b3">4</ref> .</p><p>Tab. S-5 shows comparison results for 5-way classification; for reference, we also include latency of meta-testing task and recognition accuracies which have been discussed in the primary paper. As regards the meta-training, we find that ProtoNet and CovNet are fastest, while our Meta DeepBDC is somewhat slower than them. Though the metatesting speed of ADM is comparable to that of our method, its meta-training latency is much larger than ours; the reason is that backpropagation of ADM involves GPU-unfriendly matrix inversions. Notably, DeepEMD is at least 80 times slower for 1-shot and 1000 times slower for 5-shot than the other methods; we mention that FRN also observes the big latency of DeepEMD [S-25].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3-5 Effect of Channel Number on DeepBDC and the Counterparts</head><p>As described in the main paper, both of CovNet and ADM need to estimate second moments, leading to quadratic increase of representations in channel number d. Therefore, for fair comparison, we also add a 1 ? 1 convolution for them to reduce the number of channels. Dimension reduction is hurtful for ProtoNet and DeepEMD, so for them we leave the original channel as it is. <ref type="figure" target="#fig_3">Fig. S-1</ref> plots the curves of accuracies as a function of d. In light of the curves, we can draw several conclusions as follows. (1) The channel number d has non-trivial effect on ADM and CovNet. The accuracies (%) of ADM and CovNet reach the highest values when d = 196 (82.05) and d = 256 (82.02), respectively. Their accuracies drop gradually when d becomes larger, and when d = 640, they achieve accuracies only slightly higher than ProtoNet. <ref type="bibr" target="#b1">(2)</ref> Across all values of d, both instantiations of our DeepBDC clearly perform better than the competing methods.</p><p>We mention that our re-implementation non-trivially improves performance of CovNet and ADM, providing fair and competitive baselines. Besides, these results show that dimension reduction plays an important role for second moment-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4 Linear and Non-linear Relation Modeling</head><p>One of the favorable properties of Brownian Distance Covariance (BDC) is the ability to model both linear and non-linear dependency between random variables X and Y . In contrast, traditional covariance can only model linear relations. To facilitate visual understanding, we consider five simulated examples of bivariate distributions [S-9], i.e., "W-shape", "Diamond", "Parabola", "Two parabolas" and "Circle", and two examples we developed, i.e., "Butterfly" and "Heart", respectively. In these examples, two random variables X and Y have different kinds of non-linear relationships. Also, we simulate seven kinds of linear relations based on HHG package <ref type="bibr" target="#b4">5</ref>  Here cov(X, Y ) and BDC(X, Y ) respectively denote the covariance and Brownian distance covariance. Naturally, cov(X, X) and BDC(X, X) denote variance and Brownian distance variance of X, respectively. <ref type="figure">Fig. S-2</ref> shows the scatter plots of the simulated examples together with the values of correlation and Brownian distance correlation. From <ref type="figure">Fig. S-2a</ref>, we can see that for all non-linear relations Corr(X, Y ) = 0, indicating that classical correlation fails to model such complex relations; on the contrary, Brownian distance correlation can characterize the non-linear dependencies. As shown in <ref type="figure">Fig. S-2b</ref>, compared to correlation, Brownian distance correlation has similar capability to model linear relations, except that it cannot distinguish the orientation as it is always non-negative; besides, both of them cannot reflect the slope of linear relations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>CUB Caltech-UCSD Birds-200-2011 [S-23] (CUB) dataset is a widely used fine-grained categorization benchmark. This dataset contains 200 bird classes with 11,788 images in total. We use the splits of [S-4], in which the total classes are divided into 100/50/50 for metatraining/validation/testing. Following [S-4, S-14, S-1], we conduct experiments on CUB with the original raw images, instead of cropped images via annotated bounding boxes [S-26, S-27]. miniImageNet ? CUB Chen et al. [S-4] build the crossdomain task for assessing the domain transfer ability of the models. In this setting, all 100 classes of miniImageNet are used for meta-training, while the models are evaluated on the meta-testing set (50 classes) of CUB.miniImageNet ? Aircraft Aircraft [S-15] contains 10,000 images from 100 classes. We perform meta-training on the whole miniImageNet; we adopt the splits on Aircraft proposed by[S-25], where 25 classes are used for metavalidation and 25 classes are for meta-testing. Same as [S-25], we conduct experiments with the images cropped by using the bounding box annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>in [S-21, S-11, S-16, S-25], ResNet-12 consists of four stages each of which contains one residual block. The widths of the residual blocks of the four stages are [64, 160, 320, 640]. Each residual block has three 3?3 convolution layers with a batch normalization and a 0.1 leaky ReLU. Right after every block except the last one, a 2?2 max pooling layer is used to down-sample the feature maps. We adopt ResNet-18 and ResNet-34 proposed in [S-8] with the last down-sampling being removed. The architecture of the variant of ResNet-34 is same as that of ResNet-12, except that the numbers of residual blocks of the four stages are [2, 3, 4, 2], instead of [1, 1, 1, 1] in ResNet-12.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure S- 1 .</head><label>1</label><figDesc>Accuracy as a function of channel number d for 5-way 5-shot classification on miniImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>. For each set of observation pairs, we compute the classical correlationCorr(X, Y ) = cov(X, Y ) cov(X, X) cov(Y, Y ) (S-1)and Brownian distance correlationBDCorr(X, Y ) = BDC(X, Y ) BDC(X, X) BDC(Y, Y ) (S-2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .Table 3</head><label>23</label><figDesc>Ablation analysis of our two instantiations of DeepBDC with the backbone of ResNet-12 on miniImageNet. We report accuracy and latency (ms) of one meta-testing task for 5-way classification. Latency is measured with a GeForce GTX 1080.</figDesc><table><row><cell>Method</cell><cell>Acc</cell><cell>1-shot</cell><cell>Latency</cell><cell>Acc</cell><cell>5-shot</cell><cell>Latency</cell></row><row><cell>ProtoNet [33]</cell><cell cols="2">62.11?0.44</cell><cell>115</cell><cell cols="2">80.77?0.30</cell><cell>143</cell></row><row><cell>ADM [20]</cell><cell cols="2">65.87?0.43</cell><cell>199</cell><cell cols="2">82.05?0.29</cell><cell>221</cell></row><row><cell>CovNet [44]</cell><cell cols="2">64.59?0.45</cell><cell>120</cell><cell cols="2">82.02?0.29</cell><cell>144</cell></row><row><cell cols="3">DeepEMD [47] 65.91?0.82</cell><cell>457</cell><cell cols="3">82.41?0.56 12617</cell></row><row><cell cols="3">Meta DeepBDC 67.34?0.43</cell><cell>161</cell><cell cols="2">84.46?0.28</cell><cell>198</cell></row><row><cell cols="3">STL DeepBDC 67.83?0.43</cell><cell>184</cell><cell cols="2">85.45?0.29</cell><cell>245</cell></row></table><note>. Comparison of accuracy and latency (ms) of 5-way clas- sification to the counterparts with the backbone of ResNet-12 on miniImageNet.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>ResNet-12 62.64?0.44 78.63?0.46 65.99?0.72 81.56?0.63 DN4 [21] ? ResNet-12 64.73?0.44 79.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>miniImageNet 1-shot 5-shot</cell><cell cols="2">tieredImageNet 1-shot 5-shot</cell><cell>Method</cell><cell>Backbone</cell><cell>1-shot</cell><cell>CUB 5-shot</cell></row><row><cell>CTM [19]</cell><cell cols="4">ResNet-18 64.12?0.82 80.51?0.13 68.41?0.39 84.28?1.73</cell><cell>ProtoNet [33]</cell><cell cols="3">Conv4 64.42?0.48 81.82?0.35</cell></row><row><cell>S2M2 [25]</cell><cell cols="2">ResNet-18 64.06?0.18 80.58?0.12</cell><cell>-</cell><cell>-</cell><cell>FEAT [46]</cell><cell cols="3">Conv4 68.87?0.22 82.90?0.15</cell></row><row><cell>TADAM [26]</cell><cell cols="2">ResNet-12 58.50?0.30 76.70?0.38</cell><cell>-</cell><cell>-</cell><cell>MELR [11]</cell><cell cols="3">Conv4 70.26?0.50 85.01?0.32</cell></row><row><cell cols="3">MetaOptNet [18] 85?0.31</cell><cell>-</cell><cell>-</cell><cell>MVT [27] MatchNet [39]</cell><cell cols="3">ResNet-10 ResNet-12 71.87?0.85 85.08?0.57 -85.35?0.55</cell></row><row><cell cols="3">Baseline++ [4]  ? ResNet-12 60.56?0.45 77.40?0.34</cell><cell>-</cell><cell>-</cell><cell cols="3">Wang et al. LR [43] ResNet-12 76.16</cell><cell>90.32</cell></row><row><cell cols="5">Good-Embed [37] ResNet-12 64.82?0.60 82.14?0.43 71.52?0.69 86.03?0.58</cell><cell>MAML [12]</cell><cell cols="3">ResNet-18 68.42?1.07 83.47?0.62</cell></row><row><cell>FEAT [46]</cell><cell cols="4">ResNet-12 66.78?0.20 82.05?0.14 70.80?0.23 84.79?0.16</cell><cell>?-encoder [32]</cell><cell cols="2">ResNet-18 69.80</cell><cell>82.60</cell></row><row><cell cols="5">Meta-Baseline [5] ResNet-12 63.17?0.23 79.26? 0.17 68.62?0.27 83.29?0.18</cell><cell>Baseline++ [4]</cell><cell cols="3">ResNet-18 67.02?0.90 83.58?0.54</cell></row><row><cell>MELR [11]</cell><cell cols="4">ResNet-12 67.40?0.43 83.40?0.28 72.14?0.51 87.01?0.35</cell><cell>AA [1]</cell><cell cols="3">ResNet-18 74.22?1.09 88.65?0.55</cell></row><row><cell>FRN [45]</cell><cell cols="4">ResNet-12 66.45?0.19 82.83?0.13 71.16?0.22 86.01?0.15</cell><cell>Neg-Cosine [23]</cell><cell cols="3">ResNet-18 72.66?0.85 89.40?0.43</cell></row><row><cell>IEPT [50]</cell><cell cols="4">ResNet-12 67.05?0.44 82.90?0.30 72.24?0.50 86.73?0.34</cell><cell cols="3">LaplacianShot [52] ResNet-18 80.96</cell><cell>88.68</cell></row><row><cell>BML [51]</cell><cell cols="4">ResNet-12 67.04?0.63 83.63?0.29 68.99?0.50 85.49?0.34</cell><cell>FRN [45]  ?</cell><cell cols="3">ResNet-18 82.55?0.19 92.98?0.10</cell></row><row><cell>ProtoNet [33]  ?</cell><cell cols="4">ResNet-12 62.11?0.44 80.77?0.30 68.31?0.51 83.85?0.36</cell><cell cols="4">Good-Embed [37]  ? ResNet-18 77.92?0.46 89.94?0.26</cell></row><row><cell>ADM [20]  ?</cell><cell cols="4">ResNet-12 65.87?0.43 82.05?0.29 70.78?0.52 85.70?0.43</cell><cell>ProtoNet [33]  ?</cell><cell cols="3">ResNet-18 80.90?0.43 89.81?0.23</cell></row><row><cell>CovNet [44]  ?</cell><cell cols="4">ResNet-12 64.59?0.45 82.02?0.29 69.75?0.52 84.21?0.26</cell><cell>ADM [20]  ?</cell><cell cols="3">ResNet-18 79.31?0.43 90.69?0.21</cell></row><row><cell>DeepEMD [47]</cell><cell cols="4">ResNet-12 65.91?0.82 82.41?0.56 71.16?0.87 86.03?0.58</cell><cell>CovNet [44]  ?</cell><cell cols="3">ResNet-18 80.76?0.42 92.05?0.20</cell></row><row><cell cols="5">Meta DeepBDC ResNet-12 67.34?0.43 84.46?0.28 72.34?0.49 87.31?0.32</cell><cell>Meta DeepBDC</cell><cell cols="3">ResNet-18 83.55?0.40 93.82?0.17</cell></row><row><cell>STL DeepBDC</cell><cell cols="4">ResNet-12 67.83?0.43 85.45?0.29 73.82?0.47 89.00?0.30</cell><cell>STL DeepBDC</cell><cell cols="3">ResNet-18 84.01?0.42 94.02?0.24</cell></row><row><cell></cell><cell cols="3">(a) Results on general object recognition datasets.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>(b) Results on fine-grained categorization dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>Comparison with state-of-the-art methods for both general and fine-grained few-shot image classification. The best results are in bold black and second-best ones are in red.? Reproduced with our setting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Following<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b22">23]</ref>, we conduct experiments on CUB with the original raw images. We reproduce ProtoNet and Good-Embed which are our baselines as well as FRN. From Tab. 4b, we can see that reproduced ProtoNet and Good-Embed are competitive with previous published accuracies, indicating our re-implemented baselines provide fair competition; moreover, our methods are high-ranking across the board, compared to state-of-the-art FRN, the gains of Meta DeepBDC and STL DeepBDC are 1.0/1.5 pp and 0.8/1.0 pp for 1-shot/5-shot task, respectively. Furthermore, by adopting ResNet-34 with 224?224 input images, our methods further improve. Specifically, Meta DeepBDC and STL DeepBDC achieve 85.25?0.<ref type="bibr" target="#b38">39</ref>/94.31?0.17 and 84.69?0.43/94.33?0.21, respectively, outperforming corresponding baselines of ProtoNet (80.58?/90.11?0.26) and Good-Embed (79.33?0.48/90.10?0.28).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table S</head><label>S</label><figDesc>-1. Hyperparameter settings of our DeepBDC.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Method ProtoNet ?</head><label>ProtoNet</label><figDesc>Good-Embed ? Meta DeepBDC STL DeepBDC 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot ResNet-12 62.11 80.77 64.98 82.10 67.34 84.46 67.83 85.45 ResNet-34 64.56 81.16 66.14 82.39 68.20 84.97 68.66 85.47</figDesc><table><row><cell>?</cell><cell></cell><cell>2.45 0.39 1.16 0.29 0.86</cell><cell>0.51</cell><cell>0.83</cell><cell>0.02</cell></row><row><cell cols="2">Table S-2.</cell><cell cols="4">Comparison of different capacity models on</cell></row><row><cell cols="6">miniImageNet with input images of 84?84. The ResNet-34 model</cell></row><row><cell cols="6">is a variant of [S-8] which is described in Sec. S1-2.  ? Reproduced</cell></row><row><cell cols="3">with our setting.</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="5">ProtoNet  ? Good-Embed  ? Meta DeepBDC STL DeepBDC 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot</cell></row><row><cell cols="6">ResNet-18 80.90 89.81 77.92 89.94 83.55 93.82 84.01 94.02</cell></row><row><cell cols="6">ResNet-34 80.58 90.11 79.33 90.10 85.25 94.31 84.69 94.33</cell></row><row><cell>?</cell><cell cols="2">-0.32 0.30 1.41 0.16 1.70</cell><cell>0.49</cell><cell>0.68</cell><cell>0.31</cell></row><row><cell cols="6">Table S-3. Comparsion of different capacity models on CUB with</cell></row><row><cell cols="6">input images of 224?224. Here we use ResNet-34 proposed in [S-</cell></row><row><cell>8].</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>? Reproduced with our setting.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>? 61.81 79.62 62.11 80.77 61.45 80.00 Good-Embed [S-21] ? 65.73 83.08 64.98 82.10 64.68 81.85 Meta DeepBDC 66.74 83.83 67.34 84.46 66.83 84.20</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="5">5?5 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 10?10 21?21</cell></row><row><cell cols="2">ProtoNet [S-20]  STL DeepBDC</cell><cell cols="5">67.76 85.39 67.83 85.45 67.44 85.44</cell></row><row><cell>Table S-4.</cell><cell cols="6">Accuracy (%) against number of features on</cell></row><row><cell cols="7">miniImageNet for 5-way classification.  ? Reproduced with our</cell></row><row><cell>setting.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell></cell><cell cols="2">Meta-training</cell><cell cols="2">Meta-testing</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="5">1-shot 5-shot 1-shot 5-shot 1-shot 5-shot</cell></row><row><cell cols="2">ProtoNet [S-20]  ?</cell><cell>304</cell><cell>365</cell><cell>115</cell><cell>143</cell><cell>62.11 80.77</cell></row><row><cell cols="2">ADM [S-12]  ?</cell><cell>908</cell><cell>967</cell><cell>199</cell><cell>221</cell><cell>65.87 82.05</cell></row><row><cell cols="2">CovNet [S-24]  ?</cell><cell>310</cell><cell>374</cell><cell>120</cell><cell>144</cell><cell>64.59 82.02</cell></row><row><cell cols="4">DeepEMD [S-27] &gt;80K &gt;10 6</cell><cell cols="3">457 12,617 65.91 82.41</cell></row><row><cell cols="2">Meta DeepBDC</cell><cell>505</cell><cell>623</cell><cell>161</cell><cell>198</cell><cell>67.34 84.46</cell></row><row><cell cols="2">STL DeepBDC</cell><cell>-</cell><cell></cell><cell>184</cell><cell>245</cell><cell>67.83 85.45</cell></row><row><cell cols="7">Table S-5. Comparison of latency (ms) for 5-way classification</cell></row><row><cell cols="2">on miniImageNet.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>? Reproduced with our setting.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Actually, ?(X, Y ) = 1 m 2 tr A T B and the constant 1 m 2 is assimilated into a learnable scaling parameter ? (see Sec. 3.3) and thus is left out.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/wyharveychen/CloserLookFewShot 2 https://github.com/WenbinLee/ADM</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/daviswer/fewshotlocal</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/icoz69/DeepEMD</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://cran.r-project.org/web/packages/HHG/index.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ADM We use the code released by the authors [S-12] 2 . Differently, we add one 1?1 convolution for dimension reduction before computing mean vectors and covariance matrices. As the original method performs unsatisfactorily, we</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Associative alignment for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Afrasiyabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Fran?ois</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Gagn?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 6</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Ishmael</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aristide</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pattern Recognition and Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Meta-baseline: Exploring simple meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy</forename><forename type="middle">A</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distance Covariance Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Cowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Semedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Zandvakili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="242" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guneet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Crosstransformers: spatially-aware few-shot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">MELR: Meta-learning via modeling episode-level relationships for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyi</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<idno>ICLR, 2021. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">3D Object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CogSci</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Finding Task-Relevant Features for Few-Shot Learning by Category Traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Asymmetric distribution measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Revisiting local descriptor based image-to-class measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bilinear convolutional neural networks for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruni</forename><surname>Roy Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1309" to="1322" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Negative margin matters: Understanding margin in few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 6</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esa</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.5151</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Charting the right manifold: Manifold mixup for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nupur</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vineeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balasubramanian</surname></persName>
		</author>
		<idno>WACV, 2020. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Tadam: task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Boris N Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta variance transfer: Learning to augment from the others</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seong-Jin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Won</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Insoo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<editor>Hae Beom Lee, Jae-Joon Han, and Sung Ju Hwang</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Juhwan Song</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Feature selection based on mutual information criteria of maxdependency, max-relevance, and min-redundancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchuan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuhui</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1226" to="1238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Computational optimal transport: With applications to data science. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Peyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Rapid learning or feature reuse? towards understanding the effectiveness of MAML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddh</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>ICLR, 2020. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Delta-encoder: an effective sample synthesis method for few-shot object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivan</forename><surname>Harary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattias</forename><surname>Marder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rog?rio</forename><surname>Schmidt Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Brownian distance covariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>G?bor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">L</forename><surname>Sz?kely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Measuring and testing dependence by correlation of distances. Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>G?bor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">L</forename><surname>Sz?kely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nail</forename><forename type="middle">K</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bakirov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rethinking few-shot image classification: a good embedding is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cross-domain few-shot classification via learned feature-wise transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yu</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08735</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">G2DeNet: Global Gaussian distribution embedding network and its application to visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep CNNs meet global covariance pooling: Better representation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2582" to="2597" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Instance Credibility Inference for Few-Shot Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Few-shot classification with feature map reconstruction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fewshot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Han-Jia Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">DeepEMD: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Power normalizing second-order similarity network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Beyond covariance: SICE and kernel based visual feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianjia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
		<idno>2021. 4</idno>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="300" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">IEPT: Instance-level and episode-level pretext tasks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manli</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<idno>ICLR, 2021. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Binocular mutual learning for improving few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Laplacian regularized few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Imtiaz Masud Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Associative alignment for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Afrasiyabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Fran?ois</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Gagn&amp;apos;e</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>S-1</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">OptNet: Differentiable optimization as a layer in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Crosstransformers: spatially-aware few-shot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Meta-baseline: Exploring simple metalearning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dropblock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Comparison of non-linear (a) and linear (b) relation modeling between classical Correlation (Corr) and Brownian Distance Correlation (BDCorr). This illustration was inspired by</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S-2</forename><surname>Figure</surname></persName>
		</author>
		<editor>D. Boigelot</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A consistent multivariate test of association based on ranks of distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malka</forename><surname>Gorfine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="503" to="510" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">3D Object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Asymmetric distribution measure for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Revisiting local descriptor based image-toclass measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Negative margin matters: Understanding margin in few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Tadam: task dependent adaptive metric for improved fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Boris N Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Rethinking few-shot image classification: a good embedding is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Pietro Perona, and Serge Belongie. The caltech-ucsd birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Few-shot classification with feature map reconstruction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-toset functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Han-Jia Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">DeepEMD: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Binocular mutual learning for improving few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
