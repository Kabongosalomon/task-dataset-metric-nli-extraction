<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ACCEPTED TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Deep CNNs Meet Global Covariance Pooling: Better Representation and Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-08-11">11 Aug 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Qilong</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Wangmeng</forename><forename type="middle">Zuo</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Peihua</forename><surname>Li</surname></persName>
						</author>
						<title level="a" type="main">ACCEPTED TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Deep CNNs Meet Global Covariance Pooling: Better Representation and Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-08-11">11 Aug 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Global covariance pooling</term>
					<term>matrix power normalization</term>
					<term>deep convolutional neural networks</term>
					<term>visual recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Compared with global average pooling in existing deep convolutional neural networks (CNNs), global covariance pooling can capture richer statistics of deep features, having potential for improving representation and generalization abilities of deep CNNs. However, integration of global covariance pooling into deep CNNs brings two challenges: (1) robust covariance estimation given deep features of high dimension and small sample size; (2) appropriate usage of geometry of covariances. To address these challenges, we propose a global Matrix Power Normalized COVariance (MPN-COV) Pooling. Our MPN-COV conforms to a robust covariance estimator, very suitable for scenario of high dimension and small sample size. It can also be regarded as Power-Euclidean metric between covariances, effectively exploiting their geometry. Furthermore, a global Gaussian embedding network is proposed to incorporate first-order statistics into MPN-COV. For fast training of MPN-COV networks, we implement an iterative matrix square root normalization, avoiding GPU unfriendly eigen-decomposition inherent in MPN-COV. Additionally, progressive 1 ? 1 convolutions and group convolution are introduced to compress covariance representations. The proposed methods are highly modular, readily plugged into existing deep CNNs. Extensive experiments are conducted on large-scale object classification, scene categorization, fine-grained visual recognition and texture classification, showing our methods outperform the counterparts and obtain state-of-the-art performance.</p><p>Index Terms-Global covariance pooling, matrix power normalization, deep convolutional neural networks, visual recognition. ? 1. The matrix square root normalization is a special case of MPN-COV where the power is 1/2 that usually performs best among all values of power (Refer to experiments in Sec. 4.2.1).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>D EEP learning methods, particularly deep convolutional neural networks (CNNs), have achieved great success in many computer vision tasks, especially in visual recognition <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. As described in <ref type="bibr" target="#b5">[6]</ref>, deep learning automatically learns composition of multiple transformations that aims to produce abstract representations for predictions, and a good representation is one that can capture distribution of input data and is discriminative as an input of supervised prediction. However, existing deep CNNs often use global average pooling (GAP) to summarize the last convolution features as input of prediction, which captures only first-order statistics, limiting representation and generalization abilities of deep CNNs. To overcome this problem, one possible solution is to replace first-order GAP by some more powerful statistical modeling methods.</p><p>Compared with first-order pooling methods, covariance (second-order) pooling is able to capture richer statistics of features so that it can generate more informative represen- <ref type="bibr">Wang</ref>  tations <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. In the classical, shallow architectures, Tuzel et al. <ref type="bibr" target="#b6">[7]</ref> for the first time utilize covariance matrices for representing regular regions of images. Carreira et al. <ref type="bibr" target="#b7">[8]</ref> present an O 2 P method, where second-order non-central moments are used to model free-form regions of images. Since covariance matrices are symmetric positive definite (SPD) matrices whose space forms a Riemannian manifold, geometric structure should be favorably considered for realizing the full potential. Therefore, affine invariant Riemannian metric (AIRM) <ref type="bibr" target="#b9">[10]</ref> and Log-Euclidean Riemannian metric (LERM) <ref type="bibr" target="#b10">[11]</ref> are respectively employed in <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref> to measure the distances between covariance matrices. In particular, many researches <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> show that covariance representations with hand-crafted features (e.g., SIFT <ref type="bibr" target="#b13">[14]</ref>) significantly outperform first-order counterparts.</p><formula xml:id="formula_0">? Q.</formula><p>In deep architectures, Ionescu et al. propose DeepO 2 P networks <ref type="bibr" target="#b14">[15]</ref> in which second-order pooling is inserted after the last convolution layer of deep CNNs. They establish theory and practice of backpropagation, which enables endto-end learning of CNNs involving non-linear structural matrices. A parallel work is bilinear CNN (B-CNN) <ref type="bibr" target="#b15">[16]</ref> model, which performs outer product pooling of output features of the last convolution layers from two CNNs, producing non-central moments when the two CNNs are identical. Their main difference lies in normalization on SPD matrices obtained by covariance pooling: DeepO 2 P uses matrix logarithm while B-CNN performs element-wise power normalization followed by ? 2 -normalization.</p><p>Although above global covariance pooling (GCP) methods <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> have been studied in deep architectures and report improvement, there exist two challenges that remain unresolved. The first one is robust covariance estimation.  <ref type="bibr" target="#b16">[17]</ref> for robust covariance estimation and Power-Euclidean metric <ref type="bibr" target="#b17">[18]</ref> for usage of geometry of covariance matrices, is inserted after the last convolution layer of a backbone model for summarizing the second-order statistics as inputs of classifier. We further refine MPN-COV from three aspects: firstly, in G 2 DeNet, we combine first-order statistics with covariance matrix by using a Gaussian, identified as matrix square root of an SPD matrix, for further performance improvement; then, an iterative matrix square root normalization (iSQRT-COV) method is developed for fast network training (Speed + +); finally, compact covariance representations are presented to reduce model complexity (Model Complexity --).</p><p>The dimensions of output features of the last convolution layers in deep CNNs usually are very high (e.g., 256 in AlexNet <ref type="bibr" target="#b0">[1]</ref>, 512 in VGG-VD <ref type="bibr" target="#b1">[2]</ref> and 2048 in ResNet <ref type="bibr" target="#b3">[4]</ref>), but the feature number is small <ref type="bibr">(&lt; 200)</ref>. Under such a scenario of high dimension and small sample size (HDSS), it is wellknown that the sample covariance obtained by the classical maximum likelihood estimation (MLE) is not robust <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. Furthermore, recent studies <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref> have shown that robust covariance estimation leads to clear performance improvement in the case of HDSS. The second challenge is how to make favorable use of Riemannian geometry of covariance matrices. DeepO 2 P [15] exploits geometry of covariances using LERM <ref type="bibr" target="#b10">[11]</ref>, but our experiments (Section 4.2.2) show that LERM brings side effect for covariance matrices in the HDSS scenario. B-CNN <ref type="bibr" target="#b15">[16]</ref> simply regards the space of covariances as a Euclidean space, discarding its geometric structure. Furthermore, neither DeepO 2 P <ref type="bibr" target="#b14">[15]</ref> nor B-CNN <ref type="bibr" target="#b15">[16]</ref> is concerned with robust covariance estimation. Therefore, a question naturally arises: Can we overcome above challenges that GCP faces to further improve the representation and generalization abilities of deep CNNs? Inspired by a regularized maximum likelihood estimator (namely vN-MLE) of our previous work <ref type="bibr" target="#b16">[17]</ref> and Power-Euclidean (Power-E) metric <ref type="bibr" target="#b17">[18]</ref>, this paper proposes a global Matrix Power Normalized COVariance (MPN-COV) Pooling to address the above two challenges. As shown in <ref type="bibr" target="#b16">[17]</ref>, vN-MLE performs robustly in the HDSS scenario, superior to most of the robust covariance estimators. The solution of vN-MLE corresponds to shrinkage of eigenvalues of covariance matrices <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and, interestingly, one special solution of vN-MLE is matrix square root (power of 1/2) of sample covariance. On the other hand, Power-E metric <ref type="bibr" target="#b17">[18]</ref>, which computes matrix power of SPD matrices for measuring distances, has been successfully used in medical imaging. Power-E metric has close connection with LERM <ref type="bibr" target="#b10">[11]</ref> and so can approximately measure the Riemannian distance on the space of covariances. As such, our matrix power normalization in the context of deep CNNs amounts to robust covariance estimation while approximately yet effectively exploiting Riemannian geometry of covariances. The statistical and geometrical mechanisms underlying MPN-COV and deep CNNs with MPN-COV (namely MPN-COV-Net) are presented in Section 3.1 and Section 3.2, respectively.</p><p>Although MPN-COV can handle aforementioned challenges, it has several downsides. Firstly, it discards firstorder statistics (mean vector) that is widely used in conventional deep CNNs. In order to integrate first-order information, we use a Gaussian model that accommodates both mean vector and covariance matrix for further performance improvement. We insert the Gaussian, identified as matrix square root of an SPD matrix, into deep CNNs based on Lie group theory <ref type="bibr" target="#b22">[23]</ref>. The resulting network, called G 2 DeNet, is presented in Section 3.3. Secondly, forward propagation (FP) and backward propagation (BP) of both MPN-COV and G 2 DeNet need to compute matrix power that depends on eigen-decomposition (EIG) or singular value decomposition (SVD). However, implementation of EIG/SVD is limitedly supported on CUDA platform, even much slower than their CPU counterparts <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b23">[24]</ref>), resulting in computational bottleneck. Inspired by <ref type="bibr" target="#b23">[24]</ref>, we develop an iterative matrix square root normalized covariance pooling (iSQRT-COV) 1 based on Newton-Schulz iteration <ref type="bibr" target="#b24">[25]</ref> for end-toend learning, where we introduce key pre-normalization and post-compensation for the Newton-Schulz iteration, without which deeper CNNs (e.g., ResNet) fail to converge. The iSQRT-COV, as described in Section 3.4, is very suitable for parallel implementation on GPU, which can significantly speed up training of the networks. Thirdly, the output features of deep CNNs usually are of high dimension, resulting in much larger size of covariance representations that lead to high model complexity. To reduce model complexity without sacrificing performance, in Section 3.5, we propose to exploit progressive 1 ? 1 convolutions and group convolution <ref type="bibr" target="#b25">[26]</ref> to compress covariance representations. All these efforts bring about a unified methodology, in which we not only improve significantly the existing GCP but also achieve fast training speed and affordable model complexity, making our final GCP networks very competitive and appealing.</p><p>The proposed GCP methods can be readily inserted into existing deep CNN architectures in an end-to-end manner. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates deep CNNs with our proposed MPN-COV and improved solutions. Finally, we conduct experiments on a variety of visual recognition tasks, including largescale object classification, scene categorization, fine-grained visual recognition, and texture classification. This paper summarizes and extends our preliminary works <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, and the contributions are summarized as follows:  <ref type="bibr" target="#b30">[31]</ref> and scene categorization on Places365 <ref type="bibr" target="#b31">[32]</ref>, fine-grained visual recognition on Birds-CUB200-2011 <ref type="bibr" target="#b32">[33]</ref>, Aircrafts <ref type="bibr" target="#b33">[34]</ref> and Cars <ref type="bibr" target="#b34">[35]</ref>, texture classification on DTD <ref type="bibr" target="#b35">[36]</ref> and Indoor67 <ref type="bibr" target="#b36">[37]</ref>, and iNaturalist Challenge 2018 held in FGVC5 workshop in conjunction with CVPR 2018. The results with different CNN architectures (e.g., AlexNet <ref type="bibr" target="#b0">[1]</ref>, VGG-VD <ref type="bibr" target="#b1">[2]</ref>, ResNet <ref type="bibr" target="#b3">[4]</ref> and DenseNet <ref type="bibr" target="#b4">[5]</ref>) show the superiority of our GCP networks.</p><formula xml:id="formula_1">-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>This section reviews the related works that improve deep CNNs by integration of trainable sophisticated pooling or encoding methods, which are divided into four categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deep CNNs with Global Second-order Pooling</head><p>Both DeepO 2 P [15] and B-CNN <ref type="bibr" target="#b15">[16]</ref> insert a trainable second-order non-central moment into deep CNNs, where matrix logarithm normalization and element-wise power normalization followed by ? 2 -normalization are performed, respectively. Acharya et al. <ref type="bibr" target="#b37">[38]</ref> explore a manifold network structure of covariance pooling for facial expression recognition, which performs, for input covariance matrix, bilinear mapping for dimension reduction, eigenvalue rectification and matrix logarithm consecutively. In improved B-CNN <ref type="bibr" target="#b23">[24]</ref>, Lin and Maji study the effect of different normalization methods on second-order statistics, finding out matrix square root normalization offers significant improvement over other normalization methods. In particular, they for the first time propose to use Newton-Schulz iteration <ref type="bibr" target="#b24">[25]</ref> for efficient FP while computing accurate gradients by Layapnov equation for BP. While the idea of matrix square root normalization (a special case of MPN with power of 1/2) on GCP in improved B-CNN shares similarity with our MPN-COV <ref type="bibr" target="#b26">[27]</ref>, we provide theoretical explanations on why matrix power normalization works in deep architectures and experiment with large-scale ImageNet. Our iSQRT-COV <ref type="bibr" target="#b28">[29]</ref>, which aims to speed up our MPN-COV, is inspired by improved B-CNN but has clear differences in several respects. First, we develop a meta-layer consisting of pre-normalization, coupled matrix iteration and postcompensation, where pre-normalization (by trace or Frobenius norm) and post-compensation are distinctly important for convergence of deep CNNs (e.g., ResNet-50), and have been not studied in previous works including improved B-CNN. Second, both FP and BP of iSQRT-COV are performed based on Newton-Schulz iteration, which is more efficient than improved B-CNN. Finally, our method outperforms improved B-CNN on both large-scale and small-scale classification, while making first attempt to show GCP can benefit deeper CNNs (e.g., ResNet-50).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep CNNs with Global Approximate High-order Pooling</head><p>In general, high-order pooling methods result in largesize representations. Gao et al. <ref type="bibr" target="#b38">[39]</ref> and Kong et al. <ref type="bibr" target="#b39">[40]</ref> propose compact B-CNN and low-rank B-CNN models to reduce sizes of covariance (second-order) representations, respectively. These methods replace exact covariances by small-size approximation ones, while achieving comparable performance. Based on compact B-CNN model <ref type="bibr" target="#b38">[39]</ref>, Dai et al. <ref type="bibr" target="#b40">[41]</ref> fuse additional first-order (mean) information by simply concatenating them. Kernel pooling <ref type="bibr" target="#b41">[42]</ref> extends the similar idea with the compact B-CNN to approximate higher-order (number of order &gt; 2) pooling. Sharing similar philosophy with <ref type="bibr" target="#b41">[42]</ref>, Cai et al. <ref type="bibr" target="#b42">[43]</ref> obtain small-size higherorder representations based on polynomial kernel approximation and rank-1 tensor decomposition <ref type="bibr" target="#b43">[44]</ref>, namely HI-HCA. Both kernel pooling <ref type="bibr" target="#b41">[42]</ref> and HIHCA <ref type="bibr" target="#b42">[43]</ref> improve compact B-CNN by exploiting higher-order information.</p><p>In <ref type="bibr" target="#b44">[45]</ref>, Yu and Salzmann propose a statistically-motivated second-order (SMSO) pooling, which successively consists of parametric vectorization, an element-wise square-root normalization, and a trainable affine transformation, each of which yields a well-defined distribution of data. SMSO can produce compact second-order representation while achieving state-of-the-art results. However, all above methods consider neither robust estimation nor geometry of manifold, limiting the ability of higher-order statistical modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deep CNNs with Local Second-order Statistics</head><p>In contrary to above works exploring global second-order pooling, some researchers try to incorporate local secondorder statistics into deep CNNs. Among them, Factorized Bilinear (FB) method <ref type="bibr" target="#b45">[46]</ref> introduces an additional parametric quadratic term into linear transformation of convolution or fully-connected (FC) layers. FB can incorporate more complex non-linearity structures into deep CNNs by considering second-order interaction between information flow.</p><p>Second-Order Response Transform (SORT) <ref type="bibr" target="#b46">[47]</ref> proposes to fuse outputs of two-branch block using a second-order term (i.e., element-wise product and a sum operation), in order to increase the nonlinearity of deep CNNs as well. Obviously, these methods also discard robust estimation and geometry of second-order statistics so that they cannot make full use of capacity of second-order pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Deep CNNs with Trainable BoVW Methods</head><p>In the past decades, Bag-of-Visual-Words (BoVW) model is one of the most widely used orderless pooling methods for visual classification. Recently, some works insert high-performance BoVW methods <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b47">[48]</ref> as trainable structural layers into deep CNNs. Thereinto, NetVLAD <ref type="bibr" target="#b48">[49]</ref> implements the modified vector of locally aggregated descriptors (VLAD) <ref type="bibr" target="#b47">[48]</ref> in an end-to-end manner. FisherNet <ref type="bibr" target="#b49">[50]</ref> accomplishes the trainable layer of simplified Fisher vector (FV) <ref type="bibr" target="#b11">[12]</ref>. Unlike FisherNet, Li et al. <ref type="bibr" target="#b50">[51]</ref> propose a MFAFVNet for scene categorization, which performs a deep embedded implementation of mixture of factor analyzers Fisher vector (MFA-FV) method <ref type="bibr" target="#b51">[52]</ref>. Different from these methods, this paper proposes to integrate a global matrix power normalized covariance pooling into deep CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE PROPOSED METHOD</head><p>In this section, we first describe our MPN-COV and the underlying mechanisms, and then instantiate our MPN-COV-Net. Subsequently, we present a global Gaussian embedding network to fuse first-order information, develop an iterative matrix square root normalization method to speed up training of networks, and introduce a compact strategy to reduce size of covariance representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global Matrix Power Normalized COVariance (MPN-COV) Pooling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Computation of MPN-COV</head><p>Let X ? R w?h?d be the outputs of the convolution layer right before computation of MPN-COV, where w, h and d indicate spatial width, height and the number of channels, respectively. Then, the feature tensor X is reshaped to a feature matrix X ? R d?M where M = w ? h. Given the feature matrix X consisting of M samples with d-dimension, its sample covariance is computed as</p><formula xml:id="formula_2">? = XJX T , J = 1 M (I ? 1 M 11 T ),<label>(1)</label></formula><p>where I indicates a M ? M identity matrix, 1 is a Mdimension vector with all elements being one, and T denotes the matrix transpose. Sample covariance ? is a symmetric positive definite or semidefinite matrix, which can be factorized by EIG/SVD:</p><formula xml:id="formula_3">? = U?U T ,<label>(2)</label></formula><p>where ? = diag(? 1 , . . . , ? d ) is a diagonal matrix and ? i , i = 1, . . . , d are eigenvalues arranged in non-increasing order; U = [u 1 , . . . , u d ] is an orthogonal matrix whose column u i is the eigenvector corresponding to ? i . Through EIG or SVD, we can compute matrix power as follows: Here ? &gt; 0 is a scalar and f (? i ) is power of the eigenvalues</p><formula xml:id="formula_4">Z ? = ? ? = Udiag(f (? 1 ), . . . , f (? d ))U T . (3) ( ) COV EIG POW , , l l l l l ??? ? ??? ? ??? ? ? ? ? ? ? ? ? ?? ? ?? ? ?? ? ? ? ? ? ? ? ? ? ? X U Z U Z x</formula><formula xml:id="formula_5">f (? i ) = ? ? i .<label>(4)</label></formula><p>In this paper, the operation in Eq. (3) is called MPN-COV, which is inserted after the last convolution layer of deep CNNs to collect second-order statistics of the output features (i.e., X) as global representations. Next, we describe the mechanisms underlying MPN-COV in terms of robust covariance estimation and usage of geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Robust Covariance Estimation</head><p>Assuming X = [x 1 , . . . , x M ] are sampled from a Gaussian distribution, the covariance ? of X can be estimated by optimizing the following objective function based on MLE:</p><formula xml:id="formula_6">arg min ? log |?| + tr(? ?1 S),<label>(5)</label></formula><p>where S = XJX T is sample covariance, | ? | indicates matrix determinant and tr(?) means trace of matrix. The solution to the MLE (5) is the sample covariance, i.e., ? = S. However, it is well known that MLE is not robust when data is of HDSS <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. This scenario is just what our covariance pooling faces: in most of the existing deep CNNs <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, the output features (i.e., X) of last convolution layer have less than 200 samples of dimension larger than 256, so the sample covariances are always ill-conditioned, rendering robust estimation critical. For robust estimation of covariances in the case of HDSS, the general principle is shrinkage of eigenvalues of the sample covariances for counteracting the ill-conditioning of covariance matrices <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Besides, some researchers propose various regularized MLE methods for robust covariance estimation (see <ref type="bibr" target="#b52">[53]</ref> and references therein). Notably, our MPN-COV closely conforms to the shrinkage principle <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, i.e., shrinking the largest sample eigenvalues and stretching the smallest ones. Moreover, MPN-COV can be deemed as a regularized MLE, namely vN-MLE <ref type="bibr" target="#b16">[17]</ref>:</p><formula xml:id="formula_7">arg min ? log | ?| + tr( ? ?1 S) + ?D vN (I, ?),<label>(6)</label></formula><p>where ? &gt; 0 is a regularizing constant, and D vN (A, B) = tr(A(log(A) ? log(B)) ? A + B) is matrix von-Neumann divergence. Compared with the classical MLE (5) which only includes the first two terms, the objective function of vN-MLE (6) introduces the third term, constraining the estimated covariance ? be similar to the identity matrix I.</p><p>In <ref type="bibr" target="#b16">[17]</ref>, it has been shown that the vN-MLE outperforms other shrinkage methods <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b53">[54]</ref> and regularized MLE method <ref type="bibr" target="#b52">[53]</ref>. Briefly, we have Proposition 1. MPN-COV with ? = 1 2 is the unique solution to the vN-MLE in which ? = 1, i.e.,</p><formula xml:id="formula_8">? 1 2 = arg min ? log | ?| + tr( ? ?1 S) + D vN (I, ?),<label>(7)</label></formula><p>where ? = S.</p><p>Proposition 1 shows our MPN-COV with ? = 1/2 performs robust estimation of covariance, and experiments in Section 4.2.1 show that ? = 1/2 performs best. Details on vN-MLE can be referred to <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Approximate Usage of Geometry</head><p>Since the space of d ? d covariance matrices (denoted by S + d ) forms a Riemannian manifold, geometry should be considered when distances between covariances are measured. There are mainly two kinds of Riemannian metrics, i.e., AIRM <ref type="bibr" target="#b9">[10]</ref> and LREM <ref type="bibr" target="#b10">[11]</ref>. The AIRM is affine-invariant, but it is computationally inefficient and coupled, not scalable to large-scale scenarios. The LERM is a similarity-invariant decoupled metric and efficient to compute, so that it is scalable to large-scale problems. Our MPN-COV can be regarded as matching covariance matrices with the Power-Euclidean (Pow-E) metric <ref type="bibr" target="#b17">[18]</ref>, which has close connection with the LERM, as presented in the following proposition: Proposition 2. For any two covariance matrices ? 1 and ? 2 , the limit of the Pow-E metric d ? (? 1 ,</p><formula xml:id="formula_9">? 2 ) = 1 ? ? ? 1 ? ? ? 2 F as ? &gt; 0 approaches 0 equals the LERM, i.e., lim ??0 d ? (? 1 , ? 2 ) = log(? 1 ) ? log(? 2 ) F .</formula><p>This conclusion was first mentioned in <ref type="bibr" target="#b17">[18]</ref> but without proof. Here we briefly prove this proposition. Note that</p><formula xml:id="formula_10">d ? (? 1 , ? 2 ) = 1 ? (? ? 1 ? I) ? 1 ? (? ? 2 ? I) F . For any covari- ance ? we have 1 ? (? ? ? I) = Udiag( ? ? 1 ?1 ? , . . . , ? ? n ?1</formula><p>? )U T based on its EIG. The identity about the limit in Proposition 2 follows immediately by recalling lim ??0 ? ? ?1 ? = log(?). Hence, the proposed MPN-COV can be viewed as approximately exploiting the Riemannian geometry of S + d . It seems that the LERM is better than the Pow-E metric, since the former computes the true geodesic distance but the latter only measures it approximately. We argue that this is not the case for the scenario of deep CNNs from the perspectives of both numerical stability and distribution of eigenvalues. Detailed discussion is given in Section 4.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global MPN-COV Pooling Network</head><p>We first instantiate a global matrix power normalized covariance pooling neural network (MPN-COV-Net) by inserting our MPN-COV after the last convolution layer of deep CNNs, in place of the common GAP. The diagram of our MPN-COV block is illustrated in <ref type="figure">Fig. 2</ref>. For forward propagation, we first compute the covariance pooling of output features X of the last convolution layer using Eq. (1), then we perform matrix power normalization <ref type="bibr" target="#b2">(3)</ref>. Inspired by the element-wise power normalization technique <ref type="bibr" target="#b11">[12]</ref>, we can further perform, after MPN-COV, normalization by matrix ? 2 ?norm (M-? 2 ) or by matrix Frobenius norm (M-Fro). The matrix ? 2 ?norm (also known as the spectral norm) of a matrix ?, denoted by ? 2 , is defined as the largest singular value of ?, which equals the largest eigenvalue if ? is a covariance matrix. The matrix Frobenius norm of ? can be defined in various ways such as ? F = (tr(? T ?))</p><formula xml:id="formula_11">1 2 = ( i ? 2 i ) 1 2 , where ? i are eigenvalues of ?. Then, we have f (? i ) = ? ? ? ? ? i ? ? 1 for MPN-COV+M-? 2 ? ? i ( k ? 2? k ) 1 2 for MPN-COV+M-Fro<label>(8)</label></formula><p>For backpropagation of MPN-COV block, we need to compute the partial derivative of loss function l with respect to the input X based on the methodology of matrix backpropagation <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b54">[55]</ref>. First of all, given ?l ?Z propagated from top layer, we compute the derivatives ?l ?U and ?l ?? based on the following chain rule:</p><formula xml:id="formula_12">tr ?l ?U T dU + ?l ?? T d? = tr ?l ?Z T dZ ,<label>(9)</label></formula><p>where dZ denotes variation of matrix Z. According to Eq.</p><formula xml:id="formula_13">(3), we have dZ = dUFU T + UdFU T + UFdU T , where F = diag(f (? 1 ), . . . , f (? d )) and dF = diag ?? ??1 1 , . . . , ?? ??1 d d?.</formula><p>After some arrangements, we obtain</p><formula xml:id="formula_14">?l ?U = ?l ?Z + ?l ?Z T UF,<label>(10)</label></formula><formula xml:id="formula_15">?l ?? = ? diag ? ??1 1 , . . . , ? ??1 d U T ?l ?Z U diag ,</formula><p>where (?) diag denotes the matrix diagonalization. For MPN-COV+M-? 2 and MPN-COV+M-Fro, ?l ?? takes respectively the following forms:</p><formula xml:id="formula_16">?l ?? = ? ? ? 1 diag ? ??1 1 , . . . , ? ??1 d U T ?l ?Z U diag (11) ? diag ? ? 1 tr Z ?l ?Z , 0, . . . , 0 and ?l ?? = ? k ? 2? k diag ? ??1 1 , . . . , ? ??1 d U T ?l ?Z U diag ? ? k ? 2? k tr Z ?l ?Z diag ? 2??1 1 , . . . , ? 2??1 d .<label>(12)</label></formula><p>Next, given ?l ?U and ?l ?? , we need to compute ?l ?? associated with Eq. (2), whose corresponding chain rule is tr(( ?l ?? ) T d?) = tr(( ?l ?U ) T dU + ( ?l ?? ) T d?). Note that U is an orthogonal matrix. After some arrangements, we have</p><formula xml:id="formula_17">?l ?? = U K T ? U T ?l ?U + ?l ?? diag U T ,<label>(13)</label></formula><p>where ? denotes matrix Hadamard product.</p><formula xml:id="formula_18">The matrix K = {K ij } where K ij = 1/(? i ? ? j ) if i = j and K ij = 0 otherwise.</formula><p>We refer readers to [55, Proposition 2] for indepth derivation of Eq. (13). Finally, given ?l ?? , we derive the gradient of the loss function with respect to the input feature X, which has</p><formula xml:id="formula_19">?l ?X = ?l ?? + ?l ?? T XJ.<label>(14)</label></formula><p>As described above, by using the formulas of Eq. (3) and Eq. <ref type="formula" target="#formula_2">(14)</ref>, our MPN-COV-Net can be end-to-end trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global Gaussian Embedding Network</head><p>Our MPN-COV can address the two challenges GCP faces, clearly outperforming other competing methods. Nevertheless, it neglects the first-order representation (i.e., mean vector) that is widely used in conventional deep CNNs. Previous researches <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b16">[17]</ref> have shown that combination of first-and second-order statistics is often better than either one single statistics. As is commonly done, we use Gaussians for modeling distributions of features. However, as the space of Gaussians is a manifold, it is challenging to insert a Gaussian into deep CNNs. As such, we propose to use Gaussian embedding method proposed in <ref type="bibr" target="#b22">[23]</ref>. This embedding method equips the space of Gaussians with a Lie group structure, respecting both geometrical and algebraic structures, and meanwhile it identifies a Gaussian as matrix square root of an SPD matrix, suitable for backpropagation while achieving better performance. In Appendix II, we compare with other embedding methods <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b58">[59]</ref>. In the following, we first describe Gaussian embedding method and then present FP and BP of the resulting network (i.e., G 2 DeNet). Gaussian Embedding Let X = [x 1 , . . . , x M ] ? R d?M be a set of deep convolution features, we use Gaussian to model feature distribution as</p><formula xml:id="formula_20">p(x) = 1 (2?) d 2 |?| 1 2 exp ? 1 2 (x ? ?) T ? ?1 (x ? ?) , where ? = 1 M M i=1 x i and ? = 1 M M i=1 (x i ? ?)(x i ? ?)</formula><p>T are mean vector and sample covariance matrix, respectively. Let ? ?1 = LL T be the Cholesky decomposition of the inverse of ?, where L is a lower triangular matrix of order d with positive diagonals. The Gaussian N (?, ?) can be uniquely mapped to a positive definite upper triangular matrices of order d + 1 through the mapping ?:</p><formula xml:id="formula_21">? : N (?, ?) ? ?1 =LL T ? ?????? ? H ?,J ? = J ? 0 T 1 ,<label>(15)</label></formula><p>where</p><formula xml:id="formula_22">J = L ?T and H ?,J ? U T + (d + 1). U T + (d + 1)</formula><p>indicates the set of all positive definite upper triangular matrices of order d + 1. We note that the embedding <ref type="formula" target="#formula_2">(15)</ref> is not suitable for backpropagation due to Cholesky decomposition and matrix inverse. The matrix H ?,J can be further mapped to a unique SPD matrix through a mapping ? based on its matrix polar decomposition H ?,J = S ?,J Q ?,J , i.e.,</p><formula xml:id="formula_23">? : H ?,J H?,J=S?,JQ?,J ??????????? S ?,J ,<label>(16)</label></formula><p>where S ?,J is an SPD matrix and Q ?,J is the closest orthogonal matrix to H ?,J . Through the two consecutive mappings ? and ?, we identify a Gaussian as matrix square root of an SPD matrix:</p><formula xml:id="formula_24">N (?, ?) ??? ??? S ?,J = ? + ?? T ? ? T 1 1 2 .<label>(17)</label></formula><p>We suggest readers refer to <ref type="bibr" target="#b22">[23]</ref> for theoretical details. FP and BP of G 2 DeNet According to the embedding form in Eq. (17), we design global Gaussian embedding block which consists of two layers, i.e., matrix partition layer and square root SPD matrix layer, as shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. Below we first describe the matrix partition layer. We let Y = S 2 ?,J , in which the mean vector ? and covariance matrix ? are obviously entangled. The purpose of this layer is to decouple Y and explicitly write it as the function of input feature matrix X to facilitate computation of the derivatives. We note that there exists the identity ? = 1 M XX T ? ?? T . After some elementary manipulations, we have where A = I 0 T consists of a d ? d identity matrix I and a d?dimensional zero vector 0, b is a (d + 1)?dimensional vector with all elements being zero except the last one which is equal to one, 1 is a M ?dimensional vector with all elements being one, and O is a d ? d zero matrix. The notation</p><formula xml:id="formula_25">Y = 1 M AXX T A T + 2 M AX1b T sym + O 0 0 T 1 (18) Square Root SPD Matrix Layer Matrix Partition Layer X Y Z ?? l Global Gaussian Embedding Block Loss ( ) 1 2 , 1 ? ? T T ? ? + ? ? ? ? ? N ?? ? ? ?</formula><formula xml:id="formula_26">(F) sym = 1 2 F + F T denotes matrix symmetrization. The purpose of Square Root SPD Matrix Layer is to com- pute the matrix square root of SPD matrix Y, i.e., Z = Y 1 2 .</formula><p>Similar to matrix power as described previously, the matrix Z can be computed via EIG/SVD. It is straightforward to know that Y is an SPD matrix, and so it can be factorized as</p><formula xml:id="formula_27">Y = U ? U T ,<label>(19)</label></formula><p>where</p><formula xml:id="formula_28">? = diag( ? 1 , ? ? ? , ? d+1 ) and U = [ u 1 ? ? ? u d+1 ]</formula><p>are the eigenvalues and eigenvectors of Y, respectively. The matrix square root of Y can be computed as:</p><formula xml:id="formula_29">Z = U ? 1 2 U T ,<label>(20)</label></formula><p>where</p><formula xml:id="formula_30">? 1 2 = diag( ? 1 2 1 , ? ? ? , ? 1 2 d+1 )</formula><p>is computed as elementwise square root of the eigenvalues. Combining matrix partition layer <ref type="bibr" target="#b17">(18)</ref> with square root SPD matrix layer <ref type="bibr" target="#b19">(20)</ref>, we can accomplish FP of global Gaussian embedding block.</p><p>Given ?l ?Z propagated from top layer, we perform BP by computing ?l ?Y and ?l ?X associated with square root SPD matrix layer <ref type="bibr" target="#b19">(20)</ref> and matrix partition layer <ref type="bibr" target="#b17">(18)</ref>, respectively. Note that derivation of ?l ?Y shares similar philosophy with that of Eq. (13), and we omit it for simplicity. Given ?l ?Y , we can compute ?l ?X based on Eq. <ref type="formula" target="#formula_2">(18)</ref>, which takes the following form:</p><formula xml:id="formula_31">?l ?X = 2 M A T ?l ?Y sym AX + b1 T .<label>(21)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Iterative Matrix Square Root Normalized Covariance Pooling Network</head><p>In our MPN-COV-Net and G 2 DeNet, computation of matrix square root heavily depends on EIG or SVD. However, fast implementation of EIG or SVD on GPU is still an open problem. To overcome this limitation, inspired by <ref type="bibr" target="#b23">[24]</ref>, we develop a fast training method, which is called iterative matrix square root normalization of covariance (iSQRT-COV) pooling, making use of Newton-Schulz iteration <ref type="bibr" target="#b24">[25]</ref> in both FP and BP. At the core of iSQRT-COV is a metalayer with loop-embedded directed graph structure, which consists of three consecutive structured layers, performing pre-normalization, coupled matrix iteration and postcompensation, respectively. The iSQRT-COV block is illustrated in <ref type="figure" target="#fig_2">Fig. 4</ref>, and the details are described as follows.</p><p>Newton-Schulz Iteration Higham <ref type="bibr" target="#b24">[25]</ref> studied a class of methods for iteratively computing matrix square root. These methods, termed as Newton-Pad? iterations, are developed based on the connection between matrix sign function and matrix square root, together with rational Pad? approximation. Specifically, for computing the matrix square root of A, given Y 0 = A and P 0 = I, for k = 1, ? ? ? , N , the coupled iteration takes the following form [25, Chap. 6.7]:</p><formula xml:id="formula_32">Y k = Y k?1 p lm (P k?1 Y k?1 )q lm (P k?1 Y k?1 ) ?1 P k = p lm (P k?1 Y k?1 )q lm (P k?1 Y k?1 ) ?1 P k?1 ,<label>(22)</label></formula><p>where p lm and q lm are polynomials, and l and m are non-negative integers. According to Eq. <ref type="formula" target="#formula_3">(22)</ref>, Y k and P k quadratically converge to A 1/2 and A ?1/2 , respectively. However, it converges only locally, i.e., it converges if I ? A &lt; 1 where ? denotes any induced (or consistent) matrix norm. The family of coupled iteration is stable in that small errors in the previous iteration will not be amplified. The case of l = 0, m = 1 called Newton-Schulz iteration fits for our purpose as no GPU unfriendly matrix inverse is involved:</p><formula xml:id="formula_33">Y k = 1 2 Y k?1 (3I ? P k?1 Y k?1 ) P k = 1 2 (3I ? P k?1 Y k?1 )P k?1 ,<label>(23)</label></formula><p>where k = 1, . . . , N . Clearly Eq. (23) involves only matrix product, suitable for parallel implementation on GPU. Compared to accurate square root computed by EIG, one can obtain approximate solution with a small number of iterations N , which is determined by cross-validation. Pre-normalization and Post-compensation As Newton-Schulz iteration only converges locally, we pre-normalize covariance ? by its trace or Frobenius norm, i.e.,</p><formula xml:id="formula_34">A = 1 tr(?) ? or 1 ? F ?.<label>(24)</label></formula><p>Let ? i be eigenvalues of ?, arranged in nondecreasing order.</p><p>As tr(?) = i ? i and ? F = i ? 2 i , it is easy to see that I ? A 2 , which equals to the largest singular value of</p><formula xml:id="formula_35">I ? A, is 1 ? ?1 i ?i and 1 ? ?1 ? i ? 2 i</formula><p>for the case of trace and Frobenius norm, respectively, both less than 1. Hence, the convergence condition is satisfied. The above pre-normalization for covariance pooling nontrivially changes the data magnitudes, which produces side effect on network such that the prevalent ResNet <ref type="bibr" target="#b3">[4]</ref> fails to converge. To counteract this adverse influence, after the Newton-Schulz iteration, we accordingly perform postcompensation as follows:</p><formula xml:id="formula_36">Z = tr(?)Y N or Z = ? F Y N .<label>(25)</label></formula><p>Alternatively, one may consider Batch Normalization (BN) <ref type="bibr" target="#b59">[60]</ref>, which does work, successfully helping ResNet convergence. Compared to BN, our post-compensation achieves about 1% lower top-1 error with ResNet-50 architecture on ImageNet (see Section 4.2.1 for details).</p><p>Note that derivation of BP of iSQRT-COV is not straightforward. Despite autograd toolkits provided by some deep learning frameworks can accomplish this task automatically, the involved BP is still in a black box. Meanwhile, autograd sometimes brings uncertainty, e.g., autograd of PyTorch 0.3.0 or below cannot compute gradients of iSQRT-COV correctly. To make iSQRT-COV be self-contained and enable its implementation to be accessible when autograd toolkit is unavailable (e.g., the well-known Caffe and early versions of MatConvNet), we show the gradient of the loss function l with respect to ? and give the derivation details in the Appendix I for conciseness. Specifically, given ?l ?Z , we can compute the gradient for pre-normalization by trace as</p><formula xml:id="formula_37">?l ?? = ? 1 (tr(?)) 2 tr ?l ?A T ? I + 1 tr(?) ?l ?A + 1 2 tr(?) tr ?l ?Z T Y N I.<label>(26)</label></formula><p>If pre-normalization by Frobenius norm is adopted, we have</p><formula xml:id="formula_38">?l ?? = ? 1 ? 3 F tr ?l ?A T ? ? + 1 ? F ?l ?A + 1 2 ? 3/2 F tr ?l ?Z T Y N ?,<label>(27)</label></formula><p>where ?l ?A can be found in Appendix I. Finally, given ?l ?? , the gradient of l with respect to X is given in Eq. (14).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Compact Covariance Representations</head><p>Given an input feature matrix X ? R d?M consisting of M samples with d-dimension, size of covariance representation is d ? (d + 1)/2 after matrix vectorization by considering the symmetry. Taking d = 512 or d = 1024 as an example, the size of covariance representation is 131,328 or 524,800. Such large-size representation leads to high model complexity.</p><p>To deal with this problem, we present a compact strategy for compressing covariance representations, as shown in covariance matrices, while the latter is employed to reduce size of covariance representations after GCP block.</p><p>Since the dimension of input features decides size of covariance representation, we first introduce a strategy of progressive 1 ? 1 convolutions to reduce the dimension of input features. The 1 ? 1 convolution is first introduced in <ref type="bibr" target="#b60">[61]</ref>, and has been widely used in deep CNN architectures <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> for parameter reduction. However, an abrupt dimensionality reduction (e.g., directly from 2080 to 128) may hurt the performance of covariance representations. Therefore, we propose to progressively reduce the dimension of input features from d tod (d ? d) using a set of consecutive</p><formula xml:id="formula_39">1 ? 1 convolutions, i.e., d = d 0 ? d 1 ? ? ? ? ? d K =d with d k?1 &gt; d k .</formula><p>In this way, dimension of covariance representation can be effectively reduced tod ? (d + 1)/2 (e.g., 8256 ford = 128). Compared with dimensionality reduction using only one 1 ? 1 convolution, our progressive convolutions can achieve better performance.</p><p>Once dimension of input is determined, we can further reduce the size of covariance representation by learning a low-dimensional linear transform matrix W on covariance representation z, which corresponds to inserting a FC layer (? = Wz + b) after covariance pooling. The number of parameters of W is d z ? d?, where d z and d? are dimensions of z and?, respectively. If d z is very high, transform matrix W will involve of many parameters, increasing computation and memory costs. Therefore, we introduce group convolution <ref type="bibr" target="#b25">[26]</ref> to alleviate this problem. Different from standard convolution, group convolution divides z into G groups and performs convolution operation in each sub-group. As such, number of parameters of W can be decreased to (d z ?d?)/G, very suitable for large-size covariances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>To evaluate the representation and generalization abilities of the proposed methods, we conduct experiments on both large-scale object classification and scene categorization, small-scale fine-grained visual recognition and texture classification as well as large-scale species classification competition. We first describe implementation details of our methods. Then we make ablation study of the proposed methods on large-scale ImageNet dataset, and compare with state-of-the-art methods on ImageNet <ref type="bibr" target="#b30">[31]</ref> and Places365 <ref type="bibr" target="#b31">[32]</ref>. Additionally, we verify the generalization ability of the proposed methods through transferring them to three fine-grained (i.e., Birds-CUB200-2011 <ref type="bibr" target="#b32">[33]</ref>, Aircrafts <ref type="bibr" target="#b33">[34]</ref> and Cars <ref type="bibr" target="#b34">[35]</ref>) and two texture image datasets (i.e., In-door67 <ref type="bibr" target="#b36">[37]</ref> and DTD <ref type="bibr" target="#b35">[36]</ref>). Finally, we show the results on iNaturalist Challenge 2018 held in CVPR 2018 workshop on FGVC5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>To implement MPN-COV block, we use the EIG algorithm on CPU in single-precision floating-point format, as the EIG algorithm on GPU is much slower, despite the overhead due to data transfer between GPU memory and CPU memory. Since MPN-COV allows non-negative eigenvalues, we truncate to zeros the eigenvalues smaller than eps(? 1 ), which is a matlab function denoting the positive distance from the largest eigenvalue ? 1 to its next larger floating-point number. For achieving the global Gaussian embedding block, as suggested in <ref type="bibr" target="#b14">[15]</ref>, we use SVD to compute square root SPD matrix because SVD is numerically more stable, and SVD algorithm is implemented on CPU as well. Meanwhile, we add a small positive number 1e-3 to the diagonal entries of Gaussian embedded matrices for numerical stability. The implementation of iSQRT-COV block is encapsulated in three computational modules, which accomplish for-ward&amp;backward computation of pre-normalization layer, Newton-Schulz iteration layer and post-compensation layer, respectively. We implement above methods based on the MatConvNet package <ref type="bibr" target="#b29">[30]</ref>; iSQRT-COV-Net is also implemented using Pytorch and TensorFlow.</p><p>The proposed GCP blocks are inserted after the last convolution layer (with ReLU) of deep CNNs. Unless otherwise stated, we discard the last downsampling in the networks so that we have larger number of features, and add one 1 ? 1 convolution with d = 256 channels before our covariance pooling for all CNN architectures but AlexNet. As such, we have w ? h ? 256 feature maps right before covariance pooling, where w and h are width and height of feature maps, obtaining a 256 ? 256 covariance matrix (or 32,896d covariance representation after matrix vectorization). We train our networks using mini-batch stochastic gradient descent algorithm with a momentum of 0.9 and a weight decay of 5 ? 10 ?4 . All programs run on two PCs each of which is equipped with a 4-core Intel i7-4790k@4.0GHz CPU, 32G RAM, 512GB Samsung PRO SSD and two Titan Xp GPUs. The remaining hyper-parameters of training networks will be described where appropriate in following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Large-scale Object Classification on ImageNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Ablation Study</head><p>We first analyze the proposed methods on large-scale Ima-geNet dataset, which contains 1.28M training images, 50K validation images and 100K testing images collected from 1K classes. On this dataset, we follow <ref type="bibr" target="#b1">[2]</ref> for data augmentation, and adopt the commonly used 1-crop or 10-crop prediction for performance evaluation. Following the common settings <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, we report the results on the validation set. Specifically, we study the effect of parameter architecture. Our MPN-COV-Net is trained up to 20 epochs, where the learning rates follow exponential decay, changing from 10 ?1.2 to 10 ?5 with a batch size of 128. <ref type="figure" target="#fig_4">Fig. 6(a)</ref> shows top-1 error vs. ? using single-crop prediction. We first note that the Plain-COV (? = 1, no normalization) produces an error rate of 40.41%, about 1.1% less than the original AlexNet. When ? &lt; 1, the normalization function shrinks eigenvalues larger than 1.0 and stretches those less than 1.0. As ? (less than 1.0) decreases, the error rate continuously gets smaller until the smallest value at around ? = 1 2 . With further decline of ?, however, we observe the error rate grows consistently and soon is larger than that of the Plain-COV. Note that over the interval [0.4, 0.9] the performance of MPN-COV varies insignificantly. When ? &gt; 1, the effect of normalization is contrary, i.e., eigenvalues less than 1.0 are shrunk while those larger than 1.0 are stretched, which is not beneficial for covariance representations as indicated by the consistent growth of the error rates. We note that similar trend of effect of matrix power on classification performance was also reported in <ref type="bibr" target="#b23">[24]</ref>. As such, we set ? = 1 2 throughout the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MPN-COV: Comparison of various normalization methods</head><p>We compare four kinds of normalization methods, i.e., MPN, M-Fro, M-? 2 and element-wise power normalization followed by ? 2 -normalization (E-PN for short) <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref>. <ref type="table" target="#tab_5">Table 2</ref> gives the comparison results, where we can see that all GCP methods except MPN+E-PN outperform the original network, and all normalization methods improve over the plain COV; among them, our MPN obtains the best result, and outperforms M-Fro, M-? 2 and E-PN by ?1.3%, ?1.1% and ?1.3%, respectively. Note that GCP with MPN (i.e., MPN-COV) followed by further normalization, either by M-Fro, M-? 2 or E-PN, produces negative gains, so we do not perform any further normalization on our MPN-COV in following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>iSQRT-COV: Number N of Newton-Schulz iterations</head><p>Here we assess impact of N by employing AlexNet as a backbone model, and using the same hyper-parameters as MPN-COV except the initial learning rate, which is set to 10 ?1.1 . The top-1 error rate (1-crop prediction) vs. N is illustrated in <ref type="figure" target="#fig_4">Fig. 6(b)</ref>. With single one iteration, our iSQRT-COV outperforms Plain-COV by 1.3%. As iteration number grows, the error rate of iSQRT-COV gradually  declines. With 3 iterations, iSQRT-COV is comparable to MPN-COV, having only 0.3% higher error rate, while performing marginally better than MPN-COV between 5 and 7 iterations. The results after N = 7 show growth of iteration number is not helpful for decreasing error. As larger N incurs higher computational cost, we set N to 5 in the remaining experiments for balancing efficiency and effectiveness. The similar trend was also shown in <ref type="bibr" target="#b23">[24]</ref>. An interesting phenomenon is that approximate matrix square root normalization in iSQRT-COV achieves a little gain over the exact one obtained via EIG, which may suggest the fact that matrix square root is not the optimal normalization method for covariance pooling, encouraging development of better normalization methods in the future work. iSQRT-COV: Significance of post-compensation As discussed in Section 3.4, post-compensation in iSQRT-COV helps to eliminate the side effect resulting from prenormalization. We verify its significance with ResNet-50 architecture. <ref type="table" target="#tab_6">Table 3</ref> summarizes impact of different schemes on iSQRT-COV-Net, including simply do nothing (i.e., without post-compensation), Batch Normalization (BN) <ref type="bibr" target="#b59">[60]</ref> and our post-compensation scheme. We note that iSQRT-COV- Net fails to converge without post-compensation. Careful observations show that in this case the gradients are very small (on the order of 10 ?5 ), and larger learning rate helps little. Option of BN helps the network converge, but producing about 1% higher top-1 error rate than our postcompensation scheme. The comparison above suggests that our post-compensation is essential for achieving state-ofthe-art results with deep CNN architectures, e.g., ResNet-50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MPN-COV VS. iSQRT-COV in training speed</head><p>To show acceleration effect of iSQRT-COV, we compare in <ref type="figure" target="#fig_4">Fig. 6(c)</ref> training speed between MPN-COV-Net and iSQRT-COV-Net with both 1-GPU and 2-GPU configurations. For 1-GPU configuration, the speed gap vs. batch size between the two methods keeps nearly constant. For 2-GPU configuration, their speed gap becomes more significant when batch size gets larger. As can be seen, the speed of iSQRT-COV-Net continuously grows with increase of batch size while MPN-COV-Net tends to saturate when batch size is larger than 512. Clearly, by avoiding GPU unfriendly EIG or SVD, iSQRT-COV can speed up MPN-COV and make better use of computing power of multiple GPUs.</p><p>Compact covariance representations In default setting, our methods output a 32k-dimensional covariance representation. In this paper, the strategies of progressive 1 ? 1 convolutions and group convolution <ref type="bibr" target="#b25">[26]</ref> are proposed to further compress covariance representations. We evaluate them using iSQRT-COV with ResNet-50. <ref type="table" target="#tab_7">Table 4</ref> summarizes results of our iSQRT-COV and the extra increased parameters (Params.) with respect to ResNet-50 under various compact settings. Specifically, we use a single 1 ? 1 convolution to decrease dimension of convolution features from 2048 to 256, 128 and 64. Then, progressive dimensionality reduction (DR) is performed based on two consecutive 1 ? 1 convolutions, i.e., 2048 ? 512 ? 256, 2048 ? 512 ? 128 and 2048 ? 256 ? 64. We do not employ more 1?1 convolutions as they will bring additional parameters. Meanwhile, size of covariance representation with 2048 ? 512 ? 128 (4th row) is further reduced to 2K using group convolution of one group, two and four groups, which are indicated by 1G, 2G and 4G, respectively.</p><p>As listed in <ref type="table" target="#tab_7">Table 4</ref>, by using a single 1 ? 1 convolution, the recognition error increases about 1.0% and 1.6% when d decreases from 256 to 128 and 64, respectively. The results of progressive DR versions are better than their counterparts    pre-normalization by trace performs better than Frobenius norm. G 2 DeNet combining mean vector achieves moderate gains over MPN-COV-Net using larger-size representations, and so we mainly report the results of MPN-COV-Net and iSQRT-COV-Net (trace) in following comparisons.</p><p>Why LERM does not work well? DeepO 2 P exploits matrix logarithm normalization (i.e., LERM <ref type="bibr" target="#b10">[11]</ref>) to exploit geometry of covariance, and we claim it is not suitable for deep CNNs. Firstly, the Pow-E metric in MPN-COV improves numerical stability of covariance matrices over LERM. The LERM requires the eigenvalues involved to be strictly positive <ref type="bibr" target="#b10">[11]</ref> while the Pow-E metric allows nonnegative eigenvalues <ref type="bibr" target="#b17">[18]</ref>. For LERM the common method is to add a small positive number ? to eigenvalues for numerical stability. Although ? can be decided by cross-validation, it is difficult to seek the optimal ? suitable for training of deep CNN. For example, <ref type="bibr" target="#b14">[15]</ref> suggest ? = 10 ?3 , which will smooth out eigenvalues less than 10 ?3 . In contrast, the Pow-E metric do not need such a remedy. Furthermore, from the distribution perspective, the matrix logarithm reverses the order of the significance of eigenvalues, harmful for covariance representations. To make a qualitative analysis, we randomly select 300,000 images from training set of Im-ageNet, and estimate per-image sample covariances using the outputs of the last convolution layer in AlexNet model. Then, we compute eigenvalues of all covariances using EIG in single-precision floating-point format. The histogram of eigenvalues is shown in <ref type="figure" target="#fig_5">Fig. 7 (left)</ref>, where zero eigenvalues are excluded for better view. <ref type="figure" target="#fig_5">Fig. 7 (right)</ref> shows the two normalization functions over <ref type="bibr">[10 ?5 , 10]</ref>. We can see log(?) considerably changes the eigenvalue magnitudes, reversing the order of significance of eigenvalues, e.g., a significant eigenvalue ? = 50 ? log(?) ? 3.9 but an insignificant one ? = 10 ?3 ? log(?) ? ?6.9. Since significant eigenvalues are generally more important in that they capture the statistics of principal directions along which the feature variances are larger, matrix logarithm will harm covariance pooling.</p><p>Comparison with deep local second-order networks In <ref type="table" target="#tab_10">Table 6</ref>, we compare our MPN-COV-Net and iSQRT-COV-Net, using ResNet-50 architecture, with deep local second-order networks <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. Clearly, the two networks integrating local second-order statistics improve over the original one. Our MPN-COV-Net and iSQRT-COV-Net employing matrix square root normalization, are superior to FBN <ref type="bibr" target="#b45">[46]</ref> and SORT <ref type="bibr" target="#b46">[47]</ref>. These results demonstrate again the effectiveness of our MPN-COV. Similar to the results with AlexNet, iSQRT-COV-Net outperforms MPN-COV-Net by 0.6% in top-1 error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with various CNN architectures</head><p>In the end of this subsection, we evaluate our MPN-COV with different CNN architectures. Since we modify the existing CNN architectures (as described in Section 4.1), we first compare our MPN-COV with the modified CNN architectures. <ref type="figure" target="#fig_6">Fig. 8(a)</ref> illustrates the results of different networks with 1-crop prediction, from it we can see that our MPN-COV outperforms consistently the corresponding modified CNN architectures by a clear margin. Then, we combine the proposed MPN-COV with five deep CNN models, including AlexNet <ref type="bibr" target="#b0">[1]</ref>, VGG-M <ref type="bibr" target="#b63">[64]</ref>, VGG-VD16 <ref type="bibr" target="#b1">[2]</ref>, ResNet-50 <ref type="bibr" target="#b3">[4]</ref> and ResNet-101 <ref type="bibr" target="#b3">[4]</ref>. Here we compare MPN-COV-Net with the original CNN models and the networks with similar architectures. The top-1 error and top-5 error of different networks with 10-crop prediction are given in <ref type="figure" target="#fig_6">Fig. 8(b)</ref> and <ref type="figure" target="#fig_6">Fig. 8(c)</ref>, respectively. The results of compared methods are duplicated from the original papers.</p><p>Using AlexNet as backbone model, we compare MPN-COV-Net with the original AlexNet and VGG-F <ref type="bibr" target="#b63">[64]</ref>. Our MPN-COV-Net performs much better than both of them. Comparing MPN-COV-Net using VGG-M <ref type="bibr" target="#b63">[64]</ref> with the original one, Zeiler &amp; Fergus <ref type="bibr" target="#b64">[65]</ref> and OverFeat <ref type="bibr" target="#b65">[66]</ref>, our MPN-COV-Net shows much better performance than them. Using VGG-VD16 as backbone model, our MPN-COV-Net outperforms the original VGG-VD16 <ref type="bibr" target="#b1">[2]</ref> by ?2.7% in terms of top-1 error, and performs better than GoogleNet <ref type="bibr" target="#b2">[3]</ref> and PReLU-net B <ref type="bibr" target="#b66">[67]</ref> by ?1.4% and ?0.4% in terms of top-5 error, respectively. For ResNet-50 and ResNet-101 architectures, the results show that our MPN-COV-Net performs 1.65% and 2.04% better than the original ones in terms of top-1 error, respectively. Note that our MPN-COV with ResNet-50 and ResNet-101 outperform the original ResNet-101 and ResNet-152 based on first-order GAP, respectively. We also compare iSQRT-COV-Net, in <ref type="table" target="#tab_10">Table 6</ref>, with the recently proposed SE-Net <ref type="bibr" target="#b61">[62]</ref>, CBAM <ref type="bibr" target="#b62">[63]</ref> using ResNet-50 and ResNet-101 in 1-crop prediction. Our iSQRT-COV-Net consistently improves SE-Net and CBAM. Compared with DenseNet-201 <ref type="bibr" target="#b4">[5]</ref>, our iSQRT-COV-Net obtains ?1.9% gains in top-1 error. Additionally, we make a comprehensive comparison of iSQRT-COV with GAP using ResNets in terms of efficiency and effectiveness, and the corresponding results can be found in Appendix III. These results show our GCP methods can effectively improve CNNs with various architectures with affordable model complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Large-scale Scene Categorization on Places365</head><p>We evaluate our methods on large-scale scene categorization using Places365 dataset <ref type="bibr" target="#b31">[32]</ref>, which contains about 1.8 million training images and 36,500 validation images collected from 365 scene categories. Following the common settings in <ref type="bibr" target="#b31">[32]</ref>, we resize all images to 256 ? 256 and randomly crop a 224 ? 224 image patch or its flip for training. The inference is performed with 10-crop prediction, and we report the results on validation set for comparison. Here we compare our iSQRT-COV-Net, using ResNet-50, with five kinds of CNN models, i.e., GoogleNet <ref type="bibr" target="#b2">[3]</ref>, VGG-VD16 <ref type="bibr" target="#b1">[2]</ref>, ResNet-50 <ref type="bibr" target="#b3">[4]</ref>, ResNet-152 <ref type="bibr" target="#b3">[4]</ref> and B-CNN with ResNet-50. The results of different methods are given in <ref type="table" target="#tab_11">Table 7</ref>, from it we can see that our iSQRT-COV-Net achieves the best results, and outperforms the original ResNet-50 by about 1.2% and 1% in Top-1 and Top-5 errors, respectively. Meanwhile, iSQRT-COV-Net is superior to B-CNN under the same settings. Furthermore, E-PN after our iSQRT-COV block is hurtful in the setting of training from scratch on Places365, which is similar to the results on ImageNet as in <ref type="table" target="#tab_5">Table 2</ref>. The results on both ImageNet and Places365 verify our proposed methods can significantly improve the representation ability of deep CNNs, achieving much lower classification error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experiments on Small-scale Datasets</head><p>In this section, we evaluate our methods on small-scale finegrained visual recognition and texture classification tasks under the setting of fine-tuning, and assess effect of different fine-tuning strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Fine-grained Visual Recognition</head><p>To assess the generalization (transfer) ability of the proposed methods, we pre-train the networks with our GCP on ImageNet and evaluate their performance on fine-grained visual recognition task by fine-tuning. The experiments are conducted on three benchmarks. Among them, Birds-CUB200-2011 <ref type="bibr" target="#b32">[33]</ref> is a challenging dataset, including 11,788 images from 200 bird species. FGVC-aircraft <ref type="bibr" target="#b33">[34]</ref> is a part of the FGComp 2013 challenge, which consists of 10,000 images across 100 aircraft classes. FGVC-Cars <ref type="bibr" target="#b34">[35]</ref> is also presented as a part of the FGComp 2013 challenge, containing 16,185 images from 196 car categories. We employ the fixed training/testing splits provided by the dataset developers, and train or evaluate our networks using neither part annotations nor bounding boxes. For fair comparison, we follow <ref type="bibr" target="#b15">[16]</ref> for experimental setting and evaluation protocol. Specifically, we resize the shorter side of input images to 448, and crop center 448?448 patches. We replace 1000-way softmax layer of our pre-trained networks by a k-way softmax layer, where k is number of classes in the corresponding fine-grained dataset, and fine-tune the networks for 50?100 epochs with a small learning rate lr (e.g., 10 ?2.1 ) for all layers except the last FC layer, which is set to 5 ? lr. The random horizontal flipping is used for data augmentation. After fine-tuning, we perform ? 2 ?normalization on the outputs of our GCP blocks, and feed them to train k one-vs-all linear SVMs with parameter C = 1. We predict the label of a test image by averaging SVM scores of the image and its horizontal flip. <ref type="table" target="#tab_12">Table 8</ref> presents classification results of different methods, where our networks significantly improve the original networks under either VGG-VD16 or ResNet-50. When VGG-VD16 is used as backbone model, our proposed methods are superior to both deep CNNs with trainable BoVW (i.e., NetVLAD <ref type="bibr" target="#b48">[49]</ref> and NetFV <ref type="bibr" target="#b67">[68]</ref>) and deep CNNs with global approximate high-order pooling (i.e., CBP <ref type="bibr" target="#b38">[39]</ref>, LRBP <ref type="bibr" target="#b39">[40]</ref>, KP <ref type="bibr" target="#b41">[42]</ref>, HIHCA <ref type="bibr" target="#b42">[43]</ref> and SMSO <ref type="bibr" target="#b44">[45]</ref>) by a clear margin. Additionally, our MPN-COV-Net and its variants also outperform other deep GCP networks, i.e., B-CNN <ref type="bibr" target="#b15">[16]</ref> and improved B-CNN <ref type="bibr" target="#b23">[24]</ref>. With ResNet-50 architecture, iSQRT-COV-Net (8K) respectively outperforms KP by about 2.6%, 3.8% and 0.6% on Birds, Aircrafts and Cars, while iSQRT-COV-Net (32K) further improves accuracy. On all fine-grained datasets, existing methods employing 50-layer ResNet are no better than their counterparts with 16-layer VGG-VD. The reason may be that the last convolution layer of pre-trained ResNet-50 outputs 2048-dimensional features, much higher than 512-dimensional ones of VGG-VD, which are not suitable for existing second-or higherorder pooling methods. Different from all existing methods, our methods perform dimensionality reduction and deem secondorder pooling as a component of CNN models, pre-trained on large-scale datasets. Using pre-trained iSQRT-COV-Net with ResNet-101, we establish state-of-the-art results on three fine-grained benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Texture Classification</head><p>We also transfer our iSQRT-COV-Net to texture classification, where DTD <ref type="bibr" target="#b35">[36]</ref> and Indoor67 <ref type="bibr" target="#b36">[37]</ref> are employed. Indoor67 has 6,700 images from 67 indoor scene categories, where 80 and 20 images per-category are used for training and test, respectively. DTD consists of 5,640 material images collected from 47 classes, and pre-defined splits in <ref type="bibr" target="#b35">[36]</ref> are used for evaluation. We adopt the same experimental settings with <ref type="bibr" target="#b15">[16]</ref> for fair comparison. The results of different methods are listed in <ref type="table" target="#tab_13">Table 9</ref>, where our iSQRT-COV-Net with VGG-VD16 architecture performs much better than the original model and clearly outperforms other deep secondorder pooling networks, i.e., B-CNN <ref type="bibr" target="#b15">[16]</ref> and FASON <ref type="bibr" target="#b40">[41]</ref>. Meanwhile, our iSQRT-COV-Net is superior to Deep-TEN <ref type="bibr" target="#b68">[69]</ref> and MFAFV-Net <ref type="bibr" target="#b51">[52]</ref> (i.e., deep BoVW methods) using ResNet-50 and VGG-VD16 as backbone models, respectively. Additionally, iSQRT-COV-Net performs better than SMSO <ref type="bibr" target="#b44">[45]</ref> based on both VGG-VD16 and ResNet-50. The results on both FGVC and texture classification demonstrate our GCP methods can significantly improve the generalization (transfer) ability of deep CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Effect of Different Fine-tuning Strategies.</head><p>Additionally, we evaluate how different fine-tuning strategies perform on small-scale datasets using pre-trained models with GAP/GCP on large-scale ImageNet, and whether fine-tuning with E-PN <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref> can further improve our proposed methods. Specifically, we employ standard pretrained networks (i.e., networks with GAP) on ImageNet as backbone models, and replace GAP of the pre-trained models with our iSQRT-COV block while performing finetuning on fine-grained and texture benchmarks; for convenience, this method is called iSQRT-COV (PreTr-GAP). As presented in <ref type="table" target="#tab_3">Table 10</ref>, using both VGG-VD16 and ResNet-50 as backbone models, iSQRT-COV (PreTr-GAP) significantly improves simple fine-tuning of the original GAP-based ones on all benchmarks, indicating that the standard pre-trained networks also can greatly benefit from our GCP (i.e., iSQRT-COV). We also note that iSQRT-COV-Net is superior to iSQRT-COV (PreTr-GAP), which indicates that pre-training the networks with GCP will bring improvement. It also suggests that pre-training the exact models with a largescale dataset performs better than the pre-training on a surrogate model. Furthermore, we train B-CNN with VGG-VD16 and ResNet-50 as backbone models on ImageNet, and the method is called B-CNN (PreTr-GCP); note that we insert a BN layer after ? 2 normalization, otherwise it fails to converge. As compared in <ref type="table" target="#tab_3">Table 10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">iNaturalist Challenge 2018</head><p>As part of the FGVC5 workshop at CVPR 2018, iNaturalist Challenge 2018 is a large-scale species classification competition, which contains over 8,000 species with To efficiently classify a large number of species, we use fast MPN-COV (i.e., iSQRT-COV with 3 iterations), and use a 1?1 convolution with 160 channels before GCP, leading to ?12K dimensional representations, connected to 8142-way softmax classifier. <ref type="table" target="#tab_3">Table 11</ref> gives the results of compared methods, where iSQRT-COV-Net distinctly outperforms the original ResNet-152 in configurations of both different input image sizes and ensemble models. By fusing iSQRT-COV-Net and ResNet-152 models, we positioned the first place, and outperforms the runner-up by ?1.2%. Note that only ensemble of iSQRT-COV-Net models is still better than the runner-up by ?0.8%, showing effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>This paper proposed a global Matrix Power Normalized COVariance (MPN-COV) Pooling methodology for improving the representation and generalization abilities of deep CNNs. Our matrix power normalization can not only estimate robustly covariance matrices but also can properly exploit Riemannian geometry of covariances. To further improve MPN-COV, we proposed a global Gaussian embedding method to integrate additional first-order statistical information, developed an iterative matrix square root normalization method for speeding up training of our covariance pooling networks, and studied a compact covariance representation strategy to reduce model complexity. we will apply the proposed methods to other vision tasks, such as object detection <ref type="bibr" target="#b69">[70]</ref> and semantic segmentation <ref type="bibr" target="#b70">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work was supported by the National Natural Sci- </p><p>BP of Newton-Schulz Iteration Then we compute the partial derivatives with respect to ?l ?Y k and ?l ?P k , k = N ? 1, . . . , 1, given ?l ?YN obtained by Eq. (28) and ?l ?PN = 0. As the matrix ? is symmetric, it is easy to see from equation of Newton-Schulz iteration (i.e., Eq. (23)) that Y k and P k are both symmetric. According to the chain rules (omitted hereafter for simplicity) of matrix backpropagation and after some manipulations, for k = N, . . . , 2, we can derive</p><formula xml:id="formula_41">?l ?Y k?1 = 1 2 ?l ?Y k 3I ? Y k?1 P k?1 ? P k?1 ?l ?P k P k?1 ? P k?1 Y k?1 ?l ?Y k ?l ?P k?1 = 1 2 3I ? Y k?1 P k?1 ?l ?P k ? Y k?1 ?l ?Y k Y k?1 ? ?l ?P k P k?1 Y k?1 .<label>(29)</label></formula><p>The final step of this layer is concerned with the partial derivative with respect to ?l ?A , which is given by  BP of Pre-normalization Note that here we need to combine the gradient of the loss function l with respect to ?, backpropagated from the post-compensation layer. As such, by referring to equation of pre-normalization layer, we make similar derivations as before and obtain</p><formula xml:id="formula_42">?l ?A = 1 2 ?l ?Y 1 3I ? A ? ?l ?P 1 ? A ?l ?Y 1 .<label>(30)</label></formula><formula xml:id="formula_43">?l ?? = ? 1 (tr(?)) 2 tr ?l ?A T ? I + 1 tr(?) ?l ?A + ?l ?? post .<label>(31)</label></formula><p>If we adopt pre-normalization by Frobenius norm, the gradients associated with post-compensation become</p><formula xml:id="formula_44">?l ?Y N = ? F ?l ?Z ?l ?? post = 1 2 ? 3/2 F tr ?l ?Z T Y N ?,<label>(32)</label></formula><p>and that with respect to pre-normalization is</p><formula xml:id="formula_45">?l ?? = ? 1 ? 3 F tr ?l ?A T ? ? + 1 ? F ?l ?A + ?l ?? post ,<label>(33)</label></formula><p>while the backward gradients of Newton-Schulz iteration (29) keep unchanged. Based on above derivations, we can achieve the backpropagation of iSQRT-COV block without autograd toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX II: COMPARISON OF DIFFERENT GAUS-SIAN EMBEDDING METHODS FOR G 2 DENET</head><p>To insert a global Gaussian distribution into deep CNNs, we introduce a Gaussian embedding method studied in <ref type="bibr" target="#b22">[23]</ref> to identify a Gaussian N (?, ?) as a square root SPD matrix (i.e., ?+?? T ? ? T 1 1 2 ). Although many Gaussian embedding methods have been studied, there exist clear differences between ours and them. Specifically, Nakayama et al. <ref type="bibr" target="#b58">[59]</ref> embed Gaussians in a flat manifold by taking an affine coordinate system. In <ref type="bibr" target="#b57">[58]</ref>, Gaussian is mapped to a unique positive definite lower triangular affine transform (PDLTAT) matrix (i.e., L ? 0 T 1 and LL T is the Cholesky decomposition of ?), whose space forms an affine group. Such Gaussian embedding is not suitable for backpropagation due to involvement of Cholesky decomposition of covariance matrix ?. The methods in Calvo et al. <ref type="bibr" target="#b55">[56]</ref> and Lovri'c et al. <ref type="bibr" target="#b56">[57]</ref> respectively embed the space of Gaussian in the Siegel group and the Riemannian symmetric space, identifying a</p><p>Gaussian as a unique SPD matrix, i.e., ? + ?? T ? ? T 1 or</p><formula xml:id="formula_46">C * ? + ?? T ? ? T 1</formula><p>where C is a scalar. After that, <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b72">[73]</ref> employ Log-Euclidean Riemannian metric (LERM) <ref type="bibr" target="#b10">[11]</ref> on the resulting embedding matrix in <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>, which can be presented as log ? + ?? T ? ? T 1 . Different from these methods, our introduced embedding method considers both geometric and algebraic (i.e., Lie group) structures of Gaussian, while achieving better performances. In particular, we compare our G 2 DeNet with various Gaussian embedding methods on Birds-CUB200-2011 dataset using VGG-VG16 as backbone model. The results are given in <ref type="table" target="#tab_3">Table 12</ref>, from it we can see that our introduced embedding method achieves the best performance, outperforming other competing methods by 3% ? 3.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX III: COMPARISON OF ISQRT-COV AND GAP IN TERMS OF EFFICIENCY AND EFFECTIVE-NESS USING RESNETS</head><p>In this section, we compare global average pooling (GAP) and our proposed global covariance pooling (GCP) on largescale ImageNet using ResNet-18, ResNet-34, ResNet-50 and ResNet-101 as backbone models. The evaluation metrics include network parameters, floating point operations per second (FLOPs), inference (FP computation) time per image, memory cost for testing one image and Top-1/Top-5 classification errors, given input images of size 224?224. For our GCP, we use the iSQRT-COV-Net by setting covariance representations to 32k and 8k, respectively. All models are trained with the same experimental settings and run on a workstation equipped with four Titan Xp GPUs, two Intel(R) Xeon Silver 4112 CPUs @ 2.60GHz, 64G RAM and 480 GB INTEL SSD. From the comparison results in <ref type="table" target="#tab_3">Table 13</ref>, we have three observations as follows. (1) Both our iSQRT-COV (32k) and iSQRT-COV (8k) significantly outperform the original first-order GAP under the same CNN architectures.</p><p>In particular, iSQRT-COV (8k) achieves clear gains with affordable computational cost. Specifically, it introduces extra ?7M parameters, ?0.2ms inference time and ?100M memory cost, but decreases about 5.3%, 3.5%, 2.4% and 2.3% Top-1 errors over the original GAP-based ResNet-18, ResNet-34, ResNet-50 and ResNet-101, respectively. (2) When we compare different models that have matching performance, we can see that iSQRT-COV (8k) models show much lower complexity than the corresponding GAP models. For example, ResNet34 + iSQRT-COV (8k) and ResNet50 + iSQRT-COV (8k) are comparable or slightly superior to ResNet101 + GAP and ResNet152 + GAP in performance, respectively, whereas the former ones have much lower complexity than the latter ones. (3) When different models that have similar space and time complexity are compared, it can be seen that iSQRT-COV (8k) models clearly outperform the corresponding GAP models. For example, ResNet18 + iSQRT-COV (8k), ResNet50 + iSQRT-COV (8k) and ResNet101 + iSQRT-COV (8k) have similar (or lower) complexity with ResNet34 + GAP, ResNet101 + GAP and ResNet152 + GAP, but drop 1.8%, 1.3% and 1.7% in terms of Top-1 error, respectively. Above results demonstrate that our iSQRT-COV has better ability to balance efficiency and effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX IV: COMPARISON BETWEEN SVM AND SOFTMAX CLASSIFIERS ON FINE-GRAINED VISUAL CLASSIFICATION TASK</head><p>For the purpose of fair comparison with existing works, we in fact adopt exactly the same experimental settings with <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, where an SVM is trained for classification after fine-tuning models. To assess the effect of classifiers on our method, we provide the results with softmax classifier used at training time, as presented in <ref type="table" target="#tab_3">Table 14</ref>.</p><p>We can see that SVM and softmax classifiers achieve very similar results for our iSQRT-COV-Net, except iSQRT-COV-Net with ResNet-50 on Aircrafts, where softmax classifier is a little better than SVM classifier. The experiments suggest that, for our iSQRT-COV-Net, overall training SVM classifier after fine-tuning with softmax classifier brings negligible benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX V: COMPARISON OF ISQRT-COV AND IMPROVED B-CNN IN TERMS OF MEMORY, SPEED AND ACCURACY</head><p>Here, we compare iSQRT-COV with Improved B-CNN <ref type="bibr" target="#b23">[24]</ref> in term of memory cost, training speed and classification accuracy. Our induces memory overhead as the intermediate tensors in the Newton-Schulz iteration have to be cached for usage in the backpropagation; by contrast, the methods proposed in improved B-CNN <ref type="bibr" target="#b23">[24]</ref> do not involve this memory overhead. We conduct additional experiments to evaluate speed and memory cost of different methods. The improved B-CNN proposed several different fine-tuning methods, including FP and BP both dependent upon SVD, FP by Denman-Beavers iteration or Newton-Schulz (NS) iteration while BP by SVD+Lyapunov (Lyap) equation. We compare with the method that uses NS iteration for FP and SVD+Lyap for BP, which is more efficient among all the proposed methods and allow accurate gradients computation. The authors implement, in their released code, a new method that was not described in their paper, in which gradients can be computed by iterative Lyap solver, avoiding time consuming SVD; we also compare with this method. We make experiments on Birds-CUB200-2011 dataset following the experimental settings of improved B-CNN <ref type="bibr" target="#b23">[24]</ref>. We employ VGG-VD16 as backbone model and set batch-size to 24. To implement improved B-CNN, we use the source code released by the authors. We employ the function 'sqrt newton schulz' for FP by NS iteration, the function 'sqrt svd lyap' for BP by SVD+Lyap, and the function 'lyap newton schulz' for BP by iterative Lyap solver. The experiments run on a PC equipped with a 4-core Intel i7-4790k@4.0GHz CPU, 32G RAM, 512GB Samsung PRO SSD and a single GTX 1080Ti. The results are presented in <ref type="table" target="#tab_3">Table 15</ref>, where iSQRT-COV brings extra memory (i.e., +?) as it needs to cache intermediate tensors. Nevertheless, the percentage of memory overhead with respect to that of the whole networks (ALL) is negligible (&lt;1%). The training  <ref type="bibr" target="#b23">[24]</ref> in terms of memory cost, training speed and classification accuracy (%). Following the experimental settings of Improved B-CNN <ref type="bibr" target="#b23">[24]</ref>, we employ VGG-VD16 as backbone model and set batch-size to 24, while performing fine-tuning on Birds-CUB200-2011 dataset. Here, we give memory taken by GCP layer for the whole mini-batch, percentage of memory overhead due to caching of intermediate tensors (+?) with respect to that of the whole networks (ALL), training speed (Hz) and classification accuracy. T indicates number of iterations. speed of iSQRT-COV is 1.8x faster than improved B-CNN based on NS iteration and SVD+lyap. Note that, as shown in project page of the authors, iterative Lyapunov solver is an approximation algorithm, leading to larger error. Therefore, it requires more iterations for achieving satisfying results. When number of iterations is 5, improved B-CNN based on NS iteration and Lyap iteration has comparable training speed with iSQRT-COV, but iSQRT-COV has higher classification accuracy. More iterations will bring some improvement for improved B-CNN based on NS iteration and Lyap iteration, but it slows down training speed. Overall, iSQRT-COV can make a good balance for memory cost, training speed and classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Overview of global Matrix Power Normalized COVariance (MPN-COV) Pooling networks. The MPN-COV block, inspired by vN-MLE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Diagram of the proposed global Gaussian embedding block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Diagram of the proposed iSQRT-COV block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .Fig. 5 .</head><label>55</label><figDesc>The compact strategy consists of progressive 1 ? 1 convolutions and group convolution. The formers are used to reduce feature dimension right before computation of Diagram of the proposed compact strategy. We propose to combine progressive 1 ? 1 convolutions and group convolution to compress covariance representations, as indicated by red dotted boxes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>? on MPN-COV and compare various normalization methods on GCP, as well as assess impacts of number N of Newton-Schulz iterations and post-compensation on iSQRT-COV, speedup ratio of training iSQRT-COV-Net over MPN-COV-Net, and effect of compact covariance representations. MPN-COV: Effect of parameter ? Our MPN-COV has a key parameter ?, and we evaluate it under AlexNet Ablation studies on ImageNet: (a) Effect of ? on MPN-COV with AlextNet, where Top-1 errors (1-crop prediction) are reported and the bold line indicates the result of original AlexNet; (b) Impact of number N of Newton-Schulz iterations on iSQRT-COV with AlexNet, evaluated with single-crop Top-1 error; (c) Images per second (FP+BP) of network training with AlexNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Illustration of empirical distribution of eigenvalues (left) and normalization functions (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Comparison of classification error with different CNN models. (a) show MPN-COV-Net vs. corresponding modified first-order networks evaluated with single-crop Top-1/Top-5 errors. (b) and (c) show MPN-COV-Net vs. original first-order networks and vs. state-of-the-arts evaluated with ten-crop Top-1 error and Top-5 error, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>, iSQRT-COV clearly outperforms B-CNN under different settings, i.e., iSQRT-COV (PreTr-GAP) and iSQRT-COV-Net are superior to B-CNN and B-CNN (PreTr-GCP), respectively, showing high competitiveness of iSQRT-COV does not solely come from ImageNet pre-training of GCP networks. Finally, we pre-train the networks with iSQRT-COV and perform finetuning with E-PN, and this method is indicated by iSQRT-COV + E-PN. The results of iSQRT-COV-Net vs. iSQRT-COV + E-PN show that E-PN has little effect on our iSQRT-COV under the setting of fine-tuning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>is with Tianjin Key Lab of Machine Learning, the College of Intelligence and Computing, Tianjin University, Tianjin 300350, China and with the School of Information and Communication Engineering, Dalian University of Technology, Liaoning 116024, China. (E-mail: ql-wang@tju.edu.cn) ? J. Xie and P. Li are with the School of Information and Communication Engineering, Dalian University of Technology, Liaoning 116024, China.</figDesc><table /><note>(E-mail: jiangtaoxie@mail.dlut.edu.cn; peihuali@dlut.edu.cn)? W. Zuo is with the School of Computer Science and Technol- ogy, Harbin Institute of Technology, Harbin, 150001, China. (E-mail: cswmzuo@gmail.com)? L. Zhang is with the Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong. (E-mail: cslzhang@comp.polyu.edu.hk)? Peihua Li is the corresponding author. (E-mail: peihuali@dlut.edu.cn)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>We propose a global Matrix Power Normalized COVariance (MPN-COV) pooling for deep CNNs, which can address the challenges of robust covariance estimation and</figDesc><table><row><cell>usage of Riemannian geometry of covariances, further</cell></row><row><cell>improving the representation and generalization abilities</cell></row><row><cell>of deep CNNs.</cell></row><row><cell>-We propose several solutions to overcome the downsides</cell></row><row><cell>of MPN-COV. First, we propose a Gaussian embedding</cell></row><row><cell>network to properly incorporate additional first-order</cell></row><row><cell>information. Then, we implement forward and back-</cell></row><row><cell>ward propagations of MPN-COV with ? = 1/2 based</cell></row><row><cell>on Newton-Schulz iteration for fast training of MPN-</cell></row><row><cell>COV networks. Additionally, a compact strategy of pro-</cell></row><row><cell>gressive 1 ? 1 convolutions and group convolution is introduced to reduce size of covariance representations.</cell></row><row><cell>These solutions as well as MPN-COV constitute our</cell></row><row><cell>matrix power normalization methodology for improving</cell></row><row><cell>deep CNNs.</cell></row></table><note>-The proposed methods are implemented on different deep learning platforms, and the complete code will be released to open source repository. We write C++ code based on NVIDIA cuBLAS and Matlab using MatCon- vNet [30]. Meanwhile, we implement iSQRT-COV using PyTorch and TensorFlow packages.-Extensive evaluations are conducted on various visual recognition tasks, including large-scale object classifi- cation on ImageNet</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Fig. 2. Diagram of the proposed MPN-COV block.</figDesc><table><row><cell>?? ? ?? ?</cell><cell>last conv.</cell><cell>?? ? ?? ?</cell><cell>?</cell><cell>?</cell><cell>?? ? ?? ?</cell><cell>FC layer</cell><cell>?? ? ?? ?</cell></row><row><cell></cell><cell>layer</cell><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>presents the running time of EIG and SVD of a 256 ? 256 covariance matrix. Matlab (M) built-in CPU functions deliver over 10x and 5x speedups over the CUDA counterparts and built-in GPU functions, respectively.</figDesc><table /><note>As such, both our MPN-COV-Net and G 2 DeNet opt for EIG or SVD on CPU for computing matrix square root, greatly restricting the training speed of the networks on GPUs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 1</head><label>1</label><figDesc>Time (ms) taken by matrix decomposition (single precision arithmetic) of a 256 ? 256 covariance matrix.</figDesc><table><row><cell>Algorithm</cell><cell>CUDA cuSOLVER</cell><cell>Matlab (CPU function)</cell><cell>Matlab (GPU function)</cell></row><row><cell>EIG</cell><cell>21.3</cell><cell>1.8</cell><cell>9.8</cell></row><row><cell>SVD</cell><cell>52.2</cell><cell>4.1</cell><cell>11.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 2 Top</head><label>2</label><figDesc></figDesc><table><row><cell cols="6">-1 error (%, 1-crop prediction) of GCP with various normalization</cell></row><row><cell></cell><cell cols="4">methods with AlexNet on ImageNet.</cell><cell></cell></row><row><cell>method</cell><cell>MPN (ours)</cell><cell>M-Fro</cell><cell>M-? 2</cell><cell cols="2">E-PN top-1 Err.</cell></row><row><cell>Baseline</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>41.52</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>40.41</cell></row><row><cell></cell><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>38.51</cell></row><row><cell></cell><cell></cell><cell></cell><cell>?</cell><cell>?</cell><cell>39.93</cell></row><row><cell>GCP</cell><cell></cell><cell>?</cell><cell></cell><cell>?</cell><cell>39.62</cell></row><row><cell></cell><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell>40.75</cell></row><row><cell></cell><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell>39.87</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell></cell><cell>?</cell><cell>39.65</cell></row><row><cell></cell><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>39.89</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="4">Impact of post-compensation on iSQRT-COV with ResNet-50 on</cell></row><row><cell cols="3">ImageNet, evaluated with 1-crop prediction.</cell><cell></cell></row><row><cell>Pre-normalization</cell><cell>Post-compensation</cell><cell>Top-1 Err.</cell><cell>Top-5 Err.</cell></row><row><cell></cell><cell>w/o</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>Trace</cell><cell>w/ BN [60]</cell><cell>23.12</cell><cell>6.60</cell></row><row><cell></cell><cell>w/ Trace</cell><cell>22.14</cell><cell>6.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 4</head><label>4</label><figDesc>Error rate (%, 1-crop prediction) and extra network parameters (Params.) of iSQRT-COV using various compact covariance representations (Repr.) on ImageNet. ResNet-50 is used as backbone model and is compared as baseline.</figDesc><table><row><cell>Method</cell><cell></cell><cell>DR</cell><cell cols="2">Repr. Top-1/Top-5</cell><cell>Params.</cell></row><row><cell>GAP [4]</cell><cell cols="2">N/A</cell><cell>2K</cell><cell>24.7/7.8</cell><cell>25.56M</cell></row><row><cell></cell><cell cols="2">2048 ? 256</cell><cell>32K</cell><cell>22.14/6.22</cell><cell>+30.53M</cell></row><row><cell></cell><cell>2048</cell><cell>512 ??? 256</cell><cell>32K</cell><cell>21.72/5.99</cell><cell>+31.36M</cell></row><row><cell>iSQRT -COV</cell><cell cols="2">2048 ? 128 2048 512 ??? 128 2048 ? 64</cell><cell>8K 8K 2K</cell><cell>22.78/6.43 22.33/6.28 23.73/6.99</cell><cell>+6.26M +7.07M +0.13M</cell></row><row><cell></cell><cell>2048</cell><cell>256 ??? 64</cell><cell>2K</cell><cell>22.98/6.61</cell><cell>+0.54M</cell></row><row><cell></cell><cell cols="2">4th row &amp; 1G</cell><cell>2K</cell><cell>22.40/6.35</cell><cell>+18.9M</cell></row><row><cell></cell><cell cols="2">4th row &amp; 2G</cell><cell>2K</cell><cell>22.84/6.60</cell><cell>+9.6M</cell></row><row><cell></cell><cell cols="2">4th row &amp; 4G</cell><cell>2K</cell><cell>23.11/6.77</cell><cell>+4.3M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 5</head><label>5</label><figDesc>Error rate (%, 1-crop prediction) and time of FP+BP (ms) per image of different covariance pooling methods with AlexNet on ImageNet. Numbers in parentheses indicate FP time. * Following [24], improved B-CNN successively performs matrix square root and E-PN.</figDesc><table><row><cell>Method</cell><cell>Top-1 Err.</cell><cell>Top-5 Err.</cell><cell>Time</cell></row><row><cell>AlexNet [1]</cell><cell>41.8</cell><cell>19.2</cell><cell>1.32 (0.77)</cell></row><row><cell>B-CNN [16]</cell><cell>39.89</cell><cell>18.32</cell><cell>1.92 (0.83)</cell></row><row><cell>DeepO 2 P [15]</cell><cell>42.16</cell><cell>19.62</cell><cell>11.23 (7.04)</cell></row><row><cell>Improved B-CNN  *  [24]</cell><cell>40.75</cell><cell>18.91</cell><cell>15.48 (13.04)</cell></row><row><cell>MPN-COV-Net G 2 DeNet</cell><cell>38.51 38.48</cell><cell>17.60 17.59</cell><cell>3.89 (2.59) 9.86 (5.88)</cell></row><row><cell>iSQRT-COV-Net(Frob.)</cell><cell>38.78</cell><cell>17.67</cell><cell>2.56 (0.81)</cell></row><row><cell>iSQRT-COV-Net(trace)</cell><cell>38.45</cell><cell>17.52</cell><cell>2.55 (0.81)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>DeepO 2 P and improved B-CNN using public available source code released by the respective authors, and try our best to tune hyper-parameters for them. Note that we use the suggested implementation of improved B-CNN in<ref type="bibr" target="#b23">[24]</ref>, i.e., FP by SVD and BP by Lyapunov equation. The results of different methods are listed inTable 5. We can see that our MPN-COV-Net, G 2 DeNet and iSQRT-COV-Net obtain similar results, and clearly outperform B-CNN, DeepO 2 P and improved B-CNN. We owe the gains to matrix power normalization, benefiting robust covariance estima-</figDesc><table><row><cell></cell><cell>45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>error (%)</cell><cell>15 20 25 30 35 40</cell><cell>41.52 38.51</cell><cell>37.07 34.60</cell><cell cols="2">top1-error: modified networks top5-error: modified networks top1-error: MPN-COV-Net top5-error: MPN-COV-Net 24.95 22.73 29.62 26.55</cell><cell>top1-error (%)</cell><cell>40 25 30 35</cell><cell cols="3">top1-error: original networks top1-error: MPN-COV-Net PReLU-B(25.53) overfeat(35.60) VGG-F(39.11) 40.7 ZF(37.5) 24.68 30.39 34.00 33.84 27.41</cell><cell>top5-error (%)</cell><cell>18 16 8 10 12 14</cell><cell>18.2 VGG-F 14.01</cell><cell>(16.77) ZF(16.0) overfeat (14.71) 7.75 9.20 11.43 13.49</cell><cell>top5-error: original networks top5-error: MPN-COV-Net PReLU-B(8.13) GoogLeNet(9.15)</cell></row><row><cell></cell><cell>5 10</cell><cell></cell><cell></cell><cell>10.81 8.94</cell><cell>6.54 7.52</cell><cell></cell><cell>20</cell><cell>22.85 21.20</cell><cell>19.71 21.75</cell><cell>21.43</cell><cell></cell><cell>6</cell><cell>6.71 5.74</cell><cell>5.01 6.05</cell><cell>5.71</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell></row><row><cell></cell><cell></cell><cell cols="12">4% top-1 error with 2K-dimensional representations, still clearly outperforming the original ResNet-50 with first-order GAP. Above results verify the effectiveness of our compact co-variance representations. Our compact strategies can obtain effective small-size representations, very suitable for large scale species classification problem, which will be shown in Section 4.5. 4.2.2 Comparisons with Different Methods Comparison with other deep global GCP methods We compare different variants of MPN-COV with existing deep global GCP methods using AlexNet architecture, including B-CNN [16], DeepO 2 P [15] and improved B-CNN [24]. All methods are trained from scratch on ImageNet. We imple-VGG-M VGG-VD16 ResNet-50 ResNet-101 ResNet-152 AlexNet VGG-M VGG-VD16 ResNet-50 ResNet-101 ResNet-152 ment B-CNN, AlexNet VGG-M VGG-VD16 ResNet-50 AlexNet (a) (b) (c)</cell></row></table><note>based on a single 1 ? 1 convolution, showing the strategy of progressive DR is helpful to preserve classification accuracy for small-size representations. Combining progressive 1 ? 1 convolutions with group convolution, we can obtain 22.tion and proper usage of geometry. The improved B-CNN achieves an unsatisfactory result, which can be regraded as performing element-wise power normalization followed by ? 2 normalization behind our MPN-COV. This result sug- gests that further normalization hurts MPN-COV on large- scale ImageNet classification, which is consistent with the observation in Table 2. Additionally, for iSQRT-COV-Net,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 6</head><label>6</label><figDesc>Comparison of classification error (%, 1-crop prediction) with local second-order networks with ResNet as backbone models on ImageNet.</figDesc><table><row><cell>Method</cell><cell cols="2">Backbone model Top-1 Err.</cell><cell>Top-5 Err.</cell></row><row><cell>ResNet-50 [4]</cell><cell></cell><cell>24.7</cell><cell>7.8</cell></row><row><cell>FBN [46]</cell><cell></cell><cell>24.0</cell><cell>7.1</cell></row><row><cell>SORT [47]</cell><cell></cell><cell>23.82</cell><cell>6.72</cell></row><row><cell>SE-Net [62]</cell><cell>ResNet-50</cell><cell>23.29</cell><cell>6.62</cell></row><row><cell>CBAM [63]</cell><cell></cell><cell>22.66</cell><cell>6.31</cell></row><row><cell>MPN-COV-Net</cell><cell></cell><cell>22.73</cell><cell>6.54</cell></row><row><cell>iSQRT-COV-Net</cell><cell></cell><cell>22.14</cell><cell>6.22</cell></row><row><cell>ResNet-101 [4]</cell><cell></cell><cell>23.6</cell><cell>7.1</cell></row><row><cell>SE-Net [62] CBAM [63]</cell><cell>ResNet-101</cell><cell>22.38 21.51</cell><cell>6.07 5.69</cell></row><row><cell>iSQRT-COV-Net</cell><cell></cell><cell>21.21</cell><cell>5.68</cell></row><row><cell>ResNet-152 [4]</cell><cell>ResNet-152</cell><cell>23.0</cell><cell>6.7</cell></row><row><cell>DenseNet-201 [5] iSQRT-COV-Net</cell><cell>DenseNet-201</cell><cell>22.58 20.69</cell><cell>6.34 5.48</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE 7</head><label>7</label><figDesc>Comparison of classification error (%, 10-crop prediction) on Places365 dataset. B-CNN and iSQRT-COV-Net use ResNet-50 as backbone model.</figDesc><table><row><cell></cell><cell cols="5">VGG-VD16 [2] GoogleNet [3] ResNet-50 [4] ResNet-152 [32] B-CNN</cell><cell>iSQRT-COV-Net</cell><cell>iSQRT-COV + E-PN</cell></row><row><cell>Top-1 Error</cell><cell>44.76</cell><cell>46.37</cell><cell>44.82</cell><cell>45.26</cell><cell>44.24</cell><cell>43.68</cell><cell>45.34</cell></row><row><cell>Top-5 Error</cell><cell>15.09</cell><cell>16.12</cell><cell>14.71</cell><cell>14.92</cell><cell>14.27</cell><cell>13.73</cell><cell>15.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 8</head><label>8</label><figDesc>Comparison of classification accuracy (%) with state-of-the-art methods on fine-grained benchmarks.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="2">Birds Aircrafts</cell><cell>Cars</cell></row><row><cell></cell><cell>VGG-VD16 [16]</cell><cell>70.4</cell><cell>76.6</cell><cell>79.8</cell></row><row><cell></cell><cell>NetVLAD [49]</cell><cell>81.9</cell><cell>81.8</cell><cell>88.6</cell></row><row><cell></cell><cell>NetFV [68]</cell><cell>79.9</cell><cell>79.0</cell><cell>86.2</cell></row><row><cell></cell><cell>B-CNN [16]</cell><cell>84.0</cell><cell>83.9</cell><cell>90.6</cell></row><row><cell>VGG-D16</cell><cell>CBP [39] LRBP [40] KP [42] HIHCA [43] Improved B-CNN [24]</cell><cell>84.3 84.2 86.2 85.3 85.8</cell><cell>84.1 87.3 86.9 88.3 88.5</cell><cell>91.2 90.9 92.4 91.7 92.0</cell></row><row><cell></cell><cell>SMSO [45]</cell><cell>85.01</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell></cell><cell>MPN-COV-Net G 2 DeNet</cell><cell>86.7 87.1</cell><cell>89.9 89.0</cell><cell>92.2 92.5</cell></row><row><cell></cell><cell>iSQRT-COV-Net</cell><cell>87.2</cell><cell>90.0</cell><cell>92.5</cell></row><row><cell>ResNet-50</cell><cell>CBP [39] KP [42] SMSO [45] iSQRT-COV-Net (8K) iSQRT-COV-Net (32K)</cell><cell>81.6 84.7 85.77 87.3 88.1</cell><cell>81.6 85.7 N/A 89.5 90.0</cell><cell>88.6 91.1 N/A 91.7 92.8</cell></row><row><cell cols="2">iSQRT-COV-Net with ResNet-101</cell><cell>88.7</cell><cell>91.4</cell><cell>93.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 9</head><label>9</label><figDesc>Comparison of classification accuracy (%) with state-of-the-art methods on DTD and Indoor67.</figDesc><table><row><cell>Method</cell><cell>Backbone Model</cell><cell>DTD</cell><cell>Indoor67</cell></row><row><cell>VGG-VD16 [41]</cell><cell>VGG-VD16</cell><cell>62.9?0.8</cell><cell>67.6</cell></row><row><cell>B-CNN [16]</cell><cell>VGG-VD16</cell><cell>72.9?0.8</cell><cell>79.0</cell></row><row><cell>FASON [41]</cell><cell>VGG-VD16</cell><cell>72.9?0.7</cell><cell>80.8</cell></row><row><cell>Deep-TEN [69]</cell><cell>ResNet-50</cell><cell>N/A</cell><cell>76.2</cell></row><row><cell>MFAFV-Net [52]</cell><cell>VGG-VD16</cell><cell>N/A</cell><cell>81.1</cell></row><row><cell>SMSO [45]</cell><cell>VGG-VD16 ResNet-50</cell><cell>69.26 72.51</cell><cell>79.45 79.68</cell></row><row><cell>iSQRT-COV-Net</cell><cell>VGG-VD16 ResNet-50</cell><cell>74.0?0.8 74.8?1.0</cell><cell>81.4 83.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 10</head><label>10</label><figDesc></figDesc><table><row><cell cols="7">Classification accuracy (%) of B-CNN and iSQRT-COV with different</cell></row><row><cell cols="7">fine-tuning strategies on Birds (B), Aircrafts (A), Cars (C), DTD (D) and</cell></row><row><cell></cell><cell cols="4">Indoor67 (I) datasets.</cell><cell></cell></row><row><cell></cell><cell>Method</cell><cell>B</cell><cell>A</cell><cell>C</cell><cell>D</cell><cell>I</cell></row><row><cell></cell><cell>VGG-VD16</cell><cell>70.4</cell><cell cols="3">76.6 79.8 62.9?0.8</cell><cell>67.6</cell></row><row><cell></cell><cell>B-CNN</cell><cell>84.0</cell><cell cols="3">83.9 90.6 72.9?0.8</cell><cell>79.0</cell></row><row><cell>VGG-VD16</cell><cell>B-CNN (PreTr-GCP) iSQRT-COV (PreTr-GAP) iSQRT-COV + E-PN</cell><cell>84.7 86.1 87.1</cell><cell cols="3">85.1 91.1 88.9 91.8 73.0?1.0 N/A 90.1 92.7 73.2?0.9</cell><cell>N/A 79.9 81.3</cell></row><row><cell></cell><cell>iSQRT-COV-Net</cell><cell>87.2</cell><cell cols="3">90.0 92.5 74.0?0.8</cell><cell>81.4</cell></row><row><cell></cell><cell>ResNet-50 [42]</cell><cell>78.4</cell><cell cols="2">79.2 84.7</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell></cell><cell>B-CNN</cell><cell>84.4</cell><cell cols="2">85.4 91.4</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>ResNet-50</cell><cell>B-CNN (PreTr-GCP) iSQRT-COV (PreTr-GAP)</cell><cell>85.2 86.7</cell><cell cols="3">86.1 91.5 89.6 92.2 73.4?0.9 N/A</cell><cell>N/A 82.5</cell></row><row><cell></cell><cell>iSQRT-COV + E-PN</cell><cell>88.2</cell><cell cols="3">90.4 93.2 74.6?0.9</cell><cell>82.9</cell></row><row><cell></cell><cell>iSQRT-COV-Net</cell><cell>88.1</cell><cell cols="3">90.0 92.8 74.8?1.0</cell><cell>83.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE 11</head><label>11</label><figDesc></figDesc><table><row><cell cols="3">Classification error (%) of different methods on iNaturalist Challenge</cell></row><row><cell></cell><cell>2018.</cell><cell></cell></row><row><cell>Method</cell><cell>Description</cell><cell>Top-3 Err.</cell></row><row><cell>ResNet-152</cell><cell>320?320 input 392?392 input</cell><cell>16.623 16.024</cell></row><row><cell>iSQRT-COV-Net</cell><cell>320?320 input 392?392 input</cell><cell>15.038 14.704</cell></row><row><cell>Our Fusion I</cell><cell>3 ? ResNet-152 Model</cell><cell>14.625</cell></row><row><cell>Our Fusion II</cell><cell>3 ? iSQRT-COV-Net Model</cell><cell>13.409</cell></row><row><cell>Our Fusion III</cell><cell>Fusion I + Fusion II</cell><cell>13.068</cell></row><row><cell>Runner-up</cell><cell>Deep Learning Analytics</cell><cell>14.214</cell></row><row><cell cols="3">437,513 training, 24,426 validation and 149,394 test images.</cell></row><row><cell cols="3">This dataset suffers from many visually similar species</cell></row><row><cell cols="3">and high class imbalance, which are extremely difficult</cell></row><row><cell cols="3">for accurate classification without expert knowledge. We</cell></row><row><cell cols="3">use ResNet-152 pre-trained on ImageNet-11K as backbone</cell></row><row><cell cols="3">model, and perform fine-tuning on training and validation</cell></row><row><cell cols="3">sets. The top-3 error is reported on test server for compari-</cell></row><row><cell>son.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>ence Foundation of China (Grant No. 61971086, 61806140, U19A2073, 61471082, 61671182 and 61732011). Q. Wang was supported by National Postdoctoral Program for Innovative Talents. The work was done while Q. Wang was a PhD student at the School of Information and Communication Engineering, Dalian University of Technology, China. Given ?l ?Z where l is the loss function, the chain rule is of the form tr ?l</figDesc><table><row><cell cols="6">APPENDIX I: DERIVATIONS FOR BACKPROPAGA-</cell></row><row><cell cols="5">TION OF ISQRT-COV BLOCK</cell></row><row><cell cols="6">Though autograd toolkits provided by some deep learn-</cell></row><row><cell cols="6">ing frameworks can accomplish backpropagation of iSQRT-</cell></row><row><cell cols="6">COV block automatically, their involved BP is still in a black</cell></row><row><cell cols="6">box. Meanwhile, autograd toolkits sometimes bring uncer-</cell></row><row><cell cols="6">tainty, e.g., autograd toolkit of PyTorch 0.3.0 or below cannot</cell></row><row><cell cols="6">compute gradients of iSQRT-COV correctly. To make iSQRT-</cell></row><row><cell cols="6">COV be self-contained and enable its implementation to be</cell></row><row><cell cols="6">accessible when autograd toolkit is unavailable (e.g., the</cell></row><row><cell cols="6">well-known Caffe and early versions of MatConvNet), we</cell></row><row><cell cols="6">derive the gradients associated with the structured layers</cell></row><row><cell cols="6">based on matrix backpropagation methodology [55]. Below</cell></row><row><cell cols="6">we take pre-normalization by trace as an example, deriving</cell></row><row><cell cols="3">the corresponding gradients.</cell><cell></cell><cell></cell></row><row><cell cols="6">T dZ = T d? . After some manipulations, BP of Post-compensation ?Z ?l ?YN T dY N + ?l ?? we have tr</cell></row><row><cell>?l ?Y N</cell><cell cols="2">= tr(?)</cell><cell cols="2">?l ?Z</cell></row><row><cell>?l ?? post</cell><cell>=</cell><cell cols="2">1 2 tr(?)</cell><cell>tr</cell><cell>?l ?Z</cell></row></table><note>T YN I.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>TABLE 12</head><label>12</label><figDesc>Comparison of different Gaussian embedding methods using VGG-VD16 on Birds-CUB200-2011 dataset.Nakayama et al.<ref type="bibr" target="#b58">[59]</ref> z = [ vec(?+?? T ),? T ] T 83.<ref type="bibr" target="#b4">5</ref> Calvo et al.<ref type="bibr" target="#b55">[56]</ref> or Lovri? et al.<ref type="bibr" target="#b56">[57]</ref> [72],<ref type="bibr" target="#b72">[73]</ref> (i.e., Calvo et al.<ref type="bibr" target="#b55">[56]</ref> or Lovri? et al.<ref type="bibr" target="#b56">[57]</ref> + Log-Euclidean<ref type="bibr" target="#b10">[11]</ref>) log ?+?? T ?</figDesc><table><row><cell>Method</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>TABLE 13</head><label>13</label><figDesc>Comparison of our iSQRT-COV and GAP using various ResNets in terms of network parameters, floating point operations per second (FLOPs), inference time per image, memory cost for testing one image and classification error (%, 1-crop prediction), given input images of size 224?224.</figDesc><table><row><cell>Methods</cell><cell>Parameter</cell><cell>GFLOPs.</cell><cell cols="2">Inference time (ms) Memory Cost</cell><cell>Top-1 Err.</cell><cell>Top-5 Err.</cell></row><row><cell>ResNet18 + GAP</cell><cell>11.69M</cell><cell>1.82</cell><cell>0.60</cell><cell>763M</cell><cell>30.24</cell><cell>10.92</cell></row><row><cell>ResNet18 + iSQRT-COV (32k)</cell><cell>44.20M</cell><cell>3.22</cell><cell>0.95</cell><cell>1263M</cell><cell>24.52</cell><cell>7.77</cell></row><row><cell>ResNet18 + iSQRT-COV (8k)</cell><cell>19.49M</cell><cell>3.10</cell><cell>0.85</cell><cell>883M</cell><cell>24.93</cell><cell>7.86</cell></row><row><cell>ResNet34 + GAP</cell><cell>21.80M</cell><cell>3.67</cell><cell>0.88</cell><cell>901M</cell><cell>26.70</cell><cell>8.58</cell></row><row><cell>ResNet34 + iSQRT-COV (32k)</cell><cell>54.31M</cell><cell>5.77</cell><cell>1.15</cell><cell>1407M</cell><cell>22.89</cell><cell>6.64</cell></row><row><cell>ResNet34 + iSQRT-COV (8k)</cell><cell>29.71M</cell><cell>5.56</cell><cell>1.10</cell><cell>1029M</cell><cell>23.20</cell><cell>6.89</cell></row><row><cell>ResNet50 + GAP</cell><cell>25.56M</cell><cell>3.86</cell><cell>1.29</cell><cell>975M</cell><cell>24.70</cell><cell>7.80</cell></row><row><cell>ResNet50 + iSQRT-COV (32k)</cell><cell>56.93M</cell><cell>6.31</cell><cell>1.50</cell><cell>1463M</cell><cell>22.14</cell><cell>6.22</cell></row><row><cell>ResNet50 + iSQRT-COV (8k)</cell><cell>32.32M</cell><cell>6.19</cell><cell>1.49</cell><cell>1085M</cell><cell>22.33</cell><cell>6.28</cell></row><row><cell>ResNet101 + GAP</cell><cell>44.55M</cell><cell>7.57</cell><cell>1.72</cell><cell>1233M</cell><cell>23.60</cell><cell>7.10</cell></row><row><cell>ResNet101 + iSQRT-COV (32k)</cell><cell>75.92M</cell><cell>10.02</cell><cell>1.87</cell><cell>1733M</cell><cell>21.21</cell><cell>5.68</cell></row><row><cell>ResNet101 + iSQRT-COV (8k)</cell><cell>51.31M</cell><cell>9.903</cell><cell>1.83</cell><cell>1355M</cell><cell>21.32</cell><cell>5.70</cell></row><row><cell>ResNet152 + GAP</cell><cell>60.19M</cell><cell>11.28</cell><cell>2.55</cell><cell>1483M</cell><cell>23.00</cell><cell>6.70</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>TABLE 14</head><label>14</label><figDesc>Classification accuracy (%) of iSQRT-COV-Net with the softmax and SVM classifiers on fine-grained visual classification task.</figDesc><table><row><cell></cell><cell>Backbone</cell><cell>Classifier</cell><cell cols="3">Birds Aircrafts Cars</cell></row><row><cell>iSQRT-COV</cell><cell>VGG-D16</cell><cell>SVM softmax</cell><cell>87.2 87.1</cell><cell>90.0 90.0</cell><cell>92.5 92.5</cell></row><row><cell>-Net</cell><cell>ResNet-50</cell><cell>SVM softmax</cell><cell>88.1 88.1</cell><cell>90.0 90.5</cell><cell>92.8 92.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>TABLE 15</head><label>15</label><figDesc>Comparison of iSQRT-COV and Improved B-CNN</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Region covariance: A fast descriptor for detection and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Freeform region description with second-order pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1177" to="1189" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards effective codebookless model for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="63" to="71" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Riemannian framework for tensor computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="66" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast and simple calculus on tensors in the Log-Euclidean framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image classification with the Fisher vector: Theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="222" to="245" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Higher-order occurrence pooling for bags-of-words: Visual concept detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="326" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Matrix backpropagation for deep networks with structured layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vantzos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bilinear CNN models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RAID-G: Robust estimation of approximate infinite dimensional Gaussian with application to material recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Non-Euclidean statistics for covariance matrices, with applications to diffusion tensor imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koloydenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shrinkage estimators for covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1173" to="1184" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Optimal shrinkage of eigenvalues in the spiked covariance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gavish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
		<idno>1311.0851</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lectures on the theory of estimation of many parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Soviet Mathematics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1373" to="1403" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A well-conditioned estimator for largedimensional covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ledoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="365" to="411" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Local Log-Euclidean multivariate Gaussian descriptor and its application to image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="803" to="817" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved bilinear pooling with CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Functions of Matrices: Theory and Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Higham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Society for Industrial and Applied Mathematics</title>
		<meeting><address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Is second-order information helpful for large-scale visual recognition?&quot; in ICCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">G 2 DeNet: Global Gaussian distribution embedding network and its application to visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards faster training of global covariance pooling networks by iterative matrix square root normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Matconvnet -convolutional neural networks for MATLAB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM on Multimedia</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ima-geNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1452" to="1464" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Finegrained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">3D object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on 3D Representation and Recognition, ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Recognizing indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Covariance pooling for facial expression recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Pani</forename><surname>Paudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops on Diff-CVML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Compact bilinear pooling,&quot; in CVPR</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Low-rank bilinear pooling for finegrained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FASON: First and second order information fusion network for texture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue-Hei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Kernel pooling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Higher-order integration of hierarchical convolutional activations for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Statistically-motivated second-order pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<biblScope unit="page" from="621" to="637" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Factorized bilinear models for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">SORT: Second-order response transform for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Aggregating local image descriptors into compact codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1704" to="1716" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">NetVLAD: CNN architecture for weakly supervised place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gronat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Deep FisherNet for object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<idno>abs/1608.00182</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep scene image classification with the MFAFVNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Object based scene representations using fisher scores of local subspace projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2811" to="2819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Elementary estimators for sparse covariance matrices and other structured moments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Shrinkage algorithms for MMSE covariance estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wiesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Eldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Hero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TSP</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5016" to="5029" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Training deep networks with structured layers by matrix backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vantzos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<idno>abs/1509.07838</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A distance between multivariate normal distributions based on an embedding into the Siegel group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Oller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMVA</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="242" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multivariate normal distributions parametrized as a Riemannian symmetric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lovric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Min-Oo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ruh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMVA</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="48" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Shape of Gaussians as feature descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Global Gaussian approach for scene categorization using information geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">CBAM: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y.</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Overfeat: Integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Le-Cun</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Bilinear convolutional neural networks for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Roy</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1309" to="1322" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep TEN: Texture encoding network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Dana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="640" to="651" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A novel earth mover&apos;s distance methodology for image matching with gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1689" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Geometry-aware similarity learning on SPD manifolds for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Techn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2513" to="2523" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
