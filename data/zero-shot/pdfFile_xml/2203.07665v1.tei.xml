<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">One Agent To Rule Them All: Towards Multi-agent Conversational AI</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clarke</surname></persName>
							<email>csclarke@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Peper</surname></persName>
							<email>jpeper@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Krishnamurthy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Ford Motor Company</orgName>
								<address>
									<settlement>Dearborn</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Talamonti</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Ford Motor Company</orgName>
								<address>
									<settlement>Dearborn</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Leach</surname></persName>
							<email>kevin.leach@vanderbilt.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<region>TN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Lasecki</surname></persName>
							<email>wslasecki@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Kang</surname></persName>
							<email>ypkang@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Tang</surname></persName>
							<email>lingjia@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mars</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">One Agent To Rule Them All: Towards Multi-agent Conversational AI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The increasing volume of commercially available conversational agents (CAs) on the market has resulted in users being burdened with learning and adopting multiple agents to accomplish their tasks. Though prior work has explored supporting a multitude of domains within the design of a single agent, the interaction experience suffers due to the large action space of desired capabilities. To address these problems, we introduce a new task BBAI: Black-Box Agent Integration, focusing on combining the capabilities of multiple black-box CAs at scale. We explore two techniques: question agent pairing and question response pairing aimed at resolving this task. Leveraging these techniques, we design One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs. Additionally, we introduce MARS: Multi Agent Response Selection, a new encoder model for question response pairing that jointly encodes user question and agent response pairs. We demonstrate that OFA is able to automatically and accurately integrate an ensemble of commercially available CAs spanning disparate domains. Specifically, using the MARS encoder we achieve the highest accuracy on our BBAI task, outperforming strong baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Influenced by the popularity of intelligent conversational agents (CAs), such as Apple Siri and Amazon Alexa, the conversational AI market is growing at an increasingly rapid pace and is projected to reach a valuation of US $13.9 billion by 2025 <ref type="bibr">(Market and Markets, 2020)</ref>. These CAs have already begun to show great promise when deployed in domain-specific areas such as driver assistance <ref type="bibr" target="#b14">(Lin et al., 2018)</ref>, home automation <ref type="bibr" target="#b16">(Luria et al., 2017)</ref>, and food ordering <ref type="bibr" target="#b9">(Frangoul, 2018)</ref> with platforms * Work was done while at University of Michigan <ref type="figure">Figure 1</ref>: An example interaction using One For All which integrates multiple production black-box agents into a unified experience. such as Pandora and Facebook today hosting more than 300,000 of these agents <ref type="bibr" target="#b4">(Chaves and Gerosa, 2018;</ref><ref type="bibr" target="#b18">Nealon, 2018)</ref>.</p><p>Most CAs are designed to be specialized in a single or set of specific domains. As such, users are required to interact with multiple agents in order to complete their tasks and answer their queries as shown in figure 1. For example, a user may use an agent such as Amazon Alexa for online shopping but engage with Google Assistant for daily news updates. Additionally, a given agent may be more proficient at a specific domain over another i.e A finance CA is better suited to answer finance questions. As a result, users are taxed with the burden of learning and adopting multiple agents leading to an increase in the cognitive load of interacting with agents, further discouraging the proliferation of their usage <ref type="bibr" target="#b8">(Dubiel et al., 2020;</ref><ref type="bibr" target="#b19">Novick et al., 2018;</ref><ref type="bibr" target="#b22">Saltsman et al., 2019)</ref>. This is escalated further as the number of conversational agents deployed into the market continues to increase. Therefore, the need arises for unifying multiple independent CAs through one conversational interface. This need has manifested in the commercial conversational AI industry with initiatives such as the Amazon Voice Interoperability Initiative <ref type="bibr" target="#b0">(Amazon, 2019)</ref> which aims to create voice-enabled products that contain multiple, distinct, interoperable intelligent assistants on a single device. However, this interaction is still manual, requiring the user to orchestrate which agent is initiated. In addition, while it is possible to have distinct agents in a single device, users prefer interacting with a single agent over multiple <ref type="bibr" target="#b4">(Chaves and Gerosa, 2018)</ref>.</p><p>Prior work has explored in part combining the strengths of multiple agents in one system but they rely on direct access to the design and implementation details of the to-be-integrated agents. <ref type="bibr" target="#b24">Subramaniam et al. (2018)</ref> and Cercas <ref type="bibr" target="#b3">Curry et al. (2018)</ref> direct incoming user questions to a specific agent based on the candidate agents' internal knowledge graph and NLU architectures, respectively. However, in practice, the majority of the publicly available CAs are "black boxes" where their inner-workings contain highly-protected IP that is not accessible to the public. Additionally, Cercas <ref type="bibr" target="#b3">Curry et al. (2018)</ref> facilitates their bot selection with a manual heuristic preference order that requires intimate knowledge of the agents to construct, and additional effort to maintain, thus not scaling well for the adaption of existing agents and introduction of new agents. Therefore, the task of integrating multiple production black-box CAs with a unified interface remains an open problem.</p><p>In order to explore this problem, we introduce the task BBAI: Black-Box Agent Integration that focuses on integrating multiple black-boxes CAs. We propose two techniques to tackle black-box multi-agent integration: (1) Question agent pairing and (2) Question response pairing. Intuitively, these two approaches can be viewed as a queryto-agent classification problem in contrast to that of a response selection problem. This formulation allows us to facilitate multi-agent integration whilst operating within the black-box constraints of the agents. Using these techniques we develop One For All, a novel conversational system that accurately and automatically unifies a set of black-box CAs spanning disparate domains. Additionally, we introduce MARS: Multi Agent Response Selection, a new encoder model for question response pairing that jointly encodes user question and agent response pairs. We evaluate these techniques on a suite of 19 publicly available agents consisting of Amazon Alexa 1 , Google Assistant 2 , SoundHound Houndify 3 , Ford Adasa <ref type="bibr" target="#b14">(Lin et al., 2018</ref>) and many more. 1 https://developer.amazon.com/en-US/ alexa 2 https://assistant.google.com/ 3 https://www.houndify.com/ Specifically, this paper makes the following contributions:</p><p>? Formulation of the BBAI task that focuses on the challenge of integrating disparate blackbox conversational agents into one experience. We construct a new dataset for this task, comprising of examples from a suite of 19 commercially deployed conversational agents. We publish our model and datasets. 4</p><p>? We design One For All, a novel conversational system that accurately and automatically unifies a set of black-box CAs and introduce the MARS encoder model that outperforms strong state-of-art classification and ranking model baselines on our BBAI task.</p><p>? We conduct a thorough evaluation of various agent integration approaches showing that our MARS encoder outperforms strong baselines. We show that by facilitating the integration of multiple agents we can alleviate the need for users to adopt multiple agents whilst facilitating the improvement and growth of agents over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BBAI: Black-Box Agent Integration Task Formulation</head><p>Building a unified interface for production agents spanning different domains presents several key challenges. First, most commercially available CAs are black-boxes, providing little to no information on their inner workings. Any approach for agent integration must operate without relying on the internals of any given agent. Second, these conversational agents are constantly improved upon and expanded with new capabilities. The agent integration approaches need to be flexible and adaptive to these changes with relative ease. Given these constraints we assume the existence of the following information sources for the agent integration task:</p><p>1. User query/utterance: The question that the user asks the agent.</p><p>2. Agent skill representation: A textual representation that denotes what each agent is capable of. This can be in the form of example queries or a description of that agent. <ref type="figure">Figure 2</ref>: Overview of our proposed black-box agent integration techniques. In QA Pairing, the goal is to select the correct agent using information about the agent's capabilities. In QR Pairing, the goal is to select the correct agent response.</p><p>3. Agent response: Each agent's response to the query asked.</p><p>Using this information we formulate the task of agent integration as given a query Q, a set of agents A = {a 1 , a 2 , . . . , a n } and a set of agent responses R = {r 1 , r 2 , ..., r n } to query Q, determine the question-agent-response pair (Q, A i , R i ) that resolves the query Q. Further, given the information available, we can taxonomize our approach into two techniques: (1) Question agent pairing where we preemptively select the agent for the query and (2) Question response pairing where we evaluate the set of returned responses as depicted in <ref type="figure">Figure  2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question Agent Pairing</head><p>As shown in <ref type="figure">Figure 2</ref>, the goal of question agent pairing is, given a query Q and a set of agents A = {a 1 , a 2 , . . . , a n }, determine the questionagent pair (Q, A i ) that resolves the query Q. At its core, this can be viewed as a classification problem where the model learns the respective capabilities of each independent agent in order to predict which agent to use for a given question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question Response Pairing</head><p>As shown in <ref type="figure">Figure 2</ref>, the goal of question response pairing is, given a query Q and a set of agent responses R = {r 1 , r 2 , ..., r n }, determine the question-response pair (Q, R i ) such that R i resolves the query Q. <ref type="figure">Figure 3</ref>: The transformer-based classification models in the OFA system. The models are trained on question agent pairs and tasked to predict an agent to route the given query to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The One For All System</head><p>In this section, we present the design of One For All (OFA), a scalable system that integrates multiple black-box CAs with a unified interface. We explain the various approaches implemented in One For All, detailing their inputs, outputs and training methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Question Agent Pairing</head><p>In order to predict the best agent for a given query, knowledge of each agent's individual skill-set is required. However, as described in the task formulation in Section 2, the internal details of the agents are unavailable. Everyday users of these agents have no insight into the internal specifics of these agents. However, they are able to use these agents to accomplish tasks by building a mental model of each agents' respective capabilities through usage over time. We draw inspiration from this to determine the information we can use to represent an agent's skills without access to its internals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Agent Skills Representation</head><p>Following the learning patterns described above, we model an agent's skill-set in two distinct ways:</p><p>(1) Query examples: Similar to building knowledge overtime via agent interaction, an agents' <ref type="figure">Figure 4</ref>: Overview of OFA approaches. (a) Bi-Encoder which is used for both QA and QR pairing encodes the question and candidate response/description separately and computes a ranking score via a dot product calculation. (b) Our MARS encoder jointly encodes the question and response into a single transformer and performs selfattention between the question and candidate response. To score a response we reduce the candidate embedding from a vector to a scalar score between 0...1 <ref type="bibr" target="#b11">(Humeau et al., 2020).</ref> query examples allows the model to learn what type of queries each agent is capable of resolving. For example, questions such as "Where is the nearest gas station?" and "Direct me to Starbucks please" will be amongst the query examples for a "Directions" agent.</p><p>(2) Agent descriptions:. These are textual summaries of an agent's capabilities. For example, a bank releases a new CA for its customers to use instead of having to visit the bank. Accompanied with this agent will be a semi-formal description of what this agent is capable of doing. This information is often publicly available in the agent's marketing materials.</p><p>Using these query examples and agent descriptions, we explore approaches for determining the agent best to resolve a given query. We describe in more detail the dataset collection process in Section 4.</p><p>Question agent pairing using query examples QA pairing using query examples seeks to explore how best we can facilitate agent orchestration in a data constrained environment where only a few examples of the questions the agents can answer are present. This is similar to the use of text examples for the training of an intent classifier but at the agent level instead. Therefore, we treat this as a multilabel classification problem where a given query Q is mapped to a set of agents A. e.g Q: 'locate me some good places in Kentucky that serve sushi' maps to the set of agents A: ["Alexa", "Google"] indicating that this query can be correctly answered by the agents Alexa and Google. Specifically, as shown in <ref type="figure">Figure 3</ref>, we build a multi-label classifier on top of state-of-the-art transformer models, BERT <ref type="bibr" target="#b7">(Devlin et al., 2019)</ref>, RoBerta <ref type="bibr" target="#b15">(Liu et al., 2019)</ref> and Electra <ref type="bibr" target="#b5">(Clark et al., 2020)</ref> to predict an agent A given a query Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question agent pairing using agent descriptions</head><p>While query examples are useful for understanding the capabilities of a given agent, they may not be readily available. When a new agent is introduced, users are unsure of the exact questions this agent can answer but they would typically have access to an explanation of its capabilities. As an alternative, we explore the use of such a description of the agents. For this task, we assume a textual description of an agent's capabilities, e.g. "Our productivity bot helps you stay productive and organized. From sleep timers and alarms to reminders, calendar management, and email ....".</p><p>In order to map a given query Q to an agent A described by description D i , we treat this as a semantic similarity task. The intuition behind this is that for a given query Q the agent that is capable of answering a given question is likely to feature an agent description semantically similar to the question. We explore a suite of pre-trained and finetuned language models focusing on ranking the relevance of given description D i to a query Q. Ad-ditionally, given the length of descriptions and the range of capabilities that may be described within a single description, we split the full description at the sentence level and use each sentence to represent a single skill S i belonging to agent A. With this variation, the question-description similarity score is calculated as the max i SemSim(Q, S i ).</p><p>For our BBAI task we consider the following state-of-art semantic retrieval-based approaches whose utility map well to our problem domain:</p><p>BM25 This classic method measures keyword similarity and uses it to estimate the relevance of documents to a given search query <ref type="bibr" target="#b21">(Robertson and Zaragoza, 2009</ref>). We encode the collection of agent descriptions and return the agent whose description is most relevant to the given query.</p><p>Universal Sentence Encoder <ref type="bibr" target="#b2">(Cer et al., 2018)</ref> A sentence encoding model for encoding sentences into high dimensional vectors. We use the transformer model 5 for our experiment. As shown in part (a) of <ref type="figure">Figure 4</ref>, we encode the user query and the agent description and compute the dot product as a ranking score.</p><p>Roberta + STS <ref type="bibr" target="#b20">(Reimers and Gurevych, 2019)</ref> We fine-tune Roberta-base on the STS benchmark dataset and use this model to encode our agent descriptions and user query. We compute the cosine similarity between the two vectors to compute a ranking score for each description as shown in <ref type="figure">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question Response Pairing</head><p>Contrary to question agent pairing which selects the agent beforehand, question response pairing assumes that we provide each agent in the ensemble the opportunity to respond to the query Q and focus on selecting the best response from the set of returned responses. As such, we treat this as a response ranking problem of determining which question-response pair (Q, R i ) best answers the query Q. Prior work has shown strong performance on sentence pairing tasks such as this through the use of sentence encoders and language model fine-tuning <ref type="bibr" target="#b10">(Henderson et al., 2019;</ref><ref type="bibr" target="#b11">Humeau et al., 2020;</ref><ref type="bibr" target="#b20">Reimers and Gurevych, 2019)</ref>. We explore the use of these architectures in the domain of response selection with the goal of learning rep-5 https://tfhub.dev/google/ universal-sentence-encoder/4 resentations for correct question answering from diverse conversational agents.</p><p>BM25 Similar to our use of BM25 for question agent pairing we use it to rank each of our question response pairs. USE and USE QA <ref type="bibr">(Yang et al., 2019)</ref> We apply the USE model from our agent pairing task to rank agent responses. In addition, we consider USE QA, an extended version of the USE architecture specifically designed for question-answer retrieval applications. We use the Bi-Encoder architecture as shown in <ref type="figure">Figure 4 (a)</ref>.</p><p>Roberta + STS We fine-tune Roberta-base on the STS benchmark dataset and use it to encode our question response pairs using the bi-encoder architecture in <ref type="figure">figure 4</ref>.</p><p>MARS encoder Pre-existing sentence pairing scoring models are tuned to score sentence pairs deemed semantically similar. However, in the case of conversational systems, an agent's response can be semantically similar but still incorrect. e.g Q: "What is the weather in Santa Clara today?", R: "Weather information is currently unavailable". These two sentences are semantically similar but the response does not resolve the query. In the MARS encoder, we focus on learning representation beyond similarity by also incorporating the correctness of agent responses. Using the crossencoder architecture <ref type="bibr" target="#b11">(Humeau et al., 2020;</ref><ref type="bibr" target="#b20">Reimers and Gurevych, 2019)</ref> shown in part (b) of <ref type="figure">Figure  4</ref>, we train a question response pair scoring model for the task of ranking responses to a given query Q generated by conversational agents. We concatenate both the input question and response performing full self-attention on the entire input sequence. By passing both the question and agent response through a single transformer, the agent response is able to attend to the user query and produce a more input sensitive representation of the question response embedding. Using the generated question response embedding vector we then convert it to a scalar score S(Q, R i ) between 0..1 via a linear layer. Our training objective is to minimize the Cross-Entropy loss between the correct agent responses and the negative agent responses to the query Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agent Response Alexa</head><p>Google Houndify Adasa At how many miles will I run out of gas "here's something I found on the web according to freakonomics.com previously when cars got 8 to 12 miles ...." "on the website post Dash gazette.com they say some popular car models can make it between 30 and 50 miles ....", Didn't get that! "With your current fuel economy of 28 MPG, you should be able to cover about 532 miles with the fuel you have." Is it gonna be warm Friday in Alhambra? "here's something I found on the web according to Wikipedia. Org Cobra is one of the 100 selected cities in India which will be developed ...." "No, it won't be hot Friday in Alhambra, California. Expect a high of 21 and a low of 6.", "There will be a high of seventy degrees in Alhambra on Friday November twenty-seventh." "Out of scope!" </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset Construction</head><p>For the task of BBAI, we construct a new dataset focusing on making it representative of real-world conversational agents at scale and covering a broad range of domains.</p><p>Using Amazon Mechanical Turk and scenario/paraphrasing-based prompts <ref type="bibr" target="#b12">(Kang et al., 2018;</ref><ref type="bibr" target="#b13">Larson et al., 2019)</ref>, we crowdsourced utterances across a range of agent skills/capabilities. These skills were extracted from public information sources describing each of the agents, in addition to observing their capabilities. Our dataset is comprised of utterances across 37 broad domain categories. These include domains such as Weather, Flight Information, Directions, Automobile, etc. Crowd workers were paid $0.12 for 5 utterances. These submitted utterances were then vetted by hand to ensure quality. Using the curated utterances, we then generated question responses by querying each agent to gather its response to the utterance.</p><p>In order to generate ground truth samples on which of the question-response pairs (Q, R i ) correctly resolves the query Q we launched a crowdsourcing task asking workers to indicate the candidate responses that best answer the question shown. Five workers were assigned to each response selection task and majority voting (&gt;2) was used to label the gold responses. As such for each query Q and the set of responses R we were able to gather the necessary question-agent pairs (Q, A i ) and question-response pairs (Q, R i ) needed to evaluate our approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agent Descriptions</head><p>We gather our agent descriptions by scraping the contents of each of the agent's public product pages and their built-in feature documentation web pages. We then manually clean, reformat and merge this data into a single docu-ment per agent. For our experiment, we focus only on extracting descriptions related to the built-in features of our agents.</p><p>Overall our dataset contains 5550 utterances with 19 question-response pairs per question (one from each of the 19 agents), 105,450 in total. The utterances are split into 3700 utterances (100 per domain) for the training set and 1850 (50 per domain) for the test set. The train and test sets respectively contain 2399 and 1186 utterances with at least one positive question-response pair. In the remaining examples, none of the agents were able to achieve annotator agreement (&gt;= 3). A sample dataset example is shown in table 1 with responses from 4 of the 19 agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>In this section we present and analyze the results of our experiments, detailing our insights and discussing the implications of each of our techniques.</p><p>Evaluation task: Similar to standard information retrieval evaluation measures, we denote accuracy as the metric precision@1 and use it to evaluate both our question agent and question response pairing approaches. For question agent pairing this metric denotes: Given a set of N agents to the given query, whether the agent selected ultimately resolves the query successfully. For question response pairing it denotes: Given a set of N responses to the given query, whether the top-scoring response resolves the query successfully. For this evaluation, we test on examples with at least one valid agent response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Question agent pairing</head><p>The results are summarized in tables 2 and 3. We find that for the QA pairing Roberta yields the best result with an accuracy of 69% in selecting the correct agent and 61.8% when scaled to 19   agents. Similarly, we see that we can achieve fair performance in extreme data-scarce environments when using simple agent descriptions compared to that of query agent examples, with USE achieving 47.8% accuracy. Using agent descriptions offers greater flexibility in facilitating the improvement of agents over time compared to query examples since it only requires an update to the agent description. However, it still falls short when compared to using a single agent like Google or Alexa. Also, while consistent in learning to recognize the domain a given agent may be performant in, QA approaches fall short in a few cases:</p><p>(1) Agent overlap -This is when a given domains' coverage is split between various agents. e.g The model learns that both Alexa &amp; Google have proficiency in handling some weather queries but it remains unclear about which one is best suited for the current query at hand.</p><p>(2) Query variation -While an agent's examples or descriptions may allude to proficiency in a given domain, it may still fail when asked cer-  <ref type="table">Table 4</ref>: Further breakdown of the best-performing approaches per technique on a subset of 8 out of the 37 domains. We find that our MARS encoder generalizes well across the various agent domains. tain query variations. e.g <ref type="figure">Figure 1</ref> shows a case where Alexa is capable of handling weather queries but fails when a condition like humidity is asked for. Another example is when a similar question is asked in a different or more complex way. Both Houndify &amp; Alexa are known to be proficient at answering age-related questions but for questions like "How old I will be on September 28, 1995, if I was born on March 29, 1967?", Alexa is unable to answer as opposed to Houndify. These cases are further highlighted when inspecting QA pairing performance at the domain level in table 4. We find that the QA approaches struggle with domains such as "travel suggestion" and "Directions" which are heavily split in coverage and more diverse in their variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Question response pairing</head><p>In overall performance we find that our MARS encoder outperforms strong baselines, achieving 83.55% accuracy on the BBAI task. We note that our MARS encoder outperforms the best single performing agent (Google Assistant) by 32%. This shows the utility and power of OFA in not only alleviating the need for users to learn and adopt mul-tiple agents but also validating that multiple agents working collectively can achieve significantly more than single agents working in isolation.</p><p>When inspecting the performance of MARS at the domain level we see in <ref type="table">Table 4</ref> that it is able to maintain its high performance across the varying domains unlike the QA approaches. This advantage comes from the ability to select an agent at the response level allowing the system to catch cases in which an agent once deemed proficient fails or another agent improves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Agent pairing vs Response pairing</head><p>We now describe the trade-offs between agent pairing and response pairing. Question response pairing greatly outperforms agent pairing in terms of accuracy, given that it is privy to the final responses from each of the agents. However, in practice, this comes with additional networking, compute, and latency costs from having to send the query to each of the agents and await their response. Given that the querying of agents is done in parallel, the latency cost is equal to that of the slowest agent. Question response pairing also better supports agent adaptation. With response pairing, a system can seamlessly add or remove an agent without diminishing the experience as shown by MARS in table 3. In addition, as conversational agents are upgraded to offer a more diverse feature-set such as new domain support or improved responses, they can instantly be integrated into a response pairing approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Scalability</head><p>We evaluate our approaches on a suite of 19 commercially deployed agents spanning 37 broad domain categories. As shown in table 2 we examine performance when using the 4 largest agents in terms of domain support and popularity (Alexa, Google Assistant, Houndify and Ford Adasa) showing improvement upon single-agent use in both QA and QR approaches. When scaled up to 19 agents, MARS encoder improves even further by leveraging the new capabilities of the additional agents and is the only approach that does not decrease in performance as the number of agents and domains scale. This improvement is due to the input sensitive representations that the MARS encoder is able to learn by encoding both the question and response in a single transformer.</p><p>Cross-encoding vs Bi-encoding For pairwise sentence scoring tasks such as response selection which compare question response pairs, it is impor-tant to be mindful of the trade-offs between cross encoder based models such as MARS in figure 4 (b) and bi-encoder models such as USE in 4 (a). Cross-encoders perform full self-attention over the pairwise input of the question and response, thus, producing an encoding representative of the combined input. This typically leads to much more performative models, especially in pairwise scoring tasks such as ours. However, given that this encoding isn't independent of the question for each question response pair, it is necessary to produce an encoding for each question label pair. Bi-encoders on the other hand perform self-attention over the question response pairs separately, map them to a dense vector space, and score them using an appropriate distance metric. With this separation, bi-encoders are able to index the question and compare these representations for each response resulting in faster prediction times when the numbers of candidate responses to a given question scales. Given the nature of our BBAI task which focuses on the scoring of responses to a singular question as opposed to a clustering task which requires an encoding for every pairwise combination across a set of sentences, cross-encoder based architectures remain a viable option even at the production scale for our use case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Ensemble approaches to solving complex tasks in the context of NLP are widely used <ref type="bibr" target="#b6">(Deng and Platt, 2014;</ref><ref type="bibr" target="#b1">Araque et al., 2017)</ref>. In dialogue systems, recent attempts at ensemble approaches and multi-agent architectures include Cercas <ref type="bibr" target="#b3">Curry et al. (2018)</ref> and <ref type="bibr" target="#b24">Subramaniam et al. (2018)</ref>. AlanaV2 <ref type="bibr" target="#b3">(Cercas Curry et al., 2018)</ref> demonstrated an ensemble architecture of multiple bots using a combination of rule-based machine learning systems built to support topic-based conversations across domains. It was built to be an open domain bot supporting topic-based conversations. Specifically, AlanaV2's architecture utilizes a variety of ontologies and NLU pipelines that draw information from a variety of web sources such as Reddit. However, its agent selection approach is guided by a simple priority bot list. <ref type="bibr" target="#b24">Subramaniam et al. (Subramaniam et al., 2018)</ref> describe their conversational framework that employs an Orchestrator Bot to understand the user query and direct them to a domain-specific bot that handles subsequent dialogue. In our work, we expand up the multi-agent goal by focusing on the integration of black-box conversational agents at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Response Selection</head><p>This is the task of selecting the most appropriate response given context from a pool of candidates. It is a central component of information retrieval applications and has become a focal point in the evaluation of dialogue systems. <ref type="bibr" target="#b23">(Sato et al., 2020;</ref><ref type="bibr" target="#b10">Henderson et al., 2019;</ref><ref type="bibr" target="#b26">Wang et al., 2020)</ref>. Prior work has shown strong performance on sentence pairing tasks through the use of sentence encoders and language model fine-tuning <ref type="bibr" target="#b10">(Henderson et al., 2019;</ref><ref type="bibr" target="#b11">Humeau et al., 2020;</ref><ref type="bibr" target="#b20">Reimers and Gurevych, 2019)</ref>. In our work, we explore the task of response selection using it as one of the bases for integrating black-box conversation agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The rapid proliferation of conversational agents calls for a unified approach to interacting with multiple CAs. The key challenge of building such an interface lie in that most commercial CAs are black-boxes with hidden internals. This paper introduces BBAI a new task of agent integration that focuses on unifying black-boxes CAs across varying domains. We explore two task techniques, question agent pairing and question response pairing and present One For All, a scalable system that unifies multiple black-box CAs with a centralized user interface. Using a combination of commercially available conversational agents, we evaluate a variety of approaches to multi-agent integration through One For All. Our MARS encoder achieves 83.5% accuracy on BBAI and outperforms the best single agent configuration by over 32%. These results demonstrate the power of One For All which can leverage state-of-the-art NLU approaches to enable multiple agents to collectively achieve more than any single conversational agent in isolation eliminating the need for users to learn and adopt multiple agents.</p><p>This work opens up a wide range of potential future work involving the design of systems geared towards facilitating more advanced multi-agent interaction. We foresee a system with even greater response selection performance as the NLP community continues to produce more state-of-the-art language models with even greater contextual knowledge of the world. Extensions of this work can include examining not only the integration of agents but the interoperability by facilitating the passing of shared conversation knowledge across agents especially in multi-turn conversational scenarios across multiple agents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Sample question agent responses from the One For All dataset. Responses highlighted in green represent agent responses voted as correct by crowd workers.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance breakdown of QA and QR approaches on our BBAI task when using our 4 largest agents Alexa, Google, Houndify and Adasa. Note: n = number of agents.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Accuracy (n=19)</cell><cell>Agents</cell></row><row><cell>Question Agent Pairing (QA Labels)</cell><cell>Bert Electra Roberta</cell><cell>59.10 52.86 61.88</cell><cell>Alexa, Google Houndify, Adasa Recipe agent</cell></row><row><cell>Question Agent Pairing (Descriptions)</cell><cell>BM25 USE Roberta+STS</cell><cell>23.69 43.59 36.67</cell><cell>Dictionary agent Task Manager Hotel agent, Stock agent</cell></row><row><cell></cell><cell>BM25</cell><cell>59.94</cell><cell>Math agent, Sports agent</cell></row><row><cell></cell><cell>USE</cell><cell>64.42</cell><cell>Wikipedia agent</cell></row><row><cell>Response Selection</cell><cell>USE QA</cell><cell>71.66</cell><cell>Mobile Account agent</cell></row><row><cell></cell><cell>Roberta+STS</cell><cell>56.82</cell><cell>Banking agent</cell></row><row><cell></cell><cell>MARS</cell><cell>83.55</cell><cell>Coffee shop agent</cell></row><row><cell></cell><cell>Alexa</cell><cell>44.09</cell><cell>Event Search agent</cell></row><row><cell>Individual Agents</cell><cell>Google Houndify</cell><cell>48.06 32.04</cell><cell>Jokes agent Reminders agent</cell></row><row><cell></cell><cell>Adasa</cell><cell>3.45</cell><cell>Covid-19 agent</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance breakdown of QA and QR approaches on our BBAI task on all 19 commercial agents we show that the MARS encoder is able to scale and leverage the capabilities of new agents added to the ensemble without diminishing performance compared to other approaches.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/ChrisIsKing/ black-box-multi-agent-integation</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank our anonymous reviewers for their feedback and suggestions. We also thank Yi-Chun Chen who assisted in designing the diagrams and figures shown in this work. This work was sponsored by Ford Motor Company.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Amazon and leading technology companies announce the voice interoperability initiative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amazon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enhancing deep learning sentiment analysis with ensemble techniques in social applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Araque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Corcuera-Platas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Fernando</forename><surname>S?nchez-Rada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2017.02.002</idno>
	</analytic>
	<monogr>
		<title level="m">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="236" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Universal sentence encoder for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Yi</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhomni</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurzweil</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2029</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Alana v2: Entertaining and informative opendomain social dialogue using ontologies and entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda Cercas</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Papaioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Suglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Shalyminov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Xinnuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Dusek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st Proceedings of Alexa Prize</title>
		<imprint>
			<publisher>Alexa</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Single or multiple conversational agents?: An interactional coherence comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><forename type="middle">Paula</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><forename type="middle">Aurelio</forename><surname>Gerosa</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173765</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="page" from="1" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Electra: Pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ensemble deep learning for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive evaluation of conversational agents: Reflections on the impact of search task design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Dubiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Halvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Daronnat</surname></persName>
		</author>
		<idno type="DOI">10.1145/3409256.3409814</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval, ICTIR &apos;20</title>
		<meeting>the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval, ICTIR &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="85" to="88" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Here&apos;s how robots are transforming takeout deliveries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anmar</forename><surname>Frangoul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I?igo</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<title level="m">Convert: Efficient and accurate conversational representations from transformers</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data collection for dialogue system: A startup perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Hauswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mars</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-3005</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An evaluation dataset for intent classification and out-of-scope prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Peper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mars</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1131</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11-03" />
			<biblScope unit="page" from="1311" to="1316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adasa: A conversational in-vehicle digital assistant for advanced driver assistance features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Hong</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Talamonti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Oney</surname></persName>
		</author>
		<idno>UIST-31</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 31st ACM Symposium on User Interface Software and Technology<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Jason Mars, and Lingjia Tang</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Roberta: A robustly optimized bert pretraining approach</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing social robot, screen and voice interfaces for smart-home control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Luria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Zuckerman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3025453.3025786</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, CHI &apos;17</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems, CHI &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="580" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Market and Markets. 2020. Conversational ai market</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Using facebook messenger and chatbots to grow your audience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Nealon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Conversational interaction with multiple agents initiated via proxemics and gaze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><forename type="middle">J</forename><surname>Hinojos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">E</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdokht</forename><surname>Afravi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3284432.3287185</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Human-Agent Interaction, HAI &apos;18</title>
		<meeting>the 6th International Conference on Human-Agent Interaction, HAI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="356" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentencebert: Sentence embeddings using siamese bertnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Too many fish in the sea: A motivational examination of the choice overload experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Saltsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Seery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheryl</forename><forename type="middle">L</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><forename type="middle">M</forename><surname>Lamarche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsey</forename><surname>Streamer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2019.03.010</idno>
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluating dialogue generation systems via response selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiki</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reina</forename><surname>Akama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ouchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.55</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="593" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuramalingam</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pooja</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gargi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paradkar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cobots -a cognitive multi-bot conversational framework for technical support</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS &apos;18</title>
		<meeting>the 17th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS &apos;18<address><addrLine>Richland, SC</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="597" to="604" />
		</imprint>
	</monogr>
	<note>International Foundation for Autonomous Agents and Multiagent Systems</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Response selection for multi-party conversations with dynamic topic tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weishi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shafiq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno>abs/2010.07785</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. 2019. Multilingual universal sentence encoder for semantic retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jax</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Hernandez Abrego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
