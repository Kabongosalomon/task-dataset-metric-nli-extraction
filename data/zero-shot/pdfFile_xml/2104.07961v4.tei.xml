<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ADVANCED DEEP NETWORKS FOR 3D MITOCHONDRIA INSTANCE SEGMENTATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueyi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Xiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ADVANCED DEEP NETWORKS FOR 3D MITOCHONDRIA INSTANCE SEGMENTATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Electron microscopy</term>
					<term>mitochondria</term>
					<term>in- stance segmentation</term>
					<term>deep network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mitochondria instance segmentation from electron microscopy (EM) images has seen notable progress since the introduction of deep learning methods. In this paper, we propose two advanced deep networks, named Res-UNet-R and Res-UNet-H, for 3D mitochondria instance segmentation from Rat and Human samples. Specifically, we design a simple yet effective anisotropic convolution block and deploy a multi-scale training strategy, which together boost the segmentation performance. Moreover, we enhance the generalizability of the trained models on the test set by adding a denoising operation as pre-processing. In the Large-scale 3D Mitochondria Instance Segmentation Challenge at ISBI 2021, our method ranks the 1st place. Code is available at https://github.com/Limingxing00/MitoEM 2021-Challenge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>As an important kind of organelle, mitochondria provide energy for cells and are of great value to the research of life science. Generally, electron microscopy (EM) images that contain recognizable mitochondria consume a huge storage, e.g., at the scale of Terabyte <ref type="bibr" target="#b0">[1]</ref>. Manual instance segmentation of mitochondria from such a large amount of data is impossible, and automatic segmentation algorithms are highly desired. As pioneer works, Lucci et al. <ref type="bibr" target="#b1">[2]</ref> propose a supervoxel-based method with learned shape features to recognize mitochondria. Seyedhosseini et al. <ref type="bibr" target="#b2">[3]</ref> use algebraic curves and a random forest classifier to segment mitochondria. Due to the limited generalizability, however, these traditional methods cannot be easily adapted to large-scale datasets such as Mi-toEM <ref type="bibr" target="#b3">[4]</ref> including both rat and human samples.</p><p>Recently, some methods based on convolutional neural networks (CNNs) have emerged for mitochondrial segmentation. For example, Oztel et al. <ref type="bibr" target="#b4">[5]</ref> propose a deep network to segment 2D mitochondria slices first and then integrate 3D information with median filtering in the axial dimension. Wei et al. <ref type="bibr" target="#b3">[4]</ref> summarize the CNN-based methods into two groups, * Equal contribution. ? Corresponding author: zwxiong@ustc.edu.cn top-down methods and bottom-up methods. Representative top-down methods use Mask-RCNN <ref type="bibr" target="#b5">[6]</ref> for instance segmentation. Due to the elongated and distorted shape of mitochondria, however, it is difficult to set a proper anchor size for Mask-RCNN in this task. The bottom-up methods usually predict a binary segmentation mask <ref type="bibr" target="#b6">[7]</ref>, an affinity map <ref type="bibr" target="#b7">[8]</ref>, or a binary mask with the instance boundary <ref type="bibr" target="#b8">[9]</ref>. Then a post-processing algorithm is used to distinguish instances. Although notable progress has been achieved, there is still a large room for improving the performance of mitochondria instance segmentation.</p><p>In this paper, we propose two advanced deep residual networks, named Res-UNet-R for the rat sample and Res-UNet-H for the human sample on the MitoEM dataset. Both networks generate the same form of outputs, including a semantic mask and an instance boundary. Since the human sample is more difficult (i.e., containing more noise) than the rat sample, we increase a decoder path for Res-UNet-H to predict the semantic mask and the instance boundary separately, while the decoder of Res-UNet-R has only one path. Obtaining the semantic mask and the instance boundary, we then synthesize a seed map. Finally, we adopt the connected component labeling to obtain the mitochondria instances.</p><p>To boost the segmentation performance of our networks , we design a simple yet effective anisotropic convolution block and deploy a multi-scale training strategy. Moreover, we observe that imaging noise is sparsely distributed on the Mi-toEM dataset. Especially in the human sample, the noise level is subjectively stronger than that in the rat sample. To alleviate the influence of noise on segmentation, we utilize an interpolation network <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> to restore the noisy regions coarsely marked by labor. In addition to mitochondria instance segmentation, we also verify the proposed method has superior performance for mitochondria semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Res-UNet-R and Res-UNet-H</head><p>We follow the bottom-up methods to extract the response map of mitochondria first. For the rat sample and the human sample, we propose two deep residual networks named Res-UNet-R and Res-UNet-H respectively. In the following description, we omit the exponential linear unit (ELU) after the convolutional layer for brevity. Anisotropic Convolution Block. Since the MitoEM dataset has anisotropic resolution, we design an anisotropic convolution block (ACB) as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. After a 1 ? 3 ? 3 conventional layer, we cascade two 3 ? 3 ? 3 conventional layers to further enlarge the receptive field. At the same time, we insert the skip connection in the two 3?3?3 conventional layers.</p><p>Network Structure. The overall structure of Res-UNet-H is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. Inspired by 3D U-Net <ref type="bibr" target="#b11">[12]</ref>, we first embed the feature maps extracted from a 3D block with a 1 ? 5 ? 5 conventional layer. In each layer of the encoder, there is an ACB to extract the anisotropic information. Then we adopt a 1 ? 3 ? 3 conventional layer to downsample the feature maps in the lateral dimensions. In the decoder, we use the trilinear upsampling to restore the resolution of the feature maps and the ACB to reconstruct the detailed information. For Res-UNet-R, the decoder outputs a semantic mask and an instance boundary simultaneously. Since the human sample is of poorer imaging quality than the rat sample, we design two decoder paths for Res-UNet-H to predict the semantic mask and the instance boundary separately.</p><p>Loss Function. The binary cross entropy (BCE) is a common loss function used in biomedical image segmentation. To address the class imbalance problem, we adopt a weighted BCE (WBCE) loss as</p><formula xml:id="formula_0">L W BCE (X i , Y i ) = 1 DHW W i L BCE (X i , Y i ),<label>(1)</label></formula><p>where X i and Y i are the predicted response map and groundtruth of the i-th block, D, H, and W denote the depth, height, and width of the block, and the weight W i is defined as</p><formula xml:id="formula_1">W i = Y i + W f 1?W f (1 ? Y i ) W f &gt; 0.5 1?W f W f Y i + (1 ? Y i ) else<label>(2)</label></formula><p>Here W f is the foreground voxel ratio, i.e., W f = sum(Yi) DHW . The overall loss function L is defined as</p><formula xml:id="formula_2">L = L W BCE (X M , Y M ) + L W BCE (X B , Y B ), (3)</formula><p>where X M and X B are the predicted response maps of the semantic mask and the instance boundary respectively. Y M and Y B are the corresponding ground-truth of X M and X B .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Post-processing</head><p>Obtaining the semantic mask X M ? R D?H?W and the instance boundary X B ? R D?H?W , we can generate the seed map S j (j ? [1, D ? H ? W ]) as</p><formula xml:id="formula_3">S j = 1 X j M &gt; T 1 , X j B &lt; T 2 0 else<label>(4)</label></formula><p>where T 1 and T 2 are two thresholds. In our experiments, we set T 1 = 0.9 and T 2 = 0.8. Then we generate the seed map and adopt the connected component labeling to obtain the final mitochondria instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Denoising as Pre-processing</head><p>As mentioned above, we find that by adding a denoising operation as pre-processing on the test set, the influence of noisy regions on segmentation can be alleviated, especially for the human sample. To this end, we adopt the interpolation network initially proposed for video frame <ref type="bibr" target="#b9">[10]</ref> and also employed for EM image restoration in <ref type="bibr" target="#b10">[11]</ref>. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the interpolation network takes the two adjacent frames of the noisy frame as input and predicts two kernels. The two adjacent frames are then convolved by the two kernels respectively, the sum of which contributes to the restored frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The MitoEM dataset <ref type="bibr" target="#b3">[4]</ref> consists of two (30 ?m) <ref type="bibr" target="#b2">3</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Implementation Details</head><p>We adopt Pytorch (version 1.1) to implement the proposed method. Two TITAN Xp (12GB) are used for training and inference. For the MitoEM dataset, during the training stage, we adopt the data augmentation methods following <ref type="bibr" target="#b3">[4]</ref> and set the batch size as 2. The network is optimized by Adam with a fixed learning rate 0.0001. We train the network in two stages. First, we train the network in 200K iterations with the input size 32 ? 256 ? 256 to select the best model. Then we change the input size to 36 ? 320 ? 320 and fine-tune the network in 100K iterations. We call this two-stage training as multi-scale training (MT). For the Lucchi dataset, we train Res-UNet-R with only the semantic mask output, following the training details in <ref type="bibr" target="#b3">[4]</ref>. Connected component labeling is no longer needed for the semantic segmentation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Evaluation Metrics and Results</head><p>We adopt an efficient 3D AP-75 metric <ref type="bibr" target="#b3">[4]</ref> on the MitoEM dataset. In this case, at least 0.75 intersection over union (IoU) with the ground truth for a detection is required to be Method MitoEM-R MitoEM-H Wei <ref type="bibr" target="#b3">[4]</ref> 0.521 0.605 Nightingale <ref type="bibr" target="#b12">[13]</ref> 0.715 0.625 Li <ref type="bibr" target="#b13">[14]</ref> 0.870 0.787 Ours 0.917 0.828 <ref type="table">Table 1</ref>. Instance segmentation results on the MitoEM validation set.</p><p>Method Jaccard DSC Lucchi <ref type="bibr" target="#b14">[15]</ref> 0.755 0.860 Liu <ref type="bibr" target="#b15">[16]</ref> 0.864 0.926 Yuan <ref type="bibr" target="#b16">[17]</ref> 0.865 0.927 Wei <ref type="bibr" target="#b3">[4]</ref> 0.887 -Casser <ref type="bibr" target="#b17">[18]</ref> 0.890 0.942 Res-UNet-R 0.895 0.945 <ref type="table">Table 2</ref>. Semantic segmentation results on the Lucchi test set. a true positive (TP). According to the number of mitochondrial voxels, mitochondria are divided into small, medium and large instances, with respective thresholds of 5K and 15K. On the Lucchi dataset, we evaluate jaccard-index coefficient (jaccard) and dice similarity coefficient (DSC) for the foreground objects in the volumes. As shown in <ref type="table">Table 1</ref>, on the MitoEM validation set, the AP-75 of the proposed method surpasses the existing deep learning-based methods, Wei <ref type="bibr" target="#b3">[4]</ref>, Nightingale <ref type="bibr" target="#b12">[13]</ref> and Li <ref type="bibr" target="#b13">[14]</ref>, by a large margin. Besides, for the semantic segmentation dataset Lucchi, the proposed method also outperforms some recent competitors, e.g., Lucchi <ref type="bibr" target="#b14">[15]</ref>, Liu <ref type="bibr" target="#b15">[16]</ref>, Yuan <ref type="bibr" target="#b16">[17]</ref>, Wei <ref type="bibr" target="#b3">[4]</ref> and Casser <ref type="bibr" target="#b17">[18]</ref> as shown in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Ablation Study</head><p>Main components. Take Res-UNet-R as an example, the simple baseline only generates the semantic mask and uses 3D Res block without the MT strategy. The proposed method adopts instance boundary and uses 3D ACB block with the MT strategy. We conduct an ablation study for the three main components in <ref type="table">Table 3</ref>, which validates their effectiveness. In the following subsections, we show more details about the different components and strategies.</p><p>Block Unit Selection. We test different block units in <ref type="table">Table 4</ref> on the validation set of MitoEM-R. Here 3D SE block <ref type="bibr" target="#b18">[19]</ref>, 3D ECA block <ref type="bibr" target="#b19">[20]</ref> and 3D Res block <ref type="bibr" target="#b20">[21]</ref> are simply modified from state-of-the-art methods for the image recognition task. In comparison with these more complex block units, our simply designed ACB alleviates overfitting and achieves the best results on the 3D mitochondria instance segmentation task.</p><p>Network Structure. As shown in <ref type="table">Table 5</ref>, if we train and test Res-UNet-R on MitoEM-H, the AP-75 result is 0.783. By introducing an extra decoder, Res-UNet-H improves the AP-75 result to 0.816 (3.3% increment). It verifies that Res-UNet-H can handle more complex samples.</p><p>Training Strategy. As shown in <ref type="table">Table 3</ref> and 5, the multiscale training strategy (MT) we used is beneficial for both models, especially for Res-UNet-H (AP-75 improves 1.2%). It proves that both models need larger receptive field to avoid over-fitting.</p><p>Denoising Pre-processing. As shown in <ref type="figure">Fig. 3</ref>, the noisy regions of the middle frame can be well restored by the in-  <ref type="table">Table 5</ref>. Ablation of network structure on the MitoEM-H validation set. terpolation network. As shown in <ref type="table" target="#tab_2">Table 6</ref>, it is demonstrated that the generalizability of the trained models can be enhanced on the test set by adding this denoising operation as pre-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Challenge Results</head><p>In the Large-scale 3D Mitochondria Instance Segmentation Challenge at ISBI 2021, our method ranks the 1st place. As   <ref type="table">Table 7</ref>. MitoEM Challenge leaderboard at the end of the testing phase.</p><p>shown in <ref type="table">Table 7</ref>, the proposed method notably outperforms other competitors on both MitoEM-R and MitoEM-H test sets. We also show some visualized results from the validation set of MitoEM-R and MitoEM-H in <ref type="figure">Fig.2</ref>. It can be seen that the predicted results by the proposed method is very close to ground-truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In this paper, we present two advanced deep networks for 3D mitochondria instance segmentation, named Res-UNet-R for the rat sample and Res-UNet-H for the human sample. Specifically, we exploit a simple yet effective ACB and a multi-scale training strategy to boost the segmentation performance. Moreover, we enhance the generalizability of the trained models on the test set by adding a denoising operation as pre-processing. Experimental results demonstrate the proposed method has superior performance for mitochondria instance and semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">COMPLIANCE WITH ETHICAL STANDARDS</head><p>Ethical approval was not required as confirmed by the license attached with the open access data ( https://mitoem.g rand-challenge.org/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGEMENT</head><p>This work was supported in part by Anhui Provincial Natural Science Foundation Grant No. 1908085QF256 and University Synergy Innovation Program of Anhui Province No. GXXT-2019-025.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Network structure of Res-UNet-H. Note the decoder of Res-UNet-R has only one path to generate the semantic mask and the instance boundary simultaneously.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Frame</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>EM image volumes of resolution 8 ? 8 ? 30 nm, which come from a</figDesc><table><row><cell>rat tissue (MitoEM-R) and a human tissue (MitoEM-H) re-</cell></row><row><cell>spectively. Each tissue has three parts, a training set (400 ?</cell></row><row><cell>4096 ? 4096), a validation set (100 ? 4096 ? 4096) and a</cell></row><row><cell>test set (500 ? 4096 ? 4096). Lucchi [2] is a mitochondria</cell></row><row><cell>semantic segmentation dataset in which the training and test</cell></row><row><cell>data volumns are with a size of 165 ? 1024 ? 768.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 6 .</head><label>6</label><figDesc>Ablation of denoising pre-processing on the Mi-toEM test set.</figDesc><table><row><cell cols="2">Original</cell><cell>After denoising</cell><cell></cell></row><row><cell>Frame i-1</cell><cell></cell><cell>i</cell><cell>Frame i+1</cell></row><row><cell cols="4">Fig. 3. Visualized results before and after denoising pre-</cell></row><row><cell cols="3">processing on the MitoEM-H test set.</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">MitoEM-R Small Med Large ALL</cell></row><row><cell>Res-UNet-R</cell><cell cols="3">0.305 0.861 0.848 0.850</cell></row><row><cell cols="4">After denoising 0.151 0.832 0.854 0.851</cell></row><row><cell>Method</cell><cell cols="3">MitoEM-H Small Med Large ALL</cell></row><row><cell>Res-UNet-H</cell><cell cols="3">0.522 0.844 0.826 0.828</cell></row><row><cell cols="4">After denoising 0.531 0.834 0.827 0.829</cell></row><row><cell cols="4">Method MitoEM-R MitoEM-H Average</cell></row><row><cell>Ours</cell><cell>0.851</cell><cell>0.829</cell><cell>0.8400</cell></row><row><cell>2nd</cell><cell>0.836</cell><cell>0.800</cell><cell>0.8180</cell></row><row><cell>3rd</cell><cell>0.833</cell><cell>0.800</cell><cell>0.8165</cell></row><row><cell>4th</cell><cell>0.816</cell><cell>0.804</cell><cell>0.8100</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dense connectomic reconstruction in layer 4 of the somatosensory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6469</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervoxel-based segmentation of mitochondria in em image stacks with learned shape features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aur?lien</forename><surname>Lucchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="474" to="486" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Segmentation of mitochondria in electron microscopy images using algebraic curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Ellisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tasdizen</surname></persName>
		</author>
		<editor>ISBI</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mitoem dataset: Largescale 3d mitochondria instance segmentation from em images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zudi</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mitochondria segmentation in electron microscopy volumes using deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Oztel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gozde</forename><surname>Yolcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilker</forename><surname>Ersoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filiz</forename><surname>Bunyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BIBM</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>MICCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kisuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Zung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Sebastian</forename><surname>Seung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00120</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Superhuman accuracy on the snemi3d connectomics challenge</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dcan: deep contour-aware networks for accurate gland segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Hao Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Video frame interpolation via adaptive convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to restore sstem images from deformation and corruption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">3d u-net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>?zg?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>I?ek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automatic instance segmentation of mitochondria in electron microscopy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Joost De Folter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Spiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin L</forename><surname>Collinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Contrastive learning for mitochondria segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhili</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuejin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12363</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning for structured prediction using approximate subgradient descent with working sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aur?lien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic reconstruction of mitochondria and endoplasmic reticulum in electron microscopy volumes by deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiwei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">599</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Em-net: Centerline-aware mitochondria segmentation in em images via hierarchical viewensemble convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajin</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengrong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongdao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Peng</surname></persName>
		</author>
		<editor>ISBI</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Fast mitochondria detection for connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Casser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Haehn</surname></persName>
		</author>
		<editor>MIDL</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Squeeze-andexcitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Eca-net: Efficient channel attention for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
