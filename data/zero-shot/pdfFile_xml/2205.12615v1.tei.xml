<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Autoformalization with Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-05-25">25 May 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenda</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Staats</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateja</forename><surname>Jamnik</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Autoformalization with Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-05-25">25 May 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion (25.3%) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from 29.6% to 35.2%.</p><p>Recent advances in large language models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref> showed promising capabilities of understanding formal languages <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b31">32]</ref>. However, the existing successes are limited to formal languages where there exists a large body of corpus on the web (e.g., Python language). Formal mathematics data is very scarce. For example, one of the largest formal mathematics libraries, the Archive of Formal Proofs, is only 180MB in size, that is less than 0.18% of the training data for the large language model Codex <ref type="bibr" target="#b7">[8]</ref>. Moreover, unlike in the case of commonly used programming languages, where natural language docstrings are broadly available, there is almost zero aligned data between natural language and formal mathematics. Therefore, it is unclear the recent successes can directly contribute to the development of autoformalization.</p><p>In this work, we explore the prospects of autoformalization with large language models. To our surprise, we find that large language models already have a decent capability of formalizing natural ? Correspondence to Yuhuai Wu (yuhuai@google.com).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study 1 Question:</head><p>"Prove that there is no function f from the set of non-negative integers into itself such that f (f (n)) = n + 1987 for every n."</p><p>Codex Output: theorem fixes f :: "nat \&lt;Rightarrow&gt; nat" assumes "\&lt;forall&gt; n. f (f n) = n + 1987" shows False Figure 1: Case study 1: An example of a perfect translation from natural language to Isabelle code.</p><p>language mathematics in an interactive theorem prover. See <ref type="figure">Figure 1</ref> for a perfect autoformalization example. The model not only translates into syntactically correct Isabelle code, but also grasps the non-trivial reasoning in natural language. We randomly pick 150 formalizations and manually evaluate their correctness. Among them, LLMs are capable of producing 38 perfect formalizations! As an application, we further demonstrate that autoformalization can provide useful training data for neural theorem provers. We use autoformalized statements as targets for proof search with a neural theorem prover for Isabelle/HOL. After fine-tuning our neural theorem prover on the proofs it found, its success rate on the MiniF2F benchmark [54] increases significantly, achieving a new state-of-the-art result of 35.2% theorems proven.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Autoformalization refers to the task of automatically translating from natural language mathematics to a formal language <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b43">44]</ref>. The implication of a successful autoformalization tool is huge in both practical and philosophical terms. It would reduce the currently excessive cost of formalization efforts <ref type="bibr" target="#b26">[27]</ref>, and in the long-term it could connect the various research fields that automate aspects of mathematical reasoning, such as automated theorem proving and computer algebra, to the vast body of mathematical knowledge exclusively written up in natural language. Moreover, autoformalization would be a true testament to machine understanding, grasping both the fuzziness of natural language and the preciseness of formal language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early applications of machine learning in theorem proving include the works by Schulz <ref type="bibr" target="#b41">[42]</ref> and Urban <ref type="bibr" target="#b44">[45]</ref>, and later, directly guiding interactive proof assistants using machine learning techniques <ref type="bibr" target="#b13">[14]</ref>. The revolution of deep learning then kicked off a new wave of interest in the topic starting with DeepMath <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>Several approaches have been suggested to address data scarcity: Imitation-free reinforcement learning was used to avoid the need for training on human proofs <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b50">51]</ref>. Also, hindsight experience replay <ref type="bibr" target="#b1">[2]</ref> was used to generate additional training data <ref type="bibr" target="#b3">[4]</ref>. Hahn et al. <ref type="bibr" target="#b17">[18]</ref>, Schmitt et al. <ref type="bibr" target="#b40">[41]</ref>, Kreber &amp; Hahn <ref type="bibr" target="#b28">[29]</ref> and Wu et al. <ref type="bibr" target="#b51">[52]</ref> have shown that training on synthetic formulas can be successful for temporal logics and inequalities. Rabe et al. <ref type="bibr" target="#b38">[39]</ref> masked out different subexpressions from formal mathematical statements and generated 100 training examples for each source statement. Skip-tree data can also be used to improve the performance of neural theorem provers <ref type="bibr" target="#b20">[21]</ref>.</p><p>Wang et al. <ref type="bibr" target="#b47">[48]</ref> explored the use of supervised and unsupervised translation techniques for autoformalization. Supervised translation yielded interesting results, but relied on synthetic (naturallooking) data that was generated by the Mizar theorem prover, while we rely on models trained via self-supervised language modeling, not trained for this particular purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>Formal Mathematics A few important and complex results of mathematics and computer science have been formalized manually using interactive theorem provers, such as the four color theorem <ref type="bibr" target="#b14">[15]</ref>, the Kepler conjecture <ref type="bibr" target="#b18">[19]</ref>, the odd-order theorem <ref type="bibr" target="#b15">[16]</ref> and the verification of a microkernel <ref type="bibr" target="#b26">[27]</ref>. This gives us almost complete certainty about the correctness of proofs, which can be of great value to resolve doubt about the correctness of complicated mathematical proofs or proving certain properties of software used in safety-critical applications, such as aircraft components <ref type="bibr" target="#b27">[28]</ref>.</p><p>These projects relied on interactive theorem provers, such as Isabelle <ref type="bibr" target="#b49">[50]</ref>, Coq <ref type="bibr" target="#b10">[11]</ref>, HOL Light <ref type="bibr" target="#b21">[22]</ref>, and Lean <ref type="bibr" target="#b11">[12]</ref>, which are essentially programming languages that enable users to enter their statements and proofs in a formal language, and which can then be checked automatically for correctness. Interactive theorem provers offer a limited amount of automation, but projects that formalize complex problems typically span many years of tedious work by specialists. Only in narrow domains like chip design and the verification of drivers in operating systems has the automation of logic made sufficient progress to find commercial applications.</p><p>Progress in autoformalization and the automation of proofs might eventually make mathematics a universally available tool and enable a paradigm shift in science and the development of (safetycritical) software. Our interest in formalizing mathematics, however, has an additional aspect. We believe that autoformalization will serve a dual purpose and will not only accelerate the development of tools for mathematical reasoning, but also provide a means to ground machine learning systems, enabling a positive feedback loop between machine learning and formal systems (cf. <ref type="bibr" target="#b43">[44]</ref>).</p><p>Large Language Models Our work relies heavily on large language models (LLMs), in particular on PaLM <ref type="bibr" target="#b8">[9]</ref> and Codex <ref type="bibr" target="#b7">[8]</ref>. The training goal of these models is to predict the next word given some prefix. This allows us to train these models on arbitrary text, which is available in vast quantities. After training the models on hundreds of billions of words (cf. <ref type="bibr" target="#b23">[24]</ref>), they are often able to generate high-quality text. We can also give these models an arbitrary prefix (the prompt) that they are then supposed to continue, which gives us some control over what they generate. This has been demonstrated with news articles, conversations, summaries, jokes, and poems. LLMs have also been evaluated on natural language word problems on datasets such as GSM8K <ref type="bibr" target="#b9">[10]</ref> and MATH <ref type="bibr" target="#b22">[23]</ref>, and have been shown to make progress on these benchmarks with increasing scale <ref type="bibr" target="#b8">[9]</ref>.</p><p>In-context Learning Large language models have shown a remarkable ability to learn patterns and tasks within the current input (context) that they are given <ref type="bibr" target="#b6">[7]</ref>: this is called in-context learning or few-shot learning. For example, if we prompt a language model with a few pairs of English and matching French sentences, and end with a new English sentence, then the language model is very likely to pick up on the translation task and attempt a translation of the last English sentence. This observation has been used, for example, to achieve strong translation performance without access to large corpora of matching sentence pairs <ref type="bibr" target="#b19">[20]</ref>.</p><p>This allows us to specify the task of autoformalization simply by giving a couple of example formalizations. In Section 4 we will detail how exactly we use in-context learning for autoformalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Autoformalization for Mathematical Competition Problems</head><p>Inspired by the success of LLMs for synthesizing computer code by co-training on both natural language and code on web-scale data, we explore the capabilities of LLMs to turn natural language mathematics into formalized theorems for the interactive theorem prover Isabelle. This can be seen as a machine translation task (cf. <ref type="bibr" target="#b48">[49]</ref>) in which the input language is English and output language is formal code used by the interactive proof assistant Isabelle <ref type="bibr" target="#b49">[50]</ref>.</p><p>We first study autoformalization in a constrained setting -formalizing mathematical competition problem statements. This setting has the advantage that most of the required background theory and definition has been formalized in the current libraries of Isabelle, so that formalizations are often possible without introducing additional definitions.</p><p>We start assessing LLMs' abilities to do autoformalization with a case study. We manually pick two interesting natural language mathematical statements, and prompt PaLM models of various scales <ref type="bibr" target="#b8">[9]</ref> as well as Codex <ref type="bibr" target="#b7">[8]</ref> to translate them into a formal statement in Isabelle. Next, we study a dataset in which we have human ground truth formalizations. The dataset is a subset of the miniF2F <ref type="bibr" target="#b22">[23]</ref> dataset consisting of 140 algebra problems and 120 number theory problems. Using human formalizations as the reference, we compute the BLEU scores of the formalizations produced by several LLMs. Lastly, we perform human evaluations on failure cases in autoformalization on 150 problems.</p><p>Note that many mathematical competition statements are often of the form in which one asks to find the answer to a certain problem, instead of proving a given proposition. However, formal mathematical statements are in the form of propositions, instead of questions. To transform a question into a proposition, we append the final answer after the question: $Problem_Statement The final answer is $Answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural language version:</head><formula xml:id="formula_0">"Let z = 1+i ? 2 , find ( 1 i=1 2(z i 2 )) ? ( 1 i=1 2( 1 z i 2 ))</formula><p>. The final answer is 36." Translate the natural language version to an Isabelle version: theorem fixes z::complex assumes h0: "z = (Complex (1/sqrt 2) (1/sqrt 2))" shows "(\&lt;Sum&gt;k::nat=1..12. (z^(k^2))) * (\&lt;Sum&gt; k::nat=1..12. 1/(z^(k^2)))=36" Natural language version: "Determine the value of ab if log 8 a + log 4 b 2 = 5 and log 8 b + log 4 a 2 = 7. The final answer is 512". Translate the natural language version to an Isabelle version:  The format of the prompt we use to do autoformalization is: Natural language version: $Natural_Language_Statement.</p><p>Translate the natural language version to an Isabelle version:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mathematical Competition Datasets</head><p>MATH <ref type="bibr" target="#b22">[23]</ref> contains in total 12,500 (7,500 training and 5,000 test) middle school and high school mathematical competition problems. Problems are taken from past mathematical competitions, including AMC 10, AMC 12, AIME, and more, and many can be found at http://aops.com/community/c3158_usa_contests. The dataset contains seven categories: algebra, pre-algebra, intermediate algebra, number_theory, precalculus, probability, geometry. Problem statements are written in LaTeX.</p><p>MiniF2F <ref type="bibr" target="#b53">[54]</ref> is a recently introduced benchmark containing 488 mathematical competition statements manually formalized by humans in three different formal languages. Its goal is to compare and benchmark methods across different theorem provers for machine learning research. Some of these problems come from the valid and test set of MATH algebra and number_theory, and others come from previous International Mathematical Olympiad competitions or AoPS 1 . Note that the Isabelle formalizations of the miniF2F benchmark were committed to the repository during March, 2022. According to the public information on the large language models, we think it is highly unlikely these formalizations were included in the pre-training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Case Studies</head><p>Experimental setup For all our experiments, we use the standard greedy decoding (i.e., temperature 0, p = 1) to obtain the autoformalizations. We randomly select two mathematical statements for constructing the prompt. No prompt engineering / tuning is performed when constructing the prompt. The examples are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. The natural language problem statements used in the case studies are taken from the miniF2F dataset. In the case studies below, we highlight the output of language models in red to distinguish it from the prompt. PaLM output: theorem fixes n::nat assumes "n mod 8 = 7" shows "n mod 4 = 3"</p><p>Case Study 3 Question: Natural language version: "Let f be a linear function for which f (6) ? f (2) = 12. What is f (12) ? f <ref type="bibr" target="#b1">(2)</ref>? The final answer is 30." Translate the natural language version to an Isabelle version:</p><p>Codex output: theorem fixes f :: "real \&lt;Rightarrow&gt; real" assumes "linear f" "f 6 -f 2 = 12" shows "f 12 -f 2 = 30" Case Study 1 <ref type="figure" target="#fig_9">(Figure 1)</ref> We study the example shown in <ref type="figure" target="#fig_9">Figure 1</ref>, in which we ask LLMs to autoformalize an International Mathematical Olympiad problem 2 in natural language. Surprisingly, Codex is able to autoformalize the natural language statement as an Isabelle theorem perfectly, with output given. This is surprising for the following reasons.</p><p>First of all, the amount of Isabelle code is very scarce on the internet. The entire AFP library, the largest formal library that contains most of Isabelle proofs, is only 180MB in size. Even assuming that all of this data was included in the training of Codex, this makes at most 0.18% of the pretraining data on which Codex was trained. The fact that the model can write syntactically correct Isabelle code at all is already fascinating.</p><p>Second, there is almost zero aligned data from natural language to Isabelle on the web. While some Isabelle files have comments, they typically only give a very high level description of what the theory being formalized is about. So either LLMs are able to transfer knowledge quite successfully between natural language and formal mathematics, or the task was learned mostly via few-shot learning.</p><p>Last but not least, the model is capable of understanding and formalizing nontrivial reasoning. First, the model is able to formalize the non-existence statement via proof-by-contradiction. To formalize "there is no function f ...", it assumes there is such a function, and aims to prove "False". Second, the model understands what it means by the phrase "to itself", and correctly infers the domain of function: f :: "nat \&lt;Rightarrow&gt; nat".</p><p>On the other hand, PaLM made some syntactic mistakes while getting most of the structure of the proof correctly, with outputs shown in Appendix B.1.</p><p>Case Study 2 ( <ref type="figure" target="#fig_2">Figure 3</ref>) In the next example, we ask LLMs to autoformalize a grade school mathematical word problem. Remarkably, PaLM and Codex are both capable of formalizing the statement perfectly. This is surprising because formalizations of grade school math problems in interactive theorem provers are rare (if they exist at all), as this type of mathematics is not of interest to formal mathematicians. Even more, none of the examples in the prompt (see <ref type="figure" target="#fig_1">Figure 2</ref>) that we provide are of this type. It is hence remarkable that the model is capable of extrapolating to this type of statement, showing a great promise of using LLMs for autoformalization.</p><p>To study this problem in more depth, we probe PaLM models of various sizes (8B, 64B, 540B) with outputs shown in Appendix B.2, and notice that scale is crucial for the LLMs ability to formalize. We observe that the 8B and 64B models are incapable of formalizing this problem, but the largest 540B model is able to produce a correct formalization.</p><p>Case Study 3 ( <ref type="figure" target="#fig_2">Figure 3</ref>) In our third case study, Codex gives an incorrect formalization in Isabelle. The mathematical statement involves a concept of "linear function", which the model fails to Has the model memorized these formalizations? Whilst we do not have access to the training set of Codex, we attempted to find any occurrences of the formalizations produced in the case studies on the internet. We Googled them in different variants and inspected the first page of the search results. We tried variants with and without an "Isabelle" prefix, with and without quotation marks and other special characters, and also individual parts of it, such as "Isabelle "n mod 8 = 7"", but we did not find any occurrences of related statements. We also tested that we are indeed able to find occurrences of Isabelle formalizations on the web with this methodology, using pieces of formalizations picked from several websites, including the Archive of Formal Proofs. Hence, we are confident that the model has not memorized the formalizations it generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">BLEU for Model Comparisons</head><p>The miniF2F benchmark contains 140 algebra problems and 120 number theory problems from the MATH dataset. For these problems, we have human ground truth formalizations in Isabelle, which gives us an evaluation set with pairs of natural language statements (from MATH) and their formalizations. We use this dataset to quantitatively compare different LLMs.</p><p>Given the observation about few shot learning in Case study 3, we decided to add more relevant examples to each subject to improve the quality of autoformalization. For each subject (i.e., algebra and number_theory), we randomly sample 10 problems to construct the few shot prompt. The rest of the problems are used for evaluation (i.e., 130 for algebra and 110 for number_theory. We provide the prompt used in the Appendix A.1 and A.2.</p><p>We use PaLM models of varying sizes and Codex to perform the autoformalization, and compute the BLEU scores of the formalizations, shown in <ref type="table" target="#tab_1">Table 1</ref>. Confirming our observation in Case study 2, we see a clear trend that scaling improves translation, as the BLEU scores consistently improve when we scale PaLM models from 8B to 540B, for both subjects. In addition, we see that the Codex model is better at autoformalization measured by BLEU, possibly due to the fact that Codex was trained on more formal data than PaLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Human Evaluation of Failure cases</head><p>To better understand LLMs' ability to do autoformalization, we manually inspect Codex's autoformalizations of 150 random problems from the MATH dataset <ref type="bibr" target="#b22">[23]</ref>. 50 of the problem statements are sampled from the algebra training set, 50 from number_theory and 50 from intermedi-ate_algebra. For algebra and number_theory, we use their corresponding prompt as in the last section, shown in Appendix A.1 and A.2. For intermediate_algebra, we use the prompt we used for algebra (Appendix A.1). We classify the failure modes of these translations, shown in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>We see that out of 150 problems, Codex is capable of translating 38 problems perfectly -a success rate of 25.3%. The majority of the failures are due to the misalignment of informal and formal definitions. For example, when seeing the phrase "the greatest possible value", the LLMs often fail to align it with the function Greatest/Max in Isabelle. Another example is the failure to align the fac- torial of n (i.e., !n) to fact n in Isabelle. Other common failure modes include the misapplication of functions (e.g., applying a prefix function in an infix way).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Autoformalization for Neural Theorem Proving</head><p>To demonstrate the usefulness of the formalized statements, we explore if one can improve neural theorem provers by training the neural models on proofs of automatically translated theorems. In this section, we combine autoformalization with expert iteration algorithms <ref type="bibr" target="#b2">[3]</ref>, and achieve a new state of the art in miniF2F benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Expert Iteration with Autoformalization</head><p>The basic idea of expert iteration <ref type="bibr" target="#b2">[3]</ref> is to iteratively generate a better dataset using the model, and use the data to improve the model quality. This allows the model to generate an even better quality of the dataset and hence a better model, forming a self-improvement cycle.</p><p>In neural theorem proving, one way to get better quality data is to use feedback from the proof checker to run many proof searches (or generate multiple proofs) and check the proof attempts for correctness. Newly found correct proofs can then be used as the new training data to improve the neural prover <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. The main critical ingredient that is needed is a set of problem statements on which the model can perform proof search to obtain new training data. However, unlike in Polu et al. <ref type="bibr" target="#b37">[38]</ref>, where one asks humans to manually formalize a set of problems to get formal statements, here we use LLMs to autoformalize the theorems in order to kick off the self-improvement cycle.</p><p>More formally, denote a base neural theorem prover as M 0 . Let the set of autoformalized problems be A. For each iteration i = 1 . . . N , we carry out the following procedure: use the language model M i?1 with best-first search to prove as many theorems as possible in A, collect the set of successful proofs S i , concatenate successful problems from all iterations with the formal mathematics problems to create the set A i = ( j?i S i )?B, and fine-tune M 0 on it for exactly one epoch to get a new model M i . When we take the union of successful proofs from all past iterations, we perform deduplication by problem statements, similar to Polu et al. <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Neural Theorem Provers</head><p>To demonstrate the effectiveness of the approach, we start with a recently introduced neural theorem prover for Isabelle, Thor <ref type="bibr" target="#b25">[26]</ref>. The Thor agent is fine-tuned on the PISA dataset <ref type="bibr" target="#b24">[25]</ref> (extraction and interaction code under a BSD license), which consists of 2.49 million proof steps from the Isabelle/HOL library (under a BSD-style license) and the Archive of Formal Proofs (under various licenses as described here). The model is trained with the objective to predict the next token in a proof step, given the proof state and the last proof step. When the ground truth proof step contains any of the keywords metis, meson, and smt, the model learns to predict a special token &lt;hammer&gt;. In evaluation, whenever the special token is emitted, Thor invokes the proof method Sledgehammer <ref type="bibr" target="#b35">[36]</ref> in Isabelle with a 30 second timeout.</p><p>We use a pre-trained and fine-tuned Thor agent as the base model (M 0 ). The agent's language model uses Wang <ref type="bibr" target="#b46">[47]</ref>'s implementation (under an Apache license 2.0) of a GPT-2 <ref type="bibr" target="#b39">[40]</ref> style decoder-only 28.3% 29.9%</p><formula xml:id="formula_1">After 1 expert iteration (M 1 ) 36.1% 34.0% After 2 expert iterations (M 2 ) 37.3% 35.2%</formula><p>transformer <ref type="bibr" target="#b45">[46]</ref> model with 700M non-embedding parameters. The model has 24 layers, 24 attention heads, a hidden dimension of 1536, and a vocabulary size of 50400. It uses the AdamW <ref type="bibr" target="#b34">[35]</ref> optimizer and is pre-trained on the GitHub + arXiv subsets of The Pile <ref type="bibr" target="#b12">[13]</ref> for 200,000 steps, with a context length of 2048 tokens. In pre-training a warmup strategy <ref type="bibr" target="#b16">[17]</ref> raises the learning rate linearly from 0 to 2 ? 10 ?4 in 3,000 steps. Then a cosine learning rate scheduler <ref type="bibr" target="#b33">[34]</ref> is used for the rest of the pre-training, with a final learning rate of 1.2 ? 10 ?5 . The training has a global batch size of 32 sequences, or 65,536 tokens. For fine-tuning the learning rate strategy is the same, with 10,000 warmup steps, 90,000 annealing steps, maximum learning rate 3 ? 10 ?4 and final learning rate 3 ? 10 ?5 . The global batch size is 144 sequences, or 294,912 tokens. The model's evaluation loss reaches a minimum after 13,000 steps and that checkpoint is used.</p><p>Machine specification For experiments in this paper, we use a TPUv3 with 8 cores from Google Cloud Platform. The Isabelle process has access to up to 32 CPU cores. Running all the experiments in this paper requires a total of 3920 TPU hours. Of the 3920 TPU hours, 3200 are for running the proof search on the autoformalized theorems, 240 are for training the model on the successful proofs, and 480 are for evaluating the model on miniF2F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Result</head><p>We use Codex with greedy decoding to formalize 3908 mathematical problems in algebra, intermediate algebra, and number theory from the training set of MATH <ref type="bibr" target="#b22">[23]</ref>, with the same few shot prompts used in Section 4.4. Out of them, 3363 of the autoformalized theorems are syntactically correct. We then perform expert iteration on this dataset.</p><p>We start with a neural theorem prover (M 0 ) as described in Section 5.2. In our first iteration, M 0 proves 782 theorems, with a success rate of 23.3% (out of 3363). This gives us a new set of verified proofs to further train the neural theorem prover. We proceed to fine-tune our neural theorem prover in the fashion described in Section 5.1 to get a new prover (M 1 ). This process is repeated in the second iteration, giving us 1011 successful proofs from the autoformalized theorems (30.1%). We fine-tuned M 0 again, but on the deduplicated concatenation of problems from PISA and successful proofs found for the autoformalized theorems.</p><p>After each stage of fine-tuning, we evaluate the neural theorem prover on miniF2F <ref type="bibr" target="#b53">[54]</ref>. The results are shown in <ref type="table" target="#tab_3">Table 3</ref>. The base model (M 0 ) has a success rate of 28.3% and 29.9% on the validation and test fractions of miniF2F respectively. It can be observed that the first expert iteration increases the success rate of the neural prover by 7.8% and 4.1% to 36.1% and 34.0% on the valid and test sets. The second iteration further improves them both by 1.2%, to 37.3% and 35.2%. By doing two expert iterations on the autoformalized theorems, the neural prover achieves a success rate that is 5.6% higher than the previous state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">An Outlook on Autoformalizing Advanced Mathematics</head><p>So far, we focused on mathematical competition problems, in which we achieve significant results using autoformalization. Not only can LLMs autoformalize non-trivial theorems, the autoformalized theorems can also improve neural prover performance. In this section, we take a peek into more advanced mathematics. We hope to identify some of the limitations of our methods when it comes to autoformalizing mathematics in the wild.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question: An arbitrary product of compact spaces is compact.</head><p>Codex Output: theorem fixes X :: "'a set set" assumes "\&lt;forall&gt;x \&lt;in&gt;X. compact x" shows "compact (\&lt;Prod&gt; x \&lt;in&gt; X. x)" <ref type="figure">Figure 4</ref>: A formalization for an advanced mathematical statement by Codex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Autoformalization: from Natural Language to Isabelle</head><p>Autoformalization is extremely challenging in the sense that the model needs to (1) bridge the logical gaps left in pen-and-paper proofs, (2) assume the implicit contexts and assumptions, and <ref type="formula">(3)</ref> align informal definitions/concepts to formal ones. This task is further complicated considering the context can change from time to time and the same mathematical object can be formalized in subtly different ways. In this paper, we only deal with autoformalization of theorem statements, where the model is mainly challenged by definition alignments. Compared to competition problems in Section 4.4, advanced mathematical statements assume more context information that additionally obscures the alignment. <ref type="figure">Figure 4</ref> shows a typical case where the model fails to align the informal definition to the formal one. Based on the notation used, the model does not correctly distinguish between products of numbers, products of sets, and products of topological spaces. In Isabelle, the correct conclusion for the statement should be compact_space (product_topology X I), where I is an index set that ought to have been introduced in the fixes and assumes sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Informalization: from Isabelle to Natural Language</head><p>So far, we explored one direction of translation: from natural language statement to formal statement in Isabelle. The other direction, informalization, is also of great importance for two reasons: (1) the informal texts are much easier for humans to comprehend and communicate, and (2) we can align translated informal statements with formal ones to create data, and use the back-translation techniques <ref type="bibr" target="#b42">[43]</ref> to potentially boost the translator's performance further. In this section, we explore Codex's capability of translating formal Isabelle statement to natural language.</p><p>A corpus of 38 formal-language theorems, lemmas, and definitions is selected by an Isabelle expert. These statements are automatically translated to informal mathematics using Codex; to see the prompt we used and the results for all 38 examples, see Appendix A.3 and D.2. We present two examples of informalization in <ref type="figure">Figure 5</ref>. Of the 38 examples, 36 were translated to a reasonably coherent statement, and 29 of these statements (76%) were more-or-less correct, giving a vastly better success rate than the 25% success rate of formalization (Section 4.4). Our main conclusion is that for advanced mathematics, the model is better at informalization than formalization, showing the prospect of backtranslation style algorithms.</p><p>Note that the standard is more relaxed here since we assume a human reader will supply the obvious context and correct mistakes when the intended meaning is obvious (intended by the hypothetical human writer of these sentences). To illustrate, an example of a minor "acceptable" error: assuming that "w, z are in the same connected component of the plane" when, in context, it is clear that w, z should be assumed to be in the same connected component of the complement of a previously specified curve. (The assumption as originally stated is trivial.) For an example of a major error: almost-perfect translation of the Central Limit Theorem that omits the assumption of identical distributions.</p><p>lemma seteqI:</p><formula xml:id="formula_2">" [[ x. x ?A =? x ?B; x. x ?B =? x ?A ]] =? A = B"</formula><p>Translate the Isabelle version to a natural language version:</p><formula xml:id="formula_3">Codex Output: "If A and B are sets such that A ? B and B ? A, then A = B." lemma topologyI: " [[ x y. [[ is_open T x; is_open T y ]] =? is_open T (x ? y); M. ? m ? M. is_open T m =? is_open T ( M) ]] =? topology T"</formula><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "If T is a set and T is closed under finite intersections and arbitrary unions, then T is a topology." <ref type="figure">Figure 5</ref>: Two perfect translations from Isabelle code to natural language by Codex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>Promise of Autoformalization with LLMs We have seen that automated formalization of informally given natural language statements is generally possible, even with language models not trained for this particular task. Also, automatically formalized statements are useful for training and improving the reasoning capabilities of automated neural provers. Our hope is that improved versions of this methodology will be capable of enabling a positive feedback loop involving formalization and formal reasoning that has the potential of reaching human level capabilities in both respects, as was suggested by <ref type="bibr" target="#b43">[44]</ref>.</p><p>Limitations and future directions We use a static model for the formalization process. For largescale autoformalization, we will need to formalize larger theories, preferably without fine tuning the model, as training it could be cumbersome and resource consuming. However, in order to utilize the newly added notions, the model would need to keep whole large theories in the current context window, which exceeds those of the current LLMs. This limits our approach to the generation of fairly small pieces of formal mathematics and the automatic formalization of entire theories including their definitions will require new research ideas. One path towards this goal might be the use of continuous training or expert iteration, cycle-consistency-based training <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b47">48]</ref>, or novel uses of in-context learning. To generate larger theories we will also need neural networks that can recall longer sequences (current LLMs are typically limited to a few thousand words). Retrievalaugmented language models, such as the memorizing transformer <ref type="bibr" target="#b52">[53]</ref> offer one path to overcome this limitation.</p><p>Societal Impact While the potential of creating negative societal impact through formalizations is small, the use of LLMs always comes with risks. For example, for deploying an autoformalization tool using LLMs we would need to consider the inclusivity of variable and lemma names, and of the attribution of scientific ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Few-shot Prompts</head><p>A.1 Prompt used to formalize algebra problems Natural language version: "Simplify 4</p><formula xml:id="formula_4">x ?1 3x 3 x 2 1 2x ?3 . The final answer is 18x 8 ".</formula><p>Translate the natural language version to an Isabelle version:</p><p>theorem fixes x :: real assumes h0 : "x \&lt;noteq&gt; 0" shows "1/(4/x) * ((3*x^3)/x)^2 * (1/(1 / (2 * x)))^3 = 18 * x^8" Natural language version: "For integers n, let <ref type="figure">(f (4)</ref>)))). The final answer is 1". Translate the natural language version to an Isabelle version: theorem fixes f :: "int \&lt;Rightarrow&gt; int" assumes "\&lt;forall&gt;n. odd n \&lt;longrightarrow&gt; f n = n^2" and "\&lt;forall&gt; n. even n \&lt;longrightarrow&gt; f n = n^2 -4*n -1" shows "f 4 = -1" Natural language version: "The volume of a cone is given by the formula V = 1 3 Bh, where B is the area of the base and h is the height. The area of the base of a cone is 30 square units, and its height is 6.5 units. What is the number of cubic units in its volume? The final answer is 65". Translate the natural language version to an Isabelle version: . The final answer is <ref type="bibr">47 24</ref> ". Translate the natural language version to an Isabelle version:</p><formula xml:id="formula_5">f (n) = n 2 if n is odd, n 2 ? 4n ? 1 if n is even. Find f (f (f (f</formula><p>theorem fixes x :: real and \&lt;sigma&gt;::"real \&lt;Rightarrow&gt; real" assumes "bij \&lt;sigma&gt;" and \&lt;sigma&gt;:"\&lt;forall&gt; x. \&lt;sigma&gt; x = 5 * x -12" and "\&lt;sigma&gt; (x + 1) = (inv \&lt;sigma&gt;) x" shows "x = 47 / 24" Natural language version: "What is the x-coordinate for the x-intercept of the line containing the points <ref type="bibr" target="#b6">(7,</ref><ref type="bibr" target="#b3">4)</ref> and <ref type="bibr" target="#b5">(6,</ref><ref type="bibr" target="#b2">3)</ref>? The final answer is 3". Translate the natural language version to an Isabelle version: Natural language version: "What is the remainder when 1 + 2 + 3 + 4 + ? ? ? + 9 + 10 is divided by <ref type="bibr" target="#b8">9</ref>? The final answer is 1". Translate the natural language version to an Isabelle version:</p><p>theorem "(\&lt;Sum&gt; k&lt; 11. k) mod 9 = (1::nat)" Natural language version: "Cards are numbered from 1 to 100. One card is removed and the values on the other 99 are added. The resulting sum is a multiple of 77. What number was on the card that was removed? The final answer is 45". Translate the natural language version to an Isabelle version:</p><p>theorem fixes x :: nat assumes h0 : "1 \&lt;le&gt; x \&lt;and&gt; x \&lt;le&gt; 100" and h1 : "77 dvd ((\&lt;Sum&gt;k::nat=0..100. k)-x)" shows "x=45" Natural language version: "Find 9 ?1 (mod 100), as a residue modulo 100. (Give an answer between 0 and 99, inclusive.) The final answer is 89 (mod 100)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Translate the natural language version to an Isabelle version:</head><p>theorem fixes x::nat assumes "x &lt; 100" and "x*9 mod 100 = 1" shows "x = 89" Natural language version: "Suppose m is a two-digit positive integer such that 6 ?1 (mod m) exists and 6 ?1 ? 6 2 (mod m). What is m? The final answer is 43". Translate the natural language version to an Isabelle version: theorem fixes m x :: nat assumes h0 : "10 \&lt;le&gt; m" and h1 : "m \&lt;le&gt; 99" and h2 : "(6 * x) mod m = 1" and h3 : "(x -6^2) mod m = 0" shows "m = 43" Natural language version: "Find 24 ?1 (mod 11 2 ). That is, find the residue b for which 24b ? 1 (mod 11 <ref type="bibr" target="#b1">2 )</ref>. Express your answer as an integer from 0 to 11 2 ? 1, inclusive. The final answer is 116". Translate the natural language version to an Isabelle version: theorem fixes b::int assumes "\&lt;forall&gt;b::int. 0\&lt;le&gt;b \&lt;and&gt; b\&lt;le&gt;11^2 \&lt;and&gt; [b * 24 = 1] (mod (11^2))" shows "b = 116" Natural language version: "Given that p ? 7 is a prime number, evaluate</p><formula xml:id="formula_6">1 ?1 ? 2 ?1 + 2 ?1 ? 3 ?1 + 3 ?1 ? 4 ?1 + ? ? ? + (p ? 2) ?1 ? (p ? 1) ?1 (mod p).</formula><p>The final answer is 2 (mod p)". Translate the natural language version to an Isabelle version: Natural language version: "One morning each member of Angela's family drank an 8-ounce mixture of coffee with milk. The amounts of coffee and milk varied from cup to cup, but were never zero. Angela drank a quarter of the total amount of milk and a sixth of the total amount of coffee. How many people are in the family? The final answer is 5". Translate the natural language version to an Isabelle version:</p><p>theorem fixes x y n ::nat assumes "x / 4 + y / 6 = (x + y) / n" and "n\&lt;noteq&gt;0" "x\&lt;noteq&gt;0" "y\&lt;noteq&gt;0" shows "n = 5"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Prompt used for informalization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Isabelle version:</head><p>theorem fixes z::complex assumes h0: "z = (Complex (1/sqrt 2) (1/sqrt 2))" shows "(\&lt;Sum&gt;k::nat=1..12. (z^(k^2))) * (\&lt;Sum&gt; k::nat=1..12. 1/(z^(k^2))) =36"</p><p>Translate the Isabelle version to a natural language version: "Let z = 1+i ? 2 , find</p><formula xml:id="formula_7">( 1 i=1 2(z i 2 )) ? ( 1 i=1 2( 1 z i 2 ))</formula><p>. The final answer is 36." Isabelle version: Here we show the output given by PaLM model 540B. The model got the most structure correctly, but made some syntactical errors.</p><p>Question: Natural language version: "Prove that there is no function f from the set of non-negative integers into itself such that f (f (n)) = n+1987 for every n." Translate the natural language version to an Isabelle version:</p><p>PaLM 540B Output: theorem fixes f :: "nat -&gt; nat" assumes "forall n::nat. f(f(n)) = n + 1987" shows "false"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Case Study 2</head><p>We show below the output given by PaLM models of different sizes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Case Study 3</head><p>If we include the following example in the prompt in additional to the two examples shown in <ref type="figure" target="#fig_1">Figure 2</ref>: Natural language version: "What is the x-coordinate for the x-intercept of the line containing the points <ref type="bibr" target="#b6">(7,</ref><ref type="bibr" target="#b3">4)</ref> and <ref type="figure" target="#fig_2">(6, 3)</ref>? The final answer is 3". Translate the natural language version to an Isabelle version: Note that this additional example in the prompt is only tangentially related. The phrase "linear function" is not even mentioned. Instead, it shows an example how to formalize a line. But that is sufficient for the model to understand how to formalize a "linear function". Question: Natural language version: "A map of the town that Annie, Barbara, and Charlie live in can be represented by the Cartesian plane. Annie is located at <ref type="bibr">(6, ?20)</ref> and Barbara is located at <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b13">14)</ref>. They agree to meet at the closest point that is equidistant from their current locations and walk upwards together to get to Charlie's location at <ref type="bibr" target="#b6">7</ref> 2 , 2 . How many units upward do Annie and Barbara walk together to get to Charlie? The final answer is 5." Translate the natural language version to an Isabelle version: Question: Natural language version: "A line segment begins at <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b2">3)</ref>. It is 5 units long and ends at the point (4, x) and x &gt; 0. What is the value of x? The final answer is 7".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More Examples on Mathematical Competition Problems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x :: real assumes h0 : "x &gt; 0" and h1 : "5 = sqrt ((4 -1)^2 + (x -3)^2)" shows "x = 7" Natural language version: "A line segment begins at <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b2">3)</ref>. It is 5 units long and ends at the point (4, x) and x &gt; 0. What is the value of x? The final answer is 7". Question: Natural language version: "Let z be a complex number satisfying z 2 = 4z ? 19 + 8i. Given that |z| is an integer, find z. The final answer is 3 + 4i".</p><p>Codex Output: theorem fixes z :: complex assumes h0 : "z^2 = 4 * z -19 + 8 * \&lt;i&gt;" and h1 : "norm z \&lt;in&gt; \&lt;int&gt;" shows "z = 3 + 4 * \&lt;i&gt;" Question: Natural language version: "The sequence (a n ) satisfies a 1 + a 2 + a 3 + ? ? ? + a n = n 2 a n for all n ? 2. If a 63 = 1, find a 1 . The final answer is 2016".</p><p>Codex Output: theorem fixes a :: "nat \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;forall&gt; n \&lt;ge&gt; 2. (\&lt;Sum&gt; k = 1..n. a k) = n^2 * a n" and h1 : "a 63 = 1" shows "a 1 = 2016" Question: Natural language version: "Find the units digit of the following within the indicated number base: 52 7 + 62 7 The final answer is 4".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x y :: nat assumes "x &lt; 7" and "y &lt; 7" shows "((x*7+2) + (y*7+2)) mod 7 = 4" Question: Natural language version: "How many factors of 8000 are perfect squares? The final answer is 8".</p><p>Codex Output: theorem fixes n :: nat assumes "n = card {k::nat. k^2 dvd 8000}" shows "n = 8"</p><p>Question: Natural language version: "Solve the congruence 11n ? 7 (mod 43), as a residue modulo 43.</p><p>(Give an answer between 0 and 42.) The final answer is 28".</p><p>Codex Output: theorem fixes n :: nat assumes "n &lt; 43" and "(11 * n) mod 43 = 7" shows "n = 28" Question: Natural language version: "What is the 100th digit after the decimal point of the decimal representation of 1/7? The final answer is 8".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x :: nat assumes "x = (1/7) * 10^100"</p><p>shows "x mod 10 = 8"</p><p>Question: Natural language version: "Two positive integers m and n are chosen such that m is the smallest positive integer with only two positive divisors and n is the largest integer less than 100 with exactly three positive divisors. What is m + n? The final answer is 51". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Incorrect Translations</head><p>In this section, we present failure cases for each of the categories in <ref type="table" target="#tab_2">Table 2</ref> in Section. 4.4.</p><p>Error category: incomplete/ill-formed/unclear prompt Question: Natural language version: "Find the largest value of t such that</p><formula xml:id="formula_8">13t 2 ? 34t + 12 3t ? 2 + 5t = 6t ? 1.</formula><p>The final answer is \frac{5".</p><p>Codex Output: theorem fixes t :: real assumes h0 : "13 * t^2 -34 * t + 12 = 3 * t -2" and h1 : "5 * t = 6 * t -1" shows "t = 5 / 2" Error category: fail to align definitions or concepts Question: Natural language version: "What is the smallest four-digit positive integer that is divisible by <ref type="bibr" target="#b46">47</ref>? The final answer is 1034".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x :: nat assumes "x &gt; 999" and "x &lt; 10000" and "47 dvd x" shows "x = 1034" Here, the translator correctly captured the meaning of "four-digit positive integer" (i.e., "x &gt; 999" and "x &lt; 10000") and that of "divisible by 47" (i.e., "47 dvd x"). However, it fails to align the "smallest" concept to the one in Isabelle.</p><p>Error category: inconsistent/missing assumption Question: Natural language version: "Jack walked up a hill at a speed of (x 2 ? 11x ? 22) miles per hour. Meanwhile, Jill walked a total distance of (x 2 ? 3x ? 54) miles in (x + 6) hours. If Jack and Jill walked at the same speed, what is that speed, in miles per hour? The final answer is 4". Here, the translator missed the "(x+6)" part in the natural language-it should be translated to "x^2 -11 * x -22 = (x^2 -3 * x -54)/(x+6)" instead. Also, the conclusion is incorrect either: it should be "x^2 -11 * x -22 = 4" or "(x^2 -3 * x -54)/(x+6)= 4".</p><p>Error category: syntactical/type error) Question: Natural language version: "Find 1024 N =1</p><formula xml:id="formula_9">?log 2 N ?.</formula><p>The final answer is 8204".</p><p>Codex Output: theorem fixes N :: nat shows "(\&lt;Sum&gt; N = 1..1024. nat \&lt;lfloor&gt;log 2 N\&lt;rfloor&gt;) = 8204"</p><p>In the current version, N will be inferred as a real number, so that the interval "1..1024" will be a real interval from 1 to 1024. This is incorrect, and sum over such infinite interval will result in 0 (i.e., "(\&lt;Sum&gt; N = 1..1024. nat \&lt;lfloor&gt;log 2 N\&lt;rfloor&gt;)= 0"). The correct version requires an explicit type conversion: "(\&lt;Sum&gt; N = 1..1024. \&lt;lfloor&gt;log 2 (of_int N)\&lt;rfloor&gt;)=</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8204".</head><p>Error category: missing definition in Isabelle Question: Natural language version: "The product of two positive three-digit palindromes is 436,995.</p><p>What is their sum? The final answer is 1332".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x y :: nat assumes "100 \&lt;le&gt; x \&lt;and&gt; x \&lt;le&gt; 999" and "100 \&lt;le&gt; y \&lt;and&gt; y \&lt;le&gt; 999" and "x * y = 436995" shows "x + y = 1332"</p><p>The only missing part in this example is the definition of palindromes. It appears that the translator does not know what a palindrome is so that it chooses to drop it from the assumptions. The function Z should be applied in a prefix way in Isabelle. Also, the translator missed the "for all" quantifier in the assumption. The correct assumption should be "\&lt;forall&gt; a b. Z a b = b + 10 * a -a^2".</p><p>Error category: other Question: Natural language version: "Simplify: |?3 2 + 4| The final answer is 5".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>theorem fixes x :: real assumes h0 : "x = -3^2 + 4" shows "abs x = 5"</p><p>Here, a parenthesis should be placed around 3^2 (i.e., "x = -(3^2)+ 4"). This is a subtle issue to operator precedence in Isabelle.</p><p>Error category: other Question: Natural language version: "How many numbers from 1 to 150 are not perfect squares or perfect cubes? The final answer is 135".</p><p>Codex Output: Here, we asked the model to formalize the statement of the famous Brouwer's fixed-point theorem. The model made two mistakes. The first one is that the model erroneously assume the function is on a real normed vector space rather than a euclidean space or a banach space. This is quite understandable as we left this information in the source. The second and more critical error is that the absence of the assumption of f mapping from S to itself (i.e., f (S) ? S or f (S) = S).</p><p>Question: Let ? be a closed path in the complex plane, and z be a point not on ?. Then the winding number of ? around z is an integer.</p><p>Codex Output: theorem fixes \&lt;gamma&gt; :: "real \&lt;Rightarrow&gt; complex" and z :: complex assumes "continuous_on {0..1} \&lt;gamma&gt;" "\&lt;gamma&gt; 0 = \&lt;gamma&gt; 1" "z \&lt;notin&gt; \&lt;gamma&gt; ' {0..1}" shows "winding_number \&lt;gamma&gt; z \&lt;in&gt; \&lt;int&gt;" Here, the model has made a perfect translation-not only the model correctly infers that a path in the complex plane should be a function from the real interval [0, 1] to complex, it also manages to align a path being closed to the assumption \&lt;gamma&gt; 0 = \&lt;gamma&gt; 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Informalization</head><p>The following lemma statements are from the standard library of Isabellle (i.e., HOL-Complex_Analysis and HOL-Probability). Translate the Isabelle version to a natural language version:</p><formula xml:id="formula_10">Codex Output: "If S is closed in T and S is closed in U , then S is closed in T ? U ". lemma connected_closedin: "connected S ?? (? E1 E2. closedin (top_of_set S) E1 ? closedin (top_of_set S) E2 ? S ? E1 ? E2 ? E1 ? E2 = {} ? E1 = {} ? E2 = {})"</formula><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "A set S is connected if and only if there does not exist two closed sets E 1 and E 2 such that</p><formula xml:id="formula_11">S ? E 1 ? E 2 , E 1 ? E 2 = ?, E 1 = ? and E 2 = ?". definition continuous_map where "continuous_map X Y f ? (? x ? topspace X. f x ? topspace Y) ? (? U. openin Y U ?? openin X {x ? topspace X. f x ? U})"</formula><p>Translate the Isabelle version to a natural language version:</p><formula xml:id="formula_12">Codex Output: "A function f from a topological space X to a topological space Y is continuous if for every open set U in Y , the preimage f ?1 (U ) is open in X". definition continuous_map where "continuous_map X Y f ? (? x ? topspace X. f x ? topspace Y) ? (? U. openin Y U ?? openin X {x ? topspace X. f x ? U})"</formula><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "A continuous map f : X ? Y is a map such that for every open set U ? Y , the preimage</p><formula xml:id="formula_13">f ?1 (U ) is open in X". lemma connectedin_separation: "connectedin X S ?? S ? topspace X ? (? C1 C2. C1 ? C2 = S ? C1 = {} ? C2 = {} ? C1 ? X closure_of C2 = {} ? C2 ? X closure_of C1 = {})" (is "?lhs = ?rhs")</formula><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "S is connected in X if and only if S ? X and there do not exist two non-empty sets C 1 and C 2 such that C 1 ? C 2 = S and C 1 ? XC 2 = ? and C 2 ? XC 1 = ?".</p><p>lemma connectedin_Union: assumes U: " S. S ? U =? connectedin X S" and ne: " U = {}" shows "connectedin X ( U)"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "If S is connected in X for all S ? U and S?U S = ?, then S?U S is connected in X".</p><formula xml:id="formula_14">lemma compact_space_alt: "compact_space X ?? (? U. (? U ? U. openin X U) ? topspace X ? U ?? (? F. finite F ? F ? U ? topspace X ? F))"</formula><p>Translate the Isabelle version to a natural language version: Translate the Isabelle version to a natural language version:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Codex Output:</head><p>"If X is a compact space and S is a closed subset of X, then S is a compact space". Translate the Isabelle version to a natural language version:</p><formula xml:id="formula_15">Codex Output: "If S is compact in X and f is continuous from X to Y , then f (S) is compact in Y ". lemma continuous_on_open: "continuous_on S f ?? (? T. openin (top_of_set (f ' S)) T ?? openin (top_of_set S) (S ? f -' T))"</formula><p>Translate the Isabelle version to a natural language version:   theorem Residue_theorem: fixes s pts::"complex set" and f::"complex ? complex" and g::"real ? complex" assumes "open s" "connected s" "finite pts" and holo:"f holomorphic_on s-pts" and "valid_path g" and loop:"pathfinish g = pathstart g" and "path_image g ? s-pts" and homo:" ? z. (z / ? s) ?? winding_number g z = 0" shows "contour_integral g f = 2 * pi * i *( p ?pts. winding_number g p * residue f p)"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let f be a holomorphic function on a connected open set S and let g be a closed path in S that does not pass through any of the points in the finite set P . Then g f (z)dz = 2?i p?P Res(f, p)".</p><formula xml:id="formula_16">theorem integer_winding_number: " [[path ?; pathfinish ? = pathstart ?; z / ? path_image ?]] =? winding_number ? z ? "</formula><p>Translate the Isabelle version to a natural language version: Codex Output: "Let ? be a closed path in the complex plane, and z be a point not on ?. Then the winding number of ? around z is an integer". Translate the Isabelle version to a natural language version: Codex Output: "Let ? be a closed path in the plane, and let w, z be two points in the plane. If ? does not pass through w or z, and w, z are in the same connected component of the plane, then the winding number of ? about w is the same as the winding number of ? about z". Translate the Isabelle version to a natural language version: Codex Output: "If ? is a path, s is a convex set, ? is a closed path, z is not in s, and ? is in s, then the winding number of ? around z is 0". theorem (in prob_space) central_limit_theorem_zero_mean: fixes X :: "nat ? 'a ? real" and ? :: "real measure" and ? :: real and S :: "nat ? 'a ? real" assumes X_indep: "indep_vars (?i. borel) X UNIV"</p><p>and X_mean_0: " n. expectation (X n) = 0" and ?_pos: " ? &gt; 0" and X_square_integrable: " n. integrable M (?x. (X n x) 2 )" and X_variance: " n. variance (X n) = ? 2 " and X_distrib: " n. distr M borel (X n) = ?" defines "S n ? ?x.</p><p>i&lt;n. X i x" shows "weak_conv_m (?n. distr M borel (?x. S n x / sqrt (n * ? 2 ))) std_normal_distribution"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let X 1 , X 2 , ? ? ? be a sequence of independent random variables with mean 0 and variance ? 2 . Let S n = n i=1 X i . Then S n / ? n? 2 converges in distribution to a standard normal distribution".</p><p>proposition compact_space_product_topology:</p><p>"compact_space(product_topology X I) ?? topspace(product_topology X I) = {} ? (? i ? I. compact_space(X i))"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "If X i is a compact space for all i ? I, then X 1 ? X 2 ? ? ? ? ? X n is a compact space".</p><p>Lemma statements in the remainder of this section are from the Topology entry in the AFP. <ref type="bibr" target="#b2">3</ref> All the natural language version is generated by the Codex model. Translate the Isabelle version to an natural language version: Codex Output: "If x is a limit point of a set A in a topological space T , then there exists a filter F such that x ? F and A ? F ."</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>theorem fixes a b ::real assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5" "(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7" shows "a * b = 512"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The two few-shot examplars used in case studies: both examples are merely an illustration of a syntactical translation from from L A T E Xto Isabelle, without much sophistication in natural language understanding or reasoning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Autoformalizations from natural language to Isabelle code. Left: Case study 2 -perfect formalization by PaLM. Right: Case study 3 -incorrect formalization by Codex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>theorem fixes b h</head><label></label><figDesc>v ::real assumes "0 &lt; b \&lt;and&gt; 0 &lt; h \&lt;and&gt; 0 &lt; v" and "v = 1 / 3 * (b * h)" and "b = 30" and "h = 13 / 2" shows "v = 65" Natural language version: "If 3a + b + c = ?3, a + 3b + c = 9, a + b + 3c = 19, then find abc. The final answer is -56". Translate the natural language version to an Isabelle version: theorem fixes a b c :: real assumes "3 * a + b + c = -3" and "a + 3 * b + c = 9" and "a + b + 3 * c = 19" shows "a * b * c = -56" Natural language version: "If f (x) = 5x ? 12, find a value for x so that f ?1 (x) = f (x + 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>theorem fixes a b :: real and f :: "real \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;And&gt;x. f x = a * x + b" and h1 : "f 7 = 4" and h2 : "f 6 = 3" shows "f 3 = 0" Natural language version: "Given 2 a = 32 and a b = 125 find b a . The final answer is 243". Translate the natural language version to an Isabelle version: theorem fixes a b :: real assumes "2 powr a = 32" and "a powr b = 125" shows "b powr a = 243" Natural language version: "Let f (x) = x 2 + 9 if x &lt; ?5, 3x ? 8 if x ? ?5. If f (x) = 10, find the sum of all possible values of x. The final answer is 6". Translate the natural language version to an Isabelle version: theorem fixes f :: "real \&lt;Rightarrow&gt; real" assumes "\&lt;forall&gt; x &lt; -5. f x = x^2 + 5" and "\&lt;forall&gt; x \&lt;ge&gt; -5. f x = 3 * x -8" shows "(\&lt;Sum&gt; k \&lt;in&gt; (f -' {10}). k) = 6" Natural language version: "Simplify (9 ? 4i) ? (?3 ? 4i). The final answer is 12". Translate the natural language version to an Isabelle version: theorem fixes q e :: complex assumes h0 : "q = Complex (Re 9) (Im (-4))" and h1 : "e = Complex (Re (-3)) (Im (-4))" shows "q -e = 12" Natural language version: "What is the minimum possible value for y in the equation y = x 2 ? 6x + 13? The final answer is 4". Translate the natural language version to an Isabelle version: theorem fixes x y :: real assumes h0 : "y = x^2 -6 * x + 13" shows "4 \&lt;le&gt; y" A.2 Prompt used to formalize number theory problems Natural language version: "If n is a positive integer such that 2n has 28 positive divisors and 3n has 30 positive divisors, then how many positive divisors does 6n have? The final answer is 35". Translate the natural language version to an Isabelle version: theorem fixes n :: nat assumes "n&gt;0" and "card ({k. k dvd (2*n)}) = 28" and "card ({k. k dvd (3*n)}) = 30" shows "card ({k. k dvd (6*n)}) = 35" Natural language version: "Let n be the number of integers m in the range 1 ? m ? 8 such that gcd(m, 8) = 1. What is the remainder when 3 n is divided by 8? The final answer is 1". Translate the natural language version to an Isabelle version: theorem fixes n :: nat assumes "n = card {k::nat. gcd k 8 = 1 \&lt;and&gt; 1\&lt;le&gt;k \&lt;and&gt; k &lt; 8}" shows "(3^n) mod 8 = (1::nat)"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>\&lt;Sum&gt; k \&lt;in&gt; {1..&lt;p-1}. (inv_mod k p)* (inv_mod (k+1) p)) = 2" Natural language version: "What is the remainder when 2000+2001+2002+2003+2004+ 2005 + 2006 is divided by 7? The final answer is 0". Translate the natural language version to an Isabelle version: theorem "(2000 + 2001 + 2002 + 2003 + 2004 + 2005 + 2006) mod 7 = (0::nat)"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>theorem fixes a b ::real assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5" "(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7" shows "a * b = 512" Translate the Isabelle version to a natural language version: "Determine the value of ab if log 8 a + log 4 b 2 = 5 and log 8 b + log 4 a 2 = 7. The final answer is 512". B More on case Studies B.1 Case Study 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3." Translate the natural language version to an Isabelle version: PaLM 540B output: theorem fixes n::nat assumes "n mod 8 = 7" shows "n mod 4 = 3" Question: Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3." Translate the natural language version to an Isabelle version: PaLM 64B output: theorem fixes girls :: nat assumes "(girls / 8) + 7 = girls" shows "girls = 3" Question: Natural Language version: "When all the girls at Madeline's school line up in rows of eight, there are seven left over. If instead they line up in rows of four, how many are left over? The final answer is 3." Translate the natural language version to an Isabelle version: PaLM 8B output: theorem fixes a b ::real assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 7" "(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 3"}} shows "a * b = 3"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>theorem fixes a b :: real and f :: "real \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;And&gt;x. f x = a * x + b" and h1 : "f 7 = 4" and h2 : "f 6 = 3" shows "f 3 = 0" Then Codex was able to formalize the problem perfectly: Question: Natural language version: "Let f be a linear function for which f (6) ? f (2) = 12. What is f (12) ? f (2)? The final answer is 30." Translate the natural language version to an Isabelle version: Codex Output: theorem fixes a b :: real and f :: "real \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;And&gt;x. f x = a * x + b" and h1 : "f 6 -f 2 = 12" shows "f 12 -f 2 = 30"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>C. 1</head><label>1</label><figDesc>Perfect Translations Question: Natural language version: "At what point does the line containing the points (1, 7) and (3, 11) intersect the y-axis? Express your answer as an ordered pair. The final answer is (0,5)". Translate the natural language version to an Isabelle version: Codex Output: theorem fixes a b :: real and f :: "real \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;And&gt;x. f x = a * x + b" and h1 : "f 1 = 7" and h2 : "f 3 = 11" shows "f 0 = 5"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>c :: "real \&lt;times&gt; real" assumes h0 : "a = (6, -20)" and h1 : "b = (1, 14)" and h2 : "c = (7 / 2, 2)" shows "dist a c + dist b c = 5"Question: Natural language version: "Let x be a positive integer, and define the integers n = x 2 + 2x + 17 and d = 2x + 5. When dividing n by d, the quotient is x, and the remainder is 7. Find x. The final answer is 2".Codex Output:theorem fixes x n d :: int assumes h0 : "x &gt; 0" and h1 : "n = x^2 + 2 * x + 17" and h2 : "d = 2 * x + 5" and h3 : "n div d = x" and h4 : "n mod d = 7" shows "x = 2"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Natural language version: "Let f (x) = x 2 ? 2x. How many distinct real numbers c satisfy f (f (f (f (c)))) = 3? The final answer is 9". Codex Output: theorem fixes f :: "real \&lt;Rightarrow&gt; real" assumes h0 : "\&lt;forall&gt; x. f x = x^2 -2 * x" shows "card {c. f (f (f (f c))) = 3} = 9" Question: Natural language version: "Find the solutions to z 4 = ?4. Enter the solutions, separated by commas. The final answer is 1 + i, 1 -i, -1 + i, -1 -i". Codex Output: theorem fixes z :: complex assumes "z^4 = -4" shows "z = 1 + \&lt;i&gt; \&lt;or&gt; z = 1 -\&lt;i&gt; \&lt;or&gt; z = -1 + \&lt;i&gt; \&lt;or&gt; z = -1 -\&lt;i&gt;"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Codex Output: theorem fixes m n :: nat assumes "m = (LEAST k. card {d. d dvd k \&lt;and&gt; d &gt; 0} = 2)" and "n = (GREATEST k. card {d. d dvd k \&lt;and&gt; d &gt; 0} = 3 \&lt;and&gt; k &lt; 100)" shows "m + n = 51"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Error category: wrong application of functions Question: Natural language version: "If the operation Z is defined as aZb = b + 10a ? a 2 , what is the value of 2Z6? The final answer is 22". Codex Output: theorem fixes a b :: real assumes h0 : "a Z b = b + 10 * a -a^2" shows "2 Z 6 = 22"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>theorem fixes n :: nat assumes "n \&lt;le&gt; 150" shows "card {k::nat. k \&lt;le&gt; n \&lt;and&gt; \&lt;not&gt; (\&lt;exists&gt; m. m^2 = k \&lt;or&gt; m^3 = k) } = 135" The translator somehow introduces an unnecessary variable n and assumed "n \&lt;le&gt; 150". The correct translation should have n replaced with 150 in the conclusion: "card {k::nat. k \&lt;le&gt; D More Examples on Advanced Mathematics D.1 Formalization Question: Natural language version: "Let f be a continuous function from a compact convex set S to itself. Then there exists x ? S such that f (x) = x." Translate the natural language version to an Isabelle version: Codex Output: theorem fixes f :: "'a::real_normed_vector \&lt;Rightarrow&gt; 'a" assumes "continuous_on S f" "compact S" "convex S" shows "\&lt;exists&gt;x\&lt;in&gt;S. f x = x"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>proposition openin_clauses:fixes U :: "'a topology" shows "openin U {}" " S T. openin U S =? openin U T =? openin U (S ?T)"" K. (? S ? K. openin U S) =? openin U ( K)"Translate the Isabelle version to a natural language version:Codex Output: Let $U$ be a topology, then $U$ is open if and only if it satisfies the following conditions: 1. $U$ is open. 2. If $S$ and $T$ are open, then $S \cap T$ is open. 3. If $K$ is a collection of open sets, then $\cup K$ is open.lemma openin_Int[intro]: "openin U S =? openin U T =? openin U (S ? T)"Translate the Isabelle version to a natural language version:Codex Output: "Let U be a topology, then ? is open in U , if S and T are open in U , then S ? T is open in U , if K is a collection of sets, and each set in K is open in U , then K is open in U ". lemma openin_Int[intro]: "openin U S =? openin U T =? openin U (S ? T)" Translate the Isabelle version to a natural language version: Codex Output: "If S and T are open in U , then S ? T is open in U ". lemma openin_Inter [intro]: assumes "finite F" " F = {}" " X. X ? F =? openin T X" shows "openin T ( F)" Translate the Isabelle version to a natural language version: Codex Output: "If T is a topological space, and F is a finite non-empty collection of open subsets of T , then F is open in T ". lemma openin_subtopology: "openin (subtopology U V) S ?? (? T. openin U T ? S = T ? V)" Translate the Isabelle version to a natural language version: Codex Output: "S is open in the subtopology of U induced by V if and only if there exists an open set T in U such that S = T ? V ". lemma closedin_subtopology_Un: " [[closedin (subtopology X T) S; closedin (subtopology X U) S ]] =? closedin (subtopology X (T ? U)) S"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>lemma compactin_discrete_topology: "compactin (discrete_topology X) S ?? S ? X ? finite S"Translate the Isabelle version to a natural language version:Codex Output: "S is compact in the discrete topology on X if and only if S is a finite subset of X".lemma image_compactin: assumes cpt: "compactin X S" and cont: "continuous_map X Y f" shows "compactin Y (f ' S)"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>continuous on S if and only if for any open set T in f (S), f ?1 (T ) is open in S".lemma continuous_closedin_preimage_gen: assumes "continuous_on S f" "f ' S ? T" "closedin (top_of_set T) U" shows "closedin (top_of_set S) (S ? f -' U)" Translate the Isabelle version to a natural language version: Codex Output: "If f is continuous on S and f (S) ? T , and U is closed in T , then S ? f ?1 (U ) is closed in S".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>theorem Casorati_Weierstrass: assumes "open M" "z ? M" "f holomorphic_on (M -{z})" and " l. ? (f ? ?? ? l) (at z)" " l. ? ((inverse ? f) ? ?? ? l) (at z)" shows "closure(f ' (M -{z})) = UNIV"Translate the Isabelle version to a natural language version:Codex Output: "Let f be a holomorphic function on an open set M containing z. If f is not constant in any neighborhood of z and f ?1 is not constant in any neighborhood of z, then f (M ? {z}) is dense in C".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>theorem assumes "open M" "z ? M" "f holomorphic_on (M -{z})" and " l. ? (f ? ?? ? l) (at z)" " l. ? ((inverse ? f) ? ?? ? l) (at z)" shows "closure(f ' (M -{z})) = UNIV"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>lemma winding_number_eq: " [[path ?; pathfinish ? = pathstart ?; w ? S; z ? S; connected S; S ? path_image ? = {}]] =? winding_number ? w = winding_number ? z"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>corollary winding_number_zero_outside: " [[path ?; convex s; pathfinish ? = pathstart ?; z / ? s; path_image ? ? s ]] =? winding_number ? z = 0"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>lemma seteqI: " [[ x. x ?A =? x ?B; x. x ?B =? x ?A ]] =? A = B" Translate the Isabelle version to a natural language version: Codex Output: "If A and B are sets such that A ? B and B ? A, then A = B." lemma (in carrier) openI: "m ? T =? m open" Translate the Isabelle version to a natural language version: Codex Output: "If m is a topology on a set T , then m is open." lemma (in carrier) openE: " [[ m open; m ? T =? R ]] =? R" Translate the Isabelle version to a natural language version: Codex Output: "If m is an open set in a topological space T , then m ? T ." lemma (in topology) open_kriterion: assumes t_contains_open: " x. x ?t =? ? t'. t' open ? x ?t' ? t'?t" shows "t open" Translate the Isabelle version to a natural language version: Codex Output: "If t is a subset of a topological space T such that for every x ? t, there exists an open set t ? such that x ? t ? and t ? ? t, then t is open." lemma (in carrier) carrierI [intro]: " [[ t open; x ? t ]] =? x ? carrier" Translate the Isabelle version to a natural language version: "If t is an open set in a topological space T and x ? t, then x ? T ." lemma (in topology) Un_open [intro!]: assumes abopen: "A open" "B open" shows "A ? B open" Translate the Isabelle version to a natural language version: Codex Output: "If A and B are open sets in a topological space T , then A ? B is open."lemma topologyI: " [[ x y. [[ is_open T x; is_open T y ]] =? is_open T (x ? y); M. ? m ? M. is_open T m =? is_open T ( M) ]] =? topology T"Translate the Isabelle version to a natural language version:Codex Output: "If T is a set and T is closed under finite intersections and arbitrary unions, then T is a topology."lemma (in topobase) topo_open: "t open = (t ? topo B)" Translate the Isabelle version to a natural language version: Codex Output: "If B is a topological base of a topological space T , then t is open if and only if t ? B." lemma (in topobase) topo_induct [case_names basic inter union, induct set: topo, consumes 1]: assumes opn: "x open" and bas: " x. x ? B =? P x" and int: " x y. [[x open; P x; y open; P y ]] =? P (x ? y)" and uni: " M. (? t ?M. t open ? P t) =? P ( M)" shows "P x" Translate the Isabelle version to an natural language version: Codex Output: "If B is a topological base of a topological space T , then P (x) holds for all open sets x if P (x) holds for all x ? B and P (x) is closed under finite intersections and arbitrary unions." lemma subtopologyI: fixes S (structure) fixes T (structure) assumes H1: " s. s open =? ? t. t open T ? s = t ? carrier" and H2: " t. t open T =? t ? carrier open" shows "subtopology S T" Translate the Isabelle version to an natural language version: Codex Output: "If S is a subset of a topological space T such that for every open set s in S, there exists an open set t in T such that s = t ? S and for every open set t in T , t ? S is open in S, then S is a subspace of T ." lemma (in subtopology) subtopologyE [elim]: assumes major: "s open" and minor: " t. [[ t open T ; s = t ? carrier ]] =? R" shows "R" Translate the Isabelle version to an natural language version: Codex Output: "If s is an open set in a topological space T , then s is an open set in a subspace S of T if and only if s = t ? S for some open set t in T ." lemma continuousI: fixes S (structure) fixes T (structure) assumes "f : carrier S ? carrier T " " m. m open T =? carrier ? (f -' m) open" shows "continuous f S T" Translate the Isabelle version to an natural language version: Codex Output: "If f is a function from a topological space S to a topological space T such that the preimage of every open set in T is open in S, then f is continuous." lemma continuousE: fixes S (structure) fixes T (structure) shows " [[continuous f S T; [[f : carrier S ? carrier T ; ? m. m open T ?? carrier S ? (f -' m) open ]] =? P ]] =? P"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>BLEU scores between the autoformalized statements and human formalized ground truth.</figDesc><table><row><cell cols="3">Models \ Subject algebra number_theory PaLM 8B 31.49 22.10</cell></row><row><cell>PaLM 64B</cell><cell>43.13</cell><cell>31.43</cell></row><row><cell>PaLM 540B</cell><cell>50.30</cell><cell>36.16</cell></row><row><cell>Codex</cell><cell>57.13</cell><cell>43.33</cell></row><row><cell cols="3">formalize correctly. Codex assumes this is already a known concept in Isabelle, and made up a name:</cell></row><row><cell cols="3">linear f. Can the model learn to formalize such problems if the prompt contains an example that</cell></row><row><cell cols="3">explains the concept of a line? We explore this and give an affirmative answer to the question (see</cell></row><row><cell cols="3">Appendix B.3). Once seeing a tangentially related problem that explains the concept of a "line",</cell></row><row><cell cols="3">Codex is able to perfectly formalize a "linear function". This shows the importance of the few shot</cell></row><row><cell cols="3">examples we include, and also how good a few-shot learners these models are!</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Failure case study of 150 problems formalized by Codex.</figDesc><table><row><cell>Failure cases \ Subjects Perfect translation</cell><cell cols="3">algebra number_theory inter_alg 13 17 8</cell></row><row><cell>Incomplete/ill-formed/unclear prompt</cell><cell>9</cell><cell>3</cell><cell>14</cell></row><row><cell>Fail to align definitions or concepts</cell><cell>10</cell><cell>18</cell><cell>18</cell></row><row><cell>Inconsistent/missing assumption</cell><cell>8</cell><cell>9</cell><cell>9</cell></row><row><cell>Syntactical/type error</cell><cell>7</cell><cell>2</cell><cell>11</cell></row><row><cell>Missing definition in Isabelle</cell><cell>0</cell><cell>12</cell><cell>3</cell></row><row><cell>Wrong application of functions</cell><cell>6</cell><cell>13</cell><cell>16</cell></row><row><cell>Other</cell><cell>6</cell><cell>2</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Proof success rates on miniF2F.</figDesc><table><row><cell>Model</cell><cell>valid</cell><cell>test</cell></row><row><cell>PACT [21]</cell><cell cols="2">23.9% 24.6%</cell></row><row><cell>FMSCL [38]</cell><cell cols="2">33.6% 29.6%</cell></row><row><cell>Base model (M 0 ) [26]</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Codex Output: "A topological space X is compact if and only if for every open cover U of X, there exists a finite subcover F of U". "T is compact in S if and only if T is compact in X and T ? S".</figDesc><table><row><cell>lemma compactin_subtopology:</cell></row><row><cell>"compactin (subtopology X S) T ?? compactin X T ? T ? S"</cell></row><row><cell>Translate the Isabelle version to a natural language version:</cell></row><row><cell>Codex Output:</cell></row><row><cell>lemma closedin_compact_space:</cell></row><row><cell>" [[compact_space X; closedin X S ]] =? compactin X S"</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://artofproblemsolving.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A problem from IMO 1987.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="150">\&lt;and&gt; \&lt;not&gt; (\&lt;exists&gt; m. m^2 = k \&lt;or&gt; m^3 = k)} = 135".</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.isa-afp.org/browser_info/current/AFP/Topology/Topology.html</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Translate the Isabelle version to a natural language version: Translate the Isabelle version to a natural language version: Codex Output: "Let f be a continuous function from a compact convex set S to itself. Then there exists x ? S such that f (x) = x". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Translate the Isabelle version to a natural language version:</head><p>Codex Output: "If c is a simple closed curve, then R 2 ? c is not connected".</p><p>theorem inverse_squares_sums:</p><p>Translate the Isabelle version to a natural language version:</p><p>. The final answer is ? 2 6 ".</p><p>proposition connected_space_product_topology:</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "The product topology of a family of topological spaces is connected if and only if the product of the topological spaces is empty or each topological space is connected". Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let X be a set of open sets in a second countable topology. Then the Borel ?-algebra is the ?-algebra generated by X".</p><p>theorem borel_measurable_ereal_iff_real:</p><p>Translate the Isabelle version to a natural language version: theorem ratio_test_convergence: fixes f :: "nat ? real" assumes pos_f: "eventually (?n. f n &gt; 0) sequentially" defines "l ? liminf (?n. ereal (f n / f (Suc n)))" assumes l: "l &gt; 1"</p><p>shows "summable f"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let f be a positive function, and let l be the limit inferior of the sequence f (n) f (n+1) . If l &gt; 1, then f is summable".</p><p>theorem Stone_Weierstrass_polynomial_function:</p><p>fixes f :: "'a::euclidean_space ? 'b::euclidean_space" assumes S: "compact S" and f: "continuous_on S f" and e: "0 &lt; e" shows " ? g. polynomial_function g ? (? x ? S. norm(f x -g x) &lt; e)"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Translate the Isabelle version to a natural language version:</head><p>Codex Output: "Let f be a continuous function on a compact set S. Then there exists a polynomial function g such that ?x ? S, |f (x) ? g(x)| &lt; ?. Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let S be a simply connected open set. Then S is either empty, the whole plane, or there exists a holomorphic function f from S to the unit disk and a holomorphic function g from the unit disk to S such that g ? f is the identity function on S and f ? g is the identity function on the unit disk."</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "Let ? be a closed path, then there exists a constant B such that for all z, if |z| &gt; B, then the winding number of ? at z is 0". lemma winding_number_homotopic_paths: assumes "homotopic_paths (-{z}) g h" shows "winding_number g z = winding_number h z"</p><p>Translate the Isabelle version to a natural language version:</p><p>Codex Output: "If g and h are homotopic paths in C ? {z}, then the winding number of g around z is equal to the winding number of h around z".</p><p>lemma simple_closed_path_winding_number_cases: assumes "simple_path ?" "pathfinish ? = pathstart ?" "z / ? path_image ?" shows "winding_number ? z ? {-1,0,1}" Translate the Isabelle version to a natural language version: Codex Output: "If ? is a simple closed path, z is not in the image of ?, then the winding number of ? at z is either -1, 0 or 1". corollary Cauchy_theorem_primitive:</p><p>assumes " x. x ? S =? (f has_field_derivative f' x) (at x within S)" and "valid_path g" "path_image g ? S" "pathfinish g = pathstart g" shows "(f' has_contour_integral 0) g" Translate the Isabelle version to a natural language version: Codex Output: "If f is a function with a derivative f ? on a set S, and g is a closed path in S, then g f ? (z)dz = 0".</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepmath -deep sequence models for premise selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>E?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6280-deepmath-deep-sequence-models-for-premise-selection" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<editor>Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="2235" to="2243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hindsight experience replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dwight</forename><surname>Crow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/453fadbd8a1a3af50a9df4df899537b5-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5048" to="5058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Thinking fast and slow with deep learning and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/d8e1344e27a5b08cdfd5d027d9b8d6de-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5360" to="5370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Proving theorems using incremental learning and hindsight experience replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eser</forename><surname>Ayg?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Orseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Firoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibl</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mourad</surname></persName>
		</author>
		<idno>abs/2112.10664</idno>
		<ptr target="https://arxiv.org/abs/2112.10664" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning to reason in large theories without imitation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1905.10501" />
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Holist: An environment for machine learning of higher order logic theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Wilcox</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v97/bansal19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<title level="m">NeurIPS</title>
		<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>and Dario Amodei. Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidy</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alethea</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Tillet</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2107.03374" />
	</analytic>
	<monogr>
		<title level="j">Felipe Petroski Such</title>
		<imprint>
			<publisher>Vedant Misra</publisher>
		</imprint>
	</monogr>
	<note>Joshua Achiam. and Wojciech Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">PaLM: Scaling language modeling with pathways</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensen</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parker</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodkumar</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.02311</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2204.02311" />
		<editor>Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern</editor>
		<imprint>
			<publisher>CoRR</publisher>
			<pubPlace>Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick; Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems. CoRR, abs/2110.14168</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.14168" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The Coq Proof Assistant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coq</surname></persName>
		</author>
		<ptr target="http://coq.inria.fr.URLhttp://coq.inria.fr" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The lean theorem prover (system description)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Mendon?a De Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soonho</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Avigad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Floris</forename><surname>Van Doorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Von Raumer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-21401-6_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-21401-6_26" />
	</analytic>
	<monogr>
		<title level="m">Automated Deduction -CADE-25 -25th International Conference on Automated Deduction</title>
		<editor>Amy P. Felty and Aart Middeldorp</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">9195</biblScope>
			<biblScope unit="page" from="378" to="388" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noa</forename><surname>Nabeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shawn</forename><surname>Presser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<title level="m">The Pile: An 800gb dataset of diverse text for language modeling</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tactictoe: Learning to prove with tactics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramana</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10817-020-09580-x</idno>
		<ptr target="https://doi.org/10.1007/s10817-020-09580-x" />
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reason</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The four colour theorem: Engineering of a formal proof</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georges</forename><surname>Gonthier</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-87827-8\_28</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Mathematics, 8th Asian Symposium, ASCM</title>
		<editor>Deepak Kapur</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007-12-15" />
			<biblScope unit="volume">5081</biblScope>
			<biblScope unit="page">333</biblScope>
		</imprint>
	</monogr>
	<note>Revised and Invited Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A machine-checked proof of the odd order theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georges</forename><surname>Gonthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Asperti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Avigad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Bertot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Garillot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Le Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assia</forename><surname>Mahboubi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidi</forename><forename type="middle">Ould</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioana</forename><surname>Biha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Rideau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Solovyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Tassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Th?ry</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-39634-2\_14</idno>
	</analytic>
	<monogr>
		<title level="m">Interactive Theorem Proving -4th International Conference, ITP 2013</title>
		<editor>Sandrine Blazy, Christine Paulin-Mohring, and David Pichardie</editor>
		<meeting><address><addrLine>Rennes, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">7998</biblScope>
			<biblScope unit="page" from="163" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Teaching temporal logics to neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederik</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><forename type="middle">U</forename><surname>Kreber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Finkbeiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A formal proof of the Kepler conjecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gertrud</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat Dat</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Hoang Le Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Magron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thang Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Forum of Mathematics, Pi</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2017" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Unsupervised neural machine translation with generative language models only</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>abs/2110.05448</idno>
		<ptr target="https://arxiv.org/abs/2110.05448" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Proof artifact co-training for theorem proving with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rpxJc9j04U" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A tutorial introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Light</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Methods in Computer-Aided Design, First International Conference, FMCAD &apos;96</title>
		<editor>Mandayam K. Srivas and Albert John Camilleri</editor>
		<meeting><address><addrLine>Palo Alto, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">1166</biblScope>
			<biblScope unit="page" from="265" to="269" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Measuring mathematical problem solving with the MATH dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno>abs/2103.03874</idno>
		<ptr target="https://arxiv.org/abs/2103.03874" />
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models. CoRR, abs/2203.15556</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simonyan</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2203.15556</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2203.15556" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
			<pubPlace>Erich Elsen, Jack W. Rae</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lisa</surname></persName>
		</author>
		<title level="m">Language models of isabelle proofs. 6th Conference on Artificial Intelligence and Theorem Proving</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Thor: Wielding hammers to integrate language models and automated theorem provers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szymon Tworkowski Wenda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Czechowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Odrzyg??d?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Mi?o?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateja</forename><surname>Jamnik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10893</idno>
		<ptr target="https://arxiv.org/abs/2205.10893" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Harvey Tuch, and Simon Winwood. seL4: formal verification of an OS kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerwin</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Elphinstone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">June</forename><surname>Andronick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Derrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhammika</forename><surname>Elkaduwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Kolanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Sewell</surname></persName>
		</author>
		<idno type="DOI">10.1145/1629575.1629596</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM Symposium on Operating Systems Principles</title>
		<editor>Jeanna Neefe Matthews and Thomas E. Anderson</editor>
		<meeting>the 22nd ACM Symposium on Operating Systems Principles<address><addrLine>Big Sky, Montana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-10-11" />
			<biblScope unit="page" from="207" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Formally verified software in the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerwin</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">June</forename><surname>Andronick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ihor</forename><surname>Kuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><forename type="middle">C</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Heiser</surname></persName>
		</author>
		<idno type="DOI">10.1145/3230627</idno>
		<ptr target="https://doi.org/10.1145/3230627" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Generating symbolic reasoning problems with transformer GANs. CoRR, abs/2110.10054, 2021</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><forename type="middle">U</forename><surname>Kreber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hahn</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.10054" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised machine translation using monolingual corpora only</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkYTTf-AZ" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning heuristics for quantified boolean formulas through reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gil</forename><surname>Lederman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjit</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJluxREKDB" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agustin</forename><forename type="middle">Dal</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Choy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Koray Kavukcuoglu, and Oriol Vinyals</title>
		<editor>Cyprien de Masson d&apos;Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli</editor>
		<imprint>
			<date type="published" when="2022" />
			<publisher>Nando de Freitas</publisher>
		</imprint>
	</monogr>
	<note>Competitionlevel code generation with alphacode. DeepMind</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep network guided proof search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<idno type="DOI">10.29007/8mwc</idno>
		<ptr target="https://doi.org/10.29007/8mwc" />
	</analytic>
	<monogr>
		<title level="m">LPAR-21, 21st International Conference on Logic for Programming, Artificial Intelligence and Reasoning</title>
		<editor>Thomas Eiter and David Sands</editor>
		<meeting><address><addrLine>Maun, Botswana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="85" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Skq89Scxx" />
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Bkg6RiCqY7" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Three years of experience with sledgehammer, a practical link between automatic and interactive theorem provers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Paulson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmin</forename><surname>Blanchette</surname></persName>
		</author>
		<idno type="DOI">10.29007/tnfd</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">02</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>abs/2009.03393</idno>
		<ptr target="https://arxiv.org/abs/2009.03393" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Mantas Baksys, Igor Babuschkin, and Ilya Sutskever. Formal mathematics statement curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhao</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2202.01344" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Mathematical reasoning via self-supervised skip-tree training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural circuit synthesis from specification patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederik</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Finkbeiner</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2021/hash/8230bea7d54bcdf99cdfe85cb07313d5-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021</title>
		<editor>Marc&apos;Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021-12-06" />
			<biblScope unit="page" from="15408" to="15420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning search control knowledge for equational theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-45422-5\_23</idno>
	</analytic>
	<monogr>
		<title level="m">KI 2001: Advances in Artificial Intelligence, Joint German/Austrian Conference on AI</title>
		<editor>Franz Baader, Gerhard Brewka, and Thomas Eiter</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2174</biblScope>
			<biblScope unit="page" from="320" to="334" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p16-1009</idno>
		<ptr target="https://doi.org/10.18653/v1/p16-1009" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>: Long Papers. The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A promising path towards autoformalization and general artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-53518-6_1</idno>
		<idno>doi: 10.1007/ 978-3-030-53518-6\_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-53518-6_1" />
	</analytic>
	<monogr>
		<title level="m">Intelligent Computer Mathematics -13th International Conference</title>
		<editor>Christoph Benzm?ller and Bruce R. Miller</editor>
		<meeting><address><addrLine>Bertinoro, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">MPTP -motivation, implementation, first experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10817-004-6245-1</idno>
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reason</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="319" to="339" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
		<editor>Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://github.com/kingoflolz/mesh-transformer-jax" />
		<title level="m">Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX</title>
		<imprint>
			<date type="published" when="2021-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">First experiments with neural translation of informal to formal mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-96812-4_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-96812-4_22" />
	</analytic>
	<monogr>
		<title level="m">Intelligent Computer Mathematics -11th International Conference, CICM 2018</title>
		<editor>Florian Rabe, William M. Farmer, Grant O. Passmore, and Abdou Youssef</editor>
		<meeting><address><addrLine>Hagenberg, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">11006</biblScope>
			<biblScope unit="page" from="255" to="270" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Exploration of neural machine translation in autoformalization of mathematics in mizar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chad</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Certified Programs and Proofs</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The Isabelle framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makarius</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">C</forename><surname>Paulson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Nipkow</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-71067-7\_7</idno>
	</analytic>
	<monogr>
		<title level="m">Theorem Proving in Higher Order Logics, 21st International Conference</title>
		<editor>Otmane A?t Mohamed, C?sar A. Mu?oz, and Sofi?ne Tahar</editor>
		<meeting><address><addrLine>TPHOLs; Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008-08-18" />
			<biblScope unit="volume">5170</biblScope>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to prove theorems from scratch with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minchao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Walder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tacticzero</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2021/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021</title>
		<editor>Marc&apos;Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021-12-06" />
			<biblScope unit="page" from="9330" to="9342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">INT: an inequality benchmark for evaluating generalization in theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Baker Grosse</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=O6LPudowNQm" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Memorizing transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delesley</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Learning Representations, ICLR 2022. OpenReview.net</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Jordan_disconnected: fixes c :: &quot;real ? complex&quot; assumes &quot;simple_path c</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.00110</idno>
	</analytic>
	<monogr>
		<title level="m">MiniF2F: a cross-system benchmark for formal olympiad-level mathematics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>lemma mvt_simple: fixes f :: &quot;real ? real&quot; assumes &quot;a &lt; b&quot; and derf. x. [[a ? x; x ? b</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">shows &quot; ? x ?{a&lt;..&lt;b}. f b -f a = f&apos; x (b -a)</title>
	</analytic>
	<monogr>
		<title level="m">lemma winding_number_zero_at_infinity: assumes ?: &quot;path ?&quot; and loop: &quot;pathfinish ? = pathstart ?&quot; shows &quot; ? B. ? z. B ? norm z ?? winding_number ? z = 0</title>
		<imprint/>
	</monogr>
	<note>=? (f has_derivative f&apos; x) (at x within {a..b})</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
