<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generalizable Method for Face Anti-Spoofing with Semi-Supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Sergievskiy</surname></persName>
							<email>nikolay@getentry.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xix</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Vlasov</surname></persName>
							<email>romanvlasov@getentry.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xix</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Trusov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xix</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">Generalizable Method for Face Anti-Spoofing with Semi-Supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Face anti-spoofing has drawn a lot of attention due to the high security requirements in biometric authentication systems. Bringing face biometric to commercial hardware became mostly dependent on developing reliable methods for detecting fake login sessions without specialized sensors. Current CNN-based method perform well on the domains they were trained for, but often show poor generalization on previously unseen datasets. In this paper we describe a method for utilizing unsupervised pretraining for improving performance across multiple datasets without any adaptation, introduce the Entry Antispoofing Dataset for supervised fine-tuning, and propose a multi-class auxiliary classification layer for augmenting the binary classification task of detecting spoofing attempts with explicit interpretable signals. We demonstrate the efficiency of our model by achieving state-of-the-art results on cross-dataset testing on MSU-MFSD, Replay-Attack, and OULU-NPU datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Biometric authentication systems based on face recognition are taking prominence in both everyday life and highvalue transactions with strong security requirements. However, despite the recent advances in computer vision, these systems are still confined to specialized hardware that utilizes depth or NIR sensors for preventing Presentation Attacks. Among the Presentation Attacks, print and replay attacks are the most common, and detecting them became an important problem in the field of biometric authentication. From the practical application perspective, developing a robust algorithm for detecting such attacks on commercial webcams using only signals from the video stream would enable wide adoption of face-based authentication and verification.</p><p>Recently published results show that deep learningbased models can achieve good results on the datasets they were trained on <ref type="bibr" target="#b16">[17]</ref>  <ref type="bibr" target="#b13">[14]</ref>  <ref type="bibr" target="#b7">[8]</ref>, but the generalization to other datasets is not so easily achieved -i.e. when the model that achieved a state-of-the-art result on benchmark A is tested on benchmark B (the protocol we will be referring to as "cross-test"), the discrepancy in scores is quite significant, even with the latest breakthroughs in domain adaptation that were aimed to address this problem. The consequences of such discrepancy in the real world are quite damaging for the application security.</p><p>The key motivation behind this work is that achieving strong generalization on cross-testing on multiple string benchmarks would reliably reflect the effectiveness of the algorithm in the wild. We propose to achieve this generalization by changing the approach to collecting training data. Moreover, motivated by the previous work in selfsupervised learning <ref type="bibr" target="#b2">[3]</ref> [7], we experiment with the network pretraining on larger datasets to improve the results further.</p><p>To validate the effectiveness of the developed method, we report the evaluation results in two experimental settings: intra-dataset test is evaluated on a test portion of our internal dataset, and cross-test is evaluated on well-known and established benchmarks: MSU-MFSD <ref type="bibr" target="#b15">[16]</ref>, Replay-Attack <ref type="bibr" target="#b3">[4]</ref>, and OULU-NPU [2].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Contribution</head><p>In this paper we present the following results:</p><p>1. Large-scale dataset with additional semantic annotation for training anti-spoofing models, together with an efficient approach to labeled data collection.</p><p>2. Effectiveness of task-agnostic unsupervised pretraining and explicitly defined spoofing attributes as a part of training objective.</p><p>3. New state of the art results on MSU-MFSD <ref type="bibr" target="#b15">[16]</ref> and Replay-Attack <ref type="bibr" target="#b3">[4]</ref> cross-dataset tests (with the results surpassing even the best intra-tests), and cross-test on OULU-NPU <ref type="bibr" target="#b1">[2]</ref>. Most importantly, we demonstrate consistently strong results across the most difficult face anti-spoofing benchmarks, which indicates low degree of domain overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Recent publications on task-agnostic self-supervised and semi-supervised pretraining show that using large unla-beled datasets for unsupervised pretraining followed by supervised fine-tuning is capable of outperforming standard supervised learning methods <ref type="bibr" target="#b2">[3]</ref>  <ref type="bibr" target="#b6">[7]</ref>. This is especially promising for the field of face anti-spoofing, where the problem of lack of comprehensive labeled datasets suitable for building models viable for security applications is especially severe. There have been efforts to alleviate this problem with using rich semantic annotations <ref type="bibr" target="#b17">[18]</ref>. Alternative paradigms of circumventing the data shortage by domain adaptation and generating synthetic data were demonstrated by <ref type="bibr" target="#b14">[15]</ref>  <ref type="bibr" target="#b7">[8]</ref>, citing the problem of domain shift as one of the most critical for anti-spoofing.</p><p>The main problem of existing methods is still in the domain shift and the lack of generalization between different datasets, as shown in cross-dataset tests, even in works that demonstrate state-of-the-art results on intra-dataset tests <ref type="bibr" target="#b14">[15]</ref> [8] <ref type="bibr" target="#b13">[14]</ref> [17].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Entry Antispoofing Dataset</head><p>Existing datasets for face anti-spoofing cover too narrow a domain, compared to the diversity of camera/lighting/distance/attack conditions seen in the real world. While achieving low error scores on open-source benchmarks using a cross-dataset protocol is indicative of good performance of a network under some subset of conditions, it turned out to be an unreliable predictor of the stability and accuracy when used in a real application. Specifically, regardless of the Attack Presentation Classification Error Rate (APCER) and Bona Fide Presentation Classification Error Rate (BPCER) shown by a candidate model trained on open-source datasets, there always were multiple sets of conditions where the model's predictions started being inconsistent. We have addressed this problem by building an internal dataset that would consist of the training portion and a test subset that would be comprehensive enough to address the missing subdomains in other benchmarks.</p><p>Entry Antispoofing Dataset consists of 83000 live video recordings collected via a custom-built UI that simulates the process of logging into a web-based biometric authentication system like Entry. The recordings were collected and labeled via a crowdsourcing data labeling service, from 45000 participants from more than 20 countries on five continents. Each recording was made on a mobile or laptop webcam (with roughly 30% of recordings being from laptop cameras, and 70% -from mobile), with subject's face visible from multiple angles. Subjects' genders, ages and ethnicities are not correlated with their collected recordings being spoofing or bona fide sessions, but overall distribution was not restricted in order to be as close to real-life demographic of potential users as possible. The process of collecting the dataset was iterative, with each version of the dataset produced after identifying a "blind spot subdomain" -specific set of camera/lighting/distance/other conditions, that were leading to unstable performance of the model. These blind spots were identified by crowdsourcing attacks on different iterations of earlier anti-spoofing models that were provided by our research team.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Videos Subjects</p><p>Entry 83000 45000 MSU-MFSD <ref type="bibr" target="#b15">[16]</ref> 280 35 Replay-Attack <ref type="bibr" target="#b3">[4]</ref> 1300 50 OULU-NPU <ref type="bibr" target="#b1">[2]</ref> 4950 55 <ref type="table">Table 1</ref>. Comparison of existing datasets for face anti-spoofing. <ref type="figure">Figure 1</ref>. Network architecture. We apply the network for each frame in a video stream, sequentially before aggregating received predictions to get the final spoofing score for the entire session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Architecture and algorithm</head><p>The training process is split into two steps in the following way:</p><p>1. Task-aware fine-tuning (TAFT) of a larger network using Entry Antispoofing Dataset.</p><p>2. Distillation of a high-accuracy network into a smaller one, suitable for production use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Task-aware fine-tuning</head><p>Our training process follows the general approach described by Chen et al. in <ref type="bibr" target="#b2">[3]</ref>. To recap, their training pipeline starts with an unsupervised pretraining of a large network on a large amount of unlabeled data, followed by supervised fine-tuning on a (typically smaller) task-specific labeled dataset. In our experiments, an open source pretrained network provided by Meta <ref type="bibr" target="#b6">[7]</ref> substitutes the pretraining step. We do not fine-tune the layers imported from Reg-Net, following the established practice <ref type="bibr" target="#b2">[3]</ref> [7] based on the observation that a large self-supervised pretrained network improves the generalization. Our network structure is modified from RegNet-32g <ref type="bibr" target="#b6">[7]</ref>: for the final layer we use a multi-headed classifier composed from 8 independent binary classifiers with the following semantics:</p><p>? Heads 1-6 represent the explicitly defined, visible signals that the login session was being spoofed, i.e.: fingers holding a device, visible device border, mobile UI, moire patterns, screen glare, and reflections in the screen.</p><p>? Head 7 represents the probability of an attack that is not discernible to a human eye. In the dataset it meant that the video recording was a successful spoofing attempt, but no visible signals were identified.</p><p>? Head 8 represents the overall probability that the frame is fraudulent.</p><p>The training is done with the pretrained layers from <ref type="bibr" target="#b6">[7]</ref> frozen. We are optimizing the Reduced Focal Loss function <ref type="bibr" target="#b11">[12]</ref> with AdamW [10] for 3 epochs with learning rate set to 1e ? 6. Frames that are samples from source videos are heavily augmented to further prevent the domain shift with the following set of augmentations:</p><p>? Random crop (ratio 0.33 ? 1.0 with random resize (ratio 0.7 ? 1.35).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? Random HSV shift</head><p>? Random Gaussian noise, motion blur ? Random ISO noise, 90 degree rotaion, horizontal flip</p><p>During training, we optimize a multi-class classification loss function for heads 1-8, but during inference only the probability from Head 8 is used. We observe that introducing an explicit classification of visible signals in a spoofing attempt improves the convergence speed and stabilizes the training process, but the actual spoofing detection does not require fine-grained classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Network distillation</head><p>After the network is trained, we perform the distillation procedure with a smaller architecture, to make the real-time inference feasible. Since we have a large number of labeled videos in our training dataset D, we are leveraging the weighted distillation loss from <ref type="bibr" target="#b2">[3]</ref>:</p><formula xml:id="formula_0">L = ? (1 ? ?) (xi,yi)?D L log P S (y i |x i ) ?? xi?D y P T (y|x i ; ? ) log P S (y|x i ; ? )<label>(1)</label></formula><p>where ? is a scalar temperature parameter, ? is a balancing parameter, P T (y|x i ) is the output of the teacher network, which is frozen after training, and P S (y|x i ) is the output of the student network. The architecture for the student network is EfficientNet-B3 <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Benchmarks</head><p>We evaluate the effectiveness of our network from two aspects: an evaluation portion of Entry Antispoofing Dataset for intra-test, and MSU-MFSD, Replay-Attack, and OULU-NPU for cross-database tests. When it comes to the baselines, we compare the results of our models that were never fine-tuned on target datasets to both intra-test and cross-test results of existing state-of-the-art methods, indicating which is which in the tables. When the prior crosstest result is reported for a particular baseline, we choose the best score of all cross-tests for that model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MSU-MFSD.</head><p>This dataset contains 280 videos of 35 subjects. Despite smaller scale, this benchmark is more challenging due to higher average quality of recordings used for spoofing, which is reflected in the baseline scored cited in this work.</p><p>Replay-Attack. This dataset contains 1300 videos of 50 subjects. All videos are generated by either having a (real) client trying to access a laptop through a built-in webcam or by displaying a photo or a video recording of the same client for at least 9 seconds.</p><p>OULU-NPU. This dataset contains 4950 videos of 55 subjects, collected in different lighting conditions, on six different mobile devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Protocol</head><p>The main goal of this work is to demonstrate strong generalization of our model across several challenging benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Metric</head><p>Our reported metric for cross-test evaluation is HTER (Half Total Error Rate) <ref type="bibr" target="#b0">[1]</ref>, which is widely used for comparing models in the field of biometric anti-spoofing. It is defined in terms of two error rates, False Acceptance Rate (FAR) and False Rejection Rate (FRR):</p><formula xml:id="formula_1">HT ER = F AR + F RR 2 (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In this paper we are reporting the results on two models, sharing the same general architecture and trained on the same data, with one architectural difference:</p><p>1. Entry V1. This model predicts only the probability of spoofing directly, without utilizing explicitly defined features as described in section "Task-aware finetuning". Instead, this model is trained as a simple binary classification CNN.</p><p>2. Entry V2. This model is trained according to the protocol from "Task-aware fine-tuning".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Intra-test on Entry Dataset</head><p>First, we examine the results of the intra-test on a test subset of the internal Entry Antispoofing Dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Intra-test on Entry Entry-V1 3.54 Entry-V2 0.74 Our primary hypothesis related to the dataset is that if the model achieving low HTER scores on it is capable of achieving similarly low error rates on other datasets, it will attest to the high level of generalization across domains it provides, and suggest that this dataset could be used on its own for comprehensive quality assessment moving forward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Cross-test</head><p>We consider the generalizability of the model to be the main goal of building an accurate anti-spoofing algorithm, which is why we make the emphasis on cross-database testing. Following the established practice for conducting cross-database evaluation, we evaluate HTER scores on three challenging datasets: MSU-MFSD <ref type="bibr" target="#b15">[16]</ref>, Replay-Attack <ref type="bibr" target="#b3">[4]</ref>, OULU-NPU <ref type="bibr" target="#b1">[2]</ref>. For the OULU-NPU evaluation, we chose Protocol I to be able to compare with the existing state-of-the-art results.</p><p>Model Entry V2 achieves HT ER = 0 on MSU-MFSD and Replay-Attack, therefore, it's possible to make a direct comparison with the results obtained on intra-tests that use Equal Error Rate metric, which is equivalen to HT ER at EER = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MSU-MFSD</head><p>CN N ? LST M AM (Replay ? MFSD) <ref type="bibr" target="#b13">[14]</ref> 25.72 GFA-CNN (Replay ? MFSD) <ref type="bibr" target="#b14">[15]</ref> 23.5 Entry-V1 2.4 Entry-V2 0 <ref type="table">Table 3</ref>. Cross-dataset HTER(%) scores on MSU-MFSD <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Replay-Attack</head><p>CN N ? LST M AM (MFSD ? Replay) <ref type="bibr" target="#b13">[14]</ref> 12.37 GFA-CNN (CASIA ? Replay) <ref type="bibr" target="#b14">[15]</ref> 21.4 GFA-CNN (MFSD ? Replay) <ref type="bibr" target="#b14">[15]</ref> 25.8 CNCN (CASIA ? Replay) <ref type="bibr" target="#b16">[17]</ref> 15.5 CNCN++ (CASIA ? Replay) <ref type="bibr" target="#b16">[17]</ref> 6.5 Entry-V1 2.7 Entry-V2 0 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OULU-NPU</head><p>A-DeepPixBis (Replay ? OULU) <ref type="bibr" target="#b8">[9]</ref> 25.57 DeepPixBiS (Replay ? OULU) <ref type="bibr" target="#b5">[6]</ref> 22.7 Bi-FAS-S (Replay ? OULU) <ref type="bibr" target="#b10">[11]</ref> 21.24 Bi-FAS (Replay ? OULU) <ref type="bibr" target="#b10">[11]</ref> 18.33 LBP-SVM (Replay ? OULU) <ref type="bibr" target="#b5">[6]</ref> 12.1 IQM-SVM (Replay ? OULU) <ref type="bibr" target="#b4">[5]</ref> 3.9 Entry-V1 (ours) 5.6 Entry-V2 (ours 2.6 Additionally, for OULU-NPU we report the comparison on ACER metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Application</head><p>This work was done as a part of R&amp;D effort inside XIX.ai supporting the key technology behind our biometric authentication system Entry. That was the reason why the generalization and performance requirements were dictated by the real-world applicability.</p><p>1. High accuracy after distillation. While the initial large network produces remarkable results, its size</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OULU-NPU (ACER)</head><p>LBP-SVM (intra-test) <ref type="bibr" target="#b5">[6]</ref> 25.0 IQM-SVM (intra-test) <ref type="bibr" target="#b4">[5]</ref> 32.29 A-DeepPixBis (intra-test) <ref type="bibr" target="#b8">[9]</ref> 0.75 DeepPixBiS (intra-test) <ref type="bibr" target="#b5">[6]</ref> 0.42 Bi-FAS-S (intra-test) <ref type="bibr" target="#b10">[11]</ref> 1.97 Bi-FAS (intra-test) <ref type="bibr" target="#b10">[11]</ref> 3.12 Entry-V1 (ours) 3.33 Entry-V2 (ours) 3.2 makes the scalability inefficient and, depending on the GPU accelerator used, prohibitively expensive. We have found that knowledge distillation does not have a noticeable effect on the model's accuracy when finetuned on Entry Antispoofing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Real-time inference. The anti-spoofing network, as all security-critical components, is being run on the backend, using cloud-hosted GPU accelerators. Since it turned out to be possible to distill the large model into a lightweight EfficientNet-B3, the throughput capacity was more than enough for processing multiple parallel video streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper we have presented an approach to training highly generalizable neural networks for face anti-spoofing, outlined the requirements for collecting labeled data sufficient for achieving the level of accuracy required for secure biometric authentication, and described the approach for post-processing of a model needed for deploying it as a part of a real-time video processing pipeline. We have shown the significant increase in accuracy on multiple established benchmarks by achieving the new state-of-the-art results from a combination of unsupervised pretraining and fine-tuning for the specific problem.</p><p>Augmenting the training objective with classification outputs predicting specific attributes of a spoofing attack alongside with the probability of an attack itself consistently improves the accuracy of the model further, without compromising on the generalization.</p><p>Finally, we have tested the performance differences and the increase in the inference throughput after the model distillation to prove the viability of this model in a live application.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>HTER(%) scores on internal test subset of Entry Antispoofing Dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>Cross-dataset HTER(%) scores on Replay-Attack [4].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>Cross-dataset HTER(%) scores comparison on Protocol I of the OULU-NPU dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .</head><label>6</label><figDesc></figDesc><table><row><cell>Cross-dataset ACER(%) scores on Protocol I of the</cell></row><row><cell>OULU-NPU dataset for more direct comparison with existing</cell></row><row><cell>intra-tests. All models except ours were trained on OULU specif-</cell></row><row><cell>ically. This comparison illustrates the closing gap between the</cell></row><row><cell>results obtained by a strongly generalizable model (Entry) and the</cell></row><row><cell>ones trained exclusively on OULU.</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A statistical significance test for person authentication. The Speaker and Language Recognition Workshop (Odyssey)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnny</forename><surname>Mari?thoz</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">OULU-NPU: A mobile face presentation attack database with real-world variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zinelabinde</forename><surname>Boulkenafet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jukka</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdenour</forename><surname>Hadid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th IEEE International Conference on Automatic Face Gesture Recognition (FG 2017)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="612" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semi-supervised learners. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">On the effectiveness of local binary patterns in face antispoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Chingovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?</forename><surname>Anjos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Marcel</surname></persName>
		</author>
		<editor>Arslan Br?mme and Christoph Busch</editor>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="183" to="194" />
			<pubPlace>Bonn</pubPlace>
		</imprint>
	</monogr>
	<note>Gesellschaft f?r Informatik e.V. 1, 2, 4</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image quality assessment for fake biometric detection: Application to iris, fingerprint, and face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Galbally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Fierrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Deep pixel-wise binary supervision for face presentation attack detection. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjith</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Marcel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1907" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Vision models are more robust and fair when pretrained on uncurated images without supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Duval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Seessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improving face anti-spoofing by 3d virtual synthesis. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinchuan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genxun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adeeppixbis: Attentional angular margin for face antispoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Md</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Labiba</forename><surname>Sourave Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koushik</forename><surname>Rupty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirshajit</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nabeel</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 Digital Image Computing: Techniques and Applications (DICTA)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fixing weight decay regularization in adam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno>abs/1711.05101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bi-fpnfas: Bi-directional feature pyramid network for pixel-wise face anti-spoofing by leveraging fourier spectra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koushik</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Md</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Labiba</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Rupty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2021-04" />
		</imprint>
	</monogr>
	<note>Sourave Hossain, Shirshajit Sengupta, Shehzad Noor Taus, and Nabeel Mohammed</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Reduced focal loss: 1st place solution to xview object detection in satellite imagery. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Sergievskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ponamarev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rethinking model scaling for convolutional neural networks. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Enhance the motion cues for face anti-spoofing using CNN-LSTM architecture. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuefei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning generalizable and identity-discriminative representations for face anti-spoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno>abs/1901.05602</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Face spoof detection with image distortion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="746" to="761" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Searching central difference convolutional networks for face anti-spoofing. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxiao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoying</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Celeba-spoof: Largescale face anti-spoofing dataset with rich annotations. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenfei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yidong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guojun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
