[{"caption":"Table 1: Comparison of SAT to SOTA methods on graph \nregression and classification tasks. ZINC results use edge \nweights where applicable, otherwise without edge weights. \nindicates we obtained the results ourselves by adapting \nthe code provided by the original paper. means that higher \nis better for the performance metric; indicates lower is \nbetter. \n\n","rows":["AVG . # NODES","AVG . # EDGES"],"columns":["PATTERN","12 , 000","14 , 000","CLUSTER","ZINC"],"mergedAllColumns":[],"numberCells":[{"number":"117.2","isBolded":false,"associatedRows":["AVG . # NODES"],"associatedColumns":["CLUSTER","12 , 000"],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["AVG . # EDGES"],"associatedColumns":["ZINC","12 , 000"],"associatedMergedColumns":[]},{"number":"23.2","isBolded":false,"associatedRows":["AVG . # NODES"],"associatedColumns":["ZINC","12 , 000"],"associatedMergedColumns":[]},{"number":"118.9","isBolded":false,"associatedRows":["AVG . # NODES"],"associatedColumns":["PATTERN","14 , 000"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison of SAT to SOTA methods on OGB \ndatasets. \n\n","rows":["AVG . # NODES","2 , 266 . 1","AVG . # EDGES"],"columns":["452 , 741","OGBG - CODE2","OGBG - PPA","158 , 100"],"mergedAllColumns":[],"numberCells":[{"number":"125.2","isBolded":false,"associatedRows":["AVG . # NODES"],"associatedColumns":["OGBG - CODE2","452 , 741"],"associatedMergedColumns":[]},{"number":"124.2","isBolded":false,"associatedRows":["AVG . # EDGES","2 , 266 . 1"],"associatedColumns":["OGBG - CODE2","452 , 741"],"associatedMergedColumns":[]},{"number":"243.4","isBolded":false,"associatedRows":["AVG . # NODES"],"associatedColumns":["OGBG - PPA","158 , 100"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Since SAT uses a GNN to extract structures, we compare the performance of the original sparse GNN to SAT which \nuses that GNN (\"base GNN\"). Across different choices of GNNs, we observe that both k-subtree and k-subgraph SATs \nalways outperform the original sparse GNN it uses. The evaluation metrics are the same as in Table 1. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 4: Hyperparameters for SAT models trained on different datasets. RWPE-p indicates using p steps in the random walk \npositional encoding, which results in a p-dimensional vector as the positional representation for each node. \n\n","rows":["Hidden dimensions","5000","Learning rate","2000","{0 . 0 ,","200","6","128","Batch size","#Epochs","#Layers","Warm - up steps","Dropout"],"columns":["RWPE - 7","FFN hidden dimensions","RWPE - 3","RWPE - 20","ZINC","{4 , 8}","2?Hidden dimensions","3","Size of subgraphs k","256","PATTERN","{1 , 2 , 3 , 4}","4","6","mean","128","8","OGBG - CODE2","OGBG - PPA","CLUSTER","None"],"mergedAllColumns":[],"numberCells":[{"number":"64","isBolded":false,"associatedRows":["Hidden dimensions"],"associatedColumns":["ZINC","6"],"associatedMergedColumns":[]},{"number":"0.0001","isBolded":false,"associatedRows":["Learning rate","2000","5000","5000"],"associatedColumns":["OGBG - CODE2","4","256","2?Hidden dimensions","{4 , 8}","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]},{"number":"0.0003","isBolded":false,"associatedRows":["Learning rate","2000","200"],"associatedColumns":["PATTERN","6","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","None","RWPE - 7"],"associatedMergedColumns":[]},{"number":"10epochs","isBolded":false,"associatedRows":["Warm - up steps","5000","5000","5000"],"associatedColumns":["OGBG - PPA","3","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]},{"number":"0.0003","isBolded":false,"associatedRows":["Learning rate","2000","200","200"],"associatedColumns":["OGBG - PPA","3","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]},{"number":"0.1,","isBolded":true,"associatedRows":["Dropout","6","200","{0 . 0 ,"],"associatedColumns":["PATTERN","6","128","2?Hidden dimensions","8"],"associatedMergedColumns":[]},{"number":"0.2,","isBolded":true,"associatedRows":["Dropout","6","200","{0 . 0 ,","200"],"associatedColumns":["PATTERN","6","128","2?Hidden dimensions","8"],"associatedMergedColumns":[]},{"number":"0.0005","isBolded":false,"associatedRows":["Learning rate","128"],"associatedColumns":["CLUSTER","6","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","None","RWPE - 3"],"associatedMergedColumns":[]},{"number":"0.001","isBolded":false,"associatedRows":["Learning rate"],"associatedColumns":["ZINC","6","128","FFN hidden dimensions","8","Size of subgraphs k","mean","RWPE - 20"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Hidden dimensions","6","200"],"associatedColumns":["PATTERN","6"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","128","5000","5000"],"associatedColumns":["OGBG - CODE2","4","256","2?Hidden dimensions","{4 , 8}","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["#Layers","6"],"associatedColumns":["CLUSTER"],"associatedMergedColumns":[]},{"number":"0.3,","isBolded":true,"associatedRows":["Dropout","6","200","{0 . 0 ,","200"],"associatedColumns":["OGBG - PPA","3","128","2?Hidden dimensions","8"],"associatedMergedColumns":[]},{"number":"0.4}","isBolded":true,"associatedRows":["Dropout","6","200","{0 . 0 ,","200"],"associatedColumns":["OGBG - PPA","3","128","2?Hidden dimensions","8"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","128","5000"],"associatedColumns":["PATTERN","6","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","None","RWPE - 7"],"associatedMergedColumns":[]},{"number":"48","isBolded":false,"associatedRows":["Hidden dimensions","6"],"associatedColumns":["CLUSTER","6"],"associatedMergedColumns":[]},{"number":"30","isBolded":false,"associatedRows":["#Epochs","2000","200","200","200"],"associatedColumns":["OGBG - CODE2","4","256","2?Hidden dimensions","{4 , 8}","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","128"],"associatedColumns":["CLUSTER","6","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","None","RWPE - 3"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","128","5000","5000"],"associatedColumns":["OGBG - PPA","3","128","2?Hidden dimensions","8","{1 , 2 , 3 , 4}","mean","None"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Test MAE for SAT models using different structure extractors and readout methods on the ZINC dataset. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 4. Note that the number of \nparameters used in our SAT on OGB datasets is smaller than most of the state-of-art methods. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]}]