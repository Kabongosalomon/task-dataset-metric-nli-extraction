[{"caption":"Table 1. Baselines: we compare our sMLP with dense Transform-\ners and MLPs as well as sparse Transformer-based MoEs. \n\n","rows":["Transformer 1 head","Transformer","Valid","gMLP","Perplexity","gMLP 1 head"],"columns":["sMLP - determinstic"],"mergedAllColumns":[],"numberCells":[{"number":"18","isBolded":false,"associatedRows":["Perplexity"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"35","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"15","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"45","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["Perplexity"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"16heads","isBolded":false,"associatedRows":["Perplexity","Transformer 1 head","Transformer"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"30","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"14","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"16heads","isBolded":false,"associatedRows":["Perplexity","gMLP 1 head","gMLP"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"25","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]}]},{"caption":"Table 2. Experimental Settings: In Section 4.3, we run our small \nmodel (3.50B parameters) with FLOPs per batch tokens 0.8T on \nthe small dataset (1/10 of the RoBERTa dataset); In Section 4.4, \nwe run our large model (9.41B parameters) with FLOPs per batch \ntokens 2.0T on the whole RoBERTa dataset plus CC100 corpus. \n\n","rows":["1","s - MoE","Spatial Gating Unit","16","Self - attention"],"columns":["params . ( M )","FLOPs ( G )"],"mergedAllColumns":[],"numberCells":[{"number":"12.885","isBolded":false,"associatedRows":["Self - attention","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.387","isBolded":false,"associatedRows":["s - MoE","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.316","isBolded":false,"associatedRows":["Spatial Gating Unit","16"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.316","isBolded":false,"associatedRows":["Spatial Gating Unit","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"1.058","isBolded":false,"associatedRows":["s - MoE","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"12.885","isBolded":false,"associatedRows":["Self - attention","16"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.198","isBolded":false,"associatedRows":["Self - attention","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"4.198","isBolded":false,"associatedRows":["Self - attention","16"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"1.054","isBolded":false,"associatedRows":["Spatial Gating Unit","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"16.798","isBolded":false,"associatedRows":["Spatial Gating Unit","16"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]}]},{"caption":"Table 3. Token-wise Operations Comparison: we compare our \nmethod with the previous two token-wise operations regarding \nparameters and FLOPs by each operation. \n\n","rows":["1","s - MoE","Spatial Gating Unit","16","Self - attention"],"columns":["params . ( M )","FLOPs ( G )"],"mergedAllColumns":[],"numberCells":[{"number":"4.316","isBolded":false,"associatedRows":["Spatial Gating Unit","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"12.885","isBolded":false,"associatedRows":["Self - attention","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.316","isBolded":false,"associatedRows":["Spatial Gating Unit","16"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"12.885","isBolded":false,"associatedRows":["Self - attention","16"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]},{"number":"4.198","isBolded":false,"associatedRows":["Self - attention","16"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"1.054","isBolded":false,"associatedRows":["Spatial Gating Unit","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"16.798","isBolded":false,"associatedRows":["Spatial Gating Unit","16"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"1.058","isBolded":false,"associatedRows":["s - MoE","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"4.198","isBolded":false,"associatedRows":["Self - attention","1"],"associatedColumns":["params . ( M )"],"associatedMergedColumns":[]},{"number":"4.387","isBolded":false,"associatedRows":["s - MoE","1"],"associatedColumns":["FLOPs ( G )"],"associatedMergedColumns":[]}]},{"caption":"Table 1. We train all our baselines (except GPT3 from \npaper) and our model in PyTorch ","rows":["Transformer 1 head","Transformer","Valid","gMLP","Perplexity","gMLP 1 head"],"columns":["sMLP - determinstic"],"mergedAllColumns":[],"numberCells":[{"number":"14","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"35","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"18","isBolded":false,"associatedRows":["Perplexity"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"45","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["Perplexity"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"16heads","isBolded":false,"associatedRows":["Perplexity","Transformer 1 head","Transformer"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"25","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"16heads","isBolded":false,"associatedRows":["Perplexity","gMLP 1 head","gMLP"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"30","isBolded":false,"associatedRows":["Valid","gMLP"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]},{"number":"15","isBolded":false,"associatedRows":["Valid"],"associatedColumns":["sMLP - determinstic"],"associatedMergedColumns":[]}]},{"caption":"Table 4. Head-to-head comparison measures per step and per time benefits of the sMLP (our model) over baselines. We report perplexity \n(lower better) and time to reach (lower better) as quality and training efficiency measures. All models are trained with the same amount of \ncomputation and hardware. In order to test parameter-matched models, we train an enlarged Switch Transformer with 2.0T FLOPs. Top: \nSmall models (FLOPs 0.8T). Bottom: Scaled-up models (FLOPs 2.0T). More model details are described in Table 5. \n\n","rows":["Gshard ( Lepikhin et al . , 2020 )","Switch Transformer ( Fedus et al . , 2021 )","sMLP - deterministic ( our model )","Base Layers ( Lewis et al . , 2021 )","HASH Layers ( Roller et al . , 2021 )","Switch Transformer - Enlarge ( FLOPs 2 . 3T )"],"columns":["198","100","Time to Quality","Quality after 100k steps","( Perplexity ? )","( Parameters )","Model Size","Quality after 25k steps","140","( hours ? )","120"],"mergedAllColumns":["136k","Models","185k","176k","178k","135k"],"numberCells":[{"number":"10.31B","isBolded":false,"associatedRows":["Switch Transformer - Enlarge ( FLOPs 2 . 3T )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )","198","120","100"],"associatedMergedColumns":["135k"]},{"number":"9.03B","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )"],"associatedMergedColumns":["Models"]},{"number":"18.16","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )"],"associatedMergedColumns":["185k"]},{"number":"3.50B","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Model Size","( Parameters )"],"associatedMergedColumns":["176k"]},{"number":"3.60B","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )"],"associatedMergedColumns":["185k"]},{"number":"21.13","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Time to Quality","( hours ? )"],"associatedMergedColumns":["185k"]},{"number":"20.41","isBolded":true,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Time to Quality","( hours ? )"],"associatedMergedColumns":["176k"]},{"number":"20.67","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Time to Quality","( hours ? )"],"associatedMergedColumns":["136k"]},{"number":"16.69","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )","198","120"],"associatedMergedColumns":["135k"]},{"number":"9.84","isBolded":true,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )","198","120","100","140"],"associatedMergedColumns":["135k"]},{"number":"19.26","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )"],"associatedMergedColumns":["Models"]},{"number":"3.48B","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Model Size","( Parameters )"],"associatedMergedColumns":["Models"]},{"number":"10.45","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )","198"],"associatedMergedColumns":["Models"]},{"number":"27.54","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Time to Quality","( hours ? )"],"associatedMergedColumns":["Models"]},{"number":"115.13","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Time to Quality","( hours ? )","Time to Quality","( hours ? )","198","120"],"associatedMergedColumns":["Models"]},{"number":"10.29B","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )","198","120"],"associatedMergedColumns":["135k"]},{"number":"13.57","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )"],"associatedMergedColumns":["178k"]},{"number":"3.48B","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )"],"associatedMergedColumns":["136k"]},{"number":"21.08","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Time to Quality","( hours ? )"],"associatedMergedColumns":["178k"]},{"number":"9.41B","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )","198","120","100","140"],"associatedMergedColumns":["135k"]},{"number":"10.31B","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )","198","120"],"associatedMergedColumns":["Models"]},{"number":"3.51B","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )"],"associatedMergedColumns":["178k"]},{"number":"20.36(divergence)","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )","198","120"],"associatedMergedColumns":["Models"]},{"number":"15.31","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )"],"associatedMergedColumns":["136k"]},{"number":"10.09","isBolded":false,"associatedRows":["Switch Transformer - Enlarge ( FLOPs 2 . 3T )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )","198","120","100"],"associatedMergedColumns":["135k"]},{"number":"9.03B","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Model Size","( Parameters )","Model Size","( Parameters )","198"],"associatedMergedColumns":["Models"]},{"number":"13.46","isBolded":true,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )"],"associatedMergedColumns":["176k"]},{"number":"14.5","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Quality after 25k steps","( Perplexity ? )","Quality after 100k steps","( Perplexity ? )"],"associatedMergedColumns":["Models"]}]},{"caption":"Table 5. Scaled-up Model details: We control FLOPs to the same level by adjusting the number of layers of the model. Since our model \nis based on gMLP (Liu et al., 2021a), more dense layers are needed, and only one head is needed for each device. While controlling \nFLOPs value, we found that only the Switch Transformer (Fedus et al., 2021) can be compared with our sMLP among all the baselines. \nWith the same amount of FLOPs value, our model has more parameters than the Switch Transformer; then, we train a Switch Transformer \n-Enlarge model for comparison. \n\n","rows":["1","Base Layers","2048","sMLP - deterministic ( our model )","7","HASH Layers","Switch Transformer - Enlarge","8192","8","Gshard","Switch Transformer"],"columns":["Dense","Experts","Heads","GPUs","Model","Size ( M )","FLOPs ( T )","Num of","Layers"],"mergedAllColumns":[],"numberCells":[{"number":"22","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )","2048","8192","7"],"associatedColumns":["Dense","FLOPs ( T )","Layers"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Base Layers"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Base Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Heads"],"associatedMergedColumns":[]},{"number":"9.03","isBolded":false,"associatedRows":["Gshard"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Base Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Gshard","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"10.31","isBolded":false,"associatedRows":["Base Layers"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Gshard","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","Heads"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Switch Transformer - Enlarge","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Base Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Gshard"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Switch Transformer","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","Heads"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Gshard","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["HASH Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Heads"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["HASH Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["HASH Layers"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Switch Transformer - Enlarge","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )","2048","8192","7","8","1"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Switch Transformer","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]},{"number":"10.29","isBolded":false,"associatedRows":["HASH Layers"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"2.3","isBolded":false,"associatedRows":["Switch Transformer - Enlarge"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Switch Transformer","2048","8192","7","7"],"associatedColumns":["Num of","FLOPs ( T )","GPUs"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Switch Transformer - Enlarge","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Heads"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )","2048","8192","7","8","1"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]},{"number":"10.31","isBolded":false,"associatedRows":["Switch Transformer - Enlarge"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"9.03","isBolded":false,"associatedRows":["Switch Transformer"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Switch Transformer"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"9.41","isBolded":false,"associatedRows":["sMLP - deterministic ( our model )"],"associatedColumns":["Model","FLOPs ( T )","Size ( M )"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["HASH Layers","2048","8192","8","8"],"associatedColumns":["Num of","FLOPs ( T )","Experts"],"associatedMergedColumns":[]}]},{"caption":"Table 6. Zero-shot priming evaluation: we provide head-to-head comparison of our sMLP model with FLOPs-matched state-of-the-art \nsparse Transformers on six representative NLP tasks evaluated in GPT-3 in-context learning","rows":["GPT - 3 ( Brown et al . , 2020b ) from paper","Gshard ( Lepikhin et al . , 2020 )","Switch Transformer ( Fedus et al . , 2021 )","sMLP - deterministic ( our )","Base Layers ( Lewis et al . , 2021 )","HASH Layers ( Roller et al . , 2021 )"],"columns":["COPA","StoryCloze","Average","PIQA","ReCoRD","HellaSwag","Winogrande"],"mergedAllColumns":[],"numberCells":[{"number":"79.86","isBolded":true,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"61.41","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]},{"number":"68.15","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"64.00","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"73.33","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]},{"number":"51.70","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"38.00","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"54.53","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"68.13","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"72.39","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"76.00","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"68.12","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"79.00","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"51.068","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"63.77","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"50.98","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"72.9","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"82.1","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"72.96","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"30.22","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"63.82","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"62.24","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"52.48","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"60.70","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"73.42","isBolded":false,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"53.43","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"64.72","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]},{"number":"57.40","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"57.4","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020b ) from paper"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"67.84","isBolded":false,"associatedRows":["Switch Transformer ( Fedus et al . , 2021 )"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"33.04","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["HellaSwag"],"associatedMergedColumns":[]},{"number":"67.88","isBolded":false,"associatedRows":["Gshard ( Lepikhin et al . , 2020 )"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]},{"number":"63.00","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["COPA"],"associatedMergedColumns":[]},{"number":"54.31","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["Winogrande"],"associatedMergedColumns":[]},{"number":"67.15","isBolded":false,"associatedRows":["HASH Layers ( Roller et al . , 2021 )"],"associatedColumns":["ReCoRD"],"associatedMergedColumns":[]},{"number":"55.02","isBolded":false,"associatedRows":["Base Layers ( Lewis et al . , 2021 )"],"associatedColumns":["Average"],"associatedMergedColumns":[]},{"number":"72.96","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"74.67","isBolded":true,"associatedRows":["sMLP - deterministic ( our )"],"associatedColumns":["StoryCloze"],"associatedMergedColumns":[]}]},{"caption":"Table 7. Extending gMLP to token-based MoEs hurts performance \ncompared to dense gMLP. Furthermore, increasing the number of \nexperts worsens the performance. \n\n","rows":["0","gMLP","gMLP MoE","64","32"],"columns":["Valid Perplexity"],"mergedAllColumns":[],"numberCells":[{"number":"15.7","isBolded":false,"associatedRows":["gMLP","0"],"associatedColumns":["Valid Perplexity"],"associatedMergedColumns":[]},{"number":"17.2","isBolded":false,"associatedRows":["gMLP MoE","32"],"associatedColumns":["Valid Perplexity"],"associatedMergedColumns":[]},{"number":"20.5","isBolded":false,"associatedRows":["gMLP MoE","64"],"associatedColumns":["Valid Perplexity"],"associatedMergedColumns":[]}]},{"caption":"Table 8 shows the the de-\ntailed model architecture used in the main experiments. \nThrough observation, we noticed that all the models (ex-\ncept for Gshard) drop negligibly after 15k. In addition, \nthere is a small amount of fluctuation for the Base Layers \nafter 25k. Then we choose 25k for model comparison in \nTable 4. \n\n","rows":["Gradient Accumulation","16","FLOPs","weight - decay","Spatial Gating Unit per Expert Module","Non Expert Parameters","adam - betas","Heads","Batch Size","FFNs per Expert Module","Expert Parameters","Dropout","( 0 . 9 ,"],"columns":["12","4096","adam","Base Layers","1024","28","no c10d","sMLP - deterministic","32"],"mergedAllColumns":[],"numberCells":[{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,","( 0 . 9 ,"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"100.75M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["sMLP - deterministic","32","12"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["Base Layers","32","12"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["Base Layers","32","12"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"241.79M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Heads","16"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["sMLP - deterministic","32","12"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"258.73M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"113.44M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024","no c10d","adam"],"associatedMergedColumns":[]}]},{"caption":"Table 8. Model architectures used in the main experiments in Sec-\ntion 4.3. \n\n","rows":["Gradient Accumulation","16","FLOPs","weight - decay","Spatial Gating Unit per Expert Module","Non Expert Parameters","adam - betas","Heads","Batch Size","FFNs per Expert Module","Expert Parameters","Dropout","( 0 . 9 ,"],"columns":["12","4096","adam","Base Layers","1024","28","no c10d","sMLP - deterministic","32"],"mergedAllColumns":[],"numberCells":[{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Heads","16"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096"],"associatedMergedColumns":[]},{"number":"100.75M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"113.44M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"258.73M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["sMLP - deterministic","32","12"],"associatedMergedColumns":[]},{"number":"241.79M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["Base Layers"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["Base Layers","32","12"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["Base Layers","32","12","1024","4096","12","1024"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["sMLP - deterministic","32","12"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,","( 0 . 9 ,"],"associatedColumns":["sMLP - deterministic","32","12","1024","4096","28","1024","no c10d","adam"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["Base Layers","32","12"],"associatedMergedColumns":[]}]},{"caption":"Table 9. Small dense model architectures used in Section 4.2. \n\n","rows":["FLOPs","weight - decay","Embedding Size","Non Expert Parameters","Context Length","adam - betas","warmup - updates","0 M","Hidden Dimension","Expert Parameters","Dropout","( 0 . 9 ,"],"columns":["12","24","adam","Transformer","gMLP","16","28","no c10d","sMLP - deterministic","0","inverse sqrt","1","2","4","41","5e - 4"],"mergedAllColumns":[],"numberCells":[{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["gMLP","0","41","1","2","4"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,","( 0 . 9 ,"],"associatedColumns":["gMLP","0","41","1","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"113.44M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"4000","isBolded":false,"associatedRows":["warmup - updates"],"associatedColumns":["sMLP - deterministic","12","28","1","2","4","no c10d","adam","5e - 4","inverse sqrt"],"associatedMergedColumns":[]},{"number":"4096","isBolded":false,"associatedRows":["Hidden Dimension"],"associatedColumns":["gMLP","0","41"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["Transformer"],"associatedMergedColumns":[]},{"number":"4096","isBolded":false,"associatedRows":["Hidden Dimension"],"associatedColumns":["sMLP - deterministic","12","28"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["sMLP - deterministic","12","28","1","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"4096","isBolded":false,"associatedRows":["Hidden Dimension"],"associatedColumns":["Transformer","0","24"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Context Length"],"associatedColumns":["gMLP","0","41","1"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Context Length"],"associatedColumns":["sMLP - deterministic","12","28","1"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,","( 0 . 9 ,","( 0 . 9 ,"],"associatedColumns":["sMLP - deterministic","12","28","1","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Context Length"],"associatedColumns":["Transformer","0","24","16"],"associatedMergedColumns":[]},{"number":"4000","isBolded":false,"associatedRows":["warmup - updates"],"associatedColumns":["gMLP","0","41","1","2","4","no c10d","adam","5e - 4","inverse sqrt"],"associatedMergedColumns":[]},{"number":"354.76M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["Transformer"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Embedding Size"],"associatedColumns":["Transformer","0","24"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"4000","isBolded":false,"associatedRows":["warmup - updates"],"associatedColumns":["Transformer","0","24","16","2","4","no c10d","adam","5e - 4","inverse sqrt"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["sMLP - deterministic","12","28","1","2","4"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["Transformer","0","24","16","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Embedding Size"],"associatedColumns":["sMLP - deterministic","12","28"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,"],"associatedColumns":["Transformer","0","24","16","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["Transformer","0","24","16","2","4"],"associatedMergedColumns":[]},{"number":"0.83T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["gMLP"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["gMLP","0","41","1","2","4","no c10d","adam"],"associatedMergedColumns":[]},{"number":"353.87M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["gMLP"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["Embedding Size"],"associatedColumns":["gMLP","0","41"],"associatedMergedColumns":[]},{"number":"258.73M","isBolded":false,"associatedRows":["Expert Parameters","0 M","0 M"],"associatedColumns":["sMLP - deterministic"],"associatedMergedColumns":[]}]},{"caption":"Table 10. Large model architectures used in the scalability experi-\nments in Section 4.4 and Section 4.5. \n\n","rows":["Number of MoE layers","Gradient Accumulation","16","FLOPs","weight - decay","Spatial Gating Unit per Expert Module","Non Expert Parameters","adam - betas","Heads","Batch Size","FFNs per Expert Module","Number of Dense Layers","Expert Parameters","Dropout","( 0 . 9 ,"],"columns":["adam","Base Layers","2048","1024","Efficient Language Modeling with Sparse all - MLP","8192","no c10d","sMLP - deterministic","32"],"mergedAllColumns":["20"],"numberCells":[{"number":"2.125T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["Heads","16"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192"],"associatedMergedColumns":[]},{"number":"682.6M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192","1024","no c10d","adam"],"associatedMergedColumns":["20"]},{"number":"277.1M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192","1024"],"associatedMergedColumns":["20"]},{"number":"2.125T","isBolded":false,"associatedRows":["FLOPs"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["weight - decay"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192","1024","no c10d","adam"],"associatedMergedColumns":["20"]},{"number":"2","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192","1024"],"associatedMergedColumns":["20"]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,","( 0 . 9 ,"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192","1024","no c10d","adam"],"associatedMergedColumns":["20"]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192","1024"],"associatedMergedColumns":["20"]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32","2048","8192","1024"],"associatedMergedColumns":["20"]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32"],"associatedMergedColumns":[]},{"number":"268.6M","isBolded":false,"associatedRows":["Non Expert Parameters"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["Number of MoE layers"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["Number of Dense Layers"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["FFNs per Expert Module"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["Gradient Accumulation"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192","1024"],"associatedMergedColumns":["20"]},{"number":"1","isBolded":false,"associatedRows":["Spatial Gating Unit per Expert Module"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32"],"associatedMergedColumns":[]},{"number":"0.98)","isBolded":false,"associatedRows":["adam - betas","( 0 . 9 ,"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192","1024","no c10d","adam"],"associatedMergedColumns":["20"]},{"number":"642.6M","isBolded":false,"associatedRows":["Expert Parameters"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["Number of MoE layers"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","sMLP - deterministic","32"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":["Batch Size"],"associatedColumns":["Efficient Language Modeling with Sparse all - MLP","Base Layers","32","2048","8192","1024"],"associatedMergedColumns":["20"]}]}]