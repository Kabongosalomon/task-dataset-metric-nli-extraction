[{"caption":"Improvements \nTop-1 \n? \nResNet-200 \n79.0 \n-\n+ Cosine LR Decay \n79.3 \n+0.3 \n+ Increase training epochs \n78.8  ? \n-0.5 \n+ EMA of weights \n79.1 \n+0.3 \n+ Label Smoothing \n80.4 \n+1.3 \n+ Stochastic Depth \n80.6 \n+0.2 \n+ RandAugment \n81.0 \n+0.4 \n+ Dropout on FC \n80.7  ? \n-0.3 \n+ Decrease weight decay \n82.2 \n+1.5 \n+ Squeeze-and-Excitation \n82.9 \n+0.7 \n+ ResNet-D \n83.4 \n+0.5 \n\nTable 1. Additive study of the ResNet-RS training recipe. The \ncolors refer to Training Methods , Regularization Methods \n\nand Architecture Improvements . The baseline ResNet-200 \nwas trained for the standard 90 epochs using a stepwise learn-\ning rate decay schedule. The image resolution is 256?256. All \nnumbers are reported on the ImageNet validation-set and \naveraged over 2 runs.  ? Increasing training duration to 350 epochs \nonly becomes useful once the regularization methods are used, \notherwise the accuracy drops due to over-fitting.  ? dropout hurts \nas we have not yet decreased the weight decay (See Table 2 for \nmore details). \n\n","rows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - SD - DO","+ EMA of weights","+ ResNet - D","+ Label Smoothing","RA - LS","+ Stochastic Depth","+ Increase training epochs","+ Dropout on FC","+ Cosine LR Decay","+ Decrease weight decay","+ RandAugment","RA - LS - DO","ResNet - 200","None"],"columns":["?","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","?","Regularization Methods","4e - 5","dropout hurts","Top - 1","1e - 4"],"mergedAllColumns":["more details ) .","-"],"numberCells":[{"number":"+0.3","isBolded":true,"associatedRows":["ResNet - 50","+ EMA of weights","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-1.0","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"+1.5","isBolded":true,"associatedRows":["ResNet - 50","+ Decrease weight decay","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+1.3","isBolded":true,"associatedRows":["ResNet - 50","+ Label Smoothing","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-0.3","isBolded":false,"associatedRows":["ResNet - 50","+ Dropout on FC","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"82.2","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","RA - LS - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"+0.2","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS - SD - DO"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"+0.5","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - DO"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"80.4","isBolded":false,"associatedRows":["ResNet - 50","+ Label Smoothing","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"78.8?","isBolded":false,"associatedRows":["ResNet - 50","+ Increase training epochs","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"83.4","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.5","isBolded":true,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+0.4","isBolded":true,"associatedRows":["ResNet - 50","+ RandAugment","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"81.7","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"82.2","isBolded":false,"associatedRows":["ResNet - 50","+ Decrease weight decay","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"80.6","isBolded":false,"associatedRows":["ResNet - 50","+ Stochastic Depth","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.3","isBolded":true,"associatedRows":["ResNet - 50","+ Cosine LR Decay","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-0.1","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"82.9","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.2","isBolded":true,"associatedRows":["ResNet - 50","+ Stochastic Depth","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"78.7","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"+0.7","isBolded":true,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"85.5","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS - SD - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"-0.5","isBolded":false,"associatedRows":["ResNet - 50","+ Increase training epochs","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"82.3","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"80.7?","isBolded":false,"associatedRows":["ResNet - 50","+ Dropout on FC","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"79.3","isBolded":false,"associatedRows":["ResNet - 50","+ Cosine LR Decay","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"85.3","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","RA - LS - SD - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"82.5","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"84.9","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"79.1","isBolded":false,"associatedRows":["ResNet - 50","+ EMA of weights","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.7","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"79.7","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"81.0","isBolded":false,"associatedRows":["ResNet - 50","+ RandAugment","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.4","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"-0.3","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"-0.8","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","None"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"79.0","isBolded":false,"associatedRows":["ResNet - 50","ResNet - 200","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"85.2","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]}]},{"caption":"Model \nRegularization \nWeight Decay \n? \n1e-4 \n4e-5 \n\nResNet-50 \nNone \n79.7 \n78.7 \n-1.0 \nResNet-50 \nRA-LS \n82.4 \n82.3 \n-0.1 \nResNet-50 \nRA-LS-DO \n82.2 \n82.7 \n+0.5 \n\nResNet-200 None \n82.5 \n81.7 \n-0.8 \nResNet-200 RA-LS \n85.2 \n84.9 \n-0.3 \nResNet-200 RA-LS-SD-DO 85.3 \n85.5 \n+0.2 \n\nTable 2. Decrease weight decay when using more regulariza-\ntion. Top-1 ImageNet accuracy for different regularization com-\nbinations. Decreasing the weight decay improves performance \nwhen combining regularization methods such as dropout (DO), \nstochastic depth (SD), label smoothing (LS) and RandAugment \n(RA). Image resolution is 224?224 for ResNet-50 and 256?256 \nfor ResNet-200. All numbers are reported on the ImageNet \nminival-set from an average of two runs. \n\n","rows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - SD - DO","+ EMA of weights","+ ResNet - D","+ Label Smoothing","RA - LS","+ Stochastic Depth","+ Increase training epochs","+ Dropout on FC","+ Cosine LR Decay","+ Decrease weight decay","+ RandAugment","RA - LS - DO","ResNet - 200","None"],"columns":["?","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","?","Regularization Methods","4e - 5","dropout hurts","Top - 1","1e - 4"],"mergedAllColumns":["more details ) .","-"],"numberCells":[{"number":"80.4","isBolded":false,"associatedRows":["ResNet - 50","+ Label Smoothing","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"-0.3","isBolded":false,"associatedRows":["ResNet - 50","+ Dropout on FC","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"80.6","isBolded":false,"associatedRows":["ResNet - 50","+ Stochastic Depth","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.2","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","RA - LS - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"81.0","isBolded":false,"associatedRows":["ResNet - 50","+ RandAugment","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.3","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"85.2","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"79.1","isBolded":false,"associatedRows":["ResNet - 50","+ EMA of weights","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.2","isBolded":false,"associatedRows":["ResNet - 50","+ Decrease weight decay","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"-0.8","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","None"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"85.3","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","RA - LS - SD - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"+1.5","isBolded":true,"associatedRows":["ResNet - 50","+ Decrease weight decay","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+0.7","isBolded":true,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"82.5","isBolded":false,"associatedRows":["ResNet - 200","+ ResNet - D","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"+1.3","isBolded":true,"associatedRows":["ResNet - 50","+ Label Smoothing","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"80.7?","isBolded":false,"associatedRows":["ResNet - 50","+ Dropout on FC","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.3","isBolded":true,"associatedRows":["ResNet - 50","+ EMA of weights","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-0.1","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"-1.0","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"82.9","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.5","isBolded":true,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"79.7","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"79.0","isBolded":false,"associatedRows":["ResNet - 50","ResNet - 200","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"82.4","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","otherwise the accuracy drops due to over - fitting .","Weight Decay","1e - 4"],"associatedMergedColumns":["more details ) ."]},{"number":"85.5","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS - SD - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"84.9","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"-0.3","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"+0.5","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - DO"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"-0.5","isBolded":false,"associatedRows":["ResNet - 50","+ Increase training epochs","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"78.7","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"+0.2","isBolded":true,"associatedRows":["ResNet - 50","+ Stochastic Depth","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+0.3","isBolded":true,"associatedRows":["ResNet - 50","+ Cosine LR Decay","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+0.4","isBolded":true,"associatedRows":["ResNet - 50","+ RandAugment","None"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"79.3","isBolded":false,"associatedRows":["ResNet - 50","+ Cosine LR Decay","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"83.4","isBolded":false,"associatedRows":["ResNet - 50","+ ResNet - D","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"82.7","isBolded":false,"associatedRows":["ResNet - 50","+ Squeeze - and - Excitation","RA - LS - DO"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"81.7","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","None"],"associatedColumns":["Top - 1","Regularization Methods","The baseline ResNet - 200","?","Weight Decay","4e - 5"],"associatedMergedColumns":["more details ) ."]},{"number":"78.8?","isBolded":false,"associatedRows":["ResNet - 50","+ Increase training epochs","None"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.2","isBolded":false,"associatedRows":["ResNet - 200","+ Squeeze - and - Excitation","RA - LS - SD - DO"],"associatedColumns":["?","Regularization Methods","The baseline ResNet - 200","dropout hurts","?","4e - 5"],"associatedMergedColumns":["more details ) ."]}]},{"caption":"Table 3. Performance comparison of ResNet-RS and Efficient-\nNet (abbreviated ENet). Although ResNet-RS has more parame-\nters and FLOPs, the model employs less memory and runs faster \non TPUs and GPUs. TPU latency is reported as the time per train-\ning step for 1024 images on 8 TPUv3 cores. Memory is reported \non 32 images per core, using bfloat16 precision without fusion \nor rematerialization. See Appendix H for more profiling details. \n\n","rows":["Memory ( GB )","Top - 1 Acc .","Latency ( s )"],"columns":["ENet - B6","69","RS - 420","192","164","38 ( 1 . 8x )","320","74 ( 1 . 7x )","256","RS - 350","600","128","66 ( 2 . 9x )","528","ENet - B7","43 ( 3 . 8x )"],"mergedAllColumns":["V100","TPU - v3"],"numberCells":[{"number":"1.1","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["RS - 350","256","164","69"],"associatedMergedColumns":["TPU - v3"]},{"number":"84.7","isBolded":true,"associatedRows":["Top - 1 Acc .","Memory ( GB )"],"associatedColumns":["ENet - B7","600"],"associatedMergedColumns":[]},{"number":"6.0(2.9x)","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["ENet - B7","600","66 ( 2 . 9x )","74 ( 1 . 7x )"],"associatedMergedColumns":["TPU - v3"]},{"number":"29.9(2.8x)","isBolded":false,"associatedRows":["Latency ( s )"],"associatedColumns":["ENet - B7","600","66 ( 2 . 9x )","74 ( 1 . 7x )"],"associatedMergedColumns":["V100"]},{"number":"15.7(3.3x)","isBolded":false,"associatedRows":["Latency ( s )"],"associatedColumns":["ENet - B6","528","43 ( 3 . 8x )","38 ( 1 . 8x )"],"associatedMergedColumns":["V100"]},{"number":"7.3","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["RS - 350","256","164","69"],"associatedMergedColumns":["TPU - v3"]},{"number":"84.0","isBolded":true,"associatedRows":["Top - 1 Acc .","Memory ( GB )"],"associatedColumns":["RS - 350","256"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["Top - 1 Acc .","Memory ( GB )"],"associatedColumns":["RS - 420","320"],"associatedMergedColumns":[]},{"number":"3.0(2.7x)","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["ENet - B6","528","43 ( 3 . 8x )","38 ( 1 . 8x )"],"associatedMergedColumns":["TPU - v3"]},{"number":"2.1","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["RS - 420","320","192","128"],"associatedMergedColumns":["TPU - v3"]},{"number":"28.3(1.8x)","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["ENet - B7","600","66 ( 2 . 9x )","74 ( 1 . 7x )"],"associatedMergedColumns":["TPU - v3"]},{"number":"10.2","isBolded":false,"associatedRows":["Latency ( s )"],"associatedColumns":["RS - 420","320","192","128"],"associatedMergedColumns":["V100"]},{"number":"4.7","isBolded":false,"associatedRows":["Latency ( s )"],"associatedColumns":["RS - 350","256","164","69"],"associatedMergedColumns":["V100"]},{"number":"84.0","isBolded":true,"associatedRows":["Top - 1 Acc .","Memory ( GB )"],"associatedColumns":["ENet - B6","528"],"associatedMergedColumns":[]},{"number":"16.6(2.3x)","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["ENet - B6","528","43 ( 3 . 8x )","38 ( 1 . 8x )"],"associatedMergedColumns":["TPU - v3"]},{"number":"15.5","isBolded":false,"associatedRows":["Memory ( GB )"],"associatedColumns":["RS - 420","320","192","128"],"associatedMergedColumns":["TPU - v3"]}]},{"caption":"Table 4 reveals that ResNet-RS models are very \nstrong in the semi-supervised learning setup as well. We \nobtain a top-1 ImageNet accuracy of 86.2%, while being \n4.7x faster on TPU (5.5x on GPU) than the corresponding \nNoisy Student EfficientNet-B5 model. \n\nModel \nV100 (s) TPUv3 (ms) Top-1 \n\nEfficientNet-B5 \n8.16 \n1510 \n86.1 \nResNet-RS-152 \n1.48 (5.5x) 320 (4.7x) 86.2 \n\nTable 4. ResNet-RS are efficient semi-supervised learners. \nResNet-RS-152 with image resolution 224 is 4.7x faster on TPU \n(5.5x on GPU) than EfficientNet-B5 Noisy Student (Xie et al., \n2020) for a similar ImageNet accuracy. Both models train on the \nsame additional 130M pseudo-labeled images. See Appendix H \nfor details on latency measurements. \n","rows":["EfficientNet - B5","ResNet - RS - 152","1510","ResNet - RS - 152 with image resolution 224 is","320 ( 4 . 7x )"],"columns":["strong in the semi - supervised learning setup as well .","V100 ( s )","Table 4 reveals that ResNet - RS models are very","Top - 1","semi - supervised"],"mergedAllColumns":["Noisy Student EfficientNet - B5 model .","obtain a top - 1 ImageNet accuracy of 86 . 2% , while being"],"numberCells":[{"number":"4.7xfasteronTPU(5.5xonGPU)thanthecorresponding","isBolded":true,"associatedRows":[],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well ."],"associatedMergedColumns":["obtain a top - 1 ImageNet accuracy of 86 . 2% , while being"]},{"number":"1.48(5.5x)","isBolded":true,"associatedRows":["ResNet - RS - 152"],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well .","V100 ( s )"],"associatedMergedColumns":["Noisy Student EfficientNet - B5 model ."]},{"number":"8.16","isBolded":false,"associatedRows":["EfficientNet - B5"],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well .","V100 ( s )"],"associatedMergedColumns":["Noisy Student EfficientNet - B5 model ."]},{"number":"86.1","isBolded":false,"associatedRows":["EfficientNet - B5","1510"],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well .","Top - 1"],"associatedMergedColumns":["Noisy Student EfficientNet - B5 model ."]},{"number":"86.2","isBolded":true,"associatedRows":["ResNet - RS - 152","320 ( 4 . 7x )"],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well .","Top - 1"],"associatedMergedColumns":["Noisy Student EfficientNet - B5 model ."]},{"number":"4.7xfasteronTPU","isBolded":true,"associatedRows":["ResNet - RS - 152 with image resolution 224 is"],"associatedColumns":["Table 4 reveals that ResNet - RS models are very","strong in the semi - supervised learning setup as well .","Top - 1","semi - supervised"],"associatedMergedColumns":["Noisy Student EfficientNet - B5 model ."]}]},{"caption":"Table 5. Representations from supervised learning with improved training strategies rival or outperform representations from \nstate-of-the-art self-supervised learning algorithms. Comparison of supervised training methods (supervised, RS) and self-supervised \nmethods (SimCLR, SimCLRv2) on a variety of downstream tasks. The (RS) strategy greatly outperforms the baseline supervised \ntraining, which highlights the importance of using improved supervised training techniques when comparing to self-supervised learning \nalgorithms. The RS training method uses a subset of the training methods highlighted in this work (cosine LR decay, RandAugment \nlabel smoothing, reduced weight decay, and dropout on FC) to more closely match those used in the self-supervised algorithms. All \nmodels employ the vanilla ResNet architecture without modifications and are pre-trained on ImageNet. \n\n","rows":["RS","400","90","800","SimCLRv2","Supervised","SimCLR","ResNet - 152 2x","ResNet - 152"],"columns":["Accuracy","ADE","Segmentation","NYU","Pascal","Detection","CIFAR - 100","Depth"],"mergedAllColumns":[],"numberCells":[{"number":"84.8","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLRv2","800"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"45.2","isBolded":true,"associatedRows":["ResNet - 152 2x","SimCLR","800"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"84.7","isBolded":false,"associatedRows":["ResNet - 152 2x","RS","400"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":false,"associatedRows":["ResNet - 152","RS","400"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"42.5","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLRv2","800"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"87.1","isBolded":false,"associatedRows":["ResNet - 152","SimCLR","800"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["ResNet - 152","Supervised","90"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"40.2","isBolded":false,"associatedRows":["ResNet - 152","Supervised","90"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["ResNet - 152","Supervised","90"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"86.1","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLRv2","800"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"75.5","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLRv2","800"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"41.0","isBolded":false,"associatedRows":["ResNet - 152","SimCLR","800"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"80.1","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLRv2","800"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"73.1","isBolded":false,"associatedRows":["ResNet - 152","SimCLRv2","800"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"86.8","isBolded":true,"associatedRows":["ResNet - 152 2x","SimCLR","800"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"86.6","isBolded":false,"associatedRows":["ResNet - 152 2x","Supervised","90"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLR","800"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"41.4","isBolded":false,"associatedRows":["ResNet - 152 2x","Supervised","90"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["ResNet - 152 2x","RS","400"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"42.2","isBolded":true,"associatedRows":["ResNet - 152","RS","400"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"89.3","isBolded":true,"associatedRows":["ResNet - 152 2x","RS","400"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["ResNet - 152 2x","Supervised","90"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"79.1","isBolded":false,"associatedRows":["ResNet - 152","SimCLRv2","800"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"84.7","isBolded":true,"associatedRows":["ResNet - 152","SimCLRv2","800"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"83.3","isBolded":true,"associatedRows":["ResNet - 152","SimCLR","800"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["ResNet - 152 2x","Supervised","90"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"41.1","isBolded":false,"associatedRows":["ResNet - 152","SimCLRv2","800"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"82.5","isBolded":false,"associatedRows":["ResNet - 152 2x","Supervised","90"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"83.5","isBolded":false,"associatedRows":["ResNet - 152","SimCLR","800"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"84.7","isBolded":false,"associatedRows":["ResNet - 152","SimCLRv2","800"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"88.1","isBolded":true,"associatedRows":["ResNet - 152","RS","400"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"78.2","isBolded":true,"associatedRows":["ResNet - 152","RS","400"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"83.4","isBolded":false,"associatedRows":["ResNet - 152","RS","400"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]},{"number":"78.8","isBolded":false,"associatedRows":["ResNet - 152 2x","SimCLR","800"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["ResNet - 152","Supervised","90"],"associatedColumns":["CIFAR - 100","Accuracy"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["ResNet - 152","SimCLR","800"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["ResNet - 152 2x","RS","400"],"associatedColumns":["ADE","Segmentation"],"associatedMergedColumns":[]},{"number":"85.3","isBolded":true,"associatedRows":["ResNet - 152 2x","SimCLR","800"],"associatedColumns":["Pascal","Detection"],"associatedMergedColumns":[]},{"number":"79.2","isBolded":true,"associatedRows":["ResNet - 152 2x","RS","400"],"associatedColumns":["Pascal","Segmentation"],"associatedMergedColumns":[]},{"number":"81.2","isBolded":false,"associatedRows":["ResNet - 152","Supervised","90"],"associatedColumns":["NYU","Depth"],"associatedMergedColumns":[]}]},{"caption":"Improvements \nTop-1 \n? \n\n3D ResNet-50 \n73.4 \n-\n+ Dropout on FC \n74.4 \n+1.0 \n+ Label smoothing \n74.9 \n+0.5 \n+ Stochastic depth \n76.1 \n+1.2 \n+ EMA of weights \n76.1 \n-\n+ Decrease weight decay \n76.3 \n+0.2 \n+ Increase training epochs \n76.4 \n+0.1 \n+ Scale jittering \n77.4 \n+1.0 \n+ Squeeze-and-Excitation \n77.9 \n+0.5 \n+ ResNet-D \n78.2 \n+0.3 \n\nTable 6. Additive study of training methods for video \nclassification. \nThe colors refer to Training Methods , \n\nRegularization Methods and Architecture Improvements . \nThe ResNet-RS training recipe transfers to a 3D ResNet model \non Kinetics-400 video classification (Kay et al., 2017). Reported \naccuracies are averaged over 2 runs. The baseline 3D ResNet-50 \nwas trained for 200 epochs with a cosine learning rate decay. \n\n","rows":["+ Dropout on FC","+ Squeeze - and - Excitation","+ Decrease weight decay","+ EMA of weights","3D ResNet - 50","+ ResNet - D","+ Label smoothing","+ Scale jittering","+ Stochastic depth","+ Increase training epochs"],"columns":["?","Top - 1"],"mergedAllColumns":["-"],"numberCells":[{"number":"+0.5","isBolded":true,"associatedRows":["+ Squeeze - and - Excitation"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"76.3","isBolded":false,"associatedRows":["+ Decrease weight decay"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.1","isBolded":true,"associatedRows":["+ Increase training epochs"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"78.2","isBolded":false,"associatedRows":["+ ResNet - D"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+1.2","isBolded":true,"associatedRows":["+ Stochastic depth"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"76.1","isBolded":false,"associatedRows":["+ EMA of weights"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"74.9","isBolded":false,"associatedRows":["+ Label smoothing"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"76.1","isBolded":false,"associatedRows":["+ Stochastic depth"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"73.4","isBolded":false,"associatedRows":["3D ResNet - 50"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":false,"associatedRows":["+ Squeeze - and - Excitation"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+1.0","isBolded":true,"associatedRows":["+ Scale jittering"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"76.4","isBolded":false,"associatedRows":["+ Increase training epochs"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.5","isBolded":true,"associatedRows":["+ Label smoothing"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"77.4","isBolded":false,"associatedRows":["+ Scale jittering"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"74.4","isBolded":false,"associatedRows":["+ Dropout on FC"],"associatedColumns":["Top - 1"],"associatedMergedColumns":["-"]},{"number":"+0.2","isBolded":true,"associatedRows":["+ Decrease weight decay"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+1.0","isBolded":true,"associatedRows":["+ Dropout on FC"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"+0.3","isBolded":true,"associatedRows":["+ ResNet - D"],"associatedColumns":["?"],"associatedMergedColumns":["-"]}]},{"caption":"A. Author Contributions \n\nIB, BZ: led the research, designed and ran the scaling experiments, designed and experimented with the training strate-\ngies. JS, TL, EC, AS, WF, XD: advised the research, proposed experiments and helped with the writing. AS, IB, BZ: \nran preliminary experiments using label smoothing, longer training and RandAugment. IB: demonstrated ResNets out-\nperforming EfficientNets across all scales, designed the scaling strategies and the Pareto curve of models, designed/ran \n(semi-)supervised learning experiments and significantly contributed to the writing. BZ: ran the regularization studies. \nWF, BZ: did a majority of the writing. BZ, EC: analyzed scaling experiments and generated the scaling plots. XD: \nproposed, designed and ran the 3D video classification experiments, lead the open-sourcing. AS: proposed lowering the \nweight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning. TL: \ndesigned and ran the transfer learning experiments comparing to self-supervised learning. \n\nB. Details of all ResNet-RS models in the Pareto curve \n\nThis section details all the models in the ResNet-RS Pareto curve. In Table 7, we observe that our ResNet-RS models get \nspeedups ranging from 1.7x -2.7x across the EfficientNet Pareto curve on TPUs. \n\nModel \nImage Resolution Params (M) FLOPs (B) V100 Latency (s) TPUv3 Latency (ms) Top-1 \n\nEfficientNet-B0 \n224 \n5.3 \n0.8 \n0.47 \n90 \n77.1 \nEfficientNet-B1 \n240 \n7.8 \n1.4 \n0.82 \n150 \n79.1 \nResNet-RS-50 \n160 \n36 \n4.6 \n0.31 \n70 \n78.8 \n\nEfficientNet-B2 \n260 \n9.2 \n2.0 \n1.03 \n210 \n80.1 \nResNet-RS-101 \n160 \n64 \n8.4 \n0.48 (2.1?) \n120 (1.8?) \n80.3 \n\nEfficientNet-B3 \n300 \n12 \n3.6 \n1.76 \n340 \n81.6 \nResNet-RS-101 \n192 \n64 \n12 \n0.70 \n170 \n81.2 \nResNet-RS-152 \n192 \n87 \n18 \n0.99 \n240 \n82.0 \n\nEfficientNet-B4 \n380 \n19 \n8.4 \n4.0 \n710 \n82.9 \nResNet-RS-152 \n224 \n87 \n24 \n1.48 (2.7?) \n320 (2.2?) \n82.8 \nResNet-RS-152 \n256 \n87 \n31 \n1.76 (2.3?) \n410 (1.7?) \n83.0 \n\nEfficientNet-B5 \n456 \n30 \n20 \n8.16 \n1510 \n83.7 \nResNet-RS-200 \n256 \n93 \n40 \n2.86 \n570 \n83.4 \nResNet-RS-270 \n256 \n130 \n54 \n3.76 (2.2?) \n780 (1.9?) \n83.8 \n\nEfficientNet-B6 \n528 \n43 \n38 \n15.7 \n3010 \n84.0 \nResNet-RS-350 \n256 \n164 \n69 \n4.72 (3.3?) \n1100 (2.7?) \n84.0 \n\nEfficientNet-B7 \n600 \n66 \n74 \n29.9 \n6020 \n84.7 \nResNet-RS-350 \n320 \n164 \n107 \n8.48 \n1630 \n84.2 \nResNet-RS-420 \n320 \n192 \n128 \n10.16 \n2090 \n84.4 \n\nTable 7. Details of ResNet-RS models in Pareto curve. All models are trained for 350 epochs using the improvements mentioned in \nSection 5. The exact hyperparameters for all ResNet-RS models are in Table 8. Latencies on Tesla V100 GPUs are measured with \nfull precision (float32). Latencies on TPUv3 are measured using bfloat16 precision. All latencies are measured with an initial \ntraining batch size of 128 images, which is divided by 2 until it fits onto the accelerator. \n\n","rows":["66","24","2090","69","Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 270","training batch size of","EfficientNet - B5","EfficientNet - B6","EfficientNet - B3","ResNet - RS - 152","EfficientNet - B4","ResNet - RS - 350","1510","speedups ranging from","1630","EfficientNet - B7","90","70","93","EfficientNet - B1","EfficientNet - B2","30","74","31","EfficientNet - B0","54","12","6020","36","38","18","19","3010","1100 ( 2 . 7? )","ResNet - RS - 50","ResNet - RS - 101","ResNet - RS - 200","ResNet - RS - 420","40","64","20","87","43"],"columns":["weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )","ran preliminary experiments using label smoothing , longer training and RandAugment .","V100 Latency ( s )","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","TPUv3 Latency ( ms )","BZ : ran the regularization studies .","XD :","A . Author Contributions","IB : demonstrated ResNets out -","The exact hyperparameters for all ResNet - RS models are in Table 8 .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","Image Resolution","TL :","Params ( M )","Top - 1"],"mergedAllColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get","full precision ( float32 ) . Latencies on TPUv3 are measured using bfloat16 precision . All latencies are measured with an initial"],"numberCells":[{"number":"10.16","isBolded":false,"associatedRows":["ResNet - RS - 420","66","74"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.76","isBolded":false,"associatedRows":["EfficientNet - B3","12","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"2.86","isBolded":false,"associatedRows":["ResNet - RS - 200","93","40"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"256","isBolded":false,"associatedRows":["ResNet - RS - 350"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"84.7","isBolded":false,"associatedRows":["EfficientNet - B7","66","74","6020"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"5.3","isBolded":false,"associatedRows":["EfficientNet - B0"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"8.4","isBolded":false,"associatedRows":["EfficientNet - B4","19"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.48(2.7?)","isBolded":false,"associatedRows":["ResNet - RS - 152","87","24"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"350epochsusingtheimprovementsmentionedin","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","XD :","TL :","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"150","isBolded":false,"associatedRows":["EfficientNet - B1","36","12"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"4.6","isBolded":false,"associatedRows":["ResNet - RS - 50","36"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"15.7","isBolded":false,"associatedRows":["EfficientNet - B6","43","38"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"84.0","isBolded":false,"associatedRows":["EfficientNet - B6","43","38","3010"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"600","isBolded":false,"associatedRows":["EfficientNet - B7"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"340","isBolded":false,"associatedRows":["EfficientNet - B3","12","12"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"29.9","isBolded":false,"associatedRows":["EfficientNet - B7","66","74"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.99","isBolded":false,"associatedRows":["ResNet - RS - 152","87","18"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"164","isBolded":false,"associatedRows":["ResNet - RS - 350"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.76(2.3?)","isBolded":false,"associatedRows":["ResNet - RS - 152","87","31"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"710","isBolded":false,"associatedRows":["EfficientNet - B4","19","24"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"79.1","isBolded":false,"associatedRows":["EfficientNet - B1","36","12","90"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"320","isBolded":false,"associatedRows":["ResNet - RS - 420"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"82.9","isBolded":false,"associatedRows":["EfficientNet - B4","19","24","1510"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"128","isBolded":false,"associatedRows":["ResNet - RS - 420","66"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"8.48","isBolded":false,"associatedRows":["ResNet - RS - 350","66","74"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"380","isBolded":false,"associatedRows":["EfficientNet - B4"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"107","isBolded":false,"associatedRows":["ResNet - RS - 350","66"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"128images,whichisdividedby2untilitfitsontotheaccelerator.","isBolded":false,"associatedRows":["training batch size of"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )","The exact hyperparameters for all ResNet - RS models are in Table 8 ."],"associatedMergedColumns":["full precision ( float32 ) . Latencies on TPUv3 are measured using bfloat16 precision . All latencies are measured with an initial"]},{"number":"0.47","isBolded":false,"associatedRows":["EfficientNet - B0","36","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"780(1.9?)","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 270","54"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"410(1.7?)","isBolded":false,"associatedRows":["ResNet - RS - 152","87","31"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"83.0","isBolded":false,"associatedRows":["ResNet - RS - 152","87","31","1510"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"160","isBolded":false,"associatedRows":["ResNet - RS - 101"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.7x-2.7xacrosstheEfficientNetParetocurveonTPUs.","isBolded":true,"associatedRows":["speedups ranging from"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning ."],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"192","isBolded":false,"associatedRows":["ResNet - RS - 420"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.70","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"256","isBolded":false,"associatedRows":["ResNet - RS - 152"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"130","isBolded":false,"associatedRows":["ResNet - RS - 270"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.4","isBolded":false,"associatedRows":["EfficientNet - B1","36"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.48(2.1?)","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"224","isBolded":false,"associatedRows":["ResNet - RS - 152"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"300","isBolded":false,"associatedRows":["EfficientNet - B3"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"240","isBolded":false,"associatedRows":["EfficientNet - B1"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"84.0","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 350","69","1100 ( 2 . 7? )"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"84.2","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 350","1630"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"160","isBolded":false,"associatedRows":["ResNet - RS - 50"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"83.4","isBolded":false,"associatedRows":["ResNet - RS - 200","93","40","1100 ( 2 . 7? )"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"120(1.8?)","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"8.4","isBolded":false,"associatedRows":["ResNet - RS - 101","64"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"83.8","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 270","54","1100 ( 2 . 7? )"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"164","isBolded":false,"associatedRows":["ResNet - RS - 350"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"81.2","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12","70"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"256","isBolded":false,"associatedRows":["ResNet - RS - 270"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"210","isBolded":false,"associatedRows":["EfficientNet - B2","64","12"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"81.6","isBolded":false,"associatedRows":["EfficientNet - B3","12","12","70"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"1.03","isBolded":false,"associatedRows":["EfficientNet - B2","64","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"80.3","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12","70"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"192","isBolded":false,"associatedRows":["ResNet - RS - 101"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"320","isBolded":false,"associatedRows":["ResNet - RS - 350"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"320(2.2?)","isBolded":false,"associatedRows":["ResNet - RS - 152","87","24"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"170","isBolded":false,"associatedRows":["ResNet - RS - 101","64","12"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"78.8","isBolded":false,"associatedRows":["ResNet - RS - 50","36","12","70"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"8.16","isBolded":false,"associatedRows":["EfficientNet - B5","30","20"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"2.0","isBolded":false,"associatedRows":["EfficientNet - B2","64"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"82.8","isBolded":false,"associatedRows":["ResNet - RS - 152","87","24","1510"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"456","isBolded":false,"associatedRows":["EfficientNet - B5"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"82.0","isBolded":false,"associatedRows":["ResNet - RS - 152","87","18","1510"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"570","isBolded":false,"associatedRows":["ResNet - RS - 200","93","40"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"224","isBolded":false,"associatedRows":["EfficientNet - B0"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.31","isBolded":false,"associatedRows":["ResNet - RS - 50","36","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"240","isBolded":false,"associatedRows":["ResNet - RS - 152","87","18"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","TPUv3 Latency ( ms )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"528","isBolded":false,"associatedRows":["EfficientNet - B6"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"7.8","isBolded":false,"associatedRows":["EfficientNet - B1"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.82","isBolded":false,"associatedRows":["EfficientNet - B1","36","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"3.6","isBolded":false,"associatedRows":["EfficientNet - B3","12"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"84.4","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","ResNet - RS - 420","2090"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"192","isBolded":false,"associatedRows":["ResNet - RS - 152"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"256","isBolded":false,"associatedRows":["ResNet - RS - 200"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"260","isBolded":false,"associatedRows":["EfficientNet - B2"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","WF , BZ : did a majority of the writing .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Image Resolution"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"80.1","isBolded":false,"associatedRows":["Table 7 . Details of ResNet - RS models in Pareto curve . All models are trained for","EfficientNet - B2","12","70"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"4.72(3.3?)","isBolded":false,"associatedRows":["ResNet - RS - 350","43","69"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"9.2","isBolded":false,"associatedRows":["EfficientNet - B2"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Params ( M )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"77.1","isBolded":false,"associatedRows":["EfficientNet - B0","36","12","90"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"3.76(2.2?)","isBolded":false,"associatedRows":["ResNet - RS - 270","93","54"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"0.8","isBolded":false,"associatedRows":["EfficientNet - B0","36"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","FLOPs ( B )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"4.0","isBolded":false,"associatedRows":["EfficientNet - B4","19","24"],"associatedColumns":["A . Author Contributions","ran preliminary experiments using label smoothing , longer training and RandAugment .","( semi - ) supervised learning experiments and significantly contributed to the writing .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","V100 Latency ( s )"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]},{"number":"83.7","isBolded":false,"associatedRows":["EfficientNet - B5","30","20","1510"],"associatedColumns":["A . Author Contributions","IB : demonstrated ResNets out -","BZ : ran the regularization studies .","BZ , EC : analyzed scaling experiments and generated the scaling plots .","weight decay for better performance and ran preliminary experiments comparing SimCLR to supervised learning .","Top - 1"],"associatedMergedColumns":["This section details all the models in the ResNet - RS Pareto curve . In Table 7 , we observe that our ResNet - RS models get"]}]},{"caption":"Table 8. Hyperparameters for all ResNet-RS models. All models train for 350 epochs, use a weight decay of 4e-5, an EMA value of \n0.9999 (for both weights and Batch Norm moving averages), 2 layers of RandAugment (with different magnitudes as shown above) and \na label smoothing rate of 0.1. The learning rate is warmed up to a maximum value of 0.1/B, with B the batch size, and decayed to 0 \nusing a cosine schedule (Loshchilov \u0026 Hutter, 2016). Dropout rate means each activation after the global average pooling layers gets \ndropped out with probability dropout rate. \n\n","rows":["ResNet - RS - 152","256","224","ResNet - RS - 270"],"columns":["top - 1 Val","top - 1 Test"],"mergedAllColumns":[],"numberCells":[{"number":"83.7","isBolded":false,"associatedRows":["ResNet - RS - 270","256"],"associatedColumns":["top - 1 Test"],"associatedMergedColumns":[]},{"number":"82.7","isBolded":false,"associatedRows":["ResNet - RS - 152","224"],"associatedColumns":["top - 1 Test"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["ResNet - RS - 270","256"],"associatedColumns":["top - 1 Val"],"associatedMergedColumns":[]},{"number":"82.8","isBolded":false,"associatedRows":["ResNet - RS - 152","224"],"associatedColumns":["top - 1 Val"],"associatedMergedColumns":[]}]},{"caption":"Table 10. Comparing training method between ResNet, ResNet-RS and EfficientNet. ResNet (2015) refers to the ResNet originally \ntrained in He et al. (2015). \n\n","rows":["Epochs Trained","90"],"columns":["isntead of exponential decay and Momentum instead of RMSProp . Both simplifications reduce the total number of hyper -","EfficientNets ( 2019 )","ResNet - RS ( 2021 )"],"mergedAllColumns":["parameters as ( 1 ) cosine decay has no hyperparameters associated with it and ( 2 ) Momentum has one less than RMSProp ."],"numberCells":[{"number":"350","isBolded":false,"associatedRows":["Epochs Trained","90"],"associatedColumns":["isntead of exponential decay and Momentum instead of RMSProp . Both simplifications reduce the total number of hyper -","ResNet - RS ( 2021 )"],"associatedMergedColumns":["parameters as ( 1 ) cosine decay has no hyperparameters associated with it and ( 2 ) Momentum has one less than RMSProp ."]},{"number":"350","isBolded":false,"associatedRows":["Epochs Trained","90"],"associatedColumns":["isntead of exponential decay and Momentum instead of RMSProp . Both simplifications reduce the total number of hyper -","EfficientNets ( 2019 )"],"associatedMergedColumns":["parameters as ( 1 ) cosine decay has no hyperparameters associated with it and ( 2 ) Momentum has one less than RMSProp ."]}]}]