[{"caption":"Table 2: Changes in automatic evaluation metrics after models were fine tuned on various objectives. QA refers \nto the F1 score obtained by a question answering system on the generated questions. LM refers to the perplexity \nof generated questions under a separate language model. The discriminator reward refers to the percentage of \ngenerated sequences that fooled the discriminator. Lower LM and NLL scores are better. BLEU scores decreased \nin all cases. \n\n","rows":["+QA , LM rewards","+QA , LM , discriminator rewards +Adversarial discriminator","No fine tuning","Ground Truth"],"columns":["Relevance","Fluency"],"mergedAllColumns":[],"numberCells":[{"number":"3.12","isBolded":true,"associatedRows":["No fine tuning"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"4.67","isBolded":false,"associatedRows":["Ground Truth"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"3.05","isBolded":false,"associatedRows":["+QA , LM rewards"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"2.75","isBolded":false,"associatedRows":["+QA , LM rewards"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"2.82","isBolded":false,"associatedRows":["+QA , LM , discriminator rewards +Adversarial discriminator"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"4.72","isBolded":false,"associatedRows":["Ground Truth"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"3.34","isBolded":true,"associatedRows":["No fine tuning"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"2.89","isBolded":false,"associatedRows":["+QA , LM , discriminator rewards +Adversarial discriminator"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Summary of human evaluation of selected models \n\n","rows":["+QA , LM rewards","+QA , LM , discriminator rewards +Adversarial discriminator","No fine tuning","Ground Truth"],"columns":["Relevance","Fluency"],"mergedAllColumns":[],"numberCells":[{"number":"4.72","isBolded":false,"associatedRows":["Ground Truth"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"2.75","isBolded":false,"associatedRows":["+QA , LM rewards"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"2.89","isBolded":false,"associatedRows":["+QA , LM , discriminator rewards +Adversarial discriminator"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"4.67","isBolded":false,"associatedRows":["Ground Truth"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"3.34","isBolded":true,"associatedRows":["No fine tuning"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"2.82","isBolded":false,"associatedRows":["+QA , LM , discriminator rewards +Adversarial discriminator"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]},{"number":"3.05","isBolded":false,"associatedRows":["+QA , LM rewards"],"associatedColumns":["Fluency"],"associatedMergedColumns":[]},{"number":"3.12","isBolded":true,"associatedRows":["No fine tuning"],"associatedColumns":["Relevance"],"associatedMergedColumns":[]}]}]