[{"caption":"2828 1414 \n\n2828 1414 \n\n2828 1414 \n\n2828 1414 \n\n2828 1414 \n\n1024 512 \n\n... \n2828 1414 \n\nt?5 \nt \nFigure 1: Unfolded maxout RNN architecture (right arrows in \nthe boxes denote the maxout operation). \n\nusing the state-based MBR criterion for 10 iterations. \n\nModel \nWER SWB WER CH \nRNN sigmoid (CE) \n10.8 \n16.9 \nRNN maxout (CE) \n10.4 \n16.2 \nRNN maxout (ST) \n9.3 \n15.4 \n\nTable 1: Word error rates for sigmoid vs. Maxout RNNs trained \nwith annealed dropout on Hub5\u002700 after cross-entropy training \n(and sequence training for Maxout). \n\n","rows":["RNN maxout ( CE )","RNN sigmoid ( CE )","RNN maxout ( ST )"],"columns":["Unfolded maxout RNN architecture ( right arrows in","t","512","WER CH","WER SWB"],"mergedAllColumns":["using the state - based MBR criterion for 10 iterations ."],"numberCells":[{"number":"16.9","isBolded":true,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER CH"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]},{"number":"15.4","isBolded":true,"associatedRows":["RNN maxout ( ST )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER CH"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]},{"number":"1414","isBolded":false,"associatedRows":[],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"1414","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"1024","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1414","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"10.8","isBolded":true,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER SWB"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]},{"number":"16.2","isBolded":true,"associatedRows":["RNN maxout ( CE )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER CH"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]},{"number":"2828","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"1414","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"2828","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"2828","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"2828","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"2828","isBolded":false,"associatedRows":[],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"10.4","isBolded":true,"associatedRows":["RNN maxout ( CE )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER SWB"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]},{"number":"1414","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"2828","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"1414","isBolded":false,"associatedRows":["RNN sigmoid ( CE )"],"associatedColumns":["512"],"associatedMergedColumns":[]},{"number":"9.3","isBolded":true,"associatedRows":["RNN maxout ( ST )"],"associatedColumns":["512","t","Unfolded maxout RNN architecture ( right arrows in","WER SWB"],"associatedMergedColumns":["using the state - based MBR criterion for 10 iterations ."]}]},{"caption":"Table 2: WER on the SWB part of the Hub5\u002700 testset, for \n3 variants of the 10-convolutional-layer CNN: with pooling in \ntime (a), without pooling in time (b), and without pooling nor \npadding in time (c). For more details see ","rows":["Classic maxout [ 11 ]","( c ) 10 - conv No pool , no pad","( b ) 10 - conv No pool","Classic sigmoid [ 17 ]","( a ) 10 - conv Pool"],"columns":["ST","CE","SWB ( 2000h )","-","SWB ( 300h )"],"mergedAllColumns":[],"numberCells":[{"number":"10.5","isBolded":false,"associatedRows":["( a ) 10 - conv Pool"],"associatedColumns":["SWB ( 300h )","ST","-"],"associatedMergedColumns":[]},{"number":"10.8","isBolded":false,"associatedRows":["( c ) 10 - conv No pool , no pad"],"associatedColumns":["SWB ( 300h )","ST","-"],"associatedMergedColumns":[]},{"number":"10.9","isBolded":false,"associatedRows":["( b ) 10 - conv No pool"],"associatedColumns":["SWB ( 300h )","ST","-"],"associatedMergedColumns":[]},{"number":"11.8","isBolded":false,"associatedRows":["Classic sigmoid [ 17 ]"],"associatedColumns":["SWB ( 300h )","ST"],"associatedMergedColumns":[]},{"number":"10.7","isBolded":false,"associatedRows":["( b ) 10 - conv No pool"],"associatedColumns":["SWB ( 2000h )","CE","-"],"associatedMergedColumns":[]},{"number":"11.7*","isBolded":false,"associatedRows":["Classic maxout [ 11 ]"],"associatedColumns":["SWB ( 2000h )","CE","-"],"associatedMergedColumns":[]},{"number":"11.2","isBolded":false,"associatedRows":["Classic maxout [ 11 ]"],"associatedColumns":["SWB ( 300h )","ST","-"],"associatedMergedColumns":[]},{"number":"9.7","isBolded":false,"associatedRows":["( b ) 10 - conv No pool"],"associatedColumns":["SWB ( 2000h )","ST","-"],"associatedMergedColumns":[]},{"number":"10.2","isBolded":false,"associatedRows":["( a ) 10 - conv Pool"],"associatedColumns":["SWB ( 2000h )","CE","-"],"associatedMergedColumns":[]},{"number":"10.8","isBolded":false,"associatedRows":["( c ) 10 - conv No pool , no pad"],"associatedColumns":["SWB ( 2000h )","CE","-"],"associatedMergedColumns":[]},{"number":"13.2","isBolded":false,"associatedRows":["Classic sigmoid [ 17 ]"],"associatedColumns":["SWB ( 300h )","CE"],"associatedMergedColumns":[]},{"number":"11.8","isBolded":false,"associatedRows":["( a ) 10 - conv Pool"],"associatedColumns":["SWB ( 300h )","CE","-"],"associatedMergedColumns":[]},{"number":"9.9*","isBolded":false,"associatedRows":["Classic maxout [ 11 ]"],"associatedColumns":["SWB ( 2000h )","ST","-"],"associatedMergedColumns":[]},{"number":"11.5","isBolded":false,"associatedRows":["( b ) 10 - conv No pool"],"associatedColumns":["SWB ( 300h )","CE","-"],"associatedMergedColumns":[]},{"number":"12.6","isBolded":false,"associatedRows":["Classic maxout [ 11 ]"],"associatedColumns":["SWB ( 300h )","CE","-"],"associatedMergedColumns":[]},{"number":"9.4","isBolded":true,"associatedRows":["( a ) 10 - conv Pool"],"associatedColumns":["SWB ( 2000h )","ST","-"],"associatedMergedColumns":[]},{"number":"9.7","isBolded":false,"associatedRows":["( c ) 10 - conv No pool , no pad"],"associatedColumns":["SWB ( 2000h )","ST","-"],"associatedMergedColumns":[]},{"number":"11.9","isBolded":false,"associatedRows":["( c ) 10 - conv No pool , no pad"],"associatedColumns":["SWB ( 300h )","CE","-"],"associatedMergedColumns":[]}]},{"caption":"input (40x16) \n\n3x3 conv, 64 \n\n3x3 conv, 64 \n\n3x3 conv, 128 \n\n3x3 conv, 128 \n\n2x1 pool \n\n3x3 conv, 256 \n\n3x3 conv, 256 \n\n2x1 pool \n\n3x3 conv, 256 \n\n2x2 pool \n\n3x3 conv, 512 \n\n3x3 conv, 512 \n\n4 x 8 \n\n3x3 conv, 512 \n\n2x2 pool \n\nFC 2048 \n\nFC 2048 \n\nFC 2048 \n\nFC #hmm states \n\n10-conv \n\ninput (40x16) \n\n3x3 conv, 64 \n\n3x3 conv, 64 \n\n3x3 conv, 128 \n\n3x3 conv, 128 \n\n2x1 pool \n\n3x3 conv, 256 \n\n3x3 conv, 256 \n\n2x1 pool \n\n2x2 pool \n\n3x3 conv, 512 \n\n3x3 conv, 512 \n\n2x2 pool \n\nFC 2048 \n\nFC 2048 \n\nFC 2048 \n\nFC #hmm states \n\n8-conv \n\ninput (40x16) \n\n3x3 conv, 64 \n\n3x3 conv, 64 \n\n3x3 conv, 128 \n\n3x3 conv, 128 \n\n2x1 pool \n\n3x3 conv, 256 \n\n3x3 conv, 256 \n\n2x2 pool \n\n2x1 pool \n\nFC 2048 \n\nFC 2048 \n\nFC #hmm states \n\n6-conv \n\ninput (40x11) \n\n9x9 conv, 512 \n\n4x3 conv, 512 \n\nFC 2048 \n\nFC 2048 \n\nFC 2048 \n\nFC #hmm states \n\n2-conv (classic) \n\n3x1 pool \n\nFC 2048 \n\nfeaturemap size \n(freq x time) \n\n40 x 16 \n\n20 x 16 \n\n10 x 16 \n\n2 x 4 \n\nFigure 2: The design of the VGG nets: (1) classical CNN, (2-4) very deep CNNs from [14] with 6, 8 and 10 convolutional layers \nrespectively. The deepest CNN (10-conv) obtains best performance. This figure corresponds to [14] Table 1. \n\n","rows":["4x3 conv ,","3x3 conv ,","3x1 pool","9x9 conv ,"],"columns":["2x2 pool","2 - conv ( classic )","6 - conv","FC 2048","2x1 pool","8 - conv","10 - conv","FC #hmm states"],"mergedAllColumns":["2x2 pool","20 x 16","FC 2048","2x1 pool","10 x 16"],"numberCells":[{"number":"256","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool"],"associatedMergedColumns":["2x2 pool"]},{"number":"128","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool","2x2 pool"],"associatedMergedColumns":["2x1 pool"]},{"number":"128","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["20 x 16"]},{"number":"256","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["2x2 pool"]},{"number":"128","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["2x1 pool"]},{"number":"512","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool"],"associatedMergedColumns":["FC 2048"]},{"number":"512","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool"],"associatedMergedColumns":["FC 2048"]},{"number":"512","isBolded":false,"associatedRows":["4x3 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","2 - conv ( classic )","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","FC 2048"],"associatedMergedColumns":["FC 2048"]},{"number":"128","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["2x1 pool"]},{"number":"256","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x2 pool"],"associatedMergedColumns":["2x2 pool"]},{"number":"512","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool"],"associatedMergedColumns":["FC 2048"]},{"number":"512","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool"],"associatedMergedColumns":["FC 2048"]},{"number":"512","isBolded":false,"associatedRows":["4x3 conv ,","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool"],"associatedMergedColumns":["FC 2048"]},{"number":"256","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x2 pool"],"associatedMergedColumns":["10 x 16"]},{"number":"256","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool"],"associatedMergedColumns":["10 x 16"]},{"number":"256","isBolded":false,"associatedRows":["3x1 pool","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool"],"associatedMergedColumns":["2x2 pool"]},{"number":"128","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool","2x2 pool"],"associatedMergedColumns":["20 x 16"]},{"number":"128","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,","3x3 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["20 x 16"]},{"number":"512","isBolded":false,"associatedRows":["9x9 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","2 - conv ( classic )","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","FC 2048"],"associatedMergedColumns":["FC 2048"]},{"number":"256","isBolded":false,"associatedRows":["9x9 conv ,","3x3 conv ,"],"associatedColumns":["10 - conv","6 - conv","8 - conv","FC #hmm states","FC 2048","FC 2048","FC 2048","2x2 pool","2x2 pool","2x1 pool"],"associatedMergedColumns":["10 x 16"]}]},{"caption":"Table 3: Word error rates on Hub5 2000 for various LSTM \nmodels trained with cross-entropy on 300 hours. \n\n","rows":["4 - layer 512 FMLLR+ivec","1 - layer 1024 bottleneck","3 - layer 1024 FMLLR+ivec","2 - layer 1024 FMLLR+ivec"],"columns":["WER CH","gle layer bidirectional LSTM trained on 128 - dim features ob -","WER SWB"],"mergedAllColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."],"numberCells":[{"number":"19.3","isBolded":false,"associatedRows":["1 - layer 1024 bottleneck"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER CH"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"19.2","isBolded":false,"associatedRows":["2 - layer 1024 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER CH"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"11.0","isBolded":false,"associatedRows":["3 - layer 1024 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER SWB"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"11.1","isBolded":false,"associatedRows":["2 - layer 1024 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER SWB"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"19.3","isBolded":false,"associatedRows":["4 - layer 512 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER CH"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"18.5","isBolded":false,"associatedRows":["3 - layer 1024 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER CH"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"10.8","isBolded":false,"associatedRows":["4 - layer 512 FMLLR+ivec"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER SWB"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]},{"number":"11.8","isBolded":false,"associatedRows":["1 - layer 1024 bottleneck"],"associatedColumns":["gle layer bidirectional LSTM trained on 128 - dim features ob -","WER SWB"],"associatedMergedColumns":["of cross - entropy SGD on the 300 hour ( SWB - 1 ) subset ."]}]},{"caption":"Table 4: Word error rates on Hub5 2000 for DNN and LSTM \nmodels. All models are trained on 2000 hours with cross-\nentropy and sequence discriminative training. \n\n","rows":["1 - layer LSTM ( reset )","6 - layer DNN","1 - layer LSTM ( carry - over )","4 - layer LSTM ( reset )","-"],"columns":["ST","CE","WER CH","the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB"],"mergedAllColumns":["and the two single layer LSTMs trained on bottleneck features .","-"],"numberCells":[{"number":"17.6","isBolded":false,"associatedRows":["1 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","CE"],"associatedMergedColumns":["-"]},{"number":"16.8","isBolded":false,"associatedRows":["1 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","ST"],"associatedMergedColumns":["-"]},{"number":"15.7","isBolded":false,"associatedRows":["4 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","CE"],"associatedMergedColumns":["-"]},{"number":"10.5","isBolded":false,"associatedRows":["1 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","CE"],"associatedMergedColumns":["-"]},{"number":"18.5","isBolded":false,"associatedRows":["6 - layer DNN"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","CE"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]},{"number":"15.1","isBolded":false,"associatedRows":["4 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","ST"],"associatedMergedColumns":["-"]},{"number":"17.0","isBolded":false,"associatedRows":["6 - layer DNN"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","ST"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]},{"number":"9.0","isBolded":false,"associatedRows":["4 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","ST"],"associatedMergedColumns":["-"]},{"number":"10.9","isBolded":false,"associatedRows":["1 - layer LSTM ( carry - over )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","CE"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]},{"number":"10.3","isBolded":false,"associatedRows":["6 - layer DNN"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","ST"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]},{"number":"18.3","isBolded":false,"associatedRows":["1 - layer LSTM ( carry - over )","-"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER CH","CE"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]},{"number":"9.5","isBolded":false,"associatedRows":["4 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","CE"],"associatedMergedColumns":["-"]},{"number":"10.0","isBolded":false,"associatedRows":["1 - layer LSTM ( reset )"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","ST"],"associatedMergedColumns":["-"]},{"number":"11.7","isBolded":false,"associatedRows":["6 - layer DNN"],"associatedColumns":["the bottleneck features and of a 4 - layer 512 unit LSTM . We ob -","WER SWB","CE"],"associatedMergedColumns":["and the two single layer LSTMs trained on bottleneck features ."]}]},{"caption":"Table 5: Word error rates for individual acoustic models and \nframe-level score fusions on Hub5 2000. \n\n","rows":["VGG ( a ) from Table 2","RNN+VGG+LSTM","RNN+VGG","LSTM ( 4 - layer , 512 )","RNN maxout","VGG+LSTM"],"columns":["WER CH","WER SWB"],"mergedAllColumns":[],"numberCells":[{"number":"15.7","isBolded":false,"associatedRows":["VGG ( a ) from Table 2"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"14.4","isBolded":false,"associatedRows":["RNN+VGG+LSTM"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"9.4","isBolded":false,"associatedRows":["VGG ( a ) from Table 2"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"8.6","isBolded":false,"associatedRows":["VGG+LSTM"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["VGG+LSTM"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"9.3","isBolded":false,"associatedRows":["RNN maxout"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"8.6","isBolded":false,"associatedRows":["RNN+VGG+LSTM"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"15.1","isBolded":false,"associatedRows":["LSTM ( 4 - layer , 512 )"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"14.5","isBolded":false,"associatedRows":["RNN+VGG"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"15.4","isBolded":false,"associatedRows":["RNN maxout"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"9.0","isBolded":false,"associatedRows":["LSTM ( 4 - layer , 512 )"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"8.7","isBolded":false,"associatedRows":["RNN+VGG"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Comparison of word error rates for different LMs. \n\n","rows":["30K vocab , 4M n - grams","n - gram + model M","n - gram + NNLM","n - gram + model M + NNLM","85K vocab , 36M n - grams"],"columns":["WER CH","WER SWB"],"mergedAllColumns":[],"numberCells":[{"number":"8.6","isBolded":false,"associatedRows":["30K vocab , 4M n - grams"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"14.4","isBolded":false,"associatedRows":["30K vocab , 4M n - grams"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"6.6","isBolded":false,"associatedRows":["n - gram + model M + NNLM"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"13.7","isBolded":false,"associatedRows":["85K vocab , 36M n - grams"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"12.2","isBolded":false,"associatedRows":["n - gram + model M + NNLM"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"7.0","isBolded":false,"associatedRows":["n - gram + model M"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"7.6","isBolded":false,"associatedRows":["85K vocab , 36M n - grams"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]},{"number":"12.4","isBolded":false,"associatedRows":["n - gram + NNLM"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"12.6","isBolded":false,"associatedRows":["n - gram + model M"],"associatedColumns":["WER CH"],"associatedMergedColumns":[]},{"number":"6.8","isBolded":false,"associatedRows":["n - gram + NNLM"],"associatedColumns":["WER SWB"],"associatedMergedColumns":[]}]}]