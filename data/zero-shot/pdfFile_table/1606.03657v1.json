[{"caption":"Table 1. The discriminator D and the recognition network Q \nshares most of the network. For this task, we use 1 ten-dimensional categorical code, 2 continuous \nlatent codes and 62 noise variables, resulting in a concatenated dimension of 74. \n\n","rows":["Input 28 ? 28 Gray image","FC . 128 - batchnorm - lRELU - FC . output for Q","FC .","FC . 1024 lRELU . batchnorm"],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R 74","FC . 1024 RELU . batchnorm","FC . output layer for D ,"],"numberCells":[{"number":"7?128RELU.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R 74"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"4upconv.64RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R 74"]},{"number":"7?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"1channel","isBolded":true,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"2","isBolded":true,"associatedRows":["Input 28 ? 28 Gray image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]}]},{"caption":"Table 1: The discriminator and generator CNNs used for MNIST dataset. \n\n","rows":["Input 28 ? 28 Gray image","FC . 128 - batchnorm - lRELU - FC . output for Q","FC .","FC . 1024 lRELU . batchnorm"],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R 74","FC . 1024 RELU . batchnorm","FC . output layer for D ,"],"numberCells":[{"number":"7?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"7?128RELU.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R 74"]},{"number":"1channel","isBolded":true,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"4?","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R 74"]},{"number":"4upconv.64RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"2","isBolded":true,"associatedRows":["Input 28 ? 28 Gray image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]}]},{"caption":"Table 2: The discriminator and generator CNNs used for SVHN dataset. \n\n","rows":["Input 32 ? 32 Color image","FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R","168","FC . output layer for D ,"],"numberCells":[{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"2?448RELU.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["168"]},{"number":"4conv.256lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"2","isBolded":true,"associatedRows":["Input 32 ? 32 Color image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["168"]},{"number":"4upconv.64RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["168"]},{"number":"4upconv.256RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["168"]},{"number":"4upconv.128RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"3Tanh.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"2?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["168"]}]},{"caption":"Table 3: The discriminator and generator CNNs used for SVHN dataset. \n\n","rows":["Input 32 ? 32 Color image","FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R","228","FC . output layer for D ,"],"numberCells":[{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4upconv.64RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"3Tanh.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"2","isBolded":true,"associatedRows":["Input 32 ? 32 Color image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"4conv.256lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4upconv.256RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4upconv.128RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"2?448RELU.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["228"]},{"number":"2?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["228"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]}]},{"caption":"Table 4. The discriminator D and the recognition network Q \nshares the same network, and only have separate output units at the last layer. For this task, we use 5 \ncontinuous latent codes and 128 noise variables, so the input to the generator has dimension 133. \n\n","rows":["Input 32 ? 32 Color image","FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R","228","FC . output layer for D ,"],"numberCells":[{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4upconv.128RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"3Tanh.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"2?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["228"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"2","isBolded":true,"associatedRows":["Input 32 ? 32 Color image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"2?448RELU.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["228"]},{"number":"4upconv.256RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . output layer for D ,"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"4upconv.64RELU.stride2.","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["228"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4conv.256lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 128 - batchnorm - lRELU - FC . output for Q"],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R"]}]},{"caption":"Table 4: The discriminator and generator CNNs used for Faces dataset. \n\n","rows":["Input 32 ? 32 Gray image","FC . output layer","FC . 1024 lRELU . batchnorm","FC ."],"columns":["generator G","discriminator D / recognition network Q"],"mergedAllColumns":["Input ? R 133","FC . 1024 RELU . batchnorm"],"numberCells":[{"number":"1sigmoid.","isBolded":true,"associatedRows":["FC . output layer"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4conv.64lRELU.stride","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"2","isBolded":true,"associatedRows":["Input 32 ? 32 Gray image"],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"4upconv.64RELU.stride2.batchnorm","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":[]},{"number":"8?","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4?","isBolded":false,"associatedRows":["FC . output layer"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"8?128RELU.batchnorm","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm","FC ."],"associatedColumns":["generator G"],"associatedMergedColumns":["Input ? R 133"]},{"number":"4?","isBolded":false,"associatedRows":["FC . 1024 lRELU . batchnorm"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4upconv.","isBolded":false,"associatedRows":["FC . output layer"],"associatedColumns":["generator G"],"associatedMergedColumns":["FC . 1024 RELU . batchnorm"]},{"number":"4conv.128lRELU.stride2.batchnorm","isBolded":false,"associatedRows":[],"associatedColumns":["discriminator D / recognition network Q"],"associatedMergedColumns":["Input ? R 133"]}]},{"caption":"Table 5: The hyperparameters for Faces dataset. \n\n","rows":["Azimuth ( pose )","Elevation","8e - 4","2e - 4","3e - 4","Lighting","4e - 4","5e - 4"],"columns":["?"],"mergedAllColumns":[],"numberCells":[{"number":"0.2","isBolded":false,"associatedRows":["Azimuth ( pose )","2e - 4","5e - 4"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Lighting","8e - 4","3e - 4"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Elevation","4e - 4","3e - 4"],"associatedColumns":["?"],"associatedMergedColumns":[]}]}]