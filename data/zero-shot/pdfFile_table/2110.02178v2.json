[{"caption":"Table 1: Detection w/ SSDLite. \n\n","rows":["MobileNetv2","MobileNetv1","MixNet","ResNet50","VGG","MobileViT - S ( Ours )","MobileViT - XS ( Ours )","MobileNetv3","MNASNet"],"columns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params .","mAP"],"mergedAllColumns":["( a ) Comparison w / light - weight CNNs"],"numberCells":[{"number":"4.9M","isBolded":false,"associatedRows":["MobileNetv3"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"22.0","isBolded":false,"associatedRows":["MobileNetv3"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"4.3M","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":true,"associatedRows":["ResNet50"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params .","# Params ."],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"25.2","isBolded":false,"associatedRows":["ResNet50"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP","mAP"],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"27.7","isBolded":true,"associatedRows":["MobileViT - S ( Ours )","MobileViT - S ( Ours )"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP","mAP"],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"4.5M","isBolded":false,"associatedRows":["MixNet"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"22.1","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"27.7","isBolded":true,"associatedRows":["MobileViT - S ( Ours )"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"5.1M","isBolded":false,"associatedRows":["MobileNetv1"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"23.0","isBolded":false,"associatedRows":["MNASNet"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"2.7M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours )"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"22.9M","isBolded":false,"associatedRows":["ResNet50"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params .","# Params ."],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"22.3","isBolded":false,"associatedRows":["MixNet"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"35.6M","isBolded":false,"associatedRows":["VGG"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params .","# Params ."],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"24.8","isBolded":false,"associatedRows":["MobileViT - XS ( Ours )"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"22.2","isBolded":false,"associatedRows":["MobileNetv1"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP"],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["MobileViT - S ( Ours )"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]},{"number":"25.1","isBolded":false,"associatedRows":["VGG"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","mAP","mAP"],"associatedMergedColumns":["( a ) Comparison w / light - weight CNNs"]},{"number":"4.9M","isBolded":false,"associatedRows":["MNASNet"],"associatedColumns":["semantic segmentation ( ?4 . 2 . 2 ) .","MOBILE OBJECT DETECTION","# Params ."],"associatedMergedColumns":[]}]},{"caption":"Table 2: Segmentation w/ DeepLabv3. \n\n","rows":["MobileNetv2","MobileNetv1","MobileViT - S ( Ours )","MobileViT - XXS ( Ours )","ResNet - 101","MobileViT - XS ( Ours )","instance , SSDLite \u0027 s performance improves by 1 . 8% , and its model size reduces by"],"columns":["mIOU","?F confirms MobileViT \u0027 s ability to detect variety of objects .","# Params .","Table 1a shows that , for the same input resolu -","MOBILE SEMANTIC SEGMENTATION"],"mergedAllColumns":["SSDLite with other light - weight CNN models ( MobileNetv1 / v2 / v3 , MNASNet , and MixNet ) . For","standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"],"numberCells":[{"number":"75.7","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"1.9M","isBolded":false,"associatedRows":["MobileViT - XXS ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"77.1","isBolded":true,"associatedRows":["MobileViT - XS ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"1.8?whenMo-","isBolded":true,"associatedRows":["instance , SSDLite \u0027 s performance improves by 1 . 8% , and its model size reduces by"],"associatedColumns":["Table 1a shows that , for the same input resolu -"],"associatedMergedColumns":["SSDLite with other light - weight CNN models ( MobileNetv1 / v2 / v3 , MNASNet , and MixNet ) . For"]},{"number":"73.6","isBolded":false,"associatedRows":["MobileViT - XXS ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"58.2M","isBolded":false,"associatedRows":["ResNet - 101"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"80.5","isBolded":true,"associatedRows":["ResNet - 101"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"6.4M","isBolded":false,"associatedRows":["MobileViT - S ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"4.5M","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"79.1","isBolded":false,"associatedRows":["MobileViT - S ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"2.9M","isBolded":false,"associatedRows":["MobileViT - XS ( Ours )"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"75.3","isBolded":false,"associatedRows":["MobileNetv1"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","mIOU"],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]},{"number":"11.2M","isBolded":false,"associatedRows":["MobileNetv1"],"associatedColumns":["Table 1a shows that , for the same input resolu -","?F confirms MobileViT \u0027 s ability to detect variety of objects .","MOBILE SEMANTIC SEGMENTATION","# Params ."],"associatedMergedColumns":["standard SSD - 300 with heavy - weight backbones while learning significantly fewer parameters ( Ta -"]}]},{"caption":"Table 4: MobileViT architecture. Here, d represents dimensionality of the input to the transformer \nlayer in MobileViT block (","rows":["1","8 ? 8","2","Conv - 3 ? 3 , ? 2","MV2","MobileViT block ( L \u003d 2 )","MobileViT block ( L \u003d 3 )","Network Parameters","MobileViT block ( L \u003d 4 )","MV2 , ? 2"],"columns":["Output channels","1000","Repeat","Output size","384","1","256 ? 256","320","XXS","2","640","S","128 ? 128","Output stride","XS"],"mergedAllColumns":["4","128","8","160","128 ( d \u003d 192 )","Global pool"],"numberCells":[{"number":"1.3M","isBolded":false,"associatedRows":["Network Parameters","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2","320","1","1000"],"associatedMergedColumns":["Global pool"]},{"number":"64","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["8"]},{"number":"24","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Conv - 3 ? 3 , ? 2","1"],"associatedColumns":["Output channels","Repeat","S","1"],"associatedMergedColumns":[]},{"number":"64","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 2 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","S","1","2"],"associatedMergedColumns":[]},{"number":"64(d\u003d96)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 2 )","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["4"]},{"number":"80","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["8"]},{"number":"96(d\u003d144)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 2 )","1"],"associatedColumns":["Output channels","Repeat","S","1","2"],"associatedMergedColumns":["4"]},{"number":"2.3M","isBolded":false,"associatedRows":["Network Parameters","1"],"associatedColumns":["Output channels","Repeat","XS","1","2","384","1","1000"],"associatedMergedColumns":["Global pool"]},{"number":"16","isBolded":false,"associatedRows":["Conv - 3 ? 3 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XXS","1"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["MV2","1"],"associatedColumns":["Output channels","Repeat","XXS","1"],"associatedMergedColumns":[]},{"number":"96","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","S","1","2"],"associatedMergedColumns":["4"]},{"number":"48","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":[]},{"number":"64(d\u003d80)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 4 )","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["128"]},{"number":"5.6M","isBolded":false,"associatedRows":["Network Parameters","1"],"associatedColumns":["Output channels","Repeat","S","1","2","640","1","1000"],"associatedMergedColumns":["Global pool"]},{"number":"24","isBolded":false,"associatedRows":["MV2","2"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":[]},{"number":"48","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["4"]},{"number":"96(d\u003d144)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 3 )","8 ? 8","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["160"]},{"number":"16","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 4 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":["8"]},{"number":"80(d\u003d120)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 4 )","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["128"]},{"number":"64","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["4"]},{"number":"16","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 4 )"],"associatedColumns":["Output channels","Output stride","XXS","1","2"],"associatedMergedColumns":["8"]},{"number":"32","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 3 )","8 ? 8"],"associatedColumns":["Output channels","Output stride","XXS","1","2"],"associatedMergedColumns":["160"]},{"number":"64?","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 2 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":[]},{"number":"48","isBolded":false,"associatedRows":["MV2","2"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":[]},{"number":"32?","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 2 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":["4"]},{"number":"32","isBolded":false,"associatedRows":["MV2","1"],"associatedColumns":["Output channels","Repeat","XS","1"],"associatedMergedColumns":[]},{"number":"32","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 2 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":["4"]},{"number":"16","isBolded":false,"associatedRows":["Conv - 3 ? 3 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XS","1"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["MV2","2"],"associatedColumns":["Output channels","Repeat","S","1","2"],"associatedMergedColumns":[]},{"number":"48(d\u003d64)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 2 )","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["4"]},{"number":"80(d\u003d96)","isBolded":false,"associatedRows":["MobileViT block ( L \u003d 3 )","8 ? 8","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["160"]},{"number":"32","isBolded":false,"associatedRows":["MV2","1"],"associatedColumns":["Output channels","Repeat","S","1"],"associatedMergedColumns":[]},{"number":"80","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XXS","1","2"],"associatedMergedColumns":["128 ( d \u003d 192 )"]},{"number":"16?","isBolded":true,"associatedRows":["MobileViT block ( L \u003d 4 )"],"associatedColumns":["Output channels","Output size","XXS","256 ? 256","128 ? 128"],"associatedMergedColumns":["8"]},{"number":"96","isBolded":false,"associatedRows":["MV2 , ? 2","1"],"associatedColumns":["Output channels","Repeat","XS","1","2"],"associatedMergedColumns":["128 ( d \u003d 192 )"]}]},{"caption":"Table 5: Multi-scale sampler is generic. All models are trained with basic augmentation on the \nImageNet-1k.  ? Results are with exponential moving average. \n\n","rows":["232 k","accuracy","( +2 . 4% )","MobileNetv2 - 1 . 0 w / standard sampler ( PyTorch )","error","150","250","( +1 . 4% )","Training","( +0 . 2% )","Multi - scale ( Ours )","Validation","116 k","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","-","( +0 . 9% )","0","100","200","300","( % )","375 k","187 k","Top - 1","ResNet - 50 w / standard sampler ( PyTorch )"],"columns":["Top - 1 accuracy","Input resolution","# Params","( 0 . 0% )","( b ) Validation error","160x160","-","100","Multi - scale ( Ours )","XXS","S","( % )","( c ) Validation acc . vs . input resolution","Epochs","256x256","Training time"],"mergedAllColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler .","( 1 . 16? )","( % )","( 1 . 35? )","( 1? )","Standard","Figure 9 : MobileViT - S learns better representations with multi - scale sampler on ImageNet - 1k ."],"numberCells":[{"number":"50","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","( % )"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","300","375 k","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy","( 0 . 0% )","( 0 . 0% )"],"associatedMergedColumns":["( 1? )"]},{"number":"78ksec.","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","300","375 k","Top - 1","( +0 . 2% )"],"associatedColumns":["Multi - scale ( Ours )","256x256","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Training time","-","-"],"associatedMergedColumns":["( 1? )"]},{"number":"74","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","error","0","Multi - scale ( Ours )","-","accuracy"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["Standard"]},{"number":"72","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( PyTorch )","accuracy"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )"],"associatedMergedColumns":["Standard"]},{"number":"68","isBolded":false,"associatedRows":["Training","0","100","150","Multi - scale ( Ours )","200","250","300","Validation","0","Multi - scale ( Ours )","-","Top - 1"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"30","isBolded":false,"associatedRows":["Training"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"35","isBolded":false,"associatedRows":["Training"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"20","isBolded":false,"associatedRows":["Training","0","100","150","200","250","300","Validation"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"76.2","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","-","-","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy"],"associatedMergedColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler ."]},{"number":"70","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( PyTorch )","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )"],"associatedMergedColumns":["Standard"]},{"number":"60","isBolded":false,"associatedRows":["error"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"68","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( PyTorch )","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )"],"associatedMergedColumns":["Standard"]},{"number":"40","isBolded":false,"associatedRows":["error"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"40","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","error"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"25M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params","( 0 . 0% )"],"associatedMergedColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler ."]},{"number":"54ksec.","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","150","187 k","Top - 1","( +0 . 9% )"],"associatedColumns":["Multi - scale ( Ours )","256x256","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Training time","-"],"associatedMergedColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler ."]},{"number":"67ksec.","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","300","232 k","Top - 1","( +1 . 4% )"],"associatedColumns":["Multi - scale ( Ours )","256x256","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Training time","-","-"],"associatedMergedColumns":["( 1 . 16? )"]},{"number":"25","isBolded":false,"associatedRows":["Training","0","100","150","200","250","300","Validation"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"3.5M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params","( 0 . 0% )"],"associatedMergedColumns":["( 1? )"]},{"number":"76","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","( % )","0","Multi - scale ( Ours )","-","( % )"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":[]},{"number":"55","isBolded":false,"associatedRows":["error"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"73.3","isBolded":true,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","300","232 k","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy","( 0 . 0% )","( 0 . 0% )"],"associatedMergedColumns":["( 1 . 16? )"]},{"number":"50","isBolded":false,"associatedRows":["Training","0","100","150","200","250","300","Validation","0"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"50","isBolded":false,"associatedRows":["error"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":[]},{"number":"60","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","( % )"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"78.6","isBolded":true,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","150","116 k","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy","( 0 . 0% )"],"associatedMergedColumns":["( 1 . 35? )"]},{"number":"78","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","( % )","0","Multi - scale ( Ours )","-","( % )"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"74","isBolded":false,"associatedRows":["Training","ResNet - 50 w / standard sampler ( PyTorch )","250","300","Validation","accuracy"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )"],"associatedMergedColumns":["Standard"]},{"number":"50","isBolded":false,"associatedRows":["Training","0"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"45","isBolded":false,"associatedRows":["error"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["Standard"]},{"number":"78","isBolded":false,"associatedRows":["Training","ResNet - 50 w / standard sampler ( PyTorch )","100","150","200","250","300","Validation","accuracy"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error"],"associatedMergedColumns":["Figure 9 : MobileViT - S learns better representations with multi - scale sampler on ImageNet - 1k ."]},{"number":"25","isBolded":false,"associatedRows":["Training"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"72","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","Validation","0","Multi - scale ( Ours )","-","accuracy"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"71.9","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","-","-","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy","( 0 . 0% )"],"associatedMergedColumns":["( 1? )"]},{"number":"25M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params"],"associatedMergedColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler ."]},{"number":"3.5M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params","( 0 . 0% )","( 0 . 0% )"],"associatedMergedColumns":["( 1 . 16? )"]},{"number":"77.1","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","150","187 k","Top - 1"],"associatedColumns":["Multi - scale ( Ours )","160x160","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Top - 1 accuracy","( 0 . 0% )"],"associatedMergedColumns":["Figure 10 : MobileViT \u0027 s performance on ImageNet - 1k with standard and multi - scale sampler ."]},{"number":"45","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","error"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["Standard"]},{"number":"76","isBolded":false,"associatedRows":["Training","ResNet - 50 w / standard sampler ( PyTorch )","150","200","250","300","Validation","accuracy"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error"],"associatedMergedColumns":["Standard"]},{"number":"35","isBolded":false,"associatedRows":["Training","0","100","150","Multi - scale ( Ours )","200","250","300","Validation"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"40ksec.","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?","150","116 k","Top - 1","( +2 . 4% )"],"associatedColumns":["Multi - scale ( Ours )","256x256","Input resolution","( c ) Validation acc . vs . input resolution","Multi - scale ( Ours )","S","Training time","-"],"associatedMergedColumns":["( 1 . 35? )"]},{"number":"55","isBolded":false,"associatedRows":["error","0","100","150","Multi - scale ( Ours )","200","250","300","( % )"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"30","isBolded":false,"associatedRows":["Training","0","100","150","200","250","300","Validation"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"70","isBolded":false,"associatedRows":["Training","0","100","150","Multi - scale ( Ours )","200","250","300","Validation","0","Multi - scale ( Ours )","-","Top - 1"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"3.5M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params","( 0 . 0% )","( 0 . 0% )"],"associatedMergedColumns":["( 1? )"]},{"number":"20","isBolded":false,"associatedRows":["Training"],"associatedColumns":["Multi - scale ( Ours )"],"associatedMergedColumns":["( % )"]},{"number":"25M","isBolded":false,"associatedRows":["Training","MobileNetv2 - 1 . 0 w / standard sampler ( our repro . ) ?"],"associatedColumns":["Multi - scale ( Ours )","100","Epochs","( b ) Validation error","( % )","XXS","# Params","( 0 . 0% )"],"associatedMergedColumns":["( 1 . 35? )"]}]},{"caption":"Table 6: Impact of patch sizes. Here, the patch sizes are for spatial levels at 32 ? 32, 16 ? 16, and \n8 ? 8, respectively. Also, results are shown for MobileViT-S model on the ImageNet-1k dataset. \n","rows":["4 , 4 , 4","8 , 4 , 2","3 , 3 , 3 ?","2 , 2 , 2"],"columns":["# Params .","Time","Top - 1"],"mergedAllColumns":[],"numberCells":[{"number":"78.4","isBolded":false,"associatedRows":["2 , 2 , 2"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["8 , 4 , 2"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["2 , 2 , 2"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"77.3","isBolded":false,"associatedRows":["8 , 4 , 2"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"14.69ms","isBolded":false,"associatedRows":["3 , 3 , 3 ?"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"8.20ms","isBolded":false,"associatedRows":["8 , 4 , 2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"9.85ms","isBolded":false,"associatedRows":["2 , 2 , 2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"8.23ms","isBolded":false,"associatedRows":["4 , 4 , 4"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"78.5","isBolded":true,"associatedRows":["3 , 3 , 3 ?"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["4 , 4 , 4"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"77.6","isBolded":false,"associatedRows":["4 , 4 , 4"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["3 , 3 , 3 ?"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparison between MobileNetv2 and MobileViT in terms of maximum memory (in \nkb) that needs to be materialized at each spatial resolution in the network. The top-1 accuracy \nis measured on the ImageNet-1k validation set. Here, OS (output stride) is the ratio of spatial \ndimensions of the input to the feature map. \n\n","rows":["100","Table","8","Top - 1"],"columns":["MobileNetv2 - 1 . 0","MobileNetv2 is the fastest network across all devices .","2","200","784","OS","4","400","on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","294","MobileViT - XS","On iPhone ( both CPU and neural engine ) ,"],"mergedAllColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"],"numberCells":[{"number":"11comparestheinferencetimeofdifferentmodels","isBolded":false,"associatedRows":["8","Table"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"62","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","MobileNetv2 is the fastest network across all devices .","MobileNetv2 - 1 . 0","400","200"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"74.8","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","On iPhone ( both CPU and neural engine ) ,","MobileViT - XS","784","294"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"32","isBolded":false,"associatedRows":[],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","MobileNetv2 is the fastest network across all devices .","OS","2","4"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"32","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","MobileNetv2 is the fastest network across all devices .","MobileNetv2 - 1 . 0","400","200"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"31","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","On iPhone ( both CPU and neural engine ) ,","MobileViT - XS","784","294"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"37","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","On iPhone ( both CPU and neural engine ) ,","MobileViT - XS","784","294"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"16","isBolded":false,"associatedRows":[],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","MobileNetv2 is the fastest network across all devices .","OS","2","4"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"73.3","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","MobileNetv2 is the fastest network across all devices .","MobileNetv2 - 1 . 0","400","200"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]},{"number":"98","isBolded":false,"associatedRows":["8","100"],"associatedColumns":["on three different devices , i . e . , iPhone12 CPU , iPhone12 neural engine , and NVIDIA V100 GPU .","On iPhone ( both CPU and neural engine ) ,","MobileViT - XS","784","294"],"associatedMergedColumns":["narrow , ( 2 ) run at higher spatial resolution ( 256 ? 256 instead of 224 ? 224 ) , and ( 2 ) did not use"]}]},{"caption":"Table 10: MobileViT vs. MobileNetv2 on different tasks. The FLOPs and inference time in (a), \n(b) and (c) are measured at 224 ? 224, 320 ? 320, and 512 ? 512 respectively with an exception \nto MobileViT-XS model in (a) which uses 256 ? 256 as an input resolution for measuring inference \ntime on iPhone 12 neural engine. Here, the performance of MobileViT-XS models is reported at two \ndifferent patch-size settings. See  ?A for details. \n\n","rows":["MobileNetv2","MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"columns":["Backbone","mIOU","FLOPs","# Params .","Time","( a ) ImageNet - 1k classification","Top - 1","mAP","( b ) Object detection w / SSDLite ."],"mergedAllColumns":[],"numberCells":[{"number":"2.3ms","isBolded":true,"associatedRows":["MobileNetv2","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"10.7ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"7.28ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileNetv2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"73.3","isBolded":false,"associatedRows":["MobileNetv2","MobileViT - XS ( Ours )"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"25.1ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","Time"],"associatedMergedColumns":[]},{"number":"77.1","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["# Params .","( b ) Object detection w / SSDLite .","mIOU"],"associatedMergedColumns":[]},{"number":"5.93ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileNetv2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"24.8","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"2.9M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Top - 1","( a ) ImageNet - 1k classification","# Params ."],"associatedMergedColumns":[]},{"number":"1.6G","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"22.1","isBolded":false,"associatedRows":["MobileNetv2","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"74.8","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"0.7G","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"1.6G","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"73.8","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Top - 1"],"associatedMergedColumns":[]},{"number":"12.6ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"2.3M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"75.4","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["# Params .","( b ) Object detection w / SSDLite .","mIOU"],"associatedMergedColumns":[]},{"number":"3.5M","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"0.7G","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"4.3M","isBolded":false,"associatedRows":["MobileNetv2","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"5.7G","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","FLOPs"],"associatedMergedColumns":[]},{"number":"2.7M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"4.3M","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileNetv2"],"associatedColumns":["Top - 1","( a ) ImageNet - 1k classification","# Params ."],"associatedMergedColumns":[]},{"number":"2.9M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Top - 1","( a ) ImageNet - 1k classification","# Params ."],"associatedMergedColumns":[]},{"number":"32.3ms","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","Time"],"associatedMergedColumns":[]},{"number":"2.3M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]},{"number":"6.5ms","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileNetv2","MobileNetv2"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","Time"],"associatedMergedColumns":[]},{"number":"5.7G","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","FLOPs"],"associatedMergedColumns":[]},{"number":"0.92ms","isBolded":true,"associatedRows":["MobileNetv2","MobileNetv2"],"associatedColumns":["Time"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 8 , 4 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 8 , 4 , 2 )"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"0.8G","isBolded":true,"associatedRows":["MobileNetv2","MobileViT - XS ( Ours )","MobileNetv2"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"5.8G","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileNetv2"],"associatedColumns":["Backbone","( b ) Object detection w / SSDLite .","FLOPs"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileNetv2","MobileNetv2"],"associatedColumns":["# Params .","( b ) Object detection w / SSDLite .","mIOU"],"associatedMergedColumns":[]},{"number":"0.3G","isBolded":true,"associatedRows":["MobileNetv2"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"2.7M","isBolded":true,"associatedRows":["MobileViT - XS ( Ours ; 2 , 2 , 2 )","MobileViT - XS ( Ours )","MobileViT - XS ( Ours ; 2 , 2 , 2 )"],"associatedColumns":["# Params ."],"associatedMergedColumns":[]}]},{"caption":"Table 11: Inference time on different devices. The run time of MobileViT is measured at 256?256 \nwhile for other networks, it is measured at 224 ? 224. For GPU, inference time is measured for a \nbatch of 32 images while for other devices, we use a batch size of one. Here,  ? represents that Mo-\nbileViT model uses PyTorch\u0027s Unfold and Fold operations. Also, patch sizes for MobileViT model \nat an output stride of 8, 16, and 32 are set to two. \n\n","rows":["MobileNetv2","MobileViT ( Ours )","PiT","DeIT"],"columns":["FLOPs","# Params","iPhone12 - CPU","Inference time","NVIDIA V100 GPU","iPhone12 - Neural Engine","Top - 1"],"mergedAllColumns":[],"numberCells":[{"number":"0.43ms","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","Top - 1","NVIDIA V100 GPU"],"associatedMergedColumns":[]},{"number":"0.46ms","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","Top - 1","NVIDIA V100 GPU"],"associatedMergedColumns":[]},{"number":"24.03ms","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"0.92ms","isBolded":true,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","Top - 1","iPhone12 - Neural Engine"],"associatedMergedColumns":[]},{"number":"73.3","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"17.86ms","isBolded":false,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"2.3M","isBolded":true,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","# Params","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"74.8","isBolded":true,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"5.7M","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","# Params","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"7.50ms","isBolded":true,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"1.3G","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","FLOPs","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"0.7G","isBolded":false,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","FLOPs","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"4.9M","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","# Params","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"7.28ms","isBolded":false,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","Top - 1","iPhone12 - Neural Engine"],"associatedMergedColumns":[]},{"number":"0.62ms/0.47ms?","isBolded":false,"associatedRows":["MobileViT ( Ours )"],"associatedColumns":["Inference time","Top - 1","NVIDIA V100 GPU"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"0.7G","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","FLOPs","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"28.15ms","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"10.99ms","isBolded":false,"associatedRows":["DeIT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - Neural Engine"],"associatedMergedColumns":[]},{"number":"3.5M","isBolded":false,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","# Params","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"0.3G","isBolded":true,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","FLOPs","iPhone12 - CPU"],"associatedMergedColumns":[]},{"number":"0.31ms","isBolded":true,"associatedRows":["MobileNetv2"],"associatedColumns":["Inference time","Top - 1","NVIDIA V100 GPU"],"associatedMergedColumns":[]},{"number":"10.56ms","isBolded":false,"associatedRows":["PiT"],"associatedColumns":["Inference time","Top - 1","iPhone12 - Neural Engine"],"associatedMergedColumns":[]}]}]