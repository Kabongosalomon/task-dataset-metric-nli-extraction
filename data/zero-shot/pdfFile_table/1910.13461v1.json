[{"caption":"Model \n\nSQuAD 1.1 MNLI ELI5 XSum ConvAI2 CNN/DM \nF1 \nAcc \nPPL \nPPL \nPPL \nPPL \n\nBERT Base (Devlin et al., 2019) \n88.5 \n84.3 \n-\n-\n-\n-\n\nMasked Language Model \n90.0 \n83.5 \n24.77 \n7.87 \n12.59 \n7.06 \nMasked Seq2seq \n87.0 \n82.1 \n23.40 \n6.80 \n11.43 \n6.19 \nLanguage Model \n76.7 \n80.1 \n21.40 \n7.00 \n11.51 \n6.56 \nPermuted Language Model \n89.1 \n83.7 \n24.03 \n7.69 \n12.23 \n6.96 \nMultitask Masked Language Model \n89.2 \n82.4 \n23.73 \n7.50 \n12.39 \n6.74 \n\nBART Base \nw/ Token Masking \n90.4 \n84.1 \n25.05 \n7.08 \n11.73 \n6.10 \nw/ Token Deletion \n90.4 \n84.1 \n24.61 \n6.90 \n11.46 \n5.87 \nw/ Text Infilling \n90.8 \n84.0 \n24.26 \n6.61 \n11.05 \n5.83 \nw/ Document Rotation \n77.2 \n75.3 \n53.69 17.14 \n19.87 \n10.59 \nw/ Sentence Shuffling \n85.4 \n81.5 \n41.87 10.93 \n16.67 \n7.89 \nw/ Text Infilling + Sentence Shuffling \n90.8 \n83.8 \n24.17 \n6.62 \n11.12 \n5.41 \n\nTable 1: Comparison of pre-training objectives. All models are of comparable size and are trained for 1M steps \non a combination of books and Wikipedia data. Entries in the bottom two blocks are trained on identical data \nusing the same code-base, and fine-tuned with the same procedures. Entries in the second block are inspired by \npre-training objectives proposed in previous work, but have been simplified to focus on evaluation objectives (see \n ?4.1). Performance varies considerably across tasks, but the BART models with text infilling demonstrate the most \nconsistently strong performance. \n\n","rows":["SQuAD","Masked Language Model","BERT Base ( Devlin et al . , 2019 )","w / Token Deletion","Language Model","Permuted Language Model","Multitask Masked Language Model","w / Document Rotation","w / Sentence Shuffling","w / Token Masking","Model","w / Text Infilling + Sentence Shuffling","Masked Seq2seq","w / Text Infilling"],"columns":["Acc","CNN / DM","ELI5","ConvAI2","MNLI","XSum","F1","-","PPL"],"mergedAllColumns":["BART Base"],"numberCells":[{"number":"84.1","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"5.83","isBolded":false,"associatedRows":["w / Text Infilling"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"11.51","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":[]},{"number":"6.90","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"84.0","isBolded":false,"associatedRows":["w / Text Infilling"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"12.23","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":[]},{"number":"11.73","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"11.05","isBolded":true,"associatedRows":["w / Text Infilling"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"80.1","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":[]},{"number":"11.12","isBolded":false,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"90.0","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":[]},{"number":"7.87","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":[]},{"number":"6.19","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":[]},{"number":"7.06","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":[]},{"number":"90.8","isBolded":true,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"6.74","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":[]},{"number":"24.77","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"21.40","isBolded":true,"associatedRows":["Language Model"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":[]},{"number":"6.96","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":[]},{"number":"23.40","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":[]},{"number":"17.14","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"84.3","isBolded":true,"associatedRows":["BERT Base ( Devlin et al . , 2019 )"],"associatedColumns":["MNLI","Acc"],"associatedMergedColumns":[]},{"number":"23.73","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":[]},{"number":"6.61","isBolded":true,"associatedRows":["w / Text Infilling"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"6.56","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":[]},{"number":"16.67","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"76.7","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":[]},{"number":"88.5","isBolded":false,"associatedRows":["BERT Base ( Devlin et al . , 2019 )"],"associatedColumns":["MNLI","F1"],"associatedMergedColumns":[]},{"number":"6.80","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":[]},{"number":"11.43","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":[]},{"number":"90.4","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"82.1","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":[]},{"number":"10.93","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"12.59","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"87.0","isBolded":false,"associatedRows":["Masked Seq2seq"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":[]},{"number":"24.03","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":[]},{"number":"7.00","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":[]},{"number":"6.10","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"7.08","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"53.69","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"89.1","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":[]},{"number":"7.89","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"89.2","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":[]},{"number":"90.4","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"75.3","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"1.1","isBolded":true,"associatedRows":["Model","SQuAD"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"24.61","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"77.2","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"24.17","isBolded":false,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"11.46","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"41.87","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"90.8","isBolded":true,"associatedRows":["w / Text Infilling"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"83.5","isBolded":false,"associatedRows":["Masked Language Model"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":[]},{"number":"82.4","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":[]},{"number":"7.50","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":[]},{"number":"25.05","isBolded":false,"associatedRows":["w / Token Masking"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"85.4","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["MNLI","F1","-"],"associatedMergedColumns":["BART Base"]},{"number":"6.62","isBolded":false,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"5.41","isBolded":true,"associatedRows":["w / Text Infilling + Sentence Shuffling"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"19.87","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"12.39","isBolded":false,"associatedRows":["Multitask Masked Language Model"],"associatedColumns":["ConvAI2","PPL","-"],"associatedMergedColumns":[]},{"number":"81.5","isBolded":false,"associatedRows":["w / Sentence Shuffling"],"associatedColumns":["MNLI","Acc","-"],"associatedMergedColumns":["BART Base"]},{"number":"10.59","isBolded":false,"associatedRows":["w / Document Rotation"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"5.87","isBolded":false,"associatedRows":["w / Token Deletion"],"associatedColumns":["CNN / DM","PPL","-"],"associatedMergedColumns":["BART Base"]},{"number":"7.69","isBolded":false,"associatedRows":["Permuted Language Model"],"associatedColumns":["XSum","PPL","-"],"associatedMergedColumns":[]},{"number":"24.26","isBolded":false,"associatedRows":["w / Text Infilling"],"associatedColumns":["ELI5","PPL","-"],"associatedMergedColumns":["BART Base"]}]},{"caption":"SQuAD 1.1 SQuAD 2.0 \n\nMNLI \nSST QQP QNLI STS-B RTE MRPC CoLA \nEM/F1 \nEM/F1 \nm/mm \nAcc \nAcc \nAcc \nAcc \nAcc \nAcc \nMcc \n\nBERT \n84.1/90.9 \n79.0/81.8 \n86.6/-\n93.2 91.3 \n92.3 \n90.0 \n70.4 \n88.0 \n60.6 \nUniLM \n-/-\n80.5/83.4 \n87.0/85.9 94.5 \n-\n92.7 \n-\n70.9 \n-\n61.1 \nXLNet \n89.0/94.5 \n86.1/88.8 \n89.8/-\n95.6 91.8 \n93.9 \n91.8 \n83.8 \n89.2 \n63.6 \nRoBERTa \n88.9/94.6 \n86.5/89.4 \n90.2/90.2 96.4 92.2 \n94.7 \n92.4 \n86.6 \n90.9 \n68.0 \nBART \n88.8/94.6 \n86.1/89.2 \n89.9/90.1 96.6 92.5 \n94.9 \n91.2 \n87.0 \n90.4 \n62.8 \n\nTable 2: Results for large models on SQuAD and GLUE tasks. BART performs comparably to RoBERTa and \nXLNet, suggesting that BART\u0027s uni-directional decoder layers do not reduce performance on discriminative tasks. \n\n","rows":["- / -","SQuAD","86 . 1 / 88 . 8","89 . 8 / -","RoBERTa","80 . 5 / 83 . 4","89 . 0 / 94 . 5","84 . 1 / 90 . 9","Lead - 3","86 . 6 / -","88 . 8 / 94 . 6","BERT","87 . 0 / 85 . 9","86 . 5 / 89 . 4","90 . 2 / 90 . 2","BART","PTGEN+COV ( See et al . , 2017 )","-","UniLM","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","XLNet","86 . 1 / 89 . 2","88 . 9 / 94 . 6","PTGEN ( See et al . , 2017 )","79 . 0 / 81 . 8","89 . 9 / 90 . 1"],"columns":["Acc","R2","CoLA","RTE","Mcc","BART performs comparably to RoBERTa and","-","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","QQP","SST","RL","XSum","QNLI","STS - B","MRPC","R1"],"mergedAllColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."],"numberCells":[{"number":"19.60","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"22.27","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"9.21","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"31.27","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"37.25","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"83.8","isBolded":false,"associatedRows":["XLNet","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["RTE","Acc"],"associatedMergedColumns":[]},{"number":"15.66","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"36.38","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"20.21","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"39.53","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"39.18","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"40.90","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"44.16","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"29.70","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"21.72","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"17.28","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"92.3","isBolded":false,"associatedRows":["BERT","PTGEN+COV ( See et al . , 2017 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["QNLI","Acc"],"associatedMergedColumns":[]},{"number":"38.76","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"38.76","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"70.9","isBolded":false,"associatedRows":["UniLM","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","- / -","80 . 5 / 83 . 4","87 . 0 / 85 . 9","-","-"],"associatedColumns":["RTE","Acc"],"associatedMergedColumns":[]},{"number":"40.51","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"38.81","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"90.4","isBolded":false,"associatedRows":["BART","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["MRPC","Acc"],"associatedMergedColumns":[]},{"number":"94.5","isBolded":false,"associatedRows":["UniLM","PTGEN+COV ( See et al . , 2017 )","- / -","80 . 5 / 83 . 4","87 . 0 / 85 . 9"],"associatedColumns":["SST","Acc"],"associatedMergedColumns":[]},{"number":"11.95","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"23.24","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"92.2","isBolded":false,"associatedRows":["RoBERTa","PTGEN+COV ( See et al . , 2017 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["QQP","Acc"],"associatedMergedColumns":[]},{"number":"43.33","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"21.28","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"33.42","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"1.60","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"1.1","isBolded":true,"associatedRows":["BERT","Lead - 3","SQuAD"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"90.0","isBolded":false,"associatedRows":["BERT","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["STS - B","Acc"],"associatedMergedColumns":[]},{"number":"70.4","isBolded":false,"associatedRows":["BERT","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["RTE","Acc"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":false,"associatedRows":["UniLM","PTGEN+COV ( See et al . , 2017 )","- / -","80 . 5 / 83 . 4","87 . 0 / 85 . 9","-"],"associatedColumns":["QNLI","Acc"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["CoLA","Mcc"],"associatedMergedColumns":[]},{"number":"87.0","isBolded":true,"associatedRows":["BART","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["RTE","Acc"],"associatedMergedColumns":[]},{"number":"31.15","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["MRPC","Acc","BART performs comparably to RoBERTa and","XSum","RL","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"92.4","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["STS - B","Acc"],"associatedMergedColumns":[]},{"number":"88.0","isBolded":false,"associatedRows":["BERT","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["MRPC","Acc"],"associatedMergedColumns":[]},{"number":"61.1","isBolded":false,"associatedRows":["UniLM","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","- / -","80 . 5 / 83 . 4","87 . 0 / 85 . 9","-","-","-"],"associatedColumns":["CoLA","Mcc"],"associatedMergedColumns":[]},{"number":"91.2","isBolded":false,"associatedRows":["BART","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["STS - B","Acc"],"associatedMergedColumns":[]},{"number":"16.33","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"93.2","isBolded":false,"associatedRows":["BERT","PTGEN+COV ( See et al . , 2017 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["SST","Acc"],"associatedMergedColumns":[]},{"number":"36.67","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QNLI","Acc","BART performs comparably to RoBERTa and","CNN / DailyMail","RL"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"16.30","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"19.39","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"91.8","isBolded":false,"associatedRows":["XLNet","PTGEN+COV ( See et al . , 2017 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["QQP","Acc"],"associatedMergedColumns":[]},{"number":"94.7","isBolded":false,"associatedRows":["RoBERTa","PTGEN+COV ( See et al . , 2017 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["QNLI","Acc"],"associatedMergedColumns":[]},{"number":"41.72","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"86.6","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["RTE","Acc"],"associatedMergedColumns":[]},{"number":"36.44","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"42.13","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"62.8","isBolded":false,"associatedRows":["BART","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["CoLA","Mcc"],"associatedMergedColumns":[]},{"number":"95.6","isBolded":false,"associatedRows":["XLNet","PTGEN+COV ( See et al . , 2017 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["SST","Acc"],"associatedMergedColumns":[]},{"number":"89.2","isBolded":false,"associatedRows":["XLNet","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["MRPC","Acc"],"associatedMergedColumns":[]},{"number":"16.50","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"93.9","isBolded":false,"associatedRows":["XLNet","PTGEN+COV ( See et al . , 2017 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["QNLI","Acc"],"associatedMergedColumns":[]},{"number":"91.8","isBolded":false,"associatedRows":["XLNet","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["STS - B","Acc"],"associatedMergedColumns":[]},{"number":"94.9","isBolded":true,"associatedRows":["BART","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["QNLI","Acc"],"associatedMergedColumns":[]},{"number":"40.42","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["SST","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"96.4","isBolded":false,"associatedRows":["RoBERTa","PTGEN+COV ( See et al . , 2017 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["SST","Acc"],"associatedMergedColumns":[]},{"number":"60.6","isBolded":false,"associatedRows":["BERT","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["CoLA","Mcc"],"associatedMergedColumns":[]},{"number":"17.62","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["QQP","Acc","Table 2 : Results for large models on SQuAD and GLUE tasks .","CNN / DailyMail","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"28.10","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"90.9","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","88 . 9 / 94 . 6","86 . 5 / 89 . 4","90 . 2 / 90 . 2"],"associatedColumns":["MRPC","Acc"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":false,"associatedRows":["BERT","PTGEN+COV ( See et al . , 2017 )","84 . 1 / 90 . 9","79 . 0 / 81 . 8","86 . 6 / -"],"associatedColumns":["QQP","Acc"],"associatedMergedColumns":[]},{"number":"96.6","isBolded":true,"associatedRows":["BART","PTGEN+COV ( See et al . , 2017 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["SST","Acc"],"associatedMergedColumns":[]},{"number":"45.14","isBolded":true,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["STS - B","Acc","BART performs comparably to RoBERTa and","XSum","R1","-"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]},{"number":"2.0","isBolded":true,"associatedRows":["RoBERTa","PTGEN ( See et al . , 2017 )","SQuAD","SQuAD"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"63.6","isBolded":false,"associatedRows":["XLNet","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","89 . 0 / 94 . 5","86 . 1 / 88 . 8","89 . 8 / -"],"associatedColumns":["CoLA","Mcc"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":true,"associatedRows":["BART","PTGEN+COV ( See et al . , 2017 )","88 . 8 / 94 . 6","86 . 1 / 89 . 2","89 . 9 / 90 . 1"],"associatedColumns":["QQP","Acc"],"associatedMergedColumns":[]},{"number":"8.02","isBolded":false,"associatedRows":["RoBERTa","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["RTE","Acc","BART performs comparably to RoBERTa and","XSum","R2"],"associatedMergedColumns":["XLNet , suggesting that BART \u0027 s uni - directional decoder layers do not reduce performance on discriminative tasks ."]}]},{"caption":"Table 3: Results on two standard summarization datasets. BART outperforms previous work on summarization on \ntwo tasks and all metrics, with gains of roughly 6 points on the more abstractive dataset. \n\n","rows":["UniLM","BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )","PTGEN+COV ( See et al . , 2017 )","Lead - 3","PTGEN ( See et al . , 2017 )","BERTSUMABS ( Liu \u0026 Lapata , 2019 )","BART"],"columns":["CNN / DailyMail","R2","RL","XSum","-","R1"],"mergedAllColumns":[],"numberCells":[{"number":"38.76","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","RL","-"],"associatedMergedColumns":[]},{"number":"21.28","isBolded":true,"associatedRows":["BART"],"associatedColumns":["CNN / DailyMail","R2","-"],"associatedMergedColumns":[]},{"number":"16.33","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","R2","-"],"associatedMergedColumns":[]},{"number":"17.62","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["CNN / DailyMail","R2"],"associatedMergedColumns":[]},{"number":"31.27","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","RL","-"],"associatedMergedColumns":[]},{"number":"16.50","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","R2","-"],"associatedMergedColumns":[]},{"number":"40.51","isBolded":false,"associatedRows":["UniLM"],"associatedColumns":["CNN / DailyMail","RL"],"associatedMergedColumns":[]},{"number":"39.53","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","R1"],"associatedMergedColumns":[]},{"number":"45.14","isBolded":true,"associatedRows":["BART"],"associatedColumns":["XSum","R1","-"],"associatedMergedColumns":[]},{"number":"20.21","isBolded":false,"associatedRows":["UniLM"],"associatedColumns":["CNN / DailyMail","R2"],"associatedMergedColumns":[]},{"number":"22.27","isBolded":true,"associatedRows":["BART"],"associatedColumns":["XSum","R2","-"],"associatedMergedColumns":[]},{"number":"38.76","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","R1","-"],"associatedMergedColumns":[]},{"number":"19.60","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","R2","-"],"associatedMergedColumns":[]},{"number":"33.42","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","RL"],"associatedMergedColumns":[]},{"number":"23.24","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["XSum","RL"],"associatedMergedColumns":[]},{"number":"9.21","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["XSum","R2"],"associatedMergedColumns":[]},{"number":"42.13","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","R1","-"],"associatedMergedColumns":[]},{"number":"40.42","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["CNN / DailyMail","R1"],"associatedMergedColumns":[]},{"number":"40.90","isBolded":true,"associatedRows":["BART"],"associatedColumns":["CNN / DailyMail","RL","-"],"associatedMergedColumns":[]},{"number":"8.02","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["XSum","R2"],"associatedMergedColumns":[]},{"number":"41.72","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","R1","-"],"associatedMergedColumns":[]},{"number":"39.18","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","RL","-"],"associatedMergedColumns":[]},{"number":"36.44","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","R1"],"associatedMergedColumns":[]},{"number":"19.39","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["CNN / DailyMail","R2","-"],"associatedMergedColumns":[]},{"number":"31.15","isBolded":false,"associatedRows":["BERTSUMABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","RL","-"],"associatedMergedColumns":[]},{"number":"1.60","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["XSum","R2"],"associatedMergedColumns":[]},{"number":"28.10","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["XSum","R1"],"associatedMergedColumns":[]},{"number":"29.70","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["XSum","R1"],"associatedMergedColumns":[]},{"number":"43.33","isBolded":false,"associatedRows":["UniLM"],"associatedColumns":["CNN / DailyMail","R1"],"associatedMergedColumns":[]},{"number":"11.95","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["XSum","RL"],"associatedMergedColumns":[]},{"number":"21.72","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["XSum","RL"],"associatedMergedColumns":[]},{"number":"17.28","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","R2"],"associatedMergedColumns":[]},{"number":"36.38","isBolded":false,"associatedRows":["PTGEN+COV ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","RL"],"associatedMergedColumns":[]},{"number":"37.25","isBolded":true,"associatedRows":["BART"],"associatedColumns":["XSum","RL","-"],"associatedMergedColumns":[]},{"number":"16.30","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["XSum","R1"],"associatedMergedColumns":[]},{"number":"15.66","isBolded":false,"associatedRows":["PTGEN ( See et al . , 2017 )"],"associatedColumns":["CNN / DailyMail","R2"],"associatedMergedColumns":[]},{"number":"44.16","isBolded":true,"associatedRows":["BART"],"associatedColumns":["CNN / DailyMail","R1","-"],"associatedMergedColumns":[]},{"number":"36.67","isBolded":false,"associatedRows":["Lead - 3"],"associatedColumns":["CNN / DailyMail","RL"],"associatedMergedColumns":[]},{"number":"38.81","isBolded":false,"associatedRows":["BERTSUMEXTABS ( Liu \u0026 Lapata , 2019 )"],"associatedColumns":["XSum","R1","-"],"associatedMergedColumns":[]}]},{"caption":"Table 4: BART outperforms previous work on conver-\nsational response generation. Perplexities are renor-\nmalized based on official tokenizer for ConvAI2. \n\n","rows":["Seq2Seq + Attention","Best System","BART"],"columns":["Valid PPL"],"mergedAllColumns":[],"numberCells":[{"number":"16.02","isBolded":false,"associatedRows":["Seq2Seq + Attention"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]},{"number":"11.85","isBolded":true,"associatedRows":["BART"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]},{"number":"17.51","isBolded":false,"associatedRows":["Best System"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]},{"number":"20.72","isBolded":true,"associatedRows":["BART"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]},{"number":"35.07","isBolded":false,"associatedRows":["Seq2Seq + Attention"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]},{"number":"19.09","isBolded":false,"associatedRows":["Best System"],"associatedColumns":["Valid PPL"],"associatedMergedColumns":[]}]},{"caption":"Table 5: BART achieves state-of-the-art results on \nthe challenging ELI5 abstractive question answering \ndataset. Comparison models are from Fan et al. (2019). \n\n","rows":["Best Extractive","Seq2Seq","Seq2Seq Multitask","Language Model","BART"],"columns":["R2","ELI5","RL","R1"],"mergedAllColumns":[],"numberCells":[{"number":"3.1","isBolded":false,"associatedRows":["Best Extractive"],"associatedColumns":["ELI5","R2"],"associatedMergedColumns":[]},{"number":"17.5","isBolded":false,"associatedRows":["Best Extractive"],"associatedColumns":["ELI5","RL"],"associatedMergedColumns":[]},{"number":"27.8","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["ELI5","R1"],"associatedMergedColumns":[]},{"number":"22.8","isBolded":false,"associatedRows":["Seq2Seq"],"associatedColumns":["ELI5","RL"],"associatedMergedColumns":[]},{"number":"4.7","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["ELI5","R2"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":false,"associatedRows":["Seq2Seq Multitask"],"associatedColumns":["ELI5","RL"],"associatedMergedColumns":[]},{"number":"30.6","isBolded":true,"associatedRows":["BART"],"associatedColumns":["ELI5","R1"],"associatedMergedColumns":[]},{"number":"5.4","isBolded":false,"associatedRows":["Seq2Seq Multitask"],"associatedColumns":["ELI5","R2"],"associatedMergedColumns":[]},{"number":"5.1","isBolded":false,"associatedRows":["Seq2Seq"],"associatedColumns":["ELI5","R2"],"associatedMergedColumns":[]},{"number":"28.9","isBolded":false,"associatedRows":["Seq2Seq Multitask"],"associatedColumns":["ELI5","R1"],"associatedMergedColumns":[]},{"number":"23.5","isBolded":false,"associatedRows":["Best Extractive"],"associatedColumns":["ELI5","R1"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":false,"associatedRows":["Language Model"],"associatedColumns":["ELI5","RL"],"associatedMergedColumns":[]},{"number":"24.3","isBolded":true,"associatedRows":["BART"],"associatedColumns":["ELI5","RL"],"associatedMergedColumns":[]},{"number":"28.3","isBolded":false,"associatedRows":["Seq2Seq"],"associatedColumns":["ELI5","R1"],"associatedMergedColumns":[]},{"number":"6.2","isBolded":true,"associatedRows":["BART"],"associatedColumns":["ELI5","R2"],"associatedMergedColumns":[]}]},{"caption":"Table 6: The performance (BLEU) of baseline and \nBART on WMT\u002716 RO-EN augmented with back-\ntranslation data. BART improves over a strong back-\ntranslation (BT) baseline by using monolingual English \npre-training. \n\n","rows":["Fixed BART","Tuned BART","Baseline"],"columns":["RO - EN"],"mergedAllColumns":[],"numberCells":[{"number":"36.80","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["RO - EN"],"associatedMergedColumns":[]},{"number":"37.96","isBolded":true,"associatedRows":["Tuned BART"],"associatedColumns":["RO - EN"],"associatedMergedColumns":[]},{"number":"36.29","isBolded":false,"associatedRows":["Fixed BART"],"associatedColumns":["RO - EN"],"associatedMergedColumns":[]}]}]