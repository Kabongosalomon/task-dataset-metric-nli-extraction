[{"caption":"Discrete Emotion Recognition \n\nMethod (Accuracy) \nPretrain Dataset Eval Dataset AVENet [23] Cooperative [4] MFCC \nCPC [11] APC [12] PASE [16] Ours \nCREMA-D \nCREMA-D \n37.72 \n28.08 \n41.50 \n43.61 \n46.80 \n47.80 \n55.01 \nTCD TIMIT \nCREMA-D \n28.69 \n28.81 \n41.50 \n30.60 \n39.20 \n39.32 \n49.39 \nLRW \nCREMA-D \n29.39 \n28.53 \n41.50 \n34.31 \n41.30 \n43.16 \n47.68 \nCREMA-D \nRavdess \n26.97 \n17.53 \n28.32 \n26.17 \n28.16 \n23.35 \n41.34 \nTCD TIMIT \nRavdess \n20.03 \n20.72 \n28.32 \n26.01 \n32.21 \n31.76 \n44.04 \nLRW \nRavdess \n19.07 \n21.38 \n28.32 \n29.05 \n34.63 \n30.05 \n41.92 \n\nTable 1. Discrete emotion recognition results (accuracy) presented on the CREMA-D (6 balanced classes, chance \u003d 16.66) and \nRavdess (8 balanced classes, chance \u003d 12.5) datasets. All methods are pretrained on the mentioned datasets and used as feature \nextractors on the evaluation datasets. MFCC\u0027s are used only in a supervised way on the evaluation datasets. \n\n","rows":["TCD TIMIT","LRW","Ravdess ( 8 balanced classes , chance \u003d","CREMA - D","Table 1 . Discrete emotion recognition results ( accuracy ) presented on the CREMA - D ( 6 balanced classes , chance \u003d","Ravdess"],"columns":["Ours","Method ( Accuracy )","CPC [ 11 ]","Discrete Emotion Recognition","Cooperative [ 4 ]","MFCC","PASE [ 16 ]","APC [ 12 ]","AVENet [ 23 ]"],"mergedAllColumns":[],"numberCells":[{"number":"17.53","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]},{"number":"41.50","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"28.32","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"20.72","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]},{"number":"26.97","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"29.39","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"47.80","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"44.04","isBolded":true,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"28.53","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]},{"number":"39.20","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"34.31","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"26.01","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"46.80","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"23.35","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"20.03","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"19.07","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"37.72","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"31.76","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"41.30","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"34.63","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"30.05","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"32.21","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"12.5)datasets.Allmethodsarepretrainedonthementioneddatasetsandusedasfeature","isBolded":false,"associatedRows":["Ravdess ( 8 balanced classes , chance \u003d"],"associatedColumns":["Method ( Accuracy )","Ours","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"16.66)and","isBolded":false,"associatedRows":["Table 1 . Discrete emotion recognition results ( accuracy ) presented on the CREMA - D ( 6 balanced classes , chance \u003d"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"26.17","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"55.01","isBolded":true,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"41.50","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"43.61","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"30.60","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"39.32","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"28.81","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]},{"number":"49.39","isBolded":true,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"28.32","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"41.50","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"28.69","isBolded":false,"associatedRows":["TCD TIMIT","CREMA - D"],"associatedColumns":["Discrete Emotion Recognition","AVENet [ 23 ]"],"associatedMergedColumns":[]},{"number":"41.92","isBolded":true,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"21.38","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]},{"number":"43.16","isBolded":false,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"28.32","isBolded":false,"associatedRows":["TCD TIMIT","Ravdess"],"associatedColumns":["Method ( Accuracy )","MFCC"],"associatedMergedColumns":[]},{"number":"47.68","isBolded":true,"associatedRows":["LRW","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"28.16","isBolded":false,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","APC [ 12 ]"],"associatedMergedColumns":[]},{"number":"29.05","isBolded":false,"associatedRows":["LRW","Ravdess"],"associatedColumns":["Method ( Accuracy )","CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"41.34","isBolded":true,"associatedRows":["CREMA - D","Ravdess"],"associatedColumns":["Method ( Accuracy )","Ours"],"associatedMergedColumns":[]},{"number":"28.08","isBolded":false,"associatedRows":["CREMA - D","CREMA - D"],"associatedColumns":["Method ( Accuracy )","Cooperative [ 4 ]"],"associatedMergedColumns":[]}]},{"caption":"Table 2. The samples and hours (number, time) of audio-\nvisual speech data in the training, validation and test sets of \neach dataset. \n\n","rows":["31639 /","1509 /","819 /","CREMA - D","GRID","SPC","820 /","11594 /","519 /","686 /","TCD TIMIT","LRW","415 /","977 /","8218 /","51094 /","112658 /","Ravdess"],"columns":["Val","Test","Train"],"mergedAllColumns":[],"numberCells":[{"number":"0.80","isBolded":false,"associatedRows":["TCD TIMIT","8218 /","686 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"36.35870/","isBolded":false,"associatedRows":["LRW","112658 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"1.905980/","isBolded":false,"associatedRows":["LRW","112658 /","686 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"0.48","isBolded":false,"associatedRows":["Ravdess","1509 /","415 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"8.31","isBolded":false,"associatedRows":["GRID","31639 /","686 /","977 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"9.70","isBolded":false,"associatedRows":["CREMA - D","11594 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"26.46999/","isBolded":false,"associatedRows":["GRID","31639 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"1.20","isBolded":false,"associatedRows":["TCD TIMIT","8218 /","686 /","977 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"1.886835/","isBolded":false,"associatedRows":["SPC","51094 /","415 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"5.809976/","isBolded":false,"associatedRows":["GRID","31639 /","686 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"0.70","isBolded":false,"associatedRows":["CREMA - D","11594 /","819 /"],"associatedColumns":["Val"],"associatedMergedColumns":[]},{"number":"1.89","isBolded":false,"associatedRows":["SPC","51094 /","415 /","519 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"0.68","isBolded":false,"associatedRows":["CREMA - D","11594 /","819 /","820 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"0.60","isBolded":false,"associatedRows":["Ravdess","1509 /","415 /","519 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"1.76","isBolded":false,"associatedRows":["Ravdess","1509 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"14.26798/","isBolded":false,"associatedRows":["SPC","51094 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"9.10","isBolded":false,"associatedRows":["TCD TIMIT","8218 /"],"associatedColumns":["Train"],"associatedMergedColumns":[]},{"number":"1.90","isBolded":false,"associatedRows":["LRW","112658 /","686 /","977 /"],"associatedColumns":["Test"],"associatedMergedColumns":[]}]},{"caption":"Table 3. Automatic speech recognition results presented on the GRID and SPC datasets. Compared self-supervised methods \nare all raw audio encoders. After pretraining as mentioned, features are input to ESPNet for ASR with a hybrid attention/CTC \narchitecture. \n\n","rows":["LRW","Accuracy ( ? )","GRID","SPC","Word Error Rate ( ? )"],"columns":["Ours","CPC [ 11 ]","MFCC ( Supervised )","PASE [ 16 ]"],"mergedAllColumns":[],"numberCells":[{"number":"83.3","isBolded":false,"associatedRows":["LRW","SPC","Accuracy ( ? )"],"associatedColumns":["Ours"],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["LRW","SPC","Accuracy ( ? )"],"associatedColumns":["CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"10.2","isBolded":false,"associatedRows":["LRW","GRID","Word Error Rate ( ? )"],"associatedColumns":["CPC [ 11 ]"],"associatedMergedColumns":[]},{"number":"91.1","isBolded":true,"associatedRows":["LRW","SPC","Accuracy ( ? )"],"associatedColumns":["MFCC ( Supervised )"],"associatedMergedColumns":[]},{"number":"4.7","isBolded":true,"associatedRows":["LRW","GRID","Word Error Rate ( ? )"],"associatedColumns":["MFCC ( Supervised )"],"associatedMergedColumns":[]},{"number":"11.6","isBolded":false,"associatedRows":["LRW","GRID","Word Error Rate ( ? )"],"associatedColumns":["Ours"],"associatedMergedColumns":[]},{"number":"5.8","isBolded":false,"associatedRows":["LRW","GRID","Word Error Rate ( ? )"],"associatedColumns":["PASE [ 16 ]"],"associatedMergedColumns":[]},{"number":"89.1","isBolded":false,"associatedRows":["LRW","SPC","Accuracy ( ? )"],"associatedColumns":["PASE [ 16 ]"],"associatedMergedColumns":[]}]}]