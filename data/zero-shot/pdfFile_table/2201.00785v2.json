[{"caption":"Table 1: Linear evaluation for \nshape classification on Mod-\nelNet40. Note that to make a \nfair comparison, different  *  meth-\nods use the same DGCNN en-\ncoder backbone. \n\n","rows":["STRL * [ 23 ]","Orientation * [ 39 ]","IAE ( ours )","FoldingNet * [ 58 ]","OcCo * [ 51 ]","Latent - GAN [ 1 ]","SO - Net [ 24 ]","Jigsaw * [ 45 ]","3D - GAN [ 53 ]","MAP - VAE [ 19 ]"],"columns":["ModelNet40"],"mergedAllColumns":[],"numberCells":[{"number":"83.3%","isBolded":false,"associatedRows":["3D - GAN [ 53 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"90.9%","isBolded":false,"associatedRows":["STRL * [ 23 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"89.7%","isBolded":false,"associatedRows":["OcCo * [ 51 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"92.1%","isBolded":true,"associatedRows":["IAE ( ours )"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"84.1%","isBolded":false,"associatedRows":["Jigsaw * [ 45 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"90.1%","isBolded":false,"associatedRows":["FoldingNet * [ 58 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"88.4%","isBolded":false,"associatedRows":["MAP - VAE [ 19 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"85.7%","isBolded":false,"associatedRows":["Latent - GAN [ 1 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"90.7%","isBolded":false,"associatedRows":["Orientation * [ 39 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]},{"number":"87.3%","isBolded":false,"associatedRows":["SO - Net [ 24 ]"],"associatedColumns":["ModelNet40"],"associatedMergedColumns":[]}]},{"caption":"Table 3: 3D object detection results. We fine-tuned our pre-trained model on \nScanNetV2 and SUN-RGBD validation set using a popular detection framework, \nVoteNet ","rows":["RandomRooms [ 43 ]","VoteNet [ 40 ]","IAE ( Ours )","STRL [ 23 ]","DepthContrast 2 [ 63 ]","PointContrast [ 57 ]"],"columns":["AP50","SUN RGB - D","AP25","ScanNet"],"mergedAllColumns":[],"numberCells":[{"number":"32.9","isBolded":false,"associatedRows":["VoteNet [ 40 ]"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"61.3","isBolded":false,"associatedRows":["RandomRooms [ 43 ]"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["VoteNet [ 40 ]"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"62.1","isBolded":true,"associatedRows":["DepthContrast 2 [ 63 ]"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["DepthContrast 2 [ 63 ]"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"35.4","isBolded":false,"associatedRows":["DepthContrast 2 [ 63 ]"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"58.2","isBolded":false,"associatedRows":["STRL [ 23 ]"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"35.4","isBolded":false,"associatedRows":["RandomRooms [ 43 ]"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"61.5","isBolded":false,"associatedRows":["IAE ( Ours )"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["PointContrast [ 57 ]"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"33.5","isBolded":false,"associatedRows":["VoteNet [ 40 ]"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]},{"number":"59.5","isBolded":false,"associatedRows":["STRL [ 23 ]"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"35.0","isBolded":false,"associatedRows":["STRL [ 23 ]"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"39.1","isBolded":false,"associatedRows":["DepthContrast 2 [ 63 ]"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["RandomRooms [ 43 ]"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"57.5","isBolded":false,"associatedRows":["PointContrast [ 57 ]"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"36.2","isBolded":false,"associatedRows":["RandomRooms [ 43 ]"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["IAE ( Ours )"],"associatedColumns":["SUN RGB - D","AP25"],"associatedMergedColumns":[]},{"number":"58.6","isBolded":false,"associatedRows":["VoteNet [ 40 ]"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["PointContrast [ 57 ]"],"associatedColumns":["ScanNet","AP25"],"associatedMergedColumns":[]},{"number":"39.8","isBolded":true,"associatedRows":["IAE ( Ours )"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]},{"number":"38.4","isBolded":false,"associatedRows":["STRL [ 23 ]"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]},{"number":"36.0","isBolded":true,"associatedRows":["IAE ( Ours )"],"associatedColumns":["SUN RGB - D","AP50"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["PointContrast [ 57 ]"],"associatedColumns":["ScanNet","AP50"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Semantic segmenta-\ntion results on S3DIS. We \nshow overall accuracy (OA) and in-\ntersection of union (mIoU) across \nsix folds. \n\n","rows":["IAE ( ours )","Jigsaw [ 45 ]","DGCNN [ 52 ]","OcCo [ 51 ]"],"columns":["mIoU","OA"],"mergedAllColumns":[],"numberCells":[{"number":"56.6","isBolded":false,"associatedRows":["Jigsaw [ 45 ]"],"associatedColumns":["mIoU"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["OcCo [ 51 ]"],"associatedColumns":["OA"],"associatedMergedColumns":[]},{"number":"60.7","isBolded":true,"associatedRows":["IAE ( ours )"],"associatedColumns":["mIoU"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["DGCNN [ 52 ]"],"associatedColumns":["OA"],"associatedMergedColumns":[]},{"number":"56.1","isBolded":false,"associatedRows":["DGCNN [ 52 ]"],"associatedColumns":["mIoU"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["Jigsaw [ 45 ]"],"associatedColumns":["OA"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":true,"associatedRows":["IAE ( ours )"],"associatedColumns":["OA"],"associatedMergedColumns":[]},{"number":"58.5","isBolded":false,"associatedRows":["OcCo [ 51 ]"],"associatedColumns":["mIoU"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Cross-domain generalizability \nbetween ShapeNet and ScanNet. For 3D \nobject detection task, we report mAP at \nIoU\u003d0.25 on SUN RGB-D dataset. For \nModelNet40 Linear evaluation task, we \nreport classification accuracy. \n\n","rows":["ShapeNet","Object detection","ScanNet"],"columns":["Acc / AP25"],"mergedAllColumns":[],"numberCells":[{"number":"91.1%","isBolded":false,"associatedRows":["Object detection","ScanNet"],"associatedColumns":["Acc / AP25"],"associatedMergedColumns":[]},{"number":"92.1%","isBolded":true,"associatedRows":["Object detection","ShapeNet"],"associatedColumns":["Acc / AP25"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["Object detection","ScanNet"],"associatedColumns":["Acc / AP25"],"associatedMergedColumns":[]},{"number":"59.4","isBolded":false,"associatedRows":["Object detection","ShapeNet"],"associatedColumns":["Acc / AP25"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Left: Ablation study on different decoder model. On ModelNet40, \nwe show linear evaluation results. Our implicit autoencoder formulations \ncan be improved upon explicit counterpart under various decoder models. \nRight: Ablation study on implicit function. For explicit representation, \nwe use FoldingNet as the decoder. For implicit representation, we experimented \nwith Occupancy Value (Occ Value), Unsigned Distance Function (UDF), and \nSigned Distance Function (SDF) and find consistent improvement over explicit \nrepresentation. \n","rows":["object detection , the model pre - trained on ShapeNet can achieve","Occ Value","SDF","Point Cloud","UDF","FoldingNet [ 58 ]","Explicit","SnowflakeNet [ 56 ]","OccNet [ 29 ]","Conv - OccNet [ 38 ]","OcCo [ 51 ]"],"columns":["Functions ModelNet40","Table 5 summarizes the results . For 3D","ModelNet40","Decoder"],"mergedAllColumns":["generalizability of our model ."],"numberCells":[{"number":"90.1%","isBolded":false,"associatedRows":["Explicit","OcCo [ 51 ]","Explicit","Point Cloud"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Functions ModelNet40"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"92.1%","isBolded":true,"associatedRows":["Conv - OccNet [ 38 ]"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Decoder"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"91.3%","isBolded":false,"associatedRows":["Occ Value"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Functions ModelNet40"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"89.9%","isBolded":false,"associatedRows":["SnowflakeNet [ 56 ]"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Decoder"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"92.1%","isBolded":true,"associatedRows":["Conv - OccNet [ 38 ]","SDF"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Functions ModelNet40"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"59.4mAP,","isBolded":true,"associatedRows":["object detection , the model pre - trained on ShapeNet can achieve"],"associatedColumns":["Table 5 summarizes the results . For 3D"],"associatedMergedColumns":[]},{"number":"89.7%","isBolded":false,"associatedRows":["Explicit","OcCo [ 51 ]"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Decoder"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"91.5%","isBolded":false,"associatedRows":["OccNet [ 29 ]"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Decoder"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"91.7%","isBolded":false,"associatedRows":["OccNet [ 29 ]","UDF"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40","Functions ModelNet40"],"associatedMergedColumns":["generalizability of our model ."]},{"number":"90.1%","isBolded":false,"associatedRows":["FoldingNet [ 58 ]"],"associatedColumns":["Table 5 summarizes the results . For 3D","ModelNet40"],"associatedMergedColumns":["generalizability of our model ."]}]},{"caption":"Table 6. Surprisingly, we found the implicit \ndecoders achieve consistently better performance than all explicit decoders. \nDifferent Implicit Functions. We also investigate several different implicit \nrepresentations, including signed distance function, unsigned distance function, \nand occupancy. Encouragingly, as shown in ","rows":["SUN RGB - D"],"columns":["cs\u003d0 . 7","scratch","cs\u003d0 . 5","cs\u003d0","cs\u003d0 . 2"],"mergedAllColumns":[],"numberCells":[{"number":"57.7","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["scratch"],"associatedMergedColumns":[]},{"number":"60.2","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 2"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 5"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0"],"associatedMergedColumns":[]},{"number":"59.8","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 7"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Different setting of data augmentation. \u0027cs\u0027 denotes cropping size. \n\u0027scratch\u0027 means training from scratch. \n\n","rows":["SUN RGB - D"],"columns":["cs\u003d0 . 7","scratch","cs\u003d0 . 5","cs\u003d0","cs\u003d0 . 2"],"mergedAllColumns":[],"numberCells":[{"number":"59.8","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 7"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["scratch"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 5"],"associatedMergedColumns":[]},{"number":"60.2","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0 . 2"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["SUN RGB - D"],"associatedColumns":["cs\u003d0"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparison between ex-\nplicit approaches and our model \non real data completion task. Our \nmodel built upon convolutional oc-\ncupancy network shows consistent \nimprovements. \n\n","rows":["FoldingNet [ 58 ]","Implicit Conv - OccNet [ 38 ]","Explicit","SnowflakeNet [ 56 ]","OcCo [ 51 ]"],"columns":["SUN RGB - D"],"mergedAllColumns":[],"numberCells":[{"number":"58.1","isBolded":false,"associatedRows":["Implicit Conv - OccNet [ 38 ]","SnowflakeNet [ 56 ]"],"associatedColumns":["SUN RGB - D"],"associatedMergedColumns":[]},{"number":"58.4","isBolded":false,"associatedRows":["Explicit","OcCo [ 51 ]"],"associatedColumns":["SUN RGB - D"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":true,"associatedRows":["Implicit Conv - OccNet [ 38 ]"],"associatedColumns":["SUN RGB - D"],"associatedMergedColumns":[]},{"number":"58.2","isBolded":false,"associatedRows":["Implicit Conv - OccNet [ 38 ]","FoldingNet [ 58 ]"],"associatedColumns":["SUN RGB - D"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Shape classification fine-tuned results on ScanObjectNN. \nSupervised learning methods train the model from scratch. Our method uses \nDGCNN as the encoder backbone. \n\n","rows":["PointNet [ 41 ]","PRANet [ 9 ]","IAE + DGCNN ( ours )","DGCNN [ 52 ]","PointCNN [ 25 ]","PointNet++ [ 42 ]"],"columns":["mAcc ( % ) OA ( % )"],"mergedAllColumns":[],"numberCells":[{"number":"81.4%","isBolded":false,"associatedRows":["IAE + DGCNN ( ours )"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"73.6%","isBolded":false,"associatedRows":["DGCNN [ 52 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"78.5%","isBolded":false,"associatedRows":["PointCNN [ 25 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"79.1%","isBolded":false,"associatedRows":["PRANet [ 9 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"68.2%","isBolded":false,"associatedRows":["PointNet [ 41 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"63.4%","isBolded":false,"associatedRows":["PointNet [ 41 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"75.1%","isBolded":false,"associatedRows":["PointCNN [ 25 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"77.9%","isBolded":false,"associatedRows":["PointNet++ [ 42 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"78.1%","isBolded":false,"associatedRows":["DGCNN [ 52 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"79.2%","isBolded":true,"associatedRows":["IAE + DGCNN ( ours )"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"82.1%","isBolded":true,"associatedRows":["PRANet [ 9 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]},{"number":"75.4%","isBolded":false,"associatedRows":["PointNet++ [ 42 ]"],"associatedColumns":["mAcc ( % ) OA ( % )"],"associatedMergedColumns":[]}]}]