[{"caption":"Table 1: Performance of the proposed LV-ViT with different model sizes. Here, \u0027depth\u0027 denotes \nthe number of transformer blocks used in different models. By default, the test resolution is set to \n224 ? 224 except the last one which is 288 ? 288. \n\n","rows":["26M","56M","224x224","240","384","LV - ViT - L","LV - ViT - M","4","6","512","150M","LV - ViT - S","8","LV - ViT - T","768","288x288"],"columns":["MLP Ratio","Top - 1 Acc . ( % )","#Parameters","Depth","#Heads"],"mergedAllColumns":[],"numberCells":[{"number":"3.0","isBolded":false,"associatedRows":["LV - ViT - L","768"],"associatedColumns":["MLP Ratio"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["LV - ViT - T","240"],"associatedColumns":["MLP Ratio"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["LV - ViT - M"],"associatedColumns":["Depth"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["LV - ViT - T"],"associatedColumns":["Depth"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["LV - ViT - M","512","8","56M","224x224"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["LV - ViT - S","384"],"associatedColumns":["MLP Ratio"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["LV - ViT - L","768"],"associatedColumns":["#Heads"],"associatedMergedColumns":[]},{"number":"8.5M","isBolded":false,"associatedRows":["LV - ViT - T","240","4"],"associatedColumns":["#Parameters"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["LV - ViT - L"],"associatedColumns":["Depth"],"associatedMergedColumns":[]},{"number":"79.1","isBolded":false,"associatedRows":["LV - ViT - T","240","4","26M","224x224"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"83.3","isBolded":false,"associatedRows":["LV - ViT - S","384","6","26M","224x224"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"85.3","isBolded":true,"associatedRows":["LV - ViT - L","768","8","150M","288x288"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["LV - ViT - S"],"associatedColumns":["Depth"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["LV - ViT - M","512"],"associatedColumns":["MLP Ratio"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Ablation on different widely-used data aug-\nmentations. We have empirically found our proposed \nMixToken performs even better than the combination \nof MixUp and CutMix in vision transformers. \n\n","rows":[],"columns":["Top - 1 Acc ."],"mergedAllColumns":[],"numberCells":[{"number":"82.8","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"81.3","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"83.0","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"83.1","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"83.3","isBolded":true,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]}]},{"caption":"Table 3. We can see when all the four augmentation methods are used, a top-1 accuracy of 83.1% is \nachieved. Interestingly, when the MixUp augmentation is removed, the performance can be improved \nto 83.3%. This may be explained as, using MixToken and MixUp at the same time would bring \ntoo much noise in the label, and consequently cause confusion of the model. Moreover, the CutOut \naugmentation, which randomly erases some parts of the image, is also effective and removing it \nbrings a performance drop of 0.3%. Similarly, the RandAug augmentation also contributes to the \nperformance and using it brings an improvement of 0.5%. \n\n","rows":[],"columns":["Top - 1 Acc ."],"mergedAllColumns":[],"numberCells":[{"number":"83.3","isBolded":true,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"81.3","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"82.8","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"83.0","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]},{"number":"83.1","isBolded":false,"associatedRows":[],"associatedColumns":["Top - 1 Acc ."],"associatedMergedColumns":[]}]},{"caption":"Table 4: Top-1 accuracy comparison with other methods on ImageNet [14] and ImageNet Real [2]. \nAll models are trained without external data. With the same computation and parameter constraint, \nour model consistently outperforms other CNN-based and transformer-based counterparts. The \nresults of CNNs and ViT are referenced from [37]. \n\n","rows":["316M","NFNet - F5 [ 3 ]","377M","NFNet - F4 [ 3 ]","EfficientNet - B7 [ 34 ]","LV - ViT - M?384","255M","56M","66M","87M","CNNs","30M","LV - ViT - L","LV - ViT - L?448","Fix - EfficientNet - B8 [ 34 , 38 ]","150M","EfficientNet - B5 [ 34 ]","151M","NFNet - F3 [ 3 ]","LV - ViT - L?512"],"columns":["FLOPs","Top - 1 ( % )","Train size","Real Top - 1 ( % )","Test size"],"mergedAllColumns":["_"],"numberCells":[{"number":"448","isBolded":true,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"42.2B","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"600","isBolded":true,"associatedRows":["EfficientNet - B7 [ 34 ]","66M"],"associatedColumns":["Test size"],"associatedMergedColumns":[]},{"number":"672","isBolded":true,"associatedRows":["CNNs","Fix - EfficientNet - B8 [ 34 , 38 ]","87M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"86.2","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.5B","isBolded":false,"associatedRows":["CNNs","Fix - EfficientNet - B8 [ 34 , 38 ]","87M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"85.7","isBolded":false,"associatedRows":["CNNs","Fix - EfficientNet - B8 [ 34 , 38 ]","87M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.9","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"88.3","isBolded":false,"associatedRows":["EfficientNet - B5 [ 34 ]","30M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"288","isBolded":true,"associatedRows":["LV - ViT - L","150M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"9.9B","isBolded":false,"associatedRows":["EfficientNet - B5 [ 34 ]","30M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"215.3B","isBolded":false,"associatedRows":["NFNet - F4 [ 3 ]","316M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"800","isBolded":true,"associatedRows":["CNNs","Fix - EfficientNet - B8 [ 34 , 38 ]","87M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"86.4","isBolded":false,"associatedRows":["LV - ViT - L?512","151M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"157.2B","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"224","isBolded":true,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"600","isBolded":true,"associatedRows":["EfficientNet - B7 [ 34 ]","66M"],"associatedColumns":["Train size"],"associatedMergedColumns":[]},{"number":"384","isBolded":true,"associatedRows":["NFNet - F4 [ 3 ]","316M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"288","isBolded":true,"associatedRows":["LV - ViT - L","150M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"89.2","isBolded":false,"associatedRows":["NFNet - F5 [ 3 ]","377M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"448","isBolded":true,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"83.6","isBolded":false,"associatedRows":["EfficientNet - B5 [ 34 ]","30M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":[]},{"number":"85.4","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"512","isBolded":true,"associatedRows":["LV - ViT - L?512","151M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"37.0B","isBolded":false,"associatedRows":["EfficientNet - B7 [ 34 ]","66M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.4","isBolded":false,"associatedRows":["NFNet - F4 [ 3 ]","316M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"214.8B","isBolded":false,"associatedRows":["LV - ViT - L?512","151M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"85.9","isBolded":false,"associatedRows":["NFNet - F4 [ 3 ]","316M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"416","isBolded":true,"associatedRows":["NFNet - F5 [ 3 ]","377M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"384","isBolded":true,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"89.3","isBolded":false,"associatedRows":["LV - ViT - L","150M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"512","isBolded":true,"associatedRows":["NFNet - F4 [ 3 ]","316M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"224","isBolded":true,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"16.0B","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"114.8B","isBolded":false,"associatedRows":["CNNs","NFNet - F3 [ 3 ]","255M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"90.0","isBolded":false,"associatedRows":["CNNs","Fix - EfficientNet - B8 [ 34 , 38 ]","87M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"320","isBolded":true,"associatedRows":["CNNs","NFNet - F3 [ 3 ]","255M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"84.3","isBolded":false,"associatedRows":["EfficientNet - B7 [ 34 ]","66M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":[]},{"number":"289.8B","isBolded":false,"associatedRows":["NFNet - F5 [ 3 ]","377M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"86.0","isBolded":false,"associatedRows":["NFNet - F5 [ 3 ]","377M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"90.1","isBolded":false,"associatedRows":["LV - ViT - L?512","151M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"456","isBolded":true,"associatedRows":["EfficientNet - B5 [ 34 ]","30M"],"associatedColumns":["Train size"],"associatedMergedColumns":[]},{"number":"288","isBolded":true,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"157.2B","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"448","isBolded":true,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"456","isBolded":true,"associatedRows":["EfficientNet - B5 [ 34 ]","30M"],"associatedColumns":["Test size"],"associatedMergedColumns":[]},{"number":"88.4","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.5","isBolded":false,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.7","isBolded":false,"associatedRows":["LV - ViT - L?448","150M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"85.3","isBolded":false,"associatedRows":["LV - ViT - L","150M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"448","isBolded":true,"associatedRows":["LV - ViT - L?512","151M"],"associatedColumns":["Train size"],"associatedMergedColumns":["_"]},{"number":"544","isBolded":true,"associatedRows":["NFNet - F5 [ 3 ]","377M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"416","isBolded":true,"associatedRows":["CNNs","NFNet - F3 [ 3 ]","255M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]},{"number":"59.0B","isBolded":false,"associatedRows":["LV - ViT - L","150M"],"associatedColumns":["FLOPs"],"associatedMergedColumns":["_"]},{"number":"85.7","isBolded":false,"associatedRows":["CNNs","NFNet - F3 [ 3 ]","255M"],"associatedColumns":["Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"89.4","isBolded":false,"associatedRows":["CNNs","NFNet - F3 [ 3 ]","255M"],"associatedColumns":["Real Top - 1 ( % )"],"associatedMergedColumns":["_"]},{"number":"224","isBolded":true,"associatedRows":["LV - ViT - M?384","56M"],"associatedColumns":["Test size"],"associatedMergedColumns":["_"]}]},{"caption":"Table 5: Transfer performance of the proposed LV-ViT in semantic segmentation. We take two classic \nmethods, FCN and UperNet, as segmentation architectures and show both single-scale (SS) and \nmulti-scale (MS) results on the validation set. \n\n","rows":["30M","44M","LV - ViT - S + UperNet","LV - ViT - S + FCN"],"columns":["P . Acc . ( SS )","mIoU ( MS )","mIoU ( SS )","P . Acc . ( MS )"],"mergedAllColumns":[],"numberCells":[{"number":"82.1","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["P . Acc . ( SS )"],"associatedMergedColumns":[]},{"number":"46.5","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["mIoU ( SS )"],"associatedMergedColumns":[]},{"number":"83.1","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["P . Acc . ( MS )"],"associatedMergedColumns":[]},{"number":"46.1","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["mIoU ( SS )"],"associatedMergedColumns":[]},{"number":"83.0","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["P . Acc . ( MS )"],"associatedMergedColumns":[]},{"number":"47.3","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"82.6","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["P . Acc . ( MS )"],"associatedMergedColumns":[]},{"number":"47.2","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["mIoU ( SS )"],"associatedMergedColumns":[]},{"number":"47.9","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["mIoU ( SS )"],"associatedMergedColumns":[]},{"number":"82.4","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["P . Acc . ( SS )"],"associatedMergedColumns":[]},{"number":"47.6","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"48.4","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"48.6","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["LV - ViT - S + FCN","30M"],"associatedColumns":["P . Acc . ( SS )"],"associatedMergedColumns":[]},{"number":"82.7","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["P . Acc . ( MS )"],"associatedMergedColumns":[]},{"number":"82.6","isBolded":false,"associatedRows":["LV - ViT - S + UperNet","44M"],"associatedColumns":["P . Acc . ( SS )"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Comparison with previous work on ADE20K validation set. As far as we know, our LV-\nViT-L + UperNet achieves the best result on ADE20K with only ImageNet-1K as training data in \npretraining.  ? Pretrained on ImageNet-22K. \n\n","rows":["UperNet","121M","88M","44M","LV - ViT","CNNs","86M","52M","30M","60M","ResNet - 269","ResNet - 101","SETR [ 56 ]","308M","209M","PSPNet [ 54 ]","Swin - B ? [ 26 ]","ResNeSt200","DeepLabV3+ [ 9 ]","-","DeiT - S","77M","FCN","LV - ViT - L","LV - ViT - M","ViT - Large ?","81M","UperNet [ 44 ]","Swin - T [ 26 ]","Swin - S [ 26 ]","LV - ViT - S","Transformers","Swin - B [ 26 ]","Strip Pooling [ 23 ]"],"columns":["mIoU ( MS )","Pixel Acc . ( MS )"],"mergedAllColumns":["-"],"numberCells":[{"number":"84.1","isBolded":true,"associatedRows":["LV - ViT","LV - ViT - L","UperNet","209M"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"45.6","isBolded":false,"associatedRows":["CNNs","ResNet - 101","Strip Pooling [ 23 ]","-"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"83.0","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - S","FCN","30M"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"83.1","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - S","UperNet","44M"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"48.6","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - S","UperNet","44M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"44.9","isBolded":false,"associatedRows":["CNNs","ResNet - 269","PSPNet [ 54 ]","-"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"49.7","isBolded":false,"associatedRows":["Transformers","Swin - B [ 26 ]","UperNet","121M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"50.3","isBolded":false,"associatedRows":["Transformers","ViT - Large ?","SETR [ 56 ]","308M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"44.0","isBolded":false,"associatedRows":["Transformers","DeiT - S","UperNet","52M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"83.5","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - M","UperNet","77M"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"46.1","isBolded":false,"associatedRows":["Transformers","Swin - T [ 26 ]","UperNet","60M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"51.6","isBolded":false,"associatedRows":["Transformers","Swin - B ? [ 26 ]","UperNet","121M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"81.7","isBolded":false,"associatedRows":["CNNs","ResNet - 269","PSPNet [ 54 ]","-"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":[]},{"number":"48.4","isBolded":false,"associatedRows":["CNNs","ResNeSt200","DeepLabV3+ [ 9 ]","88M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"82.1","isBolded":false,"associatedRows":["CNNs","ResNet - 101","Strip Pooling [ 23 ]","-"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"48.4","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - S","FCN","30M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"50.6","isBolded":false,"associatedRows":["LV - ViT","LV - ViT - M","UperNet","77M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"49.3","isBolded":false,"associatedRows":["Transformers","Swin - S [ 26 ]","UperNet","81M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]},{"number":"44.9","isBolded":false,"associatedRows":["CNNs","ResNet - 101","UperNet [ 44 ]","86M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":[]},{"number":"83.5","isBolded":false,"associatedRows":["Transformers","ViT - Large ?","SETR [ 56 ]","308M"],"associatedColumns":["Pixel Acc . ( MS )"],"associatedMergedColumns":["-"]},{"number":"51.8","isBolded":true,"associatedRows":["LV - ViT","LV - ViT - L","UperNet","209M"],"associatedColumns":["mIoU ( MS )"],"associatedMergedColumns":["-"]}]},{"caption":"Table 7: Default hyper-parameters for our experiments. Note that we do not use the MixUp augmen-\ntation method when ReLabel or token labeling is used. \n\n","rows":["Stoch . Depth","Weight decay","MixUp alpha","Erasing prob ."],"columns":["B","LR decay","LR","1e - 3? batch_size","Epoch","Standard","-","RandAug","Token labeling","0","300","ReLabel","5","1024","Warmup epochs","cosine","Batch size","1e - 3 ? batch_size","Supervision","Dropout"],"mergedAllColumns":[],"numberCells":[{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":["MixUp alpha"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"B.1","isBolded":true,"associatedRows":[],"associatedColumns":["Supervision","Epoch","Batch size","LR","LR decay","Warmup epochs","Dropout","-","RandAug","B"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine","5","0"],"associatedMergedColumns":[]}]},{"caption":"Table 8. We take the DeiT-Small ","rows":["Stoch . Depth","Weight decay","MixUp alpha","Erasing prob ."],"columns":["B","LR decay","LR","1e - 3? batch_size","Epoch","Standard","-","RandAug","Token labeling","0","300","ReLabel","5","1024","Warmup epochs","cosine","Batch size","1e - 3 ? batch_size","Supervision","Dropout"],"mergedAllColumns":[],"numberCells":[{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"B.1","isBolded":true,"associatedRows":[],"associatedColumns":["Supervision","Epoch","Batch size","LR","LR decay","Warmup epochs","Dropout","-","RandAug","B"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":["MixUp alpha"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["Standard","300","1024","1e - 3 ? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Erasing prob ."],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine","5","0","-"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["ReLabel","300","1024","1e - 3? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Stoch . Depth"],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine","5","0"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Weight decay"],"associatedColumns":["Token labeling","300","1024","1e - 3? batch_size","cosine"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Ablation on patch embedding. Baseline is set as 16 layer ViT with embedding size 384 and \nMLP expansion ratio of 3. All convolutional layers except the last block have 64 filters. #Convs \nindicatie the total number of convolutions for patch embedding, while the kernel size and stride \ncorrespond to each layer are shown as a list in the table. \n\n","rows":["[ 16 ]","[ 2 , 1 , 1 , 1 , 1 , 8 ]","[ 7 , 3 , 8 ]","[ 2 , 8 ]","26M","25M","[ 7 , 3 , 3 , 3 , 3 , 8 ]","1","2","3","4","[ 7 , 8 ]","6","[ 2 , 1 , 1 , 8 ]","[ 2 , 1 , 8 ]","[ 7 , 3 , 3 , 8 ]","[ 2 , 2 , 4 ]"],"columns":["Top - 1 Acc . ( % )"],"mergedAllColumns":[],"numberCells":[{"number":"81.4","isBolded":false,"associatedRows":["2","[ 7 , 8 ]","[ 2 , 8 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["1","[ 16 ]","[ 16 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":true,"associatedRows":["4","[ 7 , 3 , 3 , 8 ]","[ 2 , 1 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["3","[ 7 , 3 , 8 ]","[ 2 , 2 , 4 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":true,"associatedRows":["6","[ 7 , 3 , 3 , 3 , 3 , 8 ]","[ 2 , 1 , 1 , 1 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["3","[ 7 , 3 , 8 ]","[ 2 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]}]},{"caption":"Table 10. We found that using smaller scaling factor can lead to better performance \nand faster convergence. Part of the reason is that more information can be preserved in the main \nbranch, leading to less information loss and better performance. \n\n","rows":["[ 16 ]","[ 2 , 1 , 1 , 1 , 1 , 8 ]","[ 7 , 3 , 8 ]","[ 2 , 8 ]","26M","25M","[ 7 , 3 , 3 , 3 , 3 , 8 ]","1","2","3","4","[ 7 , 8 ]","6","[ 2 , 1 , 1 , 8 ]","[ 2 , 1 , 8 ]","[ 7 , 3 , 3 , 8 ]","[ 2 , 2 , 4 ]"],"columns":["Top - 1 Acc . ( % )"],"mergedAllColumns":[],"numberCells":[{"number":"81.1","isBolded":false,"associatedRows":["1","[ 16 ]","[ 16 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["3","[ 7 , 3 , 8 ]","[ 2 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":true,"associatedRows":["4","[ 7 , 3 , 3 , 8 ]","[ 2 , 1 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":true,"associatedRows":["6","[ 7 , 3 , 3 , 3 , 3 , 8 ]","[ 2 , 1 , 1 , 1 , 1 , 8 ]","26M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["3","[ 7 , 3 , 8 ]","[ 2 , 2 , 4 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["2","[ 7 , 8 ]","[ 2 , 8 ]","25M"],"associatedColumns":["Top - 1 Acc . ( % )"],"associatedMergedColumns":[]}]},{"caption":"Table 11: Performance of the proposed token labeling objective on representative CNN-based \n(ResNeSt) and MLP-based (Mixer-MLP) models. Our method has a consistent improvement on all \ndifferent models. Here  ? indicates results reported in original papers. \n\n","rows":["Top - 1 Acc . ( % )"],"columns":["Mixer - B / 16 [ 35 ]","Mixer - L / 16 [ 35 ]","207M","18M","ResNeSt - 50 [ 51 ]","27M","59M","Mixer - S / 16 [ 35 ]"],"mergedAllColumns":["Token Labeling"],"numberCells":[{"number":"78.3","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - B / 16 [ 35 ]","59M"],"associatedMergedColumns":["Token Labeling"]},{"number":"77.7","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - L / 16 [ 35 ]","207M"],"associatedMergedColumns":["Token Labeling"]},{"number":"76.1","isBolded":true,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - S / 16 [ 35 ]","18M"],"associatedMergedColumns":["Token Labeling"]},{"number":"76.4?","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - B / 16 [ 35 ]","59M"],"associatedMergedColumns":["Token Labeling"]},{"number":"81.1?","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["ResNeSt - 50 [ 51 ]","27M"],"associatedMergedColumns":["Token Labeling"]},{"number":"81.5","isBolded":true,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["ResNeSt - 50 [ 51 ]","27M"],"associatedMergedColumns":["Token Labeling"]},{"number":"79.5","isBolded":true,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - B / 16 [ 35 ]","59M"],"associatedMergedColumns":["Token Labeling"]},{"number":"73.8?","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - S / 16 [ 35 ]","18M"],"associatedMergedColumns":["Token Labeling"]},{"number":"80.1","isBolded":true,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - L / 16 [ 35 ]","207M"],"associatedMergedColumns":["Token Labeling"]},{"number":"75.6","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - S / 16 [ 35 ]","18M"],"associatedMergedColumns":["Token Labeling"]},{"number":"71.6?","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["Mixer - L / 16 [ 35 ]","207M"],"associatedMergedColumns":["Token Labeling"]},{"number":"80.9","isBolded":false,"associatedRows":["Top - 1 Acc . ( % )"],"associatedColumns":["ResNeSt - 50 [ 51 ]","27M"],"associatedMergedColumns":["Token Labeling"]}]},{"caption":"Table 12: Comparison with CaiT [37]. Our model exploits less training techniques, model size, and \ncomputations but achieve identical result to CaiT. \n\n","rows":["ImageNet Top - 1 Acc .","Training Epoch","Test Resolution","Embedding Dimension","Stochastic Depth [ 24 ]"],"columns":["12","3","CaiT [ 37 ]","36","4","42B","LV - ViT ( Ours )","8","69M","56M","20","48B"],"mergedAllColumns":["Token Labeling ( Ours )"],"numberCells":[{"number":"384","isBolded":false,"associatedRows":["Embedding Dimension"],"associatedColumns":["CaiT [ 37 ]","36","12","4"],"associatedMergedColumns":[]},{"number":"0.2(Linear)","isBolded":false,"associatedRows":["Stochastic Depth [ 24 ]"],"associatedColumns":["LV - ViT ( Ours )","20","8","3"],"associatedMergedColumns":[]},{"number":"85.4","isBolded":false,"associatedRows":["ImageNet Top - 1 Acc ."],"associatedColumns":["CaiT [ 37 ]","36","12","4","69M","48B"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"384?","isBolded":true,"associatedRows":["Test Resolution"],"associatedColumns":["LV - ViT ( Ours )","20","8","3"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"0.2(Fixed)","isBolded":false,"associatedRows":["Stochastic Depth [ 24 ]"],"associatedColumns":["CaiT [ 37 ]","36","12","4"],"associatedMergedColumns":[]},{"number":"384?","isBolded":true,"associatedRows":["Test Resolution"],"associatedColumns":["CaiT [ 37 ]","36","12","4"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"512","isBolded":false,"associatedRows":["Embedding Dimension"],"associatedColumns":["LV - ViT ( Ours )","20","8","3"],"associatedMergedColumns":[]},{"number":"384","isBolded":true,"associatedRows":["Test Resolution"],"associatedColumns":["LV - ViT ( Ours )","20","8","3"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"400","isBolded":false,"associatedRows":["Training Epoch"],"associatedColumns":["CaiT [ 37 ]","36","12","4","69M","48B"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"85.4","isBolded":false,"associatedRows":["ImageNet Top - 1 Acc ."],"associatedColumns":["LV - ViT ( Ours )","20","8","3","56M","42B"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"384","isBolded":true,"associatedRows":["Test Resolution"],"associatedColumns":["CaiT [ 37 ]","36","12","4"],"associatedMergedColumns":["Token Labeling ( Ours )"]},{"number":"300","isBolded":false,"associatedRows":["Training Epoch"],"associatedColumns":["LV - ViT ( Ours )","20","8","3","56M","42B"],"associatedMergedColumns":["Token Labeling ( Ours )"]}]}]