[{"caption":"(a) ESC-50 \n\n(b) DCASE \nMethod \nAccuracy \nSVM-MFCC [26]  39.6% \nAutoencoder [2]  39.9% \nRandom Forest [26]  44.3% \nPiczak ConvNet [25]  64.5% \nSoundNet [2]  74.2% \nOurs random \n62.5% \nOurs \n79.3% \nHuman perf. [26]  81.3% \n\nMethod \nAccuracy \nRG [27]  69% \nLTT [19]  72% \nRNH [28]  77% \nEnsemble [32]  78% \nSoundNet [2]  88% \nOurs random \n85% \nOurs \n93% \n\nTable 2. Sound classification. \"Ours random\" is an additional \nbaseline which shows the performance of our network without L 3 -\ntraining. Our L 3 -training sets the new state-of-the-art by a large \nmargin on both benchmarks. \n\n","rows":["Autoencoder [ 2 ]","Ours random","Ours","Doersch et al . [ 6 ]","over all parameter choices ( e . g . Donahue et al . [ 7 ] achieve","Piczak ConvNet [ 25 ]","Kr?henb?hl et al . [ 16 ]","instead of","SVM - MFCC [ 26 ]","Pathak et al . [ 24 ]","SoundNet [ 2 ]","Zhang et al . [ 36 ] ( init : [ 16 ] )","Donahue et al . [ 7 ]","Noroozi and Favaro [ 21 ]","Random Forest [ 26 ]","Human perf . [ 26 ]"],"columns":["69%","( a ) ESC - 50","77%","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","85%","93%","Table 2 . Sound classification .","LTT [ 19 ]","Accuracy","Ensemble [ 32 ]","( b ) DCASE","training . Our L","Ours random","Ours","Top 1 accuracy","RNH [ 28 ]","78%","88%","72%","Method","-","\" Ours random \" is an additional","For more details and discussions see Section","SoundNet [ 2 ]","RG [ 27 ]"],"mergedAllColumns":["thors of [ 36 ] , showing only the best performance for each method","geNet training set and measuring the classification accuracy on","margin on both benchmarks ."],"numberCells":[{"number":"62.5%","isBolded":false,"associatedRows":["Ours random","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]"],"associatedMergedColumns":[]},{"number":"79.3%","isBolded":true,"associatedRows":["Ours","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random"],"associatedMergedColumns":[]},{"number":"32.3%","isBolded":false,"associatedRows":["Ours"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"18.3%","isBolded":false,"associatedRows":["Kr?henb?hl et al . [ 16 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"44.3%","isBolded":false,"associatedRows":["Random Forest [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]"],"associatedMergedColumns":[]},{"number":"31.0%","isBolded":false,"associatedRows":["Donahue et al . [ 7 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"64.5%","isBolded":false,"associatedRows":["Piczak ConvNet [ 25 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]"],"associatedMergedColumns":[]},{"number":"3.4.Allperformancenumbersapartfromoursareprovidedbyau-","isBolded":false,"associatedRows":[],"associatedColumns":["( b ) DCASE","Method","69%","72%","77%","78%","88%","85%","93%","Ours","Table 2 . Sound classification .","baseline which shows the performance of our network without L","training . Our L","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["geNet training set and measuring the classification accuracy on"]},{"number":"39.6%","isBolded":false,"associatedRows":["SVM - MFCC [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy"],"associatedMergedColumns":[]},{"number":"31.7%","isBolded":false,"associatedRows":["Doersch et al . [ 6 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"12.9%","isBolded":false,"associatedRows":["Ours random"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"32.6%","isBolded":false,"associatedRows":["Zhang et al . [ 36 ] ( init : [ 16 ] )"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"24.5%","isBolded":false,"associatedRows":["Kr?henb?hl et al . [ 16 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"39.9%","isBolded":false,"associatedRows":["Autoencoder [ 2 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]"],"associatedMergedColumns":[]},{"number":"81.3%","isBolded":true,"associatedRows":["Human perf . [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours"],"associatedMergedColumns":[]},{"number":"27.1%","isBolded":false,"associatedRows":["over all parameter choices ( e . g . Donahue et al . [ 7 ] achieve"],"associatedColumns":["( b ) DCASE","Accuracy","69%","72%","77%","78%","88%","85%","93%","\" Ours random \" is an additional","-","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["thors of [ 36 ] , showing only the best performance for each method"]},{"number":"74.2%","isBolded":false,"associatedRows":["SoundNet [ 2 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]"],"associatedMergedColumns":[]},{"number":"31.0%whentakingfeaturesfrompool5insteadof","isBolded":false,"associatedRows":["instead of"],"associatedColumns":["( b ) DCASE","Method","69%","72%","77%","78%","88%","85%","93%","Ours","Table 2 . Sound classification .","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["thors of [ 36 ] , showing only the best performance for each method"]},{"number":"22.3%","isBolded":false,"associatedRows":["Pathak et al . [ 24 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"34.7%","isBolded":false,"associatedRows":["Noroozi and Favaro [ 21 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]}]},{"caption":"Method \nTop 1 accuracy \nRandom \n18.3% \nPathak et al. [24] \n22.3% \nKr?henb?hl et al. [16] \n24.5% \nDonahue et al. [7] \n31.0% \nDoersch et al. [6] \n31.7% \nZhang et al. [36] (init: [16]) \n32.6% \nNoroozi and Favaro [21] \n34.7% \nOurs random \n12.9% \nOurs \n32.3% \n\nTable 3. Visual classification on ImageNet. Following [36], our \nfeatures are evaluated by training a linear classifier on the Ima-\ngeNet training set and measuring the classification accuracy on \nthe validation set. For more details and discussions see Section \n3.4. All performance numbers apart from ours are provided by au-\nthors of [36], showing only the best performance for each method \nover all parameter choices (e.g. Donahue et al. [7] achieve 27.1% \ninstead of 31.0% when taking features from pool5 instead of \nconv3). \n\n","rows":["Autoencoder [ 2 ]","Ours random","Ours","Doersch et al . [ 6 ]","over all parameter choices ( e . g . Donahue et al . [ 7 ] achieve","Piczak ConvNet [ 25 ]","Kr?henb?hl et al . [ 16 ]","instead of","SVM - MFCC [ 26 ]","Pathak et al . [ 24 ]","SoundNet [ 2 ]","Zhang et al . [ 36 ] ( init : [ 16 ] )","Donahue et al . [ 7 ]","Noroozi and Favaro [ 21 ]","Random Forest [ 26 ]","Human perf . [ 26 ]"],"columns":["69%","( a ) ESC - 50","77%","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","85%","93%","Table 2 . Sound classification .","LTT [ 19 ]","Accuracy","Ensemble [ 32 ]","( b ) DCASE","training . Our L","Ours random","Ours","Top 1 accuracy","RNH [ 28 ]","78%","88%","72%","Method","-","\" Ours random \" is an additional","For more details and discussions see Section","SoundNet [ 2 ]","RG [ 27 ]"],"mergedAllColumns":["thors of [ 36 ] , showing only the best performance for each method","geNet training set and measuring the classification accuracy on","margin on both benchmarks ."],"numberCells":[{"number":"62.5%","isBolded":false,"associatedRows":["Ours random","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]"],"associatedMergedColumns":[]},{"number":"32.6%","isBolded":false,"associatedRows":["Zhang et al . [ 36 ] ( init : [ 16 ] )"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"39.9%","isBolded":false,"associatedRows":["Autoencoder [ 2 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]"],"associatedMergedColumns":[]},{"number":"34.7%","isBolded":false,"associatedRows":["Noroozi and Favaro [ 21 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"31.0%whentakingfeaturesfrompool5insteadof","isBolded":false,"associatedRows":["instead of"],"associatedColumns":["( b ) DCASE","Method","69%","72%","77%","78%","88%","85%","93%","Ours","Table 2 . Sound classification .","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["thors of [ 36 ] , showing only the best performance for each method"]},{"number":"31.7%","isBolded":false,"associatedRows":["Doersch et al . [ 6 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"32.3%","isBolded":false,"associatedRows":["Ours"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"39.6%","isBolded":false,"associatedRows":["SVM - MFCC [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy"],"associatedMergedColumns":[]},{"number":"79.3%","isBolded":true,"associatedRows":["Ours","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random"],"associatedMergedColumns":[]},{"number":"81.3%","isBolded":true,"associatedRows":["Human perf . [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours"],"associatedMergedColumns":[]},{"number":"24.5%","isBolded":false,"associatedRows":["Kr?henb?hl et al . [ 16 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"74.2%","isBolded":false,"associatedRows":["SoundNet [ 2 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]"],"associatedMergedColumns":[]},{"number":"31.0%","isBolded":false,"associatedRows":["Donahue et al . [ 7 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"44.3%","isBolded":false,"associatedRows":["Random Forest [ 26 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]"],"associatedMergedColumns":[]},{"number":"22.3%","isBolded":false,"associatedRows":["Pathak et al . [ 24 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"3.4.Allperformancenumbersapartfromoursareprovidedbyau-","isBolded":false,"associatedRows":[],"associatedColumns":["( b ) DCASE","Method","69%","72%","77%","78%","88%","85%","93%","Ours","Table 2 . Sound classification .","baseline which shows the performance of our network without L","training . Our L","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["geNet training set and measuring the classification accuracy on"]},{"number":"64.5%","isBolded":false,"associatedRows":["Piczak ConvNet [ 25 ]","Pathak et al . [ 24 ]"],"associatedColumns":["( a ) ESC - 50","Accuracy","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]"],"associatedMergedColumns":[]},{"number":"18.3%","isBolded":false,"associatedRows":["Kr?henb?hl et al . [ 16 ]"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"12.9%","isBolded":false,"associatedRows":["Ours random"],"associatedColumns":["( b ) DCASE","Method","RG [ 27 ]","LTT [ 19 ]","RNH [ 28 ]","Ensemble [ 32 ]","SoundNet [ 2 ]","Ours random","Ours","\" Ours random \" is an additional","baseline which shows the performance of our network without L","- training sets the new state - of - the - art by a large","Top 1 accuracy"],"associatedMergedColumns":["margin on both benchmarks ."]},{"number":"27.1%","isBolded":false,"associatedRows":["over all parameter choices ( e . g . Donahue et al . [ 7 ] achieve"],"associatedColumns":["( b ) DCASE","Accuracy","69%","72%","77%","78%","88%","85%","93%","\" Ours random \" is an additional","-","- training sets the new state - of - the - art by a large","Top 1 accuracy","For more details and discussions see Section"],"associatedMergedColumns":["thors of [ 36 ] , showing only the best performance for each method"]}]},{"caption":"confirm the emergence of semantics as \n\nMethod \nVision Audio \nRandom assignments \n0.165 \n0.165 \nOurs random (L 3 -Net without training) 0.204 \n0.219 \nOurs (L 3 -Net self-supervised training) \n0.409 \n0.330 \n\nTable 4. Clustering quality. Normalized Mutual Information \n(NMI) score between the unsupervised clusterings of feature em-\nbeddings and the Kinetics-Sounds labels. \n\n","rows":["Random assignments","Ours ( L","- Net self - supervised training )","Ours random ( L","- Net without training )"],"columns":["confirm the emergence of semantics as","Vision","Audio"],"mergedAllColumns":["3"],"numberCells":[{"number":"0.165","isBolded":false,"associatedRows":["Random assignments","- Net without training )"],"associatedColumns":["confirm the emergence of semantics as","Vision"],"associatedMergedColumns":[]},{"number":"0.165","isBolded":false,"associatedRows":["Random assignments","- Net without training )"],"associatedColumns":["confirm the emergence of semantics as","Audio"],"associatedMergedColumns":[]},{"number":"0.330","isBolded":false,"associatedRows":["Ours ( L","- Net self - supervised training )"],"associatedColumns":["confirm the emergence of semantics as","Audio"],"associatedMergedColumns":["3"]},{"number":"0.409","isBolded":false,"associatedRows":["Ours ( L","- Net self - supervised training )"],"associatedColumns":["confirm the emergence of semantics as","Vision"],"associatedMergedColumns":["3"]},{"number":"0.219","isBolded":false,"associatedRows":["Ours random ( L","- Net without training )"],"associatedColumns":["confirm the emergence of semantics as","Audio"],"associatedMergedColumns":[]},{"number":"0.204","isBolded":false,"associatedRows":["Ours random ( L","- Net without training )"],"associatedColumns":["confirm the emergence of semantics as","Vision"],"associatedMergedColumns":[]}]}]