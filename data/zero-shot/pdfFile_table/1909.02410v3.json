[{"caption":"Name \n\nOutput Size \nBlocks \n\natt conv I \n512 ? 5 ? 5 \n3 ? 3, 512, stride 1 \n\natt conv M \n512 ? 5 ? 5 \n3 ? 3, 512, stride 1 \n\natt conv2 I \n1024 ? 3 ? 3 \n3 ? 3, 1024, stride 1 \n\natt conv2 M 1024 ? 3 ? 3 \n3 ? 3, 1024, stride 1 \n\nattention \n1024 ? 3 ? 3 \nHadamard product \n\navg pool \n1024 ? 1 ? 1 \nAverage Pooling \n\nclassifier \nK ? 1 \nDropout, K-dimensional FC, Softmax \n\nTable 1: Layers and output sizes for the Attention Module. \n\n","rows":["1024 ?","att conv2 M","K ?","att conv M","att conv2 I","avg pool","classifier","att conv I","attention","512 ?"],"columns":["Blocks","Output Size"],"mergedAllColumns":["Average Pooling","Hadamard product"],"numberCells":[{"number":"1","isBolded":false,"associatedRows":["classifier","1024 ?","K ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":["Average Pooling"]},{"number":"1?","isBolded":false,"associatedRows":["avg pool","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":["Hadamard product"]},{"number":"3?","isBolded":false,"associatedRows":["att conv2 M","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"3?3,1024,stride","isBolded":false,"associatedRows":["att conv2 M","1024 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":["attention","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":["att conv M","512 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["avg pool","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":["Hadamard product"]},{"number":"5?","isBolded":false,"associatedRows":["att conv I","512 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":["att conv I","512 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":["att conv2 I","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["att conv2 M","1024 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":["attention","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["att conv M","512 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["att conv I","512 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"5?","isBolded":false,"associatedRows":["att conv M","512 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"3?3,512,stride","isBolded":false,"associatedRows":["att conv I","512 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["att conv2 I","1024 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":["att conv2 I","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":["att conv2 M","1024 ?"],"associatedColumns":["Output Size"],"associatedMergedColumns":[]},{"number":"3?3,512,stride","isBolded":false,"associatedRows":["att conv M","512 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]},{"number":"3?3,1024,stride","isBolded":false,"associatedRows":["att conv2 I","1024 ?"],"associatedColumns":["Blocks"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Ablation results for different architectures for the Semantic Branch. \n\n","rows":["Scratch","3 Convolutional Layers","12 M","ResNet - 18","ImageNet","4 Convolutional Layers"],"columns":["Pretraining","Parameters","Top@2","Top@1","Number of","Top@5","MCA"],"mergedAllColumns":[],"numberCells":[{"number":"12.94","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"49.80","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"60.45","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"49.90","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"60.55","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"2.5M","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch"],"associatedColumns":["Number of","Pretraining","Parameters"],"associatedMergedColumns":[]},{"number":"73.53","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"50.60","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"72.10","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"60.21","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"11.37","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"15.54","isBolded":true,"associatedRows":["ResNet - 18","ImageNet","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"60.50","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"50.35","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"71.87","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"11.67","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"13.53","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"49.58","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"12.17","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]},{"number":"52.17","isBolded":true,"associatedRows":["ResNet - 18","ImageNet","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"6.5M","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"71.70","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"6.4M","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch"],"associatedColumns":["Number of","Pretraining","Parameters"],"associatedMergedColumns":[]},{"number":"72.53","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"2.6M","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"60.95","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"71.75","isBolded":true,"associatedRows":["ResNet - 18","ImageNet","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"61.86","isBolded":true,"associatedRows":["ResNet - 18","ImageNet","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"60.90","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@2","Parameters"],"associatedMergedColumns":[]},{"number":"50.00","isBolded":false,"associatedRows":["3 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@1","Parameters"],"associatedMergedColumns":[]},{"number":"72.55","isBolded":false,"associatedRows":["4 Convolutional Layers","Scratch","12 M"],"associatedColumns":["Number of","Top@5","Parameters"],"associatedMergedColumns":[]},{"number":"11.55","isBolded":false,"associatedRows":["ResNet - 18","Scratch","12 M"],"associatedColumns":["Number of","MCA","Parameters"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Ablation results for different attention mechanisms. \n\n","rows":["RGB Baseline","Concatenation","Gated RGB Hadamard Combination ( G - RGB - H )","Hadamard Combination","Additive Combination","Gated Sem Hadamard Combination"],"columns":["Top@2","Top@1","Top@5","MCA"],"mergedAllColumns":[],"numberCells":[{"number":"82.75","isBolded":true,"associatedRows":["Gated RGB Hadamard Combination ( G - RGB - H )"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"81.60","isBolded":false,"associatedRows":["Concatenation"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"66.30","isBolded":false,"associatedRows":["Gated Sem Hadamard Combination"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"56.55","isBolded":false,"associatedRows":["Gated Sem Hadamard Combination"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"25.36","isBolded":false,"associatedRows":["Additive Combination"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"27.00","isBolded":true,"associatedRows":["Gated RGB Hadamard Combination ( G - RGB - H )"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"80.60","isBolded":false,"associatedRows":["Additive Combination"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"25.38","isBolded":false,"associatedRows":["Concatenation"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"26.38","isBolded":false,"associatedRows":["Hadamard Combination"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"72.25","isBolded":false,"associatedRows":["Concatenation"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"62.55","isBolded":true,"associatedRows":["Gated RGB Hadamard Combination ( G - RGB - H )"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"81.30","isBolded":false,"associatedRows":["Hadamard Combination"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"56.90","isBolded":false,"associatedRows":["RGB Baseline"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"75.45","isBolded":false,"associatedRows":["Gated Sem Hadamard Combination"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"78.00","isBolded":false,"associatedRows":["RGB Baseline"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"59.60","isBolded":false,"associatedRows":["Additive Combination"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"70.60","isBolded":false,"associatedRows":["Additive Combination"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"61.85","isBolded":false,"associatedRows":["Concatenation"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"20.11","isBolded":false,"associatedRows":["Gated Sem Hadamard Combination"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"67.25","isBolded":false,"associatedRows":["RGB Baseline"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"20.80","isBolded":false,"associatedRows":["RGB Baseline"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"71.95","isBolded":false,"associatedRows":["Hadamard Combination"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"73.25","isBolded":true,"associatedRows":["Gated RGB Hadamard Combination ( G - RGB - H )"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"62.25","isBolded":false,"associatedRows":["Hadamard Combination"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Ablation results for different G-RGB-H architectures. \n\n","rows":["No Conv Layers"],"columns":["Conv Layers","Top@2","Top@1","Top@5","MCA","Kernel Size"],"mergedAllColumns":[],"numberCells":[{"number":"3?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"27.00","isBolded":true,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"3?512","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"24.90","isBolded":false,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"80.22","isBolded":false,"associatedRows":["No Conv Layers"],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"24.92","isBolded":false,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"70.55","isBolded":false,"associatedRows":["No Conv Layers"],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"73.25","isBolded":true,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"62.55","isBolded":true,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"81.750","isBolded":false,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"72.30","isBolded":false,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"3?512","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"71.150","isBolded":false,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"1?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"3?1024","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["Conv Layers"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"24.20","isBolded":false,"associatedRows":["No Conv Layers"],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["Conv Layers"],"associatedMergedColumns":[]},{"number":"60.84","isBolded":false,"associatedRows":["No Conv Layers"],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"81.95","isBolded":false,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"61.00","isBolded":false,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"3?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"61.20","isBolded":false,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"1?512","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"3?1024","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"1?1024","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"82.75","isBolded":true,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"1?","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":[],"associatedColumns":["Conv Layers"],"associatedMergedColumns":[]},{"number":"3?1024","isBolded":false,"associatedRows":[],"associatedColumns":["Kernel Size"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Scene recognition results on ADE20K. \n\n","rows":[],"columns":["Top@2","Top@1","Top@5","MCA"],"mergedAllColumns":[],"numberCells":[{"number":"50.60","isBolded":false,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"62.55","isBolded":true,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"82.75","isBolded":true,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"20.80","isBolded":false,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"60.45","isBolded":false,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"12.17","isBolded":false,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"67.25","isBolded":false,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"78.00","isBolded":false,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]},{"number":"56.90","isBolded":false,"associatedRows":[],"associatedColumns":["Top@1"],"associatedMergedColumns":[]},{"number":"73.25","isBolded":true,"associatedRows":[],"associatedColumns":["Top@2"],"associatedMergedColumns":[]},{"number":"27.00","isBolded":true,"associatedRows":[],"associatedColumns":["MCA"],"associatedMergedColumns":[]},{"number":"72.10","isBolded":false,"associatedRows":[],"associatedColumns":["Top@5"],"associatedMergedColumns":[]}]},{"caption":"Table 7: State-of-the-art results on SUN 397 dataset. All stated results with no reference have been extracted from [11]. \n\n","rows":["AlexNet @ [ 1 ]","ResNet - 50","Ours","? 143 M","? 62 M","-","ResNet - 18","GoogLeNet @ [ 1 ]","? 12 M","VGG - 19 @ [ 1 ]","? 25 M","Semantic Branch","ResNet - 50 @ [ 1 ]","? 47 M","AlexNet","DenseNet - 161","? 29 M","? 7 M","?"],"columns":["Top@2","Top@1","Top@5","MCA","Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * ."],"mergedAllColumns":["Parameters","-"],"numberCells":[{"number":"71.48","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"56.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"47.45","isBolded":false,"associatedRows":["AlexNet","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["Parameters"]},{"number":"86.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"53.63","isBolded":false,"associatedRows":["GoogLeNet @ [ 1 ]","? 7 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"56.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"55.47","isBolded":false,"associatedRows":["ResNet - 50","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"53.17","isBolded":false,"associatedRows":["AlexNet @ [ 1 ]","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["Parameters"]},{"number":"36.20","isBolded":false,"associatedRows":["Semantic Branch","?","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"54.40","isBolded":false,"associatedRows":["ResNet - 18","? 12 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"86.00","isBolded":true,"associatedRows":["Ours","? 47 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"83.88","isBolded":false,"associatedRows":["GoogLeNet @ [ 1 ]","? 7 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"62.33","isBolded":false,"associatedRows":["AlexNet","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["Parameters"]},{"number":"70.40","isBolded":false,"associatedRows":["ResNet - 50","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"36.20","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"49.15","isBolded":false,"associatedRows":["AlexNet","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["Parameters"]},{"number":"78.39","isBolded":false,"associatedRows":["AlexNet","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["Parameters"]},{"number":"85.08","isBolded":false,"associatedRows":["ResNet - 50 @ [ 1 ]","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"71.57","isBolded":true,"associatedRows":["Ours","? 47 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"54.74","isBolded":false,"associatedRows":["ResNet - 50 @ [ 1 ]","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"50.11","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"55.24","isBolded":false,"associatedRows":["VGG - 19 @ [ 1 ]","? 143 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"2.6M","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"68.48","isBolded":false,"associatedRows":["Semantic Branch","?","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"82.89","isBolded":false,"associatedRows":["AlexNet @ [ 1 ]","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["Parameters"]},{"number":"56.51","isBolded":true,"associatedRows":["Ours","? 47 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"85.36","isBolded":false,"associatedRows":["ResNet - 50","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"56.51","isBolded":true,"associatedRows":["Ours","? 47 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"68.87","isBolded":false,"associatedRows":["ResNet - 18","? 12 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"53.05","isBolded":false,"associatedRows":["ResNet - 18","? 12 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"83.86","isBolded":false,"associatedRows":["ResNet - 18","? 12 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"55.47","isBolded":false,"associatedRows":["ResNet - 50","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"84.91","isBolded":false,"associatedRows":["VGG - 19 @ [ 1 ]","? 143 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]}]},{"caption":"Table 8: State-of-the-art results on Places-365 Dataset (%). (@[1] stands for performance metrics reported in [1]). \n\n","rows":["AlexNet @ [ 1 ]","ResNet - 50","Ours","? 143 M","? 62 M","-","ResNet - 18","GoogLeNet @ [ 1 ]","? 12 M","VGG - 19 @ [ 1 ]","? 25 M","Semantic Branch","ResNet - 50 @ [ 1 ]","? 47 M","AlexNet","DenseNet - 161","? 29 M","? 7 M","?"],"columns":["Top@2","Top@1","Top@5","MCA","Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * ."],"mergedAllColumns":["Parameters","-"],"numberCells":[{"number":"83.86","isBolded":false,"associatedRows":["ResNet - 18","? 12 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"56.51","isBolded":true,"associatedRows":["Ours","? 47 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"68.48","isBolded":false,"associatedRows":["Semantic Branch","?","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"2.6M","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"70.40","isBolded":false,"associatedRows":["ResNet - 50","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"49.15","isBolded":false,"associatedRows":["AlexNet","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["Parameters"]},{"number":"62.33","isBolded":false,"associatedRows":["AlexNet","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["Parameters"]},{"number":"71.57","isBolded":true,"associatedRows":["Ours","? 47 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"54.40","isBolded":false,"associatedRows":["ResNet - 18","? 12 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"53.17","isBolded":false,"associatedRows":["AlexNet @ [ 1 ]","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["Parameters"]},{"number":"55.24","isBolded":false,"associatedRows":["VGG - 19 @ [ 1 ]","? 143 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"82.89","isBolded":false,"associatedRows":["AlexNet @ [ 1 ]","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["Parameters"]},{"number":"47.45","isBolded":false,"associatedRows":["AlexNet","? 62 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["Parameters"]},{"number":"53.05","isBolded":false,"associatedRows":["ResNet - 18","? 12 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"50.11","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"55.47","isBolded":false,"associatedRows":["ResNet - 50","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"36.20","isBolded":false,"associatedRows":["Semantic Branch","?","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"68.87","isBolded":false,"associatedRows":["ResNet - 18","? 12 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"56.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","MCA"],"associatedMergedColumns":["-"]},{"number":"54.74","isBolded":false,"associatedRows":["ResNet - 50 @ [ 1 ]","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"53.63","isBolded":false,"associatedRows":["GoogLeNet @ [ 1 ]","? 7 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"83.88","isBolded":false,"associatedRows":["GoogLeNet @ [ 1 ]","? 7 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"78.39","isBolded":false,"associatedRows":["AlexNet","? 62 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["Parameters"]},{"number":"85.08","isBolded":false,"associatedRows":["ResNet - 50 @ [ 1 ]","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"86.00","isBolded":true,"associatedRows":["Ours","? 47 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"71.48","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@2"],"associatedMergedColumns":["-"]},{"number":"86.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"56.12","isBolded":false,"associatedRows":["DenseNet - 161","? 29 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"56.51","isBolded":true,"associatedRows":["Ours","? 47 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"84.91","isBolded":false,"associatedRows":["VGG - 19 @ [ 1 ]","? 143 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"55.47","isBolded":false,"associatedRows":["ResNet - 50","? 25 M"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]},{"number":"85.36","isBolded":false,"associatedRows":["ResNet - 50","? 25 M","-"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@5"],"associatedMergedColumns":["-"]},{"number":"36.20","isBolded":false,"associatedRows":["Semantic Branch","?"],"associatedColumns":["Methods using objects to drive scene recognition include : [ 10 , 11 ] , Semantic Branch , Ours , Ours * and Ours * * .","Top@1"],"associatedMergedColumns":["-"]}]}]