[{"caption":"Table 1: Results on IWSLT\u002714 De-En. Our Lite Transformer outperforms the transformer (Vaswani  et al., 2017) and the Lightweight convolution network (Wu et al., 2019b) especially in mobile settings. \n\n","rows":["338M","Transformer ( Vaswani et al . , 2017 )","Lite Transformer ( Ours )","90M","360M","527M","-","87M"],"columns":["WMT \u0027 14 En - Fr","?BLEU","#Parameters","BLEU","WMT \u0027 14 En - De"],"mergedAllColumns":["-"],"numberCells":[{"number":"21.3","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","87M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":[]},{"number":"38.4","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"+1.2","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]},{"number":"11.7M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"+1.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"17.3M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"2.9M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"26.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"37.6","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","338M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"+1.2","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"+1.7","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"2.8M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":[]},{"number":"26.1","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","527M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"+0.4","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]},{"number":"39.1","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"25.6","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"22.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"+0.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]},{"number":"33.6","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","87M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":[]},{"number":"25.1","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","338M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"11.1M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"17.3M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"35.3","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"39.6","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]}]},{"caption":"Table 2: Results on WMT\u002714 En-De and WMT\u002714 En-Fr. Our Lite Transformer improves the BLEU \nscore over the transformer under similar Mult-Adds constraints. \n\n","rows":["338M","Transformer ( Vaswani et al . , 2017 )","Lite Transformer ( Ours )","90M","360M","527M","-","87M"],"columns":["WMT \u0027 14 En - Fr","?BLEU","#Parameters","BLEU","WMT \u0027 14 En - De"],"mergedAllColumns":["-"],"numberCells":[{"number":"11.1M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"17.3M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"+1.2","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"2.9M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"+1.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"26.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"+1.7","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","?BLEU"],"associatedMergedColumns":["-"]},{"number":"22.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"35.3","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"25.1","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","338M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"39.6","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"26.1","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","527M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"+1.2","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","90M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]},{"number":"38.4","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","527M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"33.6","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","87M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":[]},{"number":"+0.5","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]},{"number":"2.8M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":[]},{"number":"11.7M","isBolded":false,"associatedRows":["Lite Transformer ( Ours )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"17.3M","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )"],"associatedColumns":["WMT \u0027 14 En - De","#Parameters"],"associatedMergedColumns":["-"]},{"number":"39.1","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"21.3","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","87M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":[]},{"number":"37.6","isBolded":false,"associatedRows":["Transformer ( Vaswani et al . , 2017 )","338M","-"],"associatedColumns":["WMT \u0027 14 En - Fr","BLEU"],"associatedMergedColumns":["-"]},{"number":"25.6","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","360M"],"associatedColumns":["WMT \u0027 14 En - De","BLEU"],"associatedMergedColumns":["-"]},{"number":"+0.4","isBolded":true,"associatedRows":["Lite Transformer ( Ours )","527M"],"associatedColumns":["WMT \u0027 14 En - De","?BLEU"],"associatedMergedColumns":["-"]}]},{"caption":"Table 4: Results on CNN-DailyMail dataset for abstractive summarization. Our Lite Transformer \nachieves similar F1-Rouge (R-1, R-2 and R-L) to the transformer (Vaswani et al., 2017) with more \nthan 2.4? less computation and 2.5? less model size. \"#MAdds (x)\" indicates the #Mult-Adds \nrequired by the model with the input length of x. \n\n","rows":["Further Compress Lite Transformer by","Transformer","Transformer can be combined with general compression techniques and achieves","Size","80","Lite Transformer","( MB )"],"columns":["#Params","35","#MAdds ( 30 )","R - 1","Transformer","( Ours )","#MAdds ( 100 )","R - 2","Lite Transformer","#MAdds ( 1000 )","160","+Pruning","0","1","Published as a conference paper at ICLR 2020","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","R - L","+Quant ( 8 bits )","43"],"mergedAllColumns":["176","compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 .","Model","Figure 5 : The model size and BLEU score on WMT En - Fr dataset with model compression . Our Lite"],"numberCells":[{"number":"39.9","isBolded":false,"associatedRows":["Transformer","( MB )","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160"],"associatedMergedColumns":["176"]},{"number":"17.3M","isBolded":true,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160","0","Transformer","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#Params"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"38.3","isBolded":false,"associatedRows":["Transformer can be combined with general compression techniques and achieves","Lite Transformer"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - L"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"18.8","isBolded":false,"associatedRows":["Transformer can be combined with general compression techniques and achieves","Lite Transformer"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - 2"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"3.6G","isBolded":false,"associatedRows":["Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 100 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"38.3","isBolded":false,"associatedRows":["Transformer can be combined with general compression techniques and achieves","Transformer"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - L"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"18.2x","isBolded":true,"associatedRows":["Lite Transformer","( MB )","Further Compress Lite Transformer by"],"associatedColumns":["Published as a conference paper at ICLR 2020"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["Lite Transformer","Size","Further Compress Lite Transformer by"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - 1"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"17.3","isBolded":false,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43"],"associatedMergedColumns":["Model"]},{"number":"41.4","isBolded":false,"associatedRows":["Transformer","Size","Further Compress Lite Transformer by"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - 1"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"12.5G","isBolded":true,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 1000 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"18.9","isBolded":false,"associatedRows":["Transformer can be combined with general compression techniques and achieves","Transformer"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1","R - 2"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"0.8G","isBolded":true,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160","0","Lite Transformer","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 30 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"69.2","isBolded":false,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160"],"associatedMergedColumns":["176"]},{"number":"44.1M","isBolded":false,"associatedRows":["Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160","0","Transformer","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#Params"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"29.9G","isBolded":false,"associatedRows":["Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 1000 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"18.2?modelsize","isBolded":false,"associatedRows":["Transformer can be combined with general compression techniques and achieves","Lite Transformer"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","+Pruning","1"],"associatedMergedColumns":["Figure 5 : The model size and BLEU score on WMT En - Fr dataset with model compression . Our Lite"]},{"number":"39.5","isBolded":false,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43"],"associatedMergedColumns":["176"]},{"number":"18.2?","isBolded":false,"associatedRows":["Lite Transformer","( MB )","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43"],"associatedMergedColumns":["176"]},{"number":"2.0G","isBolded":false,"associatedRows":["Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160","0","Lite Transformer","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 30 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"39.6","isBolded":false,"associatedRows":["Lite Transformer","( MB )","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","160"],"associatedMergedColumns":["176"]},{"number":"1.5G","isBolded":true,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43","35","+Quant ( 8 bits )","( Ours )","Lite Transformer with Long - Short Range Attention , ICLR \u0027 20","#MAdds ( 100 )"],"associatedMergedColumns":["compression . * \u0027 Quant \u0027 indicates \u0027 Quantization \u0027 ."]},{"number":"9.7","isBolded":false,"associatedRows":["Lite Transformer","Size","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43"],"associatedMergedColumns":["Model"]},{"number":"39.6","isBolded":false,"associatedRows":["Lite Transformer","( MB )","80"],"associatedColumns":["Published as a conference paper at ICLR 2020","43"],"associatedMergedColumns":["176"]}]},{"caption":"Table 5: Results on WIKITEXT-103 dataset for language modeling. We apply our Lite Transformer \narchitecture on transformer base model with adaptive inputs (Baevski \u0026 Auli, 2019) and achieve 1.8 \nlower test perplexity under similar resource constraint. \n\n","rows":["Adaptive Inputs","Lite Transformer"],"columns":["#Params","Test ppl .","#MAdds ( 100 )","Speed ( tokens / s )","#MAdds ( 1000 )","Valid ppl ."],"mergedAllColumns":[],"numberCells":[{"number":"37.2M","isBolded":false,"associatedRows":["Lite Transformer"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"7.6K","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["Speed ( tokens / s )"],"associatedMergedColumns":[]},{"number":"23.2","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["Valid ppl ."],"associatedMergedColumns":[]},{"number":"3.9G","isBolded":false,"associatedRows":["Lite Transformer"],"associatedColumns":["#MAdds ( 100 )"],"associatedMergedColumns":[]},{"number":"24.0","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["Test ppl ."],"associatedMergedColumns":[]},{"number":"10.2K","isBolded":false,"associatedRows":["Lite Transformer"],"associatedColumns":["Speed ( tokens / s )"],"associatedMergedColumns":[]},{"number":"37.8M","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"50.3G","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["#MAdds ( 1000 )"],"associatedMergedColumns":[]},{"number":"21.4","isBolded":true,"associatedRows":["Lite Transformer"],"associatedColumns":["Valid ppl ."],"associatedMergedColumns":[]},{"number":"22.2","isBolded":true,"associatedRows":["Lite Transformer"],"associatedColumns":["Test ppl ."],"associatedMergedColumns":[]},{"number":"48.7G","isBolded":false,"associatedRows":["Lite Transformer"],"associatedColumns":["#MAdds ( 1000 )"],"associatedMergedColumns":[]},{"number":"3.9G","isBolded":false,"associatedRows":["Adaptive Inputs"],"associatedColumns":["#MAdds ( 100 )"],"associatedMergedColumns":[]}]}]