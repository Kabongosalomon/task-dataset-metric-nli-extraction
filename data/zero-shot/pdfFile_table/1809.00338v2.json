[{"caption":"Table 1: Statistics for publicly available cross-age face datasets. \n\n","rows":["16 - 99","0 - 100","4 , 668","2 , 000","MORPH Album1 [ 34 ]","16 , 488","0 - 69","MORPH Album2 [ 34 ]","313 , 986","15 - 68","IMDB - WIKI [ 36 ]","1 , 690","CAF [ 45 ]","CACD [ 6 ]","78 , 207","515","163 , 446","20 , 569","FG - NET [ 1 ]","0 - 99","16 - 62","20 , 284","1 , 446 , 500","25 , 000","1 - 101","1 , 002","avg .","AgeDB [ 28 ]","CAFR","523 , 051","568","82","0 - 80"],"columns":["Average Age","# Images / Subject"],"mergedAllColumns":[],"numberCells":[{"number":"3.80","isBolded":false,"associatedRows":["MORPH Album2 [ 34 ]","78 , 207","20 , 569","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"32.69","isBolded":false,"associatedRows":["MORPH Album2 [ 34 ]","78 , 207","20 , 569","avg .","16 - 99"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"15.84","isBolded":false,"associatedRows":["FG - NET [ 1 ]","1 , 002","82","avg .","0 - 69"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"27.28","isBolded":false,"associatedRows":["MORPH Album1 [ 34 ]","1 , 690","515","avg .","15 - 68"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"67.26","isBolded":false,"associatedRows":["CAF [ 45 ]","313 , 986","4 , 668","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"38.00","isBolded":false,"associatedRows":["IMDB - WIKI [ 36 ]","523 , 051","20 , 284","avg .","0 - 100"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"25.79","isBolded":false,"associatedRows":["IMDB - WIKI [ 36 ]","523 , 051","20 , 284","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"38.03","isBolded":false,"associatedRows":["CACD [ 6 ]","163 , 446","2 , 000","avg .","16 - 62"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"29.03","isBolded":false,"associatedRows":["AgeDB [ 28 ]","16 , 488","568","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"29.00","isBolded":false,"associatedRows":["CAF [ 45 ]","313 , 986","4 , 668","avg .","0 - 80"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"57.86","isBolded":true,"associatedRows":["CAFR","1 , 446 , 500","25 , 000","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"81.72","isBolded":false,"associatedRows":["CACD [ 6 ]","163 , 446","2 , 000","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"12.22","isBolded":false,"associatedRows":["FG - NET [ 1 ]","1 , 002","82","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"3.28","isBolded":false,"associatedRows":["MORPH Album1 [ 34 ]","1 , 690","515","avg ."],"associatedColumns":["# Images / Subject"],"associatedMergedColumns":[]},{"number":"50.30","isBolded":false,"associatedRows":["AgeDB [ 28 ]","16 , 488","568","avg .","1 - 101"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]},{"number":"28.23","isBolded":true,"associatedRows":["CAFR","1 , 446 , 500","25 , 000","avg .","0 - 99"],"associatedColumns":["Average Age"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Face recognition performance comparison on CAFR. \n\n","rows":["adv","w / o L"],"columns":["w / o R","Light CNN","w / o C?","81 . 02?1 . 10","w / o Lae","The results are averaged over 10 testing splits .","w / o Lmc","Model","?","w / o Att .","w / o Lip"],"mergedAllColumns":["Training loss ablation of AIM"],"numberCells":[{"number":"1","isBolded":false,"associatedRows":["w / o L","adv"],"associatedColumns":["The results are averaged over 10 testing splits .","Model","Light CNN","w / o C?","w / o R","?","w / o Att .","w / o Lip"],"associatedMergedColumns":["Training loss ablation of AIM"]},{"number":"2","isBolded":false,"associatedRows":["w / o L","adv"],"associatedColumns":["The results are averaged over 10 testing splits .","Model","Light CNN","w / o C?","w / o R","?","w / o Att .","w / o Lip","81 . 02?1 . 10","w / o Lae","w / o Lmc"],"associatedMergedColumns":["Training loss ablation of AIM"]}]},{"caption":"Table 3: Rank-1 recognition rates (%) on MORPH Album2. \n\n","rows":[],"columns":["lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( a ) Best matched cases .","( b ) Best non - matched cases .","Figure 8 : Age - invariant face recognition example results on CAFR . Col ."],"mergedAllColumns":["face images retain the intrinsic details . Best viewed in color ."],"numberCells":[{"number":"0.99572","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.02957","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.00180","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.98026","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.30239","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( a ) Best matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.55862","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( b ) Best non - matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.54771","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( b ) Best non - matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.98697","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.27953","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( a ) Best matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.54937","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( b ) Best non - matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.30997","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) .","( a ) Best matched cases ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]},{"number":"0.03761","isBolded":false,"associatedRows":[],"associatedColumns":["Figure 8 : Age - invariant face recognition example results on CAFR . Col .","lenging factors ( e . g . , neutral , illumination , expression , and pose ) ."],"associatedMergedColumns":["face images retain the intrinsic details . Best viewed in color ."]}]},{"caption":"Table 4: Face recognition performance comparison on CACD-\n\nVS. \nMethod \nAcc (%) \nCAN [52]  92.30 \nVGGFace [30]  96.00 \nCenter Loss [49]  97.48 \nMFM-CNN [50]  97.95 \nLF-CNN [48]  98.50 \nMarginal Loss [11]  98.95 \nDeepVisage [16]  99.13 \nOE-CNN [45]  99.20 \nHuman, avg. [6]  85.70 \nHuman, voting [6]  94.20 \nAIM (Ours) \n99.38 \nAIM + CAFR (Ours) \n99.76 \n\n","rows":["Marginal Loss [ 11 ]","Center Loss [ 49 ]","Human , avg . [ 6 ]","AIM ( Ours )","DeepVisage [ 16 ]","OE - CNN [ 45 ]","MFM - CNN [ 50 ]","Human , voting [ 6 ]","AIM + CAFR ( Ours )","CAN [ 52 ]","VGGFace [ 30 ]","LF - CNN [ 48 ]"],"columns":["Face recognition performance comparison on CACD -","Acc ( % )"],"mergedAllColumns":["VS ."],"numberCells":[{"number":"96.00","isBolded":false,"associatedRows":["VGGFace [ 30 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"99.13","isBolded":false,"associatedRows":["DeepVisage [ 16 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"99.20","isBolded":false,"associatedRows":["OE - CNN [ 45 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"94.20","isBolded":false,"associatedRows":["Human , voting [ 6 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"97.95","isBolded":false,"associatedRows":["MFM - CNN [ 50 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"99.38","isBolded":true,"associatedRows":["AIM ( Ours )"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"97.48","isBolded":false,"associatedRows":["Center Loss [ 49 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"85.70","isBolded":false,"associatedRows":["Human , avg . [ 6 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"98.50","isBolded":false,"associatedRows":["LF - CNN [ 48 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"98.95","isBolded":false,"associatedRows":["Marginal Loss [ 11 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"92.30","isBolded":false,"associatedRows":["CAN [ 52 ]"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]},{"number":"99.76","isBolded":true,"associatedRows":["AIM + CAFR ( Ours )"],"associatedColumns":["Face recognition performance comparison on CACD -","Acc ( % )"],"associatedMergedColumns":["VS ."]}]},{"caption":"Table 6: Face recognition performance comparison on IJB-C. \n\n","rows":["AIM","GOTS [ 27 ]","FaceNet [ 37 ]","MN - vc [ 51 ]","VGGFace2 ft [ 4 ]","VGGFace [ 30 ]"],"columns":["TAR@FAR\u003d10","TAR@FAR\u003d10 ? 4","TAR@FAR\u003d10 ? 5"],"mergedAllColumns":[],"numberCells":[{"number":"0.862","isBolded":false,"associatedRows":["VGGFace2 ft [ 4 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.895","isBolded":true,"associatedRows":["AIM"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.927","isBolded":false,"associatedRows":["MN - vc [ 51 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.935","isBolded":true,"associatedRows":["AIM"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.771","isBolded":false,"associatedRows":["MN - vc [ 51 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.862","isBolded":false,"associatedRows":["MN - vc [ 51 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.620","isBolded":false,"associatedRows":["GOTS [ 27 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.871","isBolded":false,"associatedRows":["VGGFace [ 30 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.066","isBolded":false,"associatedRows":["GOTS [ 27 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.598","isBolded":false,"associatedRows":["VGGFace [ 30 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.147","isBolded":false,"associatedRows":["GOTS [ 27 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.927","isBolded":false,"associatedRows":["VGGFace2 ft [ 4 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.330","isBolded":false,"associatedRows":["GOTS [ 27 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.817","isBolded":false,"associatedRows":["FaceNet [ 37 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.437","isBolded":false,"associatedRows":["VGGFace [ 30 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.967","isBolded":false,"associatedRows":["VGGFace2 ft [ 4 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.330","isBolded":false,"associatedRows":["FaceNet [ 37 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.968","isBolded":false,"associatedRows":["MN - vc [ 51 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.768","isBolded":false,"associatedRows":["VGGFace2 ft [ 4 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.487","isBolded":false,"associatedRows":["FaceNet [ 37 ]"],"associatedColumns":["TAR@FAR\u003d10 ? 4"],"associatedMergedColumns":[]},{"number":"0.748","isBolded":false,"associatedRows":["VGGFace [ 30 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.962","isBolded":true,"associatedRows":["AIM"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]},{"number":"0.826","isBolded":true,"associatedRows":["AIM"],"associatedColumns":["TAR@FAR\u003d10 ? 5"],"associatedMergedColumns":[]},{"number":"0.665","isBolded":false,"associatedRows":["FaceNet [ 37 ]"],"associatedColumns":["TAR@FAR\u003d10"],"associatedMergedColumns":[]}]}]