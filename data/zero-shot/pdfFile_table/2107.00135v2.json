[{"caption":"Model \n\nTraining Set A only V only AV Fusion \n\nGBlend [63] \nMiniAS \n29.1 \n22.1 \n37.8 \nGBlend [63] \nFullAS-2M \n32.4 \n18.8 \n41.8 \nAttn Audio-Visual [21] FullAS-2M \n38.4 \n25.7 \n46.2 \nPerceiver [32] \nFullAS-2M \n38.4 \n25.8 \n44.2 \nMBT \nMiniAS \n31.3 \n27.7 \n43.9 \nMBT \nAS-500K \n44.3 \n32.3 \n52.1 \n\nTable 1: Comparison to SOTA on AudioSet [24]. We report mean average precision (mAP). We \noutperform works that train on the full Audioset (2M samples), while we train on only 500K samples. \n\n","rows":["Attn Audio - Visual [ 21 ]","SlowFast [ 22 ]","A , V","A","TBN [ 36 ]","V , F","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F","FullAS - 2M","Damen et al . [ 14 ]","Perceiver [ 32 ]","V","GBlend [ 63 ]","AS - 500K","TRN [ 68 ]","TSM [ 45 ]","MBT","TSN [ 62 ]"],"columns":["V only","Action","Verb","A only","AV Fusion","Noun"],"mergedAllColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."],"numberCells":[{"number":"46.5","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A , V , F","A"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"15.4","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A , V , F","A"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"21.5","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A , V , F"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"60.2","isBolded":false,"associatedRows":["TSN [ 62 ]","A , V , F"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"46.0","isBolded":false,"associatedRows":["TSN [ 62 ]","A , V , F"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"44.2","isBolded":false,"associatedRows":["Perceiver [ 32 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"27.7","isBolded":false,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"32.3","isBolded":true,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","AS - 500K","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"44.3","isBolded":true,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","AS - 500K","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"47.2","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"66.0","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"50.0","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"22.1","isBolded":false,"associatedRows":["GBlend [ 63 ]","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"41.8","isBolded":false,"associatedRows":["GBlend [ 63 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"38.4","isBolded":false,"associatedRows":["Attn Audio - Visual [ 21 ]","Damen et al . [ 14 ]","FullAS - 2M","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"46.2","isBolded":false,"associatedRows":["Attn Audio - Visual [ 21 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"44.3","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"40.7","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"13.0","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"32.4","isBolded":false,"associatedRows":["GBlend [ 63 ]","Damen et al . [ 14 ]","FullAS - 2M","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"22.4","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"38.5","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"38.3","isBolded":false,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"38.4","isBolded":false,"associatedRows":["Perceiver [ 32 ]","Damen et al . [ 14 ]","FullAS - 2M","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"31.3","isBolded":false,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"36.7","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"62.0","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"25.7","isBolded":false,"associatedRows":["Attn Audio - Visual [ 21 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"29.1","isBolded":false,"associatedRows":["GBlend [ 63 ]","Damen et al . [ 14 ]","MiniAS","A , V , F"],"associatedColumns":["A only"],"associatedMergedColumns":[]},{"number":"45.4","isBolded":false,"associatedRows":["TRN [ 68 ]","A , V , F"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"35.3","isBolded":false,"associatedRows":["TRN [ 68 ]","A , V , F"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"65.9","isBolded":false,"associatedRows":["TRN [ 68 ]","A , V , F"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"58.0","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"25.8","isBolded":false,"associatedRows":["Perceiver [ 32 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["MBT","A , V"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"43.9","isBolded":false,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"52.1","isBolded":true,"associatedRows":["MBT","AudioSlowFast [ 37 ] ?","AS - 500K","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"14.8","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A , V , F"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"33.2","isBolded":false,"associatedRows":["TSN [ 62 ]","A , V , F"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"37.8","isBolded":false,"associatedRows":["GBlend [ 63 ]","AudioSlowFast [ 37 ] ?","MiniAS","A , V , F"],"associatedColumns":["AV Fusion"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["AV Fusion","Action"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"18.8","isBolded":false,"associatedRows":["GBlend [ 63 ]","AudioSlowFast [ 37 ] ?","FullAS - 2M","A , V , F"],"associatedColumns":["V only"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"22.78","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A , V , F","A"],"associatedColumns":["V only","Noun"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"67.9","isBolded":true,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"65.6","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]},{"number":"42.1","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A , V , F"],"associatedColumns":["A only","Verb"],"associatedMergedColumns":["outperform works that train on the full Audioset ( 2M samples ) , while we train on only 500K samples ."]}]},{"caption":"Table 2: Comparison to SOTA on EpicKitchens-100 [14]. Modalities are A: Audio, V: Visual, F: \nOptical flow.  ?Uses pretraining on VGGSound. \n\n","rows":["SlowFast [ 22 ]","A , V","A","TBN [ 36 ]","V , F","AudioSlowFast [ 37 ] ?","A , V , F","Damen et al . [ 14 ]","V","TRN [ 68 ]","TSM [ 45 ]","TSN [ 62 ]","MBT"],"columns":["Action","Verb","Noun"],"mergedAllColumns":[],"numberCells":[{"number":"65.9","isBolded":false,"associatedRows":["TRN [ 68 ]","V , F"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"46.5","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"22.4","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"60.2","isBolded":false,"associatedRows":["TSN [ 62 ]","V , F"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"62.0","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"42.1","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"15.4","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"47.2","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"33.2","isBolded":false,"associatedRows":["TSN [ 62 ]","V , F"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"67.9","isBolded":true,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"35.3","isBolded":false,"associatedRows":["TRN [ 68 ]","V , F"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"44.3","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"14.8","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"40.7","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"45.4","isBolded":false,"associatedRows":["TRN [ 68 ]","V , F"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"21.5","isBolded":false,"associatedRows":["Damen et al . [ 14 ]","A"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"22.78","isBolded":false,"associatedRows":["AudioSlowFast [ 37 ] ?","A"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"65.6","isBolded":false,"associatedRows":["SlowFast [ 22 ]","V"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"38.3","isBolded":false,"associatedRows":["TSM [ 45 ]","V , F"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"13.0","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["MBT","A , V"],"associatedColumns":["Verb"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"46.0","isBolded":false,"associatedRows":["TSN [ 62 ]","V , F"],"associatedColumns":["Noun"],"associatedMergedColumns":[]},{"number":"36.7","isBolded":false,"associatedRows":["TBN [ 36 ]","A , V , F"],"associatedColumns":["Action"],"associatedMergedColumns":[]}]},{"caption":"provides slight performance gains for traditionally video only datasets such as Kinetics and Moments \nin Time (details provided in Appendix C ). We also examine per-class performance on the Audioset \ndataset (Figures 9 and 10 in the Appendix), and find that for the top 60 classes (ranked by overall \nperformance), audio-visual fusion improves performance over audio only or visual only for almost \nall (57 out of 60) classes, except for \u0027bagpiping\u0027, \u0027emergency vehicle\u0027 and \u0027didgeridoo\u0027 which have \nstrong audio signatures. For classes such as \u0027bicycle\u0027 and \u0027shuffling cards\u0027 where audio signals are \nweaker, fusion improves over the audio-only baseline by over 60% in absolute AP. \nComparison to state of the art: We compare MBT to previous fusion methods on AudioSet in \nTable 1. We outperform all previous works on fusion (even though we only train on a quarter of the \ntraining set -500K samples), including the recently introduced Perceiver [32] which uses early fusion \nfollowed by multiple self attention layers, and Attn Audio-Visual [21] which uses self-attention \nfusion on top of individual modality CNNs. We compare to previous video classification methods on \nEpic-Kitchens in Table 2, and note that our model outperforms all previous works that use vision only, \nas well as TBN [36] which uses three modalities -RGB, audio and optical flow. Given VGGSound is \n\nModel \nModalities Top-1 Acc Top-5 Acc \n\nChen et al ? [12] \nA \n48.8 \n76.5 \nAudioSlowFast ? [37] A \n50.1 \n77.9 \nMBT \nA \n52.3 \n78.1 \nMBT \nV \n51.2 \n72.6 \nMBT \nA,V \n64.1 \n85.6 \n\n","rows":["AudioSlowFast ? [ 37 ]","A , V","A","Chen et al ? [ 12 ]","V","MBT"],"columns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc","Top - 5 Acc"],"mergedAllColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"],"numberCells":[{"number":"52.3","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"76.5","isBolded":false,"associatedRows":["Chen et al ? [ 12 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"51.2","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"64.1","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"77.9","isBolded":false,"associatedRows":["AudioSlowFast ? [ 37 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"48.8","isBolded":false,"associatedRows":["Chen et al ? [ 12 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"72.6","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"78.1","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"85.6","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"50.1","isBolded":false,"associatedRows":["AudioSlowFast ? [ 37 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]}]},{"caption":"Table 3: Comparison to the state of the art on VGGSound [12]. Modalities are A: Audio, V: \nVisual, F: Optical flow.  ? We calculate metrics on our test set for a fair comparison using the scores \nprovided by the authors. \n","rows":["AudioSlowFast ? [ 37 ]","A , V","A","Chen et al ? [ 12 ]","V","MBT"],"columns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc","Top - 5 Acc"],"mergedAllColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"],"numberCells":[{"number":"51.2","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"77.9","isBolded":false,"associatedRows":["AudioSlowFast ? [ 37 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"85.6","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"76.5","isBolded":false,"associatedRows":["Chen et al ? [ 12 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"72.6","isBolded":false,"associatedRows":["MBT","V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"50.1","isBolded":false,"associatedRows":["AudioSlowFast ? [ 37 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"78.1","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 5 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"64.1","isBolded":true,"associatedRows":["MBT","A , V"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"48.8","isBolded":false,"associatedRows":["Chen et al ? [ 12 ]","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]},{"number":"52.3","isBolded":false,"associatedRows":["MBT","A"],"associatedColumns":["provides slight performance gains for traditionally video only datasets such as Kinetics and Moments","Top - 1 Acc"],"associatedMergedColumns":["as well as TBN [ 36 ] which uses three modalities - RGB , audio and optical flow . Given VGGSound is"]}]},{"caption":"Table 4. We find \nperformance is robust to all variations. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 4: Asymmetric vs symmetric bottleneck updates. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 5: Performance with varying backbones on AS-mini and VGGSound. \n\n","rows":["ViT - Small","ViT - Large","ViT - Base"],"columns":["AS - mini","VGGSound"],"mergedAllColumns":[],"numberCells":[{"number":"59.0","isBolded":false,"associatedRows":["ViT - Small"],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]},{"number":"38.2","isBolded":false,"associatedRows":["ViT - Small"],"associatedColumns":["AS - mini"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["ViT - Base"],"associatedColumns":["AS - mini"],"associatedMergedColumns":[]},{"number":"42.2","isBolded":false,"associatedRows":["ViT - Large"],"associatedColumns":["AS - mini"],"associatedMergedColumns":[]},{"number":"61.4","isBolded":false,"associatedRows":["ViT - Large"],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]},{"number":"64.1","isBolded":false,"associatedRows":["ViT - Base"],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]}]},{"caption":"Table 6: The effect of varying input clip span t on performance. \n","rows":["experiment and report mean and standard deviation . All segments in AudioSet are"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"10secondslong.","isBolded":false,"associatedRows":["experiment and report mean and standard deviation . All segments in AudioSet are"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 8. We \nnote that on the entire Kinetics test set, our fusion model outperforms the visual only baseline by \nabout 1% in top 1 accuracy (in line with other works ","rows":["0","2","4","6","8","mAP"],"columns":["shared encoders","synchronous","separate encoders"],"mergedAllColumns":[],"numberCells":[{"number":"40","isBolded":false,"associatedRows":["mAP","mAP"],"associatedColumns":["synchronous"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":["0","2","4","6","8"],"associatedColumns":["shared encoders"],"associatedMergedColumns":[]},{"number":"38","isBolded":false,"associatedRows":[],"associatedColumns":["synchronous"],"associatedMergedColumns":[]},{"number":"39","isBolded":false,"associatedRows":[],"associatedColumns":["synchronous"],"associatedMergedColumns":[]},{"number":"39","isBolded":false,"associatedRows":[],"associatedColumns":["separate encoders"],"associatedMergedColumns":[]},{"number":"41","isBolded":false,"associatedRows":[],"associatedColumns":["synchronous"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":["mAP"],"associatedColumns":["separate encoders"],"associatedMergedColumns":[]},{"number":"38","isBolded":false,"associatedRows":[],"associatedColumns":["separate encoders"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["0","2","4","6","8"],"associatedColumns":["shared encoders"],"associatedMergedColumns":[]},{"number":"41","isBolded":false,"associatedRows":[],"associatedColumns":["separate encoders"],"associatedMergedColumns":[]},{"number":"42","isBolded":false,"associatedRows":[],"associatedColumns":["synchronous"],"associatedMergedColumns":[]},{"number":"42","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 7: Comparison to state of the art on Moments in Time [47]. We report top 1 and top 5 \nclassification accuracy. AV: Refers to audio-visual fusion. \n\n","rows":["AssembleNet - 101 [ 54 ]","Ours ( Audio - only )","3 - stream SATT [ 9 ]","I3D [ 10 ]","Ours ( Visual - only )","AVSlowFast , R101 [ 64 ]","SlowFast R101 - NL [ 22 ]","blVNet [ 20 ]","MBT ( AV )","TS S3D - G [ 65 ]","ViViT - Base [ 6 ]","LGD - 3D R101 [ 52 ]"],"columns":["Kinetics - Sounds","Top - 5","Top - 1 acc","Kinetics","Top - 1","-","Top - 5 acc"],"mergedAllColumns":["-"],"numberCells":[{"number":"18.2","isBolded":false,"associatedRows":["blVNet [ 20 ]","Ours ( Audio - only )"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"79.8","isBolded":false,"associatedRows":["SlowFast R101 - NL [ 22 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"73.5","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1"],"associatedMergedColumns":[]},{"number":"94.4","isBolded":false,"associatedRows":["LGD - 3D R101 [ 52 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"37.3","isBolded":true,"associatedRows":["blVNet [ 20 ]","MBT ( AV )"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"85.0?","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 1","-","-","-","-","-"],"associatedMergedColumns":[]},{"number":"93.9","isBolded":false,"associatedRows":["SlowFast R101 - NL [ 22 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"71.5","isBolded":false,"associatedRows":["Ours ( Audio - only )"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"62.7","isBolded":false,"associatedRows":["blVNet [ 20 ]","AssembleNet - 101 [ 54 ]"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"25.0","isBolded":false,"associatedRows":["Ours ( Audio - only )"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"37.3","isBolded":false,"associatedRows":["blVNet [ 20 ]","ViViT - Base [ 6 ]"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"8.2","isBolded":false,"associatedRows":["blVNet [ 20 ]","Ours ( Audio - only )"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"34.3","isBolded":false,"associatedRows":["blVNet [ 20 ]","AssembleNet - 101 [ 54 ]"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"80.7","isBolded":false,"associatedRows":["Ours ( Visual - only )"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"76.1","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-"],"associatedMergedColumns":[]},{"number":"93.0","isBolded":false,"associatedRows":["TS S3D - G [ 65 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-"],"associatedMergedColumns":[]},{"number":"77.7","isBolded":false,"associatedRows":["3 - stream SATT [ 9 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-"],"associatedMergedColumns":[]},{"number":"94.0","isBolded":false,"associatedRows":["ViViT - Base [ 6 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"52.6","isBolded":false,"associatedRows":["Ours ( Audio - only )"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"79.4","isBolded":false,"associatedRows":["Ours ( Visual - only )"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"85.0","isBolded":true,"associatedRows":["SlowFast R101 - NL [ 22 ]"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"59.3","isBolded":false,"associatedRows":["blVNet [ 20 ]","blVNet [ 20 ]"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"78.8","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-"],"associatedMergedColumns":[]},{"number":"43.9","isBolded":false,"associatedRows":["Ours ( Audio - only )"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"77.2","isBolded":false,"associatedRows":["TS S3D - G [ 65 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-"],"associatedMergedColumns":[]},{"number":"96.8","isBolded":true,"associatedRows":["SlowFast R101 - NL [ 22 ]"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"91.2","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5"],"associatedMergedColumns":[]},{"number":"94.6","isBolded":true,"associatedRows":["SlowFast R101 - NL [ 22 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"56.1","isBolded":false,"associatedRows":["blVNet [ 20 ]","I3D [ 10 ]"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"36.3","isBolded":false,"associatedRows":["blVNet [ 20 ]","Ours ( Visual - only )"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"93.2","isBolded":false,"associatedRows":["3 - stream SATT [ 9 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-"],"associatedMergedColumns":[]},{"number":"59.3","isBolded":false,"associatedRows":["blVNet [ 20 ]","Ours ( Visual - only )"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"79.4","isBolded":false,"associatedRows":["LGD - 3D R101 [ 52 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"93.6","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":true,"associatedRows":["Ours ( Visual - only )"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"31.4","isBolded":false,"associatedRows":["blVNet [ 20 ]","blVNet [ 20 ]"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"61.2","isBolded":false,"associatedRows":["blVNet [ 20 ]","MBT ( AV )"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["ViViT - Base [ 6 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 1","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"29.5","isBolded":false,"associatedRows":["blVNet [ 20 ]","I3D [ 10 ]"],"associatedColumns":["Top - 1 acc"],"associatedMergedColumns":[]},{"number":"91.6","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":true,"associatedRows":["blVNet [ 20 ]","ViViT - Base [ 6 ]"],"associatedColumns":["Top - 5 acc"],"associatedMergedColumns":[]},{"number":"94.0","isBolded":false,"associatedRows":["Ours ( Visual - only )"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]},{"number":"92.5","isBolded":false,"associatedRows":["AVSlowFast , R101 [ 64 ]"],"associatedColumns":["Top - 1 acc","Kinetics","Top - 5","-","-"],"associatedMergedColumns":[]},{"number":"94.9","isBolded":false,"associatedRows":["Ours ( Visual - only )"],"associatedColumns":["Top - 5 acc","Kinetics - Sounds","Top - 5","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["-"]}]},{"caption":"Table 9: MBT vs late Fusion for different datasets. For each dataset we report the widely used primary \nmetric, i.e. Audioset: mAP, Epic-Kitchens: Top-1 action accuracy, VGGSound, Moments in Time \nand Kinetics: Top-1 classification accuracy. \n\n","rows":["Late Fusion","MBT"],"columns":["VGGSound","mini - Audioset","Epic - Kitchens","Kinetics","Moments in Time"],"mergedAllColumns":[],"numberCells":[{"number":"64.1","isBolded":false,"associatedRows":["MBT"],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":false,"associatedRows":["MBT"],"associatedColumns":["Kinetics"],"associatedMergedColumns":[]},{"number":"41.80","isBolded":false,"associatedRows":["Late Fusion"],"associatedColumns":["mini - Audioset"],"associatedMergedColumns":[]},{"number":"63.3","isBolded":false,"associatedRows":["Late Fusion"],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]},{"number":"36.48","isBolded":false,"associatedRows":["Late Fusion"],"associatedColumns":["Moments in Time"],"associatedMergedColumns":[]},{"number":"37.90","isBolded":false,"associatedRows":["Late Fusion"],"associatedColumns":["Epic - Kitchens"],"associatedMergedColumns":[]},{"number":"37.26","isBolded":false,"associatedRows":["MBT"],"associatedColumns":["Moments in Time"],"associatedMergedColumns":[]},{"number":"43.92","isBolded":false,"associatedRows":["MBT"],"associatedColumns":["mini - Audioset"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["Late Fusion"],"associatedColumns":["Kinetics"],"associatedMergedColumns":[]},{"number":"43.40","isBolded":false,"associatedRows":["MBT"],"associatedColumns":["Epic - Kitchens"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Transfer learning on Audioset-mini and VGGSound. \n\n","rows":["N / A","VGGSound init .","AS - 500K init .","K400 init .","ImageNet init ."],"columns":["AS - mini","VGGSound"],"mergedAllColumns":["N / A"],"numberCells":[{"number":"44.0","isBolded":false,"associatedRows":["K400 init ."],"associatedColumns":["AS - mini"],"associatedMergedColumns":["N / A"]},{"number":"64.1","isBolded":false,"associatedRows":["ImageNet init ."],"associatedColumns":["VGGSound"],"associatedMergedColumns":[]},{"number":"46.6","isBolded":false,"associatedRows":["VGGSound init ."],"associatedColumns":["AS - mini"],"associatedMergedColumns":[]},{"number":"65.3","isBolded":false,"associatedRows":["AS - 500K init .","N / A"],"associatedColumns":["VGGSound"],"associatedMergedColumns":["N / A"]},{"number":"64.0","isBolded":false,"associatedRows":["K400 init ."],"associatedColumns":["VGGSound"],"associatedMergedColumns":["N / A"]},{"number":"43.3","isBolded":false,"associatedRows":["ImageNet init ."],"associatedColumns":["AS - mini"],"associatedMergedColumns":[]}]}]