[{"caption":"Table 5: Sparse models are robust to dropped tokens when fine-tuning. We find the fine-tuning \nquality on SuperGLUE is not impacted significantly across the values explored. Interestingly, drop-\nping 10-15% of tokens can perform approximately as well as models that drop \u003c 1%. We also \nobserve that load balance losses (Aux Loss) improve fine-tuning. The dropped token percentage \ncorresponds to the fraction of dropped tokens across all expert layers at peak validation accuracy. \n","rows":["No","Yes","Sparse"],"columns":["Studies on ST - MoE - 32B","Train CF","Eval CF","Percent Tokens Dropped","SuperGLUE ( ? )"],"mergedAllColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."],"numberCells":[{"number":"85.8","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"4.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.9%","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.4%","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"1.25","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"3.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.21","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"86.4","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"4.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"5.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"86.5?","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.0%","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.0%","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"86.4","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"86.7","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"5.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.3%","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"85.9","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.0%","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"15.6%","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"10.6%","isBolded":false,"associatedRows":["Sparse","Yes"],"associatedColumns":["Studies on ST - MoE - 32B","Percent Tokens Dropped"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.75","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"85.7","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"1.25","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"85.8","isBolded":false,"associatedRows":["Sparse","No"],"associatedColumns":["Studies on ST - MoE - 32B","SuperGLUE ( ? )"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"0.75","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Train CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"3.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]},{"number":"2.0","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["Studies on ST - MoE - 32B","Eval CF"],"associatedMergedColumns":["of Yang et al . ( 2021 ) that unequal load balance may not significantly impact model quality ."]}]},{"caption":"Table 7: Impact of sentinel tokens for fine-tuning. The addition of sentinel tokens (a similar \nconcept used in ","rows":["Dense","Sparse"],"columns":["SuperGLUE ( ? )","GEC ( ? )"],"mergedAllColumns":[],"numberCells":[{"number":"0.33","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.9?","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"22.9?","isBolded":true,"associatedRows":["Sparse"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"22.3?","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"22.1?","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"86.6?","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"0.04","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"0.24","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.1?","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"0.42","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Dense"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"0.09","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]},{"number":"86.6?","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"0.18","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"22.2?","isBolded":false,"associatedRows":["Sparse"],"associatedColumns":["GEC ( ? )"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparing capacity factors (CF) and routing algorithms. Increasing both train and eval \nCF improves performance. Increasing or decreasing the eval CF gives an additional lever if you have \nmore or less compute at eval time. ","rows":["Dense - L","Dense - XL","Top - 2","Top - 3","-","Top - 1"],"columns":["Train CF","Neg . Log Perp . ( ? )","Eval CF"],"mergedAllColumns":[],"numberCells":[{"number":"1.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.360","isBolded":false,"associatedRows":["Top - 3","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 3"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.378","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.424","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.384","isBolded":false,"associatedRows":["Dense - XL","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.356","isBolded":false,"associatedRows":["Top - 3","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.369","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.392","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.428","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.360","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.359","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.378","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 3","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 3","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.373","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 3"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.375","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.404","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.397","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.402","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.384","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.474","isBolded":false,"associatedRows":["Dense - L","-","-"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Profiling sparse models on TPUs. Increasing the train capacity factor from 1.25 to 2.0 \nincreases the step-time by +7% for the large (1B) model but by +14% for our 32B model. As the \nmodel size increases, we find the small quality gains of higher train capacity factors from Table 8 \nare more than offset by the significant 14% slow-down. Note: the step time between ST-MoE-L and \nST-MoE-32B are not comparable because they used a different number of cores. \n\n","rows":["ST - MoE - 32B","ST - MoE - L"],"columns":["Train CF","Step Time ( s ) ( ? )"],"mergedAllColumns":[],"numberCells":[{"number":"2.447(+7%)","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Step Time ( s ) ( ? )"],"associatedMergedColumns":[]},{"number":"4.244","isBolded":false,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Step Time ( s ) ( ? )"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.397","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Step Time ( s ) ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"4.819(+14%)","isBolded":false,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Step Time ( s ) ( ? )"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Fine-tuning performance of FLOP-matched dense and sparse models. Comparison \nof the dense-L baseline and the sparse FLOP-matched version (higher numbers better). We observe \nconsistent gains across diverse tasks, using approximately the same amount of computation. The \nonly two tasks without improvement from the sparse model are the two smallest: CB with 250 \ntraining examples and WSC with 259. \n\n","rows":["acc","RTE","SuperGLUE","MultiRC","ARC - Challenge","ReCoRD","WiC","BoolQ","avg","Closed Book TriviaQA","dev","ARC - Easy","WinoGrande ( XL )","SQuADv2","Copa","CB","CNN - DM","WSC","ROUGE - 2","F1","100","ANLI ( R3 )","Closed Book NatQA","XSum","Closed Book WebQA"],"columns":["Dense - L ( ? )","ST - MoE - L ( ? )"],"mergedAllColumns":["+19%","+8%","+20%","+6%","+5%","? 2%","+4%","+13%","+3%","+2%","+1%","+10%"],"numberCells":[{"number":"50.2","isBolded":false,"associatedRows":["ARC - Challenge","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+19%"]},{"number":"27.2","isBolded":false,"associatedRows":["Closed Book NatQA","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+20%"]},{"number":"91.0","isBolded":false,"associatedRows":["RTE","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+10%"]},{"number":"87.4","isBolded":true,"associatedRows":["SuperGLUE","avg","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"94.0","isBolded":false,"associatedRows":["SQuADv2","F1","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":[]},{"number":"33.8","isBolded":true,"associatedRows":["Closed Book TriviaQA","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+13%"]},{"number":"81.7","isBolded":true,"associatedRows":["WinoGrande ( XL )","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+2%"]},{"number":"87.6","isBolded":false,"associatedRows":["SQuADv2","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"20.3","isBolded":false,"associatedRows":["CNN - DM","ROUGE - 2","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+10%"]},{"number":"83.0","isBolded":false,"associatedRows":["Copa","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+2%"]},{"number":"29.5","isBolded":true,"associatedRows":["Closed Book NatQA","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+20%"]},{"number":"74.0","isBolded":true,"associatedRows":["WiC","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"75.4","isBolded":true,"associatedRows":["ARC - Easy","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+6%"]},{"number":"28.1","isBolded":false,"associatedRows":["Closed Book TriviaQA","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+13%"]},{"number":"20.7","isBolded":true,"associatedRows":["CNN - DM","ROUGE - 2","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+10%"]},{"number":"83.9","isBolded":false,"associatedRows":["MultiRC","F1","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+5%"]},{"number":"86.0","isBolded":true,"associatedRows":["MultiRC","F1","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+5%"]},{"number":"98.2","isBolded":false,"associatedRows":["CB","acc","dev","100"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+4%"]},{"number":"21.8","isBolded":true,"associatedRows":["XSum","ROUGE - 2","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["? 2%"]},{"number":"70.4","isBolded":false,"associatedRows":["WiC","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"30.5","isBolded":false,"associatedRows":["Closed Book WebQA","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+8%"]},{"number":"93.3","isBolded":false,"associatedRows":["WSC","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+3%"]},{"number":"88.9","isBolded":true,"associatedRows":["ReCoRD","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["? 2%"]},{"number":"94.5","isBolded":true,"associatedRows":["SQuADv2","F1","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":[]},{"number":"54.3","isBolded":false,"associatedRows":["ANLI ( R3 )","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+8%"]},{"number":"63.5","isBolded":false,"associatedRows":["ARC - Easy","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+6%"]},{"number":"56.9","isBolded":true,"associatedRows":["ARC - Challenge","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+19%"]},{"number":"33.2","isBolded":true,"associatedRows":["Closed Book WebQA","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+8%"]},{"number":"88.6","isBolded":true,"associatedRows":["BoolQ","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+3%"]},{"number":"91.0","isBolded":true,"associatedRows":["Copa","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+2%"]},{"number":"88.1","isBolded":true,"associatedRows":["SQuADv2","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"95.2","isBolded":true,"associatedRows":["WSC","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+3%"]},{"number":"75.4","isBolded":false,"associatedRows":["WinoGrande ( XL )","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+2%"]},{"number":"87.1","isBolded":false,"associatedRows":["BoolQ","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+3%"]},{"number":"92.1","isBolded":true,"associatedRows":["RTE","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+10%"]},{"number":"85.7","isBolded":false,"associatedRows":["ReCoRD","acc","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["? 2%"]},{"number":"85.1","isBolded":false,"associatedRows":["SuperGLUE","avg","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["+1%"]},{"number":"19.9","isBolded":false,"associatedRows":["XSum","ROUGE - 2","dev"],"associatedColumns":["Dense - L ( ? )"],"associatedMergedColumns":["? 2%"]},{"number":"57.3","isBolded":true,"associatedRows":["ANLI ( R3 )","acc","dev"],"associatedColumns":["ST - MoE - L ( ? )"],"associatedMergedColumns":["+8%"]}]},{"caption":"Table 11: Model comparisons. A comparison of the Dense-L and T5-XXL, the two largest Switch \nTransformer variants (Switch-XXL and Switch-C), and the ST-MoE-L and ST-MoE-32B. d model \nrefers to the model hiddenstate size and d f f is the internal size of the FFN layer. d kv is the dimension \nof each attention head. Expert Layer Freq. is the fraction of FFN layers replaced with a sparse layer. \nSparse-Dense refers to the architectural variant described in Appendix C. \n\n","rows":["4096","2080","Switch - C","6144","10240","ST - MoE - 32B","Switch - XXL","T5 - XXL","890B","ST - MoE - L","395B","1571B","645B","Dense - L","1024","269B","2816"],"columns":["Num . Heads","5120","Parameters","d model","Num . Experts","2048","Num . Layers","d kv","FLOPs / seq","-"],"mergedAllColumns":["1 / 4"],"numberCells":[{"number":"64","isBolded":false,"associatedRows":["ST - MoE - 32B","269B","645B"],"associatedColumns":["d model","5120","Num . Experts","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"4.1B","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Parameters"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["Switch - XXL","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers","-","-"],"associatedMergedColumns":[]},{"number":"11.1B","isBolded":false,"associatedRows":["T5 - XXL"],"associatedColumns":["Parameters"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Switch - XXL"],"associatedColumns":["Parameters","5120","Num . Heads","-","-"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Switch - C"],"associatedColumns":["Parameters","5120","Num . Heads","-","-"],"associatedMergedColumns":["1 / 4"]},{"number":"15","isBolded":false,"associatedRows":["Switch - C","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers","-","-"],"associatedMergedColumns":["1 / 4"]},{"number":"32","isBolded":false,"associatedRows":["ST - MoE - L","269B","645B"],"associatedColumns":["d model","5120","Num . Experts","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"0.8B","isBolded":false,"associatedRows":["Dense - L"],"associatedColumns":["Parameters"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["T5 - XXL","1571B","645B","4096","10240"],"associatedColumns":["d kv"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["ST - MoE - L","1571B","645B","1024","2816"],"associatedColumns":["d kv"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Dense - L","1571B","645B","1024","2816"],"associatedColumns":["d kv"],"associatedMergedColumns":[]},{"number":"6.3T","isBolded":false,"associatedRows":["Switch - XXL","395B"],"associatedColumns":["FLOPs / seq"],"associatedMergedColumns":[]},{"number":"6.3T","isBolded":false,"associatedRows":["T5 - XXL","395B"],"associatedColumns":["FLOPs / seq"],"associatedMergedColumns":[]},{"number":"27","isBolded":false,"associatedRows":["Dense - L","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Parameters","5120","Num . Heads","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"64","isBolded":false,"associatedRows":["Switch - XXL","269B","645B"],"associatedColumns":["d model","5120","Num . Experts","-","-"],"associatedMergedColumns":[]},{"number":"20.2T","isBolded":false,"associatedRows":["ST - MoE - 32B","269B"],"associatedColumns":["FLOPs / seq"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Dense - L"],"associatedColumns":["Parameters","5120","Num . Heads"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["ST - MoE - L"],"associatedColumns":["Parameters","5120","Num . Heads","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"27","isBolded":false,"associatedRows":["ST - MoE - 32B","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"24","isBolded":false,"associatedRows":["T5 - XXL","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers","-"],"associatedMergedColumns":[]},{"number":"27","isBolded":false,"associatedRows":["ST - MoE - L","269B"],"associatedColumns":["FLOPs / seq","5120","Num . Layers","-","-","2048"],"associatedMergedColumns":["1 / 4"]},{"number":"64","isBolded":false,"associatedRows":["Switch - XXL","395B","890B","4096","10240"],"associatedColumns":["d kv"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Switch - C","1571B","890B","2080","6144"],"associatedColumns":["d kv"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["T5 - XXL"],"associatedColumns":["Parameters","5120","Num . Heads","-"],"associatedMergedColumns":[]}]},{"caption":"Table 12: ST-MoE-32B versus previous best for inference-only techniques and fine-tuned mod-\nels. A split of \"dev/test\" refers to dev split for Zero-Shot and One-Shot and test split for Fine-Tune \nquality. Data not available filled in with \"-\". Superscript letters denote the result: a : Raffel et al. \n","rows":["acc","RTE","SuperGLUE","MultiRC","ANLI R3","CB TriviaQA","WinoGrande XL","ARC - Challenge","ReCoRD","CB NatQA","WiC","BoolQ","avg","dev","ARC - Easy","SQuADv2","Copa","CB WebQA","CB","CNN - DM","dev / test","c","test","d","e","WSC","h","ROUGE - 2","em","F1","-","XSum"],"columns":["Fine - Tune","One - Shot","d","e","Previous Best ( ? )","Ours ( ? )","Zero - Shot"],"mergedAllColumns":["a","b"],"numberCells":[{"number":"71.9","isBolded":false,"associatedRows":["ARC - Easy","acc","test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["a"]},{"number":"62.1","isBolded":false,"associatedRows":["SQuADv2","acc","dev"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":[]},{"number":"68.3","isBolded":false,"associatedRows":["SQuADv2","F1","dev"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":[]},{"number":"64.6e","isBolded":false,"associatedRows":["SQuADv2","acc","dev","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":[]},{"number":"52.7e","isBolded":false,"associatedRows":["WiC","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"53.2","isBolded":false,"associatedRows":["ARC - Challenge","acc","test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["a"]},{"number":"68.0","isBolded":false,"associatedRows":["CB TriviaQA","em","dev"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["a"]},{"number":"62.3","isBolded":false,"associatedRows":["CB TriviaQA","em","dev","-","e","-","c"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"98.0","isBolded":false,"associatedRows":["CB","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"90.3","isBolded":false,"associatedRows":["ReCoRD","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"84.9","isBolded":false,"associatedRows":["WSC","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"53.4","isBolded":false,"associatedRows":["ANLI R3","acc","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"74.7","isBolded":false,"associatedRows":["ANLI R3","acc","test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"99.2","isBolded":false,"associatedRows":["Copa","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"99.2","isBolded":false,"associatedRows":["CB","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"96.1","isBolded":false,"associatedRows":["WinoGrande XL","acc","dev","-","e","-","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"68.8","isBolded":false,"associatedRows":["RTE","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"70.0e","isBolded":false,"associatedRows":["SQuADv2","F1","dev","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":[]},{"number":"27.1","isBolded":false,"associatedRows":["XSum","ROUGE - 2","test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"41.9","isBolded":false,"associatedRows":["CB NatQA","em","test","-","e","-","c"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["b"]},{"number":"61.6","isBolded":false,"associatedRows":["CB TriviaQA","em","dev","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"95.2","isBolded":false,"associatedRows":["ARC - Easy","acc","test","-","e","-","c"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"51.4","isBolded":false,"associatedRows":["ARC - Challenge","acc","test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["a"]},{"number":"21.7","isBolded":false,"associatedRows":["CNN - DM","ROUGE - 2","test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"86.5","isBolded":false,"associatedRows":["ARC - Challenge","acc","test","-","e","-","c"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"96.4","isBolded":false,"associatedRows":["ReCoRD","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"82.8e","isBolded":false,"associatedRows":["BoolQ","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"42.8b","isBolded":true,"associatedRows":["CB WebQA","em","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["b"]},{"number":"92.0","isBolded":false,"associatedRows":["BoolQ","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"71.5e","isBolded":false,"associatedRows":["RTE","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"40.9","isBolded":false,"associatedRows":["ANLI R3","acc","test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["a"]},{"number":"38.0f","isBolded":false,"associatedRows":["CB WebQA","em","test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["b"]},{"number":"97.3","isBolded":false,"associatedRows":["WSC","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"96.6","isBolded":false,"associatedRows":["WSC","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"92.4","isBolded":false,"associatedRows":["BoolQ","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"93.5","isBolded":false,"associatedRows":["RTE","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"83.0","isBolded":false,"associatedRows":["BoolQ","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"23.9e","isBolded":false,"associatedRows":["CB NatQA","em","test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["b"]},{"number":"90.8","isBolded":false,"associatedRows":["SQuADv2","acc","dev","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":[]},{"number":"50.5","isBolded":false,"associatedRows":["WiC","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"47.4","isBolded":false,"associatedRows":["CB WebQA","em","test","-","e","-","c"],"associatedColumns":["Ours ( ? )","Fine - Tune","d"],"associatedMergedColumns":["b"]},{"number":"90.8e","isBolded":false,"associatedRows":["ReCoRD","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"25.3","isBolded":false,"associatedRows":["CB WebQA","em","test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["b"]},{"number":"73.2","isBolded":false,"associatedRows":["WinoGrande XL","acc","dev","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"46.4d","isBolded":false,"associatedRows":["CB","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"72.9","isBolded":false,"associatedRows":["MultiRC","F1","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"91.3","isBolded":false,"associatedRows":["SQuADv2","acc","dev","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":[]},{"number":"91.2","isBolded":false,"associatedRows":["SuperGLUE","avg","test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"89.6","isBolded":false,"associatedRows":["MultiRC","F1","dev / test","-","e","-","d","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"96.2a","isBolded":true,"associatedRows":["SQuADv2","F1","dev","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["WinoGrande XL","acc","dev"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"83.9e","isBolded":false,"associatedRows":["WSC","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"92.7g","isBolded":false,"associatedRows":["ARC - Easy","acc","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"88.6","isBolded":false,"associatedRows":["MultiRC","F1","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"74.8e","isBolded":false,"associatedRows":["CB TriviaQA","em","dev","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["a"]},{"number":"21.5","isBolded":false,"associatedRows":["CB NatQA","em","test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot","e"],"associatedMergedColumns":["b"]},{"number":"76.6e","isBolded":false,"associatedRows":["ARC - Easy","acc","test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["a"]},{"number":"91.0d","isBolded":false,"associatedRows":["Copa","acc","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"41.5","isBolded":true,"associatedRows":["CB NatQA","em","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["b"]},{"number":"92.0e","isBolded":false,"associatedRows":["Copa","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]},{"number":"72.9d","isBolded":false,"associatedRows":["MultiRC","F1","dev / test"],"associatedColumns":["Previous Best ( ? )","Zero - Shot"],"associatedMergedColumns":["a"]},{"number":"96.3","isBolded":false,"associatedRows":["SQuADv2","F1","dev","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":false,"associatedRows":["WiC","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"81.4g","isBolded":false,"associatedRows":["ARC - Challenge","acc","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune","d"],"associatedMergedColumns":["a"]},{"number":"77.7","isBolded":false,"associatedRows":["WiC","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"40.8e","isBolded":false,"associatedRows":["ANLI R3","acc","test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot","d"],"associatedMergedColumns":["a"]},{"number":"90.9","isBolded":false,"associatedRows":["SuperGLUE","avg","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"98.2","isBolded":false,"associatedRows":["Copa","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"94.1","isBolded":false,"associatedRows":["RTE","acc","dev / test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"95.1","isBolded":false,"associatedRows":["ReCoRD","acc","dev / test","-","e","-","h"],"associatedColumns":["Ours ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"24.6","isBolded":false,"associatedRows":["XSum","ROUGE - 2","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"21.6a","isBolded":false,"associatedRows":["CNN - DM","ROUGE - 2","test","-","e","-"],"associatedColumns":["Previous Best ( ? )","Fine - Tune"],"associatedMergedColumns":["a"]},{"number":"73.2e","isBolded":false,"associatedRows":["CB","acc","dev / test","-","e"],"associatedColumns":["Previous Best ( ? )","One - Shot"],"associatedMergedColumns":["a"]}]},{"caption":"Table 13: Notable examples of specialization in encoder experts. We find experts that specialize \nin punctuation, conjunctions \u0026 articles, verbs, visual descriptions, proper names, counting \u0026 num-\nbers. Across all layers (not shown), we observe experts that primarily operate on sentinel tokens \n(marked as \u003cextra id x\u003e). Note that a SentencePiece model ","rows":["Conjunctions and articles","Counting and numbers","Visual descriptions","Layer","Verbs","Proper names"],"columns":["center upper blue inner yellow raw mama",". )"],"mergedAllColumns":["Dou Now Ga GT Q Ga C Ko C Ko Ga G","the the the The the the the","falling designed based disagree submitted develop",", , , , , : . : , \u0026 , \u0026 \u0026 ? \u0026 - , , ? , , , . \u003cextra id 27\u003e","the the if ? a designed does been is not","bright bright over open your dark blue"],"numberCells":[{"number":"0","isBolded":false,"associatedRows":["Visual descriptions","Layer"],"associatedColumns":[". )"],"associatedMergedColumns":["falling designed based disagree submitted develop"]},{"number":"1","isBolded":false,"associatedRows":["Verbs","Layer"],"associatedColumns":[". )"],"associatedMergedColumns":["the the if ? a designed does been is not"]},{"number":"1","isBolded":false,"associatedRows":["Counting and numbers","Layer"],"associatedColumns":[". )","center upper blue inner yellow raw mama"],"associatedMergedColumns":["Dou Now Ga GT Q Ga C Ko C Ko Ga G"]},{"number":"6","isBolded":false,"associatedRows":["Conjunctions and articles","Layer"],"associatedColumns":[". )"],"associatedMergedColumns":[]},{"number":"6","isBolded":false,"associatedRows":["Conjunctions and articles","Layer"],"associatedColumns":[". )"],"associatedMergedColumns":["the the the The the the the"]},{"number":"1","isBolded":false,"associatedRows":["Proper names","Layer"],"associatedColumns":[". )","center upper blue inner yellow raw mama"],"associatedMergedColumns":["bright bright over open your dark blue"]},{"number":"3","isBolded":false,"associatedRows":["Conjunctions and articles","Layer"],"associatedColumns":[". )"],"associatedMergedColumns":[", , , , , : . : , \u0026 , \u0026 \u0026 ? \u0026 - , , ? , , , . \u003cextra id 27\u003e"]}]},{"caption":"Table 14: Entropy of routed sentinel tokens across encoder and decoder layers. We support our \nqualitative observation that encoder experts specialize, but decoder expert don\u0027t by computing the \nentropy over the routing for sentinel tokens. The encoder routing entropy is low, but the decoder \nrouter is high entropy, and nearly equal to uniform routing. Because each layer has 32-experts, a \ncompletely uniform distribution has entropy of 3.5. \n","rows":["Encoder","Decoder"],"columns":[") .","Uniform ( 32 - experts )","Layer 1","Layer 2","Layer 3","Layer 4","Layer 5","Layer 6"],"mergedAllColumns":[],"numberCells":[{"number":"3.5","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Uniform ( 32 - experts )"],"associatedMergedColumns":[]},{"number":"1.7","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 4"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 2"],"associatedMergedColumns":[]},{"number":"1.2","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 6"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 4"],"associatedMergedColumns":[]},{"number":"2.2","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 1"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 3"],"associatedMergedColumns":[]},{"number":"3.5","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Uniform ( 32 - experts )"],"associatedMergedColumns":[]},{"number":"1.8","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 2"],"associatedMergedColumns":[]},{"number":"1.7","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 5"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 1"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 5"],"associatedMergedColumns":[]},{"number":"1.6","isBolded":false,"associatedRows":["Encoder"],"associatedColumns":[") .","Layer 3"],"associatedMergedColumns":[]},{"number":"3.4","isBolded":false,"associatedRows":["Decoder"],"associatedColumns":[") .","Layer 6"],"associatedMergedColumns":[]}]},{"caption":"Table 15: Examples of specialization in multilingual experts (encoder). Multilingual ex-\nperts also exhibit specialization, which sometimes spans across different languages (e.g. \"for\" and \n\"pour\"). Experts trained on multilingual mixtures do not exhibit language specialization. \n\n","rows":["$ 50 comment","Numbers","2","Table"],"columns":["to \u003cextra id 6\u003eto til \u003cextra id 9\u003e","numbers , conjunctions \u0026 articles and proper names .","Routed tokens"],"mergedAllColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."],"numberCells":[{"number":".10.2016!","isBolded":false,"associatedRows":["Numbers","$ 50 comment"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"20","isBolded":false,"associatedRows":["Numbers","$ 50 comment"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"11","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"022016.)iOS","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"174","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"91?n??","isBolded":false,"associatedRows":["Numbers","$ 50 comment"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"203!51.!","isBolded":false,"associatedRows":["Numbers","$ 50 comment"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"178\u0026","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"11\u002622:30","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]},{"number":"15presentssomeexamplesofexpertsspecializinginsentineltokens,","isBolded":false,"associatedRows":["Table"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"17","isBolded":false,"associatedRows":["2"],"associatedColumns":["numbers , conjunctions \u0026 articles and proper names .","Routed tokens","to \u003cextra id 6\u003eto til \u003cextra id 9\u003e"],"associatedMergedColumns":["\u003cextra id 19\u003e\u003cextra id 20\u003e\u003cextra id 21\u003e . . ."]}]},{"caption":"Table 16: A dense FFN immediately before or after each sparse layer improves quality. Insert-\ning an extra dense FFN immediately before or after each sparse layer improves quality 2x as much \nas placing the dense layers (randomly) elsewhere in the network. All of the non-baseline models \nhave the same amount of FFN layers added for fair comparisons. Note that improving perplexity \nbecomes harder as the model gets better. \n\n","rows":["Sparse model w / extra FFN layer after each sparse layer","Sparse model w / extra FFN layer before each sparse layer","Dense model w / extra FFN layers","Dense model ( baseline )","Sparse model ( baseline )","Sparse model w / extra FNN layers placed randomly in the network"],"columns":["Neg . Log Perp . ( ? )","?"],"mergedAllColumns":["-"],"numberCells":[{"number":"-1.474","isBolded":false,"associatedRows":["Dense model ( baseline )"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.014","isBolded":false,"associatedRows":["Sparse model w / extra FFN layer after each sparse layer"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-1.369","isBolded":true,"associatedRows":["Sparse model w / extra FFN layer before each sparse layer"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-1.383","isBolded":false,"associatedRows":["Sparse model ( baseline )"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-1.369","isBolded":true,"associatedRows":["Sparse model w / extra FFN layer after each sparse layer"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-1.452","isBolded":false,"associatedRows":["Dense model w / extra FFN layers"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"0.014","isBolded":false,"associatedRows":["Sparse model w / extra FFN layer before each sparse layer"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"-1.376","isBolded":false,"associatedRows":["Sparse model w / extra FNN layers placed randomly in the network"],"associatedColumns":["Neg . Log Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"0.007","isBolded":false,"associatedRows":["Sparse model w / extra FNN layers placed randomly in the network"],"associatedColumns":["?"],"associatedMergedColumns":["-"]},{"number":"0.022","isBolded":false,"associatedRows":["Dense model w / extra FFN layers"],"associatedColumns":["?"],"associatedMergedColumns":["-"]}]},{"caption":"Table 17 shows the results of our different methods. Both the additive and multiplicative biases are \nessentially free: cheap to compute, adds few new parameters, and incurs no additional communi-\ncation costs with model and expert parallelism. When using our router z-loss from Section 3.1, we \nobserve no instabilities from the multiplicative bias. We do see that the multiplicative interactions \nimprove performance, achieving a 4% speedup in convergence time over our strong sparse baseline. \nThis hints that a promising avenue for future architectural research is finding new ways of adding \nmore multiplicative interactions into networks. \n\nModel \nNeg. Log. Perp. (?) \n? \n\nDense Baseline \n-1.474 \n-\nSparse Baseline \n-1.369 \n-\n\nSparse + Additive Bias \n-1.371 \n-0.002 \nSparse + Multiplicative Bias \n-1.361 \n0.008 \n\nTable 17: More multiplicative interactions improve sparse model quality. Both the additive and \nthe multiplicative bias add virtually no parameters or compute. \n\n","rows":["cation costs with model and expert parallelism . When using our router z - loss from Section","Sparse + Additive Bias","Dense Baseline","Sparse + Multiplicative Bias","Sparse Baseline"],"columns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","?","Neg . Log . Perp . ( ? )"],"mergedAllColumns":["essentially free : cheap to compute , adds few new parameters , and incurs no additional communi -","more multiplicative interactions into networks .","-"],"numberCells":[{"number":"3.1,we","isBolded":false,"associatedRows":["cation costs with model and expert parallelism . When using our router z - loss from Section"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are"],"associatedMergedColumns":["essentially free : cheap to compute , adds few new parameters , and incurs no additional communi -"]},{"number":"-1.474","isBolded":false,"associatedRows":["Dense Baseline"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","Neg . Log . Perp . ( ? )"],"associatedMergedColumns":["more multiplicative interactions into networks ."]},{"number":"-1.371","isBolded":false,"associatedRows":["Sparse + Additive Bias"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","Neg . Log . Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-1.361","isBolded":true,"associatedRows":["Sparse + Multiplicative Bias"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","Neg . Log . Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-1.369","isBolded":false,"associatedRows":["Sparse Baseline"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","Neg . Log . Perp . ( ? )"],"associatedMergedColumns":["-"]},{"number":"-0.002","isBolded":false,"associatedRows":["Sparse + Additive Bias"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","?"],"associatedMergedColumns":["-"]},{"number":"0.008","isBolded":false,"associatedRows":["Sparse + Multiplicative Bias"],"associatedColumns":["Table 17 shows the results of our different methods . Both the additive and multiplicative biases are","?"],"associatedMergedColumns":["-"]}]},{"caption":"Table 18: Batch Prioritized Top-1 Routing (BPR) performance. BPR top-1 routing improves \nquality when capacity factors are ? 1. However, once the capacity factor reaches 1.25, the improve-\nments greatly diminish and it underperforms top-2 routing. Future work can try BPR with top-2 \nrouting, which should hopefully further improve the performance. \n\n","rows":["Dense","Dense - L","Top - 2","-","Top - 1","BPR Top - 1"],"columns":["Train CF","Eval CF","Neg . Log . Perp . ( ? )"],"mergedAllColumns":[],"numberCells":[{"number":"-1.397","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.376","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.378","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.375","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.404","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.379","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.416","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.409","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.375","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.378","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.402","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.424","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.386","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.433","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.384","isBolded":false,"associatedRows":["Dense - L","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.397","isBolded":false,"associatedRows":["BPR Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.373","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.474","isBolded":false,"associatedRows":["Dense","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.392","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.369","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"-1.384","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["BPR Top - 1"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.428","isBolded":false,"associatedRows":["Top - 1","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["BPR Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 1","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Eval CF"],"associatedMergedColumns":[]}]},{"caption":"Table 19: Data and mixture weights in the training set. We sample from different dataset sources \nwith probability proportional to \"weight in mixture\". The number of tokens listed are in billions (B). \nFor more details on the C4 corpus see ","rows":["Wikipedia","390","183","Conversations","174","Filtered C4","143","650","Filtered Webpages","3","247","Forums","News","Books"],"columns":["Weight in Mixture","PRE - TRAINING DATASET DETAILS"],"mergedAllColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."],"numberCells":[{"number":"0.02","isBolded":false,"associatedRows":["Forums","247"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.23","isBolded":false,"associatedRows":["Conversations","174"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.34","isBolded":false,"associatedRows":["Filtered Webpages","143"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.05","isBolded":false,"associatedRows":["Wikipedia","3"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.17","isBolded":false,"associatedRows":["Books","390"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.02","isBolded":false,"associatedRows":["News","650"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]},{"number":"0.17","isBolded":false,"associatedRows":["Filtered C4","183"],"associatedColumns":["PRE - TRAINING DATASET DETAILS","Weight in Mixture"],"associatedMergedColumns":["the dataset introduced in GLaM ( Du et al . , 2021 ) ."]}]},{"caption":"Table 20: Fine-tuning protocol sensitivity. We vary the batch size, learning rate and whether we \nreset the optimizer slot variables for both dense and sparse models. Resetting the optimizer state \nduring fine-tuning hurts performance. We observe a difference in optimal batch size and learning \nrate for sparse vs. dense models. Certain hyperparameter fine-tuning settings make the sparse and \ndense models perform almost exactly the same, showing the importance of correctly tuning the \nhyperparameters. \n","rows":["Dense","262k","Sparse","1M","65k","5e - 4","1e - 4","1e - 3"],"columns":["SuperGLUE ( ? )"],"mergedAllColumns":[],"numberCells":[{"number":"84.9","isBolded":false,"associatedRows":["Dense","5e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.0","isBolded":false,"associatedRows":["Dense","1e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["Sparse","1e - 3","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Dense","1e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Dense","1e - 3","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Sparse","5e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Dense","5e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.3","isBolded":false,"associatedRows":["Sparse","1e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["Sparse","5e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["Dense","5e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.2","isBolded":false,"associatedRows":["Sparse","1e - 3","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Dense","1e - 3","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"86.1","isBolded":false,"associatedRows":["Sparse","5e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.3","isBolded":false,"associatedRows":["Sparse","1e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["Dense","1e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Dense","1e - 3","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"86.9","isBolded":true,"associatedRows":["Sparse","1e - 3","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.6","isBolded":false,"associatedRows":["Sparse","1e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.2","isBolded":false,"associatedRows":["Dense","5e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.6","isBolded":false,"associatedRows":["Dense","1e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.9","isBolded":false,"associatedRows":["Dense","1e - 3","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.8","isBolded":false,"associatedRows":["Sparse","1e - 3","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"83.5","isBolded":false,"associatedRows":["Sparse","5e - 4","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"86.5","isBolded":false,"associatedRows":["Sparse","5e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["Sparse","1e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.5","isBolded":false,"associatedRows":["Sparse","1e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":true,"associatedRows":["Dense","1e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"82.5","isBolded":false,"associatedRows":["Dense","1e - 3","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["Sparse","1e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["Sparse","1e - 3","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["Dense","5e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["Dense","5e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":false,"associatedRows":["Sparse","1e - 3","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.9","isBolded":false,"associatedRows":["Dense","1e - 4","65k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["Sparse","5e - 4","262k"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]},{"number":"84.3","isBolded":false,"associatedRows":["Dense","1e - 3","1M"],"associatedColumns":["SuperGLUE ( ? )"],"associatedMergedColumns":[]}]},{"caption":"Table 21: Performance of top-2 and top-3 routing with different thresholds. Top-3 routing does \nslightly better with lower thresholds than top-2 routing. \n\n","rows":["Dense","Dense - L","Top - 2","Top - 3","-"],"columns":["Train CF","Neg . Log . Perp . ( ? )","Threshold"],"mergedAllColumns":[],"numberCells":[{"number":"-1.384","isBolded":false,"associatedRows":["Dense - L","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Threshold"],"associatedMergedColumns":[]},{"number":"-1.356","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 3"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["Top - 3","-"],"associatedColumns":["Threshold"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"-1.351","isBolded":true,"associatedRows":["Top - 3","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.349","isBolded":true,"associatedRows":["Top - 3","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.354","isBolded":false,"associatedRows":["Top - 2","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"-1.474","isBolded":false,"associatedRows":["Dense","-","-"],"associatedColumns":["Neg . Log . Perp . ( ? )"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Top - 2","-"],"associatedColumns":["Threshold"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Top - 3","-"],"associatedColumns":["Threshold"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 2"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Top - 3"],"associatedColumns":["Train CF"],"associatedMergedColumns":[]}]}]