[{"caption":"Table 2. Median FID and IS for the unsupervised approaches (see \n","rows":["SINGLE LABEL ( SS )","CLUSTERING ( SS )","CLUSTERING","SINGLE LABEL","RANDOM LABEL"],"columns":["FID","IS"],"mergedAllColumns":[],"numberCells":[{"number":"20.2","isBolded":false,"associatedRows":["RANDOM LABEL"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"20.4","isBolded":false,"associatedRows":["SINGLE LABEL"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"23.5","isBolded":false,"associatedRows":["CLUSTERING ( SS )"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"22.7","isBolded":false,"associatedRows":["CLUSTERING"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"22.0","isBolded":false,"associatedRows":["CLUSTERING ( SS )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"23.7","isBolded":false,"associatedRows":["SINGLE LABEL ( SS )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"25.3","isBolded":false,"associatedRows":["SINGLE LABEL"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["RANDOM LABEL"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"22.2","isBolded":false,"associatedRows":["SINGLE LABEL ( SS )"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"23.2","isBolded":false,"associatedRows":["CLUSTERING"],"associatedColumns":["FID"],"associatedMergedColumns":[]}]},{"caption":"Table 4. It can be \nseen that S 2 GAN-CO outperforms all fully unsupervised \napproaches for all considered label percentages. While the \ngap between S 2 GAN-CO with 5% labels and CLUSTER-\n\nING in terms of FID is small, S 2 GAN-CO has a consider-\nably larger IS. When using 20% labeled training examples \nS 2 GAN-CO obtains an FID of 13.9 and an IS of 49.2, \nwhich is remarkably close to BIGGAN and S 2 GAN given \nthe simplicity of the S 2 GAN-CO approach. As the the \npercentage of labels decreases, the gap between S 2 GAN \nand S 2 GAN-CO increases. \n\n","rows":["0","5"],"columns":["Random label"],"mergedAllColumns":["Clustering ( SS )"],"numberCells":[{"number":"20","isBolded":false,"associatedRows":["0","5"],"associatedColumns":["Random label"],"associatedMergedColumns":["Clustering ( SS )"]},{"number":"15","isBolded":false,"associatedRows":["0","5"],"associatedColumns":["Random label"],"associatedMergedColumns":["Clustering ( SS )"]},{"number":"30","isBolded":false,"associatedRows":["0","5"],"associatedColumns":["Random label"],"associatedMergedColumns":["Clustering ( SS )"]},{"number":"10","isBolded":false,"associatedRows":["0","5"],"associatedColumns":["Random label"],"associatedMergedColumns":["Clustering ( SS )"]},{"number":"25","isBolded":false,"associatedRows":["0","5"],"associatedColumns":["Random label"],"associatedMergedColumns":["Clustering ( SS )"]}]},{"caption":"Table 5. Training with hard (predicted) labels leads to better mod-\nels than training with soft (predicted) labels (see ","rows":["+SOFT","S 2 GAN"],"columns":["FID","5%","10%",") .","20%","IS"],"mergedAllColumns":[],"numberCells":[{"number":"12.9","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","FID","10%"],"associatedMergedColumns":[]},{"number":"10.4","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","FID","20%"],"associatedMergedColumns":[]},{"number":"15.4","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","FID","5%"],"associatedMergedColumns":[]},{"number":"8.4","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","FID","20%"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","IS","10%"],"associatedMergedColumns":[]},{"number":"40.3","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","IS","5%"],"associatedMergedColumns":[]},{"number":"8.9","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","FID","10%"],"associatedMergedColumns":[]},{"number":"62.1","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","IS","20%"],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["+SOFT"],"associatedColumns":[") .","IS","10%"],"associatedMergedColumns":[]},{"number":"57.6","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","IS","5%"],"associatedMergedColumns":[]},{"number":"10.8","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","FID","5%"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["S 2 GAN"],"associatedColumns":[") .","IS","20%"],"associatedMergedColumns":[]}]},{"caption":"Table 12. Pre-trained vs co-training approaches, and the effect of self-supervision during GAN training. While co-training approaches \noutperform fully unsupervised approaches, they are clearly outperformed by the pre-trained approaches. Self-supervision during GAN \ntraining helps in all cases. \n\n","rows":["5%"],"columns":["FID","IS"],"mergedAllColumns":[],"numberCells":[{"number":"10%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"10%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"20%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"20%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]}]},{"caption":"FID \nIS \n\n5% \n10% \n20% \n5% \n10% \n20% \n\nS 2 GAN \n11.0?0.31 9.0?0.30 8.4?0.02 57.6?0.86 72.9?1.41 77.7?1.24 \nS 2 GAN-CO 21.6?0.64 17.6?0.27 13.8?0.48 29.8?0.21 37.1?0.54 50.1?1.45 \nS 3 GAN \n10.3?0.16 8.1?0.14 7.8?0.20 59.9?0.74 78.3?1.08 82.1?1.89 \nS 3 GAN-CO 20.2?0.14 16.5?0.12 12.8?0.51 31.1?0.18 38.7?0.36 52.7?1.08 \n\nTable 13. Training with hard (predicted) labels leads to better models than training with soft (predicted) labels. \n\n","rows":["5%"],"columns":["FID","IS"],"mergedAllColumns":[],"numberCells":[{"number":"20%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"10%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"20%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"10%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]}]},{"caption":"FID \nIS \n\n5% \n10% \n20% \n5% \n10% \n20% \n\nS 2 GAN \n11.0?0.31 9.0?0.30 8.4?0.02 57.6?0.86 72.9?1.41 77.7?1.24 \nS 2 GAN SOFT 15.6?0.58 13.3?1.71 11.3?1.42 40.1?0.97 49.3?4.67 58.5?5.84 \n\nTable 14. Mean FID and IS for the unsupervised approaches. \n\n","rows":["5%"],"columns":["FID","IS"],"mergedAllColumns":[],"numberCells":[{"number":"20%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]},{"number":"20%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"10%","isBolded":false,"associatedRows":["5%"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"10%","isBolded":false,"associatedRows":["5%","5%"],"associatedColumns":["IS"],"associatedMergedColumns":[]}]}]