[{"caption":"Table 1: Topic coherence of different topic models, evalu-\nated on the held-out arXiv data. Our full TopicEq model is \nshown as \"Ours (context + Eq LSTM).\" \n\nQuantum physics spin energy field electron magnetic state states hamiltonian \n\nParticle physics \n\nhiggs neutrino coupling decay scale masses mixing quark \n\nAstrophysics \n\nmass gas star stellar galaxies disk halo radius luminosity \n\nRelativity \n\nblack metric hole schwarzschild gravity holes einstein \n\nNumber theory \n\nprime integer numbers conjecture integers degree modulo \n\nGraph theory \n\ngraph vertex vertices edges node edge number set tree \n\nLinear algebra \n\nmatrix matrices vector basis vectors diagonal rank linear \n\nOptimization \n\nproblem optimization algorithm function solution gradient \n\nProbability \n\nrandom probability distribution process measure time \n\nMachine learning layer word image feature sentence model cnn lstm training \n\n","rows":["Ours ( context + Eq BOW )","Ours ( context + Eq LSTM shuffled )","LDA ( context only )","Ours ( context + Eq LSTM )","Ours ( context only )"],"columns":["100 ( # Topics )","50"],"mergedAllColumns":[],"numberCells":[{"number":".086","isBolded":false,"associatedRows":["Ours ( context + Eq BOW )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".094","isBolded":true,"associatedRows":["Ours ( context + Eq LSTM )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".085","isBolded":false,"associatedRows":["Ours ( context + Eq LSTM shuffled )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".085","isBolded":false,"associatedRows":["Ours ( context only )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".097","isBolded":true,"associatedRows":["Ours ( context + Eq LSTM )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".083","isBolded":false,"associatedRows":["LDA ( context only )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".087","isBolded":false,"associatedRows":["Ours ( context + Eq BOW )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".086","isBolded":false,"associatedRows":["Ours ( context + Eq LSTM shuffled )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".084","isBolded":false,"associatedRows":["Ours ( context only )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".085","isBolded":false,"associatedRows":["LDA ( context only )"],"associatedColumns":["50"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Topics learned by the TopicEq model. Left: topic \nname (summarized by us). Right: top words in topic. \n\n","rows":["( Lau et al . 2017 )","( Ours )","size 500 , with dropout rate","LSTM + LDA","batch size 200 , learning rate","LSTM ( no topic )","TD - LSTM","TE - LSTM"],"columns":["100","Error ( % )","Perplexity","For the inference network q ( ?|C ) , we use","50"],"mergedAllColumns":["are jointly optimized by Adam ( Kingma and Ba 2015 ) , with","No joint training","equation TE - LSTM architecture has two layers and state","Joint training with topic model"],"numberCells":[{"number":"0.002,andgradientclipping","isBolded":false,"associatedRows":["batch size 200 , learning rate"],"associatedColumns":["Perplexity","50","For the inference network q ( ?|C ) , we use"],"associatedMergedColumns":["are jointly optimized by Adam ( Kingma and Ba 2015 ) , with"]},{"number":"5.41","isBolded":false,"associatedRows":["size 500 , with dropout rate","TD - LSTM","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","100"],"associatedMergedColumns":["Joint training with topic model"]},{"number":"1.0","isBolded":false,"associatedRows":["batch size 200 , learning rate"],"associatedColumns":["Perplexity","50","For the inference network q ( ?|C ) , we use"],"associatedMergedColumns":["are jointly optimized by Adam ( Kingma and Ba 2015 ) , with"]},{"number":"5.44","isBolded":false,"associatedRows":["size 500 , with dropout rate","TD - LSTM","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","50"],"associatedMergedColumns":["Joint training with topic model"]},{"number":"0.5appliedtoeachlayer(Sri-","isBolded":false,"associatedRows":["size 500 , with dropout rate"],"associatedColumns":["Perplexity","50","For the inference network q ( ?|C ) , we use"],"associatedMergedColumns":["equation TE - LSTM architecture has two layers and state"]},{"number":"13.4","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM + LDA","( Lau et al . 2017 )"],"associatedColumns":["Error ( % )","100"],"associatedMergedColumns":["No joint training"]},{"number":"5.34","isBolded":true,"associatedRows":["size 500 , with dropout rate","TE - LSTM","( Ours )"],"associatedColumns":["Perplexity","100"],"associatedMergedColumns":["Joint training with topic model"]},{"number":"11.7","isBolded":true,"associatedRows":["size 500 , with dropout rate","TE - LSTM","( Ours )"],"associatedColumns":["Error ( % )","100"],"associatedMergedColumns":["Joint training with topic model"]},{"number":"12.5","isBolded":false,"associatedRows":["size 500 , with dropout rate","TD - LSTM","( Lau et al . 2017 )"],"associatedColumns":["Error ( % )","100"],"associatedMergedColumns":["Joint training with topic model"]},{"number":"5.54","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM + LDA","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","50"],"associatedMergedColumns":["No joint training"]},{"number":"5.81","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM ( no topic )","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","50"],"associatedMergedColumns":["No joint training"]},{"number":"5.81","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM ( no topic )","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","100"],"associatedMergedColumns":["No joint training"]},{"number":"15.3","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM ( no topic )","( Lau et al . 2017 )"],"associatedColumns":["Error ( % )","100"],"associatedMergedColumns":["No joint training"]},{"number":"5.52","isBolded":false,"associatedRows":["size 500 , with dropout rate","LSTM + LDA","( Lau et al . 2017 )"],"associatedColumns":["Perplexity","100"],"associatedMergedColumns":["No joint training"]},{"number":"5.36","isBolded":true,"associatedRows":["size 500 , with dropout rate","TE - LSTM","( Ours )"],"associatedColumns":["Perplexity","50"],"associatedMergedColumns":["Joint training with topic model"]}]},{"caption":"Model setting. For the inference network q(?|C), we use \na 2-layer FFNN with 300 units, similar to (Miao, Yu, and \nBlunsom 2016; Miao, Grefenstette, and Blunsom 2017). The \nequation TE-LSTM architecture has two layers and state \nsize 500, with dropout rate 0.5 applied to each layer (Sri-\nvastava et al. 2014). The parameters of the TopicEq model \nare jointly optimized by Adam (Kingma and Ba 2015), with \nbatch size 200, learning rate 0.002, and gradient clipping 1.0 \n(Pascanu, Mikolov, and Bengio 2012). \n\nTopic Model Evaluation \n\nWe first study the topic modeling performance of TopicEq, \nby evaluating the coherence of the learned topics ? (Chang \net al. 2009; Newman et al. 2010b; Mimno et al. 2011). \nSpecifically, following (Lau, Newman, and Baldwin 2014), \nwe compute the normalized PMI metric on the held-out test \nset. As our TopicEq model incorporates joint, RNN-based \nequation model, to analyze its effect, we compare the full \nTopicEq model with the following baseline topic models: \n? LDA (context only): we apply LDA to the word text \n? Ours (context only): TopicEq without the equation model \n? Ours (context + Eq BOW): TopicEq\u0027s joint LSTM equa-\ntion model (Eq 3) is replaced by a baseline bag-of-tokens \nmodel similar to that for context words. \nThe evaluation results are summarized in Table 1. The full \nTopicEq model is shown as \"Ours (context + Eq LSTM)\" \nin the table. We observe that TopicEq\u0027s topic model compo-\nnent (2nd row) performs on a par with LDA (1st row), but it \nachieves a significant boost (+0.01) when trained together \nwith the LSTM equation model (4th row). Adding equa-\ntions as bag of tokens (3rd row) does improve topic models \nmarginally (+0.002), but the improvement made by using \njoint LSTM equation model is 5 times greater. These results \n\nEquation Model \nPerplexity Error (%) \n50 \n100 \n100 \n\nNo joint training \nLSTM (no topic) \n5.81 5.81 \n15.3 \nLSTM + LDA \n5.54 5.52 \n13.4 \n\nJoint training with topic model \nTD-LSTM (Lau et al. 2017) \n5.44 5.41 \n12.5 \nTE-LSTM (Ours) \n5.36 5.34 \n11.7 \n\n","rows":["Ours ( context + Eq BOW )","Ours ( context + Eq LSTM shuffled )","LDA ( context only )","Ours ( context + Eq LSTM )","Ours ( context only )"],"columns":["100 ( # Topics )","50"],"mergedAllColumns":[],"numberCells":[{"number":".085","isBolded":false,"associatedRows":["Ours ( context only )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".097","isBolded":true,"associatedRows":["Ours ( context + Eq LSTM )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".083","isBolded":false,"associatedRows":["LDA ( context only )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".087","isBolded":false,"associatedRows":["Ours ( context + Eq BOW )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".094","isBolded":true,"associatedRows":["Ours ( context + Eq LSTM )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".086","isBolded":false,"associatedRows":["Ours ( context + Eq LSTM shuffled )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".086","isBolded":false,"associatedRows":["Ours ( context + Eq BOW )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".085","isBolded":false,"associatedRows":["LDA ( context only )"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".084","isBolded":false,"associatedRows":["Ours ( context only )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".085","isBolded":false,"associatedRows":["Ours ( context + Eq LSTM shuffled )"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Test perplexity for phrase prediction. \n\n","rows":["Alignment Model","Topic - Aware","50","Baseline ( no topic )"],"columns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"mergedAllColumns":[],"numberCells":[{"number":"602","isBolded":true,"associatedRows":["Baseline ( no topic )"],"associatedColumns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"associatedMergedColumns":[]},{"number":"602","isBolded":true,"associatedRows":["Baseline ( no topic )"],"associatedColumns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"associatedMergedColumns":[]},{"number":"100(#Topics)","isBolded":false,"associatedRows":["Alignment Model","50"],"associatedColumns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"associatedMergedColumns":[]},{"number":"406","isBolded":false,"associatedRows":["Topic - Aware"],"associatedColumns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"associatedMergedColumns":[]},{"number":"387","isBolded":false,"associatedRows":["Topic - Aware"],"associatedColumns":["results for three of the learned topics ( 3rd - 5th column ) , as well as the non - topic baseline ( 2nd column ) ."],"associatedMergedColumns":[]}]},{"caption":"Table 10: Topic coherence evaluation for each topic model. \n\n","rows":["Context Only","with joint Alignment Model"],"columns":["100 ( # Topics )","50"],"mergedAllColumns":[],"numberCells":[{"number":".084","isBolded":true,"associatedRows":["Context Only"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".087","isBolded":false,"associatedRows":["with joint Alignment Model"],"associatedColumns":["100 ( # Topics )"],"associatedMergedColumns":[]},{"number":".088","isBolded":false,"associatedRows":["with joint Alignment Model"],"associatedColumns":["50"],"associatedMergedColumns":[]},{"number":".085","isBolded":true,"associatedRows":["Context Only"],"associatedColumns":["50"],"associatedMergedColumns":[]}]}]