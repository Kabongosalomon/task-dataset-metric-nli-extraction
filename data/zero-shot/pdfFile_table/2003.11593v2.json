[{"caption":"1.00 1.02 1.04 1.06 1.08 1.10 \n\n0.12 \n\n0.13 \n\n0.14 \n\n0.15 \n\n0.16 \n\nClassification loss \n\nYelp \n\n1.00 1.02 1.04 1.06 1.08 1.10 \n\n0.06 \n\n0.08 \n\n0.10 \n\n0.12 \n\n0.14 \n\nAmazon \nLHTR \nLHTR 1 \nNN model \n\nFigure 3: Classification loss of LHTR, LHTR 1 and NN model on the extreme test set {x ? T , ||x|| ? \n?t} for increasing values of ? (X-axis), on Yelp and Amazon. \n\nModel \nAmazon \nYelp \nBulk Extreme Overall Bulk Extreme Overall \n\nNN model \n\n0.085 \n0.135 \n0.098 \n0.098 \n0.148 \n0.111 \n\nLHTR 1 \n\n0.104 \n0.091 \n0.101 \n0.160 \n0.139 \n0.155 \n\nLHTR \n\n0.105 \n0.08 \n0.0988 0.162 \n0.1205 \n0.152 \nProposed Model 0.085 \n0.08 \n0.084 \n0.097 \n0.1205 \n0.103 \nTable 1: Classification losses on Amazon and Yelp. \u0027Proposed Model\u0027 results from using NN model \nmodel for the bulk and LHTR for the extreme test sets. The extreme region contains 6.9k samples for \nAmazon and 6.1k samples for Yelp, both corresponding roughly to 25% of the whole test set size. \n\n","rows":["NN","Amazon and","loss","LHTR 1","Classification","model","Proposed Model","model for the bulk and LHTR for the extreme test sets . The extreme region contains"],"columns":["Overall","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Extreme","Yelp","model on the extreme test set {x ? T , ||x|| ?","model","Amazon","Table 1 : Classification losses on Amazon and Yelp . \u0027 Proposed Model \u0027 results from using NN","Bulk"],"mergedAllColumns":["LHTR 1","Model","NN model"],"numberCells":[{"number":"0.14","isBolded":false,"associatedRows":[],"associatedColumns":["Yelp"],"associatedMergedColumns":["LHTR 1"]},{"number":"0.0988","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.098","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.139","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.12","isBolded":false,"associatedRows":[],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"0.148","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.14","isBolded":false,"associatedRows":["loss","Proposed Model","model"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"6.1ksamplesforYelp,bothcorrespondingroughlyto25%ofthewholetestsetsize.","isBolded":true,"associatedRows":["Amazon and","Classification"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Yelp","Overall","Table 1 : Classification losses on Amazon and Yelp . \u0027 Proposed Model \u0027 results from using NN"],"associatedMergedColumns":["Model"]},{"number":"0.08","isBolded":false,"associatedRows":["Classification","Proposed Model","model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.111","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.084","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Overall"],"associatedMergedColumns":["Model"]},{"number":"1.06","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"1.10","isBolded":false,"associatedRows":["Classification","Proposed Model","model"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"1.08","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"1.10","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.097","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.155","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Overall"],"associatedMergedColumns":["Model"]},{"number":"1.08","isBolded":false,"associatedRows":["Classification","LHTR 1","model"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"1.04","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.091","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.13","isBolded":false,"associatedRows":[],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"0.101","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.08","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.16","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.135","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.085","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Yelp","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.104","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Yelp","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.085","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Yelp","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Bulk"],"associatedMergedColumns":["Model"]},{"number":"1.04","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"0.12","isBolded":false,"associatedRows":["loss","Proposed Model","model"],"associatedColumns":["Amazon"],"associatedMergedColumns":[]},{"number":"1.00","isBolded":false,"associatedRows":["Classification","Proposed Model","model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.160","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.08","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Extreme"],"associatedMergedColumns":["Model"]},{"number":"1.06","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"1.02","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.103","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.105","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Yelp","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.10","isBolded":false,"associatedRows":["Classification","Proposed Model","model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["LHTR 1"]},{"number":"0.1205","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Extreme"],"associatedMergedColumns":["Model"]},{"number":"6.9ksamplesfor","isBolded":true,"associatedRows":["model for the bulk and LHTR for the extreme test sets . The extreme region contains"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Overall","model"],"associatedMergedColumns":["Model"]},{"number":"1.00","isBolded":false,"associatedRows":["Classification","NN"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]},{"number":"0.098","isBolded":false,"associatedRows":["Classification","NN","model"],"associatedColumns":["Amazon","Figure 3 : Classification loss of LHTR , LHTR 1 and NN","Amazon","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.152","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Overall"],"associatedMergedColumns":["Model"]},{"number":"0.06","isBolded":false,"associatedRows":["Classification","Proposed Model","model"],"associatedColumns":["Amazon"],"associatedMergedColumns":["NN model"]},{"number":"0.162","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Bulk"],"associatedMergedColumns":["Model"]},{"number":"0.1205","isBolded":false,"associatedRows":["Classification","Proposed Model"],"associatedColumns":["Amazon","model on the extreme test set {x ? T , ||x|| ?","Yelp","Extreme"],"associatedMergedColumns":["Model"]},{"number":"0.15","isBolded":false,"associatedRows":[],"associatedColumns":["Yelp"],"associatedMergedColumns":[]},{"number":"1.02","isBolded":false,"associatedRows":["Classification","NN"],"associatedColumns":["Yelp"],"associatedMergedColumns":["NN model"]}]},{"caption":"Table 2: Quantitative Evaluation. Algorithms are compared according to C3 and C4. dist1 and dist2 \nrespectively stand for distinct 1 and 2, it measures the diversity of new sequences in terms of unigrams \nand bigrams. F1 is the F1-score for FastText classifier trained on an augmented labelled training set. \n\n","rows":["0 . 10 / 0 . 47","Kobayashi [ 33 ]","0 . 18 / 0 . 62","Wei and Zou [ 57 ]","0 . 18 / 0 . 58","0 . 15 / 0 . 53","GENELIEX","0 . 15 / 0 . 52","0 . 14 / 0 . 52","Raw Data","0 . 11 / 0 . 50","0 . 14 / 0 . 54","0 . 14 / 0 . 53","X"],"columns":["X"],"mergedAllColumns":["0 . 14 / 0 . 58","0 . 16 / 0 . 59"],"numberCells":[{"number":"85.2","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 14 / 0 . 58"]},{"number":"86.3","isBolded":true,"associatedRows":["GENELIEX"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 16 / 0 . 59"]},{"number":"84.0","isBolded":false,"associatedRows":["Raw Data"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"85.0","isBolded":false,"associatedRows":["Kobayashi [ 33 ]"],"associatedColumns":["X"],"associatedMergedColumns":[]},{"number":"92.9","isBolded":false,"associatedRows":["Kobayashi [ 33 ]","0 . 10 / 0 . 47"],"associatedColumns":["X"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["Raw Data","X","X"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"94.0","isBolded":false,"associatedRows":["Kobayashi [ 33 ]","0 . 10 / 0 . 47","0 . 14 / 0 . 53","0 . 15 / 0 . 53"],"associatedColumns":["X"],"associatedMergedColumns":[]},{"number":"88.4","isBolded":true,"associatedRows":["GENELIEX","0 . 14 / 0 . 52","0 . 18 / 0 . 58"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 16 / 0 . 59"]},{"number":"93.2","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]","0 . 11 / 0 . 50"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 14 / 0 . 58"]},{"number":"94.2","isBolded":true,"associatedRows":["Wei and Zou [ 57 ]","0 . 11 / 0 . 50","0 . 14 / 0 . 54","0 . 15 / 0 . 52"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 14 / 0 . 58"]},{"number":"93.3","isBolded":false,"associatedRows":["Raw Data","X"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"94.1","isBolded":false,"associatedRows":["Raw Data","X","X","X"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"87.0","isBolded":false,"associatedRows":["Kobayashi [ 33 ]","0 . 10 / 0 . 47","0 . 14 / 0 . 53"],"associatedColumns":["X"],"associatedMergedColumns":[]},{"number":"94.2","isBolded":true,"associatedRows":["GENELIEX","0 . 14 / 0 . 52","0 . 18 / 0 . 58","0 . 18 / 0 . 62"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 16 / 0 . 59"]},{"number":"87.0","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]","0 . 11 / 0 . 50","0 . 14 / 0 . 54"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 14 / 0 . 58"]},{"number":"94.0","isBolded":true,"associatedRows":["GENELIEX","0 . 14 / 0 . 52"],"associatedColumns":["X"],"associatedMergedColumns":["0 . 16 / 0 . 59"]}]},{"caption":"Table 3: Qualitative evaluation with three turkers. Sent. stands for sentiment label preservation. \nThe Krippendorff Alpha for Amazon is ? \u003d 0.28 on the sentiment classification and ? \u003d 0.20 for \ncohesion. The Krippendorff Alpha for Yelp is ? \u003d 0.57 on the sentiment classification and ? \u003d 0.48 \nfor cohesion. \n\n","rows":["Raw Data","Kobayashi [ 33 ]","Wei and Zou [ 57 ]","GENELIEX"],"columns":["Cohesion","Sent .","Yelp","Amazon"],"mergedAllColumns":["Model"],"numberCells":[{"number":"80.0","isBolded":true,"associatedRows":["Kobayashi [ 33 ]"],"associatedColumns":["Amazon","Sent ."],"associatedMergedColumns":["Model"]},{"number":"0.60","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]"],"associatedColumns":["Yelp","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"80.0","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]"],"associatedColumns":["Yelp","Sent ."],"associatedMergedColumns":["Model"]},{"number":"0.71","isBolded":false,"associatedRows":["Raw Data"],"associatedColumns":["Yelp","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"82.9","isBolded":false,"associatedRows":["Kobayashi [ 33 ]"],"associatedColumns":["Yelp","Sent ."],"associatedMergedColumns":["Model"]},{"number":"80.6","isBolded":false,"associatedRows":["Raw Data"],"associatedColumns":["Yelp","Sent ."],"associatedMergedColumns":["Model"]},{"number":"85.7","isBolded":true,"associatedRows":["GENELIEX"],"associatedColumns":["Yelp","Sent ."],"associatedMergedColumns":["Model"]},{"number":"0.72","isBolded":false,"associatedRows":["Kobayashi [ 33 ]"],"associatedColumns":["Yelp","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"67.4","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]"],"associatedColumns":["Amazon","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"69.0","isBolded":false,"associatedRows":["Wei and Zou [ 57 ]"],"associatedColumns":["Amazon","Sent ."],"associatedMergedColumns":["Model"]},{"number":"78.4","isBolded":false,"associatedRows":["GENELIEX"],"associatedColumns":["Amazon","Sent ."],"associatedMergedColumns":["Model"]},{"number":"0.77","isBolded":true,"associatedRows":["GENELIEX"],"associatedColumns":["Yelp","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"78.3","isBolded":false,"associatedRows":["Raw Data"],"associatedColumns":["Amazon","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"84.2","isBolded":true,"associatedRows":["Kobayashi [ 33 ]"],"associatedColumns":["Amazon","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"73.2","isBolded":false,"associatedRows":["GENELIEX"],"associatedColumns":["Amazon","Cohesion"],"associatedMergedColumns":["Model"]},{"number":"83.6","isBolded":false,"associatedRows":["Raw Data"],"associatedColumns":["Amazon","Sent ."],"associatedMergedColumns":["Model"]}]},{"caption":"Table 4: Network architectures for Amazon small dataset and Yelp small dataset . The weight decay \nis set to 10 5 , the learning rate is set to 5  *  10 ?4 , the number of epochs is set to 500 and the batch size \nis set to 64. \n\n","rows":["is set to"],"columns":["Table 4 : Network architectures for Amazon small dataset and Yelp small dataset . The weight decay"],"mergedAllColumns":[],"numberCells":[{"number":"105,thelearningrateissetto5*","isBolded":false,"associatedRows":["is set to"],"associatedColumns":["Table 4 : Network architectures for Amazon small dataset and Yelp small dataset . The weight decay"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":["is set to"],"associatedColumns":["Table 4 : Network architectures for Amazon small dataset and Yelp small dataset . The weight decay"],"associatedMergedColumns":[]}]},{"caption":"LHTR 1 \nLHTR \n\nSizes of the layers ? \n[768,384,200,50,8,1] [768,384,200,100] [768,384,200,150] \nSizes of the layers of C bulk \n\n? \n\n[150,75,8,1] \n[100,50,8,1] \n[150,75,8,1] \nSizes of the layers of C ext \n\n? \n\nX \nX \n[150,75,8,1] \n? 3 \nX \nX \n0.01 \nTable 6: Network architectures for Amazon dataset and Yelp dataset. The weight decay is set to 10 5 , \nthe learning rate is set to 1  *  10 ?4 , the number of epochs is set to 500 and the batch size is set to 256. \n\n","rows":["?","the learning rate is set to","X","LHTR"],"columns":["Sizes of the layers of C bulk","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","Sizes of the layers of C ext","LHTR","Table 6 : Network architectures for Amazon dataset and Yelp dataset . The weight decay is set to 10","Sizes of the layers ?"],"mergedAllColumns":["?"],"numberCells":[{"number":"3","isBolded":false,"associatedRows":["?"],"associatedColumns":["LHTR","Sizes of the layers ?","Sizes of the layers of C bulk","Sizes of the layers of C ext"],"associatedMergedColumns":["?"]},{"number":"1","isBolded":false,"associatedRows":["the learning rate is set to","LHTR"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.01","isBolded":true,"associatedRows":["?","X","X"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]"],"associatedMergedColumns":["?"]},{"number":"1*10?4,thenumberofepochsissetto500andthebatchsizeissetto256.","isBolded":true,"associatedRows":["the learning rate is set to"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]","Table 6 : Network architectures for Amazon dataset and Yelp dataset . The weight decay is set to 10"],"associatedMergedColumns":["?"]},{"number":"5","isBolded":false,"associatedRows":["the learning rate is set to","X"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]"],"associatedMergedColumns":["?"]}]},{"caption":"B.7 Experiments for data generation \n\nB.7.1 Experimental setting \n\nAs mentioned in Section 5.1, hyperparameters for dataset augmentation are detailed in Table 7. For \n","rows":["?","the learning rate is set to","X","LHTR"],"columns":["Sizes of the layers of C bulk","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","Sizes of the layers of C ext","LHTR","Table 6 : Network architectures for Amazon dataset and Yelp dataset . The weight decay is set to 10","Sizes of the layers ?"],"mergedAllColumns":["?"],"numberCells":[{"number":"1","isBolded":false,"associatedRows":["the learning rate is set to","LHTR"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":["the learning rate is set to","X"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]"],"associatedMergedColumns":["?"]},{"number":"0.01","isBolded":true,"associatedRows":["?","X","X"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]"],"associatedMergedColumns":["?"]},{"number":"3","isBolded":false,"associatedRows":["?"],"associatedColumns":["LHTR","Sizes of the layers ?","Sizes of the layers of C bulk","Sizes of the layers of C ext"],"associatedMergedColumns":["?"]},{"number":"1*10?4,thenumberofepochsissetto500andthebatchsizeissetto256.","isBolded":true,"associatedRows":["the learning rate is set to"],"associatedColumns":["LHTR","[ 768 , 384 , 200 , 150 ]","[ 150 , 75 , 8 , 1 ]","[ 150 , 75 , 8 , 1 ]","Table 6 : Network architectures for Amazon dataset and Yelp dataset . The weight decay is set to 10"],"associatedMergedColumns":["?"]}]}]