[{"caption":"TABLE 1: Ablation study of tracking performance with \ndifferent methods on nuScenes validation set. Results in \n(a) suggest that the deep feature affinity matrix contributes \nto data association. From (b), we observe a robust trend that \na motion model with a higher frame rate image sequence \nencourages tracking performance. \n\n","rows":["-","KF3D"],"columns":["AMOTP ?","( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"mergedAllColumns":["( b ) Ablation study of full frames .","KF3D"],"numberCells":[{"number":"1.535","isBolded":false,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?","AMOTP ?"],"associatedMergedColumns":["( b ) Ablation study of full frames ."]},{"number":"1.528","isBolded":false,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?","AMOTP ?"],"associatedMergedColumns":["KF3D"]},{"number":"0.2421","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?","AMOTA@1 ?"],"associatedMergedColumns":["KF3D"]},{"number":"0.2306","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.596","isBolded":false,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.540","isBolded":false,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.2013","isBolded":false,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.535","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.2329","isBolded":false,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?","AMOTA@1 ?"],"associatedMergedColumns":["KF3D"]},{"number":"0.2321","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?","AMOTA@1 ?"],"associatedMergedColumns":["( b ) Ablation study of full frames ."]},{"number":"1.535","isBolded":true,"associatedRows":["KF3D","-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.535","isBolded":true,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.2301","isBolded":false,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.1779","isBolded":false,"associatedRows":["-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.2213","isBolded":false,"associatedRows":["KF3D","-","-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.530","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?","AMOTP ?"],"associatedMergedColumns":["( b ) Ablation study of full frames ."]},{"number":"0.2306","isBolded":false,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTA@1 ?","AMOTA@1 ?"],"associatedMergedColumns":["( b ) Ablation study of full frames ."]},{"number":"1.518","isBolded":true,"associatedRows":["-"],"associatedColumns":["( a ) Ablation study of dropping affinity matrix .","AMOTP ?","AMOTP ?"],"associatedMergedColumns":["KF3D"]}]},{"caption":"TABLE 2: Tracking performance comparison with different \ndesigns of affinity matrix on nuScenes validation set. \nResults suggest that using 3D IoU and motion-based sub-\naffinity matrix yielding the best validation performance of \nour final pipeline. \n\n","rows":["3D","2D","BEV","motion","centroid","cosine"],"columns":["AMOTP ?","AMOTA@1 ?"],"mergedAllColumns":[],"numberCells":[{"number":"1.534","isBolded":true,"associatedRows":["BEV","cosine"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.1929","isBolded":false,"associatedRows":["BEV","motion"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.2234","isBolded":false,"associatedRows":["BEV","cosine"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.2306","isBolded":true,"associatedRows":["3D","centroid"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.1381","isBolded":false,"associatedRows":["2D","motion"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.2300","isBolded":false,"associatedRows":["3D","centroid"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.535","isBolded":false,"associatedRows":["BEV","motion"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.536","isBolded":false,"associatedRows":["3D","centroid"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.599","isBolded":false,"associatedRows":["BEV","motion"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.535","isBolded":true,"associatedRows":["3D","centroid"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.674","isBolded":false,"associatedRows":["2D","motion"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.2306","isBolded":true,"associatedRows":["3D","motion"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 3: Importance of using projection of 3D bounding \nbox center estimation on KITTI sub-validation set. We \nevaluate our KF3D model using different center inputs C \non the Car category to reveal the importance of estimating \nthe projection of a 3D center. The increase of MOTA and \nhigher 3D IoU AP with COCO (50 : 5 : 95) suggest that the \nprojection of a 3D center benefits our tracking pipeline over \nthe 2D center. \n\n","rows":["0 - 50m","0 - 30m","Easy","Medium","Hard","3D Cen","0 - 100m","2D Cen"],"columns":["?","3d","bev","MOTA ?","C ?"],"mergedAllColumns":[],"numberCells":[{"number":"41.71","isBolded":true,"associatedRows":["3D Cen","0 - 30m","Easy"],"associatedColumns":["bev"],"associatedMergedColumns":[]},{"number":"70.78","isBolded":false,"associatedRows":["2D Cen","0 - 50m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"23.53","isBolded":false,"associatedRows":["2D Cen","0 - 50m","Medium"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"36.74","isBolded":true,"associatedRows":["3D Cen","0 - 30m","Easy"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"66.77","isBolded":true,"associatedRows":["3D Cen","0 - 100m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"79.50","isBolded":true,"associatedRows":["3D Cen","0 - 30m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"21.99","isBolded":false,"associatedRows":["2D Cen","0 - 100m","Hard"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"24.91","isBolded":false,"associatedRows":["2D Cen","0 - 30m","Easy"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"15.87","isBolded":false,"associatedRows":["2D Cen","0 - 50m","Medium"],"associatedColumns":["3d"],"associatedMergedColumns":[]},{"number":"14.99","isBolded":false,"associatedRows":["2D Cen","0 - 100m","Hard"],"associatedColumns":["3d"],"associatedMergedColumns":[]},{"number":"33.73","isBolded":true,"associatedRows":["3D Cen","0 - 50m","Medium"],"associatedColumns":["bev"],"associatedMergedColumns":[]},{"number":"0.60","isBolded":false,"associatedRows":["2D Cen","0 - 50m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"29.30","isBolded":true,"associatedRows":["3D Cen","0 - 50m","Medium"],"associatedColumns":["?"],"associatedMergedColumns":[]},{"number":"72.53","isBolded":true,"associatedRows":["3D Cen","0 - 50m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"31.05","isBolded":true,"associatedRows":["3D Cen","0 - 100m","Hard"],"associatedColumns":["bev"],"associatedMergedColumns":[]},{"number":"0.54","isBolded":true,"associatedRows":["3D Cen","0 - 100m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"65.15","isBolded":false,"associatedRows":["2D Cen","0 - 100m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"77.28","isBolded":false,"associatedRows":["2D Cen","0 - 30m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"15.11","isBolded":false,"associatedRows":["2D Cen","0 - 30m","Easy"],"associatedColumns":["3d"],"associatedMergedColumns":[]},{"number":"0.44","isBolded":true,"associatedRows":["3D Cen","0 - 30m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"0.51","isBolded":true,"associatedRows":["3D Cen","0 - 50m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"0.62","isBolded":false,"associatedRows":["2D Cen","0 - 100m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"0.56","isBolded":false,"associatedRows":["2D Cen","0 - 30m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"26.67","isBolded":true,"associatedRows":["3D Cen","0 - 100m","Hard"],"associatedColumns":["?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 4: Comparison of location refinement with dif-\nferent motion model on nuScenes validation set. Result \nsuggests the VeloLSTM achieves the highest performance \namong the other methods. Besides, employing a motion \nmodel benefits 3D detection and tracking. We use full frames \nand final affinity matrices. \n\n","rows":["VeloLSTM","Momentum","Detection","KF3D"],"columns":["AMOTP ?","NDS","AMOTA@1 ?"],"mergedAllColumns":[],"numberCells":[{"number":"0.222","isBolded":false,"associatedRows":["Detection"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.3620","isBolded":false,"associatedRows":["Momentum"],"associatedColumns":["NDS"],"associatedMergedColumns":[]},{"number":"1.530","isBolded":false,"associatedRows":["KF3D"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.242","isBolded":true,"associatedRows":["VeloLSTM"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.518","isBolded":true,"associatedRows":["VeloLSTM"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.227","isBolded":false,"associatedRows":["Momentum"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.532","isBolded":false,"associatedRows":["Momentum"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.3666","isBolded":true,"associatedRows":["VeloLSTM"],"associatedColumns":["NDS"],"associatedMergedColumns":[]},{"number":"0.3634","isBolded":false,"associatedRows":["KF3D"],"associatedColumns":["NDS"],"associatedMergedColumns":[]},{"number":"0.232","isBolded":false,"associatedRows":["KF3D"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.3622","isBolded":false,"associatedRows":["Detection"],"associatedColumns":["NDS"],"associatedMergedColumns":[]},{"number":"1.538","isBolded":false,"associatedRows":["Detection"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 5: Tracking performance on the testing set of \nnuScenes tracking benchmark [61]. We report the average \nAMOTA@1 and AMOTP over 7 categories on the bench-\nmark with only published methods shown. Our quasi-dense \n3D tracking pipeline outperforms the best camera-based \nsubmission (underlined) by near 500% while bridging the \ngap to LiDAR-based methods on the nuScenes 3D tracking \nbenchmark. \n\n","rows":["LiDAR + Camera","Mapillary - AB3DMOT [ 61 ]","LiDAR","QD3DT ( Ours )","Camera","CenterTrack - Open [ 57 ]","PointPillars - AB3DMOT [ 61 ]","CenterTrack - Vision [ 57 ]","Megvii - AB3DMOT [ 61 ]"],"columns":["AMOTP ?","AMOTA@1 ?"],"mergedAllColumns":[],"numberCells":[{"number":"1.501","isBolded":false,"associatedRows":["Megvii - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.703","isBolded":false,"associatedRows":["PointPillars - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.217","isBolded":true,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.989","isBolded":true,"associatedRows":["CenterTrack - Open [ 57 ]","LiDAR + Camera"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"1.543","isBolded":false,"associatedRows":["CenterTrack - Vision [ 57 ]","Camera"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.029","isBolded":false,"associatedRows":["PointPillars - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.151","isBolded":false,"associatedRows":["Megvii - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.108","isBolded":false,"associatedRows":["CenterTrack - Open [ 57 ]","LiDAR + Camera"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.790","isBolded":false,"associatedRows":["Mapillary - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.046","isBolded":false,"associatedRows":["CenterTrack - Vision [ 57 ]","Camera"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"1.550","isBolded":false,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["AMOTP ?"],"associatedMergedColumns":[]},{"number":"0.018","isBolded":false,"associatedRows":["Mapillary - AB3DMOT [ 61 ]","LiDAR"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 6: 3D detection and tracking performance in Vehi-\ncle Level 2 difficulty on the testing set of Waymo dataset. \nOur pipeline serves as a strong baseline with non-zero \nscores using only camera modality in the 3D detection and \ntracking challenge on LiDAR-dominated benchmark. \n\n","rows":["PV - RCNN [ 93 ]","Lidar+Camera","CenterPoint [ 56 ]","Lidar","QD3DT ( Ours )","pillars kf baseline [ 63 ]","HorizonMOT3D [ 92 ]","Camera"],"columns":["mAP ?","MOTP ?","mAPH ?","MOTA ?","( a ) 3D Tracking Performance"],"mergedAllColumns":["( b ) 3D Detection Performance ."],"numberCells":[{"number":"0.0001","isBolded":false,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?"],"associatedMergedColumns":[]},{"number":"0.7783","isBolded":false,"associatedRows":["HorizonMOT3D [ 92 ]","Lidar+Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?","mAPH ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.4008","isBolded":false,"associatedRows":["pillars kf baseline [ 63 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?"],"associatedMergedColumns":[]},{"number":"0.0233","isBolded":false,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?","mAPH ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.7823","isBolded":false,"associatedRows":["HorizonMOT3D [ 92 ]","Lidar+Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?","mAP ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.0242","isBolded":false,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?","mAP ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.7369","isBolded":false,"associatedRows":["PV - RCNN [ 93 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?","mAP ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.1577","isBolded":false,"associatedRows":["HorizonMOT3D [ 92 ]","Lidar+Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?"],"associatedMergedColumns":[]},{"number":"0.5938","isBolded":false,"associatedRows":["CenterPoint [ 56 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?"],"associatedMergedColumns":[]},{"number":"0.1856","isBolded":false,"associatedRows":["pillars kf baseline [ 63 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?"],"associatedMergedColumns":[]},{"number":"0.7299","isBolded":false,"associatedRows":["CenterPoint [ 56 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?","mAPH ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.6407","isBolded":false,"associatedRows":["HorizonMOT3D [ 92 ]","Lidar+Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?"],"associatedMergedColumns":[]},{"number":"0.1637","isBolded":false,"associatedRows":["CenterPoint [ 56 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?"],"associatedMergedColumns":[]},{"number":"0.7323","isBolded":false,"associatedRows":["PV - RCNN [ 93 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTA ?","mAPH ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.7342","isBolded":false,"associatedRows":["CenterPoint [ 56 ]","Lidar"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?","mAP ?"],"associatedMergedColumns":["( b ) 3D Detection Performance ."]},{"number":"0.0658","isBolded":false,"associatedRows":["QD3DT ( Ours )","Camera"],"associatedColumns":["( a ) 3D Tracking Performance","MOTP ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 7: 3D detection and tracking performance in Ve-\nhicle Level 2 difficulty on the validation set of Waymo \ndataset. We compare 3D detection and tracking results on \ndifferent extent of the observable area. LiDAR-based GT \ncovers a 360-degree area, while camera-based GT filters \nout annotations outside of camera view. MOTA and mAPH \nincrease greatly while lowering IoU thresholds slightly. \n\n","rows":["Overall","2 . 8e - 06","LiDAR - based GT","Camera - based GT","1 . 8e - 06"],"columns":["mAPH ?","MOTA ?","IoU"],"mergedAllColumns":[],"numberCells":[{"number":"0.0195","isBolded":false,"associatedRows":["LiDAR - based GT","Overall"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.1183","isBolded":false,"associatedRows":["LiDAR - based GT","Overall"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.1743","isBolded":false,"associatedRows":["Camera - based GT","Overall","2 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["LiDAR - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.0308","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["LiDAR - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.1161","isBolded":false,"associatedRows":["LiDAR - based GT","Overall","1 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.0286","isBolded":false,"associatedRows":["Camera - based GT","Overall","1 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.3401","isBolded":false,"associatedRows":["Camera - based GT","Overall","1 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["IoU"],"associatedMergedColumns":[]},{"number":"0.2242","isBolded":false,"associatedRows":["LiDAR - based GT","Overall","1 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]},{"number":"0.1867","isBolded":false,"associatedRows":["Camera - based GT","Overall"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.0408","isBolded":false,"associatedRows":["Camera - based GT","Overall","2 . 8e - 06"],"associatedColumns":["mAPH ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 8: Centroid-based evaluation across datasets. This \nexperiment uses our final model and the full frames setting \nfor nuScenes. We evaluate the results in different datasets to \nreveal the importance of choosing evaluation metrics. The \nsimilarity of MOTA and MOTP performance suggests that \nour pipeline has been well trained and performs equally \nwell on the Waymo Open dataset. \n\n","rows":["0 - 50m","nuScenes","0 - 30m","Waymo","0 - 100m"],"columns":["O ?","MOTA ?","C ?","MOTP I ?"],"mergedAllColumns":[],"numberCells":[{"number":"0.18","isBolded":false,"associatedRows":["Waymo","0 - 50m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"14.84","isBolded":false,"associatedRows":["nuScenes","0 - 50m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"0.75","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"14.66","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"0.18","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["nuScenes","0 - 50m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"15.05","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"18.66","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"12.14","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.73","isBolded":false,"associatedRows":["nuScenes","0 - 50m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"17.63","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"14.18","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"25.93","isBolded":false,"associatedRows":["nuScenes","0 - 50m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"16.10","isBolded":false,"associatedRows":["Waymo","0 - 50m"],"associatedColumns":["O ?"],"associatedMergedColumns":[]},{"number":"57.33","isBolded":false,"associatedRows":["Waymo","0 - 30m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"44.47","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.79","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["nuScenes","0 - 100m"],"associatedColumns":["MOTP I ?"],"associatedMergedColumns":[]},{"number":"0.64","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"0.74","isBolded":false,"associatedRows":["Waymo","0 - 50m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]},{"number":"36.87","isBolded":false,"associatedRows":["Waymo","0 - 50m"],"associatedColumns":["MOTA ?"],"associatedMergedColumns":[]},{"number":"0.61","isBolded":false,"associatedRows":["nuScenes","0 - 30m"],"associatedColumns":["C ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 9: Performance of 3D estimation on object detec-\ntion IoU mAP. The evaluation demonstrates the effective-\nness of our model from each separate metric. With different \namounts of training data in our GTA dataset, the results \nsuggest that large data capacity benefits the performance of \na data-hungry network. \n\n","rows":["100%","1%","GTA","10%"],"columns":["3d","AP 70","bev","aos","Medium","bbox"],"mergedAllColumns":[],"numberCells":[{"number":"91.66","isBolded":false,"associatedRows":["GTA","10%"],"associatedColumns":["Medium","AP 70","bbox"],"associatedMergedColumns":[]},{"number":"4.10","isBolded":false,"associatedRows":["1%"],"associatedColumns":["Medium","AP 70","bev"],"associatedMergedColumns":[]},{"number":"90.83","isBolded":false,"associatedRows":["GTA","10%"],"associatedColumns":["Medium","AP 70","aos"],"associatedMergedColumns":[]},{"number":"78.18","isBolded":false,"associatedRows":["1%"],"associatedColumns":["Medium","AP 70","bbox"],"associatedMergedColumns":[]},{"number":"94.62","isBolded":true,"associatedRows":["100%","10%"],"associatedColumns":["Medium","AP 70","bbox"],"associatedMergedColumns":[]},{"number":"75.59","isBolded":false,"associatedRows":["1%"],"associatedColumns":["Medium","AP 70","aos"],"associatedMergedColumns":[]},{"number":"15.63","isBolded":true,"associatedRows":["100%","10%"],"associatedColumns":["Medium","AP 70","3d"],"associatedMergedColumns":[]},{"number":"21.61","isBolded":true,"associatedRows":["100%","10%"],"associatedColumns":["Medium","AP 70","bev"],"associatedMergedColumns":[]},{"number":"94.23","isBolded":true,"associatedRows":["100%","10%"],"associatedColumns":["Medium","AP 70","aos"],"associatedMergedColumns":[]},{"number":"1.31","isBolded":false,"associatedRows":["1%"],"associatedColumns":["Medium","AP 70","3d"],"associatedMergedColumns":[]},{"number":"14.61","isBolded":false,"associatedRows":["GTA","10%"],"associatedColumns":["Medium","AP 70","bev"],"associatedMergedColumns":[]},{"number":"8.45","isBolded":false,"associatedRows":["GTA","10%"],"associatedColumns":["Medium","AP 70","3d"],"associatedMergedColumns":[]}]},{"caption":"TABLE 10: Comparison of the different matching algo-\nrithms on nuScenes validation set. We use only keyframes \nand all affinity matrices as our setting. We found that using \ngreedy matching yields similar results to the Hungarian \nmatching but with less computation complexity on well-\ntrained quasi-dense embedding pairs. \n\n","rows":["Hungarian [ 77 ]","Greedy"],"columns":["AMOTA@0 . 2 ?","AMOTA@1 ?"],"mergedAllColumns":[],"numberCells":[{"number":"0.230","isBolded":false,"associatedRows":["Greedy"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.230","isBolded":false,"associatedRows":["Hungarian [ 77 ]"],"associatedColumns":["AMOTA@1 ?"],"associatedMergedColumns":[]},{"number":"0.3479","isBolded":false,"associatedRows":["Hungarian [ 77 ]"],"associatedColumns":["AMOTA@0 . 2 ?"],"associatedMergedColumns":[]},{"number":"0.3479","isBolded":false,"associatedRows":["Greedy"],"associatedColumns":["AMOTA@0 . 2 ?"],"associatedMergedColumns":[]}]},{"caption":"TABLE 12: Inference Time (second) of our proposed frame-\nwork on KITTI tracking benchmark. We recorded the wall \nclock of the execution time consumption of each module, \nwhich might have slight overhead, e.g., functions with result \ndumping. Bold fonts are the summation of each sub-module \nand misc. time. Note that elapsed time for object detection \nis not included in the specified runtime of the KITTI bench-\nmark. \n\n","rows":["Greedy Matching","2D Box , 3D Estimation","3D transform","Tracking","Reprojection ( world to img )","Total","Misc .","LSTM Predict","LSTM Update","Detection","Contrastive Feature","3D Lifting ( img to world )"],"columns":["Second"],"mergedAllColumns":[],"numberCells":[{"number":"0.0019","isBolded":false,"associatedRows":["Greedy Matching"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0123","isBolded":false,"associatedRows":["3D Lifting ( img to world )"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0019","isBolded":false,"associatedRows":["Reprojection ( world to img )"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0076","isBolded":false,"associatedRows":["LSTM Predict"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0009","isBolded":false,"associatedRows":["LSTM Update"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.1620","isBolded":true,"associatedRows":["Total"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0222","isBolded":true,"associatedRows":["Tracking"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.1233","isBolded":false,"associatedRows":["2D Box , 3D Estimation"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.1256","isBolded":true,"associatedRows":["Detection"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0118","isBolded":false,"associatedRows":["Misc ."],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0023","isBolded":false,"associatedRows":["Contrastive Feature"],"associatedColumns":["Second"],"associatedMergedColumns":[]},{"number":"0.0142","isBolded":true,"associatedRows":["3D transform"],"associatedColumns":["Second"],"associatedMergedColumns":[]}]}]