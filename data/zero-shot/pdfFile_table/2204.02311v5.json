[{"caption":"Table 1. The \nthree models were trained identically (except batch size) using the same data and vocabulary. Training is \ndescribed in more detail in Sections 3 and 5. \n\n","rows":["PaLM 540B","18432","PaLM 8B","48","16","118","512 ?","64","32","PaLM 62B"],"columns":["d model","# of Parameters","Batch Size"],"mergedAllColumns":["( in billions )","256 ? 512"],"numberCells":[{"number":"540.35","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"1024?","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]},{"number":"4096","isBolded":false,"associatedRows":["PaLM 8B","32","16"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["( in billions )"]},{"number":"8.63","isBolded":false,"associatedRows":["PaLM 8B","32","16"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["( in billions )"]},{"number":"62.50","isBolded":false,"associatedRows":["PaLM 62B","64","32"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"1024","isBolded":false,"associatedRows":["PaLM 62B","64","32","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]},{"number":"8192","isBolded":false,"associatedRows":["PaLM 62B","64","32"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"2048","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]}]},{"caption":"Model \nLayers # of Heads d model \n# of Parameters \n(in billions) \nBatch Size \n\nPaLM 8B \n32 \n16 \n4096 \n8.63 \n256 ? 512 \nPaLM 62B \n64 \n32 \n8192 \n62.50 \n512 ? 1024 \nPaLM 540B \n118 \n48 \n18432 \n540.35 \n512 ? 1024 ? 2048 \n\nTable 1: Model architecture details. We list the number of layers, d model , the number of attention heads and \nattention head size. The feed-forward size d ff is always 4 ? d model and attention head size is always 256. \n\n","rows":["PaLM 540B","18432","PaLM 8B","48","16","118","512 ?","64","32","PaLM 62B"],"columns":["d model","# of Parameters","Batch Size"],"mergedAllColumns":["( in billions )","256 ? 512"],"numberCells":[{"number":"8.63","isBolded":false,"associatedRows":["PaLM 8B","32","16"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["( in billions )"]},{"number":"540.35","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"2048","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]},{"number":"62.50","isBolded":false,"associatedRows":["PaLM 62B","64","32"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"8192","isBolded":false,"associatedRows":["PaLM 62B","64","32"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["256 ? 512"]},{"number":"1024?","isBolded":false,"associatedRows":["PaLM 540B","118","48","18432","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]},{"number":"4096","isBolded":false,"associatedRows":["PaLM 8B","32","16"],"associatedColumns":["# of Parameters","d model"],"associatedMergedColumns":["( in billions )"]},{"number":"1024","isBolded":false,"associatedRows":["PaLM 62B","64","32","512 ?"],"associatedColumns":["# of Parameters","Batch Size"],"associatedMergedColumns":["256 ? 512"]}]},{"caption":"Table 3: Model FLOPs utilization of PaLM and prior large models. PaLM achieves a notably high MFU \nbecause of several optimizations across the model, compiler, and parallelism strategy. The corresponding \nhardware FLOPs utilization of PaLM is 57.8%. Details of the calculation are in Appendix B. \n\n","rows":["2240 A100","175B","Gopher","GPT - 3","PaLM","6144 TPU v4","530B","4096 TPU v3","540B","V100","Megatron - Turing NLG","280B"],"columns":["Accelerator chips","utilization","Model FLOPS"],"mergedAllColumns":[],"numberCells":[{"number":"21.3%","isBolded":false,"associatedRows":["GPT - 3","175B","V100"],"associatedColumns":["Model FLOPS","Accelerator chips","utilization"],"associatedMergedColumns":[]},{"number":"30.2%","isBolded":false,"associatedRows":["Megatron - Turing NLG","530B","2240 A100"],"associatedColumns":["Model FLOPS","Accelerator chips","utilization"],"associatedMergedColumns":[]},{"number":"46.2%","isBolded":false,"associatedRows":["PaLM","540B","6144 TPU v4"],"associatedColumns":["Model FLOPS","Accelerator chips","utilization"],"associatedMergedColumns":[]},{"number":"32.5%","isBolded":false,"associatedRows":["Gopher","280B","4096 TPU v3"],"associatedColumns":["Model FLOPS","Accelerator chips","utilization"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Results obtained by the PaLM 540B model across 29 NLP benchmarks. For the few-shot results, the \nnumber of shots for each task are mentioned in parenthesis. The splits for each task are the same ones used in \nDu et al. (2021) and Brown et al. (2020). Superscripts denote results from past work: a GLaM 62B/64E (Du \net al., 2021), b GPT-3 175B (Brown et al., 2020), c Megatron-Turing NLG 530B (Smith et al., 2022), d Gopher \n(Rae et al., 2021), e LaMDA (Thoppilan et al., 2022) (results reported from Wei et al. (2022a), f Chinchilla \n","rows":["SQuADv2 ( F1 )","RTE","CoQA ( F1 )","( 5 )","SQuADv2 ( EM )","ANLI R3","ANLI R2","OpenbookQA","ANLI R1","Drop ( F1 )","ReCoRD","HellaSwag","QuAC ( F1 )","WiC","BoolQ","Multirc ( F1a )","Copa","Web Questions ( EM )","Winogrande","CB","a","b","RACE - h","ARC - c","StoryCloze","ARC - e","e","f","WSC","Natural Questions ( EM )","PIQA","Lambada ( EM )","RACE - m","TriviaQA ( EM )","Winograd"],"columns":["b","Prior","PaLM","540B","Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","SOTA","1 - shot","Few - shot"],"mergedAllColumns":["Task"],"numberCells":[{"number":"42.4a","isBolded":false,"associatedRows":["ANLI R1","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"21.2","isBolded":false,"associatedRows":["Natural Questions ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"51.8","isBolded":false,"associatedRows":["CB","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"73.3","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"88.7","isBolded":false,"associatedRows":["BoolQ","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"58.5c(32)","isBolded":false,"associatedRows":["WiC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"74.7a","isBolded":false,"associatedRows":["Multirc ( F1a )","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"90.3a","isBolded":false,"associatedRows":["ReCoRD","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"41.5b","isBolded":false,"associatedRows":["QuAC ( F1 )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"53.4","isBolded":false,"associatedRows":["OpenbookQA","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"44.2","isBolded":false,"associatedRows":["ANLI R2","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"52.0a(3)","isBolded":false,"associatedRows":["ARC - c","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"47.7","isBolded":false,"associatedRows":["QuAC ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"54.6(5)","isBolded":false,"associatedRows":["RACE - h","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"78.7","isBolded":false,"associatedRows":["RTE","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"47.7(1)","isBolded":false,"associatedRows":["QuAC ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"87.5","isBolded":false,"associatedRows":["Winograd","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"78.7","isBolded":false,"associatedRows":["SQuADv2 ( EM )","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"41.1b(64)","isBolded":false,"associatedRows":["Web Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"74.9","isBolded":false,"associatedRows":["Winogrande"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"43.4b","isBolded":false,"associatedRows":["QuAC ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"68.1","isBolded":false,"associatedRows":["RACE - m","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"44.3b(5)","isBolded":false,"associatedRows":["QuAC ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"88.0","isBolded":false,"associatedRows":["BoolQ","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"50.3a","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"72.9","isBolded":false,"associatedRows":["RTE","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"82.0c","isBolded":false,"associatedRows":["PIQA"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"83.2c(5)","isBolded":false,"associatedRows":["PIQA","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"81.2(5)","isBolded":false,"associatedRows":["RTE","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"57.6","isBolded":false,"associatedRows":["OpenbookQA"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"82.9","isBolded":false,"associatedRows":["SQuADv2 ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"86.1","isBolded":false,"associatedRows":["StoryCloze","b","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"77.5a(4)","isBolded":false,"associatedRows":["Multirc ( F1a )","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"92.8","isBolded":false,"associatedRows":["ReCoRD","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"81.1","isBolded":false,"associatedRows":["Winogrande","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"81.4a","isBolded":false,"associatedRows":["PIQA","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"92.9(2)","isBolded":false,"associatedRows":["ReCoRD","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"52.6","isBolded":false,"associatedRows":["ANLI R1","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"57.8a","isBolded":false,"associatedRows":["Drop ( F1 )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"89.4(5)","isBolded":false,"associatedRows":["Winograd","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"80.2c","isBolded":false,"associatedRows":["HellaSwag","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"56.1(5)","isBolded":false,"associatedRows":["ANLI R2","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"45.2","isBolded":false,"associatedRows":["QuAC ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"19.0","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"48.7","isBolded":false,"associatedRows":["ANLI R2","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"22.6","isBolded":false,"associatedRows":["Web Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"84.8a(8)","isBolded":false,"associatedRows":["CB","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"85.1(5)","isBolded":false,"associatedRows":["Winogrande","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"49.1","isBolded":false,"associatedRows":["RACE - h","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"52.1","isBolded":false,"associatedRows":["RACE - h","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"84.6","isBolded":false,"associatedRows":["StoryCloze","b","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"79.9","isBolded":false,"associatedRows":["CoQA ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"65.4b(100)","isBolded":false,"associatedRows":["OpenbookQA","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"83.7","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"76.9","isBolded":false,"associatedRows":["TriviaQA ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"41.2a(10)","isBolded":false,"associatedRows":["ANLI R2","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"80.8","isBolded":false,"associatedRows":["SQuADv2 ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"71.5a","isBolded":false,"associatedRows":["RTE","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"40.8a","isBolded":false,"associatedRows":["ANLI R3","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"76.6","isBolded":false,"associatedRows":["ARC - e","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"88.3b","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"86.3(5)","isBolded":false,"associatedRows":["Multirc ( F1a )","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"44.3a(2)","isBolded":false,"associatedRows":["ANLI R1","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"79.2a(16)","isBolded":false,"associatedRows":["Winogrande","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"89.1","isBolded":false,"associatedRows":["WSC","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"48.2a","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"56.9(5)","isBolded":false,"associatedRows":["ANLI R1","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"47.9c","isBolded":false,"associatedRows":["RACE - h"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"76.4e","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"26.3a","isBolded":false,"associatedRows":["Natural Questions ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"88.6a(2)","isBolded":false,"associatedRows":["Winograd","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"70.8","isBolded":false,"associatedRows":["Drop ( F1 )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"87.2c(15)","isBolded":false,"associatedRows":["Lambada ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"83.7","isBolded":false,"associatedRows":["Winogrande","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"85.0","isBolded":false,"associatedRows":["ARC - e","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"89.7(8)","isBolded":false,"associatedRows":["Lambada ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"52.3","isBolded":false,"associatedRows":["ANLI R3","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"25.3","isBolded":false,"associatedRows":["Web Questions ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"89.1(8)","isBolded":false,"associatedRows":["BoolQ","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"81.5","isBolded":false,"associatedRows":["CoQA ( F1 )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"71.1a","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"95.0(5)","isBolded":false,"associatedRows":["Copa","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"84.9","isBolded":false,"associatedRows":["Multirc ( F1a )","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"89.0(5)","isBolded":false,"associatedRows":["StoryCloze","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"57.3a","isBolded":false,"associatedRows":["Drop ( F1 )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"66.5a","isBolded":false,"associatedRows":["SQuADv2 ( EM )","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"65.9(5)","isBolded":false,"associatedRows":["ARC - c","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"43.5(64)","isBolded":false,"associatedRows":["Web Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"89.3(5)","isBolded":false,"associatedRows":["CB","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"83.2","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"87.7b(70)","isBolded":false,"associatedRows":["StoryCloze","b","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"84.8c(32)","isBolded":false,"associatedRows":["BoolQ","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"82.3","isBolded":false,"associatedRows":["PIQA","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"64.7a","isBolded":false,"associatedRows":["SQuADv2 ( EM )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"92.0a","isBolded":false,"associatedRows":["Copa","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"91.0","isBolded":false,"associatedRows":["Copa","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"66.9a?(8)","isBolded":false,"associatedRows":["RACE - m","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"93.0","isBolded":false,"associatedRows":["Copa","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"48.4","isBolded":false,"associatedRows":["ANLI R1","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"44.7a(4)","isBolded":false,"associatedRows":["ANLI R3","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"29.3","isBolded":false,"associatedRows":["Natural Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"73.7c","isBolded":false,"associatedRows":["Winogrande","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"75.5","isBolded":false,"associatedRows":["SQuADv2 ( EM )","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"90.3a","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"40.0a","isBolded":false,"associatedRows":["ANLI R2","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"80.8","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"88.4(5)","isBolded":false,"associatedRows":["ARC - e","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"52.7a","isBolded":false,"associatedRows":["WiC","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"63.2","isBolded":false,"associatedRows":["WiC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"77.9","isBolded":false,"associatedRows":["Lambada ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"64.0a","isBolded":false,"associatedRows":["RACE - m"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"73.7a","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"68.0(32)","isBolded":false,"associatedRows":["OpenbookQA","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"84.0","isBolded":false,"associatedRows":["CoQA ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"83.3(5)","isBolded":false,"associatedRows":["SQuADv2 ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"83.8(5)","isBolded":false,"associatedRows":["HellaSwag","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"75.8a","isBolded":false,"associatedRows":["TriviaQA ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"39.6(64)","isBolded":false,"associatedRows":["Natural Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"49.3a?(2)","isBolded":false,"associatedRows":["RACE - h","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"80.9e(10)","isBolded":false,"associatedRows":["ARC - e","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"93.0a(16)","isBolded":false,"associatedRows":["Copa","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"85.0","isBolded":false,"associatedRows":["CoQA ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"64.6(5)","isBolded":false,"associatedRows":["WiC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"83.4","isBolded":false,"associatedRows":["HellaSwag","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"81.8","isBolded":false,"associatedRows":["Lambada ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"71.3a","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"39.2a","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"41.3a","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"39.9e","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"72.1(8)","isBolded":false,"associatedRows":["RACE - m","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"85.3a","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"83.6","isBolded":false,"associatedRows":["HellaSwag","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"81.4(1)","isBolded":false,"associatedRows":["TriviaQA ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"65.6a","isBolded":false,"associatedRows":["RACE - m","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"83.9a","isBolded":false,"associatedRows":["WSC","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"81.4","isBolded":false,"associatedRows":["TriviaQA ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"80.9a","isBolded":false,"associatedRows":["Lambada ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"67.0a(10)","isBolded":false,"associatedRows":["SQuADv2 ( EM )","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"10.6","isBolded":false,"associatedRows":["Web Questions ( EM )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"82.4c(20)","isBolded":false,"associatedRows":["HellaSwag","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"92.9","isBolded":false,"associatedRows":["ReCoRD","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"89.7b","isBolded":false,"associatedRows":["Winograd","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"85.6a(2)","isBolded":false,"associatedRows":["WSC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"89.5(5)","isBolded":false,"associatedRows":["WSC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"48.7a","isBolded":false,"associatedRows":["RACE - h","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"71.8a","isBolded":false,"associatedRows":["SQuADv2 ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"55.8","isBolded":false,"associatedRows":["OpenbookQA","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"77.6","isBolded":false,"associatedRows":["CoQA ( F1 )","f","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"53.0","isBolded":false,"associatedRows":["ARC - c","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"60.1","isBolded":false,"associatedRows":["ARC - c","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"86.3","isBolded":false,"associatedRows":["WSC","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"24.7","isBolded":false,"associatedRows":["Natural Questions ( EM )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"77.7f","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"82.8a","isBolded":false,"associatedRows":["BoolQ","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"83.9","isBolded":false,"associatedRows":["PIQA","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"71.8a(10)","isBolded":false,"associatedRows":["SQuADv2 ( F1 )","f","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"90.6(2)","isBolded":false,"associatedRows":["ReCoRD","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"70.8(1)","isBolded":false,"associatedRows":["Drop ( F1 )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"76.6a","isBolded":false,"associatedRows":["ARC - e","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"69.4","isBolded":false,"associatedRows":["Drop ( F1 )","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"85.2(5)","isBolded":false,"associatedRows":["PIQA","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"83.9","isBolded":false,"associatedRows":["CB","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"79.6(5)","isBolded":false,"associatedRows":["SQuADv2 ( EM )","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"59.1","isBolded":false,"associatedRows":["WiC","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"83.5","isBolded":false,"associatedRows":["Multirc ( F1a )","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"84.7b","isBolded":false,"associatedRows":["StoryCloze","b","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"51.2(5)","isBolded":false,"associatedRows":["ANLI R3","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"76.8(5)","isBolded":false,"associatedRows":["RTE","f","e","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"75.8a(1)","isBolded":false,"associatedRows":["TriviaQA ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"90.1","isBolded":false,"associatedRows":["Winograd","f","a"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"58.6a(2)","isBolded":false,"associatedRows":["Drop ( F1 )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"91.0b","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"53.2b","isBolded":false,"associatedRows":["ARC - c","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"73.2a","isBolded":false,"associatedRows":["CB","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]},{"number":"45.7","isBolded":false,"associatedRows":["ANLI R3","f","e"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"32.5a(1)","isBolded":false,"associatedRows":["Natural Questions ( EM )","f","a","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","Prior","SOTA"],"associatedMergedColumns":["Task"]},{"number":"53.6","isBolded":false,"associatedRows":["OpenbookQA","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"81.5(5)","isBolded":false,"associatedRows":["CoQA ( F1 )","f","b","b","( 5 )"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","Few - shot","PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"69.3","isBolded":false,"associatedRows":["RACE - m","b","b","b"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","1 - shot","PaLM","540B","b"],"associatedMergedColumns":["Task"]},{"number":"51.4","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 5 lists the average scores for the Natural Language Understanding ( NLU ) and Natural Language","0 - shot","Prior","SOTA","b"],"associatedMergedColumns":["Task"]}]},{"caption":"Table 5: Average (Avg) Natural Language Generation (NLG) and Natural Language Understanding (NLU) \nresults across 29 benchmarks using 1-shot evaluation. NLG benchmarks include eight tasks -TriviaQA, NQS, \nWebQS, SQuADv2, LAMBADA, DROP, QuAC and CoQA -while the remaining are NLU benchmarks. \nResults for GPT-3 and GLaM are from Du et al. (2021). \n\n","rows":["PaLM 540B","GLaM 64B / 64E","PaLM 8B","GPT - 3 175B","PaLM 62B"],"columns":["Avg NLU","Avg NLG"],"mergedAllColumns":[],"numberCells":[{"number":"68.7","isBolded":false,"associatedRows":["GLaM 64B / 64E"],"associatedColumns":["Avg NLU"],"associatedMergedColumns":[]},{"number":"67.3","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Avg NLU"],"associatedMergedColumns":[]},{"number":"52.9","isBolded":false,"associatedRows":["GPT - 3 175B"],"associatedColumns":["Avg NLG"],"associatedMergedColumns":[]},{"number":"58.4","isBolded":false,"associatedRows":["GLaM 64B / 64E"],"associatedColumns":["Avg NLG"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Avg NLG"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["GPT - 3 175B"],"associatedColumns":["Avg NLU"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Avg NLG"],"associatedMergedColumns":[]},{"number":"63.9","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["Avg NLG"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Avg NLU"],"associatedMergedColumns":[]},{"number":"74.7","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["Avg NLU"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Results (5-shot) of Chinchilla ","rows":["PaLM 540B","PaLM 8B","Chinchilla 70B ( Prior SOTA )","PaLM 62B"],"columns":["Humanities","Table 6 , PaLM 540B improves the average score of","Social Sciences","Average","STEM","Other"],"mergedAllColumns":["the category for Other tasks ."],"numberCells":[{"number":"73.9","isBolded":true,"associatedRows":["Chinchilla 70B ( Prior SOTA )"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Other"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"25.6","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Humanities"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"79.3","isBolded":false,"associatedRows":["Chinchilla 70B ( Prior SOTA )"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Social Sciences"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"25.3","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Average"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"55.6","isBolded":true,"associatedRows":["PaLM 540B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","STEM"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"41.9","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","STEM"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"77.0","isBolded":true,"associatedRows":["PaLM 540B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Humanities"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"27.8","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Other"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"69.6","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Other"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"24.1","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Social Sciences"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"53.7","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Average"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"67.5","isBolded":false,"associatedRows":["Chinchilla 70B ( Prior SOTA )"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Average"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"23.8","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","STEM"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"54.9","isBolded":false,"associatedRows":["Chinchilla 70B ( Prior SOTA )"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","STEM"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"59.5","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Humanities"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"62.7","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Social Sciences"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"63.6","isBolded":false,"associatedRows":["Chinchilla 70B ( Prior SOTA )"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Humanities"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"81.0","isBolded":true,"associatedRows":["PaLM 540B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Social Sciences"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"55.8","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Other"],"associatedMergedColumns":["the category for Other tasks ."]},{"number":"69.3","isBolded":true,"associatedRows":["PaLM 540B"],"associatedColumns":["Table 6 , PaLM 540B improves the average score of","Average"],"associatedMergedColumns":["the category for Other tasks ."]}]},{"caption":"Table 7: Results on SuperGLUE dev set. We compare with T5-11B (Raffel et al., 2020) and ST-MoE-32B \n(Zoph et al., 2022). Scores reported are the peak validation scores per task. \n\n","rows":["Finetuned","90 . 4 / 69 . 9","T5 - 11B","87 . 4 / 66 . 1","ST - MoE - 32B","86 . 3 / -","93 . 8 / 93 . 2","PaLM 540B ( finetuned )","100 / 100","95 . 0 / 95 . 6","100","94 . 9 / 96 . 4","92 . 9 / -","90 . 1 / 69 . 2","94 . 0 / 94 . 6","95","Few - shot"],"columns":["WiC","BoolQ","RTE","Avg","WSC","Record","CoPA","CB"],"mergedAllColumns":["100"],"numberCells":[{"number":"93.1","isBolded":false,"associatedRows":["ST - MoE - 32B","Few - shot"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot","95","86 . 3 / -","92 . 9 / -","94 . 0 / 94 . 6"],"associatedColumns":["WiC","WSC"],"associatedMergedColumns":["100"]},{"number":"92.2","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Finetuned"],"associatedColumns":["Avg","BoolQ"],"associatedMergedColumns":["100"]},{"number":"78.8","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["WiC"],"associatedMergedColumns":["100"]},{"number":"89.3","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot"],"associatedColumns":["BoolQ","CB"],"associatedMergedColumns":["100"]},{"number":"89.1","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot"],"associatedColumns":["Avg","BoolQ"],"associatedMergedColumns":["100"]},{"number":"95.7","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["RTE"],"associatedMergedColumns":["100"]},{"number":"89.9","isBolded":false,"associatedRows":["T5 - 11B","Few - shot"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"96.2","isBolded":false,"associatedRows":["T5 - 11B","Finetuned","94 . 9 / 96 . 4","100","87 . 4 / 66 . 1","93 . 8 / 93 . 2"],"associatedColumns":["WSC"],"associatedMergedColumns":[]},{"number":"93.2","isBolded":false,"associatedRows":["ST - MoE - 32B","Few - shot"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"98.0","isBolded":false,"associatedRows":["T5 - 11B","Few - shot","94 . 9 / 96 . 4"],"associatedColumns":["CoPA"],"associatedMergedColumns":[]},{"number":"92.6","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot"],"associatedColumns":["Avg"],"associatedMergedColumns":["100"]},{"number":"95.7","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["Record","RTE"],"associatedMergedColumns":["100"]},{"number":"93.9","isBolded":false,"associatedRows":["T5 - 11B","Finetuned","94 . 9 / 96 . 4","100","87 . 4 / 66 . 1","93 . 8 / 93 . 2"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"64.6","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot","95","86 . 3 / -","92 . 9 / -"],"associatedColumns":["RTE","WiC"],"associatedMergedColumns":["100"]},{"number":"78.8","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["RTE","WiC"],"associatedMergedColumns":["100"]},{"number":"81.0","isBolded":false,"associatedRows":["ST - MoE - 32B","Finetuned","100 / 100","100","90 . 4 / 69 . 9","95 . 0 / 95 . 6"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"92.2","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot"],"associatedColumns":["BoolQ"],"associatedMergedColumns":["100"]},{"number":"81.2","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","Few - shot","95","86 . 3 / -","92 . 9 / -"],"associatedColumns":["Record","RTE"],"associatedMergedColumns":["100"]},{"number":"90.8","isBolded":false,"associatedRows":["T5 - 11B","Few - shot"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"77.3","isBolded":false,"associatedRows":["T5 - 11B","Finetuned","94 . 9 / 96 . 4","100","87 . 4 / 66 . 1","93 . 8 / 93 . 2"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"95.7","isBolded":false,"associatedRows":["ST - MoE - 32B","Finetuned","100 / 100","100","90 . 4 / 69 . 9","95 . 0 / 95 . 6"],"associatedColumns":["RTE"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Results on SuperGLUE dev set comparing PaLM-540B few-shot and finetuned. \n\n","rows":["Finetuned","100","92 . 9 / -","86 . 3 / -","90 . 1 / 69 . 2","94 . 0 / 94 . 6","95","100 / 100","Few - shot"],"columns":["WiC","BoolQ","RTE","WSC","CB"],"mergedAllColumns":[],"numberCells":[{"number":"89.1","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"64.6","isBolded":false,"associatedRows":["Few - shot","95","86 . 3 / -","92 . 9 / -"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"81.2","isBolded":false,"associatedRows":["Few - shot","95","86 . 3 / -","92 . 9 / -"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"92.2","isBolded":false,"associatedRows":["Finetuned"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":false,"associatedRows":["Few - shot","95","86 . 3 / -","92 . 9 / -"],"associatedColumns":["WSC"],"associatedMergedColumns":[]},{"number":"95.7","isBolded":false,"associatedRows":["Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"78.8","isBolded":false,"associatedRows":["Finetuned","100 / 100","100","90 . 1 / 69 . 2","94 . 0 / 94 . 6"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"89.3","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":["CB"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Results on SuperGLUE test set (leaderboard). We compare with state-of-the-art span corruption \nbased Encoder-Decoder ","rows":["95 . 1 / 94 . 4","88 . 7 / 63 . 6","94 . 2 / 93 . 3","94 . 4 / 96 . 0","75 . 4 / 30 . 5","91 . 1 / 90 . 2","ST - MoE - 32B","Best Decoder - only LM","PaLM 540B ( finetuned )","96 . 9 / 98 . 0","89 . 6 / 65 . 8","52 . 0 / 75 . 6"],"columns":["WiC","BoolQ","RTE","Avg","WSC","CoPA"],"mergedAllColumns":[],"numberCells":[{"number":"91.2","isBolded":true,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"91.9","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"71.8","isBolded":false,"associatedRows":["Best Decoder - only LM"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"96.6","isBolded":true,"associatedRows":["ST - MoE - 32B","96 . 9 / 98 . 0","89 . 6 / 65 . 8","95 . 1 / 94 . 4"],"associatedColumns":["WSC"],"associatedMergedColumns":[]},{"number":"95.9","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","94 . 4 / 96 . 0","88 . 7 / 63 . 6","94 . 2 / 93 . 3"],"associatedColumns":["WSC"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["Best Decoder - only LM","52 . 0 / 75 . 6","75 . 4 / 30 . 5","91 . 1 / 90 . 2"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"93.5","isBolded":false,"associatedRows":["ST - MoE - 32B","96 . 9 / 98 . 0","89 . 6 / 65 . 8","95 . 1 / 94 . 4"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"80.1","isBolded":false,"associatedRows":["Best Decoder - only LM","52 . 0 / 75 . 6","75 . 4 / 30 . 5","91 . 1 / 90 . 2"],"associatedColumns":["WSC"],"associatedMergedColumns":[]},{"number":"90.4","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"92.0","isBolded":false,"associatedRows":["Best Decoder - only LM","52 . 0 / 75 . 6"],"associatedColumns":["CoPA"],"associatedMergedColumns":[]},{"number":"92.4","isBolded":true,"associatedRows":["ST - MoE - 32B"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"77.7","isBolded":true,"associatedRows":["ST - MoE - 32B","96 . 9 / 98 . 0","89 . 6 / 65 . 8","95 . 1 / 94 . 4"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"99.2","isBolded":true,"associatedRows":["ST - MoE - 32B","96 . 9 / 98 . 0"],"associatedColumns":["CoPA"],"associatedMergedColumns":[]},{"number":"76.4","isBolded":false,"associatedRows":["Best Decoder - only LM"],"associatedColumns":["BoolQ"],"associatedMergedColumns":[]},{"number":"99.0","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","94 . 4 / 96 . 0"],"associatedColumns":["CoPA"],"associatedMergedColumns":[]},{"number":"95.9","isBolded":true,"associatedRows":["PaLM 540B ( finetuned )","94 . 4 / 96 . 0","88 . 7 / 63 . 6","94 . 2 / 93 . 3"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["PaLM 540B ( finetuned )","94 . 4 / 96 . 0","88 . 7 / 63 . 6","94 . 2 / 93 . 3"],"associatedColumns":["WiC"],"associatedMergedColumns":[]},{"number":"49.4","isBolded":false,"associatedRows":["Best Decoder - only LM","52 . 0 / 75 . 6","75 . 4 / 30 . 5","91 . 1 / 90 . 2"],"associatedColumns":["WiC"],"associatedMergedColumns":[]}]},{"caption":"Table 12: Results obtained by the PaLM 540B and PaLM-Coder 540B models across code synthesis and \nsoftware engineering tasks. For the few-shot results, the number of shots for each task are mentioned in \nparenthesis. Superscripts denote results that are quoted from past work: a Chen et al. (2021); b Austin et al. \n(2021); c Lachaux et al. (2020); d Yasunaga \u0026 Liang (2021).  *  Davinci Codex results are our own calculations \nobtained using the OpenAI Codex API and recommended settings for Codex as outlined in Chen et al. (2021). \n\n","rows":["64b","pass@1","8b","pass@100","-","pass@80","GSM8K - Python ( 4 )","0","100","HumanEval ( 0 )","MBPP ( 3 )","535b","DeepFix ( 2 )","80","60","pass@25","GSM8K","Performance","40","20","TransCoder ( 3 )"],"columns":["12B","Code Finetuning","LaMDA","Codex *","Human Eval","TransCoder","MBPP ( pass@80 )","pass@k","Work","137B","Davinci","Human Eval ( pass@100 )","540B","pass@1","DeepFix","Codex","PaLM - Coder","MBPP","100","PaLM","Pretraining only","80","60","TransCoder ( pass@25 )","40","20","Coder 540B","Other"],"mergedAllColumns":["-"],"numberCells":[{"number":"88.4","isBolded":true,"associatedRows":["100","80","HumanEval ( 0 )","pass@100","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0","8b","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *","PaLM - Coder","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"0.8","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0","8b","-","64b","535b","0","8b"],"associatedColumns":["Code Finetuning","Other","Work","PaLM - Coder","pass@1","Human Eval","MBPP","TransCoder","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"82.5","isBolded":true,"associatedRows":["100","80","TransCoder ( 3 )","pass@25","-","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"47.3","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@100"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":[],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP"],"associatedMergedColumns":["-"]},{"number":"0.8","isBolded":false,"associatedRows":["80","64b","80","GSM8K"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP"],"associatedMergedColumns":["-"]},{"number":"0.6","isBolded":false,"associatedRows":["Performance","60","64b","60","Performance"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix"],"associatedMergedColumns":["-"]},{"number":"30.2","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@1"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"55.1","isBolded":true,"associatedRows":["100","80","TransCoder ( 3 )","pass@1","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"0.0","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"50.9","isBolded":false,"associatedRows":["100","80","GSM8K - Python ( 4 )","pass@1","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"44.5c","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@1","-"],"associatedColumns":["Code Finetuning","Other","Work"],"associatedMergedColumns":["-"]},{"number":"0.4","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0","8b","-","64b"],"associatedColumns":["Code Finetuning","Davinci","Coder 540B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"7.6","isBolded":false,"associatedRows":["100","80","GSM8K - Python ( 4 )","pass@1"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"0.2","isBolded":false,"associatedRows":["0","8b"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"71.7d","isBolded":false,"associatedRows":["100","80","DeepFix ( 2 )","pass@1","-"],"associatedColumns":["Code Finetuning","Other","Work"],"associatedMergedColumns":["-"]},{"number":"4.3","isBolded":false,"associatedRows":["100","80","DeepFix ( 2 )","pass@1"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"0.2","isBolded":false,"associatedRows":[],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40"],"associatedMergedColumns":["-"]},{"number":"32.1","isBolded":false,"associatedRows":["100","80","GSM8K - Python ( 4 )","pass@1","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"76.2","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@100"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":[]},{"number":"67.2c","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@25","-","-"],"associatedColumns":["Code Finetuning","Other","Work"],"associatedMergedColumns":["-"]},{"number":"36.0","isBolded":true,"associatedRows":["100","80","HumanEval ( 0 )","pass@1","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"0.0","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )"],"associatedMergedColumns":["-"]},{"number":"36.8","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@1"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"28.8","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@1"],"associatedColumns":["Code Finetuning","Codex","12B"],"associatedMergedColumns":["-"]},{"number":"0.4","isBolded":false,"associatedRows":["0","8b","64b"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"14.8","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@1"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"51.8","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@1"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"79.8","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@25","-"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"0.6","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0","8b","-","64b","535b","0"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"0.0","isBolded":false,"associatedRows":["0"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"0.6","isBolded":false,"associatedRows":["Performance"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix"],"associatedMergedColumns":["-"]},{"number":"0.2","isBolded":false,"associatedRows":["20","64b","20"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix","60","40"],"associatedMergedColumns":["-"]},{"number":"84.4","isBolded":true,"associatedRows":["100","80","MBPP ( 3 )","pass@80","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"82.1","isBolded":true,"associatedRows":["100","80","DeepFix ( 2 )","pass@1","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"1.0","isBolded":false,"associatedRows":[],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM"],"associatedMergedColumns":["-"]},{"number":"47.0","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@1","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"26.2","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@1"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"1.0","isBolded":false,"associatedRows":["100","80","GSM8K - Python ( 4 )","100"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder"],"associatedMergedColumns":["-"]},{"number":"0.4","isBolded":false,"associatedRows":["Performance","40","64b","40","Performance"],"associatedColumns":["Pretraining only","Codex","12B","PaLM - Coder","100","Human Eval","MBPP","TransCoder","80","DeepFix","60"],"associatedMergedColumns":["-"]},{"number":"36.0","isBolded":true,"associatedRows":["100","80","HumanEval ( 0 )","pass@1","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"71.7","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@25","-","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"73.7","isBolded":false,"associatedRows":["100","80","DeepFix ( 2 )","pass@1"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"0.6","isBolded":false,"associatedRows":["0","8b","64b","535b","0"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@1","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"14.0","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@1"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"0.0","isBolded":false,"associatedRows":[],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )"],"associatedMergedColumns":["-"]},{"number":"75.0","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@80"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"1.0","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b","535b","0","8b","-","64b","535b","0","8b","64b"],"associatedColumns":["Code Finetuning","Other","Work","PaLM - Coder","pass@1","Human Eval","MBPP","TransCoder","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"0.8","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@1","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"81.7","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@100","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["0","8b","64b","535b","0","8b","64b"],"associatedColumns":["Pretraining only","PaLM","540B","PaLM","100","Human Eval","MBPP","TransCoder","80","DeepFix","60","40","20","Human Eval ( pass@100 )","MBPP ( pass@80 )","TransCoder ( pass@25 )"],"associatedMergedColumns":["-"]},{"number":"72.3","isBolded":false,"associatedRows":["100","80","HumanEval ( 0 )","pass@100"],"associatedColumns":["Code Finetuning","Codex","12B"],"associatedMergedColumns":[]},{"number":"51.3","isBolded":true,"associatedRows":["100","80","GSM8K - Python ( 4 )","pass@1"],"associatedColumns":["Pretraining only","PaLM","540B"],"associatedMergedColumns":["-"]},{"number":"54.4","isBolded":false,"associatedRows":["100","80","TransCoder ( 3 )","pass@1","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"62.4","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@80"],"associatedColumns":["Pretraining only","LaMDA","137B"],"associatedMergedColumns":["-"]},{"number":"80.8","isBolded":false,"associatedRows":["100","80","MBPP ( 3 )","pass@80","-"],"associatedColumns":["Code Finetuning","PaLM","Coder 540B"],"associatedMergedColumns":["-"]},{"number":"81.1","isBolded":false,"associatedRows":["100","80","DeepFix ( 2 )","pass@1","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]},{"number":"0.4","isBolded":false,"associatedRows":["Performance"],"associatedColumns":["Pretraining only","LaMDA","137B","PaLM","pass@k","Human Eval","MBPP","TransCoder","80","DeepFix","60"],"associatedMergedColumns":["-"]},{"number":"50.4","isBolded":true,"associatedRows":["100","80","MBPP ( 3 )","pass@1","-"],"associatedColumns":["Code Finetuning","Davinci","Codex *"],"associatedMergedColumns":["-"]}]},{"caption":"Table 13: DeepFix success rates as percentages, where \"success\" means the predicted code compiles and \nthe prediction involves a small edit, under various ways of defining \"small\" edits. In parentheses, we \nshow the percentage of predictions representing small edits. \"Normalized Edit Distance\" is computed as \nLevenshteinDistance(x, y)/ max{len(x), len(y)} for strings x and y. \"Lines Changed\" counts the total number \nof line insertions, deletions, and edits. In both cases, we ignore all indentation changes. \n\n","rows":["Lines Changed ? 7","Compile Rate ( any edit size )","Lines Changed ? 5","Normalized Edit Distance ?","Lines Changed ? 6"],"columns":["PaLM 540B","PaLM - Coder 540B","Code Finetuning","Pretraining only","LaMDA 137B","Davinci Codex"],"mergedAllColumns":[],"numberCells":[{"number":"82.1","isBolded":true,"associatedRows":["Compile Rate ( any edit size )"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"2.5(3.4)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"2.1(3.1)","isBolded":false,"associatedRows":["Lines Changed ? 6"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"4.3","isBolded":false,"associatedRows":["Compile Rate ( any edit size )"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"74.7(91.7)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"73.9(90.9)","isBolded":true,"associatedRows":["Lines Changed ? 7"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"1.7(1.9)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"71.0(96.5)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"79.4(96.7)","isBolded":true,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"0.20","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"70.5(86.7)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["Compile Rate ( any edit size )"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"71.5(87.9)","isBolded":true,"associatedRows":["Lines Changed ? 6"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"68.4(93.7)","isBolded":false,"associatedRows":["Lines Changed ? 7"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"68.0(93.1)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"2.5(4.1)","isBolded":false,"associatedRows":["Lines Changed ? 7"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["Compile Rate ( any edit size )"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"0.15","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"72.4(98.1)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"67.9(83.3)","isBolded":true,"associatedRows":["Lines Changed ? 5"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]},{"number":"70.1(85.5)","isBolded":false,"associatedRows":["Lines Changed ? 6"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"77.0(94.0)","isBolded":true,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"63.8(87.8)","isBolded":false,"associatedRows":["Lines Changed ? 5"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"0.10","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"66.8(81.1)","isBolded":false,"associatedRows":["Lines Changed ? 5"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"2.1(2.7)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"1.7(2.1)","isBolded":false,"associatedRows":["Lines Changed ? 5"],"associatedColumns":["Pretraining only","LaMDA 137B"],"associatedMergedColumns":[]},{"number":"66.6(91.4)","isBolded":false,"associatedRows":["Lines Changed ? 6"],"associatedColumns":["Pretraining only","PaLM 540B"],"associatedMergedColumns":[]},{"number":"72.9(88.7)","isBolded":false,"associatedRows":["Lines Changed ? 7"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"71.7(87.5)","isBolded":true,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","PaLM - Coder 540B"],"associatedMergedColumns":[]},{"number":"77.1(94.7)","isBolded":false,"associatedRows":["Normalized Edit Distance ?"],"associatedColumns":["Code Finetuning","Davinci Codex"],"associatedMergedColumns":[]}]},{"caption":"Table 14: Translation BLEU scores on traditional WMT language pairs. Superscripts denote results from \npast work: a FLAN(Wei et al., 2022a); b GPT-3 175B (Brown et al., 2020); c (Edunov et al., 2018); d (Wang \net al., 2019b); e (Caswell et al., 2019); f Lin et al. (2020); g (Wang et al., 2019b); h ","rows":["a","de","en","fr","ro"],"columns":["Tgt","Finetuned","Prior","PaLM","540B","Supervised","0 - shot","SOTA","1 - shot","Few - shot"],"mergedAllColumns":["d","e"],"numberCells":[{"number":"37.5","isBolded":true,"associatedRows":["en","fr","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"25.4","isBolded":false,"associatedRows":["en","de"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"38.0a(9)","isBolded":false,"associatedRows":["fr","en","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"40.6a(11)","isBolded":false,"associatedRows":["de","en","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"31.8","isBolded":true,"associatedRows":["en","de","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"43.8","isBolded":true,"associatedRows":["de","en","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"33.7b","isBolded":false,"associatedRows":["fr","en","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"42.1","isBolded":true,"associatedRows":["ro","en","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"41.1","isBolded":true,"associatedRows":["fr","en","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"16.7","isBolded":false,"associatedRows":["en","ro"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["d"]},{"number":"33.9a(9)","isBolded":false,"associatedRows":["en","fr","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"44.0","isBolded":true,"associatedRows":["en","fr","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"20.6b","isBolded":false,"associatedRows":["en","ro","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["d"]},{"number":"43.9","isBolded":true,"associatedRows":["de","en","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"45.6c","isBolded":false,"associatedRows":["en","fr","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"45.4f","isBolded":false,"associatedRows":["fr","en","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"43.8","isBolded":true,"associatedRows":["ro","en","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"41.2","isBolded":false,"associatedRows":["en","de","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"30.4b","isBolded":false,"associatedRows":["de","en","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"33.4","isBolded":false,"associatedRows":["en","ro","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["d"]},{"number":"36.8","isBolded":false,"associatedRows":["ro","en"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"38.9","isBolded":false,"associatedRows":["de","en"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"38.6b","isBolded":false,"associatedRows":["ro","en","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"20.5a(9)","isBolded":false,"associatedRows":["en","ro","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["d"]},{"number":"26.2b","isBolded":false,"associatedRows":["en","de","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"32.9","isBolded":false,"associatedRows":["en","fr"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"28.3b","isBolded":false,"associatedRows":["en","fr","a"],"associatedColumns":["1 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"47.5","isBolded":true,"associatedRows":["de","en","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"24.2","isBolded":true,"associatedRows":["en","ro","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["d"]},{"number":"31.8","isBolded":true,"associatedRows":["en","de","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"35.5","isBolded":false,"associatedRows":["fr","en"],"associatedColumns":["0 - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"37.3a(9)","isBolded":false,"associatedRows":["ro","en","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"39.1h","isBolded":false,"associatedRows":["ro","en","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"37.4","isBolded":true,"associatedRows":["en","de","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":true,"associatedRows":["en","fr","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"41.2g","isBolded":false,"associatedRows":["de","en","a"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["e"]},{"number":"39.9","isBolded":true,"associatedRows":["ro","en","a"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"37.4","isBolded":true,"associatedRows":["fr","en","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"28.7","isBolded":true,"associatedRows":["en","ro","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["d"]},{"number":"42.8","isBolded":true,"associatedRows":["fr","en","a"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["e"]},{"number":"26.8a(11)","isBolded":false,"associatedRows":["en","de","a"],"associatedColumns":["Few - shot","Prior","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"28.2","isBolded":true,"associatedRows":["en","ro","a"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["d"]}]},{"caption":"Table 15: Translation BLEU scores on non-English centric and extremely-low resource language pairs. a ","rows":["kk","de","en","fr"],"columns":["Tgt","Finetuned","PaLM","540B","Supervised","0 - shot","1 - shot","Few - shot","SOTA"],"mergedAllColumns":["a","b","c"],"numberCells":[{"number":"18.0","isBolded":false,"associatedRows":["kk","en"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["b"]},{"number":"20.9","isBolded":false,"associatedRows":["de","fr"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["a"]},{"number":"30.5","isBolded":true,"associatedRows":["kk","en"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["b"]},{"number":"1.8","isBolded":false,"associatedRows":["en","kk"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"20.8","isBolded":false,"associatedRows":["kk","en"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["b"]},{"number":"24.9b","isBolded":false,"associatedRows":["fr","de"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["c"]},{"number":"15.5","isBolded":true,"associatedRows":["en","kk"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":[]},{"number":"28.6","isBolded":false,"associatedRows":["de","fr"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["a"]},{"number":"25.7","isBolded":false,"associatedRows":["de","fr"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["a"]},{"number":"17.4","isBolded":false,"associatedRows":["fr","de"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["c"]},{"number":"4.2","isBolded":false,"associatedRows":["en","kk"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":true,"associatedRows":["de","fr"],"associatedColumns":["Supervised","Finetuned","Tgt","SOTA"],"associatedMergedColumns":["a"]},{"number":"20.3","isBolded":false,"associatedRows":["kk","en"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["b"]},{"number":"9.5","isBolded":false,"associatedRows":["fr","de"],"associatedColumns":["1 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["c"]},{"number":"5.1","isBolded":false,"associatedRows":["en","kk"],"associatedColumns":["Few - shot","PaLM","Tgt","540B"],"associatedMergedColumns":[]},{"number":"25.2","isBolded":true,"associatedRows":["fr","de"],"associatedColumns":["0 - shot","PaLM","Tgt","540B"],"associatedMergedColumns":["c"]}]},{"caption":"Table 16: ROUGE-2 results in GEM data-to-text and summarization datasets. We present finetuning results \nin comparison with prior reported SOTA, T5 XXL finetuned baselines. We also present few-shot results \ncomparing them to LaMDA baselines. a (Dusek \u0026 Jurvc\u0027ivcek, 2019), b (Xue et al., 2021b), c (Bakshi et al., \n2021), d (Gehrmann et al., 2021), e ","rows":["WikiLingua ( en ? en )","WikiLingua ( ru ? en )","MLSum ( es )","WikiLingua ( tr ? en )","E2E ( en )","Czech Restaurant ( cs )","-","WikiLingua ( vi ? en )","MLSum ( de )","WikiLingua ( es ? en )","XSum ( en )","WebNLG ( en )","WebNLG ( ru )"],"columns":["T5","62B","Prior","PaLM","LaMDA","540B","137B","8B","Finetuning","XXL","1 - shot","SOTA"],"mergedAllColumns":["Data - To - Text","Summarization"],"numberCells":[{"number":"2.2","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"6.6","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"12.8","isBolded":true,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"5.4","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"12.2","isBolded":true,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"23.4","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"19.3","isBolded":false,"associatedRows":["WikiLingua ( en ? en )","-"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"28.8","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"21.4","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"29.1","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"7.9","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"12.0","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"25.5b","isBolded":true,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Data - To - Text"]},{"number":"33.1","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"14.6b","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"9.9","isBolded":true,"associatedRows":["WikiLingua ( en ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"3.4","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"48.6","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"2.3","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"14.9","isBolded":true,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"27.7","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"13.9","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"22.1","isBolded":false,"associatedRows":["WikiLingua ( en ? en )","-"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"16.3","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"18.5","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"10.6","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"6.6","isBolded":true,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"11.2","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"8.2","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"2.3","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"5.8","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"13.8b","isBolded":true,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"18.2","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"44.4","isBolded":true,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"5.6","isBolded":false,"associatedRows":["WikiLingua ( en ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"1.5","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"3.6","isBolded":true,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"18.3d","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"9.7","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"0.1","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"45.7","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"8.9","isBolded":false,"associatedRows":["WikiLingua ( en ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"23.2","isBolded":false,"associatedRows":["WikiLingua ( en ? en )","-"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"1.8","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"38.6","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"30.2a","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Data - To - Text"]},{"number":"45.2","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"16.1","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"17.9","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"19.1","isBolded":true,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"5.4","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"49.3","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"30.0","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"4.0","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"45.3","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"5.2","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"18.3b","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"21.2","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"16.6","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"13.4","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"23.3","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"5.5","isBolded":true,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"12.0","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"23.2e","isBolded":true,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"29.2","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"16.7","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"16.1","isBolded":true,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"13.8","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"45.8b","isBolded":true,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Data - To - Text"]},{"number":"21.0","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"18.6","isBolded":true,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"35.9","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"23.8","isBolded":true,"associatedRows":["WikiLingua ( en ? en )","-"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"30.3","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"3.2","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"12.5","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"39.6","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"33.5","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"4.6","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"26.5","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"16.3","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"8.5","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"8.5","isBolded":true,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"23.1","isBolded":true,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"30.2","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"20.9","isBolded":true,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"11.2","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"23.2","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"7.7","isBolded":true,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"36.4d","isBolded":true,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]},{"number":"4.5","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"0.5","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"1.8","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"5.4","isBolded":false,"associatedRows":["WikiLingua ( en ? en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"30.6","isBolded":true,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"53.5c","isBolded":true,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Data - To - Text"]},{"number":"45.3","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"22.4","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"12.2","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"5.6","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"10.5","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"0.3","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"30.5","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"0.9","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","LaMDA","137B"],"associatedMergedColumns":["Summarization"]},{"number":"35.2","isBolded":true,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"47.6","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"14.9b","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","Prior","SOTA"],"associatedMergedColumns":["Summarization"]}]},{"caption":"Table 17: Comparison against SOTA on TyDiQA-GoldP validation set (exact match metric). \n\n","rows":["mT5 XXL","ByT5 XXL"],"columns":["Ar","Te","Fi","Ru","Avg","Ko","Sw","En","Id","Bn"],"mergedAllColumns":[],"numberCells":[{"number":"76.9","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Ar"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Te"],"associatedMergedColumns":[]},{"number":"80.5","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Bn"],"associatedMergedColumns":[]},{"number":"85.2","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Sw"],"associatedMergedColumns":[]},{"number":"83.9","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Te"],"associatedMergedColumns":[]},{"number":"76.3","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Fi"],"associatedMergedColumns":[]},{"number":"85.7","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Id"],"associatedMergedColumns":[]},{"number":"78.2","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ru"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Sw"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"77.7","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["En"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Id"],"associatedMergedColumns":[]},{"number":"79.1","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"84.9","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Te"],"associatedMergedColumns":[]},{"number":"78.8","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Fi"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ar"],"associatedMergedColumns":[]},{"number":"75.5","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["En"],"associatedMergedColumns":[]},{"number":"76.8","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Ru"],"associatedMergedColumns":[]},{"number":"77.1","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ru"],"associatedMergedColumns":[]},{"number":"81.8","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Id"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Ko"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ko"],"associatedMergedColumns":[]},{"number":"85.0","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Bn"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ar"],"associatedMergedColumns":[]},{"number":"78.9","isBolded":true,"associatedRows":["ByT5 XXL"],"associatedColumns":["Fi"],"associatedMergedColumns":[]},{"number":"83.2","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Bn"],"associatedMergedColumns":[]},{"number":"75.5","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["En"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["ByT5 XXL"],"associatedColumns":["Ko"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["mT5 XXL"],"associatedColumns":["Sw"],"associatedMergedColumns":[]}]},{"caption":"Table 18: Performance on the \"clean\" subset of the 10 partially contaminated English NLP tasks. For \nexample, for WebQuestions, 73.3% of the dev set examples were clean, and the clean subset had PaLM 540B \n1-shot dev accuracy of 22.6 + 0.3 \u003d 22.9. \n\n","rows":["TriviaQA ( Wiki )","SQuADv2 ( F1 )","ARC - c","ARC - e","WSC","WebQuestions","Winograd","Lambada","ReCoRD","CB"],"columns":["Table 18 , both the 8B and 540B have approximately","Subset Delta","Accuracy","PaLM 8B 1 - Shot","Proportion","Full Set","Clean","PaLM 540B 1 - Shot"],"mergedAllColumns":["similar number of negative deltas between the clean and full validation set ."],"numberCells":[{"number":"+0.4","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"87.5","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-2.5","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-1.6","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+0.1","isBolded":false,"associatedRows":["TriviaQA ( Wiki )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-0.3","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"42.3","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+1.1","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"14.8%","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+0.6","isBolded":false,"associatedRows":["Lambada"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-2.0","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-3.1","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"71.3","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+5.8","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"83.9","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"69.6%","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"61.5%","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-0.4","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"81.4","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"56.6%","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"87.8","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"57.8","isBolded":false,"associatedRows":["Lambada"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+0.0","isBolded":false,"associatedRows":["Lambada"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-1.1","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"81.4","isBolded":false,"associatedRows":["TriviaQA ( Wiki )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"81.8","isBolded":false,"associatedRows":["Lambada"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+1.1","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-1.8","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"41.1","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"80.1%","isBolded":false,"associatedRows":["TriviaQA ( Wiki )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"92.8","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+0.3","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"50.1","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"73.3%","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"48.5","isBolded":false,"associatedRows":["TriviaQA ( Wiki )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"82.9","isBolded":false,"associatedRows":["SQuADv2 ( F1 )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"12.6","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"+0.5","isBolded":false,"associatedRows":["TriviaQA ( Wiki )"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"63.2%","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-1.4","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"75.3%","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"60.1","isBolded":false,"associatedRows":["ARC - c"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"85.0","isBolded":false,"associatedRows":["ARC - e"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"86.3","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"82.4","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"51.8%","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-4.4","isBolded":false,"associatedRows":["Winograd"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"-3.5","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Clean","Subset Delta"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"70.7%","isBolded":false,"associatedRows":["Lambada"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 8B 1 - Shot","Clean","Proportion"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]},{"number":"22.6","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Table 18 , both the 8B and 540B have approximately","PaLM 540B 1 - Shot","Full Set","Accuracy"],"associatedMergedColumns":["similar number of negative deltas between the clean and full validation set ."]}]},{"caption":"Table 19: Performance on the \"clean\" subset for 0-shot machine translation tasks. \n\n","rows":["En - De","De - En","Fr - En","En - Fr","En - Ro","Ro - En"],"columns":["PaLM 8B 0 - shot","PaLM 62B 0 - shot","Proportion","BLEU","Full Set","Clean Set","Clean","PaLM 540B 0 - shot"],"mergedAllColumns":[],"numberCells":[{"number":"21.4","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.6","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"39.6","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"33.9","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"17.8","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"41.1","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"35.3","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"38.2","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"25.0","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"7.6","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"75.2%","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"40.2","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"40.4","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"94.3%","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"74.2%","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"24.3","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"34.9","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"14.8","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"64.0%","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"21.6","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 8B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.9","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"39.9","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["Ro - En"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"7.6","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"43.8","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"24.2","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"38.4","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 540B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.7","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 8B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":false,"associatedRows":["De - En"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"25.5","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"15.2","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 62B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]},{"number":"88.9%","isBolded":false,"associatedRows":["En - Fr"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"96.5%","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 8B 0 - shot","Clean","Proportion"],"associatedMergedColumns":[]},{"number":"15.1","isBolded":false,"associatedRows":["En - Ro"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"36.4","isBolded":false,"associatedRows":["Fr - En"],"associatedColumns":["PaLM 62B 0 - shot","Clean Set","BLEU"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["En - De"],"associatedColumns":["PaLM 540B 0 - shot","Full Set","BLEU"],"associatedMergedColumns":[]}]},{"caption":"Table 20: Probability of generating a comment that could be perceived as toxic (i.e. toxicity score \u003e 0.5) \nat least once in 25 continuations for different model sizes. We compute the toxicity probability for \"Toxic\" \nand \"Non-Toxic\" prompts and report the results as such. We report the metric both in the first full-sentence \ncompletion and in the full 128 decoding steps similar to ","rows":["PaLM 540B","PaLM 8B","PaLM 62B"],"columns":["Toxic","First - sentence","128 - decode steps","Non - toxic"],"mergedAllColumns":[],"numberCells":[{"number":"0.46","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["First - sentence","Non - toxic"],"associatedMergedColumns":[]},{"number":"0.56","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["128 - decode steps","Non - toxic"],"associatedMergedColumns":[]},{"number":"0.46","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["First - sentence","Non - toxic"],"associatedMergedColumns":[]},{"number":"0.91","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["128 - decode steps","Toxic"],"associatedMergedColumns":[]},{"number":"0.90","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["128 - decode steps","Toxic"],"associatedMergedColumns":[]},{"number":"0.53","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["128 - decode steps","Non - toxic"],"associatedMergedColumns":[]},{"number":"0.78","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["First - sentence","Toxic"],"associatedMergedColumns":[]},{"number":"0.44","isBolded":false,"associatedRows":["PaLM 8B"],"associatedColumns":["First - sentence","Non - toxic"],"associatedMergedColumns":[]},{"number":"0.81","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["First - sentence","Toxic"],"associatedMergedColumns":[]},{"number":"0.80","isBolded":false,"associatedRows":["PaLM 540B"],"associatedColumns":["First - sentence","Toxic"],"associatedMergedColumns":[]},{"number":"0.91","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["128 - decode steps","Toxic"],"associatedMergedColumns":[]},{"number":"0.58","isBolded":false,"associatedRows":["PaLM 62B"],"associatedColumns":["128 - decode steps","Non - toxic"],"associatedMergedColumns":[]}]},{"caption":"Table 21: Comparison of PaLM, Chinchilla, and Gopher on English NLP tasks. \n\n","rows":["Trivia QA few - shot","Average Task Metric","HellaSWAG 0 - shot","Natural Questions few - shot","Winogrande 0 - shot","Trivia QA 0 - shot","Chinchilla","Training FLOP Count 20 ( Zettaflops )","Preferred","Normalized","PaLM","PIQA 0 - shot","Metric","Lambada 0 - shot","BoolQ 0 - shot","50","40","20","Natural Questions 0 - shot"],"columns":["280","English NLP","Chinchilla","780","PaLM 62B","PaLM 540B","540","PaLM 8B","795","300","1400","Gopher","8","70","62"],"mergedAllColumns":["30","Chinchilla"],"numberCells":[{"number":"81.4","isBolded":false,"associatedRows":["Trivia QA few - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"39.6","isBolded":false,"associatedRows":["Natural Questions few - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["Preferred","Preferred"],"associatedColumns":["PaLM 62B","62","795","English NLP","Gopher"],"associatedMergedColumns":["Chinchilla"]},{"number":"82.3","isBolded":false,"associatedRows":["PIQA 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"81.8","isBolded":false,"associatedRows":["PIQA 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"80.5","isBolded":false,"associatedRows":["PIQA 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"68.3","isBolded":false,"associatedRows":["BoolQ 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"67.5","isBolded":false,"associatedRows":["Metric","50","Chinchilla","Metric"],"associatedColumns":["PaLM 62B","62","795","English NLP"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["HellaSWAG 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["Winogrande 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"62.5","isBolded":false,"associatedRows":["Preferred","40","Metric"],"associatedColumns":["PaLM 62B","62","795","English NLP","Gopher"],"associatedMergedColumns":["Chinchilla"]},{"number":"295.7","isBolded":false,"associatedRows":["Training FLOP Count 20 ( Zettaflops )","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"21.2","isBolded":false,"associatedRows":["Natural Questions 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"70.3","isBolded":false,"associatedRows":["Average Task Metric","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":false,"associatedRows":["Lambada 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"10.1","isBolded":false,"associatedRows":["Natural Questions 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["Trivia QA 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"73.2","isBolded":false,"associatedRows":["Trivia QA few - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"24.5","isBolded":false,"associatedRows":["Natural Questions few - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"55.0","isBolded":false,"associatedRows":["Normalized","20","Preferred"],"associatedColumns":["PaLM 62B","62","795","English NLP","Gopher"],"associatedMergedColumns":["30"]},{"number":"74.5","isBolded":false,"associatedRows":["Lambada 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Winogrande 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["Average Task Metric","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"2527.2","isBolded":false,"associatedRows":["Training FLOP Count 20 ( Zettaflops )","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"67.3","isBolded":false,"associatedRows":["Trivia QA 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"65.0","isBolded":false,"associatedRows":["Preferred","Metric"],"associatedColumns":["PaLM 62B","62","795","English NLP"],"associatedMergedColumns":["Chinchilla"]},{"number":"8.4","isBolded":false,"associatedRows":["Natural Questions 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":false,"associatedRows":["HellaSWAG 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["Winogrande 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"27.6","isBolded":false,"associatedRows":["Natural Questions few - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"39.5","isBolded":false,"associatedRows":["Trivia QA 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"588.0","isBolded":false,"associatedRows":["Training FLOP Count 20 ( Zettaflops )","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"63.6","isBolded":false,"associatedRows":["Trivia QA few - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"79.2","isBolded":false,"associatedRows":["HellaSWAG 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"59.5","isBolded":false,"associatedRows":["Average Task Metric","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"77.1","isBolded":false,"associatedRows":["PIQA 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"51.2","isBolded":false,"associatedRows":["Average Task Metric"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":false,"associatedRows":["HellaSWAG 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"81.8","isBolded":false,"associatedRows":["PIQA 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"75.4","isBolded":false,"associatedRows":["Lambada 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"16.6","isBolded":false,"associatedRows":["Natural Questions 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["Natural Questions few - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["Trivia QA 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"48.5","isBolded":false,"associatedRows":["Trivia QA few - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"18.1","isBolded":false,"associatedRows":["Natural Questions 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"79.3","isBolded":false,"associatedRows":["BoolQ 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["Lambada 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["BoolQ 0 - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"504.0","isBolded":false,"associatedRows":["Training FLOP Count 20 ( Zettaflops )","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"74.9","isBolded":false,"associatedRows":["Winogrande 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"52.5","isBolded":false,"associatedRows":["Normalized","Preferred"],"associatedColumns":["PaLM 62B","62","795","English NLP","Gopher"],"associatedMergedColumns":["30"]},{"number":"70.0","isBolded":false,"associatedRows":["Metric","PaLM","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"68.7","isBolded":false,"associatedRows":["HellaSWAG 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"37.4","isBolded":false,"associatedRows":["Training FLOP Count 20 ( Zettaflops )"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["Trivia QA 0 - shot","Metric"],"associatedColumns":["Gopher","280","300"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":false,"associatedRows":["Natural Questions few - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["BoolQ 0 - shot","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":false,"associatedRows":["Lambada 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"66.3","isBolded":false,"associatedRows":["Winogrande 0 - shot"],"associatedColumns":["PaLM 8B","8","780"],"associatedMergedColumns":[]},{"number":"57.5","isBolded":false,"associatedRows":["Normalized","Preferred"],"associatedColumns":["PaLM 62B","62","795","English NLP","Gopher"],"associatedMergedColumns":["Chinchilla"]},{"number":"88.7","isBolded":false,"associatedRows":["BoolQ 0 - shot","Metric"],"associatedColumns":["PaLM 540B","540","780"],"associatedMergedColumns":[]},{"number":"72.7","isBolded":false,"associatedRows":["Trivia QA few - shot","Metric"],"associatedColumns":["PaLM 62B","62","795"],"associatedMergedColumns":[]},{"number":"65.2","isBolded":false,"associatedRows":["Average Task Metric","Metric"],"associatedColumns":["Chinchilla","70","1400"],"associatedMergedColumns":[]}]},{"caption":"Table 3. The MFU calculation for Megatron-Turing NLG \n530B is as follows: it was trained on A100 GPUs with 312 peak matmul TFLOP/s, and achieved a training throughput \nof 65.43K tokens/second (1920 ? 2048/60.1) on 2240 GPUs (Smith et al., 2022), resulting in MFU of 29.7% without \nattention ((65.43 ? 6 ? 530)/(312 ? 2240)) or 30.2% with it. In comparison, PaLM 540B achieves an average training \nthroughput of 238.3K tokens/sec at a batch size of 2048. The training of PaLM 540B uses rematerialization because \nthe feasible batch size with rematerialization enables higher training throughput. Without the rematerialization costs, \nthe resulting model FLOPs utilization is 45.7% without self-attention ((238.3 ? 6 ? 540)/(275 ? 6144)) or 46.2% with \nit. PaLM\u0027s analytically computed hardware FLOPs utilization, which includes rematerialization FLOPs, is 57.8%. \n\n","rows":["62B","540B","8B"],"columns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","( non - attn+attn )","( non - attn+attn+remat )","Train FLOPs","TFLOPs per token"],"mergedAllColumns":["497","other sources of inefficiency .","3570"],"numberCells":[{"number":"10","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"0.392","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"4.10","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"4.29?","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"24","isBolded":true,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"0.388","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["497"]},{"number":"0.0561","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"3.28","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["3570"]},{"number":"23","isBolded":true,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"22","isBolded":true,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"10","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"3.08?","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"10","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"2.56?","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"0.0550","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["other sources of inefficiency ."]}]},{"caption":"Table 22: Compute usage to train PaLM 8B and PaLM 540B to 780 billion tokens and PaLM 62B to 795B \ntokens. \n\n","rows":["62B","540B","8B"],"columns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","( non - attn+attn )","( non - attn+attn+remat )","Train FLOPs","TFLOPs per token"],"mergedAllColumns":["497","other sources of inefficiency .","3570"],"numberCells":[{"number":"0.0561","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"10","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"0.392","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"22","isBolded":true,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"10","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"0.388","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["497"]},{"number":"2.56?","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"10","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"4.10","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"0.0550","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"23","isBolded":true,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]},{"number":"3.28","isBolded":false,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","TFLOPs per token","( non - attn+attn )"],"associatedMergedColumns":["3570"]},{"number":"4.29?","isBolded":false,"associatedRows":["8B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["other sources of inefficiency ."]},{"number":"24","isBolded":true,"associatedRows":["540B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["3570"]},{"number":"3.08?","isBolded":false,"associatedRows":["62B"],"associatedColumns":["Next we report the compute FLOPs usage during training for the three model sizes of PaLM in Table 22 , both","Train FLOPs","( non - attn+attn+remat )"],"associatedMergedColumns":["497"]}]},{"caption":"Table 27: PaLM Datasheet \n\nLanguage \nPercentage \nLanguage \nPercentage \n\nJava \n18.8% \nShell \n0.5% \nHTML \n17.5% \nRust \n0.4% \nJavascript \n11.6% \nSQL \n0.3% \nPython \n7.3% \nLua \n0.3% \nC \n7.3% \nNotebooks \n0.3% \nPHP \n7.2% \nDart \n0.2% \nC# \n6.4% \nOther \n0.6% \nC++ \n6.3% \nVisual Basic \n\u003c0.1% \nXML \n4.8% \nPerl \n\u003c0.1% \nRuby \n2.7% \nS \n\u003c0.1% \nGo \n2.6% \nClojure \n\u003c0.1% \nMatlab \n1.8% \nEmacs Lisp \n\u003c0.1% \nTypescript \n1.4% \nTCL \n\u003c0.1 % \n\n","rows":["C#","C","Go","HTML","Shell","Visual Basic","S","Typescript","Javascript","Lua","Notebooks","PHP","Ruby","Python","Clojure","Emacs Lisp","Java","C++","Rust","Perl","SQL","XML","TCL","Dart","Other","Matlab"],"columns":["Table 27 : PaLM Datasheet","Percentage"],"mergedAllColumns":[],"numberCells":[{"number":"\u003c0.1%","isBolded":true,"associatedRows":["C++","Visual Basic"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["XML","Perl"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"18.8%","isBolded":false,"associatedRows":["Java"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"11.6%","isBolded":false,"associatedRows":["Javascript"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.3%","isBolded":false,"associatedRows":["Python"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["Javascript","SQL"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"4.8%","isBolded":false,"associatedRows":["XML"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"17.5%","isBolded":false,"associatedRows":["HTML"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Matlab","Emacs Lisp"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.6%","isBolded":false,"associatedRows":["C#","Other"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"1.4%","isBolded":false,"associatedRows":["Typescript"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Typescript","TCL"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"1.8%","isBolded":false,"associatedRows":["Matlab"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"6.4%","isBolded":false,"associatedRows":["C#"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"2.6%","isBolded":false,"associatedRows":["Go"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["C","Notebooks"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Go","Clojure"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.3%","isBolded":false,"associatedRows":["C"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"6.3%","isBolded":false,"associatedRows":["C++"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Ruby","S"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["Python","Lua"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.2%","isBolded":false,"associatedRows":["PHP"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.2%","isBolded":false,"associatedRows":["PHP","Dart"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.5%","isBolded":false,"associatedRows":["Java","Shell"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"2.7%","isBolded":false,"associatedRows":["Ruby"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.4%","isBolded":false,"associatedRows":["HTML","Rust"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]}]},{"caption":"Table 28: Proportion of each programming language in the pre-training code data. The percentages show the \nproportion by bytes of each language. The programming language of each file is determined heuristically by \nits extension. \n","rows":["C#","C","Go","HTML","Shell","Visual Basic","S","Typescript","Javascript","Lua","Notebooks","PHP","Ruby","Python","Clojure","Emacs Lisp","Java","C++","Rust","Perl","SQL","XML","TCL","Dart","Other","Matlab"],"columns":["Table 27 : PaLM Datasheet","Percentage"],"mergedAllColumns":[],"numberCells":[{"number":"\u003c0.1%","isBolded":true,"associatedRows":["C++","Visual Basic"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"18.8%","isBolded":false,"associatedRows":["Java"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["C","Notebooks"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["XML","Perl"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.2%","isBolded":false,"associatedRows":["PHP"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"17.5%","isBolded":false,"associatedRows":["HTML"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["Javascript","SQL"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.2%","isBolded":false,"associatedRows":["PHP","Dart"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"4.8%","isBolded":false,"associatedRows":["XML"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"2.6%","isBolded":false,"associatedRows":["Go"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Matlab","Emacs Lisp"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Go","Clojure"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"2.7%","isBolded":false,"associatedRows":["Ruby"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Ruby","S"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"\u003c0.1%","isBolded":true,"associatedRows":["Typescript","TCL"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.6%","isBolded":false,"associatedRows":["C#","Other"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"11.6%","isBolded":false,"associatedRows":["Javascript"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.3%","isBolded":false,"associatedRows":["C"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"6.4%","isBolded":false,"associatedRows":["C#"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.5%","isBolded":false,"associatedRows":["Java","Shell"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"6.3%","isBolded":false,"associatedRows":["C++"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"1.4%","isBolded":false,"associatedRows":["Typescript"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"7.3%","isBolded":false,"associatedRows":["Python"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"1.8%","isBolded":false,"associatedRows":["Matlab"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.3%","isBolded":false,"associatedRows":["Python","Lua"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]},{"number":"0.4%","isBolded":false,"associatedRows":["HTML","Rust"],"associatedColumns":["Table 27 : PaLM Datasheet","Percentage"],"associatedMergedColumns":[]}]},{"caption":"Table 29: Language distribution of the training data (excluding code data). \n","rows":["ps","pt","hmn","fil","Zulu","Swedish","Turkish","Kannada","Unknown","Arabic ( Latin )","Catalan","Scots Gaelic","ar - Latn","Armenian","af","Romanian","Igbo","Yiddish","am","ar","Icelandic","Gujarati","az","Laothian","ro","ceb","hi - Latn","ru","be","Sundanese","Telugu ( Latin )","bg","rw","bn","Kurdish","sd","bs","French","Indonesian","si","sk","Hawaiian","sl","sm","sn","so","sq","bg - Latn","ca","sr","st","Basque","su","sv","sw","Latvian","co","cs","Gujarati ( Latin )","te","tg","th","cy","tk","Czech","da","Kyrgyz","tr","tt","de","Russian","Bosnian","ru - Latn","Bulgarian ( Latin )","Kinyarwanda","ug","Portuguese","uk","Russian ( Latin )","Hindi","Norwegian","Japanese ( Latin )","haw","uz","el","en","eo","es","Irish","et","eu","Kazakh","Javanese","vi","Latin","fa","Malayalam ( Latin )","gu - Latn","Oriya","Italian","fi","Corsican","fr","Slovenian","fy","Maori","ga","gd","Xhosa","gl","und","Welsh","Sesotho","kn - Latn","gu","Croatian","xh","Uighur","Danish","ha","Frisian","Amharic","ckb","Greek","hi","Hebrew","Mongolian","hr","ht","el - Latn","hu","Shona","yi","hy","Ukrainian","yo","ml - Latn","Malay","id","Tamil ( Latin )","ig","te - Latn","Haitian Creole","Swahili","Macedonian","is","it","Japanese","zh","iw","Estonian","Sindhi","Pashto","Bengali","Tatar","ja","ta - Latn","Kannada ( Latin )","zu","Uzbek","Persian","German","jv","Azerbaijani","Telugu","Maltese","Chinese ( Latin )","ka","Esperanto","Tagalog","Turkmen","Nepali","Georgian","bn - Latn","Cebuano","mr - Latn","kk","Malayalam","km","kn","ko","Lithuanian","Korean","ku","Khmer","ky","la","lb","Chinese","Vietnamese","Galician","Somali","Nyanja","Slovak","lo","Belarusian","Serbian","Marathi","lt","lv","Samoan","Tajik","Arabic","Spanish","mg","Thai","zh - Latn","mi","mk","ml","Malagasy","mn","Hindi ( Latin )","mr","ms","mt","my","Bengali ( Latin )","Burmese","Luxembourgish","ne","nl","Greek ( Latin )","no","Sinhalese","Afrikaans","Yoruba","ja - Latn","ny","Finnish","Albanian","or","Bulgarian","Marathi ( Latin )","Hausa","English","pa","Hungarian","pl"],"columns":["Percentage","Tokens ( B )"],"mergedAllColumns":[],"numberCells":[{"number":"0.055","isBolded":false,"associatedRows":["be","Belarusian","ckb","Gujarati ( Latin )","Unknown"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["co","Corsican","gu - Latn","Gujarati ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.050%","isBolded":false,"associatedRows":["sr","Serbian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.011%","isBolded":false,"associatedRows":["uk","Ukrainian","ig","Igbo"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.324","isBolded":false,"associatedRows":["hy","Armenian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.153","isBolded":false,"associatedRows":["eu","Basque"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"4.855","isBolded":false,"associatedRows":["tr","Turkish","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"15.654","isBolded":false,"associatedRows":["es","Spanish","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.008%","isBolded":false,"associatedRows":["el","Greek","mn","Gujarati ( Latin )","Mongolian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.160","isBolded":false,"associatedRows":["gd","Scots Gaelic"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.137%","isBolded":false,"associatedRows":["ceb","Cebuano"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.022%","isBolded":false,"associatedRows":["gd","Scots Gaelic"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.006%","isBolded":false,"associatedRows":["sk","Slovak","yi","Yiddish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.053%","isBolded":false,"associatedRows":["co","Corsican"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.014","isBolded":false,"associatedRows":["te","Telugu","kn - Latn","Turkmen","Kinyarwanda","Kannada ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.086%","isBolded":false,"associatedRows":["ca","Catalan"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.015%","isBolded":false,"associatedRows":["ja","Japanese","ml","Bulgarian ( Latin )","Malayalam"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.036","isBolded":false,"associatedRows":["ms","Malay","ny","Nyanja"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.044%","isBolded":false,"associatedRows":["be","Belarusian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.012%","isBolded":false,"associatedRows":["id","Vietnamese","Indonesian","mt","Maltese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.061","isBolded":false,"associatedRows":["el","Greek","mn","Gujarati ( Latin )","Mongolian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.020%","isBolded":false,"associatedRows":["en","English","Portuguese","sd","Russian ( Latin )","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.308%","isBolded":false,"associatedRows":["it","Italian","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.042","isBolded":false,"associatedRows":["lb","Hindi ( Latin )","Luxembourgish","bn - Latn","Bengali ( Latin )","Gujarati"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"12.064","isBolded":false,"associatedRows":["und","Unknown","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.036%","isBolded":false,"associatedRows":["lb","Hindi ( Latin )","Luxembourgish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.010%","isBolded":false,"associatedRows":["ca","Catalan","ga","Irish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["hi","Hindi","zh - Latn","Sundanese","Chinese ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.282","isBolded":false,"associatedRows":["th","Thai"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.015%","isBolded":false,"associatedRows":["zh","Chinese","af","Afrikaans"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.329","isBolded":false,"associatedRows":["be","Belarusian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.098%","isBolded":false,"associatedRows":["vi","Vietnamese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.069%","isBolded":false,"associatedRows":["ro","Romanian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.444","isBolded":false,"associatedRows":["ko","Korean"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.047%","isBolded":false,"associatedRows":["eo","Esperanto"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.310","isBolded":false,"associatedRows":["sk","Slovak"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.019%","isBolded":false,"associatedRows":["fr","French","Portuguese","pa","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.029%","isBolded":false,"associatedRows":["ms","Malay"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.031","isBolded":false,"associatedRows":["et","Estonian","ta - Latn","Sundanese","Kinyarwanda","Tamil ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.035%","isBolded":false,"associatedRows":["hi - Latn","Hindi ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.212","isBolded":false,"associatedRows":["ms","Malay"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.123","isBolded":false,"associatedRows":["tr","Turkish","Portuguese","te - Latn","Russian ( Latin )","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.174","isBolded":false,"associatedRows":["sl","Slovenian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.019%","isBolded":false,"associatedRows":["de","German","Portuguese","haw","Russian ( Latin )","Hawaiian","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.726","isBolded":false,"associatedRows":["vi","Vietnamese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.147%","isBolded":false,"associatedRows":["ar","Arabic"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.026%","isBolded":false,"associatedRows":["bn","Bengali"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.004%","isBolded":false,"associatedRows":["et","Estonian","ta - Latn","Sundanese","Kinyarwanda","Tamil ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"3.501%","isBolded":false,"associatedRows":["de","German","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.108","isBolded":false,"associatedRows":["ja","Japanese","ml","Bulgarian ( Latin )","Malayalam"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"2.832","isBolded":false,"associatedRows":["ja","Japanese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.138","isBolded":false,"associatedRows":["es","Spanish","Portuguese","tg","Tajik","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.064","isBolded":false,"associatedRows":["co","Corsican","gu - Latn","Gujarati ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.023%","isBolded":false,"associatedRows":["az","Scots Gaelic","Azerbaijani"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.079","isBolded":false,"associatedRows":["uk","Ukrainian","ig","Igbo"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.008%","isBolded":false,"associatedRows":["eo","Esperanto","km","Khmer"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["bg","Bulgarian","sw","Swahili"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.004%","isBolded":false,"associatedRows":["jv","Javanese","or","Oriya"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.364%","isBolded":false,"associatedRows":["no","Norwegian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.060","isBolded":false,"associatedRows":["eo","Esperanto","km","Khmer"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.110","isBolded":false,"associatedRows":["fi","Finnish","is","Icelandic"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"4.701","isBolded":false,"associatedRows":["pt","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.232","isBolded":false,"associatedRows":["hi","Hindi"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.007%","isBolded":false,"associatedRows":["be","Belarusian","ckb","Gujarati ( Latin )","Unknown"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.017%","isBolded":false,"associatedRows":["tr","Turkish","Portuguese","te - Latn","Russian ( Latin )","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.418%","isBolded":false,"associatedRows":["fi","Finnish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.040","isBolded":false,"associatedRows":["hi - Latn","Hindi ( Latin )","yo","Yoruba"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.002%","isBolded":false,"associatedRows":["lt","Lithuanian","st","Sesotho"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.035","isBolded":false,"associatedRows":["bn","Bengali","su","Sundanese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.020","isBolded":false,"associatedRows":["az","Scots Gaelic","Azerbaijani","zu","Zulu"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.634%","isBolded":false,"associatedRows":["pt","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.175","isBolded":false,"associatedRows":["fil","Tagalog"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.032","isBolded":false,"associatedRows":["jv","Javanese","or","Oriya"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.704%","isBolded":false,"associatedRows":["sv","Swedish","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.049%","isBolded":false,"associatedRows":["el","Greek"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.137","isBolded":false,"associatedRows":["und","Unknown","Portuguese","tt","Tatar","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.006%","isBolded":false,"associatedRows":["th","Thai","gu","Gujarati"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.076","isBolded":false,"associatedRows":["ps","Pashto","am","Amharic"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"3.932","isBolded":false,"associatedRows":["ru","Russian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.373","isBolded":false,"associatedRows":["sr","Serbian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.024%","isBolded":false,"associatedRows":["gl","Galician"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.427","isBolded":false,"associatedRows":["bs","Bosnian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.001%","isBolded":false,"associatedRows":["ka","Georgian","tk","Turkmen"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.069","isBolded":false,"associatedRows":["la","Latin","my","Burmese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.194","isBolded":false,"associatedRows":["bn","Bengali"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.014","isBolded":false,"associatedRows":["gd","Scots Gaelic","sn","Shona"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.376","isBolded":false,"associatedRows":["ht","Haitian Creole"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.075","isBolded":false,"associatedRows":["ro","Romanian","mr","Marathi"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.080","isBolded":false,"associatedRows":["ceb","Cebuano","uz","Uzbek"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.003%","isBolded":false,"associatedRows":["gl","Galician","ug","Uighur"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.002%","isBolded":false,"associatedRows":["gd","Scots Gaelic","sn","Shona"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.268","isBolded":false,"associatedRows":["lb","Hindi ( Latin )","Luxembourgish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.477","isBolded":false,"associatedRows":["iw","Hebrew"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.192","isBolded":false,"associatedRows":["jv","Javanese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["hi - Latn","Hindi ( Latin )","yo","Yoruba"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"5.218","isBolded":false,"associatedRows":["sv","Swedish","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.030","isBolded":false,"associatedRows":["fil","Tagalog","mi","Maori"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.163","isBolded":false,"associatedRows":["lt","Lithuanian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.134","isBolded":false,"associatedRows":["it","Italian","Portuguese","kk","Kazakh","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.046","isBolded":false,"associatedRows":["hy","Armenian","lo","Laothian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.890","isBolded":false,"associatedRows":["uk","Ukrainian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"9.699","isBolded":false,"associatedRows":["it","Italian","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.010%","isBolded":false,"associatedRows":["ro","Romanian","mr","Marathi"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.058%","isBolded":false,"associatedRows":["bs","Bosnian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.075","isBolded":false,"associatedRows":["hu","Hungarian","ne","Nepali"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.382%","isBolded":false,"associatedRows":["ja","Japanese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.014%","isBolded":false,"associatedRows":["ko","Korean","kn","Kannada"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.012%","isBolded":false,"associatedRows":["da","Danish","bg - Latn","Bulgarian ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["ht","Belarusian","Haitian Creole","ky","Kyrgyz"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.175","isBolded":false,"associatedRows":["gl","Galician"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.038","isBolded":false,"associatedRows":["hi","Hindi","zh - Latn","Sundanese","Chinese ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"77.984%","isBolded":false,"associatedRows":["en","English","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.140","isBolded":false,"associatedRows":["de","German","Portuguese","haw","Macedonian","Hawaiian","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.482","isBolded":false,"associatedRows":["la","Latin"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.051%","isBolded":false,"associatedRows":["ht","Haitian Creole"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.040","isBolded":false,"associatedRows":["bg","Bulgarian","sw","Swahili"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.086%","isBolded":false,"associatedRows":["ps","Pashto"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.012","isBolded":false,"associatedRows":["ceb","Cebuano"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.006%","isBolded":false,"associatedRows":["ar - Latn","Hindi ( Latin )","Arabic ( Latin )","ha","Hausa"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.018%","isBolded":false,"associatedRows":["nl","Portuguese","ru - Latn","Russian ( Latin )","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["bs","Bosnian","ml - Latn","Gujarati ( Latin )","Malayalam ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.081","isBolded":false,"associatedRows":["ar","Arabic","mg","Bulgarian ( Latin )","Malagasy"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.179","isBolded":false,"associatedRows":["et","Estonian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.015%","isBolded":false,"associatedRows":["ru","Russian","fy","Frisian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.091","isBolded":false,"associatedRows":["ar","Arabic"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"3.250%","isBolded":false,"associatedRows":["fr","French","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"3.101","isBolded":false,"associatedRows":["fi","Finnish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.021%","isBolded":false,"associatedRows":["ka","Georgian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.018%","isBolded":false,"associatedRows":["sv","Swedish","Portuguese","hmn","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.075%","isBolded":false,"associatedRows":["hu","Hungarian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["cy","Welsh","si","Gujarati ( Latin )","Sinhalese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"7.690","isBolded":false,"associatedRows":["nl","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"2.695","isBolded":false,"associatedRows":["no","Norwegian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"2.112%","isBolded":false,"associatedRows":["es","Spanish","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.059%","isBolded":false,"associatedRows":["fa","Persian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.024%","isBolded":false,"associatedRows":["et","Estonian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.008","isBolded":false,"associatedRows":["eu","Basque","xh","Xhosa"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.010%","isBolded":false,"associatedRows":["hu","Hungarian","ne","Nepali"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.008%","isBolded":false,"associatedRows":["sr","Serbian","el - Latn","Gujarati ( Latin )","Greek ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.019%","isBolded":false,"associatedRows":["und","Unknown","Portuguese","tt","Tatar","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.187%","isBolded":false,"associatedRows":["da","Danish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.002%","isBolded":false,"associatedRows":["te","Telugu","kn - Latn","Turkmen","Kinyarwanda","Kannada ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.003%","isBolded":false,"associatedRows":["sl","Slovenian","rw","Sundanese","Kinyarwanda"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.076","isBolded":false,"associatedRows":["ca","Catalan","ga","Irish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.044","isBolded":false,"associatedRows":["sk","Slovak","yi","Yiddish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.044%","isBolded":false,"associatedRows":["ar - Latn","Belarusian","Arabic ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["la","Latin","my","Burmese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.636","isBolded":false,"associatedRows":["ca","Catalan"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"578.064","isBolded":false,"associatedRows":["en","English","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.119","isBolded":false,"associatedRows":["pt","Norwegian","Portuguese","lv","Latvian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"24.094","isBolded":false,"associatedRows":["fr","French","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"10.764","isBolded":false,"associatedRows":["pl","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.010%","isBolded":false,"associatedRows":["ps","Pashto","am","Amharic"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.024%","isBolded":false,"associatedRows":["sl","Slovenian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.046","isBolded":false,"associatedRows":["ar - Latn","Hindi ( Latin )","Arabic ( Latin )","ha","Hausa"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.014%","isBolded":false,"associatedRows":["no","Norwegian","ja - Latn","Bulgarian ( Latin )","Japanese ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.108","isBolded":false,"associatedRows":["zh","Chinese","af","Afrikaans"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["hr","Croatian","sm","Samoan"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.155","isBolded":false,"associatedRows":["ka","Georgian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.530%","isBolded":false,"associatedRows":["ru","Russian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["ms","Malay","ny","Nyanja"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"25.954","isBolded":false,"associatedRows":["de","German","Portuguese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.198","isBolded":false,"associatedRows":["hr","Croatian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"1.037%","isBolded":false,"associatedRows":["nl","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.134","isBolded":false,"associatedRows":["nl","Portuguese","ru - Latn","Russian ( Latin )","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.107","isBolded":false,"associatedRows":["no","Norwegian","ja - Latn","Bulgarian ( Latin )","Japanese ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["fa","Persian","mr - Latn","Gujarati ( Latin )","Marathi ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.016%","isBolded":false,"associatedRows":["pt","Norwegian","Portuguese","lv","Latvian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.510","isBolded":false,"associatedRows":["ro","Romanian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.038%","isBolded":false,"associatedRows":["th","Thai"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.035","isBolded":false,"associatedRows":["hr","Croatian","sm","Samoan"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.266","isBolded":false,"associatedRows":["bg","Bulgarian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.003%","isBolded":false,"associatedRows":["az","Scots Gaelic","Azerbaijani","zu","Zulu"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.076","isBolded":false,"associatedRows":["vi","Vietnamese","so","Somali"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.042%","isBolded":false,"associatedRows":["sk","Slovak"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.031%","isBolded":false,"associatedRows":["hi","Hindi"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.065%","isBolded":false,"associatedRows":["cy","Welsh"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.481","isBolded":false,"associatedRows":["cy","Welsh"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.018%","isBolded":false,"associatedRows":["pl","Portuguese","mk","Macedonian","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.069","isBolded":false,"associatedRows":["iw","Hebrew","ku","Kurdish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.022%","isBolded":false,"associatedRows":["lt","Lithuanian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.021%","isBolded":false,"associatedRows":["te","Telugu"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.175","isBolded":false,"associatedRows":["id","Norwegian","Indonesian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.257","isBolded":false,"associatedRows":["hi - Latn","Hindi ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.010","isBolded":false,"associatedRows":["ka","Georgian","tk","Turkmen"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.015%","isBolded":false,"associatedRows":["fi","Finnish","is","Icelandic"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.628%","isBolded":false,"associatedRows":["und","Unknown","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.043","isBolded":false,"associatedRows":["th","Thai","gu","Gujarati"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.348","isBolded":false,"associatedRows":["eo","Esperanto"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.010%","isBolded":false,"associatedRows":["vi","Vietnamese","so","Somali"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.132","isBolded":false,"associatedRows":["sv","Swedish","Portuguese","hmn","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.015%","isBolded":false,"associatedRows":["cs","Czech","sq","Albanian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.086","isBolded":false,"associatedRows":["id","Vietnamese","Indonesian","mt","Maltese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.063","isBolded":false,"associatedRows":["sr","Serbian","el - Latn","Gujarati ( Latin )","Greek ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.004%","isBolded":false,"associatedRows":["fil","Tagalog","mi","Maori"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.170","isBolded":false,"associatedRows":["az","Scots Gaelic","Azerbaijani"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.018%","isBolded":false,"associatedRows":["it","Italian","Portuguese","kk","Kazakh","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.159%","isBolded":false,"associatedRows":["id","Vietnamese","Indonesian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.402%","isBolded":false,"associatedRows":["zh","Chinese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.026%","isBolded":false,"associatedRows":["jv","Javanese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.027%","isBolded":false,"associatedRows":["hr","Croatian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.006%","isBolded":false,"associatedRows":["lb","Hindi ( Latin )","Luxembourgish","bn - Latn","Bengali ( Latin )","Gujarati"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.064%","isBolded":false,"associatedRows":["iw","Hebrew"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.404%","isBolded":false,"associatedRows":["cs","Czech"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.069","isBolded":false,"associatedRows":["cy","Welsh","si","Gujarati ( Latin )","Sinhalese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.064","isBolded":false,"associatedRows":["ht","Belarusian","Haitian Creole","ky","Kyrgyz"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.108","isBolded":false,"associatedRows":["cs","Czech","sq","Albanian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.065%","isBolded":false,"associatedRows":["la","Latin"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.036%","isBolded":false,"associatedRows":["bg","Bulgarian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.366","isBolded":false,"associatedRows":["el","Greek"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.011%","isBolded":false,"associatedRows":["ar","Arabic","mg","Bulgarian ( Latin )","Malagasy"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.155","isBolded":false,"associatedRows":["te","Telugu"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.024%","isBolded":false,"associatedRows":["fil","Tagalog"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.067","isBolded":false,"associatedRows":["fa","Persian","mr - Latn","Gujarati ( Latin )","Marathi ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.325","isBolded":false,"associatedRows":["ar - Latn","Belarusian","Arabic ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.638","isBolded":false,"associatedRows":["ps","Pashto"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.437","isBolded":false,"associatedRows":["fa","Persian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.392","isBolded":false,"associatedRows":["co","Corsican"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.149","isBolded":false,"associatedRows":["en","English","Portuguese","sd","Sindhi","Hawaiian","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.555","isBolded":false,"associatedRows":["hu","Hungarian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.066","isBolded":false,"associatedRows":["bs","Bosnian","ml - Latn","Gujarati ( Latin )","Malayalam ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.011%","isBolded":false,"associatedRows":["ceb","Cebuano","uz","Uzbek"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.111","isBolded":false,"associatedRows":["ru","Russian","fy","Frisian"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.009%","isBolded":false,"associatedRows":["iw","Hebrew","ku","Kurdish"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"2.991","isBolded":false,"associatedRows":["cs","Czech"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.006%","isBolded":false,"associatedRows":["hy","Armenian","lo","Laothian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.025","isBolded":false,"associatedRows":["gl","Galician","ug","Uighur"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"1.387","isBolded":false,"associatedRows":["da","Danish"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.138","isBolded":false,"associatedRows":["fr","French","Portuguese","pa","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.044%","isBolded":false,"associatedRows":["hy","Armenian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.089","isBolded":false,"associatedRows":["da","Danish","bg - Latn","Bulgarian ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.655%","isBolded":false,"associatedRows":["tr","Turkish","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.135","isBolded":false,"associatedRows":["pl","Portuguese","mk","Macedonian","Telugu ( Latin )"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.022","isBolded":false,"associatedRows":["sl","Slovenian","rw","Kinyarwanda"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.005%","isBolded":false,"associatedRows":["bn","Bengali","su","Sundanese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.019%","isBolded":false,"associatedRows":["es","Spanish","Portuguese","tg","Tajik","Telugu ( Latin )"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.015","isBolded":false,"associatedRows":["lt","Lithuanian","st","Sesotho"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.021%","isBolded":false,"associatedRows":["eu","Basque"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.001%","isBolded":false,"associatedRows":["eu","Basque","xh","Xhosa"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.195%","isBolded":false,"associatedRows":["ko","Korean"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"1.452%","isBolded":false,"associatedRows":["pl","Portuguese"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]},{"number":"0.106","isBolded":false,"associatedRows":["ko","Korean","kn","Kannada"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"2.977","isBolded":false,"associatedRows":["zh","Chinese"],"associatedColumns":["Tokens ( B )"],"associatedMergedColumns":[]},{"number":"0.120%","isBolded":false,"associatedRows":["uk","Ukrainian"],"associatedColumns":["Percentage"],"associatedMergedColumns":[]}]},{"caption":"Table 31. With additional training up to 1.3T tokens, PaLM \n62B slightly underperforms Chinchilla on BIG-bench but significantly closes the performance gap, while PaLM 62B \noutperforms Chinchilla on the 9 English NLP tasks and its performance matches the interpolated scaling curve. \n\n","rows":["Preferred","Normalized","2048","512","1024","128","Metric","50","40","30","20","10"],"columns":["Preferred","BIG - bench","62b ( 0 . 79T tokens )","Metric","English NLP","8b ( 0 . 78T tokens )","540b ( 0 . 78T tokens )"],"mergedAllColumns":["Gopher","Chinchilla"],"numberCells":[{"number":"52.5","isBolded":false,"associatedRows":["Normalized","20"],"associatedColumns":["English NLP","Metric","Preferred"],"associatedMergedColumns":["Gopher"]},{"number":"0.0","isBolded":false,"associatedRows":["Normalized"],"associatedColumns":["BIG - bench","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"57.5","isBolded":false,"associatedRows":["Normalized","30"],"associatedColumns":["English NLP","Metric","62b ( 0 . 79T tokens )"],"associatedMergedColumns":[]},{"number":"65.0","isBolded":false,"associatedRows":["Preferred","40"],"associatedColumns":["English NLP"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["Normalized","10","128","512","1024"],"associatedColumns":["BIG - bench","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"0.6","isBolded":false,"associatedRows":["Normalized","10","128","512","1024","2048"],"associatedColumns":["English NLP","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"0.8","isBolded":false,"associatedRows":["Normalized","10","128","512","1024","2048","128"],"associatedColumns":["English NLP","8b ( 0 . 78T tokens )","540b ( 0 . 78T tokens )"],"associatedMergedColumns":["Chinchilla"]},{"number":"50.0","isBolded":false,"associatedRows":["Normalized","10","128","512","1024","2048"],"associatedColumns":["English NLP","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"1.0","isBolded":false,"associatedRows":["Metric"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["Normalized"],"associatedColumns":["BIG - bench","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"67.5","isBolded":false,"associatedRows":["Metric","50"],"associatedColumns":["English NLP"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Normalized","10","128"],"associatedColumns":["BIG - bench","Metric","Preferred"],"associatedMergedColumns":["Chinchilla"]},{"number":"0.8","isBolded":false,"associatedRows":["Metric"],"associatedColumns":["BIG - bench"],"associatedMergedColumns":[]},{"number":"55.0","isBolded":false,"associatedRows":["Normalized","20"],"associatedColumns":["English NLP","Metric","Preferred"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Normalized"],"associatedColumns":["BIG - bench","Metric","Preferred"],"associatedMergedColumns":["Gopher"]},{"number":"70.0","isBolded":false,"associatedRows":["Metric","50"],"associatedColumns":["English NLP"],"associatedMergedColumns":[]},{"number":"62.5","isBolded":false,"associatedRows":["Preferred","40"],"associatedColumns":["English NLP"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["Preferred","30"],"associatedColumns":["English NLP","Metric"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":false,"associatedRows":["Preferred"],"associatedColumns":["BIG - bench"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Normalized","10","128","512","1024","2048","128","512","1024","2048"],"associatedColumns":["English NLP","8b ( 0 . 78T tokens )","540b ( 0 . 78T tokens )"],"associatedMergedColumns":["Chinchilla"]},{"number":"0.4","isBolded":false,"associatedRows":["Normalized"],"associatedColumns":["BIG - bench","Metric","62b ( 0 . 79T tokens )"],"associatedMergedColumns":[]}]},{"caption":"Table 31: Performance comparison on English NLP tasks of PaLM originally trained on approximately 780 \nbillion tokens, PaLM 62B trained longer on 1325 billion tokens, and Chinchilla trained on 1400 billion tokens. \n\n","rows":["Trivia QA few - shot","Average Task Metric","HellaSWAG 0 - shot","Natural Questions few - shot","Winogrande 0 - shot","Trivia QA 0 - shot","Training FLOP Count ( Zettaflops )","2048","Figure 27 : With additional training to","512","1024","PIQA 0 - shot","Lambada 0 - shot","BoolQ 0 - shot","Performance","30","Natural Questions 0 - shot","10"],"columns":["BIGbench","Chinchilla","PaLM 62B","780","Model Size ( Billions of Parameters )","PaLM 540B","540","MBPP","1325","795","1400","Training Tokens ( Billions of Tokens )","70","60","GSM8K","50","62","40","30","20"],"mergedAllColumns":["67","Total Training FLOP Count ( Zettaflops )","62b ( trained longer )","540b ( 0 . 78T tokens )"],"numberCells":[{"number":"588.0","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Training FLOP Count ( Zettaflops )"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Figure 27 : With additional training to","BoolQ 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"75.4","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Lambada 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"39.6","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions few - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA few - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":["67"]},{"number":"0.4","isBolded":false,"associatedRows":["30","512","1024","2048","10"],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","MBPP","40","30","20"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"67.3","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":[],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"74.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA few - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":["67"]},{"number":"0.8","isBolded":false,"associatedRows":["30","512","1024","2048","10","512","1024","2048","30","512"],"associatedColumns":["PaLM 540B","1325","540","BIGbench","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"0.8","isBolded":false,"associatedRows":[],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60"],"associatedMergedColumns":["67"]},{"number":"295.7","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Training FLOP Count ( Zettaflops )"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["Performance"],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60","50"],"associatedMergedColumns":["62b ( trained longer )"]},{"number":"31.0","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions few - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"76.3","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Lambada 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Winogrande 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":false,"associatedRows":["30","512","1024","2048","10","512","1024"],"associatedColumns":["PaLM 62B","795","62","MBPP","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"0.6","isBolded":false,"associatedRows":["Performance"],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60","50"],"associatedMergedColumns":["67"]},{"number":"80.6","isBolded":false,"associatedRows":["Figure 27 : With additional training to","HellaSWAG 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"80.5","isBolded":false,"associatedRows":["Figure 27 : With additional training to","PIQA 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":[],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"74.9","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Winogrande 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"88.7","isBolded":false,"associatedRows":["Figure 27 : With additional training to","BoolQ 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"65.2","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Average Task Metric"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":["67"]},{"number":"18.1","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["Figure 27 : With additional training to","PIQA 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"21.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Winogrande 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","BoolQ 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["30","512","1024","2048","10","512","1024","2048","30","512","1024","2048"],"associatedColumns":["Chinchilla","1400","70","BIGbench","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"81.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","PIQA 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"16.6","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"1.325Ttokens,PaLM62Bachievessignificantimprovementsona","isBolded":true,"associatedRows":["Figure 27 : With additional training to"],"associatedColumns":["Chinchilla","1400","70","BIGbench","60","50","40"],"associatedMergedColumns":["Total Training FLOP Count ( Zettaflops )"]},{"number":"83.6","isBolded":false,"associatedRows":["Figure 27 : With additional training to","HellaSWAG 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":false,"associatedRows":["Figure 27 : With additional training to","HellaSWAG 0 - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"83.9","isBolded":false,"associatedRows":["Figure 27 : With additional training to","BoolQ 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions few - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"82.3","isBolded":false,"associatedRows":["Figure 27 : With additional training to","PIQA 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"66.5","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Average Task Metric"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":["67"]},{"number":"1.0","isBolded":false,"associatedRows":[],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )"],"associatedMergedColumns":["67"]},{"number":"2527.2","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Training FLOP Count ( Zettaflops )"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"492.9","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Training FLOP Count ( Zettaflops )"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"27.6","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions few - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":[]},{"number":"70.3","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Average Task Metric"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":["67"]},{"number":"72.7","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA few - shot"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":["67"]},{"number":"80.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","HellaSWAG 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":[],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","60","50","40"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"71.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Winogrande 0 - shot"],"associatedColumns":["PaLM 62B","1325","62"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Average Task Metric"],"associatedColumns":["PaLM 62B","795","62"],"associatedMergedColumns":["67"]},{"number":"0.2","isBolded":false,"associatedRows":["30","512"],"associatedColumns":["PaLM 62B","Training Tokens ( Billions of Tokens )","Model Size ( Billions of Parameters )","GSM8K","40","30","20"],"associatedMergedColumns":["540b ( 0 . 78T tokens )"]},{"number":"73.2","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Trivia QA few - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":["67"]},{"number":"77.4","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Lambada 0 - shot"],"associatedColumns":["Chinchilla","1400","70"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Lambada 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]},{"number":"21.2","isBolded":false,"associatedRows":["Figure 27 : With additional training to","Natural Questions 0 - shot"],"associatedColumns":["PaLM 540B","780","540"],"associatedMergedColumns":[]}]},{"caption":"Table 32: Task-specific results comparing PaLM 62B originally trained on approximately 795 billion tokens \nand trained longer on 1325 billion tokens with PaLM 540B on MMLU, BIG-bench, GSM8K, MBPP and \nHumanEval datasets corresponding to ","rows":["Avg NLU 1 - shot","MBPP 3 - shot","BIG - bench 5 - shot","MMLU average 5 - shot","HumanEval 0 - shot","GSM8K 8 - shot + no calculator","Avg NLG 1 - shot"],"columns":["PaLM 540B","1325","795","PaLM 62B","780"],"mergedAllColumns":[],"numberCells":[{"number":"62.8","isBolded":false,"associatedRows":["MMLU average 5 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"63.9","isBolded":true,"associatedRows":["Avg NLG 1 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"15.9","isBolded":false,"associatedRows":["HumanEval 0 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["BIG - bench 5 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"67.3","isBolded":false,"associatedRows":["Avg NLU 1 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["Avg NLG 1 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"54.0","isBolded":true,"associatedRows":["GSM8K 8 - shot + no calculator"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"21.4","isBolded":false,"associatedRows":["MBPP 3 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"74.7","isBolded":true,"associatedRows":["Avg NLU 1 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"26.2","isBolded":true,"associatedRows":["HumanEval 0 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"53.7","isBolded":true,"associatedRows":["BIG - bench 5 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":true,"associatedRows":["MBPP 3 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"32.4","isBolded":false,"associatedRows":["BIG - bench 5 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"23.7","isBolded":false,"associatedRows":["HumanEval 0 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"69.3","isBolded":true,"associatedRows":["MMLU average 5 - shot"],"associatedColumns":["PaLM 540B","780"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Avg NLU 1 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"31.2","isBolded":false,"associatedRows":["MBPP 3 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"60.1","isBolded":false,"associatedRows":["Avg NLG 1 - shot"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["GSM8K 8 - shot + no calculator"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["GSM8K 8 - shot + no calculator"],"associatedColumns":["PaLM 62B","1325"],"associatedMergedColumns":[]},{"number":"53.7","isBolded":false,"associatedRows":["MMLU average 5 - shot"],"associatedColumns":["PaLM 62B","795"],"associatedMergedColumns":[]}]},{"caption":"Table 33: When we compare training longer with a refreshed dataset versus the dataset with repeated \nsubcorpora for an additional 95 billion tokens from the original PaLM 62B baseline, we find that PaLM \n62B performs better on English NLP tasks with the refreshed dataset. Based on this ablation, we continue \ntraining PaLM 62B with a refreshed dataset to 1.325 trillion tokens (see ","rows":["Winogrande 1 - shot","Trivia QA 1 - shot","HellaSWAG 1 - shot","Lambada 1 - shot","BoolQ 1 - shot","ARC - c 1 - shot","PIQA 1 - shot","Natural Questions 1 - shot"],"columns":["( trained on unique data )","in last 95B tokens )","( new data added to avoid","refreshed data","more than once )","training on any data","795B tokens","see data repeats","( smaller subcorpora","repeats in data","890B tokens","original baseline"],"mergedAllColumns":[],"numberCells":[{"number":"80.9","isBolded":false,"associatedRows":["PIQA 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"76.8","isBolded":true,"associatedRows":["Winogrande 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":false,"associatedRows":["Natural Questions 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"76.6","isBolded":false,"associatedRows":["Winogrande 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"83.4","isBolded":false,"associatedRows":["BoolQ 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"83.1","isBolded":false,"associatedRows":["BoolQ 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"72.7","isBolded":false,"associatedRows":["Trivia QA 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"73.3","isBolded":false,"associatedRows":["Trivia QA 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"79.5","isBolded":false,"associatedRows":["HellaSWAG 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"76.6","isBolded":false,"associatedRows":["Winogrande 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"85.8","isBolded":true,"associatedRows":["BoolQ 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"75.5","isBolded":false,"associatedRows":["Lambada 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["Lambada 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"79.0","isBolded":true,"associatedRows":["Lambada 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"23.9","isBolded":false,"associatedRows":["Natural Questions 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":false,"associatedRows":["HellaSWAG 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"74.2","isBolded":true,"associatedRows":["Trivia QA 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"80.1","isBolded":true,"associatedRows":["HellaSWAG 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"24.1","isBolded":true,"associatedRows":["Natural Questions 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["ARC - c 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"80.3","isBolded":false,"associatedRows":["PIQA 1 - shot"],"associatedColumns":["890B tokens","repeats in data","( smaller subcorpora","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"51.8","isBolded":false,"associatedRows":["ARC - c 1 - shot"],"associatedColumns":["795B tokens","original baseline","( trained on unique data )","see data repeats","in last 95B tokens )"],"associatedMergedColumns":[]},{"number":"56.3","isBolded":true,"associatedRows":["ARC - c 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]},{"number":"81.3","isBolded":true,"associatedRows":["PIQA 1 - shot"],"associatedColumns":["890B tokens","refreshed data","( new data added to avoid","training on any data","more than once )"],"associatedMergedColumns":[]}]},{"caption":"Table 40: Results obtained by the PaLM 8B and 62B model in comparison to PaLM 540B across 29 NLP \nbenchmarks. ","rows":["RTE","StoryCloze","WSC","ANLI R3","ANLI R2","ANLI R1","Natural","ReCoRD","Lambada ( EM )","HellaSwag","WiC","BoolQ","TriviaQA ( EM )","Multirc ( F1a )","Questions","Copa","Web Questions ( EM )","CB"],"columns":["62B","H","540B","8B","780B","Additional","Results","795B","PaLM","1325B","0 - shot","1 - shot","Few - shot"],"mergedAllColumns":["Task","( EM )"],"numberCells":[{"number":"36.4","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"24.9","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"21.2","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"81.2","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"75.4","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"34.5","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"75.5","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"89.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"84.9","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"36.3","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"84.8","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"89.1","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"78.9","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"88.8","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"27.6","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"68.7","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"88.1","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"91.2","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"76.9","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"54.2","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"40.8","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"83.8","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"93.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"52.3","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"91.6","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"49.4","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"81.4","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"64.7","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"78.7","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"85.2","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"89.3","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"48.7","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"41.1","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"40.1","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"45.7","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"41.1a","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"84.9","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"80.0","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"77.5","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"52.6","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"72.1","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"91.0","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"47.0","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"64.6","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"83.5","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"86.3","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"8.4","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"89.7(8)","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"57.5","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"86.3","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"23.1","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"43.5(64)","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"93.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"45.4","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"57.8","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"88.0","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"74.8","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["Task"]},{"number":"35.3","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"77.9","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"86.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"22.6","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"57.1","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"81.8","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"83.5","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"83.3","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"81.5","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"67.3","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"68.3","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"82.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"86.1","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"79.6","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"83.9","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"14.6","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"34.5","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"50.6","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"92.9","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"87.8","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"47.3","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"81.0","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"19.9","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"81.4","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"79.7","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"55.5","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"48.4","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"55.4","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"75.5","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"59.1","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"34.5","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"19.8","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"88.7","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"68.9","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"83.4","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"56.1","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"34.9","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"H.1","isBolded":true,"associatedRows":[],"associatedColumns":["H"],"associatedMergedColumns":[]},{"number":"44.2","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"12.6","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"70.1","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"83.6","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"32.4","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"72.7","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"82.7","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"72.7","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"95.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"10.6","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"6.7","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"39.4","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"89.1(8)","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"86.1","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"72.9","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"51.8","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"38.2","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"39.6(64)","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"79.7","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"83.1","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"56.7","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"39.5","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"68.6","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"68.2","isBolded":false,"associatedRows":["HellaSwag"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"83.2","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"91.4","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"51.2","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"10.6","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"87.8","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"36.7","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"78.3","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"86.3","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"78.6","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"18.1","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["Task"]},{"number":"91.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"78.6","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"69.5","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"29.8","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"29.3","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"47.5","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"92.9(2)","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"37.2","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"63.2","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"71.5","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"35.8","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Additional","0 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"11.5","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"57.1","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"88.0","isBolded":false,"associatedRows":["BoolQ"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"78.7","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"32.5","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"31.4","isBolded":false,"associatedRows":["ANLI R2"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"89.0","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"56.9","isBolded":false,"associatedRows":["ANLI R1"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"81.4(1)","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["Task"]},{"number":"84.6","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"83.8","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"93.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"32.7","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"92.8","isBolded":false,"associatedRows":["ReCoRD"],"associatedColumns":["Results","1 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"67.9","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","0 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"26.5","isBolded":false,"associatedRows":["Natural","Questions"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["Task"]},{"number":"93.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","0 - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"86.7","isBolded":false,"associatedRows":["StoryCloze"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"47.2","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"76.5","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"86.0","isBolded":false,"associatedRows":["Copa"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"57.8","isBolded":false,"associatedRows":["RTE"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"71.4","isBolded":false,"associatedRows":["CB"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"89.5","isBolded":false,"associatedRows":["WSC"],"associatedColumns":["Results","Few - shot","PaLM","540B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"81.0","isBolded":false,"associatedRows":["Lambada ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]},{"number":"48.6","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","1 - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"52.4","isBolded":false,"associatedRows":["WiC"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"41.1","isBolded":false,"associatedRows":["Multirc ( F1a )"],"associatedColumns":["Results","Few - shot","PaLM","8B","780B"],"associatedMergedColumns":["( EM )"]},{"number":"29.7","isBolded":false,"associatedRows":["Web Questions ( EM )"],"associatedColumns":["Results","Few - shot","PaLM","62B","795B"],"associatedMergedColumns":["( EM )"]},{"number":"48.5","isBolded":false,"associatedRows":["TriviaQA ( EM )"],"associatedColumns":["Results","1 - shot","PaLM","8B","780B"],"associatedMergedColumns":["Task"]},{"number":"45.9","isBolded":false,"associatedRows":["ANLI R3"],"associatedColumns":["Results","1 - shot","PaLM","62B","1325B"],"associatedMergedColumns":["( EM )"]}]},{"caption":"Table 41: Results obtained by the PaLM 8B, 62B and 540B model across 24 BIG-bench Lite tasks on 5-shot \nevaluation. The reported scores are not normalized, and match those shown in Figure 7. \n","rows":["play dialog same or different","winowhy","auto debugging","known unknowns","symbol interpretation","linguistics puzzles","vitaminc fact verification","formal fallacies syllogisms negation","repeat copy logic","bbq lite json","novel concepts","logic grid puzzle","conlang translation","emoji movie","logical deduction","strange stories","language identification","operators","parsinlu reading comprehension","strategyqa","code line description","conceptual combinations","misconceptions russian","hindu knowledge"],"columns":["Human","( Avg . )","62B","PaLM","540B","8B","( Best )"],"mergedAllColumns":["Task"],"numberCells":[{"number":"59.0","isBolded":false,"associatedRows":["operators"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"16.1","isBolded":false,"associatedRows":["language identification"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"52.3","isBolded":false,"associatedRows":["winowhy"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"52.2","isBolded":false,"associatedRows":["play dialog same or different"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"0.0","isBolded":false,"associatedRows":["linguistics puzzles"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"59.2","isBolded":false,"associatedRows":["misconceptions russian"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"34.9","isBolded":false,"associatedRows":["hindu knowledge"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"53.1","isBolded":false,"associatedRows":["repeat copy logic"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"73.9","isBolded":false,"associatedRows":["strategyqa"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"66.3","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"1.5","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"80.0","isBolded":false,"associatedRows":["formal fallacies syllogisms negation"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["novel concepts"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"84.4","isBolded":false,"associatedRows":["winowhy"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"25.9","isBolded":false,"associatedRows":["conceptual combinations"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"58.7","isBolded":false,"associatedRows":["known unknowns"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"38.2","isBolded":false,"associatedRows":["auto debugging"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"71.2","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"54.8","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"45.1","isBolded":false,"associatedRows":["logic grid puzzle"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"59.4","isBolded":false,"associatedRows":["novel concepts"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"53.1","isBolded":false,"associatedRows":["play dialog same or different"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["vitaminc fact verification"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"77.7","isBolded":false,"associatedRows":["hindu knowledge"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"38.9","isBolded":false,"associatedRows":["vitaminc fact verification"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"91.0","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"40.1","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["code line description"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["conceptual combinations"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"11.8","isBolded":false,"associatedRows":["language identification"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"6.2","isBolded":false,"associatedRows":["repeat copy logic"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"60.6","isBolded":false,"associatedRows":["code line description"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"36.7","isBolded":false,"associatedRows":["misconceptions russian"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"41.9","isBolded":false,"associatedRows":["strange stories"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"92.6","isBolded":false,"associatedRows":["emoji movie"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"73.9","isBolded":false,"associatedRows":["known unknowns"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"95.4","isBolded":false,"associatedRows":["hindu knowledge"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"88.9","isBolded":false,"associatedRows":["logical deduction"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"64.7","isBolded":false,"associatedRows":["misconceptions russian"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"65.4","isBolded":false,"associatedRows":["strategyqa"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"62.9","isBolded":false,"associatedRows":["strategyqa"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"19.0","isBolded":false,"associatedRows":["symbol interpretation"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"55.7","isBolded":false,"associatedRows":["winowhy"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"50.0","isBolded":false,"associatedRows":["auto debugging"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["play dialog same or different"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["strange stories"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"90.6","isBolded":false,"associatedRows":["operators"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"80.1","isBolded":false,"associatedRows":["strange stories"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"0.1","isBolded":false,"associatedRows":["linguistics puzzles"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["emoji movie"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"21.9","isBolded":false,"associatedRows":["symbol interpretation"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"55.4","isBolded":false,"associatedRows":["strategyqa"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"0.1","isBolded":false,"associatedRows":["linguistics puzzles"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"83.2","isBolded":false,"associatedRows":["conceptual combinations"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"52.1","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"36.5","isBolded":false,"associatedRows":["logic grid puzzle"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"23.8","isBolded":false,"associatedRows":["operators"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"36.0","isBolded":false,"associatedRows":["language identification"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["misconceptions russian"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"25.0","isBolded":false,"associatedRows":["emoji movie"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"55.0","isBolded":false,"associatedRows":["language identification"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"49.2","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"15.0","isBolded":false,"associatedRows":["code line description"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"42.3","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"88.4","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"26.7","isBolded":false,"associatedRows":["code line description"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["symbol interpretation"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"49.5","isBolded":false,"associatedRows":["formal fallacies syllogisms negation"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"91.0","isBolded":false,"associatedRows":["emoji movie"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"59.7","isBolded":false,"associatedRows":["conceptual combinations"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"33.3","isBolded":false,"associatedRows":["logic grid puzzle"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"0.0","isBolded":false,"associatedRows":["linguistics puzzles"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["logic grid puzzle"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"36.8","isBolded":false,"associatedRows":["symbol interpretation"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"14.7","isBolded":false,"associatedRows":["auto debugging"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"90.0","isBolded":false,"associatedRows":["strategyqa"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"96.3","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"50.0","isBolded":false,"associatedRows":["known unknowns"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"48.8","isBolded":false,"associatedRows":["formal fallacies syllogisms negation"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"45.2","isBolded":false,"associatedRows":["operators"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"38.2","isBolded":false,"associatedRows":["auto debugging"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"13.7","isBolded":false,"associatedRows":["auto debugging"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"24.4","isBolded":false,"associatedRows":["logical deduction"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"71.9","isBolded":false,"associatedRows":["novel concepts"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"90.0","isBolded":false,"associatedRows":["code line description"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"55.0","isBolded":false,"associatedRows":["emoji movie"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"87.9","isBolded":false,"associatedRows":["strange stories"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"70.2","isBolded":false,"associatedRows":["vitaminc fact verification"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"46.9","isBolded":false,"associatedRows":["novel concepts"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"19.9","isBolded":false,"associatedRows":["symbol interpretation"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"81.3","isBolded":false,"associatedRows":["conceptual combinations"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"38.8","isBolded":false,"associatedRows":["misconceptions russian"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"43.3","isBolded":false,"associatedRows":["logical deduction"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"59.9","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"15.6","isBolded":false,"associatedRows":["repeat copy logic"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"65.9","isBolded":false,"associatedRows":["winowhy"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"80.2","isBolded":false,"associatedRows":["known unknowns"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"63.8","isBolded":false,"associatedRows":["strange stories"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"83.3","isBolded":false,"associatedRows":["repeat copy logic"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"45.6","isBolded":false,"associatedRows":["operators"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"54.1","isBolded":false,"associatedRows":["formal fallacies syllogisms negation"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"30.0","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"12.9","isBolded":false,"associatedRows":["language identification"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["known unknowns"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]},{"number":"63.7","isBolded":false,"associatedRows":["vitaminc fact verification"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"44.4","isBolded":false,"associatedRows":["vitaminc fact verification"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"38.8","isBolded":false,"associatedRows":["repeat copy logic"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"61.9","isBolded":false,"associatedRows":["hindu knowledge"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"40.1","isBolded":false,"associatedRows":["logical deduction"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"51.2","isBolded":false,"associatedRows":["play dialog same or different"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"43.2","isBolded":false,"associatedRows":["play dialog same or different"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"27.6","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"21.6","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"0.0","isBolded":false,"associatedRows":["linguistics puzzles"],"associatedColumns":["PaLM","8B"],"associatedMergedColumns":["Task"]},{"number":"42.4","isBolded":false,"associatedRows":["logic grid puzzle"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"53.3","isBolded":false,"associatedRows":["formal fallacies syllogisms negation"],"associatedColumns":["PaLM","540B"],"associatedMergedColumns":["Task"]},{"number":"31.2","isBolded":false,"associatedRows":["logical deduction"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"67.2","isBolded":false,"associatedRows":["novel concepts"],"associatedColumns":["Human","( Avg . )"],"associatedMergedColumns":["Task"]},{"number":"61.0","isBolded":false,"associatedRows":["winowhy"],"associatedColumns":["PaLM","62B"],"associatedMergedColumns":["Task"]},{"number":"100.0","isBolded":false,"associatedRows":["hindu knowledge"],"associatedColumns":["Human","( Best )"],"associatedMergedColumns":["Task"]}]},{"caption":"Table 42: Preferred metric scores on top ten BIG-bench tasks where the PaLM 540B performance exceeds \nthe average human performance. Raw scores correspond to the scores obtained by the model on the preferred \nmetric for each task (as defined by the task). Normalized scores are obtained from the raw scores by setting \nthe random chance score to 0, and the maximum score to 100. Normalized scores can be negative if the \nmodel performs worse than random chance. \n\n","rows":["persian idioms","conlang translation","sufficient information","logical args","swedish to german proverbs","common morpheme","parsinlu reading comprehension","physics","periodic elements","bbq lite json"],"columns":["PaLM 540B","Normalized score","Raw score","Human ( Avg . )"],"mergedAllColumns":[],"numberCells":[{"number":"49.2","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"39.9","isBolded":true,"associatedRows":["bbq lite json"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"21.6","isBolded":true,"associatedRows":["conlang translation"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"71.5","isBolded":false,"associatedRows":["periodic elements"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":false,"associatedRows":["swedish to german proverbs"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"66.3","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"7.5","isBolded":true,"associatedRows":["periodic elements"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"79.5","isBolded":false,"associatedRows":["sufficient information"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"66.3","isBolded":false,"associatedRows":["conlang translation"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["common morpheme"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"10.3","isBolded":true,"associatedRows":["common morpheme"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"72.7","isBolded":false,"associatedRows":["persian idioms"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"90.6","isBolded":false,"associatedRows":["logical args"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"21.6","isBolded":true,"associatedRows":["conlang translation"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"49.2","isBolded":false,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["physics"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"26.2","isBolded":true,"associatedRows":["swedish to german proverbs"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"1.5","isBolded":true,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"46.8","isBolded":true,"associatedRows":["swedish to german proverbs"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":["common morpheme"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"7.5","isBolded":true,"associatedRows":["periodic elements"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":true,"associatedRows":["bbq lite json"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"32.8","isBolded":true,"associatedRows":["common morpheme"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":true,"associatedRows":["logical args"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"-6.7","isBolded":true,"associatedRows":["persian idioms"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"30.8","isBolded":true,"associatedRows":["sufficient information"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"79.9","isBolded":false,"associatedRows":["swedish to german proverbs"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"94.4","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"1.5","isBolded":true,"associatedRows":["parsinlu reading comprehension"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":true,"associatedRows":["physics"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"96.3","isBolded":false,"associatedRows":["bbq lite json"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"19.9","isBolded":true,"associatedRows":["physics"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"20.0","isBolded":true,"associatedRows":["persian idioms"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"77.3","isBolded":false,"associatedRows":["physics"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"79.5","isBolded":false,"associatedRows":["sufficient information"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"52.6","isBolded":true,"associatedRows":["logical args"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"63.6","isBolded":false,"associatedRows":["persian idioms"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"30.8","isBolded":true,"associatedRows":["sufficient information"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"88.3","isBolded":false,"associatedRows":["logical args"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"71.5","isBolded":false,"associatedRows":["periodic elements"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]}]},{"caption":"Table 43: Preferred metric scores on top ten BIG-bench tasks where the average human performance exceeds \nthe PaLM 540B performance. Raw scores correspond to the scores obtained by the model on the preferred \nmetric for each task (as defined by the task). Normalized scores are obtained from the raw scores by setting \nthe random chance score to 0, and the maximum score to 100. Normalized scores can be negative if the \nmodel performs worse than random chance. \n","rows":["temporal sequences","navigate","ascii word recognition","movie recommendation","hhh alignment","mnist ascii","hyperbaton","chinese remainder theorem","simple text editing","tracking shuffled objects"],"columns":["PaLM 540B","Normalized score","Raw score","Human ( Avg . )"],"mergedAllColumns":[],"numberCells":[{"number":"10.6","isBolded":true,"associatedRows":["navigate"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"90.6","isBolded":false,"associatedRows":["temporal sequences"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["tracking shuffled objects"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":true,"associatedRows":["navigate"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"60.4","isBolded":false,"associatedRows":["movie recommendation"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":true,"associatedRows":["chinese remainder theorem"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"13.4","isBolded":true,"associatedRows":["ascii word recognition"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"29.3","isBolded":true,"associatedRows":["temporal sequences"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["chinese remainder theorem"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"12.5","isBolded":true,"associatedRows":["movie recommendation"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"12.2","isBolded":true,"associatedRows":["mnist ascii"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"4.9","isBolded":true,"associatedRows":["tracking shuffled objects"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":true,"associatedRows":["simple text editing"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"51.1","isBolded":true,"associatedRows":["hhh alignment"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"62.2","isBolded":false,"associatedRows":["tracking shuffled objects"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":true,"associatedRows":["hyperbaton"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["chinese remainder theorem"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":true,"associatedRows":["hyperbaton"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"2.4","isBolded":true,"associatedRows":["mnist ascii"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"87.5","isBolded":false,"associatedRows":["temporal sequences"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["hhh alignment"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"2.2","isBolded":true,"associatedRows":["hhh alignment"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"23.9","isBolded":true,"associatedRows":["tracking shuffled objects"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"47.0","isBolded":true,"associatedRows":["temporal sequences"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":true,"associatedRows":["chinese remainder theorem"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"47.2","isBolded":false,"associatedRows":["movie recommendation"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"75.1","isBolded":false,"associatedRows":["hyperbaton"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"78.0","isBolded":false,"associatedRows":["navigate"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"91.0","isBolded":false,"associatedRows":["mnist ascii"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"56.7","isBolded":false,"associatedRows":["simple text editing"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"50.2","isBolded":false,"associatedRows":["hyperbaton"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["hhh alignment"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":false,"associatedRows":["mnist ascii"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"34.4","isBolded":true,"associatedRows":["movie recommendation"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["ascii word recognition"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"13.4","isBolded":true,"associatedRows":["ascii word recognition"],"associatedColumns":["Normalized score","PaLM 540B"],"associatedMergedColumns":[]},{"number":"56.0","isBolded":false,"associatedRows":["navigate"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["ascii word recognition"],"associatedColumns":["Normalized score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"56.7","isBolded":false,"associatedRows":["simple text editing"],"associatedColumns":["Raw score","Human ( Avg . )"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":true,"associatedRows":["simple text editing"],"associatedColumns":["Raw score","PaLM 540B"],"associatedMergedColumns":[]}]},{"caption":"Table 44: Granular ROUGE-2 results for GEM datasets split into precision, recall, and f-measure, expanding \non the results reported in Section 6.6. \n\n","rows":["13 . 3 / 14 . 8 / 12 . 2","25 . 2 / 22 . 4 / 23 . 2","XSum ( en )","22 . 5 / 20 . 3 / 21 . 0"],"columns":["23 . 9 / 17 . 4 / 19 . 0","32 . 4 / 29 . 9 / 30 . 6","540B","23 . 9 / 23 . 3 / 23 . 4","51 . 3 / 48 . 3 / 49 . 2","12 . 4 / 12 . 5 / 12 . 0","22 . 1 / 17 . 7 / 18 . 6","27 . 9 / 21 . 5 / 23 . 2","PaLM","34 . 2 / 32 . 8 / 33 . 1","24 . 6 / 19 . 7 / 20 . 9","Finetuning","47 . 1 / 44 . 8 / 45 . 3","26 . 6 / 22 . 3 / 23 . 1"],"mergedAllColumns":["Summarization"],"numberCells":[{"number":"56.36","isBolded":false,"associatedRows":["XSum ( en )","13 . 3 / 14 . 8 / 12 . 2","25 . 2 / 22 . 4 / 23 . 2","22 . 5 / 20 . 3 / 21 . 0"],"associatedColumns":["Finetuning","PaLM","540B","32 . 4 / 29 . 9 / 30 . 6","47 . 1 / 44 . 8 / 45 . 3","51 . 3 / 48 . 3 / 49 . 2","23 . 9 / 23 . 3 / 23 . 4","34 . 2 / 32 . 8 / 33 . 1","12 . 4 / 12 . 5 / 12 . 0","27 . 9 / 21 . 5 / 23 . 2","24 . 6 / 19 . 7 / 20 . 9","22 . 1 / 17 . 7 / 18 . 6","26 . 6 / 22 . 3 / 23 . 1","23 . 9 / 17 . 4 / 19 . 0"],"associatedMergedColumns":["Summarization"]}]},{"caption":"Table 45: Granular ROUGE-L results for GEM data-to-text and summarization datasets split into \nprecision/recall/f-measure, expanding on the results reported in Section 6.6. \n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 46: BLEURT-20 results for GEM data-to-text and summarization datasets, expanding on the results \nreported in Section 6.6. \n","rows":["WikiLingua ( vi ? en )","MLSum ( de )","WikiLingua ( ru ? en )","WikiLingua ( es ? en )","MLSum ( es )","WikiLingua ( tr ? en )","E2E ( en )","XSum ( en )","WikiLingua ( en )","Czech Restaurant ( cs )","WebNLG ( en )","WebNLG ( ru )"],"columns":["T5","62B","PaLM","540B","8B","Finetuning","XXL","1 - shot"],"mergedAllColumns":["Data - To - Text","Summarization"],"numberCells":[{"number":"68.95","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"76.44","isBolded":true,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"41.82","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"54.32","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"53.86","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"26.49","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"67.92","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"31.58","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"38.97","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"52.15","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"77.49","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"42.56","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"50.54","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"51.04","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"45.71","isBolded":true,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"56.36","isBolded":true,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"50.54","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"78.01","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"57.50","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"24.31","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"76.65","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"23.23","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"56.64","isBolded":false,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"52.93","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"54.44","isBolded":true,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"49.27","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"44.80","isBolded":false,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"79.19","isBolded":true,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"71.25","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"44.62","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"76.01","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"60.82","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"56.15","isBolded":false,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"35.18","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"45.38","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"75.13","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"47.22","isBolded":false,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"45.55","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"45.38","isBolded":true,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"29.76","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"30.45","isBolded":false,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"57.29","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"76.80","isBolded":true,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"44.78","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"40.53","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"75.85","isBolded":true,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"53.01","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"45.54","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"51.80","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Data - To - Text"]},{"number":"51.26","isBolded":true,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"61.05","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"61.44","isBolded":true,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"73.94","isBolded":true,"associatedRows":["WebNLG ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"27.24","isBolded":true,"associatedRows":["MLSum ( es )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"44.55","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"41.54","isBolded":false,"associatedRows":["WikiLingua ( tr ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"56.13","isBolded":true,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"40.96","isBolded":true,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"31.82","isBolded":true,"associatedRows":["MLSum ( es )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"66.53","isBolded":true,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"36.37","isBolded":false,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"57.86","isBolded":true,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"69.72","isBolded":true,"associatedRows":["E2E ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"53.49","isBolded":false,"associatedRows":["WikiLingua ( es ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"74.37","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"41.14","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"54.99","isBolded":true,"associatedRows":["WikiLingua ( vi ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"48.89","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"46.94","isBolded":true,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"75.82","isBolded":false,"associatedRows":["WebNLG ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"54.26","isBolded":true,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"52.93","isBolded":false,"associatedRows":["Czech Restaurant ( cs )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"54.11","isBolded":false,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"47.72","isBolded":true,"associatedRows":["WikiLingua ( en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"42.36","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["1 - shot","PaLM","8B"],"associatedMergedColumns":["Summarization"]},{"number":"55.50","isBolded":false,"associatedRows":["XSum ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"44.85","isBolded":true,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["1 - shot","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"75.83","isBolded":false,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"55.31","isBolded":false,"associatedRows":["WebNLG ( ru )"],"associatedColumns":["1 - shot","PaLM","62B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"63.20","isBolded":true,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","PaLM","540B"],"associatedMergedColumns":["Summarization"]},{"number":"49.00","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]},{"number":"76.46","isBolded":true,"associatedRows":["E2E ( en )"],"associatedColumns":["Finetuning","PaLM","8B"],"associatedMergedColumns":["Data - To - Text"]},{"number":"52.92","isBolded":false,"associatedRows":["WikiLingua ( ru ? en )"],"associatedColumns":["Finetuning","PaLM","62B"],"associatedMergedColumns":["Summarization"]},{"number":"61.63","isBolded":false,"associatedRows":["MLSum ( de )"],"associatedColumns":["Finetuning","T5","XXL"],"associatedMergedColumns":["Summarization"]}]}]