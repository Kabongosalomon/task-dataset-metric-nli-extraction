[{"caption":"Table 1: Comparison with heuristic methods (AUC). \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 2: Comparison with latent feature methods (AUC). \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 5. The AP comparison results \nwith latent feature methods are shown in ","rows":["Comparison with heuristic methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"90%traininglinks.","isBolded":false,"associatedRows":["Comparison with heuristic methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 6. We can see that our proposed SEAL shows great \nperformance improvement over all baselines in both AUC and AP. \n\n","rows":["Comparison with heuristic methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"90%traininglinks.","isBolded":false,"associatedRows":["Comparison with heuristic methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 5: Comparison with heuristic methods (AP), 90% training links. \n\n","rows":["Comparison with heuristic methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"90%traininglinks.","isBolded":false,"associatedRows":["Comparison with heuristic methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 6: Comparison with latent feature methods (AP), 90% training links. \n\n","rows":["Comparison with latent feature methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"90%traininglinks.","isBolded":false,"associatedRows":["Comparison with latent feature methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 7. As \nwe can see, SEAL has good scalability. For networks with over 1E7 potential links, SEAL took less \nthan an hour to make all the predictions. One possible way to further scale SEAL to social networks \nwith millions of users is to first use some simple heuristics such as common neighbors to filter out \nmost unlikely links and then use SEAL to make further recommendations. Another way is to restrict \nthe candidate friend recommendations to be those who are at most 2 or 3 hops away from the target \nuser, which will vastly reduce the number of candidate links to infer for each user and thus further \nincrease the scalability. \n\n","rows":["Comparison with latent feature methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"90%traininglinks.","isBolded":false,"associatedRows":["Comparison with latent feature methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 7: Inference time of SEAL. \n\n","rows":["321","146","16","Inference time for all potential links ( s )","31"],"columns":["1 . 22E+07","2 . 13E - 04","Yeast","2 . 82E+06","1 . 35E - 04","1 . 26E+07","Router","3 . 96E - 04","Power"],"mergedAllColumns":[],"numberCells":[{"number":"1640","isBolded":false,"associatedRows":["Inference time for all potential links ( s )","31","321","146","16"],"associatedColumns":["Power","1 . 22E+07","1 . 35E - 04"],"associatedMergedColumns":[]},{"number":"2681","isBolded":false,"associatedRows":["Inference time for all potential links ( s )","31","321","146","16"],"associatedColumns":["Router","1 . 26E+07","2 . 13E - 04"],"associatedMergedColumns":[]},{"number":"1106","isBolded":false,"associatedRows":["Inference time for all potential links ( s )","31","321","146"],"associatedColumns":["Yeast","2 . 82E+06","3 . 96E - 04"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparison with heuristic methods (AUC), 50% training links. \n\n","rows":["Comparison with heuristic methods ( AUC ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"50%traininglinks.","isBolded":false,"associatedRows":["Comparison with heuristic methods ( AUC ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 9: Comparison with latent feature methods (AUC), 50% training links. \n\n","rows":["Comparison with latent feature methods ( AUC ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"50%traininglinks.","isBolded":false,"associatedRows":["Comparison with latent feature methods ( AUC ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 10: Comparison with heuristic methods (AP), 50% training links. \n\n","rows":["Comparison with latent feature methods ( AUC ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"50%traininglinks.","isBolded":false,"associatedRows":["Comparison with latent feature methods ( AUC ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 11: Comparison with latent feature methods (AP), 50% training links. \n\n","rows":["Comparison with heuristic methods ( AP ) ,"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"50%traininglinks.","isBolded":false,"associatedRows":["Comparison with heuristic methods ( AP ) ,"],"associatedColumns":[],"associatedMergedColumns":[]}]}]