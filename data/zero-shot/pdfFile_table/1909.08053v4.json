[{"caption":"Table 1. Parameters used for scaling studies. Hidden size per atten-\ntion head is kept constant at 96. \n\n","rows":["24","100%","16","3072","1536","1920","Weak","2304","Scaling","72","40","20","64","54","32"],"columns":["Model + Data Parallel","Model Parallel","GPUs","Size","Attention","( billions )","1","2","256","Number","4","parallel","512","of","128","8","layers","Model","+data","Hidden","heads","parameters","64"],"mergedAllColumns":["100%"],"numberCells":[{"number":"4.2","isBolded":false,"associatedRows":["Scaling","2304","24","64"],"associatedColumns":["Number","of","parameters","( billions )","1","2"],"associatedMergedColumns":[]},{"number":"2.5","isBolded":false,"associatedRows":["Scaling","1920","20","54"],"associatedColumns":["Number","of","parameters","( billions )","1"],"associatedMergedColumns":[]},{"number":"40%","isBolded":true,"associatedRows":["Weak"],"associatedColumns":["Number","Hidden","Size","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"20%","isBolded":true,"associatedRows":["Weak"],"associatedColumns":["Number","Hidden","Size","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"60%","isBolded":true,"associatedRows":["Scaling"],"associatedColumns":["Number","Hidden","Size","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"95%","isBolded":true,"associatedRows":["Scaling","3072"],"associatedColumns":["Number","Attention","heads","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"1.2","isBolded":false,"associatedRows":["Scaling","1536","16","40"],"associatedColumns":["Number","of","parameters","( billions )"],"associatedMergedColumns":[]},{"number":"79%","isBolded":true,"associatedRows":["Scaling","3072","32","72"],"associatedColumns":["Model","+data","parallel","GPUs","64","128","256","512","Model + Data Parallel"],"associatedMergedColumns":["100%"]},{"number":"74%","isBolded":true,"associatedRows":["Scaling","3072","32","72"],"associatedColumns":["Model","+data","parallel","GPUs","64","128","256","512","Model + Data Parallel"],"associatedMergedColumns":["100%"]},{"number":"8.3","isBolded":false,"associatedRows":["Scaling","3072","32","72"],"associatedColumns":["Number","of","parameters","( billions )","1","2","4"],"associatedMergedColumns":[]},{"number":"83%","isBolded":true,"associatedRows":["Scaling","3072","32","72"],"associatedColumns":["Model","parallel","GPUs","( billions )","1","2","4","8","Model + Data Parallel"],"associatedMergedColumns":["100%"]},{"number":"82%","isBolded":true,"associatedRows":["Scaling","3072","32"],"associatedColumns":["Number","of","layers","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"80%","isBolded":true,"associatedRows":["Scaling"],"associatedColumns":["Number","Hidden","Size","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"77%","isBolded":true,"associatedRows":["Scaling","3072","32","72"],"associatedColumns":["Number","of","layers","( billions )","1","2","4","8","Model Parallel"],"associatedMergedColumns":["100%"]},{"number":"96%","isBolded":true,"associatedRows":["Scaling","3072","100%","32","72"],"associatedColumns":["Number","parallel","parameters","( billions )","1","2","4","8","Model + Data Parallel"],"associatedMergedColumns":["100%"]}]},{"caption":"Table 2. Model configurations used for GPT-2. \nHidden \nTime \nParameter Layers Hidden Attn \nSize Total \nper \nCount \nSize Heads \nper \nGPUs Epoch \nHead \n(days) \n355M \n24 \n1024 \n16 \n64 \n64 \n0.86 \n2.5B \n54 \n1920 \n20 \n96 \n128 \n2.27 \n8.3B \n72 \n3072 \n24 \n128 \n512 \n2.10 \n\nTable 3. Zero-shot results. SOTA are from (Khandelwal et al.,  2019) for Wikitext103 and (Radford et al., 2019) for LAMBADA. \n\n","rows":["1920","Previous SOTA","1024","512","128","355M","3072"],"columns":["Head","Size","GPUs","Epoch","Time","Count","Perplexity ?","Table 3 . Zero - shot results .","Attn","( days )","Accuracy ?","LAMBADA","Heads","Total","Table 2 . Model configurations used for GPT - 2 .","Model","Hidden","Parameter","per","Layers","Wikitext103","SOTA are from ( Khandelwal et al . ,"],"mergedAllColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."],"numberCells":[{"number":"63.24%","isBolded":false,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Total","GPUs","( days )","SOTA are from ( Khandelwal et al . ,","LAMBADA","Accuracy ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"61.73%","isBolded":false,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Total","GPUs","( days )","SOTA are from ( Khandelwal et al . ,","LAMBADA","Accuracy ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"66.51%","isBolded":true,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Total","GPUs","( days )","SOTA are from ( Khandelwal et al . ,","LAMBADA","Accuracy ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"15.79","isBolded":false,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head","SOTA are from ( Khandelwal et al . ,","Wikitext103","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"64","isBolded":false,"associatedRows":["355M","355M","1024"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Size","per","Head"],"associatedMergedColumns":[]},{"number":"0.86","isBolded":false,"associatedRows":["355M","355M","1024","128"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Time","per","Epoch","( days )"],"associatedMergedColumns":[]},{"number":"2.5B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Parameter","Count","Head"],"associatedMergedColumns":[]},{"number":"19.31","isBolded":false,"associatedRows":["355M","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head","SOTA are from ( Khandelwal et al . ,","Wikitext103","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"64","isBolded":false,"associatedRows":["355M","355M","1024"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Total","GPUs","( days )"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["355M","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head"],"associatedMergedColumns":[]},{"number":"12.76","isBolded":false,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head","SOTA are from ( Khandelwal et al . ,","Wikitext103","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"96","isBolded":false,"associatedRows":["355M","1920"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Size","per","Head"],"associatedMergedColumns":[]},{"number":"2.27","isBolded":false,"associatedRows":["355M","1920","128"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Time","per","Epoch","( days )"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["355M"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Layers","Size","Head"],"associatedMergedColumns":[]},{"number":"8.3B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Layers","Count","Head","Table 3 . Zero - shot results .","Model","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"16","isBolded":false,"associatedRows":["355M","355M","1024"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head"],"associatedMergedColumns":[]},{"number":"2.10","isBolded":false,"associatedRows":["355M","3072","128","512"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Time","per","Epoch","( days )"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["355M","1920"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head"],"associatedMergedColumns":[]},{"number":"72","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Layers","Size","Head"],"associatedMergedColumns":[]},{"number":"2.5B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Layers","Count","Head","Table 3 . Zero - shot results .","Model","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"45.18%","isBolded":false,"associatedRows":["355M","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Total","GPUs","( days )","SOTA are from ( Khandelwal et al . ,","LAMBADA","Accuracy ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]},{"number":"54","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Layers","Size","Head"],"associatedMergedColumns":[]},{"number":"8.3B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Parameter","Count","Head"],"associatedMergedColumns":[]},{"number":"10.81","isBolded":true,"associatedRows":["Previous SOTA","3072"],"associatedColumns":["Table 2 . Model configurations used for GPT - 2 .","Hidden","Attn","Heads","Head","SOTA are from ( Khandelwal et al . ,","Wikitext103","Perplexity ?"],"associatedMergedColumns":["2019 ) for Wikitext103 and ( Radford et al . , 2019 ) for LAMBADA ."]}]},{"caption":"Table 4. Model configurations used for BERT. \nParameter Layers Hidden Attention \nTotal \nCount \nSize \nHeads \nGPUs \n336M \n24 \n1024 \n16 \n128 \n1.3B \n24 \n2048 \n32 \n256 \n3.9B \n48 \n2560 \n40 \n512 \n\n","rows":["336M","2048","1024","2560"],"columns":["Table 4 . Model configurations used for BERT .","Size","Heads","Attention","Parameter","Count","Layers"],"mergedAllColumns":["256","128"],"numberCells":[{"number":"1.3B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 4 . Model configurations used for BERT .","Parameter","Count"],"associatedMergedColumns":["128"]},{"number":"16","isBolded":false,"associatedRows":["336M","1024"],"associatedColumns":["Table 4 . Model configurations used for BERT .","Attention","Heads"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["336M"],"associatedColumns":["Table 4 . Model configurations used for BERT .","Layers","Size"],"associatedMergedColumns":[]},{"number":"3.9B","isBolded":false,"associatedRows":[],"associatedColumns":["Table 4 . Model configurations used for BERT .","Parameter","Count"],"associatedMergedColumns":["256"]},{"number":"48","isBolded":false,"associatedRows":[],"associatedColumns":["Table 4 . Model configurations used for BERT .","Layers","Size"],"associatedMergedColumns":["256"]},{"number":"40","isBolded":false,"associatedRows":["2560"],"associatedColumns":["Table 4 . Model configurations used for BERT .","Attention","Heads"],"associatedMergedColumns":["256"]},{"number":"24","isBolded":false,"associatedRows":[],"associatedColumns":["Table 4 . Model configurations used for BERT .","Layers","Size"],"associatedMergedColumns":["128"]},{"number":"32","isBolded":false,"associatedRows":["2048"],"associatedColumns":["Table 4 . Model configurations used for BERT .","Attention","Heads"],"associatedMergedColumns":["128"]}]},{"caption":"Table 5. Development set results for MNLI, QQP, SQuAD 1.1 and SQuAD 2.0 and test set results for RACE. The trained tokens represents \nconsumed tokens during model pretraining (proportional to batch size times number of iterations) normalized by consumed tokens during \nmodel pretraining for our 336M model. \n\n","rows":["SQuAD","Megatron - 3 . 9B ensemble","XLNet ( Yang et al . , 2019 )","Megatron - 336M","QQP","1","trained tokens","2","3","RoBERTa ( Liu et al . , 2019b )","MNLI m / mm","ALBERT ( Lan et al . , 2019 )","Megatron - 1 . 3B","Megatron - 3 . 9B","ALBERT ensemble ( Lan et al . , 2019 )"],"columns":["( dev set )","F1 / EM","RACE m / h","accuracy","( test set )"],"mergedAllColumns":[],"numberCells":[{"number":"86.1)","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"90.0","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"84.0)","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"81.5)","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"83.2","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"90.9","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"(90.4/","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"88.6)","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"90.5","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"92.2","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"90.6/","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.9/","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"89.1","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"87.3","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"88.0","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"94.2/","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.2/","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"88.5","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"87.4","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"89.7/","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"92.6","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","trained tokens"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"(89.0/","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"89.4/","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"89.4","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"91.0","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"95.5/","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.0","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"95.1/","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"87.9","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"(91.2/","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"88.9","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.2/","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"91.4/","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.8","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"90.0)","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"89.7","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"92.2","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"81.8)","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"88.1/","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.8/","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"85.4","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"90.8","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"92.3","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"92.3","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"91.2/","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"91.4","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"85.5)","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"86.5","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"94.8/","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens","MNLI m / mm","QQP","SQuAD","SQuAD"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"89.3","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"95.5/","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"86.5","isBolded":false,"associatedRows":["ALBERT ( Lan et al . , 2019 )","3"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"83.0","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"91.4/","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"90.2","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]},{"number":"95.8/","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"(86.5/","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"(88.6/","isBolded":false,"associatedRows":["XLNet ( Yang et al . , 2019 )","2"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"94.9/","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"1.1","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens","MNLI m / mm","QQP","SQuAD"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"(86.9/","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"87.1","isBolded":false,"associatedRows":["Megatron - 1 . 3B","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"88.6)","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"91.7/","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","trained tokens"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"(93.1/","isBolded":true,"associatedRows":["Megatron - 3 . 9B ensemble","trained tokens"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["Megatron - 336M","1"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"94.6/","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"(91.8/","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":true,"associatedRows":["Megatron - 3 . 9B","1"],"associatedColumns":["RACE m / h","accuracy","( test set )"],"associatedMergedColumns":[]},{"number":"88.9","isBolded":false,"associatedRows":["ALBERT ensemble ( Lan et al . , 2019 )","trained tokens"],"associatedColumns":["RACE m / h","F1 / EM","( dev set )"],"associatedMergedColumns":[]},{"number":"90.2/","isBolded":false,"associatedRows":["RoBERTa ( Liu et al . , 2019b )","2"],"associatedColumns":["RACE m / h","accuracy","( dev set )"],"associatedMergedColumns":[]}]},{"caption":"Table 6. Hyperparameters for finetuning BERT model on down-\nstream tasks. \nTask \nModel Batch Learning Training \nsize \nrate \nepochs \n336M \nMNLI \n1.3B \n128 \n1e-5 \n10 \n3.8B \n336M \n128 \n5e-5 \nQQP \n1.3B \n128 \n3e-5 \n12 \n3.8B \n256 \n4e-5 \n336M \n64 \n3e-5 \nSQUAD 1.1 \n1.3B \n48 \n3e-5 \n2 \n3.8B \n48 \n1e-5 \n336M \n48 \n3e-5 \nSQUAD 2.0 \n1.3B \n64 \n3e-5 \n2 \n3.8B \n48 \n1e-5 \n336M \n32 \n2e-5 \nRACE \n1.3B \n16 \n1e-5 \n3 \n3.8B \n32 \n2e-5 \n\n","rows":["336M","QQP","3e - 5","128","RACE","MNLI","SQUAD","1e - 5"],"columns":["336M","Task","1e - 5","Training","3e - 5","256","size","Batch","128","Model","Table 6 . Hyperparameters for finetuning BERT model on down -","epochs","5e - 5"],"mergedAllColumns":["336M","3e - 5","2e - 5","1e - 5"],"numberCells":[{"number":"32","isBolded":false,"associatedRows":["RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5","3e - 5","1e - 5"],"associatedMergedColumns":["2e - 5"]},{"number":"1.3B","isBolded":false,"associatedRows":["SQUAD","MNLI"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size"],"associatedMergedColumns":["336M"]},{"number":"64","isBolded":false,"associatedRows":["SQUAD","QQP","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256"],"associatedMergedColumns":["336M"]},{"number":"48","isBolded":false,"associatedRows":["SQUAD","QQP","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"3.8B","isBolded":false,"associatedRows":["RACE"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256","3e - 5","3e - 5","1e - 5"],"associatedMergedColumns":["2e - 5"]},{"number":"3.8B","isBolded":false,"associatedRows":["RACE"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256","3e - 5","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"2.0","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Task","size","336M","256","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"1.3B","isBolded":false,"associatedRows":["SQUAD","RACE"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"32","isBolded":false,"associatedRows":["RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5","3e - 5"],"associatedMergedColumns":["1e - 5"]},{"number":"48","isBolded":false,"associatedRows":["SQUAD","QQP","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256"],"associatedMergedColumns":["3e - 5"]},{"number":"1.1","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Task","size","336M","256"],"associatedMergedColumns":["3e - 5"]},{"number":"3.8B","isBolded":false,"associatedRows":["SQUAD","MNLI"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size"],"associatedMergedColumns":["336M"]},{"number":"48","isBolded":false,"associatedRows":["SQUAD","RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5"],"associatedMergedColumns":["1e - 5"]},{"number":"48","isBolded":false,"associatedRows":["RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"10","isBolded":false,"associatedRows":["SQUAD","MNLI","336M","128","1e - 5"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Training","epochs"],"associatedMergedColumns":["336M"]},{"number":"12","isBolded":false,"associatedRows":["SQUAD","QQP","336M","128","3e - 5"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Training","epochs","5e - 5"],"associatedMergedColumns":["336M"]},{"number":"64","isBolded":false,"associatedRows":["SQUAD","RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"1.3B","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256"],"associatedMergedColumns":["3e - 5"]},{"number":"1.3B","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M"],"associatedMergedColumns":["336M"]},{"number":"3.8B","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M"],"associatedMergedColumns":["336M"]},{"number":"1.3B","isBolded":false,"associatedRows":["RACE"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256","3e - 5","3e - 5"],"associatedMergedColumns":["2e - 5"]},{"number":"3.8B","isBolded":false,"associatedRows":["SQUAD","QQP"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Model","size","336M","256","3e - 5"],"associatedMergedColumns":["3e - 5"]},{"number":"16","isBolded":false,"associatedRows":["RACE","336M"],"associatedColumns":["Table 6 . Hyperparameters for finetuning BERT model on down -","Batch","size","128","256","3e - 5","3e - 5"],"associatedMergedColumns":["2e - 5"]}]},{"caption":"Table 7. Effect of number of attention heads on scaling on 8.3 \nbillion of parameters with 8-way model parallelism. \n\n","rows":["Table 8 . Speedup obtained for the"],"columns":["Hidden size per head","Scaling Efficiency","128","192","82%","Attention heads","80%"],"mergedAllColumns":["77%"],"numberCells":[{"number":"24","isBolded":false,"associatedRows":[],"associatedColumns":["Attention heads","192"],"associatedMergedColumns":[]},{"number":"96","isBolded":false,"associatedRows":[],"associatedColumns":["Hidden size per head","192","128"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":[],"associatedColumns":["Attention heads"],"associatedMergedColumns":[]},{"number":"1.2billionparametersmodel","isBolded":false,"associatedRows":["Table 8 . Speedup obtained for the"],"associatedColumns":["Scaling Efficiency","82%","80%"],"associatedMergedColumns":["77%"]},{"number":"32","isBolded":false,"associatedRows":[],"associatedColumns":["Attention heads","192","128"],"associatedMergedColumns":[]}]},{"caption":"Attention heads Hidden size per head Scaling Efficiency \n16 \n192 \n82% \n24 \n128 \n80% \n32 \n96 \n77% \n\nTable 8. Speedup obtained for the 1.2 billion parameters model \nusing model parallelism while keeping the batch size constant. \n\n","rows":["Speedup","# of GPUs"],"columns":["using model parallelism while keeping the batch size constant ."],"mergedAllColumns":[],"numberCells":[{"number":"4","isBolded":false,"associatedRows":["# of GPUs"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":["# of GPUs"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"1.64","isBolded":false,"associatedRows":["Speedup"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"2.34","isBolded":false,"associatedRows":["Speedup"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Speedup"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":["# of GPUs"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["# of GPUs"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]},{"number":"2.98","isBolded":false,"associatedRows":["Speedup"],"associatedColumns":["using model parallelism while keeping the batch size constant ."],"associatedMergedColumns":[]}]}]