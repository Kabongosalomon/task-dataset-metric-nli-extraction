[{"caption":"Table 1. Results on the volleyball dataset. We report aver-\nage accuracy for collective activity and individual actions. For \nOURS-temporal for the ground truth bounding boxes (GT) we \nreport results with the bbox matching, and for the detections \n(MRF) we report results with the embed matching. \n\nworks very well. Interestingly, using the embed and \nembed-soft matching are beneficial for the performance \nwhen detections are used instead of the ground truth. It is \nalso understandable: appearance is more robust than coor-\ndinates, but it also means that our model is actually able to \ncapture that robust appearance representation, which might \nnot be absolutely necessary for the prediction in a single \nframe scenario. Note that, whereas for the collective actions \nthe temporal data seems to help significantly, the improve-\nment for the individual action estimation is very modest, \nespecially for the detections. We hypothesize that in order \nto discriminate better between individual actions, it is nec-\nessary to look at how the low-level details change, which \ncould be potentially smoothed out during the spatial pool-\ning, and thus they are hard to capture for our RNN. \n\n","rows":["Inception - person ( GT )","embed - soft ( MRF / GT )","Inception - scene ( GT )","HDTM - scene [ 20 ] ( GT )","OURS - temporal ( MRF / GT )","HDTM - person [ 20 ] ( GT )","OURS - single ( MRF / GT )","boxes ( MRF / GT )","embed ( MRF / GT )","-","HDTM [ 20 ] ( GT )"],"columns":["individual","collective"],"mergedAllColumns":["-"],"numberCells":[{"number":"90.0","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"78.1","isBolded":false,"associatedRows":["Inception - person ( GT )","-"],"associatedColumns":["individual"],"associatedMergedColumns":["-"]},{"number":"89.9","isBolded":true,"associatedRows":["OURS - temporal ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"77.4/","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]},{"number":"82.4","isBolded":true,"associatedRows":["OURS - temporal ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":["-"]},{"number":"81.1","isBolded":false,"associatedRows":["OURS - single ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":["-"]},{"number":"74.7","isBolded":false,"associatedRows":["HDTM - scene [ 20 ] ( GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"77.8/","isBolded":false,"associatedRows":["OURS - single ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":["-"]},{"number":"90.6","isBolded":true,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"87.1/","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"81.9","isBolded":false,"associatedRows":["HDTM [ 20 ] ( GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"86.2/","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"89.9","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"87.1/","isBolded":false,"associatedRows":["OURS - temporal ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"81.8","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]},{"number":"80.2","isBolded":false,"associatedRows":["HDTM - person [ 20 ] ( GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"83.3/","isBolded":false,"associatedRows":["OURS - single ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"68.6/","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]},{"number":"77.9/","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]},{"number":"75.5","isBolded":false,"associatedRows":["Inception - scene ( GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["OURS - single ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":["-"]},{"number":"77.9/","isBolded":false,"associatedRows":["OURS - temporal ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":["-"]},{"number":"81.9","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]},{"number":"82.0/","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["collective","collective"],"associatedMergedColumns":["-"]},{"number":"82.4","isBolded":true,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["individual","individual"],"associatedMergedColumns":["-"]}]},{"caption":"Table 2. Comparison of different matching strategies for the \nvolleyball dataset. boxes corresponds to the nearest neigh-\nbour (NN) match in the space of bounding box coordinates, \nembed corresponds to the NN in the embedding space e, and \nembed-soft is a soft matching in e. \n\n","rows":["embed - soft ( MRF / GT )","boxes ( MRF / GT )","embed ( MRF / GT )"],"columns":["individual","collective"],"mergedAllColumns":[],"numberCells":[{"number":"90.6","isBolded":true,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"86.2/","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"68.6/","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"82.0/","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"82.4","isBolded":true,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"87.1/","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"89.9","isBolded":false,"associatedRows":["boxes ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"77.9/","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"90.0","isBolded":false,"associatedRows":["embed ( MRF / GT )"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"81.8","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"77.4/","isBolded":false,"associatedRows":["embed - soft ( MRF / GT )"],"associatedColumns":["individual"],"associatedMergedColumns":[]}]},{"caption":"Method \ncollective individual \nboxes MRF \n82.0 \n68.6 \nboxes NMS \n77.0 \n68.1 \nembed MRF \n87.1 \n77.9 \nembed NMS \n85.2 \n76.2 \nembed-soft MRF \n86.2 \n77.4 \nembed-soft NMS \n85.1 \n75.7 \n\nTable 3. Comparative results of detection schemes on the \nvolleyball dataset. We report the average accuracy for the \ncollective and individual action recognition. \n\n","rows":["embed NMS","boxes NMS","boxes MRF","embed MRF","embed - soft NMS","embed - soft MRF"],"columns":["individual","collective"],"mergedAllColumns":[],"numberCells":[{"number":"68.6","isBolded":false,"associatedRows":["boxes MRF"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"87.1","isBolded":true,"associatedRows":["embed MRF"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["boxes NMS"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"68.1","isBolded":false,"associatedRows":["boxes NMS"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["embed - soft NMS"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["embed - soft NMS"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["embed - soft MRF"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"82.0","isBolded":false,"associatedRows":["boxes MRF"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"85.2","isBolded":false,"associatedRows":["embed NMS"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"76.2","isBolded":false,"associatedRows":["embed NMS"],"associatedColumns":["individual"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["embed - soft MRF"],"associatedColumns":["collective"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":true,"associatedRows":["embed MRF"],"associatedColumns":["individual"],"associatedMergedColumns":[]}]}]