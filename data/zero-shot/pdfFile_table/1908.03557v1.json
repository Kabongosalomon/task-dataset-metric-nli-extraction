[{"caption":"Table 1, including baselines using the same visual features and number of \nbounding region proposals as our methods (first section), our models (second section), and other \nincomparable methods (third section) that use external question-answer pairs from Visual Genome \n(+VG) , multiple detectors (Yu et al., 2019a) (+Multiple Detectors) and ensembles of their models. \nIn comparable settings, our method is significantly simpler and outperforms existing work. \n\nModel \nTest-Dev Test-Std \n\nPythia v0.1 (Jiang et al., 2018) \n68.49 \n-\nPythia v0.3 (Singh et al., 2019) \n68.71 \n-\n\nVisualBERT w/o Early Fusion \n68.18 \n-\nVisualBERT w/o COCO Pre-training \n70.18 \n-\nVisualBERT \n70.80 \n71.00 \n\nPythia v0.1 + VG + Other Data Augmentation (Jiang et al., 2018) \n70.01 \n70.24 \nMCAN + VG (Yu et al., 2019b) \n70.63 \n70.90 \nMCAN + VG + Multiple Detectors (Yu et al., 2019b)  72.55 \n-\nMCAN + VG + Multiple Detectors + BERT (Yu et al., 2019b)  72.80 \n-\nMCAN + VG + Multiple Detectors + BERT + Ensemble (Yu et al., 2019b)  75.00 \n75.23 \n\nTable 1: Model performance on VQA. VisualBERT outperforms Pythia v0.1 and v0.3, which are \ntested under a comparable setting. \n\n","rows":["VisualBERT w / o Early Fusion","VisualBERT","MCAN + VG + Multiple Detectors + BERT ( Yu et al . , 2019b )","Pythia","Table 1 : Model performance on VQA . VisualBERT outperforms Pythia","VisualBERT w / o COCO Pre - training","MCAN + VG + Multiple Detectors + BERT + Ensemble ( Yu et al . , 2019b )","MCAN + VG ( Yu et al . , 2019b )","MCAN + VG + Multiple Detectors ( Yu et al . , 2019b )"],"columns":["Test - Dev","Test - Std","Model","Table 1 , including baselines using the same visual features and number of"],"mergedAllColumns":["-","In comparable settings , our method is significantly simpler and outperforms existing work ."],"numberCells":[{"number":"70.63","isBolded":false,"associatedRows":["MCAN + VG ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"75.23","isBolded":false,"associatedRows":["MCAN + VG + Multiple Detectors + BERT + Ensemble ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Std"],"associatedMergedColumns":["-"]},{"number":"70.01","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"70.24","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Std"],"associatedMergedColumns":["-"]},{"number":"68.71","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"68.18","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"68.49","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["In comparable settings , our method is significantly simpler and outperforms existing work ."]},{"number":"71.00","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Std"],"associatedMergedColumns":["-"]},{"number":"v0.1(Jiangetal.,2018)","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Model"],"associatedMergedColumns":["In comparable settings , our method is significantly simpler and outperforms existing work ."]},{"number":"v0.1+VG+OtherDataAugmentation(Jiangetal.,2018)","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Model"],"associatedMergedColumns":["-"]},{"number":"v0.1andv0.3,whichare","isBolded":false,"associatedRows":["Table 1 : Model performance on VQA . VisualBERT outperforms Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Std"],"associatedMergedColumns":["-"]},{"number":"v0.3(Singhetal.,2019)","isBolded":false,"associatedRows":["Pythia"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Model"],"associatedMergedColumns":["-"]},{"number":"72.55","isBolded":false,"associatedRows":["MCAN + VG + Multiple Detectors ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"75.00","isBolded":false,"associatedRows":["MCAN + VG + Multiple Detectors + BERT + Ensemble ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"70.90","isBolded":false,"associatedRows":["MCAN + VG ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Std"],"associatedMergedColumns":["-"]},{"number":"70.18","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"72.80","isBolded":false,"associatedRows":["MCAN + VG + Multiple Detectors + BERT ( Yu et al . , 2019b )"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]},{"number":"70.80","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Table 1 , including baselines using the same visual features and number of","Test - Dev"],"associatedMergedColumns":["-"]}]},{"caption":"Table 2: Model performance on VCR. VisualBERT w/o COCO Pre-training outperforms R2C, \nwhich enjoys the same resource while VisualBERT further improves the results. \n\n","rows":["VisualBERT w / o Early Fusion","VisualBERT","R2C ( Zellers et al . , 2019 )","VisualBERT w / o COCO Pre - training","-","B2T2 ( Leaderboard ; Unpublished )"],"columns":["Q ? AR","Dev","Test","Q ? A","QA ? R"],"mergedAllColumns":["Model","-"],"numberCells":[{"number":"67.2","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )","-"],"associatedColumns":["QA ? R","Dev"],"associatedMergedColumns":["Model"]},{"number":"72.6","isBolded":false,"associatedRows":["B2T2 ( Leaderboard ; Unpublished )","-"],"associatedColumns":["Q ? A","Test"],"associatedMergedColumns":["Model"]},{"number":"47.9","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-","-"],"associatedColumns":["Q ? AR","Dev"],"associatedMergedColumns":["-"]},{"number":"55.0","isBolded":false,"associatedRows":["B2T2 ( Leaderboard ; Unpublished )","-","-","-","-","-"],"associatedColumns":["Q ? AR","Test"],"associatedMergedColumns":["Model"]},{"number":"69.5","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-"],"associatedColumns":["QA ? R","Dev"],"associatedMergedColumns":["-"]},{"number":"50.6","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion","-","-"],"associatedColumns":["Q ? AR","Dev"],"associatedMergedColumns":["Model"]},{"number":"67.9","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["Q ? A","Dev"],"associatedMergedColumns":["-"]},{"number":"65.1","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )"],"associatedColumns":["Q ? A","Test"],"associatedMergedColumns":["Model"]},{"number":"52.4","isBolded":false,"associatedRows":["VisualBERT","-","-"],"associatedColumns":["Q ? AR","Test"],"associatedMergedColumns":["-"]},{"number":"67.3","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )","-"],"associatedColumns":["QA ? R","Test"],"associatedMergedColumns":["Model"]},{"number":"73.2","isBolded":false,"associatedRows":["VisualBERT","-"],"associatedColumns":["QA ? R","Test"],"associatedMergedColumns":["-"]},{"number":"43.1","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )","-","-"],"associatedColumns":["Q ? AR","Dev"],"associatedMergedColumns":["Model"]},{"number":"63.8","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )"],"associatedColumns":["Q ? A","Dev"],"associatedMergedColumns":["Model"]},{"number":"75.7","isBolded":false,"associatedRows":["B2T2 ( Leaderboard ; Unpublished )","-","-","-"],"associatedColumns":["QA ? R","Test"],"associatedMergedColumns":["Model"]},{"number":"70.1","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion"],"associatedColumns":["Q ? A","Dev"],"associatedMergedColumns":["Model"]},{"number":"71.9","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion","-"],"associatedColumns":["QA ? R","Dev"],"associatedMergedColumns":["Model"]},{"number":"52.2","isBolded":false,"associatedRows":["VisualBERT","-","-"],"associatedColumns":["Q ? AR","Dev"],"associatedMergedColumns":["-"]},{"number":"71.6","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Q ? A","Test"],"associatedMergedColumns":["-"]},{"number":"73.2","isBolded":false,"associatedRows":["VisualBERT","-"],"associatedColumns":["QA ? R","Dev"],"associatedMergedColumns":["-"]},{"number":"70.8","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Q ? A","Dev"],"associatedMergedColumns":["-"]},{"number":"44.0","isBolded":false,"associatedRows":["R2C ( Zellers et al . , 2019 )","-","-"],"associatedColumns":["Q ? AR","Test"],"associatedMergedColumns":["Model"]}]},{"caption":"Table 3. VisualBERT w/o Early Fusion and VisualBERT w/o COCO Pre-training \nsurpass the previous best model MaxEnt by a large margin while VisualBERT widens the gap. \n\n","rows":["VisualBERT w / o Early Fusion","VisualBERT","MaxEnt ( Suhr et al . , 2019 )","VisualBERT w / o COCO Pre - training"],"columns":["Test - U","Dev","Test - P","Test - U ( Cons )","-"],"mergedAllColumns":[],"numberCells":[{"number":"54.1","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"64.6","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"54.8","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - P"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - U"],"associatedMergedColumns":[]},{"number":"67.4","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Dev","-","-"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - P","-","-"],"associatedMergedColumns":[]},{"number":"63.5","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["Dev","-"],"associatedMergedColumns":[]},{"number":"12.0","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - U ( Cons )"],"associatedMergedColumns":[]},{"number":"26.9","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - U ( Cons )","-","-"],"associatedMergedColumns":[]},{"number":"67.3","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - U","-","-"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Comparison with the state-of-the-art model on NLVR 2 . The two ablation models signifi-\ncantly outperform MaxEnt while the full model widens the gap. \n\n","rows":["VisualBERT w / o Early Fusion","VisualBERT","MaxEnt ( Suhr et al . , 2019 )","VisualBERT w / o COCO Pre - training"],"columns":["Test - U","Dev","Test - P","Test - U ( Cons )","-"],"mergedAllColumns":[],"numberCells":[{"number":"67.3","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - U","-","-"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - P","-","-"],"associatedMergedColumns":[]},{"number":"64.6","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"67.4","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Dev","-","-"],"associatedMergedColumns":[]},{"number":"63.5","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["Dev","-"],"associatedMergedColumns":[]},{"number":"26.9","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Test - U ( Cons )","-","-"],"associatedMergedColumns":[]},{"number":"54.8","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - P"],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"12.0","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - U ( Cons )"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":false,"associatedRows":["MaxEnt ( Suhr et al . , 2019 )"],"associatedColumns":["Test - U"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Comparison with the state-of-the-art model on the Flickr30K. VisualBERT holds a clear \nadvantage over BAN. \n\n","rows":["VisualBERT w / o Early Fusion","VisualBERT","Grounding","VisualBERT w / o COCO Pre - training","BAN ( Kim et al . , 2018 )","-"],"columns":["R@1","Dev","Test","R@5","R@10","Upper Bound"],"mergedAllColumns":["Acc","Model","-"],"numberCells":[{"number":"0.4","isBolded":true,"associatedRows":["VisualBERT w / o COCO Pre - training","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["-"]},{"number":"86.24","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-","-"],"associatedColumns":["R@10","Dev"],"associatedMergedColumns":["-"]},{"number":"71.33","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["R@1","Test"],"associatedMergedColumns":["-"]},{"number":"87.45","isBolded":false,"associatedRows":["BAN ( Kim et al . , 2018 )","-","-","-","-","-"],"associatedColumns":["Upper Bound","Test"],"associatedMergedColumns":["Model"]},{"number":"84.53","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["Model"]},{"number":"0.5","isBolded":true,"associatedRows":["VisualBERT w / o COCO Pre - training","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["-"]},{"number":"83.98","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["-"]},{"number":"0.3","isBolded":true,"associatedRows":["VisualBERT w / o COCO Pre - training","-","Grounding"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["Acc"]},{"number":"0.2","isBolded":true,"associatedRows":["VisualBERT w / o COCO Pre - training","-","Grounding"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["Acc"]},{"number":"70.40","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["R@1","Dev"],"associatedMergedColumns":["-"]},{"number":"86.51","isBolded":false,"associatedRows":["VisualBERT","-","-"],"associatedColumns":["R@10","Test"],"associatedMergedColumns":["-"]},{"number":"0.1","isBolded":true,"associatedRows":["VisualBERT w / o COCO Pre - training","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["Acc"]},{"number":"86.39","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion","-","-"],"associatedColumns":["R@10","Dev"],"associatedMergedColumns":["Model"]},{"number":"86.31","isBolded":false,"associatedRows":["VisualBERT","-","-"],"associatedColumns":["R@10","Dev"],"associatedMergedColumns":["-"]},{"number":"86.97","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-","-","-"],"associatedColumns":["Upper Bound","Dev"],"associatedMergedColumns":["-"]},{"number":"87.45","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training","-","-","-"],"associatedColumns":["Upper Bound","Test"],"associatedMergedColumns":["-"]},{"number":"84.49","isBolded":false,"associatedRows":["VisualBERT","-"],"associatedColumns":["R@5","Dev"],"associatedMergedColumns":["-"]},{"number":"68.07","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["R@1","Dev"],"associatedMergedColumns":["-"]},{"number":"69.69","isBolded":false,"associatedRows":["BAN ( Kim et al . , 2018 )","-"],"associatedColumns":["R@1","Test"],"associatedMergedColumns":["Model"]},{"number":"84.98","isBolded":false,"associatedRows":["VisualBERT","-"],"associatedColumns":["R@5","Test"],"associatedMergedColumns":["-"]},{"number":"84.22","isBolded":false,"associatedRows":["BAN ( Kim et al . , 2018 )","-","-","-"],"associatedColumns":["R@5","Test"],"associatedMergedColumns":["Model"]},{"number":"86.97","isBolded":false,"associatedRows":["BAN ( Kim et al . , 2018 )","-","-","-","-","-"],"associatedColumns":["Upper Bound","Dev"],"associatedMergedColumns":["Model"]},{"number":"70.33","isBolded":false,"associatedRows":["VisualBERT w / o Early Fusion"],"associatedColumns":["R@1","Dev"],"associatedMergedColumns":["Model"]},{"number":"86.35","isBolded":false,"associatedRows":["BAN ( Kim et al . , 2018 )","-","-","-","-","-"],"associatedColumns":["R@10","Test"],"associatedMergedColumns":["Model"]}]},{"caption":"Table 5: Performance of the ablation models on \nNLVR 2 . Results confirm that task-agnostic pre-\ntraining (C1) and early fusion of vision and lan-\nguage (C2) are essential for VisualBERT. \n\n","rows":["VisualBERT","C2 VisualBERT w / o Early Fusion","VisualBERT w / o COCO Pre - training","C4 VisualBERT w / o Objective 2","C3 VisualBERT w / o BERT Initialization","VisualBERT w / o Grounded Pre - training"],"columns":["Dev"],"mergedAllColumns":["C1"],"numberCells":[{"number":"63.9","isBolded":false,"associatedRows":["VisualBERT w / o Grounded Pre - training"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"64.7","isBolded":false,"associatedRows":["C3 VisualBERT w / o BERT Initialization"],"associatedColumns":["Dev"],"associatedMergedColumns":["C1"]},{"number":"66.7","isBolded":false,"associatedRows":["VisualBERT"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"61.4","isBolded":false,"associatedRows":["C2 VisualBERT w / o Early Fusion"],"associatedColumns":["Dev"],"associatedMergedColumns":["C1"]},{"number":"62.9","isBolded":false,"associatedRows":["VisualBERT w / o COCO Pre - training"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"64.9","isBolded":false,"associatedRows":["C4 VisualBERT w / o Objective 2"],"associatedColumns":["Dev"],"associatedMergedColumns":["C1"]}]}]