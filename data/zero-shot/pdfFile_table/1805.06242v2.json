[{"caption":"Table 1: Accuracies (in %) on the SwDA test set, baseline with \nno context (NC) and Utt-Att-BiRNN model with context (WC) \n\nModels \nNC \nWC \n\nPrior related work \nMost common class baseline \n31.50 \nStolcke et al., 2000 [10] \n71.00 \nKalchbrenner and Blunsom, 2013 [15] \n73.90 \nLee and Dernoncourt, 2016 [22] \n73.10 \nOrtega and Vu, 2017 [20] \n73.80 \nOur work \nCharacter LM rep. \n71.84 \n76.47 \nWord-embeddings mean rep. \n71.73 \n75.43 \nConcatenated rep. \n70.83 \n76.15 \nAverage char-word-level predictions \n71.85 \n76.84 \nAverage char-word-level \u0026 \nconcatenated rep. predictions \n71.97 \n77.42 \n\n100 hidden units respectively. For the proposed model, we use \n64 hidden units with the dropout regularizer ","rows":["concatenated rep . predictions","Kalchbrenner and Blunsom , 2013 [ 15 ]","Most common class baseline","Character LM rep .","Stolcke et al . , 2000 [ 10 ]","Concatenated rep .","Ortega and Vu , 2017 [ 20 ]","Lee and Dernoncourt , 2016 [ 22 ]","Word - embeddings mean rep .","Average char - word - level predictions"],"columns":["NC","100 hidden units respectively . For the proposed model , we use","WC"],"mergedAllColumns":["Prior related work","Average char - word - level \u0026","Our work"],"numberCells":[{"number":"76.47","isBolded":false,"associatedRows":["Character LM rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Our work"]},{"number":"71.73","isBolded":false,"associatedRows":["Word - embeddings mean rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Our work"]},{"number":"71.97","isBolded":false,"associatedRows":["concatenated rep . predictions"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Average char - word - level \u0026"]},{"number":"71.00","isBolded":false,"associatedRows":["Stolcke et al . , 2000 [ 10 ]"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Prior related work"]},{"number":"73.90","isBolded":false,"associatedRows":["Kalchbrenner and Blunsom , 2013 [ 15 ]"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Prior related work"]},{"number":"70.83","isBolded":false,"associatedRows":["Concatenated rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Our work"]},{"number":"73.80","isBolded":false,"associatedRows":["Ortega and Vu , 2017 [ 20 ]"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Prior related work"]},{"number":"76.84","isBolded":false,"associatedRows":["Average char - word - level predictions"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Our work"]},{"number":"71.84","isBolded":false,"associatedRows":["Character LM rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Our work"]},{"number":"75.43","isBolded":false,"associatedRows":["Word - embeddings mean rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Our work"]},{"number":"77.42","isBolded":false,"associatedRows":["concatenated rep . predictions"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Average char - word - level \u0026"]},{"number":"31.50","isBolded":false,"associatedRows":["Most common class baseline"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Prior related work"]},{"number":"71.85","isBolded":false,"associatedRows":["Average char - word - level predictions"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","NC"],"associatedMergedColumns":["Our work"]},{"number":"76.15","isBolded":false,"associatedRows":["Concatenated rep ."],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Our work"]},{"number":"73.10","isBolded":false,"associatedRows":["Lee and Dernoncourt , 2016 [ 22 ]"],"associatedColumns":["100 hidden units respectively . For the proposed model , we use","WC"],"associatedMergedColumns":["Prior related work"]}]},{"caption":"Table 2: The test samples from the SwDA corpus where both \nclassifiers, simple utterance-level and Utt-Att-BiRNN, failed to \ncorrectly predict classes (the majority classes, Statement-non-\nopinion (sd) and Statement-opinion (sv), are reported here). \nWhere Num is a number of samples, GT stands for ground truth, \nand pct. for percentage. \n\n","rows":["198","sd","sv","51"],"columns":["pct ."],"mergedAllColumns":["We \u0027 re hearing the same"],"numberCells":[{"number":"4.73","isBolded":false,"associatedRows":["sv","sd","sd","198"],"associatedColumns":["pct ."],"associatedMergedColumns":[]},{"number":"1.22","isBolded":false,"associatedRows":["sd","sv","sv","51"],"associatedColumns":["pct ."],"associatedMergedColumns":["We \u0027 re hearing the same"]}]}]