[{"caption":"Baseline \nBatchNorm \nBaseline \nBatchNorm \n\n1 RNN, 5 total \n2400 \n10.55 \n11.99 \n13.55 \n14.40 \n3 RNN, 5 total \n1880 \n9.55 \n8.29 \n11.61 \n10.56 \n5 RNN, 7 total \n1510 \n8.59 \n7.61 \n10.77 \n9.78 \n7 RNN, 9 total \n1280 \n8.76 \n7.68 \n10.83 \n9.52 \n\nTable 1: Comparison of WER on a training and development set for various depths of RNN, with and without \nBatchNorm. The number of parameters is kept constant as the depth increases, thus the number of hidden units \nper layer decreases. All networks have 38 million parameters. The architecture \"M RNN, N total\" implies 1 \nlayer of 1D convolution at the input, M consecutive bidirectional RNN layers, and the rest as fully-connected \nlayers with N total layers in the network. \n\n","rows":["1510","2400","1880","per layer decreases . All networks have 38 million parameters . The architecture \" M RNN , N total \" implies","1280"],"columns":["BatchNorm","Baseline"],"mergedAllColumns":["BatchNorm . The number of parameters is kept constant as the depth increases , thus the number of hidden units"],"numberCells":[{"number":"8.59","isBolded":false,"associatedRows":["1510"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"9total","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"7total","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":["1280"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"8.76","isBolded":false,"associatedRows":["1280"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"13.55","isBolded":false,"associatedRows":["2400"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"10.56","isBolded":false,"associatedRows":["1880"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"7RNN,","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["per layer decreases . All networks have 38 million parameters . The architecture \" M RNN , N total \" implies"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":["BatchNorm . The number of parameters is kept constant as the depth increases , thus the number of hidden units"]},{"number":"1RNN,","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"5RNN,","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"10.83","isBolded":false,"associatedRows":["1280"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"9.55","isBolded":false,"associatedRows":["1880"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"5total","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"10.77","isBolded":false,"associatedRows":["1510"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"9.78","isBolded":false,"associatedRows":["1510"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"8.29","isBolded":false,"associatedRows":["1880"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"7.68","isBolded":false,"associatedRows":["1280"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"3RNN,","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"11.61","isBolded":false,"associatedRows":["1880"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"7.61","isBolded":false,"associatedRows":["1510"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"5total","isBolded":false,"associatedRows":[],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"11.99","isBolded":false,"associatedRows":["2400"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]},{"number":"10.55","isBolded":false,"associatedRows":["2400"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"14.40","isBolded":false,"associatedRows":["2400"],"associatedColumns":["BatchNorm"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison of WER on a training and development set with and without SortaGrad, and with and \nwithout batch normalization. \n\n","rows":["Not Sorted","Sorted"],"columns":["BatchNorm","Dev","Baseline","Train"],"mergedAllColumns":[],"numberCells":[{"number":"11.96","isBolded":false,"associatedRows":["Not Sorted"],"associatedColumns":["Dev","Baseline"],"associatedMergedColumns":[]},{"number":"7.68","isBolded":false,"associatedRows":["Sorted"],"associatedColumns":["Train","BatchNorm"],"associatedMergedColumns":[]},{"number":"10.71","isBolded":false,"associatedRows":["Not Sorted"],"associatedColumns":["Train","Baseline"],"associatedMergedColumns":[]},{"number":"9.78","isBolded":false,"associatedRows":["Not Sorted"],"associatedColumns":["Dev","BatchNorm"],"associatedMergedColumns":[]},{"number":"10.83","isBolded":false,"associatedRows":["Sorted"],"associatedColumns":["Dev","Baseline"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":["Sorted"],"associatedColumns":["Dev","BatchNorm"],"associatedMergedColumns":[]},{"number":"8.04","isBolded":false,"associatedRows":["Not Sorted"],"associatedColumns":["Train","BatchNorm"],"associatedMergedColumns":[]},{"number":"8.76","isBolded":false,"associatedRows":["Sorted"],"associatedColumns":["Train","Baseline"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Comparison of development set WER for networks with either simple RNN or GRU, for various \ndepths. All models have batch normalization, one layer of 1D-invariant convolution, and approximately 38 \nmillion parameters. \n\n","rows":[],"columns":["Simple RNN","Architecture","GRU"],"mergedAllColumns":[],"numberCells":[{"number":"7.79","isBolded":false,"associatedRows":[],"associatedColumns":["GRU"],"associatedMergedColumns":[]},{"number":"7Recurrent","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"14.40","isBolded":false,"associatedRows":[],"associatedColumns":["Simple RNN"],"associatedMergedColumns":[]},{"number":"3Recurrent","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"5Recurrent","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"1Recurrent","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"8.00","isBolded":false,"associatedRows":[],"associatedColumns":["GRU"],"associatedMergedColumns":[]},{"number":"5layers,","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"10.53","isBolded":false,"associatedRows":[],"associatedColumns":["GRU"],"associatedMergedColumns":[]},{"number":"7layers,","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"10.56","isBolded":false,"associatedRows":[],"associatedColumns":["Simple RNN"],"associatedMergedColumns":[]},{"number":"9.78","isBolded":false,"associatedRows":[],"associatedColumns":["Simple RNN"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":[],"associatedColumns":["Simple RNN"],"associatedMergedColumns":[]},{"number":"5layers,","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"9layers,","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"8.19","isBolded":false,"associatedRows":[],"associatedColumns":["GRU"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Comparison of WER for various arrangements of convolutional layers. In all cases, the convolutions \nare followed by 7 recurrent layers and 1 fully connected layer. For 2D-invariant convolutions the first dimen-\nsion is frequency and the second dimension is time. All models have BatchNorm, SortaGrad, and 35 million \nparameters. \n\n","rows":["11","5 , 5 , 5","1 , 1 , 2","1 - layer 1D","1 - layer 2D","41x11 , 21x11","512 , 512 , 512","41x11 , 21x11 , 21x11","3 - layer 1D","3 - layer 2D","5 , 5","2x2","1280","1 , 2","41x11","32 , 32 , 96","2","32 , 32","2x2 , 2x1 , 2x1","2 - layer 2D","2 - layer 1D","2x2 , 2x1","640 , 640","32"],"columns":["Noisy Dev","Regular Dev"],"mergedAllColumns":[],"numberCells":[{"number":"8.94","isBolded":false,"associatedRows":["1 - layer 2D","32","41x11","2x2"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"15.71","isBolded":false,"associatedRows":["2 - layer 2D","32 , 32","41x11 , 21x11","2x2 , 2x1"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"8.61","isBolded":false,"associatedRows":["3 - layer 2D","32 , 32 , 96","41x11 , 21x11 , 21x11","2x2 , 2x1 , 2x1"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":["1 - layer 1D","1280","11","2"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"20.22","isBolded":false,"associatedRows":["3 - layer 1D","512 , 512 , 512","5 , 5 , 5","1 , 1 , 2"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"19.21","isBolded":false,"associatedRows":["2 - layer 1D","640 , 640","5 , 5","1 , 2"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"19.36","isBolded":false,"associatedRows":["1 - layer 1D","1280","11","2"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"14.74","isBolded":false,"associatedRows":["3 - layer 2D","32 , 32 , 96","41x11 , 21x11 , 21x11","2x2 , 2x1 , 2x1"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"9.20","isBolded":false,"associatedRows":["3 - layer 1D","512 , 512 , 512","5 , 5 , 5","1 , 1 , 2"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"16.22","isBolded":false,"associatedRows":["1 - layer 2D","32","41x11","2x2"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"9.67","isBolded":false,"associatedRows":["2 - layer 1D","640 , 640","5 , 5","1 , 2"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"9.06","isBolded":false,"associatedRows":["2 - layer 2D","32 , 32","41x11 , 21x11","2x2 , 2x1"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Comparison of WER with different amounts of striding for unigram and bigram outputs on a model \nwith 1 layer of 1D-invariant convolution, 7 recurrent layers, and 1 fully connected layer. All models have \nBatchNorm, SortaGrad, and 35 million parameters. The models are compared on a development set with and \nwithout the use of a 5-gram language model. \n\n","rows":["2","3","4"],"columns":["Unigrams","Dev LM","Dev no LM","Bigrams"],"mergedAllColumns":[],"numberCells":[{"number":"9.66","isBolded":false,"associatedRows":["2"],"associatedColumns":["Dev LM","Bigrams"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":["2"],"associatedColumns":["Dev LM","Unigrams"],"associatedMergedColumns":[]},{"number":"15.01","isBolded":false,"associatedRows":["3"],"associatedColumns":["Dev no LM","Unigrams"],"associatedMergedColumns":[]},{"number":"15.60","isBolded":false,"associatedRows":["3"],"associatedColumns":["Dev no LM","Bigrams"],"associatedMergedColumns":[]},{"number":"9.65","isBolded":false,"associatedRows":["3"],"associatedColumns":["Dev LM","Unigrams"],"associatedMergedColumns":[]},{"number":"9.93","isBolded":false,"associatedRows":["4"],"associatedColumns":["Dev LM","Bigrams"],"associatedMergedColumns":[]},{"number":"14.93","isBolded":false,"associatedRows":["2"],"associatedColumns":["Dev no LM","Unigrams"],"associatedMergedColumns":[]},{"number":"14.56","isBolded":false,"associatedRows":["2"],"associatedColumns":["Dev no LM","Bigrams"],"associatedMergedColumns":[]},{"number":"18.86","isBolded":false,"associatedRows":["4"],"associatedColumns":["Dev no LM","Unigrams"],"associatedMergedColumns":[]},{"number":"11.92","isBolded":false,"associatedRows":["4"],"associatedColumns":["Dev LM","Unigrams"],"associatedMergedColumns":[]},{"number":"10.06","isBolded":false,"associatedRows":["3"],"associatedColumns":["Dev LM","Bigrams"],"associatedMergedColumns":[]},{"number":"14.84","isBolded":false,"associatedRows":["4"],"associatedColumns":["Dev no LM","Bigrams"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Comparison of WER for English and CER for Mandarin with and without a language model. These \nare simple RNN models with only one layer of 1D invariant convolution. \n\n","rows":["English","9 - layer , 7 RNN","5 - layer , 1 RNN","Mandarin"],"columns":["Dev LM","Dev no LM"],"mergedAllColumns":[],"numberCells":[{"number":"9.80","isBolded":false,"associatedRows":["Mandarin","5 - layer , 1 RNN"],"associatedColumns":["Dev no LM"],"associatedMergedColumns":[]},{"number":"14.39","isBolded":false,"associatedRows":["English","5 - layer , 1 RNN"],"associatedColumns":["Dev LM"],"associatedMergedColumns":[]},{"number":"14.93","isBolded":false,"associatedRows":["English","9 - layer , 7 RNN"],"associatedColumns":["Dev no LM"],"associatedMergedColumns":[]},{"number":"27.79","isBolded":false,"associatedRows":["English","5 - layer , 1 RNN"],"associatedColumns":["Dev no LM"],"associatedMergedColumns":[]},{"number":"5.81","isBolded":false,"associatedRows":["Mandarin","9 - layer , 7 RNN"],"associatedColumns":["Dev LM"],"associatedMergedColumns":[]},{"number":"7.13","isBolded":false,"associatedRows":["Mandarin","5 - layer , 1 RNN"],"associatedColumns":["Dev LM"],"associatedMergedColumns":[]},{"number":"7.55","isBolded":false,"associatedRows":["Mandarin","9 - layer , 7 RNN"],"associatedColumns":["Dev no LM"],"associatedMergedColumns":[]},{"number":"9.52","isBolded":false,"associatedRows":["English","9 - layer , 7 RNN"],"associatedColumns":["Dev LM"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Comparison of two different all-reduce implementations. All times are in seconds. Performance gain \nis the ratio of OpenMPI all-reduce time to our all-reduce time. \n\n","rows":["4","16","128","8","64","32"],"columns":["OpenMPI","Performance","Our","Gain","all - reduce"],"mergedAllColumns":[],"numberCells":[{"number":"1393.7","isBolded":false,"associatedRows":["16"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"422.6","isBolded":false,"associatedRows":["128","64"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"611.0","isBolded":false,"associatedRows":["64"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"1602.1","isBolded":false,"associatedRows":["128","64"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"21562.6","isBolded":false,"associatedRows":["16"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"15.5","isBolded":false,"associatedRows":["16"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]},{"number":"3.8","isBolded":false,"associatedRows":["128","64"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]},{"number":"8191.8","isBolded":false,"associatedRows":["32"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"48881.6","isBolded":false,"associatedRows":["8"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"19.8","isBolded":false,"associatedRows":["8"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]},{"number":"2470.9","isBolded":false,"associatedRows":["8"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"1339.6","isBolded":false,"associatedRows":["32"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"1395.2","isBolded":false,"associatedRows":["64"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"21.4","isBolded":false,"associatedRows":["4"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]},{"number":"2587.4","isBolded":false,"associatedRows":["4"],"associatedColumns":["Our","all - reduce"],"associatedMergedColumns":[]},{"number":"55359.1","isBolded":false,"associatedRows":["4"],"associatedColumns":["OpenMPI","all - reduce"],"associatedMergedColumns":[]},{"number":"2.3","isBolded":false,"associatedRows":["64"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]},{"number":"6.1","isBolded":false,"associatedRows":["32"],"associatedColumns":["Performance","Gain"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparison of time spent in seconds in computing the CTC loss function and gradient in one epoch \nfor two different implementations. Speedup is the ratio of CPU CTC time to GPU CTC time. \n\n","rows":["5 - layer , 3 RNN","English","Mandarin"],"columns":["Speedup","CPU CTC Time","GPU CTC Time"],"mergedAllColumns":[],"numberCells":[{"number":"28.9","isBolded":false,"associatedRows":["English","5 - layer , 3 RNN"],"associatedColumns":["Speedup"],"associatedMergedColumns":[]},{"number":"5888.12","isBolded":false,"associatedRows":["English","5 - layer , 3 RNN"],"associatedColumns":["CPU CTC Time"],"associatedMergedColumns":[]},{"number":"203.56","isBolded":false,"associatedRows":["English","5 - layer , 3 RNN"],"associatedColumns":["GPU CTC Time"],"associatedMergedColumns":[]},{"number":"12.5","isBolded":false,"associatedRows":["Mandarin","5 - layer , 3 RNN"],"associatedColumns":["Speedup"],"associatedMergedColumns":[]},{"number":"1688.01","isBolded":false,"associatedRows":["Mandarin","5 - layer , 3 RNN"],"associatedColumns":["CPU CTC Time"],"associatedMergedColumns":[]},{"number":"135.05","isBolded":false,"associatedRows":["Mandarin","5 - layer , 3 RNN"],"associatedColumns":["GPU CTC Time"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Summary of the datasets used to train DS2 in English. The Wall Street Journal (WSJ), Switchboard \nand Fisher [13] corpora are all published by the Linguistic Data Consortium. The LibriSpeech dataset [46] is \navailable free on-line. The other datasets are internal Baidu corpora. \n\n","rows":["read","Baidu","Fisher","conversational","mixed"],"columns":["300","960","80"],"mergedAllColumns":[],"numberCells":[{"number":"2000","isBolded":false,"associatedRows":["Fisher","conversational"],"associatedColumns":["80","300"],"associatedMergedColumns":[]},{"number":"3600","isBolded":false,"associatedRows":["Baidu","mixed"],"associatedColumns":["80","300","960"],"associatedMergedColumns":[]},{"number":"5000","isBolded":false,"associatedRows":["Baidu","read"],"associatedColumns":["80","300","960"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Comparison of English WER for Regular and Noisy development sets on increasing training dataset \nsize. The architecture is a 9-layer model with 2 layers of 2D-invariant convolution and 7 recurrent layers with \n68M parameters. \n\n","rows":["6000","100%","1%","2400","10%","1200","12000","20%","50%","120"],"columns":["Noisy Dev","Regular Dev"],"mergedAllColumns":[],"numberCells":[{"number":"9.51","isBolded":false,"associatedRows":["50%","6000"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"29.23","isBolded":false,"associatedRows":["1%","120"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"22.99","isBolded":false,"associatedRows":["10%","1200"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"50.97","isBolded":false,"associatedRows":["1%","120"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"20.41","isBolded":false,"associatedRows":["20%","2400"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"13.59","isBolded":false,"associatedRows":["100%","50%","12000","6000"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"13.80","isBolded":false,"associatedRows":["10%","1200"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"11.65","isBolded":false,"associatedRows":["20%","2400"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"15.90","isBolded":false,"associatedRows":["50%","6000"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"8.46","isBolded":false,"associatedRows":["100%","50%","12000","6000"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]}]},{"caption":"Table 11: Comparing the effect of model size on the WER of the English speech system on both the regular and \nnoisy development sets. We vary the number of hidden units in all but the convolutional layers. The GRU model \nhas 3 layers of bidirectional GRUs with 1 layer of 2D-invariant convolution. The RNN model has 7 layers of \nbidirectional simple recurrence with 3 layers of 2D-invariant convolution. Both models output bigrams with a \ntemporal stride of 3. All models contain approximately 35 million parameters and are trained with BatchNorm \nand SortaGrad. \n\n","rows":["100 ?","RNN","GRU"],"columns":["Noisy Dev","Model size","Regular Dev"],"mergedAllColumns":[],"numberCells":[{"number":"70?","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"9.06","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"15.98","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":["100 ?"],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"18?","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":["100 ?"],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"7.73","isBolded":false,"associatedRows":["100 ?","RNN"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"38?","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"8.54","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"13.06","isBolded":false,"associatedRows":["100 ?","RNN"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"10.59","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"14.17","isBolded":false,"associatedRows":["100 ?","GRU"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"106","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]},{"number":"7.78","isBolded":false,"associatedRows":["100 ?","GRU"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"8.44","isBolded":false,"associatedRows":["RNN"],"associatedColumns":["Regular Dev"],"associatedMergedColumns":[]},{"number":"21.38","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"17.07","isBolded":false,"associatedRows":["GRU"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"15.09","isBolded":false,"associatedRows":["RNN"],"associatedColumns":["Noisy Dev"],"associatedMergedColumns":[]},{"number":"70?","isBolded":false,"associatedRows":[],"associatedColumns":["Model size"],"associatedMergedColumns":[]}]},{"caption":"Table 12: Comparison of DS1 and DS2 WER on an internal test set of 3,300 examples. The test set contains a \nwide variety of speech including accents, low signal-to-noise speech, spontaneous and conversational speech. \n\n","rows":["Baidu Test"],"columns":["DS2","DS1"],"mergedAllColumns":[],"numberCells":[{"number":"24.01","isBolded":false,"associatedRows":["Baidu Test"],"associatedColumns":["DS1"],"associatedMergedColumns":[]},{"number":"13.59","isBolded":false,"associatedRows":["Baidu Test"],"associatedColumns":["DS2"],"associatedMergedColumns":[]}]},{"caption":"Table 13: Comparison of WER for two speech systems and human level performance on read speech. \n","rows":["WSJ eval \u0027 93","WSJ eval \u0027 92","LibriSpeech test - clean","LibriSpeech test - other"],"columns":["Human","DS2","DS1","Read Speech"],"mergedAllColumns":[],"numberCells":[{"number":"13.25","isBolded":false,"associatedRows":["LibriSpeech test - other"],"associatedColumns":["Read Speech","DS2"],"associatedMergedColumns":[]},{"number":"8.08","isBolded":false,"associatedRows":["WSJ eval \u0027 93"],"associatedColumns":["Read Speech","Human"],"associatedMergedColumns":[]},{"number":"3.60","isBolded":false,"associatedRows":["WSJ eval \u0027 92"],"associatedColumns":["Read Speech","DS2"],"associatedMergedColumns":[]},{"number":"5.03","isBolded":false,"associatedRows":["WSJ eval \u0027 92"],"associatedColumns":["Read Speech","Human"],"associatedMergedColumns":[]},{"number":"6.94","isBolded":false,"associatedRows":["WSJ eval \u0027 93"],"associatedColumns":["Read Speech","DS1"],"associatedMergedColumns":[]},{"number":"12.69","isBolded":false,"associatedRows":["LibriSpeech test - other"],"associatedColumns":["Read Speech","Human"],"associatedMergedColumns":[]},{"number":"5.83","isBolded":false,"associatedRows":["LibriSpeech test - clean"],"associatedColumns":["Read Speech","Human"],"associatedMergedColumns":[]},{"number":"7.89","isBolded":false,"associatedRows":["LibriSpeech test - clean"],"associatedColumns":["Read Speech","DS1"],"associatedMergedColumns":[]},{"number":"21.74","isBolded":false,"associatedRows":["LibriSpeech test - other"],"associatedColumns":["Read Speech","DS1"],"associatedMergedColumns":[]},{"number":"5.33","isBolded":false,"associatedRows":["LibriSpeech test - clean"],"associatedColumns":["Read Speech","DS2"],"associatedMergedColumns":[]},{"number":"4.94","isBolded":false,"associatedRows":["WSJ eval \u0027 92"],"associatedColumns":["Read Speech","DS1"],"associatedMergedColumns":[]},{"number":"4.98","isBolded":false,"associatedRows":["WSJ eval \u0027 93"],"associatedColumns":["Read Speech","DS2"],"associatedMergedColumns":[]}]},{"caption":"Table 14: Comparing WER of the DS1 system to the DS2 system on accented speech. \n\n","rows":["VoxForge Commonwealth","VoxForge American - Canadian","VoxForge Indian","VoxForge European"],"columns":["Human","DS2","DS1","Accented Speech"],"mergedAllColumns":[],"numberCells":[{"number":"17.55","isBolded":false,"associatedRows":["VoxForge European"],"associatedColumns":["Accented Speech","DS2"],"associatedMergedColumns":[]},{"number":"45.35","isBolded":false,"associatedRows":["VoxForge Indian"],"associatedColumns":["Accented Speech","DS1"],"associatedMergedColumns":[]},{"number":"7.55","isBolded":false,"associatedRows":["VoxForge American - Canadian"],"associatedColumns":["Accented Speech","DS2"],"associatedMergedColumns":[]},{"number":"28.46","isBolded":false,"associatedRows":["VoxForge Commonwealth"],"associatedColumns":["Accented Speech","DS1"],"associatedMergedColumns":[]},{"number":"13.56","isBolded":false,"associatedRows":["VoxForge Commonwealth"],"associatedColumns":["Accented Speech","DS2"],"associatedMergedColumns":[]},{"number":"8.15","isBolded":false,"associatedRows":["VoxForge Commonwealth"],"associatedColumns":["Accented Speech","Human"],"associatedMergedColumns":[]},{"number":"31.20","isBolded":false,"associatedRows":["VoxForge European"],"associatedColumns":["Accented Speech","DS1"],"associatedMergedColumns":[]},{"number":"12.76","isBolded":false,"associatedRows":["VoxForge European"],"associatedColumns":["Accented Speech","Human"],"associatedMergedColumns":[]},{"number":"22.44","isBolded":false,"associatedRows":["VoxForge Indian"],"associatedColumns":["Accented Speech","DS2"],"associatedMergedColumns":[]},{"number":"22.15","isBolded":false,"associatedRows":["VoxForge Indian"],"associatedColumns":["Accented Speech","Human"],"associatedMergedColumns":[]},{"number":"15.01","isBolded":false,"associatedRows":["VoxForge American - Canadian"],"associatedColumns":["Accented Speech","DS1"],"associatedMergedColumns":[]},{"number":"4.85","isBolded":false,"associatedRows":["VoxForge American - Canadian"],"associatedColumns":["Accented Speech","Human"],"associatedMergedColumns":[]}]},{"caption":"Table 15: Comparison of DS1 and DS2 system on noisy speech. \"CHiME eval clean\" is a noise-free baseline. \nThe \"CHiME eval real\" dataset is collected in real noisy environments and the \"CHiME eval sim\" dataset has \nsimilar noise synthetically added to clean speech. Note that we use only one of the six channels to test each \nutterance. \n\n","rows":["CHiME eval sim","CHiME eval real","CHiME eval clean"],"columns":["Human","DS2","DS1","Noisy Speech"],"mergedAllColumns":[],"numberCells":[{"number":"67.94","isBolded":false,"associatedRows":["CHiME eval real"],"associatedColumns":["Noisy Speech","DS1"],"associatedMergedColumns":[]},{"number":"45.05","isBolded":false,"associatedRows":["CHiME eval sim"],"associatedColumns":["Noisy Speech","DS2"],"associatedMergedColumns":[]},{"number":"21.79","isBolded":false,"associatedRows":["CHiME eval real"],"associatedColumns":["Noisy Speech","DS2"],"associatedMergedColumns":[]},{"number":"31.33","isBolded":false,"associatedRows":["CHiME eval sim"],"associatedColumns":["Noisy Speech","Human"],"associatedMergedColumns":[]},{"number":"6.30","isBolded":false,"associatedRows":["CHiME eval clean"],"associatedColumns":["Noisy Speech","DS1"],"associatedMergedColumns":[]},{"number":"3.34","isBolded":false,"associatedRows":["CHiME eval clean"],"associatedColumns":["Noisy Speech","DS2"],"associatedMergedColumns":[]},{"number":"11.84","isBolded":false,"associatedRows":["CHiME eval real"],"associatedColumns":["Noisy Speech","Human"],"associatedMergedColumns":[]},{"number":"80.27","isBolded":false,"associatedRows":["CHiME eval sim"],"associatedColumns":["Noisy Speech","DS1"],"associatedMergedColumns":[]},{"number":"3.46","isBolded":false,"associatedRows":["CHiME eval clean"],"associatedColumns":["Noisy Speech","Human"],"associatedMergedColumns":[]}]},{"caption":"Table 16: Comparison of the improvements in DeepSpeech with architectural improvements. The development \nand test sets are Baidu internal corpora. All the models in the table have about 80 million parameters each \n\n","rows":["5 - layer , 3 RNN","9 - layer , 7 RNN + BatchNorm + 2D conv","5 - layer , 3 RNN + BatchNorm","5 - layer , 1 RNN"],"columns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Dev","Test"],"mergedAllColumns":["performance substantially ."],"numberCells":[{"number":"9.39","isBolded":false,"associatedRows":["5 - layer , 3 RNN + BatchNorm"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Test"],"associatedMergedColumns":["performance substantially ."]},{"number":"11.85","isBolded":false,"associatedRows":["5 - layer , 3 RNN"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Test"],"associatedMergedColumns":["performance substantially ."]},{"number":"7.13","isBolded":false,"associatedRows":["5 - layer , 1 RNN"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Dev"],"associatedMergedColumns":["performance substantially ."]},{"number":"7.93","isBolded":false,"associatedRows":["9 - layer , 7 RNN + BatchNorm + 2D conv"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Test"],"associatedMergedColumns":["performance substantially ."]},{"number":"6.49","isBolded":false,"associatedRows":["5 - layer , 3 RNN"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Dev"],"associatedMergedColumns":["performance substantially ."]},{"number":"6.22","isBolded":false,"associatedRows":["5 - layer , 3 RNN + BatchNorm"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Dev"],"associatedMergedColumns":["performance substantially ."]},{"number":"5.81","isBolded":false,"associatedRows":["9 - layer , 7 RNN + BatchNorm + 2D conv"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Dev"],"associatedMergedColumns":["performance substantially ."]},{"number":"15.41","isBolded":false,"associatedRows":["5 - layer , 1 RNN"],"associatedColumns":["convolution and BatchNorm outperforms the shallow RNN by 48% relative , thus continuing the","Test"],"associatedMergedColumns":["performance substantially ."]}]}]