[{"caption":"Network \nEasy Medium Hard \n\nRetinaFace A [3] (with CM 1 ) \n90.70% 87.88% 73.50% \nRetinaFace A w/o CM 1 \n89.55% 86.21% 68.83% \nRetinaFace A with CM 1 and DDC 2 \n90.28% 87.13% 73.24% \nQuantized RetinaFace A [3] (with CM 1 ) \n90.72% 87.45% 73.56% \nQuantized RetinaFace A with CM 1 and DDC 2 90.32% 87.68% 73.53% \nRetinaFace B [3] (with CM 1 ) \n89.98% 87.11% 72.01% \nRetinaFace B w/o CM 1 \n88.68% 84.98% 68.56% \nRetinaFace B with CM 1 and DDC 2 \n89.60% 86.13% 71.93% \nQuantized RetinaFace B [3] (with CM 1 ) \n89.70% 86.91% 71.89% \nQuantized RetinaFace B with CM 1 and DDC 2 89.56% 86.02% 71.75% \n\n1 CM stands for \"context module.\" \n2 DDC stands for \"depthwise and dilated convolutions.\" \nA The networks are trained from a pre-trained model. \nB The networks are trained from scratch. \n\nTable 1. Accuracy of RetinaFace [3] and the proposed network on the WIDER \nFACE [17] validation subset. \n","rows":["with CM","RetinaFace","[ 3 ] ( with CM","Quantized RetinaFace","and DDC",")","w / o CM"],"columns":["1","Easy","2","Medium","Hard"],"mergedAllColumns":[],"numberCells":[{"number":"87.45%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Medium","1","1","2"],"associatedMergedColumns":[]},{"number":"87.13%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Medium","1","1"],"associatedMergedColumns":[]},{"number":"73.24%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Hard","1","1"],"associatedMergedColumns":[]},{"number":"72.01%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Hard","1","1","2","1","2"],"associatedMergedColumns":[]},{"number":"89.98%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Easy","1","1","2","1","2"],"associatedMergedColumns":[]},{"number":"71.93%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Hard","1","1","2","1","2","1","1"],"associatedMergedColumns":[]},{"number":"87.11%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Medium","1","1","2","1","2"],"associatedMergedColumns":[]},{"number":"68.56%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Hard","1","1","2","1","2","1"],"associatedMergedColumns":[]},{"number":"90.32%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Easy","1","1","2","1"],"associatedMergedColumns":[]},{"number":"88.68%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Easy","1","1","2","1","2","1"],"associatedMergedColumns":[]},{"number":"86.21%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Medium","1"],"associatedMergedColumns":[]},{"number":"86.91%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Medium","1","1","2","1","2","1","1","2"],"associatedMergedColumns":[]},{"number":"68.83%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Hard","1"],"associatedMergedColumns":[]},{"number":"84.98%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Medium","1","1","2","1","2","1"],"associatedMergedColumns":[]},{"number":"73.56%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Hard","1","1","2"],"associatedMergedColumns":[]},{"number":"89.55%","isBolded":false,"associatedRows":["RetinaFace","w / o CM","[ 3 ] ( with CM","and DDC"],"associatedColumns":["Easy","1"],"associatedMergedColumns":[]},{"number":"89.60%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Easy","1","1","2","1","2","1","1"],"associatedMergedColumns":[]},{"number":"89.56%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Easy","1","1","2","1","2","1","1","2","1"],"associatedMergedColumns":[]},{"number":"90.72%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Easy","1","1","2"],"associatedMergedColumns":[]},{"number":"87.88%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Medium"],"associatedMergedColumns":[]},{"number":"73.53%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Hard","1","1","2","1"],"associatedMergedColumns":[]},{"number":"71.75%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Hard","1","1","2","1","2","1","1","2","1"],"associatedMergedColumns":[]},{"number":"90.28%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Easy","1","1"],"associatedMergedColumns":[]},{"number":"90.70%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Easy"],"associatedMergedColumns":[]},{"number":"71.89%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Hard","1","1","2","1","2","1","1","2"],"associatedMergedColumns":[]},{"number":"86.02%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Medium","1","1","2","1","2","1","1","2","1"],"associatedMergedColumns":[]},{"number":"87.68%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","with CM","and DDC"],"associatedColumns":["Medium","1","1","2","1"],"associatedMergedColumns":[]},{"number":"86.13%","isBolded":false,"associatedRows":["RetinaFace","with CM","and DDC","and DDC"],"associatedColumns":["Medium","1","1","2","1","2","1","1"],"associatedMergedColumns":[]},{"number":"73.50%","isBolded":false,"associatedRows":["RetinaFace","[ 3 ] ( with CM",")","and DDC"],"associatedColumns":["Hard"],"associatedMergedColumns":[]},{"number":"89.70%","isBolded":false,"associatedRows":["Quantized RetinaFace","[ 3 ] ( with CM","[ 3 ] ( with CM",")"],"associatedColumns":["Easy","1","1","2","1","2","1","1","2"],"associatedMergedColumns":[]}]},{"caption":"Table 2. We trained the RetinaFace \nusing the SGD optimizer (momentum at 0.9, weight decay at 0.0005, and batch \nsize of 32) on the NVIDIA Titan Xp GPUs with 12GB memory. The learning \nrate starts from 10 ?3 , and is divided by 10 at the 190th and at the 220th epoch. \nThe training process terminates at the 250th epoch. \n\n","rows":["No . of Epochs","64 ? 64 ,"],"columns":["16 ? 16 , 32 ? 32 , 8? prediction layers","8? , 16? , 32? down - sampling","MobileNetV1 - 0 . 25","32"],"mergedAllColumns":[],"numberCells":[{"number":"128?128,16?predictionlayers","isBolded":false,"associatedRows":["64 ? 64 ,"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"256?256,","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"512?512,32?predictionlayers","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"250","isBolded":false,"associatedRows":["No . of Epochs"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers","32"],"associatedMergedColumns":[]}]},{"caption":"Backbone \nMobileNetV1-0.25 \nPrediction Levels \n8?, 16?, 32? down-sampling \nAnchor Settings \n16 ? 16, 32 ? 32, 8? prediction layers \n64 ? 64, 128 ? 128, 16? prediction layers \n256 ? 256, 512 ? 512, 32? prediction layers \nBatch Size \n32 \nNo. of Epochs \n250 \n\nTable 2. Parameter settings of the experiments for RetinaFace [3]. \n\n","rows":["No . of Epochs","64 ? 64 ,"],"columns":["16 ? 16 , 32 ? 32 , 8? prediction layers","8? , 16? , 32? down - sampling","MobileNetV1 - 0 . 25","32"],"mergedAllColumns":[],"numberCells":[{"number":"512?512,32?predictionlayers","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"128?128,16?predictionlayers","isBolded":false,"associatedRows":["64 ? 64 ,"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"256?256,","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"250","isBolded":false,"associatedRows":["No . of Epochs"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers","32"],"associatedMergedColumns":[]}]},{"caption":"Table 3. When the operations in the context module \nare replaced with depthwise convolutions and dilated filters, the model size of \nthe context module decreases from 138 KB to 23 KB, and the computational \ncost of the context module decreases from 708 MACs per input pixel to 119 \nMACs per input pixel. By applying depthwise convolutions and dilated filters \nto the network, the total computational costs decrease by about 30%, and the \ntotal model size decreases by about 20%. \n","rows":["No . of Epochs","64 ? 64 ,"],"columns":["16 ? 16 , 32 ? 32 , 8? prediction layers","8? , 16? , 32? down - sampling","MobileNetV1 - 0 . 25","32"],"mergedAllColumns":[],"numberCells":[{"number":"250","isBolded":false,"associatedRows":["No . of Epochs"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers","32"],"associatedMergedColumns":[]},{"number":"256?256,","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"128?128,16?predictionlayers","isBolded":false,"associatedRows":["64 ? 64 ,"],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]},{"number":"512?512,32?predictionlayers","isBolded":false,"associatedRows":[],"associatedColumns":["MobileNetV1 - 0 . 25","8? , 16? , 32? down - sampling","16 ? 16 , 32 ? 32 , 8? prediction layers"],"associatedMergedColumns":[]}]},{"caption":"Network \nModel Size Computational Cost \n(Bytes) (MACs/Input pixel) \nCM 1 Total CM 1 \nTotal \n\nRetinaFace 1 [3] \n138K 1.12M 708 \n1,888 \nRetinaFace with CM and DDC 2 23K 0.90M 119 \n1,298 \n\n1 CM stands for \"context module.\" \n2 DDC stands for \"depthwise and dilated convolutions.\" \n\nTable 3. Computational costs and the model sizes of RetinaFace [3] and the proposed \nnetwork. \n\n","rows":["RetinaFace","138K","CM","[ 3 ]","23K","RetinaFace with CM and DDC"],"columns":["( Bytes )","Network","Total CM","Computational Cost","119","Model Size","( MACs / Input pixel )","708"],"mergedAllColumns":["CM stands for \" context module . \""],"numberCells":[{"number":"1","isBolded":false,"associatedRows":[],"associatedColumns":["Network","( Bytes )","Total CM"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":["RetinaFace with CM and DDC"],"associatedColumns":["Model Size","( Bytes )"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":["RetinaFace","[ 3 ]"],"associatedColumns":["Model Size","( Bytes )","Total CM","708"],"associatedMergedColumns":[]},{"number":"0.90M","isBolded":true,"associatedRows":["RetinaFace with CM and DDC","23K"],"associatedColumns":["Model Size","( Bytes )","Total CM","708"],"associatedMergedColumns":[]},{"number":"1.12M","isBolded":true,"associatedRows":["RetinaFace","[ 3 ]","138K"],"associatedColumns":["Model Size","( Bytes )","Total CM"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":[],"associatedColumns":["Network","( Bytes )","Total CM","708","119"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["Network","( Bytes )","Total CM","708","119"],"associatedMergedColumns":["CM stands for \" context module . \""]},{"number":"1","isBolded":false,"associatedRows":["RetinaFace with CM and DDC","CM"],"associatedColumns":["Computational Cost","( MACs / Input pixel )"],"associatedMergedColumns":[]}]}]