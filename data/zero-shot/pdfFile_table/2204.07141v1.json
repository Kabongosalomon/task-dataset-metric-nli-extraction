[{"caption":"Table 1: Extreme low-shot. We evaluate the label-efficiency of self-supervised models pretrained on the \nImageNet-1K dataset. For evaluation, we use an extremely small number of the ImageNet-1K labels and report \nthe mean top-1 accuracy and standard deviation across 3 random splits of the data. \n\n","rows":["ViT - B / 4","ViT - B / 8","ViT - S / 8","ViT - S / 16","MAE ( He et al . , 2021 )","ViT - H / 14","MSN ( Ours )","ViT - B / 16","1600","200","300","400","600","800","ViT - L / 16","ViT - L / 7"],"columns":["1","2","5"],"mergedAllColumns":["DINO ( Caron et al . , 2021 )","iBOT ( Zhou et al . , 2021 )"],"numberCells":[{"number":"0.6","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"46.1?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["1"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"64.6?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"12.3?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.1","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.6","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"45.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.6","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.5","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"32.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"55.1?","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"71.6?","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"72.4?","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"65.5?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"8.2?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"59.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"56.2?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["2"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.7","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"64.6?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"72.1?","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.7","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["2"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"40.5?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.2","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"66.4?","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"62.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"64.7?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"19.3?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"64.9?","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"50.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"1.8","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.8","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.7","isBolded":false,"associatedRows":["MSN ( Ours )","ViT - B / 8","600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"25.0?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"40.4?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"18.6?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"57.1?","isBolded":true,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 7","200"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"64.7?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.6","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"58.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"11.6?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"55.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["1"],"associatedMergedColumns":[]},{"number":"41.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"55.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["2"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"47.1?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"56.0?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"42.3?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["5"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"51.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"54.3?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"45.5?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"38.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["1"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.2","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - L / 16","1600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"61.4?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.5","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 8","300"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"58.5?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["5"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"0.7","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 8","800"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"48.9?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - S / 16","800"],"associatedColumns":["2"],"associatedMergedColumns":["iBOT ( Zhou et al . , 2021 )"]},{"number":"49.8?","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","600"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.4","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 4","300"],"associatedColumns":["1"],"associatedMergedColumns":["DINO ( Caron et al . , 2021 )"]},{"number":"0.3","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - B / 16","400"],"associatedColumns":["5"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Low-shot evaluation on ImageNet-1K using 1% of the labels (approximately 13 images per class). \n ? Indicates evaluations we computed using publicly available models. \n\n","rows":["304M","ViT - B / 4","DINO ( Caron et al . , 2021 )","795M","ViT - B / 8","PAWS ( Assran et al . , 2021 )","MSN","iBOT ( Zhou et al . , 2021 ) ?","24M","ViT - S / 16","22M","iBOT ( Zhou et al . , 2021 )","86M","RN200 ( 2? )","ViT - B / 16","RN50","RN151+SK ( 3? )","Barlow - Tw . ( Zbontar et al . , 2021 )","250M","SimCLRv2 ( Chen et al . , 2020c )","DINO ( Caron et al . , 2021 ) ?","BYOL ( Grill et al . , 2020 )","ViT - L / 7"],"columns":["Top 1"],"mergedAllColumns":["Comparing larger architectures","Comparing similar architectures"],"numberCells":[{"number":"55.0","isBolded":false,"associatedRows":["Barlow - Tw . ( Zbontar et al . , 2021 )","RN50","24M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"66.5","isBolded":false,"associatedRows":["PAWS ( Assran et al . , 2021 )","RN50","24M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"65.9","isBolded":false,"associatedRows":["iBOT ( Zhou et al . , 2021 )","ViT - S / 16","22M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"69.7","isBolded":false,"associatedRows":["iBOT ( Zhou et al . , 2021 ) ?","ViT - B / 16","86M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"75.7","isBolded":true,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","ViT - B / 4","86M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"67.2","isBolded":true,"associatedRows":["MSN","ViT - S / 16","22M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"74.9","isBolded":false,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","RN151+SK ( 3? )","795M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"75.1","isBolded":false,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","ViT - L / 7","304M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"57.9","isBolded":false,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","RN50","24M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"64.5","isBolded":false,"associatedRows":["DINO ( Caron et al . , 2021 )","ViT - S / 16","22M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"71.2","isBolded":false,"associatedRows":["BYOL ( Grill et al . , 2020 )","RN200 ( 2? )","250M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"70.0","isBolded":false,"associatedRows":["DINO ( Caron et al . , 2021 ) ?","ViT - B / 8","86M"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]}]},{"caption":"Table 3: Linear evaluation on ImageNet-1K using 100% of the labels. \n\n","rows":["632M","DINO ( Caron et al . , 2021 )","MoCov3 ( Chen et al . , 2021 )","795M","1000","24M","22M","MAE ( He et al . , 2021 )","ViT - H / 14","86M","ViT - L / 7","304M","ViT - B / 8","MSN","ViT - BN - L / 7","ViT - S / 16","iBOT ( Zhou et al . , 2021 )","RN200 ( 2? )","ViT - B / 16","RN50","1600","RN151+SK ( 3? )","200","300","400","600","250M","800","SimCLRv2 ( Chen et al . , 2020c )","BYOL ( Grill et al . , 2020 )"],"columns":["Top 1"],"mergedAllColumns":["Comparing larger architectures","Comparing similar architectures"],"numberCells":[{"number":"81.0","isBolded":true,"associatedRows":["MoCov3 ( Chen et al . , 2021 )","ViT - BN - L / 7","304M","300"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"80.7","isBolded":true,"associatedRows":["MSN","ViT - L / 7","304M","200"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"77.0","isBolded":false,"associatedRows":["DINO ( Caron et al . , 2021 )","ViT - S / 16","22M","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"79.4","isBolded":false,"associatedRows":["iBOT ( Zhou et al . , 2021 )","ViT - B / 16","86M","400"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"79.6","isBolded":false,"associatedRows":["BYOL ( Grill et al . , 2020 )","RN200 ( 2? )","250M","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"76.6","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","ViT - H / 14","632M","1600"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"77.9","isBolded":true,"associatedRows":["iBOT ( Zhou et al . , 2021 )","ViT - S / 16","22M","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"80.1","isBolded":false,"associatedRows":["DINO ( Caron et al . , 2021 )","ViT - B / 8","86M","300"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"76.9","isBolded":false,"associatedRows":["MSN","ViT - S / 16","22M","600"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"79.8","isBolded":false,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","RN151+SK ( 3? )","795M","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing larger architectures"]},{"number":"74.4","isBolded":false,"associatedRows":["BYOL ( Grill et al . , 2020 )","RN50","24M","1000"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]},{"number":"71.7","isBolded":false,"associatedRows":["SimCLRv2 ( Chen et al . , 2020c )","RN50","24M","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Comparing similar architectures"]}]},{"caption":"Table 4: End-to-end fine-tuning of a ViT-B/16 encoder on ImageNet-1K using 100% of the labels. MSN obtains \ncompetitive performance with both joint-embedding approaches and auto-encoding approaches. \n\n","rows":["DINO ( Caron et al . , 2021 )","1600","iBOT ( He et al . , 2021 )","600","800","MaskFeat ( Wei et al . , 2021 )","Data2Vec ( Baevski et al . , 2022 )","MSN","SimMIM ( Xie et al . , 2021 )","BEiT ( Bao et al . , 2021 )","MAE ( He et al . , 2021 )","-"],"columns":["Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"83.6","isBolded":false,"associatedRows":["MAE ( He et al . , 2021 )","1600"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["MaskFeat ( Wei et al . , 2021 )","-"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["DINO ( Caron et al . , 2021 )","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"83.2","isBolded":false,"associatedRows":["BEiT ( Bao et al . , 2021 )","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["iBOT ( He et al . , 2021 )","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["SimMIM ( Xie et al . , 2021 )","-"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"84.2","isBolded":true,"associatedRows":["Data2Vec ( Baevski et al . , 2022 )","800"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"83.4","isBolded":false,"associatedRows":["MSN","600"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Fine-Tuning Transfer Learning with a ViT-Base/16 pre-trained on ImageNet-1K. Across all tasks, \nMSN either outperforms or achieves similar results to DINO pre-training. The MSN model is trained with a \nmasking ratio of 0.3; i.e., dropping 30% of patches, and thus reduces the computational cost of pre-training \nrelative to DINO. \n\n","rows":["DINO","MSN"],"columns":["CIFAR100","Top 1","iNat19","iNat18","CIFAR10"],"mergedAllColumns":[],"numberCells":[{"number":"78.1","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","iNat19"],"associatedMergedColumns":[]},{"number":"90.5","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","CIFAR100"],"associatedMergedColumns":[]},{"number":"99.0","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","CIFAR10"],"associatedMergedColumns":[]},{"number":"72.0","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","iNat18"],"associatedMergedColumns":[]},{"number":"78.2","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","iNat19"],"associatedMergedColumns":[]},{"number":"99.0","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","CIFAR10"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","iNat18"],"associatedMergedColumns":[]},{"number":"90.5","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","CIFAR100"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Linear Eval. Transfer Learning with a ViT-Base/16 pre-trained on ImageNet-1K. Across both tasks \nand various levels of supervision, MSN either outperforms or achieves similar results to DINO pre-training. \nThe MSN model is trained with a masking ratio of 0.3; i.e., dropping 30% of patches, and thus reduces the \ncomputational cost of pre-training relative to DINO. \n\n","rows":["DINO","MSN"],"columns":["CIFAR100","Top 1","50000 labels","CIFAR10","4000 labels"],"mergedAllColumns":[],"numberCells":[{"number":"82.8","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","CIFAR100","50000 labels"],"associatedMergedColumns":[]},{"number":"82.9","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","CIFAR100","50000 labels"],"associatedMergedColumns":[]},{"number":"93.8","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","CIFAR10","4000 labels"],"associatedMergedColumns":[]},{"number":"95.7","isBolded":false,"associatedRows":["MSN"],"associatedColumns":["Top 1","CIFAR10","50000 labels"],"associatedMergedColumns":[]},{"number":"93.2","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","CIFAR10","4000 labels"],"associatedMergedColumns":[]},{"number":"95.3","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Top 1","CIFAR10","50000 labels"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Masking strategy. Impact of masking strategy on low-shot accuracy (1% of ImageNet-1K labels) of \na ViT-B/16. We only generate one anchor view of each image, except in the last row, where we generate two \nviews, one with a Random Mask and one with a Focal Mask. A random masking ratio of 0.5 is used. Applying a \nrandom mask to the anchor view is better than applying no mask. By combining both random and focal masking \nstrategies, we obtain the strongest performance. \n\n","rows":["Focal Mask","Random Mask","Random Mask + Focal Mask","No Mask"],"columns":["Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"59.8","isBolded":true,"associatedRows":["Random Mask + Focal Mask"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"49.3","isBolded":false,"associatedRows":["No Mask"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"52.3","isBolded":false,"associatedRows":["Random Mask"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"39.3","isBolded":false,"associatedRows":["Focal Mask"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Masking ratio. Impact of pre-training random masking ratio (fraction of randomly dropped patches in \neach random mask) on ImageNet 1% accuracy. Accuracy of larger models improves when leveraging aggressive \nmasking during pre-training. \n\n","rows":["ViT - B / 16","Architecture","NaN","ViT - L / 16","ViT - S / 16"],"columns":["Top 1","-"],"mergedAllColumns":["Random Masking Ratio","-"],"numberCells":[{"number":"0.7","isBolded":false,"associatedRows":["Architecture"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"69.6","isBolded":true,"associatedRows":["ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["-"]},{"number":"0.15","isBolded":false,"associatedRows":["Architecture"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"66.0","isBolded":false,"associatedRows":["ViT - S / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"69.4","isBolded":false,"associatedRows":["ViT - L / 16","NaN","NaN"],"associatedColumns":["Top 1","-"],"associatedMergedColumns":["-"]},{"number":"0.3","isBolded":false,"associatedRows":["Architecture"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"0.5","isBolded":false,"associatedRows":["Architecture"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"66.3","isBolded":true,"associatedRows":["ViT - S / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]},{"number":"68.8","isBolded":false,"associatedRows":["ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["-"]},{"number":"70.1","isBolded":true,"associatedRows":["ViT - L / 16","NaN","NaN"],"associatedColumns":["Top 1","-"],"associatedMergedColumns":["-"]},{"number":"64.8","isBolded":false,"associatedRows":["ViT - S / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Random Masking Ratio"]}]},{"caption":"Table 9: Impact of view-sharing during pre-training on low-shot accuracy (1% of ImageNet-1K labels) of a ViT-\nB/16. The target view is constructed by applying random ColorJitter, Crop, Horizontal Flips, and GaussianBlur \nto the input image. When using the same image view, MSN finds a shortcut solution. Using color jitter prevents \nthis pathological behaviour. Randomly applying additional geometric data transformations to the anchor further \nimproves performance, demonstrating the importance of view invariance in the low-shot setting. \n\n","rows":["Target View","Target View + ColorJitter","Target View + ColorJitter + Crop + Flip + GaussianBlur"],"columns":["Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"48.7","isBolded":false,"associatedRows":["Target View + ColorJitter"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"7.0","isBolded":false,"associatedRows":["Target View"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"52.3","isBolded":true,"associatedRows":["Target View + ColorJitter + Crop + Flip + GaussianBlur"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Impact of random masking ratio on GPU memory usage and runtime when pre-training a ViT-L/7. \nMeasurements are conducted on a single AWS p4d-24xlarge machine, containing 8 A100 GPUs, using a \nbatch-size of 2 images per GPU. In each iteration we also generate 10 focal views (small crops) of each input \nimage; the random masking ratio has no impact on these views. Using more aggressive masking of the global \nview progressively reduces device memory utilization and speeds up training. \n\n","rows":[],"columns":["18G","26G","21G","Masking Ratio"],"mergedAllColumns":[],"numberCells":[{"number":"0.7","isBolded":false,"associatedRows":[],"associatedColumns":["Masking Ratio","26G","21G","18G"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":[],"associatedColumns":["Masking Ratio","26G","21G"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":[],"associatedColumns":["Masking Ratio","26G"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":[],"associatedColumns":["Masking Ratio"],"associatedMergedColumns":[]}]},{"caption":"Table 11: Effect of Sinkhorn normalization. We train a ViT-S/16 with a masking ratio of 0.15, and explore \nthe impact of Sinkhorn normalization during pre-training on low-shot performance with 1% of ImageNet-1K. \nTuning the ME-MAX regularization weight and omitting Sinkhorn normalization gives better performance. \n\n","rows":["ViT - S / 16","None","Sinkhorn"],"columns":["ME - MAX weight ?","Architecture","Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"67.2","isBolded":true,"associatedRows":["None"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"60.8","isBolded":false,"associatedRows":["ViT - S / 16","None"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["Sinkhorn"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"5.0","isBolded":false,"associatedRows":["None"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Sinkhorn"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["ViT - S / 16","None"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]},{"number":"C.2","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]}]},{"caption":"Table 12. \n\n","rows":["ViT - S / 16","None","Sinkhorn"],"columns":["ME - MAX weight ?","Architecture","Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"1.0","isBolded":false,"associatedRows":["Sinkhorn"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["ViT - S / 16","None"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]},{"number":"67.2","isBolded":true,"associatedRows":["None"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"C.2","isBolded":false,"associatedRows":[],"associatedColumns":["Architecture"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["Sinkhorn"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"60.8","isBolded":false,"associatedRows":["ViT - S / 16","None"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"5.0","isBolded":false,"associatedRows":["None"],"associatedColumns":["ME - MAX weight ?"],"associatedMergedColumns":[]}]},{"caption":"Table 12: Effect of number of prototypes. We train a ViT-B/16 with a masking ratio of 0.3, and explore the \nimpact of the number of prototypes during pre-training on low-shot performance with 1% of ImageNet-1K. \nUsing more prototypes has little effect on training, but using fewer prototypes can degrade performance. \n\n","rows":["ViT - B / 16","2048","512","1024"],"columns":["Top 1"],"mergedAllColumns":[],"numberCells":[{"number":"67.6","isBolded":false,"associatedRows":["512"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":true,"associatedRows":["ViT - B / 16","1024"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":true,"associatedRows":["2048"],"associatedColumns":["Top 1"],"associatedMergedColumns":[]}]},{"caption":"Table 13: MAE low-shot evaluations. Top-1 low-shot validation accuracy for different training strategies with \nMAE pre-trained models. Partial fine-tuning corresponds to fine-tuning the last block of the pre-trained model \nalong with a linear head on the available labeled samples. Linear evaluation corresponds to training a linear \nclassifier on top of the frozen pre-trained encoder. MAE benefits from partial fine-tuning, but for sufficiently \nlarge models, such as the ViT-H/14, this leads to significant overfitting in the low-shot regime, where one must \ninstead one must resort to linear evaluation. \n\n","rows":["ViT - B / 16","Linear Eval .","Partial Fine - Tuning","ViT - L / 16","ViT - H / 14"],"columns":["rand","2","Top 1","5","?13"],"mergedAllColumns":["Images per Class"],"numberCells":[{"number":"32.8","isBolded":false,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","5","rand"],"associatedMergedColumns":["Images per Class"]},{"number":"42.3","isBolded":false,"associatedRows":["ViT - B / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","5"],"associatedMergedColumns":["Images per Class"]},{"number":"51.1","isBolded":false,"associatedRows":["ViT - B / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","?13"],"associatedMergedColumns":["Images per Class"]},{"number":"35.7","isBolded":true,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","5"],"associatedMergedColumns":["Images per Class"]},{"number":"40.5","isBolded":false,"associatedRows":["ViT - B / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","5"],"associatedMergedColumns":["Images per Class"]},{"number":"22.1","isBolded":false,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","2"],"associatedMergedColumns":["Images per Class"]},{"number":"25.2","isBolded":true,"associatedRows":["ViT - B / 16","Linear Eval ."],"associatedColumns":["Top 1","5"],"associatedMergedColumns":["Images per Class"]},{"number":"48.6","isBolded":true,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","?13"],"associatedMergedColumns":["Images per Class"]},{"number":"59.4","isBolded":false,"associatedRows":["ViT - B / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","?13"],"associatedMergedColumns":["Images per Class"]},{"number":"46.7","isBolded":false,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","?13","rand"],"associatedMergedColumns":["Images per Class"]},{"number":"18.6","isBolded":false,"associatedRows":["ViT - H / 14","Linear Eval ."],"associatedColumns":["Top 1","2","rand"],"associatedMergedColumns":["Images per Class"]},{"number":"19.3","isBolded":true,"associatedRows":["ViT - L / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","2"],"associatedMergedColumns":["Images per Class"]},{"number":"14.5","isBolded":true,"associatedRows":["ViT - B / 16","Linear Eval ."],"associatedColumns":["Top 1","2"],"associatedMergedColumns":["Images per Class"]},{"number":"25.0","isBolded":false,"associatedRows":["ViT - B / 16","Partial Fine - Tuning"],"associatedColumns":["Top 1","2"],"associatedMergedColumns":["Images per Class"]},{"number":"36.6","isBolded":true,"associatedRows":["ViT - B / 16","Linear Eval ."],"associatedColumns":["Top 1","?13"],"associatedMergedColumns":["Images per Class"]}]},{"caption":"Table 14: Evaluation on alternative ImageNet validation sets. We evaluate the performance of a fine-tuned \nViT-B/16 model on four alternative ImageNet validation sets: ImageNet-A, ImageNet-R, ImageNet-Sketch, and \nImageNet-C. The metric used for the first three (-A, -R, and -Sketch) is top-1 accuracy on the validation set. \nOn ImageNet-C, performance is measured in terms of mean Corruption Error (mCE) (Hendrycks \u0026 Dietterich,  2019). \n\n","rows":["MSN ViT - B / 16","MAE ViT - B / 16 ( He et al . , 2021 )","Supervised ResNet50"],"columns":[")"],"mergedAllColumns":[],"numberCells":[{"number":"0.04","isBolded":false,"associatedRows":["Supervised ResNet50"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"34.5","isBolded":false,"associatedRows":["MAE ViT - B / 16 ( He et al . , 2021 )"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"46.6","isBolded":true,"associatedRows":["MSN ViT - B / 16"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"35.9","isBolded":false,"associatedRows":["MAE ViT - B / 16 ( He et al . , 2021 )"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"36.3","isBolded":true,"associatedRows":["MSN ViT - B / 16"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"51.7","isBolded":false,"associatedRows":["MAE ViT - B / 16 ( He et al . , 2021 )"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"24.2","isBolded":false,"associatedRows":["Supervised ResNet50"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"36.11","isBolded":false,"associatedRows":["Supervised ResNet50"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"37.5","isBolded":true,"associatedRows":["MSN ViT - B / 16"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"76.7","isBolded":false,"associatedRows":["Supervised ResNet50"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"48.3","isBolded":false,"associatedRows":["MAE ViT - B / 16 ( He et al . , 2021 )"],"associatedColumns":[")"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":true,"associatedRows":["MSN ViT - B / 16"],"associatedColumns":[")"],"associatedMergedColumns":[]}]},{"caption":"Table 15: Robustness to missing patches (low-shot). Evaluating the low-shot accuracy of pre-trained models \non 1% of ImageNet-1K when corrupting the annotated images by dropping patches. We train a linear classifier \nusing masked images, and then evaluate on the standard ImageNet-1K validation set using unmasked images. \nWe observe that MSN pre-training leads to representations that are more robust to masking. Moreover, models \npre-trained with more aggressive masking exhibit this behaviour to a higher degree. \n\n","rows":["ViT - B / 16","Arch .","DINO","Alg .","Pre - train Masking Ratio","ViT - L / 7"],"columns":["Top 1"],"mergedAllColumns":["?","Eval . Masking Ratio"],"numberCells":[{"number":"75.1","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"74.9","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.7","isBolded":false,"associatedRows":["Alg .","Arch .","Pre - train Masking Ratio"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.3","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.0","isBolded":false,"associatedRows":["Alg .","Arch .","Pre - train Masking Ratio"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.0","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.7","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"69.5","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"63.1","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"67.1","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-0.2","isBolded":true,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-2.4","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"67.0","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-3.9","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]}]},{"caption":"Table 16. As expected, the cosine similarity between masked and unmasked representations \nof the same image is higher when pre-training with MSN, supporting the observation that masked-\npretraining results in representations that are more robust to patch-removal. \n\n","rows":["ViT - B / 16","Arch .","DINO","Alg .","Pre - train Masking Ratio","ViT - L / 7"],"columns":["Top 1"],"mergedAllColumns":["?","Eval . Masking Ratio"],"numberCells":[{"number":"63.1","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-0.2","isBolded":true,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"74.9","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.0","isBolded":false,"associatedRows":["Alg .","Arch .","Pre - train Masking Ratio"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.0","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-3.9","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"67.0","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"-2.4","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.7","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"69.5","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"0.7","isBolded":false,"associatedRows":["Alg .","Arch .","Pre - train Masking Ratio"],"associatedColumns":["Top 1"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.3","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"67.1","isBolded":false,"associatedRows":["DINO","ViT - B / 16"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]},{"number":"75.1","isBolded":false,"associatedRows":["DINO","ViT - L / 7"],"associatedColumns":["Top 1"],"associatedMergedColumns":["?"]}]},{"caption":"Table 16: Robustness to missing patches (cosine-similarity). Average Cosine Distance between masked and \nunmasked representations of the same image. We compare the representations learned with MSN masked \npre-training to those learned with DINO when using a ViT-B/16 encoder. The MSN ViT-B/16 is pre-trained \nwith a masking ratio of 0.3. The cosine distances are computed and averaged over the ImageNet-1k validation \nset. The cosine similarity between masked and unmasked representations of the same image is higher when \npre-training with MSN, supporting the observation that masked-pretraining results in representations that are \nmore robust to patch-removal. \n\n","rows":["DINO","MSN","Alg ."],"columns":["Cosine Similarity"],"mergedAllColumns":["Eval . Masking Ratio"],"numberCells":[{"number":"0.3","isBolded":false,"associatedRows":["Alg ."],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.98","isBolded":true,"associatedRows":["MSN"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.81","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.9","isBolded":false,"associatedRows":["Alg ."],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.5","isBolded":false,"associatedRows":["Alg ."],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.99","isBolded":true,"associatedRows":["MSN"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.7","isBolded":false,"associatedRows":["Alg ."],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.92","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.97","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.99","isBolded":true,"associatedRows":["MSN"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.97","isBolded":true,"associatedRows":["MSN"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.99","isBolded":true,"associatedRows":["MSN"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.15","isBolded":false,"associatedRows":["Alg ."],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.56","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]},{"number":"0.98","isBolded":false,"associatedRows":["DINO"],"associatedColumns":["Cosine Similarity"],"associatedMergedColumns":["Eval . Masking Ratio"]}]}]