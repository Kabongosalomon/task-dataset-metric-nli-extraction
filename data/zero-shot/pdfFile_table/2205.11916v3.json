[{"caption":"Table 1: Accuracy comparison of Zero-shot-CoT with Zero-shot on each tasks. The values on the left \nside of each task are the results of using answer extraction prompts depending on answer format as \ndescribed at  ? 3. The values on the right side are the result of additional experiment where standard \nanswer prompt \"The answer is\" is used for answer extraction. See Appendix A.5 for detail setups. \n\n","rows":["answer prompt \" The answer is \" is used for answer extraction . See Appendix"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"A.5fordetailsetups.","isBolded":false,"associatedRows":["answer prompt \" The answer is \" is used for answer extraction . See Appendix"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison with baseline methods using accuracies on MultiArith and GSM8K. Text-\ndavinci-002 (175B) is used as the model if not specified. We used the same 8 examples as described \nin [Wei et al., 2022] for Few-shot and Few-shot-CoT settings. (*1) To verify the variance of changing \nexamples, we report two results for 4-shot-cot by splitting the eight examples into two groups. (*2) We \ninsert \"Let\u0027s think step by step.\" at the beginning of answer part of each exemplars for Few-shot-CoT \nto test performance gains. Further experiment results with PaLM are found at Appendix D \n\nMultiArith GSM8K \n\nZero-Shot \n17.7 \n10.4 \nFew-Shot (2 samples) \n33.7 \n15.6 \nFew-Shot (8 samples) \n33.8 \n15.6 \n\nZero-Shot-CoT \n78.7 \n40.7 \nFew-Shot-CoT (2 samples) \n84.8 \n41.3 \nFew-Shot-CoT (4 samples : First) (*1) \n89.2 \n-\nFew-Shot-CoT (4 samples : Second) (*1) \n90.5 \n-\nFew-Shot-CoT (8 samples) \n93.0 \n48.7 \nZero-Plus-Few-Shot-CoT (8 samples) (*2) \n92.8 \n51.5 \n\nFinetuned GPT-3 175B [Wei et al., 2022] \n-\n33 \nFinetuned GPT-3 175B + verifier [Wei et al., 2022] \n-\n55 \n\nPaLM 540B: Zero-Shot \n25.5 \n12.5 \nPaLM 540B: Zero-Shot-CoT \n66.1 \n43.0 \nPaLM 540B: Zero-Shot-CoT + self consistency \n89.0 \n70.1 \nPaLM 540B: Few-Shot [Wei et al., 2022]  -\n17.9 \nPaLM 540B: Few-Shot-CoT [Wei et al., 2022]  -\n56.9 \nPaLM 540B: Few-Shot-CoT + self consistency ","rows":["Zero - Plus - Few - Shot - CoT ( 8 samples ) ( * 2 )","Few - Shot - CoT ( 4 samples : First ) ( * 1 )","Few - Shot - CoT ( 4 samples : Second ) ( * 1 )","PaLM 540B : Few - Shot [ Wei et al . , 2022 ]","-","PaLM 540B : Zero - Shot - CoT + self consistency","Few - Shot ( 8 samples )","Few - Shot - CoT ( 8 samples )","PaLM 540B : Few - Shot - CoT [ Wei et al . , 2022 ]","Few - Shot ( 2 samples )","Zero - Shot - CoT","PaLM 540B : Zero - Shot - CoT","Few - Shot - CoT ( 2 samples )","Zero - Shot","PaLM 540B : Zero - Shot"],"columns":["33","55","MultiArith","Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","-"],"mergedAllColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D","-"],"numberCells":[{"number":"90.5","isBolded":false,"associatedRows":["Few - Shot - CoT ( 4 samples : Second ) ( * 1 )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["-"]},{"number":"33.8","isBolded":false,"associatedRows":["Few - Shot ( 8 samples )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"15.6","isBolded":false,"associatedRows":["Few - Shot ( 8 samples )","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"17.9","isBolded":false,"associatedRows":["PaLM 540B : Few - Shot [ Wei et al . , 2022 ]","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","33","55"],"associatedMergedColumns":["-"]},{"number":"56.9","isBolded":false,"associatedRows":["PaLM 540B : Few - Shot - CoT [ Wei et al . , 2022 ]","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","33","55"],"associatedMergedColumns":["-"]},{"number":"17.7","isBolded":true,"associatedRows":["Zero - Shot"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"40.7","isBolded":true,"associatedRows":["Zero - Shot - CoT","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"70.1","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot - CoT + self consistency","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","33","55"],"associatedMergedColumns":["-"]},{"number":"78.7","isBolded":true,"associatedRows":["Zero - Shot - CoT"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"84.8","isBolded":false,"associatedRows":["Few - Shot - CoT ( 2 samples )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"51.5","isBolded":true,"associatedRows":["Zero - Plus - Few - Shot - CoT ( 8 samples ) ( * 2 )","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["-"]},{"number":"25.5","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith","-","-"],"associatedMergedColumns":["-"]},{"number":"33.7","isBolded":false,"associatedRows":["Few - Shot ( 2 samples )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"10.4","isBolded":true,"associatedRows":["Zero - Shot","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"92.8","isBolded":true,"associatedRows":["Zero - Plus - Few - Shot - CoT ( 8 samples ) ( * 2 )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["-"]},{"number":"43.0","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot - CoT","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","33","55"],"associatedMergedColumns":["-"]},{"number":"48.7","isBolded":false,"associatedRows":["Few - Shot - CoT ( 8 samples )","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["-"]},{"number":"89.0","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot - CoT + self consistency"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith","-","-"],"associatedMergedColumns":["-"]},{"number":"15.6","isBolded":false,"associatedRows":["Few - Shot ( 2 samples )","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"41.3","isBolded":false,"associatedRows":["Few - Shot - CoT ( 2 samples )","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"89.2","isBolded":false,"associatedRows":["Few - Shot - CoT ( 4 samples : First ) ( * 1 )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["to test performance gains . Further experiment results with PaLM are found at Appendix D"]},{"number":"93.0","isBolded":false,"associatedRows":["Few - Shot - CoT ( 8 samples )"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith"],"associatedMergedColumns":["-"]},{"number":"12.5","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot","-"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","GSM8K","33","55"],"associatedMergedColumns":["-"]},{"number":"66.1","isBolded":true,"associatedRows":["PaLM 540B : Zero - Shot - CoT"],"associatedColumns":["Table 2 : Comparison with baseline methods using accuracies on MultiArith and GSM8K . Text -","MultiArith","-","-"],"associatedMergedColumns":["-"]}]},{"caption":"Table 3: Examples generated by Zero-Shot-CoT on CommonsenseQA for Error Analysis. \n\n","rows":["175B"],"columns":["0","Zero - shot - CoT","Zero - shot"],"mergedAllColumns":[],"numberCells":[{"number":"20","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"80","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"50","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"6.7B","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot - CoT","0"],"associatedMergedColumns":[]},{"number":"1.3B","isBolded":false,"associatedRows":["175B"],"associatedColumns":["Zero - shot","0"],"associatedMergedColumns":[]},{"number":"60","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"60","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"0.3B","isBolded":false,"associatedRows":["175B"],"associatedColumns":["Zero - shot","0"],"associatedMergedColumns":[]},{"number":"30","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"80","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"0.3B","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot","0"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"6.7B","isBolded":false,"associatedRows":["175B"],"associatedColumns":["Zero - shot - CoT","0"],"associatedMergedColumns":[]},{"number":"1.3B","isBolded":false,"associatedRows":[],"associatedColumns":["Zero - shot","0"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Robustness study against template measured on the MultiArith dataset with the Text-\ndavinci-002 (175B) variant. (*1) This template is used in Ahn et al. [2022] where a language model is \nprompted to generate step-by-step actions given a high-level instruction for controlling robotic actions. \n(*2) This template is used in Reynolds and McDonell [2021] but is not quantitatively evaluated. \n\n","rows":["First , ( * 1 )","Let \u0027 s solve this problem by splitting it into steps . ( * 2 )","instructive","Let \u0027 s think step by step .","Let \u0027 s think like a detective step by step .","Let \u0027 s think about this logically .","Let \u0027 s be realistic and think step by step ."],"columns":["Accuracy","No ."],"mergedAllColumns":[],"numberCells":[{"number":"78.7","isBolded":true,"associatedRows":["instructive","Let \u0027 s think step by step ."],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"70.3","isBolded":false,"associatedRows":["Let \u0027 s think like a detective step by step ."],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"74.5","isBolded":false,"associatedRows":["Let \u0027 s think about this logically ."],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"77.3","isBolded":false,"associatedRows":["First , ( * 1 )"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"7","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"6","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"70.8","isBolded":false,"associatedRows":["Let \u0027 s be realistic and think step by step ."],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":[],"associatedColumns":["No ."],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["Let \u0027 s solve this problem by splitting it into steps . ( * 2 )"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Robustness study of Few-shot-CoT against examples. When the examples are from en-\ntirely different tasks, the performance generally becomes worse, but when the answer formats are \nmatched (i.e. CommonsenseQA to AQUA-RAT, multiple-choice), the performance loss is less severe. \n ? CommonsenseQA samples are used in this variation \n\nZero-shot \nFew-shot-CoT  ? \nZero-shot-CoT \nFew-shot-CoT \n\nAQUA-RAT \n22.4 \n31.9 \n33.5 \n39.0 \nMultiArith \n17.7 \n27.0 \n78.7 \n88.2 \n\n","rows":["By the way , I found a good restaurant nearby .","Abrakadabra !","14","irrelevant","15","AQUA - RAT","16","MultiArith","It \u0027 s a beautiful day .","( Zero - shot )","-"],"columns":["Zero - shot - CoT","Zero - shot","Few - shot - CoT ?","Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Few - shot - CoT"],"mergedAllColumns":["CommonsenseQA samples are used in this variation"],"numberCells":[{"number":"17.7","isBolded":false,"associatedRows":["-","( Zero - shot )"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"88.2","isBolded":false,"associatedRows":["MultiArith","By the way , I found a good restaurant nearby ."],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Few - shot - CoT"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"31.9","isBolded":false,"associatedRows":["AQUA - RAT","( Zero - shot )"],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Few - shot - CoT ?"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"33.5","isBolded":false,"associatedRows":["AQUA - RAT","It \u0027 s a beautiful day ."],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Zero - shot - CoT"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"13.1","isBolded":false,"associatedRows":["16","It \u0027 s a beautiful day ."],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"17.5","isBolded":false,"associatedRows":["14","irrelevant","By the way , I found a good restaurant nearby ."],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["AQUA - RAT","By the way , I found a good restaurant nearby ."],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Few - shot - CoT"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"27.0","isBolded":false,"associatedRows":["MultiArith","( Zero - shot )"],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Few - shot - CoT ?"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"78.7","isBolded":false,"associatedRows":["MultiArith","It \u0027 s a beautiful day ."],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Zero - shot - CoT"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"15.5","isBolded":false,"associatedRows":["15","Abrakadabra !"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"17.7","isBolded":false,"associatedRows":["MultiArith"],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Zero - shot"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]},{"number":"22.4","isBolded":false,"associatedRows":["AQUA - RAT"],"associatedColumns":["Table 5 : Robustness study of Few - shot - CoT against examples . When the examples are from en -","Zero - shot"],"associatedMergedColumns":["CommonsenseQA samples are used in this variation"]}]},{"caption":"Table 7: Dataset Description. Our experiments used publicly available datasets except for \"Last \nLetters\" and \"Coin Flip\" datasets. We created these two datasets. See Appendix A.2.2 for the details. \n(*1) N : Number, M : Pick up one from multiple choices, Y : Answer Yes or No, F : Free Format. \n(*2) Average number of words in questions texts. \n\n","rows":["2290","AQUA - RAT","F","1000","M","N","395","Coin Flip","254","750","Shuffled Objects","Last Letters","MultiArith","SVAMP","Y","1319","AddSub","StrategyQA","Date Understanding","500","SingleEq","600","369","1221","GSM8K","508","CommonsenseQA"],"columns":["test . jsonl","dev_rand_split . jsonl","words","questions . json","AddSub . json","SVAMP . json","-","Avg #","( * 2 )","MultiArith . json","task . json","three_objects / task . json"],"mergedAllColumns":[],"numberCells":[{"number":"35.0","isBolded":false,"associatedRows":["Date Understanding","M","369"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json","dev_rand_split . jsonl","task . json"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":false,"associatedRows":["Last Letters","F","500"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json","dev_rand_split . jsonl","task . json","task . json","three_objects / task . json"],"associatedMergedColumns":[]},{"number":"9.6","isBolded":false,"associatedRows":["StrategyQA","Y","2290"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json","dev_rand_split . jsonl"],"associatedMergedColumns":[]},{"number":"27.8","isBolded":false,"associatedRows":["CommonsenseQA","M","1221"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":false,"associatedRows":["AddSub","N","395"],"associatedColumns":["Avg #","words","( * 2 )","questions . json"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["SVAMP","N","1000"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["Coin Flip","Y","500"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json","dev_rand_split . jsonl","task . json","task . json","three_objects / task . json","-"],"associatedMergedColumns":[]},{"number":"27.4","isBolded":false,"associatedRows":["SingleEq","N","508"],"associatedColumns":["Avg #","words","( * 2 )"],"associatedMergedColumns":[]},{"number":"91.1","isBolded":false,"associatedRows":["Shuffled Objects","M","750"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl","test . jsonl","SVAMP . json","dev_rand_split . jsonl","task . json","task . json"],"associatedMergedColumns":[]},{"number":"46.9","isBolded":false,"associatedRows":["GSM8K","N","1319"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json"],"associatedMergedColumns":[]},{"number":"51.9","isBolded":false,"associatedRows":["AQUA - RAT","M","254"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json","MultiArith . json","test . jsonl"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["MultiArith","N","600"],"associatedColumns":["Avg #","words","( * 2 )","questions . json","AddSub . json"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Description of language models. (*1) As for GPT-3 model series, we attach model size \ninformation to each model by referring to https://blog.eleuther.ai/gpt3-model-sizes/ \n\nLanguage Model # of params Library / API Name \nModel Name in Library / API License \n\nPaLM \n540B \n-\n-\nunspecified \nPaLM \n62B \n-\n-\nunspecified \nPaLM \n8B \n-\n-\nunspecified \n\nOriginal GPT3 \n175B (*1) \nOpenAI API \ndavinci \nunspecified \nOriginal GPT3 \n6.7B (*1) \nOpenAI API \ncurie \nunspecified \nOriginal GPT3 \n1.3B (*1) \nOpenAI API \nbabbage \nunspecified \nOriginal GPT3 \n0.3B (*1) \nOpenAI API \nada \nunspecified \n\nInstruct GPT3 \n175B (*1) \nOpenAI API \ntext-davinci-002 \nunspecified \nInstruct GPT3 \n175B (*1) \nOpenAI API \ntext-davinci-001 \nunspecified \nInstruct GPT3 \n6.7B (*1) \nOpenAI API \ntext-curie-001 \nunspecified \nInstruct GPT3 \n1.3B (*1) \nOpenAI API \ntext-babbage-001 \nunspecified \nInstruct GPT3 \n0.3B (*1) \nOpenAI API \ntext-ada-001 \nunspecified \n\nOPT \n13B \nHugging Face Library opt-13b \nApache-2.0 \nT0 \n11B \nHugging Face Library T0pp \nApache-2.0 \nGPT-J \n6B \nHugging Face Library gptj \nApache-2.0 \nGPT-Neo \n2.7B \nHugging Face Library gpt-neo \nApache-2.0 \nGPT-2 \n1.5B \nHugging Face Library gpt2-xl \nApache-2.0 \n\n","rows":["Original GPT3","GPT - 2","Instruct GPT3","GPT - Neo"],"columns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","13B","OpenAI API","11B","62B","540B","# of params","8B","175B ( * 1 )","6B","Hugging Face Library"],"mergedAllColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"],"numberCells":[{"number":"0.3B(*1)","isBolded":false,"associatedRows":["Instruct GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","175B ( * 1 )","175B ( * 1 )","OpenAI API","OpenAI API"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"2.7B","isBolded":false,"associatedRows":["GPT - Neo"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","175B ( * 1 )","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","13B","11B","6B"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"6.7B(*1)","isBolded":false,"associatedRows":["Original GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"1.5B","isBolded":false,"associatedRows":["GPT - 2"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","175B ( * 1 )","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","13B","11B","6B","Hugging Face Library"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"1.3B(*1)","isBolded":false,"associatedRows":["Original GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"6.7B(*1)","isBolded":false,"associatedRows":["Instruct GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","175B ( * 1 )","175B ( * 1 )"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"0.3B(*1)","isBolded":false,"associatedRows":["Original GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]},{"number":"1.3B(*1)","isBolded":false,"associatedRows":["Instruct GPT3"],"associatedColumns":["Table 8 : Description of language models . ( * 1 ) As for GPT - 3 model series , we attach model size","# of params","540B","62B","8B","175B ( * 1 )","OpenAI API","OpenAI API","OpenAI API","175B ( * 1 )","175B ( * 1 )","OpenAI API"],"associatedMergedColumns":["information to each model by referring to https : / / blog . eleuther . ai / gpt3 - model - sizes /"]}]},{"caption":"Table 21: Categorization results of generated chain of thought by \nZero-shot-CoT for CommonsenseQA datasets. \n\n","rows":["CoT is correct","Others","Logical Mistake","Incorrect","CoT is incorrect","CommonSense Mistake","Factual Mistake"],"columns":["Zero - Shot - CoT ( % )"],"mergedAllColumns":[],"numberCells":[{"number":"22.0","isBolded":false,"associatedRows":["Incorrect","CoT is incorrect"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["Incorrect","Factual Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"78.0","isBolded":true,"associatedRows":["Incorrect","CoT is correct"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"10.0","isBolded":false,"associatedRows":["Incorrect","Others"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["Incorrect","Logical Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"62.0","isBolded":true,"associatedRows":["Incorrect","CommonSense Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]}]},{"caption":"Table 23: Categorization results of produced chain of thought for MultiArith datasets. (*1) \nThese categories are cited from Wei et al. [2022]. \n\n","rows":["CoT is correct","Others","Logical Mistake","Incorrect","CoT is incorrect","CommonSense Mistake","Factual Mistake","Correct"],"columns":["( 26 . 2 )","Few - Shot - CoT ( % )","( 4 . )","( 2 . 4 )","( 7 . 1 )","( 35 . 7 )","( 6 . )","( 10 . )","Zero - Shot - CoT ( % )","( 40 . )","( 8 . )"],"mergedAllColumns":[],"numberCells":[{"number":"2.0","isBolded":false,"associatedRows":["Incorrect","CoT is incorrect"],"associatedColumns":["Few - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"23.8","isBolded":true,"associatedRows":["Incorrect","CommonSense Mistake"],"associatedColumns":["Few - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["Incorrect","Factual Mistake"],"associatedColumns":["Few - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":false,"associatedRows":["Incorrect","Logical Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"2.4","isBolded":false,"associatedRows":["Incorrect","Others"],"associatedColumns":["Few - Shot - CoT ( % )","( 26 . 2 )","( 2 . 4 )","( 7 . 1 )","( 2 . 4 )","( 35 . 7 )"],"associatedMergedColumns":[]},{"number":"6.0","isBolded":false,"associatedRows":["Correct","CoT is incorrect"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"10.0","isBolded":false,"associatedRows":["Incorrect","CommonSense Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"2.0","isBolded":false,"associatedRows":["Incorrect","Factual Mistake"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"94.0","isBolded":false,"associatedRows":["Correct","CoT is correct"],"associatedColumns":["Zero - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"98.0","isBolded":false,"associatedRows":["Correct","CoT is correct"],"associatedColumns":["Few - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"73.8","isBolded":false,"associatedRows":["Incorrect","Logical Mistake"],"associatedColumns":["Few - Shot - CoT ( % )"],"associatedMergedColumns":[]},{"number":"20.0","isBolded":true,"associatedRows":["Incorrect","Others"],"associatedColumns":["Zero - Shot - CoT ( % )","( 8 . )","( 4 . )","( 6 . )","( 10 . )","( 40 . )"],"associatedMergedColumns":[]}]},{"caption":"Table 25: Further experiment results with PaLM (540B). Evaluation metric is Accuracy. \n\n","rows":["Zero - shot - CoT","Zero - shot","Zero - shot - CoT + self consistency"],"columns":["AQUA - RAT","MultiArith","SVAMP","GSM8K"],"mergedAllColumns":[],"numberCells":[{"number":"36.1","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["AQUA - RAT"],"associatedMergedColumns":[]},{"number":"43.0","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GSM8K"],"associatedMergedColumns":[]},{"number":"63.1","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["SVAMP"],"associatedMergedColumns":[]},{"number":"66.1","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["MultiArith"],"associatedMergedColumns":[]},{"number":"80.5","isBolded":false,"associatedRows":["Zero - shot - CoT + self consistency"],"associatedColumns":["SVAMP"],"associatedMergedColumns":[]},{"number":"46.5","isBolded":false,"associatedRows":["Zero - shot - CoT + self consistency"],"associatedColumns":["AQUA - RAT"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Zero - shot - CoT + self consistency"],"associatedColumns":["GSM8K"],"associatedMergedColumns":[]},{"number":"25.5","isBolded":true,"associatedRows":["Zero - shot"],"associatedColumns":["MultiArith"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":false,"associatedRows":["Zero - shot - CoT + self consistency"],"associatedColumns":["MultiArith"],"associatedMergedColumns":[]},{"number":"23.4","isBolded":true,"associatedRows":["Zero - shot"],"associatedColumns":["AQUA - RAT"],"associatedMergedColumns":[]},{"number":"63.1","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["SVAMP"],"associatedMergedColumns":[]},{"number":"12.5","isBolded":true,"associatedRows":["Zero - shot"],"associatedColumns":["GSM8K"],"associatedMergedColumns":[]}]},{"caption":"Table 26: Model scale study. Evaluation metric is accuracy on MultiArith dataset. 175B-1 : text-\ndavinci-001, 175B-2 : text-davinci-002. It is verified that CoT is effective when the model is larger, \nsuch as Instruct GPT-3 (175B parameters; text-davinci-001 and text-davinci-002) and Original GPT-3 \n(175B parameters; davinci). In this experiment, the order of performance (ascending) is Zero-shot, \nFew-shot (8samples), Zero-shot-CoT, and Few-shot-CoT (8samples) for davinci and text-davinci-002. \n\n","rows":["Zero - shot - CoT","Zero - shot","Few - shot - CoT","Few - shot"],"columns":["GPT - J ( 6B )","GPT - 2 ( 1 . 5B )","OPT ( 13B )","T0 ( 11B )","GPT - Neo ( 2 . 7B )"],"mergedAllColumns":[],"numberCells":[{"number":"4.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.3/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.7/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - 2 ( 1 . 5B )"],"associatedMergedColumns":[]},{"number":"1.8/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"33.7","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.3/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"8.1","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"6.3/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["T0 ( 11B )"],"associatedMergedColumns":[]},{"number":"2.0/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.3/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.8/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.3","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"14.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"78.7","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.5/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"19.0","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - J ( 6B )"],"associatedMergedColumns":[]},{"number":"1.5/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.7/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.3/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.8","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["T0 ( 11B )"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - Neo ( 2 . 7B )"],"associatedMergedColumns":[]},{"number":"3.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["OPT ( 13B )"],"associatedMergedColumns":[]},{"number":"2.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["OPT ( 13B )"],"associatedMergedColumns":[]},{"number":"3.2","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - 2 ( 1 . 5B )"],"associatedMergedColumns":[]},{"number":"3.7/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.0/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.5/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"93.0","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"47.8/","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.5","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - J ( 6B )"],"associatedMergedColumns":[]},{"number":"1.3","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - Neo ( 2 . 7B )"],"associatedMergedColumns":[]},{"number":"17.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"36.8/","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"5.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.3/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.8/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"44.3","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"8.0/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.8/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"5.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.2/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 27: Model scale study with PaLM. Evalua-\ntion metric is accuracy on GSM8K dataset. \n\n","rows":["Zero - shot - CoT","Zero - shot","Few - shot - CoT","Few - shot"],"columns":["GPT - J ( 6B )","GPT - 2 ( 1 . 5B )","OPT ( 13B )","T0 ( 11B )","GPT - Neo ( 2 . 7B )"],"mergedAllColumns":[],"numberCells":[{"number":"1.7/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"44.3","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.5","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - J ( 6B )"],"associatedMergedColumns":[]},{"number":"4.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.5/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.8/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.3/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"47.8/","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.3/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"33.7","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"19.0","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.3","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - Neo ( 2 . 7B )"],"associatedMergedColumns":[]},{"number":"2.5/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"6.3/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"5.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"17.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"8.1","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - Neo ( 2 . 7B )"],"associatedMergedColumns":[]},{"number":"2.2/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"78.7","isBolded":true,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.8","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["T0 ( 11B )"],"associatedMergedColumns":[]},{"number":"2.0/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.7/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["T0 ( 11B )"],"associatedMergedColumns":[]},{"number":"2.0/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.8/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"8.0/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.3/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.3/","isBolded":false,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["GPT - 2 ( 1 . 5B )"],"associatedMergedColumns":[]},{"number":"2.2","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":["OPT ( 13B )"],"associatedMergedColumns":[]},{"number":"3.8/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"36.8/","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"14.0/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.2","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - 2 ( 1 . 5B )"],"associatedMergedColumns":[]},{"number":"3.3","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"5.2/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.3/","isBolded":false,"associatedRows":["Zero - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"4.8/","isBolded":false,"associatedRows":["Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"93.0","isBolded":true,"associatedRows":["Few - shot - CoT"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.5/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["GPT - J ( 6B )"],"associatedMergedColumns":[]},{"number":"3.7","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":["OPT ( 13B )"],"associatedMergedColumns":[]},{"number":"3.7/","isBolded":false,"associatedRows":["Zero - shot"],"associatedColumns":[],"associatedMergedColumns":[]}]}]