[{"caption":"Table 1: Human evaluations comparing unCLIP to GLIDE. We compare to both the AR and diffusion prior \nfor unCLIP. Reported figures are 95% confidence intervals of the probability that the unCLIP model specified \nby the row beats GLIDE. Sampling hyperparameters for all models were swept to optimize an automated \nproxy for human photorealism evaluations. \n\nsimilarity, users are additionally prompted with a caption, and must choose which image better matches the \ncaption. In both evaluations, there is a third \"Not sure\" option. For diversity, we propose a new evaluation \nprotocol in which humans are presented with two 4 ? 4 grids of samples and must choose which is more \ndiverse (with a third option, \"Not sure\"). For this evaluation, we produce sample grids using 1,000 captions \nfrom the MS-COCO validation set, and always compare sample grids for the same caption. Before running \nhuman comparisons, we swept over sampling hyperparameters for each model using a CLIP linear probe \ntrained to be a proxy for human photorealism evaluations (Appendix A). These hyperparameters are fixed \nacross all three types of evaluation. \n\n","rows":["AR","Diffusion"],"columns":["Photorealism","Diversity","Caption Similarity"],"mergedAllColumns":[],"numberCells":[{"number":"2.8%","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Diversity"],"associatedMergedColumns":[]},{"number":"3.0%","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Diversity"],"associatedMergedColumns":[]},{"number":"3.0%","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Caption Similarity"],"associatedMergedColumns":[]},{"number":"3.1%","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Photorealism"],"associatedMergedColumns":[]},{"number":"62.6%?","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Diversity"],"associatedMergedColumns":[]},{"number":"45.3%?","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Caption Similarity"],"associatedMergedColumns":[]},{"number":"47.1%?","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Photorealism"],"associatedMergedColumns":[]},{"number":"48.9%?","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Photorealism"],"associatedMergedColumns":[]},{"number":"3.1%","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Photorealism"],"associatedMergedColumns":[]},{"number":"41.1%?","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Caption Similarity"],"associatedMergedColumns":[]},{"number":"3.0%","isBolded":false,"associatedRows":["AR"],"associatedColumns":["Caption Similarity"],"associatedMergedColumns":[]},{"number":"70.5%?","isBolded":false,"associatedRows":["Diffusion"],"associatedColumns":["Diversity"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison of FID on MS-COCO 256 ? 256. We use guidance scale 1.25 for the decoder for both \nthe AR and diffusion prior, and achieve the best results using the diffusion prior. \n\n","rows":["DF - GAN ( Tao et al . , 2020 )","unCLIP ( Diffusion prior )","Make - A - Scene ( Gafni et al . , 2022 )","AttnGAN ( Xu et al . , 2017 )","LAFITE ( Zhou et al . , 2021 )","DM - GAN ( Zhu et al . , 2019 )","XMC - GAN ( Zhang et al . , 2021 )","unCLIP ( AR prior )","DM - GAN + CL ( Ye et al . , 2021 )","GLIDE ( Nichol et al . , 2021 )"],"columns":["FID","Zero - shot FID ( filt )","Zero - shot FID","? 28"],"mergedAllColumns":[],"numberCells":[{"number":"20.79","isBolded":false,"associatedRows":["DM - GAN + CL ( Ye et al . , 2021 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"10.87","isBolded":true,"associatedRows":["unCLIP ( Diffusion prior )"],"associatedColumns":["Zero - shot FID ( filt )","? 28"],"associatedMergedColumns":[]},{"number":"12.24","isBolded":false,"associatedRows":["GLIDE ( Nichol et al . , 2021 )"],"associatedColumns":["Zero - shot FID","? 28"],"associatedMergedColumns":[]},{"number":"11.84","isBolded":false,"associatedRows":["Make - A - Scene ( Gafni et al . , 2022 )"],"associatedColumns":["Zero - shot FID ( filt )","? 28"],"associatedMergedColumns":[]},{"number":"9.33","isBolded":false,"associatedRows":["XMC - GAN ( Zhang et al . , 2021 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"8.12","isBolded":false,"associatedRows":["LAFITE ( Zhou et al . , 2021 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"26.94","isBolded":false,"associatedRows":["LAFITE ( Zhou et al . , 2021 )"],"associatedColumns":["Zero - shot FID","? 28"],"associatedMergedColumns":[]},{"number":"11.08","isBolded":false,"associatedRows":["unCLIP ( AR prior )"],"associatedColumns":["Zero - shot FID ( filt )","? 28"],"associatedMergedColumns":[]},{"number":"7.55","isBolded":true,"associatedRows":["Make - A - Scene ( Gafni et al . , 2022 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"12.89","isBolded":false,"associatedRows":["GLIDE ( Nichol et al . , 2021 )"],"associatedColumns":["Zero - shot FID ( filt )","? 28"],"associatedMergedColumns":[]},{"number":"10.39","isBolded":true,"associatedRows":["unCLIP ( Diffusion prior )"],"associatedColumns":["Zero - shot FID","? 28"],"associatedMergedColumns":[]},{"number":"10.63","isBolded":false,"associatedRows":["unCLIP ( AR prior )"],"associatedColumns":["Zero - shot FID","? 28"],"associatedMergedColumns":[]},{"number":"32.64","isBolded":false,"associatedRows":["DM - GAN ( Zhu et al . , 2019 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"21.42","isBolded":false,"associatedRows":["DF - GAN ( Tao et al . , 2020 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]},{"number":"35.49","isBolded":false,"associatedRows":["AttnGAN ( Xu et al . , 2017 )"],"associatedColumns":["FID"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Hyperparameters for the models \n\n24 \n\n","rows":["Text encoder heads","Model size","250","-","Latent decoder depth","Text encoder depth","1B","Adam ?2","Diffusion prior","Latent decoder heads","Heads channels","Sampling steps","AR prior","Crop fraction","EMA decay","Dropout"],"columns":["4096","1000","32 , 16 , 8","800K","DDIM [ 47 ]","192","600K","4 . 0e - 2","1 . 6e - 4","1 , 1 , 2 , 2 , 4 , 4","256","2048","512","1 , 2 , 3 , 4","1 . 0e - 10","1 . 2e - 4","6 . 0e - 2","linear","1 . 1e - 4","-","300M","700M","384","320","2","3","1664","1024","1 . 0e - 4","cosine","1 . 0e - 6","2 to match the empirical variance of RGB pixel values of ImageNet images","learned [ 34 ]","1 . 0e - 8","analytic [ 2 ]","1M"],"mergedAllColumns":["scaled to [ ? 1 , 1 ] .","-","256 ? 1024"],"numberCells":[{"number":"0.96","isBolded":false,"associatedRows":["Adam ?2","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","analytic [ 2 ]","700M","-","-","-","-","-","256","2048","-","-","-","-","-","-","6 . 0e - 2","4096","600K","1 . 1e - 4"],"associatedMergedColumns":["-"]},{"number":"64","isBolded":false,"associatedRows":["Heads channels","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4"],"associatedMergedColumns":["256 ? 1024"]},{"number":"24","isBolded":false,"associatedRows":["Text encoder depth","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4","-","32 , 16 , 8","256","2048"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.91","isBolded":false,"associatedRows":["Adam ?2"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048","-","-","384","1664","-","-","4 . 0e - 2","4096","1M","1 . 6e - 4"],"associatedMergedColumns":["-"]},{"number":"0.25","isBolded":false,"associatedRows":["Crop fraction","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","linear","DDIM [ 47 ]"],"associatedMergedColumns":["256 ? 1024"]},{"number":"32","isBolded":false,"associatedRows":["Text encoder heads"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.999","isBolded":false,"associatedRows":["Adam ?2","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","linear","DDIM [ 47 ]","300M","192","2","1 , 1 , 2 , 2 , 4 , 4","-","-","-","-","-","-","-","-","-","-","-","512","1M","1 . 0e - 4"],"associatedMergedColumns":["-"]},{"number":"0.9999","isBolded":false,"associatedRows":["EMA decay","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","analytic [ 2 ]","700M","-","-","-","-","-","256","2048","-","-","-","-","-","-","6 . 0e - 2","4096","600K","1 . 1e - 4","1 . 0e - 6"],"associatedMergedColumns":["-"]},{"number":"64?256","isBolded":true,"associatedRows":["Sampling steps","AR prior","Diffusion prior","250"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images"],"associatedMergedColumns":["scaled to [ ? 1 , 1 ] ."]},{"number":"0.999","isBolded":false,"associatedRows":["Adam ?2","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4","-","32 , 16 , 8","256","2048","-","-","-","-","-","-","-","2048","800K","1 . 2e - 4"],"associatedMergedColumns":["-"]},{"number":"27","isBolded":false,"associatedRows":["Sampling steps","-","Diffusion prior","250"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.999","isBolded":false,"associatedRows":["EMA decay"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048","-","-","384","1664","-","-","4 . 0e - 2","4096","1M","1 . 6e - 4","1 . 0e - 10"],"associatedMergedColumns":["-"]},{"number":"26","isBolded":false,"associatedRows":["Latent decoder heads"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048","-","-","384","1664","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"64","isBolded":true,"associatedRows":["Sampling steps","AR prior","Diffusion prior"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images"],"associatedMergedColumns":["scaled to [ ? 1 , 1 ] ."]},{"number":"0.9999","isBolded":false,"associatedRows":["EMA decay","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","DDIM [ 47 ]","700M","320","3","1 , 2 , 3 , 4","-","-","-","-","-","-","-","-","-","-","-","1024","1M","1 . 2e - 4","1 . 0e - 8"],"associatedMergedColumns":["-"]},{"number":"15","isBolded":false,"associatedRows":["Sampling steps","-","Diffusion prior","250"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","linear"],"associatedMergedColumns":["256 ? 1024"]},{"number":"24","isBolded":false,"associatedRows":["Latent decoder depth"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048","-","-","384","1664"],"associatedMergedColumns":["256 ? 1024"]},{"number":"32","isBolded":false,"associatedRows":["Text encoder heads","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","analytic [ 2 ]","700M","-","-","-","-","-","256","2048","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.9999","isBolded":false,"associatedRows":["EMA decay","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4","-","32 , 16 , 8","256","2048","-","-","-","-","-","-","-","2048","800K","1 . 2e - 4","1 . 0e - 8"],"associatedMergedColumns":["-"]},{"number":"24","isBolded":false,"associatedRows":["Text encoder depth","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","analytic [ 2 ]","700M","-","-","-","-","-","256","2048"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4","-","32 , 16 , 8","256","2048","-","-","-","-","-","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.1","isBolded":false,"associatedRows":["Dropout","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","DDIM [ 47 ]","700M","320","3","1 , 2 , 3 , 4","-","-","-","-","-","-","-","-","-","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"64","isBolded":false,"associatedRows":["Sampling steps","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.9999","isBolded":false,"associatedRows":["EMA decay","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","linear","DDIM [ 47 ]","300M","192","2","1 , 1 , 2 , 2 , 4 , 4","-","-","-","-","-","-","-","-","-","-","-","512","1M","1 . 0e - 4","1 . 0e - 8"],"associatedMergedColumns":["-"]},{"number":"32","isBolded":false,"associatedRows":["Text encoder heads","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]","700M","512","3","1 , 2 , 3 , 4","-","32 , 16 , 8","256","2048","-"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.999","isBolded":false,"associatedRows":["Adam ?2","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","DDIM [ 47 ]","700M","320","3","1 , 2 , 3 , 4","-","-","-","-","-","-","-","-","-","-","-","1024","1M","1 . 2e - 4"],"associatedMergedColumns":["-"]},{"number":"3.5B","isBolded":false,"associatedRows":["Model size","1B","1B"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","learned [ 34 ]"],"associatedMergedColumns":["256 ? 1024"]},{"number":"0.25","isBolded":false,"associatedRows":["Crop fraction","-","-","-"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","1000","cosine","DDIM [ 47 ]"],"associatedMergedColumns":["256 ? 1024"]},{"number":"24","isBolded":false,"associatedRows":["Text encoder depth"],"associatedColumns":["2 to match the empirical variance of RGB pixel values of ImageNet images","-","-","-","700M","-","-","-","-","-","256","2048"],"associatedMergedColumns":["256 ? 1024"]}]}]