[{"caption":"Table 1. State-of-the-art comparison. We report the results of NetVLAD++ for action spotting (Average-mAP %) on SoccerNet-v2 ","rows":["AudioVid [ 41 ]","NetVLAD [ 19 ]","CALF [ 7 ]","NetVLAD++","MaxPool [ 19 ]"],"columns":["Ball","Foul","visible","tar .","Yel . ?Red","Kick - off","unshown","Clearance","Offside","off","Penalty","out","Red","Goal","Corner","Substitution","Dir .","Ind .","Yellow","Throw - in","Shots","free - kick","card","on"],"mergedAllColumns":[],"numberCells":[{"number":"0.7","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Yel . ?Red"],"associatedMergedColumns":[]},{"number":"35.2","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["card","Yellow"],"associatedMergedColumns":[]},{"number":"51.6","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Clearance"],"associatedMergedColumns":[]},{"number":"2.6","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Offside"],"associatedMergedColumns":[]},{"number":"45.7","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Substitution","Kick - off"],"associatedMergedColumns":[]},{"number":"70.3","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Clearance","out","Ball"],"associatedMergedColumns":[]},{"number":"0.9","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["card","Red"],"associatedMergedColumns":[]},{"number":"3.7","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Yel . ?Red"],"associatedMergedColumns":[]},{"number":"11.8","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["card","Yellow"],"associatedMergedColumns":[]},{"number":"25.7","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","Offside"],"associatedMergedColumns":[]},{"number":"47.4","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","out","Ball"],"associatedMergedColumns":[]},{"number":"59.4","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"23.3","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","unshown"],"associatedMergedColumns":[]},{"number":"46.7","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","Dir ."],"associatedMergedColumns":[]},{"number":"30.6","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Yel . ?Red","Penalty"],"associatedMergedColumns":[]},{"number":"23.3","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","unshown"],"associatedMergedColumns":[]},{"number":"14.0","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["tar .","on","Shots"],"associatedMergedColumns":[]},{"number":"39.3","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Substitution","Offside"],"associatedMergedColumns":[]},{"number":"6.2","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Yel . ?Red","Penalty"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":true,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Yel . ?Red","Goal"],"associatedMergedColumns":[]},{"number":"41.0","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["tar .","off","Shots"],"associatedMergedColumns":[]},{"number":"21.5","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"33.6","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","Dir ."],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Yel . ?Red"],"associatedMergedColumns":[]},{"number":"53.0","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Clearance","Foul"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Substitution","Corner"],"associatedMergedColumns":[]},{"number":"22.7","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","Ind ."],"associatedMergedColumns":[]},{"number":"41.7","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["card","Yellow"],"associatedMergedColumns":[]},{"number":"16.7","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","Ind ."],"associatedMergedColumns":[]},{"number":"69.0","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Clearance","Throw - in"],"associatedMergedColumns":[]},{"number":"39.9","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["card","Red"],"associatedMergedColumns":[]},{"number":"62.1","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Substitution","Kick - off"],"associatedMergedColumns":[]},{"number":"40.7","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"21.4","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["tar .","off","Shots"],"associatedMergedColumns":[]},{"number":"42.1","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"13.1","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["tar .","off","Shots"],"associatedMergedColumns":[]},{"number":"71.8","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Substitution","Corner"],"associatedMergedColumns":[]},{"number":"55.1","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Substitution","Corner"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Clearance","Throw - in"],"associatedMergedColumns":[]},{"number":"32.3","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Yel . ?Red","Penalty"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","Ind ."],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Yel . ?Red","Goal"],"associatedMergedColumns":[]},{"number":"79.3","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Yel . ?Red","Penalty"],"associatedMergedColumns":[]},{"number":"32.7","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Clearance"],"associatedMergedColumns":[]},{"number":"21.3","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["tar .","on","Shots"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Substitution"],"associatedMergedColumns":[]},{"number":"27.3","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["tar .","off","Shots"],"associatedMergedColumns":[]},{"number":"44.4","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["free - kick","Ind ."],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Clearance","Foul"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["card","Red"],"associatedMergedColumns":[]},{"number":"54.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Substitution"],"associatedMergedColumns":[]},{"number":"42.4","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","Throw - in"],"associatedMergedColumns":[]},{"number":"52.1","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Yel . ?Red","Penalty"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["card","Red"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","unshown"],"associatedMergedColumns":[]},{"number":"24.3","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","Offside"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Yel . ?Red"],"associatedMergedColumns":[]},{"number":"4.0","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["card","Red"],"associatedMergedColumns":[]},{"number":"18.6","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["tar .","on","Shots"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Clearance","Throw - in"],"associatedMergedColumns":[]},{"number":"56.7","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["card","Yellow"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Substitution","Corner"],"associatedMergedColumns":[]},{"number":"24.2","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Goal"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","Offside"],"associatedMergedColumns":[]},{"number":"54.3","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","out","Ball"],"associatedMergedColumns":[]},{"number":"71.6","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Yel . ?Red","Goal"],"associatedMergedColumns":[]},{"number":"39.3","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["tar .","on","Shots"],"associatedMergedColumns":[]},{"number":"33.2","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["card","Yellow"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Clearance","Foul"],"associatedMergedColumns":[]},{"number":"26.8","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Foul"],"associatedMergedColumns":[]},{"number":"34.3","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Clearance"],"associatedMergedColumns":[]},{"number":"19.7","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["tar .","off","Shots"],"associatedMergedColumns":[]},{"number":"55.5","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Clearance","Foul"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Substitution","Corner"],"associatedMergedColumns":[]},{"number":"30.3","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Substitution","Kick - off"],"associatedMergedColumns":[]},{"number":"37.2","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Substitution","Kick - off"],"associatedMergedColumns":[]},{"number":"54.9","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Yel . ?Red","Goal"],"associatedMergedColumns":[]},{"number":"26.6","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["tar .","on","Shots"],"associatedMergedColumns":[]},{"number":"34.7","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Throw - in"],"associatedMergedColumns":[]},{"number":"52.9","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Substitution","Kick - off"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["free - kick","Dir ."],"associatedMergedColumns":[]},{"number":"57.0","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Clearance"],"associatedMergedColumns":[]},{"number":"43.0","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","unshown"],"associatedMergedColumns":[]},{"number":"63.9","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","out","Ball"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["Yel . ?Red"],"associatedMergedColumns":[]},{"number":"43.5","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["free - kick","Dir ."],"associatedMergedColumns":[]},{"number":"53.4","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"68.7","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["Substitution"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Ind ."],"associatedMergedColumns":[]},{"number":"31.4","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["free - kick","visible"],"associatedMergedColumns":[]},{"number":"46.7","isBolded":false,"associatedRows":["AudioVid [ 41 ]"],"associatedColumns":["Clearance"],"associatedMergedColumns":[]},{"number":"47.3","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["Substitution"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["free - kick","unshown"],"associatedMergedColumns":[]},{"number":"38.7","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","out","Ball"],"associatedMergedColumns":[]},{"number":"13.5","isBolded":false,"associatedRows":["MaxPool [ 19 ]"],"associatedColumns":["free - kick","Dir ."],"associatedMergedColumns":[]},{"number":"51.7","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["Substitution"],"associatedMergedColumns":[]}]},{"caption":"Table 2. Ablation Studies. (Top) Main Contributions: We highlight the improvement of each component of our novel [NetVLAD++] \nmodule and architecture on top of [NetVLAD], with optimal NMS parameters [NMS*] and optimal window size T [NMS*/T*]. We \nhighlight the contribution of the learnable linear layer [w/o lin.layer] and the temporally-aware feature pooling [w/o tmp-aware]. All \nperformances are averaged over 5 runs. (Bottom) Temporal context: We report the Average-mAP for temporal window size T ranging \nfrom 5 to 30, averaged over 5 runs. Best performances per class are reported in bold. T \u003d 15s appears to be optimal. \nSoccerNet-v2 \n\nvisible \nunshown \n\nBall out \nThrow-in \n\nFoul \nInd. free-kick \nClearance \n\nShots on tar. \nShots off tar. \nCorner \nSubstitution \nKick-off \nYellow card \nOffside \nDir. free-kick \nGoal \nPenalty \nYel.?Red \n\nRed card \n\nAblation \nMain Contributions \n\nNetVLAD \n31.4 34.2 23.5 46.9 41.2 31.3 17.4 34.2 18.5 19.1 55.6 50.9 46.7 31.4 17.8 34.2 54.5 33.9 0.0 0.0 \n\n+ NMS* \n47.1 52.3 34.8 60.2 57.5 52.8 38.8 54.5 36.2 36.0 72.4 66.7 63.4 49.6 33.0 50.6 66.3 55.0 2.4 4.5 \n\n+ NMS*/T* \n48.4 54.2 32.5 62.8 60.0 53.8 38.8 56.2 36.6 37.7 76.7 67.2 62.5 51.8 30.8 51.2 67.0 60.2 3.8 5.2 \n\nNetVLAD++ \n53.3 59.1 35.1 70.2 68.9 64.1 45.2 56.6 38.2 40.4 79.8 68.9 61.1 56.1 38.0 58.2 71.6 79.1 5.5 3.5 \n\nw/o tmp-aware 50.2 56.6 32.2 64.2 61.3 54.4 39.4 56.6 37.3 39.6 77.6 66.1 60.7 56.4 32.7 55.6 66.4 64.3 4.5 16.9 \n\nw/o lin.layer \n50.7 55.8 37.3 68.2 65.3 62.4 43.4 56.0 37.1 38.3 78.9 70.3 59.6 50.0 35.3 55.2 70.2 67.7 1.7 1.5 \n\nWindow Size \nTemporal context \n\nT \u003d 05s \n46.0 52.8 28.6 66.9 68.6 46.5 36.1 50.2 34.9 41.1 81.2 58.9 54.7 51.7 9.5 58.6 45.2 64.3 12.5 1.2 \n\nT \u003d 10s \n50.7 57.1 34.5 70.2 70.1 61.5 42.8 53.7 37.3 39.3 81.9 66.6 59.1 55.1 26.8 58.3 63.1 68.6 5.8 1.7 \n\nT \u003d 15s \n53.3 59.1 35.1 70.2 68.9 64.1 45.2 56.6 38.2 40.4 79.8 68.9 61.1 56.1 38.0 58.2 71.6 79.1 5.5 3.5 \n\nT \u003d 20s \n53.0 58.3 35.1 67.5 66.1 62.2 44.5 56.4 38.5 39.5 77.2 68.9 59.1 54.8 39.0 57.0 73.4 78.6 10.3 7.1 \n\nT \u003d 25s \n50.7 55.6 34.9 64.2 62.8 59.4 45.0 55.4 38.9 37.3 71.0 65.2 59.6 54.5 39.1 54.0 70.9 63.7 16.5 4.6 \n\nT \u003d 30s \n49.4 53.9 35.1 60.1 57.5 54.7 43.2 51.6 38.3 35.9 65.7 62.1 59.3 55.2 39.4 53.8 70.8 75.5 9.4 7.5 \n\n10 \n20 \n30 \n40 \n50 \n60 \n70 \n80 \n90 \nSize of the NMS window (s) \n\n25 \n\n30 \n\n35 \n\n40 \n\n45 \n\n50 \n\nAverage-mAP (Action Spotting) \n\n","rows":["T \u003d 25s","w / o tmp - aware","T \u003d 15s","T \u003d 10s","T \u003d 30s","NetVLAD++","T \u003d 20s","NetVLAD","w / o lin . layer","+ NMS * / T *","T \u003d 05s","+ NMS *"],"columns":["Ball","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Clearance","Offside","Temporal context","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","out","SoccerNet - v2","Goal","Corner","Substitution","Dir .","Shots","Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","Main Contributions","on","Foul","visible","tar .","Yel . ?Red","unshown","Ablation","off","Penalty","Red","Ind .","Yellow","Window Size","Throw - in","free - kick","card"],"mergedAllColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."],"numberCells":[{"number":"57.5","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"40.4","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.4","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"79.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.2","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"36.1","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.2","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.1","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.7","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"77.6","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"67.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"79.8","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.2","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.6","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.0","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.5","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"51.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.3","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.3","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.2","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"73.4","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.2","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"60.0","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.3","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.7","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"32.7","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"47.1","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"9.5","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"41.2","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.3","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.8","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"52.3","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.3","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.3","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.0","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.9","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.6","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"78.6","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.0","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"60.2","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.9","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.2","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.9","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.9","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.4","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.1","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"23.5","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"26.8","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.3","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.9","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.6","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.6","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"61.5","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"1.7","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"5.8","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.6","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.8","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"71.0","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"1.5","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.2","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"63.4","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"16.9","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.6","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.3","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"36.0","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.5","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"4.6","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"45.0","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"46.0","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.3","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"79.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.8","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.2","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"79.8","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"44.5","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.1","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"36.2","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.8","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.9","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"4.5","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"46.5","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.7","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.2","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"45.2","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.5","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"46.7","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"2.4","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"41.1","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"75.5","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.2","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.5","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.1","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.1","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"3.5","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.7","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"60.7","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.6","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"33.0","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"57.5","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.9","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"71.6","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"48.4","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.9","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.4","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.8","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.0","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"36.6","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"12.5","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.7","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"30.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.2","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"1.2","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.5","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.8","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.2","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"49.6","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"9.4","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"43.4","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.6","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"4.5","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"33.9","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.5","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"63.1","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.0","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"65.7","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.2","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.7","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.7","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.1","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.3","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"65.3","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.6","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"71.6","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"3.5","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"35.1","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.1","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.2","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"67.5","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"52.8","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"0.0","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"67.7","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"7.5","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"5.5","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"76.7","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.6","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.2","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"63.7","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"49.4","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"5.5","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"31.3","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"17.8","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"45.2","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"42.8","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"57.1","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"46.9","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"31.4","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.0","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.9","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"65.2","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"1.7","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.3","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"16.5","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"62.1","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"77.2","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"50.2","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.6","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"61.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.9","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"40.4","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.4","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"70.8","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.4","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"72.4","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"54.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.4","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"51.6","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.2","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.4","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"60.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"32.5","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"56.6","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.3","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"28.6","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.3","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.9","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"37.3","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"51.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.6","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.9","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"81.9","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"61.1","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"61.3","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"0.0","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"31.4","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"67.0","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"53.3","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","SoccerNet - v2","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.9","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"10.3","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"52.8","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Foul","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"3.8","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Yel . ?Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.1","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Throw - in","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"81.2","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"78.9","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Corner","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"45.2","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"64.3","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"34.5","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"51.7","isBolded":false,"associatedRows":["T \u003d 05s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Yellow","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"43.2","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"57.0","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Dir .","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.2","isBolded":false,"associatedRows":["w / o lin . layer"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"32.2","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","unshown","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"60.1","isBolded":false,"associatedRows":["T \u003d 30s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","out","Ball","Main Contributions","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"17.4","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","free - kick","Ind .","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.4","isBolded":false,"associatedRows":["w / o tmp - aware"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Goal","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.6","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"19.1","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","off","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.1","isBolded":false,"associatedRows":["NetVLAD++"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.6","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Penalty","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"58.3","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","visible","Ablation","Window Size"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"7.1","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"5.2","isBolded":false,"associatedRows":["+ NMS * / T *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","card","Red","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"59.1","isBolded":false,"associatedRows":["T \u003d 10s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Kick - off","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"18.5","isBolded":false,"associatedRows":["NetVLAD"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"68.9","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"66.7","isBolded":false,"associatedRows":["+ NMS *"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Substitution","Main Contributions"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.2","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","tar .","on","Shots","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"39.0","isBolded":false,"associatedRows":["T \u003d 20s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"55.4","isBolded":false,"associatedRows":["T \u003d 25s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Clearance","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]},{"number":"38.0","isBolded":false,"associatedRows":["T \u003d 15s"],"associatedColumns":["Table 2 . Ablation Studies . ( Top ) Main Contributions : We highlight the improvement of each component of our novel [ NetVLAD++ ]","module and architecture on top of [ NetVLAD ] , with optimal NMS parameters [ NMS * ] and optimal window size T [ NMS * / T * ] .","highlight the contribution of the learnable linear layer [ w / o lin . layer ] and the temporally - aware feature pooling [ w / o tmp - aware ] .","Offside","Main Contributions","Temporal context"],"associatedMergedColumns":["from 5 to 30 , averaged over 5 runs . Best performances per class are reported in bold . T \u003d 15s appears to be optimal ."]}]},{"caption":"Table 3. More video encoder: Spotting performance using \nI3D, C3D and ResNET-152 video encoders, averaged over 5 runs \n(means ? std). NetVLAD++ with linear layer for dimensionality \nreduction results in best performances for all encoders. \n\n","rows":["C3D","I3D","ResNet"],"columns":["( PCA )","( lin layer )","NetVLAD++","NetVLAD"],"mergedAllColumns":[],"numberCells":[{"number":"0.1","isBolded":false,"associatedRows":["I3D"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":true,"associatedRows":["I3D"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]},{"number":"46.1?","isBolded":false,"associatedRows":["C3D"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"50.7?","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"48.4?","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"38.1?","isBolded":false,"associatedRows":["I3D"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"34.9?","isBolded":false,"associatedRows":["I3D"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"48.6?","isBolded":true,"associatedRows":["C3D"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"41.5?","isBolded":true,"associatedRows":["I3D"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["C3D"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"53.3?","isBolded":true,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["I3D"],"associatedColumns":["NetVLAD","( PCA )"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["C3D"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"47.2?","isBolded":false,"associatedRows":["C3D"],"associatedColumns":["NetVLAD++","( PCA )"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":true,"associatedRows":["ResNet"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":true,"associatedRows":["C3D"],"associatedColumns":["NetVLAD++","( lin layer )"],"associatedMergedColumns":[]}]},{"caption":"Table 4. More pooling modules. Spotting performances using \nMax, Avg and NetRVLAD pooling modules. All temporally-\naware pooling method outperforms the original pooling. \n\n","rows":["MaxPooling ( PCA )","NetVLAD ( lin . layer )","AvgPooling ( PCA )","NetRVLAD ( lin . layer )"],"columns":["Original","Tmp . - Aware"],"mergedAllColumns":[],"numberCells":[{"number":"32.5?","isBolded":true,"associatedRows":["AvgPooling ( PCA )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["NetVLAD ( lin . layer )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["NetRVLAD ( lin . layer )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"40.6?","isBolded":false,"associatedRows":["AvgPooling ( PCA )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"50.2?","isBolded":true,"associatedRows":["NetVLAD ( lin . layer )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":true,"associatedRows":["NetRVLAD ( lin . layer )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"53.3?","isBolded":false,"associatedRows":["NetVLAD ( lin . layer )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"23.7?","isBolded":true,"associatedRows":["MaxPooling ( PCA )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":true,"associatedRows":["AvgPooling ( PCA )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["MaxPooling ( PCA )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"48.0?","isBolded":true,"associatedRows":["NetRVLAD ( lin . layer )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":true,"associatedRows":["MaxPooling ( PCA )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["AvgPooling ( PCA )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":true,"associatedRows":["NetVLAD ( lin . layer )"],"associatedColumns":["Original"],"associatedMergedColumns":[]},{"number":"31.6?","isBolded":false,"associatedRows":["MaxPooling ( PCA )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]},{"number":"50.9?","isBolded":false,"associatedRows":["NetRVLAD ( lin . layer )"],"associatedColumns":["Tmp . - Aware"],"associatedMergedColumns":[]}]},{"caption":"Table 5. SoccerNet-v2 Challenge. Our NetVLAD++ approach \nreach best performances on the SoccerNet \n\nMethod \nAvg-mAP Visible Unshown \n\nNetVLAD [19] \n30.74 \n32.99 \n23.27 \n\nCALF [7] \n42.22 \n43.51 \n37.91 \n\nRMS-Net [37] \n49.66 \n53.11 \n38.92 \n\nNetVLAD++ \n52.54 \n57.12 \n46.15 \n\n","rows":["RMS - Net [ 37 ]","NetVLAD [ 19 ]","CALF [ 7 ]","NetVLAD++"],"columns":["Unshown","SoccerNet - v2 Challenge . Our NetVLAD++ approach","Visible","Avg - mAP"],"mergedAllColumns":["reach best performances on the SoccerNet"],"numberCells":[{"number":"37.91","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Unshown"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"38.92","isBolded":false,"associatedRows":["RMS - Net [ 37 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Unshown"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"52.54","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Avg - mAP"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"53.11","isBolded":false,"associatedRows":["RMS - Net [ 37 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Visible"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"46.15","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Unshown"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"23.27","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Unshown"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"42.22","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Avg - mAP"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"43.51","isBolded":false,"associatedRows":["CALF [ 7 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Visible"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"32.99","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Visible"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"49.66","isBolded":false,"associatedRows":["RMS - Net [ 37 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Avg - mAP"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"30.74","isBolded":false,"associatedRows":["NetVLAD [ 19 ]"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Avg - mAP"],"associatedMergedColumns":["reach best performances on the SoccerNet"]},{"number":"57.12","isBolded":true,"associatedRows":["NetVLAD++"],"associatedColumns":["SoccerNet - v2 Challenge . Our NetVLAD++ approach","Visible"],"associatedMergedColumns":["reach best performances on the SoccerNet"]}]}]