[{"caption":"Table 1: Statistics of the HVU training set for different categories. The category \nwith the highest number of labels and annotations is the object category. \n\n","rows":["1678","69","#Labels"],"columns":["Concept","Action","Attribute","Scene"],"mergedAllColumns":[],"numberCells":[{"number":"117","isBolded":false,"associatedRows":["#Labels","1678","69"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"291","isBolded":false,"associatedRows":["#Labels","1678","69"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"248","isBolded":false,"associatedRows":["#Labels"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"739","isBolded":false,"associatedRows":["#Labels","1678"],"associatedColumns":["Action"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison of the HVU dataset with other publicly available video \nrecognition datasets in terms of #labels per category. Note that SOA is not \npublicly available. \n\n","rows":["Kinetics [ 27 ]","EPIC - KITCHEN [ 9 ]","69","SOA [ 36 ]","49","HVU ( Ours )","ActivityNet [ 5 ]","-","AVA [ 23 ]","1678","80","HACS [ 64 ]","UCF101 [ 47 ]","Something - Something [ 22 ]"],"columns":["Concept","Action","108K","Attribute","13K","140K","#Videos","Scene","-","20K","500K","7K","Object","51"],"mergedAllColumns":["\u0027 18"],"numberCells":[{"number":"148","isBolded":false,"associatedRows":["SOA [ 36 ]","49","1678"],"associatedColumns":["Action","51","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"101","isBolded":false,"associatedRows":["UCF101 [ 47 ]","-","-"],"associatedColumns":["Action","51"],"associatedMergedColumns":[]},{"number":"600","isBolded":false,"associatedRows":["Kinetics [ 27 ]","-","-"],"associatedColumns":["Action","51","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"39.6K","isBolded":false,"associatedRows":["EPIC - KITCHEN [ 9 ]","-","1678","-","-","-"],"associatedColumns":["#Videos","7K","13K","20K","108K","140K","500K"],"associatedMergedColumns":["\u0027 18"]},{"number":"291","isBolded":false,"associatedRows":["HVU ( Ours )","49","1678","69","-"],"associatedColumns":["Concept","-","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"174","isBolded":false,"associatedRows":["Something - Something [ 22 ]","-","-"],"associatedColumns":["Action","51","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"739","isBolded":false,"associatedRows":["HVU ( Ours )","49","1678"],"associatedColumns":["Action","51","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"117","isBolded":false,"associatedRows":["HVU ( Ours )","49","1678","69"],"associatedColumns":["Attribute","-","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"200","isBolded":false,"associatedRows":["ActivityNet [ 5 ]","-","-"],"associatedColumns":["Action","51","-"],"associatedMergedColumns":[]},{"number":"149","isBolded":false,"associatedRows":["EPIC - KITCHEN [ 9 ]","-","1678"],"associatedColumns":["Action","51","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"356","isBolded":false,"associatedRows":["SOA [ 36 ]","49"],"associatedColumns":["Object","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"248","isBolded":false,"associatedRows":["HVU ( Ours )"],"associatedColumns":["Scene","-","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"57.6K","isBolded":false,"associatedRows":["AVA [ 23 ]","-","-","80","-","-","-"],"associatedColumns":["#Videos","7K","13K","20K"],"associatedMergedColumns":[]},{"number":"323","isBolded":false,"associatedRows":["EPIC - KITCHEN [ 9 ]","-"],"associatedColumns":["Object","-","-","-","-","-","-"],"associatedMergedColumns":["\u0027 18"]},{"number":"200","isBolded":false,"associatedRows":["HACS [ 64 ]","-","-"],"associatedColumns":["Action","51","-","-","-"],"associatedMergedColumns":["\u0027 18"]}]},{"caption":"Table 3: MAP (%) performance of different architecture on the HVU dataset. \nThe backbone ConvNet for all models is ResNet18. \n\n","rows":["3D - STCNet","3D - ResNet","29","HATNet"],"columns":["Concept","Action","Attribute","Event","Object","Scene","HVU Overall %"],"mergedAllColumns":[],"numberCells":[{"number":"35.9","isBolded":false,"associatedRows":["3D - ResNet"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"35.8","isBolded":false,"associatedRows":["3D - ResNet","29"],"associatedColumns":["HVU Overall %"],"associatedMergedColumns":[]},{"number":"48.2","isBolded":false,"associatedRows":["3D - ResNet"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"26.1","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"55.8","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"29.9","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"51.8","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"50.6","isBolded":false,"associatedRows":["3D - ResNet"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"51.9","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"28.6","isBolded":false,"associatedRows":["3D - ResNet"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"22.7","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"50.3","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"33.6","isBolded":true,"associatedRows":["HATNet"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"36.7","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["HVU Overall %"],"associatedMergedColumns":[]},{"number":"30.1","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"35.8","isBolded":false,"associatedRows":["3D - STCNet"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"22.5","isBolded":false,"associatedRows":["3D - ResNet","29"],"associatedColumns":["Concept"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Multi-task learning performance (mAP (%) comparison of 3D-ResNet18 \nand HATNet, when trained on HVU with all categories in the multi-task pipeline. \nThe backbone ConvNet for all models is ResNet18. \n\n","rows":["3D - ResNet ( Standard )","3D - ResNet ( Multi - Task )","HATNet ( Standard )","29","HATNet ( Multi - Task )"],"columns":["Concept","Overall","Action","Attribute","Event","Object","Scene"],"mergedAllColumns":["37","40"],"numberCells":[{"number":"26.1","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Action"],"associatedMergedColumns":["37"]},{"number":"36.6","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Event"],"associatedMergedColumns":["40"]},{"number":"51.8","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"31.1","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Attribute"],"associatedMergedColumns":["40"]},{"number":"34.2","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"48.9","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Action"],"associatedMergedColumns":["40"]},{"number":"39.8","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Event"],"associatedMergedColumns":["37"]},{"number":"50.6","isBolded":false,"associatedRows":["3D - ResNet ( Standard )"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"35.1","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Object"],"associatedMergedColumns":["37"]},{"number":"38.5","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"22.5","isBolded":false,"associatedRows":["3D - ResNet ( Standard )","29"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"55.8","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"57.2","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Scene"],"associatedMergedColumns":["37"]},{"number":"28.6","isBolded":false,"associatedRows":["3D - ResNet ( Standard )"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"48.2","isBolded":false,"associatedRows":["3D - ResNet ( Standard )"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Overall"],"associatedMergedColumns":["37"]},{"number":"51.7","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Scene"],"associatedMergedColumns":["40"]},{"number":"24.1","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Concept"],"associatedMergedColumns":["40"]},{"number":"35.9","isBolded":false,"associatedRows":["3D - ResNet ( Standard )"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"35.8","isBolded":false,"associatedRows":["3D - ResNet ( Standard )","29"],"associatedColumns":["Overall"],"associatedMergedColumns":[]},{"number":"29.6","isBolded":false,"associatedRows":["3D - ResNet ( Multi - Task )"],"associatedColumns":["Object"],"associatedMergedColumns":["40"]},{"number":"33.6","isBolded":false,"associatedRows":["HATNet ( Standard )"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"34.9","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Attribute"],"associatedMergedColumns":["37"]},{"number":"27.3","isBolded":true,"associatedRows":["HATNet ( Multi - Task )"],"associatedColumns":["Concept"],"associatedMergedColumns":["37"]}]},{"caption":"Table 5: Performance (mAP (%)) comparison of HVU and Kinetics datasets \nfor transfer learning generalization ability when evaluated on different action \nrecognition dataset. The trained model for all of the datasets is 3D-ResNet18. \n\n","rows":["From Scratch","HVU","Kinetics"],"columns":["UCF101","HMDB51","Kinetics"],"mergedAllColumns":["-"],"numberCells":[{"number":"67.8","isBolded":true,"associatedRows":["HVU"],"associatedColumns":["Kinetics"],"associatedMergedColumns":["-"]},{"number":"90.5","isBolded":true,"associatedRows":["HVU"],"associatedColumns":["UCF101"],"associatedMergedColumns":["-"]},{"number":"65.1","isBolded":true,"associatedRows":["HVU"],"associatedColumns":["HMDB51"],"associatedMergedColumns":["-"]},{"number":"65.6","isBolded":false,"associatedRows":["From Scratch"],"associatedColumns":["Kinetics"],"associatedMergedColumns":[]},{"number":"65.2","isBolded":false,"associatedRows":["From Scratch"],"associatedColumns":["UCF101"],"associatedMergedColumns":[]},{"number":"89.8","isBolded":false,"associatedRows":["Kinetics"],"associatedColumns":["UCF101"],"associatedMergedColumns":[]},{"number":"62.1","isBolded":false,"associatedRows":["Kinetics"],"associatedColumns":["HMDB51"],"associatedMergedColumns":[]},{"number":"33.4","isBolded":false,"associatedRows":["From Scratch"],"associatedColumns":["HMDB51"],"associatedMergedColumns":[]}]},{"caption":"Table 6: State-of-the-art performance comparison on UCF101, HMDB51 test sets \nand Kinetics validation set. The results on UCF101 and HMDB51 are average \nmAP over three splits, and for Kinetics(400,600) is Top-1 mAP on validation set. \nFor a fair comparison, here we report the performance of methods which utilize \nonly RGB frames as input. *SlowFast uses multiple branches of 3D-ResNet with \nbigger backbones. \n\n","rows":["ARTNet [ 57 ]","ResNext101","Two Stream ( spatial stream ) [ 46 ]","Sport1M","TSN [ 59 ]","HVU","VGG - M","ResNet18","VGG11","ir - CSN - 101 [ 52 ]","DynamoNet [ 13 ]","ResNet101","HATNet ( 16 frames )","Inception v1","Imagenet","73","Imagenet , Kinetics","R ( 2+1 ) D [ 53 ]","Inception v3","STC - ResNext 101 ( 64 frames ) [ 10 ]","SlowFast 4?16 [ 15 ]","HATNet ( 32 frames )","-","ResNet50","SlowFast 16?8 * [ 15 ]","Kinetics","RGB - I3D [ 6 ]","3D ResNext 101 ( 16 frames ) [ 24 ]","C3D [ 50 ]"],"columns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"mergedAllColumns":["72","-"],"numberCells":[{"number":"93.2","isBolded":false,"associatedRows":["TSN [ 59 ]","Imagenet , Kinetics","Inception v3"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"74.8","isBolded":false,"associatedRows":["RGB - I3D [ 6 ]","Imagenet , Kinetics","Inception v1","73"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"96.8","isBolded":false,"associatedRows":["R ( 2+1 ) D [ 53 ]","Kinetics","ResNet50"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"79.4","isBolded":false,"associatedRows":["HATNet ( 16 frames )","HVU","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"93.5","isBolded":false,"associatedRows":["ARTNet [ 57 ]","Kinetics","ResNet18"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"90.7","isBolded":false,"associatedRows":["3D ResNext 101 ( 16 frames ) [ 24 ]","Kinetics","ResNext101"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"96.9","isBolded":false,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet18"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"51.6","isBolded":false,"associatedRows":["C3D [ 50 ]","Sport1M","VGG11","73"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"72.1","isBolded":false,"associatedRows":["RGB - I3D [ 6 ]","Imagenet , Kinetics","Inception v1","73","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"69.2","isBolded":false,"associatedRows":["ARTNet [ 57 ]","Kinetics","ResNet18","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"77.4","isBolded":false,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet18","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"63.8","isBolded":false,"associatedRows":["3D ResNext 101 ( 16 frames ) [ 24 ]","Kinetics","ResNext101","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"96.5","isBolded":false,"associatedRows":["HATNet ( 16 frames )","HVU","ResNet50"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"76.8","isBolded":false,"associatedRows":["DynamoNet [ 13 ]","Kinetics","ResNet101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"74.5","isBolded":false,"associatedRows":["R ( 2+1 ) D [ 53 ]","Kinetics","ResNet50","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"78.8","isBolded":false,"associatedRows":["SlowFast 4?16 [ 15 ]","Kinetics","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"76.7","isBolded":false,"associatedRows":["ir - CSN - 101 [ 52 ]","Kinetics","ResNet101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"96.8","isBolded":false,"associatedRows":["HATNet ( 32 frames )","Kinetics","ResNet50"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"74.8","isBolded":false,"associatedRows":["HATNet ( 32 frames )","Kinetics","ResNet50","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"95.6","isBolded":false,"associatedRows":["RGB - I3D [ 6 ]","Imagenet , Kinetics","Inception v1"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"81.1","isBolded":false,"associatedRows":["SlowFast 16?8 * [ 15 ]","Kinetics","ResNet101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"76.3","isBolded":false,"associatedRows":["HATNet ( 16 frames )","HVU","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"73.4","isBolded":false,"associatedRows":["HATNet ( 16 frames )","HVU","ResNet50","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"81.6","isBolded":true,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"96.5","isBolded":false,"associatedRows":["STC - ResNext 101 ( 64 frames ) [ 10 ]","Kinetics","ResNext101"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"40.5","isBolded":false,"associatedRows":["Two Stream ( spatial stream ) [ 46 ]","Imagenet","VGG - M","73"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":[]},{"number":"79.3","isBolded":true,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"84.5","isBolded":false,"associatedRows":["RGB - I3D [ 6 ]","Imagenet","Inception v1"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"77.2","isBolded":false,"associatedRows":["HATNet ( 32 frames )","Kinetics","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"74.2","isBolded":false,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet18","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"75.6","isBolded":false,"associatedRows":["SlowFast 4?16 [ 15 ]","Kinetics","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"82.3","isBolded":false,"associatedRows":["C3D [ 50 ]","Sport1M","VGG11"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"97.8","isBolded":true,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet50"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"72.5","isBolded":false,"associatedRows":["TSN [ 59 ]","Imagenet , Kinetics","Inception v3","73","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"49.8","isBolded":false,"associatedRows":["RGB - I3D [ 6 ]","Imagenet","Inception v1","73"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"68.7","isBolded":false,"associatedRows":["STC - ResNext 101 ( 64 frames ) [ 10 ]","Kinetics","ResNext101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"74.5","isBolded":false,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet18","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"65.1","isBolded":false,"associatedRows":["3D ResNext 101 ( 16 frames ) [ 24 ]","Kinetics","ResNext101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"78.9*","isBolded":false,"associatedRows":["SlowFast 16?8 * [ 15 ]","Kinetics","ResNet101","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"67.6","isBolded":false,"associatedRows":["ARTNet [ 57 ]","Kinetics","ResNet18","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"74.9","isBolded":false,"associatedRows":["STC - ResNext 101 ( 64 frames ) [ 10 ]","Kinetics","ResNext101","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["-"]},{"number":"76.5","isBolded":true,"associatedRows":["HATNet ( 32 frames )","HVU","ResNet50","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]},{"number":"80.2","isBolded":false,"associatedRows":["HATNet ( 32 frames )","Kinetics","ResNet50","-","-"],"associatedColumns":["Pre - Trained Dataset CNN Backbone UCF101 HMDB51 Kinetics - 400 Kinetics - 600"],"associatedMergedColumns":["72"]}]},{"caption":"Table 8: Video clustering performance: evaluation based on extracted features \nfrom networks pre-trained on Kinetics and HVU datasets. \n\n","rows":["HVU","HATNet","Kinetics","3D - ResNet50"],"columns":["Clustering Accuracy ( % )"],"mergedAllColumns":[],"numberCells":[{"number":"50.3","isBolded":false,"associatedRows":["3D - ResNet50","Kinetics"],"associatedColumns":["Clustering Accuracy ( % )"],"associatedMergedColumns":[]},{"number":"54.8","isBolded":true,"associatedRows":["HATNet","HVU"],"associatedColumns":["Clustering Accuracy ( % )"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":false,"associatedRows":["3D - ResNet50","HVU"],"associatedColumns":["Clustering Accuracy ( % )"],"associatedMergedColumns":[]}]},{"caption":"Table 1: Statistics of machine generated tags of HVU training set for different \ncategories. The category with the highest number of labels and annotations is \nthe object category. \n\n","rows":["2651","#Labels"],"columns":["Concept","Action","Attribute","Event","Scene"],"mergedAllColumns":[],"numberCells":[{"number":"160","isBolded":false,"associatedRows":["#Labels","2651"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"419","isBolded":false,"associatedRows":["#Labels"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"877","isBolded":false,"associatedRows":["#Labels","2651"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"149","isBolded":false,"associatedRows":["#Labels","2651"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"122","isBolded":false,"associatedRows":["#Labels","2651"],"associatedColumns":["Concept"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Performance comparison between machine generated and human-\nverified tags of HVU. This evaluation shows how human annotation process \nis crucial to have a more efficient dataset. The CNN model which is used for this \nexperiment is 3D-ResNet18. \n\n","rows":["Machine - Generated HVU","Human - Annotation HVU"],"columns":["Concept","Action","Attribute","Event","Object","Scene","HVU Overall %"],"mergedAllColumns":[],"numberCells":[{"number":"46.3","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"31.6","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["HVU Overall %"],"associatedMergedColumns":[]},{"number":"29.2","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"22.4","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"50.1","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Scene"],"associatedMergedColumns":[]},{"number":"31.4","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"25.3","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Attribute"],"associatedMergedColumns":[]},{"number":"46.7","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"35.7","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Event"],"associatedMergedColumns":[]},{"number":"27.9","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Object"],"associatedMergedColumns":[]},{"number":"23.2","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"43.8","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Action"],"associatedMergedColumns":[]},{"number":"20.1","isBolded":false,"associatedRows":["Machine - Generated HVU"],"associatedColumns":["Concept"],"associatedMergedColumns":[]},{"number":"35.4","isBolded":false,"associatedRows":["Human - Annotation HVU"],"associatedColumns":["HVU Overall %"],"associatedMergedColumns":[]}]}]