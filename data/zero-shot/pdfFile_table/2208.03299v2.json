[{"caption":"Table 1: Retriever loss ablation. We compare different loss functions to pre-train the retriever jointly \nwith the language model. We use the prefix MLM task, and the December 2021 Wikipedia dump for both \nthe index and pre-training data. Fine-tuning is performed with query-side fine-tuning and the loss used for \npre-training. Best result is bold, second highest underlined. \n\n","rows":["PDist","No Joint pre - training","2","ADist","Fixed retriever","EMDR","LOOP","Closed - book","-"],"columns":["NQ","64 - shot","Avg .","1024 - shot","WoW","MLM","FEVER"],"mergedAllColumns":[],"numberCells":[{"number":"43.0","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"75.3","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"34.9","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"0.823","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"73.8","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"42.2","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"9.0","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"14.1","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"85.7","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"16.5","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"90.2","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"0.780","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"46.2","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"50.8","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"18.3","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"59.0","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"49.6","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"51.4","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"14.3","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"0.783","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"40.9","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"45.3","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"0.783","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"90.0","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"14.1","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"45.7","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"1.083","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"6.5","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"14.4","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"43.7","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"9.9","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"10.7","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"0.766","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["64 - shot","MLM"],"associatedMergedColumns":[]},{"number":"47.1","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"45.0","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"87.5","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":false,"associatedRows":["PDist"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":false,"associatedRows":["Closed - book"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"41.8","isBolded":false,"associatedRows":["LOOP"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"39.9","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"90.9","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"16.6","isBolded":false,"associatedRows":["No Joint pre - training","-"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"17.2","isBolded":false,"associatedRows":["ADist"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["EMDR","2"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]}]},{"caption":"Table 2: Pretext task ablation. We compare different pretext tasks, used to jointly pre-train our models. \nExamples are randomly sampled from the training set of the KILT version of the dataset. We report the \nexact match on NaturalQuestions, the F1 score on Wizard of Wikipedia and the accuracy on FEVER. \n\n","rows":["Prefix Language Modelling","Title - to - section generation","Masked Language Modelling"],"columns":["NQ","64 - shot","Avg .","1024 - shot","WoW","FEVER"],"mergedAllColumns":[],"numberCells":[{"number":"15.2","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.7","isBolded":true,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"40.1","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"69.7","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"42.4","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.7","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"18.3","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"50.6","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"86.0","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"14.5","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"49.3","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"45.4","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"41.0","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"49.5","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"88.8","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"42.7","isBolded":true,"associatedRows":["Masked Language Modelling"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"64.9","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"84.6","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["Prefix Language Modelling"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"41.1","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"66.1","isBolded":false,"associatedRows":["Title - to - section generation"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Index content ablation. In this table, we report results for models where the content of the index \nwas changed between the pre-training and the fine-tuning. \n\n","rows":["CC","Wiki"],"columns":["NQ","64 - shot","Avg .","1024 - shot","WoW","FEVER"],"mergedAllColumns":[],"numberCells":[{"number":"42.7","isBolded":true,"associatedRows":["Wiki","Wiki"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"18.3","isBolded":false,"associatedRows":["Wiki","Wiki"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"50.6","isBolded":true,"associatedRows":["Wiki","Wiki"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"41.1","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"42.0","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"39.8","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"42.4","isBolded":true,"associatedRows":["Wiki","Wiki"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"18.4","isBolded":true,"associatedRows":["Wiki","CC"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"88.8","isBolded":false,"associatedRows":["Wiki","Wiki"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"38.4","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":false,"associatedRows":["Wiki","Wiki"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"50.4","isBolded":false,"associatedRows":["Wiki","CC"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.8","isBolded":true,"associatedRows":["Wiki","CC"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"41.2","isBolded":false,"associatedRows":["Wiki","CC"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.7","isBolded":false,"associatedRows":["Wiki","Wiki"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"88.1","isBolded":false,"associatedRows":["Wiki","CC"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":true,"associatedRows":["CC","Wiki"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"37.8","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"85.8","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"17.1","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"14.5","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"40.9","isBolded":false,"associatedRows":["Wiki","CC"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"46.9","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"15.3","isBolded":true,"associatedRows":["Wiki","CC"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"32.9","isBolded":false,"associatedRows":["CC","Wiki"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"67.3","isBolded":false,"associatedRows":["Wiki","CC"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"88.9","isBolded":true,"associatedRows":["CC","CC"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["Wiki","Wiki"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"17.3","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"49.4","isBolded":false,"associatedRows":["CC","CC"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]}]},{"caption":"Table 4: Retriever fine-tuning ablation. Here, we compare different strategies to fine-tune the retriever \nin a few-shot setting. \n\n","rows":["Top - 100 re - ranking","Fixed retriever","Query - side fine - tuning","Standard fine - tuning"],"columns":["NQ","64 - shot","Avg .","1024 - shot","WoW","FEVER"],"mergedAllColumns":[],"numberCells":[{"number":"41.1","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"51.7","isBolded":true,"associatedRows":["Standard fine - tuning"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"77.0","isBolded":true,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"89.3","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"48.3","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"45.0","isBolded":true,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"17.7","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"15.0","isBolded":true,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"75.4","isBolded":false,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"14.5","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"45.7","isBolded":true,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.7","isBolded":true,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"88.9","isBolded":false,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["64 - shot","WoW"],"associatedMergedColumns":[]},{"number":"18.7","isBolded":true,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"72.0","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"89.7","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"44.3","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["Fixed retriever"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"51.6","isBolded":false,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["1024 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"17.9","isBolded":false,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"18.4","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["1024 - shot","WoW"],"associatedMergedColumns":[]},{"number":"73.2","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["64 - shot","FEVER"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["64 - shot","Avg ."],"associatedMergedColumns":[]},{"number":"44.2","isBolded":false,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["64 - shot","NQ"],"associatedMergedColumns":[]},{"number":"47.0","isBolded":false,"associatedRows":["Standard fine - tuning"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"47.1","isBolded":true,"associatedRows":["Top - 100 re - ranking"],"associatedColumns":["1024 - shot","NQ"],"associatedMergedColumns":[]},{"number":"90.2","isBolded":true,"associatedRows":["Query - side fine - tuning"],"associatedColumns":["1024 - shot","FEVER"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Performance on MMLU as a function of model size. \n\n","rows":["Atlas","Closed - book T5","?"],"columns":["5 - shot","11B","770M","5 - shot ( multi - task )","Full / Transfer","3B"],"mergedAllColumns":[],"numberCells":[{"number":"42.1","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"43.5","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"54.0","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"65.8","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"42.4","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot","11B"],"associatedMergedColumns":[]},{"number":"+11.8","isBolded":false,"associatedRows":["?"],"associatedColumns":["Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"29.2","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot","770M"],"associatedMergedColumns":[]},{"number":"50.4","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"+15.6","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"42.3","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot","3B"],"associatedMergedColumns":[]},{"number":"35.7","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot","3B"],"associatedMergedColumns":[]},{"number":"+9.5","isBolded":false,"associatedRows":["?"],"associatedColumns":["Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"+8.7","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"+9.8","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot","770M"],"associatedMergedColumns":[]},{"number":"+12.9","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"+6.6","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot","3B"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot","770M"],"associatedMergedColumns":[]},{"number":"56.3","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"+13.9","isBolded":false,"associatedRows":["?"],"associatedColumns":["Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"36.1","isBolded":false,"associatedRows":["Closed - book T5"],"associatedColumns":["5 - shot","11B"],"associatedMergedColumns":[]},{"number":"+7.3","isBolded":false,"associatedRows":["?"],"associatedColumns":["5 - shot","11B"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Standard vs de-biased inference for MMLU These results are reported for Atlas-11B, using \ncyclic permutations for de-biasing, which increases inference costs by a factor of 4?. \n\n","rows":["Standard Inference","De - biased Inference"],"columns":["5 - shot","Zero - shot","5 - shot ( multi - task )","Full / Transfer"],"mergedAllColumns":[],"numberCells":[{"number":"65.8","isBolded":false,"associatedRows":["Standard Inference"],"associatedColumns":["Full / Transfer"],"associatedMergedColumns":[]},{"number":"56.6","isBolded":false,"associatedRows":["De - biased Inference"],"associatedColumns":["5 - shot ( multi - task )"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":false,"associatedRows":["Standard Inference"],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["Standard Inference"],"associatedColumns":["5 - shot ( multi - task )"],"associatedMergedColumns":[]},{"number":"47.9","isBolded":false,"associatedRows":["De - biased Inference"],"associatedColumns":["5 - shot"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["Standard Inference"],"associatedColumns":["5 - shot"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":false,"associatedRows":["De - biased Inference"],"associatedColumns":["Full / Transfer"],"associatedMergedColumns":[]},{"number":"47.1","isBolded":false,"associatedRows":["De - biased Inference"],"associatedColumns":["Zero - shot"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Comparison to state-of-the-art on MMLU.  *  For the 5-shot setting, Atlas uses fine-tuning, \nwhile previous works use in-context learning. The Atlas model uses de-biased inference. Train FLOPS refers \nto total the amount of computation necessary to train the model, including pre-training and/or fine-tuning. \n\n","rows":["Atlas","11B","175B","GPT - 3","3 . 1e23","70B","Full / Transfer","3 . 3e22","5 . 0e23","Chinchilla","280B","UnifiedQA","3 . 5e22","Atlas *","Gopher","zero - shot","5 - shot ( multi - task )"],"columns":["All","Hum .","Soc . Sci .","STEM","Other"],"mergedAllColumns":["5 - shot"],"numberCells":[{"number":"66.1","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Gopher","280B","5 . 0e23"],"associatedColumns":["Other"],"associatedMergedColumns":[]},{"number":"48.9","isBolded":false,"associatedRows":["5 - shot ( multi - task )","UnifiedQA","11B","3 . 3e22"],"associatedColumns":["All"],"associatedMergedColumns":["5 - shot"]},{"number":"43.9","isBolded":false,"associatedRows":["5 - shot ( multi - task )","GPT - 3","175B","3 . 1e23"],"associatedColumns":["All"],"associatedMergedColumns":[]},{"number":"47.1","isBolded":false,"associatedRows":["zero - shot","Atlas","11B","3 . 5e22"],"associatedColumns":["All"],"associatedMergedColumns":[]},{"number":"61.1","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Hum ."],"associatedMergedColumns":["5 - shot"]},{"number":"40.2","isBolded":false,"associatedRows":["5 - shot ( multi - task )","UnifiedQA","11B","3 . 3e22"],"associatedColumns":["STEM"],"associatedMergedColumns":["5 - shot"]},{"number":"71.9","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Gopher","280B","5 . 0e23"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":[]},{"number":"50.4","isBolded":false,"associatedRows":["5 - shot ( multi - task )","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":[]},{"number":"56.6","isBolded":false,"associatedRows":["5 - shot ( multi - task )","UnifiedQA","11B","3 . 3e22"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":["5 - shot"]},{"number":"54.6","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas *","11B","3 . 5e22"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":["5 - shot"]},{"number":"56.6","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["All"],"associatedMergedColumns":["5 - shot"]},{"number":"66.4","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":["5 - shot"]},{"number":"47.9","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas *","11B","3 . 5e22"],"associatedColumns":["All"],"associatedMergedColumns":["5 - shot"]},{"number":"38.0","isBolded":false,"associatedRows":["zero - shot","Atlas","11B","3 . 5e22"],"associatedColumns":["STEM"],"associatedMergedColumns":[]},{"number":"54.4","isBolded":false,"associatedRows":["zero - shot","Atlas","11B","3 . 5e22"],"associatedColumns":["Other"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Gopher","280B","5 . 0e23"],"associatedColumns":["All"],"associatedMergedColumns":[]},{"number":"53.9","isBolded":false,"associatedRows":["Full / Transfer","GPT - 3","175B","3 . 1e23"],"associatedColumns":["All"],"associatedMergedColumns":["5 - shot"]},{"number":"55.0","isBolded":true,"associatedRows":["5 - shot ( multi - task )","Chinchilla","70B","5 . 0e23"],"associatedColumns":["STEM"],"associatedMergedColumns":[]},{"number":"54.6","isBolded":false,"associatedRows":["5 - shot ( multi - task )","UnifiedQA","11B","3 . 3e22"],"associatedColumns":["Other"],"associatedMergedColumns":["5 - shot"]},{"number":"52.5","isBolded":false,"associatedRows":["Full / Transfer","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Hum ."],"associatedMergedColumns":["5 - shot"]},{"number":"79.3","isBolded":true,"associatedRows":["5 - shot ( multi - task )","Chinchilla","70B","5 . 0e23"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":[]},{"number":"57.9","isBolded":false,"associatedRows":["Full / Transfer","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Other"],"associatedMergedColumns":["5 - shot"]},{"number":"63.9","isBolded":false,"associatedRows":["Full / Transfer","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":["5 - shot"]},{"number":"66.0","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["All"],"associatedMergedColumns":["5 - shot"]},{"number":"56.2","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Gopher","280B","5 . 0e23"],"associatedColumns":["Hum ."],"associatedMergedColumns":[]},{"number":"50.1","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Hum ."],"associatedMergedColumns":["5 - shot"]},{"number":"48.8","isBolded":false,"associatedRows":["5 - shot ( multi - task )","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Other"],"associatedMergedColumns":[]},{"number":"53.2","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["STEM"],"associatedMergedColumns":["5 - shot"]},{"number":"74.4","isBolded":true,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Other"],"associatedMergedColumns":["5 - shot"]},{"number":"52.8","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas *","11B","3 . 5e22"],"associatedColumns":["Other"],"associatedMergedColumns":["5 - shot"]},{"number":"43.6","isBolded":false,"associatedRows":["zero - shot","Atlas","11B","3 . 5e22"],"associatedColumns":["Hum ."],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["5 - shot ( multi - task )","GPT - 3","175B","3 . 1e23"],"associatedColumns":["Hum ."],"associatedMergedColumns":[]},{"number":"46.1","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas *","11B","3 . 5e22"],"associatedColumns":["Hum ."],"associatedMergedColumns":["5 - shot"]},{"number":"67.5","isBolded":true,"associatedRows":["5 - shot ( multi - task )","Chinchilla","70B","5 . 0e23"],"associatedColumns":["All"],"associatedMergedColumns":[]},{"number":"73.9","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Chinchilla","70B","5 . 0e23"],"associatedColumns":["Other"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Other"],"associatedMergedColumns":["5 - shot"]},{"number":"41.4","isBolded":false,"associatedRows":["Full / Transfer","GPT - 3","175B","3 . 1e23"],"associatedColumns":["STEM"],"associatedMergedColumns":["5 - shot"]},{"number":"77.2","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":["5 - shot"]},{"number":"47.4","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Gopher","280B","5 . 0e23"],"associatedColumns":["STEM"],"associatedMergedColumns":[]},{"number":"63.6","isBolded":true,"associatedRows":["5 - shot ( multi - task )","Chinchilla","70B","5 . 0e23"],"associatedColumns":["Hum ."],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["zero - shot","Atlas","11B","3 . 5e22"],"associatedColumns":["Soc . Sci ."],"associatedMergedColumns":[]},{"number":"46.4","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas","11B","3 . 5e22"],"associatedColumns":["STEM"],"associatedMergedColumns":["5 - shot"]},{"number":"45.6","isBolded":false,"associatedRows":["5 - shot ( multi - task )","UnifiedQA","11B","3 . 3e22"],"associatedColumns":["Hum ."],"associatedMergedColumns":["5 - shot"]},{"number":"36.7","isBolded":false,"associatedRows":["5 - shot ( multi - task )","GPT - 3","175B","3 . 1e23"],"associatedColumns":["STEM"],"associatedMergedColumns":[]},{"number":"38.8","isBolded":false,"associatedRows":["5 - shot ( multi - task )","Atlas *","11B","3 . 5e22"],"associatedColumns":["STEM"],"associatedMergedColumns":["5 - shot"]}]},{"caption":"Table 8: Comparison to state-of-the-art on question answering. We report results on NaturalQues-\ntions, and on TriviaQA for both the filtered set, commonly used for open-domain question answering \nand the unfiltered hidden set for which evaluation is accessible online: https://competitions.codalab.org/ \ncompetitions/17208. For the 64-shot setting, our model uses fine-tuning, while the other models use prompting. \n\n","rows":["GPT - 3 ( Brown et al . , 2020 )","RETRO ( Borgeaud et al . , 2021 )","FiD - KD ( Izacard \u0026 Grave , 2021 )","Atlas","Chinchilla ( Hoffmann et al . , 2022 )","R2 - D2 ( Fajcik et al . , 2021 )","FiD ( Izacard \u0026 Grave , 2020 )","-","Gopher ( Rae et al . , 2021 )","PaLM ( Chowdhery et al . , 2022 )"],"columns":["NQ","TriviaQA filtered","64 - shot","TriviaQA unfiltered","-","Full"],"mergedAllColumns":["-"],"numberCells":[{"number":"84.7","isBolded":true,"associatedRows":["Atlas","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","64 - shot","-","-","-"],"associatedMergedColumns":["-"]},{"number":"67.6","isBolded":false,"associatedRows":["FiD ( Izacard \u0026 Grave , 2020 )","-","-","-"],"associatedColumns":["TriviaQA filtered","Full","-"],"associatedMergedColumns":["-"]},{"number":"55.9","isBolded":false,"associatedRows":["R2 - D2 ( Fajcik et al . , 2021 )","-"],"associatedColumns":["NQ","Full","-","-"],"associatedMergedColumns":["-"]},{"number":"42.4","isBolded":true,"associatedRows":["Atlas"],"associatedColumns":["NQ","64 - shot","-","-","-"],"associatedMergedColumns":["-"]},{"number":"39.6","isBolded":false,"associatedRows":["PaLM ( Chowdhery et al . , 2022 )"],"associatedColumns":["NQ","64 - shot"],"associatedMergedColumns":["-"]},{"number":"29.9","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020 )"],"associatedColumns":["NQ","64 - shot"],"associatedMergedColumns":[]},{"number":"72.3","isBolded":false,"associatedRows":["Chinchilla ( Hoffmann et al . , 2022 )","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","64 - shot"],"associatedMergedColumns":["-"]},{"number":"28.2","isBolded":false,"associatedRows":["Gopher ( Rae et al . , 2021 )"],"associatedColumns":["NQ","64 - shot"],"associatedMergedColumns":["-"]},{"number":"69.9","isBolded":false,"associatedRows":["R2 - D2 ( Fajcik et al . , 2021 )","-","-","-"],"associatedColumns":["TriviaQA filtered","Full","-","-"],"associatedMergedColumns":["-"]},{"number":"74.5","isBolded":true,"associatedRows":["Atlas","-","-"],"associatedColumns":["TriviaQA filtered","64 - shot","-","-","-"],"associatedMergedColumns":["-"]},{"number":"79.8","isBolded":true,"associatedRows":["Atlas","-","-","-"],"associatedColumns":["TriviaQA filtered","Full","-","-","-"],"associatedMergedColumns":["-"]},{"number":"73.3","isBolded":false,"associatedRows":["FiD - KD ( Izacard \u0026 Grave , 2021 )","-","-","-"],"associatedColumns":["TriviaQA filtered","Full","-"],"associatedMergedColumns":["-"]},{"number":"89.4","isBolded":true,"associatedRows":["Atlas","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","Full","-","-","-"],"associatedMergedColumns":["-"]},{"number":"51.4","isBolded":false,"associatedRows":["FiD ( Izacard \u0026 Grave , 2020 )","-"],"associatedColumns":["NQ","Full","-"],"associatedMergedColumns":["-"]},{"number":"61.3","isBolded":false,"associatedRows":["Gopher ( Rae et al . , 2021 )","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","64 - shot"],"associatedMergedColumns":["-"]},{"number":"57.2","isBolded":false,"associatedRows":["Gopher ( Rae et al . , 2021 )","-","-"],"associatedColumns":["TriviaQA filtered","64 - shot"],"associatedMergedColumns":["-"]},{"number":"71.2","isBolded":false,"associatedRows":["GPT - 3 ( Brown et al . , 2020 )","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","64 - shot"],"associatedMergedColumns":[]},{"number":"54.7","isBolded":false,"associatedRows":["FiD - KD ( Izacard \u0026 Grave , 2021 )","-"],"associatedColumns":["NQ","Full","-"],"associatedMergedColumns":["-"]},{"number":"45.5","isBolded":false,"associatedRows":["RETRO ( Borgeaud et al . , 2021 )","-"],"associatedColumns":["NQ","Full"],"associatedMergedColumns":["-"]},{"number":"60.4","isBolded":true,"associatedRows":["Atlas","-"],"associatedColumns":["NQ","Full","-","-","-"],"associatedMergedColumns":["-"]},{"number":"35.5","isBolded":false,"associatedRows":["Chinchilla ( Hoffmann et al . , 2022 )"],"associatedColumns":["NQ","64 - shot"],"associatedMergedColumns":["-"]},{"number":"64.6","isBolded":false,"associatedRows":["Chinchilla ( Hoffmann et al . , 2022 )","-","-"],"associatedColumns":["TriviaQA filtered","64 - shot"],"associatedMergedColumns":["-"]},{"number":"81.4","isBolded":false,"associatedRows":["PaLM ( Chowdhery et al . , 2022 )","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","64 - shot"],"associatedMergedColumns":["-"]},{"number":"80.1","isBolded":false,"associatedRows":["FiD ( Izacard \u0026 Grave , 2020 )","-","-","-","-","-"],"associatedColumns":["TriviaQA unfiltered","Full","-"],"associatedMergedColumns":["-"]}]},{"caption":"Table 9: Comparison to state-of-the-art on FEVER. We report accuracy on FEVER test set, for \nwhich evaluation is available here: https://competitions.codalab.org/competitions/18814. For the few-shot \nsettings, our model uses fine-tuning while other models use prompting.  ? uses an index composed of the \nFEVER Wikipedia corpus. \n\n","rows":["Atlas","-"],"columns":["( Rae et al . , 2021 )"],"mergedAllColumns":[],"numberCells":[{"number":"64.3","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["( Rae et al . , 2021 )"],"associatedMergedColumns":[]},{"number":"80.1?","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["( Rae et al . , 2021 )"],"associatedMergedColumns":[]},{"number":"79.5","isBolded":true,"associatedRows":["-","-"],"associatedColumns":["( Rae et al . , 2021 )"],"associatedMergedColumns":[]},{"number":"56.2","isBolded":false,"associatedRows":["Atlas"],"associatedColumns":["( Rae et al . , 2021 )"],"associatedMergedColumns":[]},{"number":"78.0/","isBolded":true,"associatedRows":["Atlas"],"associatedColumns":["( Rae et al . , 2021 )"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Downstream results on the KILT hidden test sets Downstream metrics are accuracy (AIDA \nCoNLL-YAGO, FEVER, T-REx, zero-shot RE), exact match (Natural Questions, HotpotQA, TriviaQA), or \nF1 (Wizard of Wikipedia). \n\n","rows":["GENRE ( Cao et al . , 2021 )","set , and achieve a score of 78% , within","comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas scores 56 . 2% , outperforming Gopher by","FID with RS ( Hofst?tter et al . , 2022 )","SEAL ( Bevilacqua et al . , 2022 )","Re2G ( Glass et al . , 2022 )","Atlas , full train set","Sphere ( Piktus et al . , 2021 )","-","Atlas , 64 - shot"],"columns":["acc","NQ","HoPo","TQA","em","f1","-","zsRE","FEV","T - REx","AIDA","whereas Atlas retrieves from CCNet and the December 2021 Wikipedia dump .","WoW"],"mergedAllColumns":["trained with sentence - level annotations , and is supplied with the Wikipedia corpus released with FEVER ,","Model"],"numberCells":[{"number":"51.6","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"83.6","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]},{"number":"34.7","isBolded":false,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , 64 - shot","-"],"associatedColumns":["HoPo","em","-"],"associatedMergedColumns":["Model"]},{"number":"90.6","isBolded":true,"associatedRows":["Atlas , full train set"],"associatedColumns":["AIDA","acc","-"],"associatedMergedColumns":["Model"]},{"number":"51.7","isBolded":false,"associatedRows":["Re2G ( Glass et al . , 2022 )","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"53.7","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"89.6","isBolded":false,"associatedRows":["Re2G ( Glass et al . , 2022 )","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"39.1","isBolded":false,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-","-"],"associatedColumns":["HoPo","em","-"],"associatedMergedColumns":["Model"]},{"number":"84.0","isBolded":false,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , full train set","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"80.8","isBolded":false,"associatedRows":["Atlas , full train set","-"],"associatedColumns":["zsRE","acc","-"],"associatedMergedColumns":["Model"]},{"number":"76.3","isBolded":false,"associatedRows":["Re2G ( Glass et al . , 2022 )","-","-","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"84.6","isBolded":true,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"61.2","isBolded":false,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"20.6","isBolded":false,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"15.5","isBolded":false,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , 64 - shot","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"89.5","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"74.9","isBolded":false,"associatedRows":["Atlas , 64 - shot","-"],"associatedColumns":["zsRE","acc","-"],"associatedMergedColumns":["Model"]},{"number":"15.5","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"85.1","isBolded":false,"associatedRows":["Atlas , full train set","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]},{"number":"43.6","isBolded":false,"associatedRows":["Atlas , 64 - shot","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"74.2","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-"],"associatedColumns":["zsRE","acc","-"],"associatedMergedColumns":["Model"]},{"number":"18.3","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"93.5","isBolded":true,"associatedRows":["Atlas , full train set","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"61.3","isBolded":true,"associatedRows":["Atlas , full train set","-","-"],"associatedColumns":["NQ","em","-"],"associatedMergedColumns":["Model"]},{"number":"74.6","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-"],"associatedColumns":["zsRE","acc","-"],"associatedMergedColumns":["Model"]},{"number":"40.5","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-","-"],"associatedColumns":["HoPo","em","-"],"associatedMergedColumns":["Model"]},{"number":"76.4","isBolded":false,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , 64 - shot","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"92.2","isBolded":false,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"87.1","isBolded":false,"associatedRows":["Atlas , 64 - shot","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"89.0","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-"],"associatedColumns":["FEV","acc","-"],"associatedMergedColumns":["Model"]},{"number":"58.9","isBolded":false,"associatedRows":["Atlas , 64 - shot","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]},{"number":"1.5%oftheProoFVer,whichusesaspecializedarchitecture,aretriever","isBolded":false,"associatedRows":["set , and achieve a score of 78% , within"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"50.6","isBolded":true,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , full train set","-"],"associatedColumns":["HoPo","em","-"],"associatedMergedColumns":["Model"]},{"number":"89.9","isBolded":false,"associatedRows":["GENRE ( Cao et al . , 2021 )"],"associatedColumns":["AIDA","acc"],"associatedMergedColumns":["Model"]},{"number":"21.6","isBolded":true,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of","Atlas , full train set"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"70.9","isBolded":false,"associatedRows":["SEAL ( Bevilacqua et al . , 2022 )","-","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"80.1%","isBolded":false,"associatedRows":["comprised of the FEVER Wikipedia corpus , we set a new state - of - the - art of"],"associatedColumns":["NQ","em","-","whereas Atlas retrieves from CCNet and the December 2021 Wikipedia dump ."],"associatedMergedColumns":["trained with sentence - level annotations , and is supplied with the Wikipedia corpus released with FEVER ,"]},{"number":"38.3","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-","-"],"associatedColumns":["HoPo","em","-"],"associatedMergedColumns":["Model"]},{"number":"83.7","isBolded":true,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-"],"associatedColumns":["zsRE","acc","-"],"associatedMergedColumns":["Model"]},{"number":"66.5","isBolded":false,"associatedRows":["Atlas , 64 - shot"],"associatedColumns":["AIDA","acc","-"],"associatedMergedColumns":["Model"]},{"number":"72.7","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-","-"],"associatedColumns":["TQA","em","-"],"associatedMergedColumns":["Model"]},{"number":"18.9","isBolded":false,"associatedRows":["Re2G ( Glass et al . , 2022 )","-","-","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"5.1points.Lastlywefine-tuneourmodelonthefulltraining","isBolded":false,"associatedRows":["Atlas scores 56 . 2% , outperforming Gopher by","-"],"associatedColumns":["WoW","f1","-"],"associatedMergedColumns":["Model"]},{"number":"81.7","isBolded":false,"associatedRows":["Sphere ( Piktus et al . , 2021 )","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]},{"number":"85.2","isBolded":false,"associatedRows":["FID with RS ( Hofst?tter et al . , 2022 )","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]},{"number":"87.7","isBolded":true,"associatedRows":["Re2G ( Glass et al . , 2022 )","-"],"associatedColumns":["T - REx","acc","-"],"associatedMergedColumns":["Model"]}]},{"caption":"Table 11: Results on our TempLAMA-derived dataset. We report performance for a static, closed-book \nT5-11B, as well as Atlas-11B supplied with a test-time Wikipedia index from 2017 or 2020. We evaluate \nmodels finetuned on a small training set of 248 time-sensitive cloze-question-answer pairs, using answers \neither from 2017 or 2020. Good models should score highly when the test set year matches the year of the \ntest-time index, and score low otherwise. \n\n","rows":["2017 answers","2017","2020 answers","2020"],"columns":["Atlas","2020 Test Set Acc .","2017 Test Set Acc .","Closed - book"],"mergedAllColumns":[],"numberCells":[{"number":"1.5","isBolded":false,"associatedRows":["2017 answers","2017"],"associatedColumns":["2020 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"3.5","isBolded":false,"associatedRows":["2020 answers","2020"],"associatedColumns":["2017 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"4.8","isBolded":false,"associatedRows":["2020 answers","2020"],"associatedColumns":["2017 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"4.8","isBolded":false,"associatedRows":["2020 answers","2017"],"associatedColumns":["2017 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"3.6","isBolded":false,"associatedRows":["2020 answers","2017"],"associatedColumns":["2020 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"50.1","isBolded":false,"associatedRows":["2020 answers","2017"],"associatedColumns":["2017 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"53.1","isBolded":false,"associatedRows":["2017 answers","2020"],"associatedColumns":["2020 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"12.1","isBolded":false,"associatedRows":["2017 answers","2020"],"associatedColumns":["2017 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"12.1","isBolded":false,"associatedRows":["2017 answers","2017"],"associatedColumns":["2017 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"3.6","isBolded":false,"associatedRows":["2020 answers","2020"],"associatedColumns":["2020 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"60.5","isBolded":false,"associatedRows":["2020 answers","2020"],"associatedColumns":["2020 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"2.9","isBolded":false,"associatedRows":["2017 answers","2017"],"associatedColumns":["2020 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]},{"number":"10.2","isBolded":false,"associatedRows":["2017 answers","2020"],"associatedColumns":["2017 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"4.2","isBolded":false,"associatedRows":["2020 answers","2017"],"associatedColumns":["2020 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["2017 answers","2017"],"associatedColumns":["2017 Test Set Acc .","Atlas"],"associatedMergedColumns":[]},{"number":"2.9","isBolded":false,"associatedRows":["2017 answers","2020"],"associatedColumns":["2020 Test Set Acc .","Closed - book"],"associatedMergedColumns":[]}]},{"caption":"Table 12: Impact of index data temporality on NaturalQuestions. We report exact match performance \non NaturalQuestions using different Wikipedia dumps in the index. We observe that the dump from December \n2018, commonly used for NaturalQuestions, leads to the best result. \n\n","rows":["64 - shot","Full"],"columns":["Dec . 2017","Dec . 2018","Aug . 2019","Dec . 2020","Dec . 2021"],"mergedAllColumns":[],"numberCells":[{"number":"44.7","isBolded":false,"associatedRows":["64 - shot"],"associatedColumns":["Dec . 2017"],"associatedMergedColumns":[]},{"number":"44.0","isBolded":false,"associatedRows":["64 - shot"],"associatedColumns":["Dec . 2020"],"associatedMergedColumns":[]},{"number":"63.2","isBolded":false,"associatedRows":["Full"],"associatedColumns":["Dec . 2017"],"associatedMergedColumns":[]},{"number":"61.1","isBolded":false,"associatedRows":["Full"],"associatedColumns":["Dec . 2020"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["64 - shot"],"associatedColumns":["Dec . 2021"],"associatedMergedColumns":[]},{"number":"62.4","isBolded":false,"associatedRows":["Full"],"associatedColumns":["Aug . 2019"],"associatedMergedColumns":[]},{"number":"59.6","isBolded":false,"associatedRows":["Full"],"associatedColumns":["Dec . 2021"],"associatedMergedColumns":[]},{"number":"45.1","isBolded":true,"associatedRows":["64 - shot"],"associatedColumns":["Dec . 2018"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":true,"associatedRows":["Full"],"associatedColumns":["Dec . 2018"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["64 - shot"],"associatedColumns":["Aug . 2019"],"associatedMergedColumns":[]}]},{"caption":"Table 13: MMLU scores with de-biasing: \n\nSetting \nModel \nAll \nHum. Soc. Sci. STEM Other \n\nzero-shot \n\nStandard \n36.8 \n37.5 \n39.0 \n30.2 \n39.7 \nAll permutations \n48.5 \n45.7 \n55.2 \n39.4 \n54.4 \nCyclic Permutations \n47.1 \n43.6 \n54.1 \n38.0 \n54.9 \n\n5-shot \n\nStandard \n43.39 \n41.8 \n49.3 \n33.9 \n48.8 \nAll permutations \n49.0 \n46 \n56.1 \n40.5 \n54.6 \nCyclic Permutations \n47.9 \n46.1 \n54.6 \n38.8 \n52.8 \n\n","rows":["5 - shot","All permutations","Cyclic Permutations","46","zero - shot","Standard"],"columns":["All","Hum .","Soc . Sci .","Table 13 : MMLU scores with de - biasing :","STEM","Other"],"mergedAllColumns":[],"numberCells":[{"number":"33.9","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"56.1","isBolded":false,"associatedRows":["5 - shot","All permutations","46"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"48.8","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["5 - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]},{"number":"54.6","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"54.6","isBolded":false,"associatedRows":["5 - shot","All permutations","46"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"55.2","isBolded":false,"associatedRows":["zero - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"46.1","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Hum ."],"associatedMergedColumns":[]},{"number":"45.7","isBolded":false,"associatedRows":["zero - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Hum ."],"associatedMergedColumns":[]},{"number":"47.1","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]},{"number":"40.5","isBolded":false,"associatedRows":["5 - shot","All permutations","46"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"30.2","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"39.7","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"38.8","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"49.3","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"47.9","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"54.4","isBolded":false,"associatedRows":["zero - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"48.5","isBolded":false,"associatedRows":["zero - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]},{"number":"37.5","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Hum ."],"associatedMergedColumns":[]},{"number":"41.8","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Hum ."],"associatedMergedColumns":[]},{"number":"54.9","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Other"],"associatedMergedColumns":[]},{"number":"39.4","isBolded":false,"associatedRows":["zero - shot","All permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","STEM"],"associatedMergedColumns":[]},{"number":"43.6","isBolded":false,"associatedRows":["zero - shot","Cyclic Permutations"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","Hum ."],"associatedMergedColumns":[]},{"number":"43.39","isBolded":false,"associatedRows":["zero - shot","Standard"],"associatedColumns":["Table 13 : MMLU scores with de - biasing :","All"],"associatedMergedColumns":[]}]},{"caption":"Table 14: Hyperparameters for MMLU \n\n770M \n3B \n11B \n\nBatch size \n64 \n64 \n64 \nLearning rate \n(5e-5, 1e-5) (5e-5, 1e-5) (5e-5, 1e-5) \nRetriever Temperature \n0.1 \n0.1 \n0.1 \n5-shot train steps \n64 \n32 \n16 \n5-shot (multitask) max train steps \n2000 \n500 \n250 \nFull / transfer max train steps \n5000 \n2000 \n2000 \n\n","rows":["Batch size","Retriever Temperature","5 - shot train steps"],"columns":["11B","( 5e - 5 , 1e - 5 )","770M","Table 14 : Hyperparameters for MMLU","3B"],"mergedAllColumns":[],"numberCells":[{"number":"64","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","3B"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Retriever Temperature"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","11B","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["5 - shot train steps"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","11B","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","770M"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["5 - shot train steps"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","770M","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Retriever Temperature"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","770M","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["5 - shot train steps"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","3B","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","11B"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Retriever Temperature"],"associatedColumns":["Table 14 : Hyperparameters for MMLU","3B","( 5e - 5 , 1e - 5 )"],"associatedMergedColumns":[]}]},{"caption":"Table 15: Interrun Variance for 5-shot MMLU using Atlas-11B \n\nRun # \nAll \nHum. \nSoc. Sci. \nSTEM \nOther \n\n1 \n45.2 \n40.6 \n54.1 \n37.1 \n51.1 \n2 \n45.1 \n39.8 \n54.4 \n37.1 \n52.0 \n3 \n45.0 \n40.0 \n54.1 \n37.7 \n51.1 \n4 \n45.6 \n41.3 \n54.7 \n37.0 \n51.6 \n5 \n44.3 \n40.6 \n50.7 \n38.1 \n49.8 \n\n","rows":["1","2","3","4","5"],"columns":["All","Hum .","Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci .","STEM","Other"],"mergedAllColumns":[],"numberCells":[{"number":"45.6","isBolded":false,"associatedRows":["4"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","All"],"associatedMergedColumns":[]},{"number":"54.7","isBolded":false,"associatedRows":["4"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"45.1","isBolded":false,"associatedRows":["2"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","All"],"associatedMergedColumns":[]},{"number":"50.7","isBolded":false,"associatedRows":["5"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["3"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Other"],"associatedMergedColumns":[]},{"number":"37.7","isBolded":false,"associatedRows":["3"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","STEM"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["3"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Hum ."],"associatedMergedColumns":[]},{"number":"51.6","isBolded":false,"associatedRows":["4"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Other"],"associatedMergedColumns":[]},{"number":"52.0","isBolded":false,"associatedRows":["2"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Other"],"associatedMergedColumns":[]},{"number":"37.1","isBolded":false,"associatedRows":["2"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","STEM"],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["1"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["4"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Hum ."],"associatedMergedColumns":[]},{"number":"40.6","isBolded":false,"associatedRows":["5"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Hum ."],"associatedMergedColumns":[]},{"number":"38.1","isBolded":false,"associatedRows":["5"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","STEM"],"associatedMergedColumns":[]},{"number":"40.6","isBolded":false,"associatedRows":["1"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Hum ."],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["1"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Other"],"associatedMergedColumns":[]},{"number":"54.4","isBolded":false,"associatedRows":["2"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"45.0","isBolded":false,"associatedRows":["3"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","All"],"associatedMergedColumns":[]},{"number":"44.3","isBolded":false,"associatedRows":["5"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","All"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["4"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","STEM"],"associatedMergedColumns":[]},{"number":"39.8","isBolded":false,"associatedRows":["2"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Hum ."],"associatedMergedColumns":[]},{"number":"37.1","isBolded":false,"associatedRows":["1"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","STEM"],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["5"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Other"],"associatedMergedColumns":[]},{"number":"54.1","isBolded":false,"associatedRows":["3"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","Soc . Sci ."],"associatedMergedColumns":[]},{"number":"45.2","isBolded":false,"associatedRows":["1"],"associatedColumns":["Interrun Variance for 5 - shot MMLU using Atlas - 11B","All"],"associatedMergedColumns":[]}]},{"caption":"Table 16: MMLU Test set scores for Atlas for each model size and each of the 57 domains \n\n5-shot \n5-shot (multi-task) \nFull / Transfer \n\n770M 3B \n11B 770M 3B \n11B 770M 3B \n11B \nAll \n38.9 \n42.3 43.4 \n42.1 \n48.7 56.4 \n56.3 \n59.9 65.8 \n\nHumanities \n37.3 \n40.0 41.9 \n37.7 \n46.4 50.0 \n50.9 \n53.0 60.3 \nSocial Sciences \n41.7 \n46.8 49.3 \n47.5 \n53.7 65.6 \n66.0 \n70.8 77.2 \nSTEM \n32.3 \n35.0 33.9 \n34.4 \n39.4 46.2 \n44.8 \n50.7 53.4 \nOther \n44.9 \n48.1 48.8 \n50.4 \n55.9 66.6 \n65.5 \n68.1 74.4 \n\nabstract algebra \n30.0 \n27.0 28.0 \n27.0 \n31.0 30.0 \n22.0 \n27.0 33.0 \nanatomy \n28.9 \n50.4 45.2 \n44.4 \n57.8 64.4 \n57.8 \n68.9 69.6 \nastronomy \n55.3 \n59.9 59.2 \n52.6 \n66.4 67.8 \n69.1 \n78.3 79.6 \nbusiness ethics \n49.0 \n51.0 48.0 \n50.0 \n62.0 60.0 \n51.0 \n70.0 68.0 \nclinical knowledge \n41.9 \n44.9 40.0 \n46.8 \n54.3 64.9 \n64.2 \n72.5 74.0 \ncollege biology \n38.2 \n45.8 50.0 \n36.8 \n52.1 63.2 \n63.2 \n72.2 78.5 \ncollege chemistry \n32.0 \n29.0 29.0 \n31.0 \n33.0 38.0 \n45.0 \n39.0 45.0 \ncollege computer science \n33.0 \n35.0 30.0 \n23.0 \n29.0 30.0 \n43.0 \n48.0 47.0 \ncollege mathematics \n31.0 \n31.0 28.0 \n29.0 \n27.0 34.0 \n32.0 \n29.0 36.0 \ncollege medicine \n31.2 \n35.8 38.2 \n50.3 \n40.5 52.0 \n60.1 \n59.5 63.6 \ncollege physics \n20.6 \n26.5 31.4 \n21.6 \n28.4 39.2 \n27.5 \n44.1 42.2 \ncomputer security \n53.0 \n50.0 55.0 \n49.0 \n61.0 64.0 \n69.0 \n71.0 76.0 \nconceptual physics \n34.9 \n41.7 37.4 \n40.9 \n43.4 57.0 \n53.2 \n58.3 59.6 \neconometrics \n28.9 \n21.1 27.2 \n26.3 \n25.4 34.2 \n28.9 \n37.7 36.8 \nelectrical engineering \n26.9 \n31.7 31.7 \n38.6 \n44.1 51.7 \n61.4 \n60.7 67.6 \nelementary mathematics \n25.9 \n28.8 29.4 \n29.6 \n30.2 32.8 \n29.6 \n35.5 33.9 \nformal logic \n34.9 \n33.3 33.3 \n23.0 \n30.2 29.4 \n34.1 \n38.9 34.1 \nglobal facts \n28.0 \n34.0 34.0 \n36.0 \n40.0 49.0 \n50.0 \n49.0 52.0 \nhigh school biology \n24.8 \n37.7 27.7 \n48.7 \n57.1 66.5 \n66.5 \n76.8 81.9 \nhigh school chemistry \n34.5 \n31.0 31.0 \n31.5 \n36.5 48.3 \n44.8 \n52.2 52.2 \nhigh school computer science \n31.0 \n39.0 28.0 \n37.0 \n42.0 42.0 \n50.0 \n59.0 57.0 \nhigh school european history \n42.4 \n49.7 53.3 \n50.9 \n58.2 69.7 \n70.9 \n73.9 80.0 \nhigh school geography \n38.9 \n42.4 50.0 \n46.5 \n56.6 69.2 \n74.2 \n80.8 82.8 \nhigh school gov. and pol. \n57.5 \n60.6 60.1 \n52.9 \n64.8 76.7 \n80.8 \n85.5 91.7 \nhigh school macroeconomics \n32.8 \n39.7 44.9 \n39.0 \n45.6 57.2 \n55.1 \n63.1 66.7 \nhigh school mathematics \n30.7 \n33.0 35.6 \n28.1 \n27.8 37.0 \n30.7 \n34.8 37.0 \nhigh school microeconomics \n34.5 \n42.9 45.4 \n44.1 \n51.7 68.9 \n63.4 \n70.2 81.1 \nhigh school physics \n18.5 \n24.5 22.5 \n25.8 \n25.8 33.1 \n27.2 \n30.5 39.7 \nhigh school psychology \n52.8 \n61.1 59.8 \n56.7 \n67.2 79.4 \n76.3 \n84.0 87.0 \nhigh school statistics \n39.8 \n29.6 34.7 \n27.3 \n34.7 38.0 \n37.0 \n43.1 45.8 \nhigh school us history \n43.6 \n49.0 55.9 \n46.1 \n57.8 59.8 \n62.7 \n72.5 76.5 \nhigh school world history \n48.1 \n52.7 59.9 \n48.1 \n66.2 65.4 \n70.0 \n78.5 79.7 \nhuman aging \n46.2 \n44.8 39.5 \n48.0 \n55.2 60.1 \n56.1 \n68.2 73.1 \nhuman sexuality \n41.2 \n43.5 27.5 \n46.6 \n51.1 59.5 \n77.1 \n72.5 81.7 \ninternational law \n54.5 \n57.9 60.3 \n55.4 \n72.7 73.6 \n81.8 \n82.6 85.1 \njurisprudence \n38.9 \n55.6 32.4 \n53.7 \n60.2 73.1 \n76.9 \n73.1 81.5 \nlogical fallacies \n43.6 \n54.0 57.1 \n44.2 \n58.3 70.6 \n64.4 \n73.0 76.7 \nmachine learning \n36.6 \n34.8 28.6 \n31.3 \n37.5 46.4 \n36.6 \n47.3 50.9 \nmanagement \n45.6 \n51.5 52.4 \n48.5 \n52.4 81.6 \n78.6 \n75.7 87.4 \nmarketing \n59.4 \n67.1 70.5 \n66.7 \n74.4 83.8 \n83.8 \n83.3 91.9 \nmedical genetics \n50.0 \n53.0 58.0 \n56.0 \n61.0 75.0 \n68.0 \n78.0 81.0 \nmiscellaneous \n63.0 \n64.2 68.8 \n64.0 \n72.4 84.3 \n85.4 \n83.9 90.9 \nmoral disputes \n37.0 \n41.3 41.3 \n40.8 \n50.3 60.1 \n61.9 \n66.2 73.7 \nmoral scenarios \n24.7 \n24.7 26.5 \n21.9 \n26.9 26.6 \n23.8 \n23.8 35.8 \nnutrition \n40.9 \n45.1 45.1 \n49.0 \n52.3 67.0 \n64.7 \n68.6 76.8 \nphilosophy \n48.6 \n50.5 56.3 \n49.8 \n59.2 69.5 \n70.4 \n73.0 77.8 \nprehistory \n45.7 \n50.0 52.8 \n54.9 \n64.8 74.4 \n69.8 \n75.0 80.6 \nprofessional accounting \n28.4 \n33.0 34.0 \n35.1 \n34.0 45.7 \n43.6 \n46.1 51.8 \nprofessional law \n32.4 \n33.5 34.8 \n30.4 \n37.6 39.1 \n41.5 \n41.5 50.5 \nprofessional medicine \n29.4 \n26.1 27.6 \n34.6 \n40.8 52.2 \n47.8 \n43.4 59.6 \nprofessional psychology \n37.7 \n43.0 50.2 \n45.1 \n51.0 60.6 \n59.5 \n62.4 74.0 \npublic relations \n40.0 \n46.4 44.5 \n51.8 \n54.5 66.4 \n63.6 \n66.4 68.2 \nsecurity studies \n35.1 \n33.5 38.8 \n44.1 \n39.6 57.6 \n60.8 \n61.6 72.2 \nsociology \n45.3 \n51.2 51.2 \n52.7 \n60.2 69.2 \n74.1 \n78.6 85.1 \nus foreign policy \n58.0 \n70.0 73.0 \n63.0 \n63.0 74.0 \n80.0 \n80.0 83.0 \nvirology \n34.3 \n34.3 32.5 \n38.0 \n42.8 45.2 \n47.6 \n49.4 53.0 \n","rows":["All","high school world history","college computer science","professional accounting","college physics","high school mathematics","high school statistics","formal logic","global facts","econometrics","clinical knowledge","international law","high school gov . and pol .","prehistory","professional medicine","world religions","business ethics","astronomy","philosophy","security studies","high school european history","college chemistry","nutrition","medical genetics","human aging","human sexuality","miscellaneous","anatomy","conceptual physics","sociology","electrical engineering","jurisprudence","public relations","professional psychology","elementary mathematics","abstract algebra","college mathematics","logical fallacies","high school macroeconomics","Humanities","Social Sciences","high school computer science","high school chemistry","high school psychology","machine learning","STEM","moral scenarios","computer security","marketing","high school us history","college biology","management","virology","college medicine","professional law","high school geography","moral disputes","us foreign policy","high school microeconomics","high school physics","high school biology","Other"],"columns":["5 - shot","11B","770M","5 - shot ( multi - task )","MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"mergedAllColumns":[],"numberCells":[{"number":"50.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"38.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"61.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"53.2","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"52.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"59.8","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"74.0","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"52.9","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"45.7","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"29.4","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"50.9","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"41.7","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"55.6","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"39.7","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"26.6","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"87.0","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"42.1","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"32.8","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"44.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"60.6","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"21.9","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"64.4","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"29.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"26.1","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"50.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"44.5","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"58.3","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"66.5","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"59.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"46.8","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"27.5","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"36.6","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"45.1","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"56.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"45.4","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"53.0","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"27.2","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"54.5","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"50.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"44.2","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"48.1","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"35.8","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"73.9","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"33.1","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"26.9","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"35.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"65.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"63.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"48.1","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"62.7","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"37.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"38.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"59.5","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"22.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"60.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"27.2","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"51.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"78.6","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"67.1","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"67.2","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"26.3","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"57.1","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"33.3","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"43.6","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"34.7","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"45.3","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"33.9","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"42.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"53.3","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"63.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"37.7","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"56.6","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"52.2","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"66.7","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"84.3","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"39.6","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"45.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"48.6","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"30.2","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"30.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"40.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"52.3","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"57.2","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"63.4","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"66.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"70.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"54.0","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"43.5","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"60.8","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"78.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"74.0","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"81.7","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"76.7","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"45.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"81.6","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"46.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"23.0","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"32.5","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"57.6","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"53.7","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"45.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"35.1","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"64.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"28.9","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"60.2","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"46.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"55.1","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"73.1","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"61.4","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"79.4","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"77.8","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"77.2","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"53.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"46.4","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"38.8","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"37.4","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"52.6","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"61.9","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"27.6","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"46.1","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"80.6","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"32.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"54.3","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"68.6","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"32.8","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"63.6","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"62.4","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"66.7","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"35.8","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"39.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"31.4","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"55.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"67.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"72.5","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"42.4","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"28.9","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"73.1","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"79.6","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"56.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"34.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"43.6","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"60.6","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"70.5","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"38.2","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"50.2","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"30.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"37.7","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"78.5","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"50.5","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"32.4","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"74.1","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"82.5","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"53.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"67.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"68.1","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"41.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"52.1","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"52.4","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"48.1","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"24.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"27.8","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"23.8","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"53.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"37.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"71.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"43.6","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"64.7","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"33.5","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"50.3","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"21.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"50.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"76.5","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"87.4","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"21.1","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"27.3","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"47.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"61.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"65.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"72.5","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"47.3","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"34.3","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"22.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"34.3","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"72.5","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"60.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"51.8","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"18.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"41.2","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"78.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"48.3","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"50.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"42.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"49.7","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"36.8","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"53.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"45.7","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"41.9","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"34.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"28.8","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"60.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"65.5","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"52.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"48.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"52.0","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"20.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"34.6","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"45.8","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"31.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"31.5","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"70.4","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"57.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"58.3","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"48.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"45.2","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"57.1","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"51.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"29.4","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"45.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"44.8","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"55.4","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"36.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"72.7","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"34.9","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"48.0","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"34.5","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"39.2","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"58.2","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"57.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"83.3","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"69.8","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"56.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"44.1","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"38.0","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"37.5","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"46.2","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"68.2","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"46.5","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"37.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"66.5","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"52.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"83.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"47.8","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"44.8","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"48.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"76.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"69.1","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"56.3","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"42.4","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"54.9","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"52.7","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"53.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"84.0","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"30.7","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"63.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"55.9","isBolded":false,"associatedRows":["high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"71.9","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"47.6","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"36.6","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"26.9","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"70.9","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"46.6","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"35.6","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"29.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"55.2","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"85.1","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"34.7","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"25.9","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"51.5","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"82.6","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"57.9","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"48.5","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"83.9","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"74.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"36.5","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"91.7","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"37.0","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"33.3","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"37.6","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"25.4","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"51.7","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"49.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"41.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"73.6","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"49.4","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"35.1","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"56.1","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"76.8","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"45.6","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"62.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"49.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"46.2","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"28.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"46.4","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"28.6","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"42.9","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"26.5","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"40.9","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"30.2","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"91.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"64.9","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"29.6","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"60.3","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"36.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"76.3","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"50.3","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"39.1","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"69.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"87.1","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"59.6","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"51.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"52.4","isBolded":false,"associatedRows":["logical fallacies","management"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"29.4","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"31.2","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"60.1","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"81.5","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"57.5","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"24.8","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"25.8","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"77.1","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"59.4","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"43.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"74.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"70.6","isBolded":false,"associatedRows":["logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"42.2","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"50.9","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"44.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"82.8","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"60.1","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"45.6","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"59.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"35.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"23.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"23.8","isBolded":false,"associatedRows":["moral scenarios"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"61.6","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"31.3","isBolded":false,"associatedRows":["machine learning","logical fallacies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"34.5","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"39.5","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"33.5","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"35.5","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"60.1","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"59.5","isBolded":false,"associatedRows":["human sexuality","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"50.5","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"33.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"56.7","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"40.0","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"68.2","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"45.1","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"55.0","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"43.1","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"28.4","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"47.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"27.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"43.0","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"76.7","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"59.6","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"63.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"29.0","isBolded":false,"associatedRows":["college computer science","college chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"34.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"52.7","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"39.8","isBolded":false,"associatedRows":["high school us history","high school statistics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"32.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"90.9","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"78.6","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"63.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"40.9","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"59.8","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"51.8","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"31.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"28.1","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"42.8","isBolded":false,"associatedRows":["virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"65.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"34.9","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"63.1","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"61.1","isBolded":false,"associatedRows":["high school psychology","high school us history"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]},{"number":"73.1","isBolded":false,"associatedRows":["jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"30.7","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"60.1","isBolded":false,"associatedRows":["moral disputes"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"63.0","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"45.1","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"39.7","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"76.8","isBolded":false,"associatedRows":["moral scenarios","nutrition"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"42.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"72.2","isBolded":false,"associatedRows":["security studies"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","11B"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["college computer science"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"27.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","11B"],"associatedMergedColumns":[]},{"number":"83.8","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"85.4","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"46.1","isBolded":false,"associatedRows":["professional accounting"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"81.8","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","770M"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","770M"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","Full / Transfer","3B"],"associatedMergedColumns":[]},{"number":"28.4","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"54.5","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","770M"],"associatedMergedColumns":[]},{"number":"80.1","isBolded":false,"associatedRows":["world religions","virology"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"25.8","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","3B"],"associatedMergedColumns":[]},{"number":"69.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot ( multi - task )","11B"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for Atlas for each model size and each of the 57 domains","5 - shot","3B"],"associatedMergedColumns":[]}]},{"caption":"Table 17: MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57 \ndomains \n\n5-shot \n5-shot (multi-task) \nFull / Transfer \n\n770M 3B \n11B 770M 3B \n11B 770M 3B \n11B \nAll \n29.2 \n35.7 36.1 \n26.5 \n40.0 43.5 \n42.4 \n50.4 54.0 \n\nHumanities \n30.5 \n35.4 35.5 \n27.3 \n38.5 41.6 \n41.0 \n48.6 51.3 \nSocial Sciences \n29.7 \n38.0 39.4 \n24.8 \n43.8 48.9 \n48.6 \n57.8 64.7 \nSTEM \n29.0 \n31.4 30.8 \n26.5 \n32.8 35.8 \n33.4 \n40.6 41.7 \nOther \n26.7 \n37.7 38.6 \n27.0 \n45.0 48.5 \n46.8 \n55.2 59.1 \n\nabstract algebra \n26.0 \n23.0 21.0 \n29.0 \n30.0 26.0 \n23.0 \n29.0 26.0 \nanatomy \n21.5 \n40.0 40.7 \n27.4 \n39.3 45.9 \n35.6 \n43.7 42.2 \nastronomy \n37.5 \n38.8 37.5 \n27.6 \n39.5 41.4 \n36.2 \n50.7 55.3 \nbusiness ethics \n29.0 \n54.0 42.0 \n26.0 \n47.0 55.0 \n53.0 \n64.0 60.0 \nclinical knowledge \n32.5 \n33.6 40.0 \n28.7 \n44.2 47.9 \n45.3 \n52.8 57.7 \ncollege biology \n29.9 \n34.7 34.0 \n29.9 \n34.7 40.3 \n38.2 \n46.5 52.1 \ncollege chemistry \n37.0 \n22.0 32.0 \n20.0 \n35.0 33.0 \n36.0 \n34.0 36.0 \ncollege computer science \n28.0 \n35.0 34.0 \n28.0 \n27.0 36.0 \n31.0 \n44.0 35.0 \ncollege mathematics \n31.0 \n29.0 27.0 \n22.0 \n34.0 27.0 \n30.0 \n33.0 32.0 \ncollege medicine \n24.3 \n34.7 34.1 \n27.2 \n40.5 40.5 \n35.8 \n41.6 48.6 \ncollege physics \n33.3 \n23.5 23.5 \n22.5 \n19.6 26.5 \n22.5 \n32.4 24.5 \ncomputer security \n36.0 \n42.0 46.0 \n31.0 \n49.0 52.0 \n50.0 \n65.0 61.0 \nconceptual physics \n26.4 \n35.7 30.2 \n23.4 \n30.6 32.8 \n34.5 \n37.4 43.8 \neconometrics \n26.3 \n21.9 28.9 \n17.5 \n19.3 24.6 \n29.8 \n25.4 29.8 \nelectrical engineering \n31.0 \n33.1 31.7 \n31.0 \n31.0 36.6 \n41.4 \n47.6 51.7 \nelementary mathematics \n26.2 \n27.5 28.0 \n27.0 \n31.2 33.3 \n25.9 \n31.2 35.5 \nformal logic \n34.1 \n34.1 31.7 \n15.1 \n34.9 31.0 \n31.7 \n38.1 42.1 \nglobal facts \n32.0 \n30.0 25.0 \n34.0 \n34.0 27.0 \n28.0 \n34.0 30.0 \nhigh school biology \n22.6 \n31.9 29.7 \n27.1 \n41.6 50.0 \n43.5 \n57.7 60.6 \nhigh school chemistry \n27.1 \n26.6 27.6 \n28.6 \n31.5 29.1 \n30.5 \n36.5 38.9 \nhigh school computer science \n26.0 \n32.0 25.0 \n33.0 \n37.0 45.0 \n45.0 \n55.0 48.0 \nhigh school european history \n34.5 \n43.0 42.4 \n24.2 \n60.0 59.4 \n58.2 \n69.1 76.4 \nhigh school geography \n31.3 \n40.4 36.9 \n24.7 \n45.5 50.5 \n56.1 \n66.7 74.2 \nhigh school gov. and pol. \n28.0 \n49.2 51.3 \n19.2 \n56.0 59.6 \n55.4 \n70.5 75.6 \nhigh school macroeconomics \n25.6 \n37.7 32.1 \n26.7 \n42.3 43.6 \n41.0 \n51.5 56.4 \nhigh school mathematics \n35.9 \n35.2 35.9 \n28.1 \n26.7 31.1 \n27.8 \n36.7 31.9 \nhigh school microeconomics \n27.3 \n29.8 36.1 \n20.6 \n35.7 42.9 \n42.9 \n50.8 60.5 \nhigh school physics \n21.9 \n25.2 22.5 \n24.5 \n28.5 29.1 \n27.8 \n31.1 27.8 \nhigh school psychology \n26.1 \n46.4 51.0 \n24.8 \n54.3 60.2 \n56.3 \n67.3 76.1 \nhigh school statistics \n27.8 \n33.3 33.3 \n17.6 \n30.6 33.8 \n32.9 \n33.3 37.0 \nhigh school us history \n30.4 \n39.7 45.6 \n27.5 \n46.1 58.3 \n51.0 \n63.2 72.5 \nhigh school world history \n42.6 \n50.6 41.8 \n29.1 \n54.0 64.6 \n66.7 \n72.2 73.8 \nhuman aging \n28.3 \n37.2 29.6 \n26.0 \n45.3 46.2 \n46.6 \n57.0 62.8 \nhuman sexuality \n29.8 \n34.4 41.2 \n25.2 \n42.0 44.3 \n51.1 \n58.0 59.5 \ninternational law \n57.9 \n57.9 41.3 \n44.6 \n57.9 58.7 \n62.8 \n71.9 71.1 \njurisprudence \n30.6 \n33.3 34.3 \n32.4 \n49.1 52.8 \n55.6 \n67.6 74.1 \nlogical fallacies \n40.5 \n55.8 46.6 \n25.8 \n51.5 62.0 \n43.6 \n69.3 71.2 \nmachine learning \n33.0 \n34.8 36.6 \n29.5 \n35.7 37.5 \n32.1 \n37.5 42.9 \nmanagement \n21.4 \n29.1 40.8 \n24.3 \n47.6 50.5 \n60.2 \n69.9 70.9 \nmarketing \n38.9 \n58.5 60.7 \n31.2 \n67.9 75.6 \n69.2 \n79.9 85.9 \nmedical genetics \n26.0 \n36.0 36.0 \n29.0 \n43.0 44.0 \n40.0 \n54.0 50.0 \nmiscellaneous \n24.5 \n45.2 46.4 \n27.1 \n52.2 58.2 \n51.3 \n64.6 72.7 \nmoral disputes \n32.4 \n37.3 38.7 \n28.6 \n43.4 43.4 \n49.7 \n64.7 64.7 \nmoral scenarios \n24.7 \n24.7 24.7 \n23.0 \n23.9 24.7 \n23.8 \n24.0 23.8 \nnutrition \n30.1 \n33.0 34.6 \n25.8 \n42.5 44.1 \n50.3 \n55.6 61.1 \nphilosophy \n28.6 \n32.5 37.3 \n31.2 \n38.9 45.0 \n44.1 \n56.6 59.2 \nprehistory \n33.6 \n37.0 41.4 \n27.5 \n39.8 50.6 \n41.0 \n51.5 57.7 \nprofessional accounting \n21.3 \n28.0 30.5 \n25.9 \n35.5 34.0 \n37.2 \n41.5 42.2 \nprofessional law \n28.2 \n33.4 34.0 \n27.6 \n35.4 35.5 \n38.3 \n43.0 45.6 \nprofessional medicine \n19.5 \n26.5 24.3 \n20.2 \n32.0 37.9 \n38.6 \n40.8 46.0 \nprofessional psychology \n27.8 \n32.8 32.8 \n26.6 \n39.5 43.6 \n38.4 \n48.0 58.3 \npublic relations \n22.7 \n43.6 40.0 \n21.8 \n47.3 56.4 \n50.0 \n55.5 60.0 \nsecurity studies \n37.6 \n26.1 31.0 \n20.4 \n34.7 44.1 \n56.3 \n61.6 66.9 \nsociology \n43.3 \n41.8 38.8 \n30.8 \n45.8 52.7 \n60.2 \n66.7 72.1 \nus foreign policy \n49.0 \n57.0 66.0 \n38.0 \n56.0 61.0 \n59.0 \n75.0 76.0 \n","rows":["All","high school world history","college computer science","professional accounting","college physics","high school mathematics","high school statistics","formal logic","global facts","econometrics","clinical knowledge","international law","high school gov . and pol .","prehistory","professional medicine","world religions","business ethics","astronomy","philosophy","security studies","high school european history","college chemistry","nutrition","medical genetics","human aging","human sexuality","miscellaneous","anatomy","conceptual physics","sociology","electrical engineering","jurisprudence","public relations","professional psychology","elementary mathematics","abstract algebra","college mathematics","logical fallacies","high school macroeconomics","Humanities","Social Sciences","high school computer science","high school chemistry","high school psychology","machine learning","STEM","moral scenarios","computer security","marketing","high school us history","college biology","management","virology","college medicine","professional law","high school geography","moral disputes","us foreign policy","high school microeconomics","high school physics","high school biology","Other"],"columns":["5 - shot","MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","11B","770M","5 - shot ( multi - task )","Full / Transfer","3B"],"mergedAllColumns":["domains"],"numberCells":[{"number":"41.0","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"22.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"61.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"38.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"35.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"36.7","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"24.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"25.9","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"55.3","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"76.1","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"29.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"40.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"64.7","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"48.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"36.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"38.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"38.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"43.3","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"57.9","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"47.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.4","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"23.4","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"31.5","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"71.9","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"40.3","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"44.1","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"47.4","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"30.1","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"54.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"38.9","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"48.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"30.6","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"31.2","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.3","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"58.7","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"57.7","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"33.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"22.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"27.3","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"35.2","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"28.2","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"27.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"30.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"22.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"40.5","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"42.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"42.9","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"59.6","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"37.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"42.9","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"20.2","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"45.3","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"50.0","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"41.4","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"67.3","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"60.2","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"29.8","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"24.6","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"58.5","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"37.2","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"50.5","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"66.7","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"41.5","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"29.8","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"38.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"45.8","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.6","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"45.3","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"71.2","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"60.2","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"37.0","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"69.1","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"42.2","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"40.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"27.1","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"24.3","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"34.1","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"50.0","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"73.8","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"67.6","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"17.6","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"40.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"24.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"58.0","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"33.6","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"66.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"28.7","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"43.5","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"40.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"41.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"60.0","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"43.6","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"79.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"30.4","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"57.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"40.8","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"30.6","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"41.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"29.1","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"15.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"58.3","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"45.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"37.3","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"41.4","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"85.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"30.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"54.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"35.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"30.5","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"25.2","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"29.1","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"30.1","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"27.8","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"27.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"62.8","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"41.6","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"70.5","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"26.6","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"27.5","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"34.3","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"37.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"35.8","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"56.4","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"49.1","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"69.9","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"56.3","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"26.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"29.5","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"32.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"43.6","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"47.6","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"50.3","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"27.1","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"64.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"38.3","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"20.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"69.3","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"28.6","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"34.5","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"32.1","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"32.5","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"46.6","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"43.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"29.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"55.5","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"49.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"30.2","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"26.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"29.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"59.4","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"38.9","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"70.9","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"27.8","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"28.3","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"45.2","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"37.2","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"47.9","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"62.8","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"31.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"43.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"58.3","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"23.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"59.2","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"29.2","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"60.7","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"47.3","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"76.4","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"21.8","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"26.7","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"42.6","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"19.5","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"31.1","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"38.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"45.5","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"25.9","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"40.9","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"24.5","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"40.0","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"34.7","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"57.9","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"37.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"57.3","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"42.2","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"31.1","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"26.1","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"26.5","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"32.5","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"39.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"51.5","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"42.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"34.6","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"58.2","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"32.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"72.1","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"26.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"34.9","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"41.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"27.8","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"32.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"42.9","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"46.0","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"43.0","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"43.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"36.1","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"48.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"66.9","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"41.6","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"34.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"64.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"37.5","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"37.9","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"60.5","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"28.6","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"32.8","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"38.4","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"23.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"57.7","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"31.2","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"37.7","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"22.7","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"45.0","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"33.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"21.3","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"50.5","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"32.8","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"32.1","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"37.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"25.4","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"32.9","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"29.1","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"31.2","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"60.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"35.7","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"45.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"51.3","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"44.2","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"41.2","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"22.5","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"59.1","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"25.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"54.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"35.9","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"56.0","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"23.9","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"33.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"60.0","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"55.2","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"64.7","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"21.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"61.6","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"32.4","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"35.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"50.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"29.6","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"56.6","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"46.2","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"43.6","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"57.9","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"44.1","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"63.7","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"28.6","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"36.9","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"41.0","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"24.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"67.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"57.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"36.1","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"72.5","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"23.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.5","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"58.2","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"32.4","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"25.2","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"29.1","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"36.5","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"20.6","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"31.7","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"40.7","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"56.4","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"52.2","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"37.0","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"24.2","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"51.5","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"76.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"33.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"50.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"50.6","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"31.7","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"38.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"51.0","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"35.7","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"35.7","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"24.3","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"21.4","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"43.4","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"50.7","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"31.9","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"42.3","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"56.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"48.9","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"69.2","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"22.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"46.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"32.7","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"30.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"34.7","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"47.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"51.0","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"40.8","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"34.5","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"30.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"66.7","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"56.1","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"49.7","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"48.0","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"75.6","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"27.8","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"33.0","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"32.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"50.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"42.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"48.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"27.6","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"38.8","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"54.0","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"31.4","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"39.3","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"41.4","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"39.5","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"33.1","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"52.7","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"21.9","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"23.8","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"31.2","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"44.6","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"51.3","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"41.8","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"55.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"34.7","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"34.8","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"39.8","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"19.6","isBolded":false,"associatedRows":["elementary mathematics","college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"19.2","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"35.9","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"55.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"31.3","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"38.8","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"49.1","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"39.7","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"23.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"74.1","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"32.4","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"25.8","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"19.3","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"61.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"55.4","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"46.6","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"35.5","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"53.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"31.9","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"64.6","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"49.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"27.5","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"48.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"48.0","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"34.3","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"32.0","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"44.1","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"37.3","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"46.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"51.3","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"44.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"42.5","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"26.2","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"40.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"37.6","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"23.0","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"46.1","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"50.6","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"27.6","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"34.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"33.8","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"52.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"52.8","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"20.4","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"43.0","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"30.8","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"26.1","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"59.5","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"39.5","isBolded":false,"associatedRows":["elementary mathematics","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"72.7","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"52.8","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"41.6","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"52.1","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"50.8","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"63.2","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"37.4","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"28.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"41.3","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"60.6","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"21.9","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"36.1","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"49.2","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"40.0","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"30.5","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"24.0","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"37.5","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"30.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"40.4","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"29.8","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"62.0","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"34.7","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"57.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"55.6","isBolded":false,"associatedRows":["high school world history","jurisprudence"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"23.8","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"37.0","isBolded":false,"associatedRows":["elementary mathematics","college chemistry","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"66.7","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"27.6","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"33.0","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"61.1","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"33.3","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"55.8","isBolded":false,"associatedRows":["medical genetics","logical fallacies"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"33.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"35.7","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"29.9","isBolded":false,"associatedRows":["elementary mathematics","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"27.8","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"34.4","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"65.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"36.6","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"44.0","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"28.9","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"75.6","isBolded":false,"associatedRows":["high school macroeconomics","high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"25.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"27.5","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"45.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"59.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"51.1","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"34.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"42.4","isBolded":false,"associatedRows":["high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"57.0","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"31.0","isBolded":false,"associatedRows":["elementary mathematics","college mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"51.5","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"43.6","isBolded":false,"associatedRows":["public relations","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"56.3","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"26.5","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"70.2","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"72.2","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"29.8","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"64.6","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"44.3","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"44.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"27.1","isBolded":false,"associatedRows":["high school chemistry","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"51.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"24.3","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"38.7","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"24.7","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"32.8","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"43.8","isBolded":false,"associatedRows":["elementary mathematics","conceptual physics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"45.6","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"21.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"25.8","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"36.6","isBolded":false,"associatedRows":["machine learning","medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"45.6","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"46.0","isBolded":false,"associatedRows":["elementary mathematics","computer security","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"17.5","isBolded":false,"associatedRows":["elementary mathematics","econometrics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"45.0","isBolded":false,"associatedRows":["high school computer science","high school european history","high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"33.6","isBolded":false,"associatedRows":["elementary mathematics","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"41.8","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"30.6","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"38.6","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"27.2","isBolded":false,"associatedRows":["elementary mathematics","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"25.6","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"22.6","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"42.0","isBolded":false,"associatedRows":["high school world history","human sexuality"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"29.5","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"74.2","isBolded":false,"associatedRows":["high school macroeconomics","high school geography"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"24.0","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"46.4","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"35.6","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"38.1","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"39.8","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"36.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"30.5","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","770M"],"associatedMergedColumns":["domains"]},{"number":"28.1","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"27.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","11B"],"associatedMergedColumns":["domains"]},{"number":"46.4","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"26.7","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"32.8","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"42.0","isBolded":false,"associatedRows":["elementary mathematics","business ethics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","11B"],"associatedMergedColumns":["domains"]},{"number":"24.8","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"40.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"71.1","isBolded":false,"associatedRows":["high school world history","international law"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]},{"number":"46.4","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"43.4","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"29.0","isBolded":false,"associatedRows":["elementary mathematics","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"75.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"28.0","isBolded":false,"associatedRows":["college computer science","college medicine"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","770M"],"associatedMergedColumns":["domains"]},{"number":"24.7","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot","3B"],"associatedMergedColumns":["domains"]},{"number":"55.6","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"43.7","isBolded":false,"associatedRows":["elementary mathematics","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","3B"],"associatedMergedColumns":["domains"]},{"number":"54.3","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","5 - shot ( multi - task )","3B"],"associatedMergedColumns":["domains"]},{"number":"60.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","770M"],"associatedMergedColumns":["domains"]},{"number":"35.5","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the T5 closed book baseline for each model size and each of the 57","Full / Transfer","11B"],"associatedMergedColumns":["domains"]}]},{"caption":"Table 18: MMLU Test set scores for the de-biased Atlas-XXL using cyclic permutations for each of the 57 \ndomains for zero-shot, 5 shot, 5-shot-multitask and the transfer setting \n\nDomain \nzero-shot \n5-shot \n5-shot (multi-task) Full / Transfer \n\nAll \n47.1 \n47.9 \n56.6 \n66.0 \n\nHumanities \n43.6 \n46.1 \n50.1 \n61.1 \nSocial Sciences \n54.1 \n54.6 \n66.4 \n77.2 \nSTEM \n38.0 \n38.8 \n46.4 \n53.2 \nOther \n53.9 \n52.8 \n66.2 \n74.4 \n\nabstract algebra \n22.0 \n26.0 \n31.0 \n31.0 \nanatomy \n48.9 \n47.4 \n62.2 \n70.4 \nastronomy \n61.8 \n62.5 \n68.4 \n81.6 \nbusiness ethics \n60.0 \n57.0 \n62.0 \n70.0 \nclinical knowledge \n50.6 \n49.4 \n66.4 \n72.8 \ncollege biology \n51.4 \n53.5 \n61.1 \n77.8 \ncollege chemistry \n36.0 \n39.0 \n39.0 \n45.0 \ncollege computer science \n32.0 \n32.0 \n33.0 \n49.0 \ncollege mathematics \n30.0 \n35.0 \n35.0 \n34.0 \ncollege medicine \n44.5 \n41.0 \n52.6 \n67.6 \ncollege physics \n24.5 \n26.5 \n37.3 \n42.2 \ncomputer security \n59.0 \n59.0 \n68.0 \n76.0 \nconceptual physics \n37.0 \n41.3 \n57.0 \n60.0 \neconometrics \n20.2 \n20.2 \n36.8 \n37.7 \nelectrical engineering \n37.9 \n40.0 \n50.3 \n65.5 \nelementary mathematics \n31.2 \n28.0 \n30.7 \n36.5 \nformal logic \n27.8 \n27.0 \n32.5 \n35.7 \nglobal facts \n41.0 \n43.0 \n51.0 \n53.0 \nhigh school biology \n53.2 \n56.5 \n68.7 \n83.2 \nhigh school chemistry \n41.9 \n41.4 \n49.3 \n51.2 \nhigh school computer science \n40.0 \n36.0 \n46.0 \n60.0 \nhigh school european history \n56.4 \n58.8 \n68.5 \n80.6 \nhigh school geography \n57.1 \n59.6 \n71.2 \n81.3 \nhigh school gov. and pol. \n67.9 \n67.9 \n77.2 \n90.2 \nhigh school macroeconomics \n46.9 \n48.5 \n57.9 \n65.9 \nhigh school mathematics \n28.1 \n28.9 \n34.1 \n31.5 \nhigh school microeconomics \n51.7 \n51.7 \n68.9 \n82.4 \nhigh school physics \n26.5 \n25.8 \n32.5 \n41.1 \nhigh school psychology \n66.2 \n65.5 \n78.9 \n86.8 \nhigh school statistics \n31.5 \n30.1 \n43.1 \n45.8 \nhigh school us history \n57.8 \n54.9 \n64.7 \n77.5 \nhigh school world history \n59.1 \n62.9 \n65.4 \n79.3 \nhuman aging \n48.4 \n50.7 \n60.5 \n70.4 \nhuman sexuality \n55.7 \n54.2 \n61.8 \n84.0 \ninternational law \n66.1 \n72.7 \n71.9 \n84.3 \njurisprudence \n61.1 \n64.8 \n72.2 \n81.5 \nlogical fallacies \n54.6 \n57.7 \n71.2 \n77.9 \nmachine learning \n37.5 \n39.3 \n43.8 \n44.6 \nmanagement \n56.3 \n56.3 \n79.6 \n89.3 \nmarketing \n72.2 \n73.1 \n84.6 \n91.9 \nmedical genetics \n55.0 \n58.0 \n71.0 \n81.0 \nmiscellaneous \n69.7 \n67.8 \n83.8 \n90.4 \nmoral disputes \n45.1 \n46.8 \n60.1 \n72.3 \nmoral scenarios \n24.5 \n30.3 \n25.8 \n38.5 \nnutrition \n56.5 \n53.9 \n67.0 \n77.1 \nphilosophy \n56.3 \n57.6 \n70.7 \n77.2 \nprehistory \n59.3 \n60.5 \n71.6 \n78.7 \nprofessional accounting \n35.1 \n33.0 \n42.2 \n50.7 \nprofessional law \n36.3 \n38.4 \n39.4 \n51.7 \nprofessional medicine \n35.7 \n33.1 \n52.2 \n60.7 \nprofessional psychology \n47.7 \n49.3 \n60.9 \n74.0 \npublic relations \n54.5 \n53.6 \n68.2 \n68.2 \nsecurity studies \n47.3 \n45.7 \n59.2 \n73.9 \nsociology \n62.2 \n62.7 \n71.6 \n84.6 \nus foreign policy \n64.0 \n68.0 \n73.0 \n83.0 \nvirology \n39.8 \n40.4 \n44.6 \n51.8 \n","rows":["All","high school world history","college computer science","professional accounting","college physics","high school mathematics","high school statistics","formal logic","global facts","econometrics","clinical knowledge","international law","high school gov . and pol .","prehistory","professional medicine","world religions","business ethics","astronomy","philosophy","security studies","high school european history","college chemistry","nutrition","medical genetics","human aging","human sexuality","miscellaneous","anatomy","conceptual physics","sociology","electrical engineering","jurisprudence","public relations","professional psychology","abstract algebra","elementary mathematics","college mathematics","logical fallacies","high school macroeconomics","Humanities","Social Sciences","high school computer science","high school chemistry","high school psychology","machine learning","STEM","moral scenarios","computer security","marketing","high school us history","college biology","management","virology","college medicine","professional law","high school geography","moral disputes","us foreign policy","high school microeconomics","high school physics","high school biology","Other"],"columns":["5 - shot","MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot","5 - shot ( multi - task )","Full / Transfer"],"mergedAllColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"],"numberCells":[{"number":"51.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"61.1","isBolded":false,"associatedRows":["college computer science","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.3","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"49.3","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.2","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"46.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"43.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.5","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"37.7","isBolded":false,"associatedRows":["econometrics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.4","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.6","isBolded":false,"associatedRows":["college computer science","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"37.9","isBolded":false,"associatedRows":["electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"25.8","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"32.0","isBolded":false,"associatedRows":["college computer science","college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"30.7","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.6","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"46.1","isBolded":false,"associatedRows":["college computer science","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"38.8","isBolded":false,"associatedRows":["college computer science","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.7","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"47.9","isBolded":false,"associatedRows":["college computer science","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.4","isBolded":false,"associatedRows":["college computer science","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"61.8","isBolded":false,"associatedRows":["college computer science","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.0","isBolded":false,"associatedRows":["conceptual physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"55.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"34.0","isBolded":false,"associatedRows":["college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"48.5","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.0","isBolded":false,"associatedRows":["conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.0","isBolded":false,"associatedRows":["college computer science","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.2","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.2","isBolded":false,"associatedRows":["college computer science","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"46.4","isBolded":false,"associatedRows":["college computer science","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"44.6","isBolded":false,"associatedRows":["machine learning","international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"36.3","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"80.6","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"74.0","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.7","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"67.6","isBolded":false,"associatedRows":["college medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"67.9","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"84.6","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.9","isBolded":false,"associatedRows":["international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.7","isBolded":false,"associatedRows":["international law","logical fallacies"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.4","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.3","isBolded":false,"associatedRows":["conceptual physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.2","isBolded":false,"associatedRows":["international law","human sexuality"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"33.0","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"42.2","isBolded":false,"associatedRows":["college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"33.1","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.6","isBolded":false,"associatedRows":["international law","logical fallacies"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"43.6","isBolded":false,"associatedRows":["college computer science","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"47.4","isBolded":false,"associatedRows":["college computer science","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.9","isBolded":false,"associatedRows":["international law","logical fallacies"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"58.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"64.7","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"78.7","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"38.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","STEM"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"42.2","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.9","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"46.9","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"35.0","isBolded":false,"associatedRows":["college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"72.3","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"26.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.5","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"39.3","isBolded":false,"associatedRows":["machine learning","international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"48.4","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.2","isBolded":false,"associatedRows":["college computer science","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.5","isBolded":false,"associatedRows":["college computer science","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"45.1","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"28.9","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"74.9","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.0","isBolded":false,"associatedRows":["conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"40.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.0","isBolded":false,"associatedRows":["electrical engineering","global facts"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.7","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"83.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"84.6","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"50.1","isBolded":false,"associatedRows":["college computer science","abstract algebra","Humanities"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"31.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.2","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.0","isBolded":false,"associatedRows":["college medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.1","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"32.5","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"26.5","isBolded":false,"associatedRows":["college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.6","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"47.7","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"78.9","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.0","isBolded":false,"associatedRows":["conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"34.1","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"40.4","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"49.0","isBolded":false,"associatedRows":["college computer science","college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"32.5","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"81.0","isBolded":false,"associatedRows":["medical genetics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"72.2","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"32.0","isBolded":false,"associatedRows":["college computer science","college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.8","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"36.0","isBolded":false,"associatedRows":["college computer science","college mathematics","college chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"49.3","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"40.0","isBolded":false,"associatedRows":["electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"61.8","isBolded":false,"associatedRows":["international law","human sexuality"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"67.9","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.0","isBolded":false,"associatedRows":["conceptual physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.0","isBolded":false,"associatedRows":["college computer science","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.7","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"70.7","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"38.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"61.1","isBolded":false,"associatedRows":["college computer science","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"25.8","isBolded":false,"associatedRows":["high school microeconomics","high school physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"26.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"72.8","isBolded":false,"associatedRows":["college computer science","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"80.7","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.2","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"79.3","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"47.1","isBolded":false,"associatedRows":["college computer science","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"37.3","isBolded":false,"associatedRows":["college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"81.5","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"35.7","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"33.0","isBolded":false,"associatedRows":["college computer science","college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"73.9","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.8","isBolded":false,"associatedRows":["college computer science","business ethics","college biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"86.8","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"70.4","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.5","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"67.8","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"30.0","isBolded":false,"associatedRows":["college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"76.0","isBolded":false,"associatedRows":["conceptual physics","computer security"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.1","isBolded":false,"associatedRows":["international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"69.7","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"24.5","isBolded":false,"associatedRows":["college medicine","college physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.2","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.2","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.9","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.3","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"70.4","isBolded":false,"associatedRows":["college computer science","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.4","isBolded":false,"associatedRows":["college computer science","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"39.0","isBolded":false,"associatedRows":["college computer science","college mathematics","college chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"52.2","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"24.5","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.5","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"37.5","isBolded":false,"associatedRows":["machine learning","international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"65.4","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"65.5","isBolded":false,"associatedRows":["high school microeconomics","high school psychology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"81.6","isBolded":false,"associatedRows":["college computer science","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"61.1","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"48.9","isBolded":false,"associatedRows":["college computer science","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"50.6","isBolded":false,"associatedRows":["college computer science","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"43.1","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"20.2","isBolded":false,"associatedRows":["econometrics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"37.0","isBolded":false,"associatedRows":["conceptual physics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.7","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.5","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"35.7","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.6","isBolded":false,"associatedRows":["college computer science","abstract algebra","All"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.1","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"43.8","isBolded":false,"associatedRows":["machine learning","international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"83.8","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.2","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.2","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.2","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"64.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"82.4","isBolded":false,"associatedRows":["high school microeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"65.9","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"87.1","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"39.4","isBolded":false,"associatedRows":["professional medicine","professional law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"36.8","isBolded":false,"associatedRows":["econometrics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"52.8","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"56.3","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"73.0","isBolded":false,"associatedRows":["us foreign policy","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"52.6","isBolded":false,"associatedRows":["college medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"45.8","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"51.8","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"39.0","isBolded":false,"associatedRows":["college computer science","college mathematics","college chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"45.0","isBolded":false,"associatedRows":["college computer science","college mathematics","college chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"65.5","isBolded":false,"associatedRows":["electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"50.7","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"49.4","isBolded":false,"associatedRows":["college computer science","clinical knowledge","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"90.2","isBolded":false,"associatedRows":["high school gov . and pol ."],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.6","isBolded":false,"associatedRows":["philosophy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"72.2","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"50.3","isBolded":false,"associatedRows":["electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.7","isBolded":false,"associatedRows":["professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"28.0","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.9","isBolded":false,"associatedRows":["high school macroeconomics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"47.3","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"41.9","isBolded":false,"associatedRows":["high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"44.5","isBolded":false,"associatedRows":["college medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"31.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"67.0","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"79.6","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.2","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.5","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.6","isBolded":false,"associatedRows":["sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"72.7","isBolded":false,"associatedRows":["international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"68.4","isBolded":false,"associatedRows":["college computer science","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"20.2","isBolded":false,"associatedRows":["econometrics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"46.8","isBolded":false,"associatedRows":["moral disputes","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"39.8","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"31.5","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"44.6","isBolded":false,"associatedRows":["sociology","virology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"71.2","isBolded":false,"associatedRows":["international law","logical fallacies"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"30.3","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"58.8","isBolded":false,"associatedRows":["high school european history","high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"91.9","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"45.7","isBolded":false,"associatedRows":["security studies","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"74.4","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"35.1","isBolded":false,"associatedRows":["professional accounting","prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.5","isBolded":false,"associatedRows":["college computer science","business ethics","astronomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"55.7","isBolded":false,"associatedRows":["international law","human sexuality"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"54.1","isBolded":false,"associatedRows":["college computer science","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"31.2","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.2","isBolded":false,"associatedRows":["college computer science","business ethics","anatomy"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"35.0","isBolded":false,"associatedRows":["college mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"31.5","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"36.5","isBolded":false,"associatedRows":["elementary mathematics","electrical engineering"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.5","isBolded":false,"associatedRows":["high school world history","high school us history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"62.9","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"50.7","isBolded":false,"associatedRows":["high school world history","human aging"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"64.8","isBolded":false,"associatedRows":["international law","jurisprudence"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"27.8","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"90.4","isBolded":false,"associatedRows":["miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.0","isBolded":false,"associatedRows":["college computer science","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.1","isBolded":false,"associatedRows":["high school world history"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.2","isBolded":false,"associatedRows":["world religions","sociology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"73.1","isBolded":false,"associatedRows":["medical genetics","marketing"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"59.3","isBolded":false,"associatedRows":["prehistory"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"30.1","isBolded":false,"associatedRows":["high school world history","high school statistics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"89.3","isBolded":false,"associatedRows":["medical genetics","management"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.9","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"83.2","isBolded":false,"associatedRows":["electrical engineering","high school biology"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"28.1","isBolded":false,"associatedRows":["high school microeconomics","high school mathematics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"60.9","isBolded":false,"associatedRows":["professional psychology","professional medicine"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"84.0","isBolded":false,"associatedRows":["international law","human sexuality"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"77.1","isBolded":false,"associatedRows":["philosophy","nutrition"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"27.0","isBolded":false,"associatedRows":["electrical engineering","formal logic"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"70.0","isBolded":false,"associatedRows":["college computer science","business ethics"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"57.1","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.9","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"66.4","isBolded":false,"associatedRows":["college computer science","abstract algebra","Social Sciences"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot ( multi - task )"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"22.0","isBolded":false,"associatedRows":["college computer science","abstract algebra","Other"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","zero - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"36.0","isBolded":false,"associatedRows":["high school computer science","high school gov . and pol .","high school chemistry"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"53.6","isBolded":false,"associatedRows":["public relations"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","5 - shot"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"81.3","isBolded":false,"associatedRows":["high school gov . and pol .","high school geography"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"84.3","isBolded":false,"associatedRows":["international law"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]},{"number":"38.5","isBolded":false,"associatedRows":["moral scenarios","miscellaneous"],"associatedColumns":["MMLU Test set scores for the de - biased Atlas - XXL using cyclic permutations for each of the 57","Full / Transfer"],"associatedMergedColumns":["domains for zero - shot , 5 shot , 5 - shot - multitask and the transfer setting"]}]},{"caption":"Table 19: Impact of model size on question answering datasets. We report exact match performance \non the test sets of NaturalQuestions and TriviaQA filtered depending on the number of parameters in the \nreader module. For these experiments the index contains the December 2018 Wikipedia dump. \n\n","rows":["TriviaQA 64 - shot","NaturalQuestions 64 - shot","TriviaQA full","NaturalQuestions full"],"columns":["11B","770M","220M","3B"],"mergedAllColumns":[],"numberCells":[{"number":"54.1","isBolded":false,"associatedRows":["NaturalQuestions full"],"associatedColumns":["220M"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["TriviaQA 64 - shot"],"associatedColumns":["220M"],"associatedMergedColumns":[]},{"number":"65.0","isBolded":false,"associatedRows":["TriviaQA 64 - shot"],"associatedColumns":["770M"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":false,"associatedRows":["TriviaQA 64 - shot"],"associatedColumns":["3B"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["NaturalQuestions 64 - shot"],"associatedColumns":["3B"],"associatedMergedColumns":[]},{"number":"71.4","isBolded":false,"associatedRows":["TriviaQA 64 - shot"],"associatedColumns":["11B"],"associatedMergedColumns":[]},{"number":"60.8","isBolded":false,"associatedRows":["NaturalQuestions full"],"associatedColumns":["770M"],"associatedMergedColumns":[]},{"number":"74.9","isBolded":false,"associatedRows":["TriviaQA full"],"associatedColumns":["770M"],"associatedMergedColumns":[]},{"number":"27.0","isBolded":false,"associatedRows":["NaturalQuestions 64 - shot"],"associatedColumns":["220M"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["NaturalQuestions full"],"associatedColumns":["11B"],"associatedMergedColumns":[]},{"number":"35.4","isBolded":false,"associatedRows":["NaturalQuestions 64 - shot"],"associatedColumns":["770M"],"associatedMergedColumns":[]},{"number":"77.5","isBolded":false,"associatedRows":["TriviaQA full"],"associatedColumns":["3B"],"associatedMergedColumns":[]},{"number":"78.0","isBolded":false,"associatedRows":["TriviaQA full"],"associatedColumns":["11B"],"associatedMergedColumns":[]},{"number":"45.0","isBolded":false,"associatedRows":["NaturalQuestions 64 - shot"],"associatedColumns":["11B"],"associatedMergedColumns":[]},{"number":"63.4","isBolded":false,"associatedRows":["NaturalQuestions full"],"associatedColumns":["3B"],"associatedMergedColumns":[]},{"number":"71.8","isBolded":false,"associatedRows":["TriviaQA full"],"associatedColumns":["220M"],"associatedMergedColumns":[]}]},{"caption":"Number of parameters \n220M 770M 3B \n11B \n\nNaturalQuestions 64-shot \n27.0 \n35.4 \n41.3 45.0 \nNaturalQuestions full \n54.1 \n60.8 \n63.4 64.0 \n\nTriviaQA 64-shot \n55.3 \n65.0 \n70.2 71.4 \nTriviaQA full \n71.8 \n74.9 \n77.5 78.0 \n\nTable 20: Downstream results on KILT dev sets. \n\n","rows":["Atlas 64 - shot","Atlas full dataset"],"columns":["acc","NQ","HoPo","zsRE","TQA","FEV","T - REx","em","AIDA","f1","WoW"],"mergedAllColumns":["Model"],"numberCells":[{"number":"92.7","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["AIDA","acc"],"associatedMergedColumns":["Model"]},{"number":"60.2","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["zsRE","acc"],"associatedMergedColumns":["Model"]},{"number":"84.4","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["TQA","em"],"associatedMergedColumns":["Model"]},{"number":"63.4","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["NQ","em"],"associatedMergedColumns":["Model"]},{"number":"94.4","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["FEV","acc"],"associatedMergedColumns":["Model"]},{"number":"84.8","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["T - REx","acc"],"associatedMergedColumns":["Model"]},{"number":"80.9","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["zsRE","acc"],"associatedMergedColumns":["Model"]},{"number":"88.1","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["FEV","acc"],"associatedMergedColumns":["Model"]},{"number":"69.0","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["AIDA","acc"],"associatedMergedColumns":["Model"]},{"number":"58.5","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["T - REx","acc"],"associatedMergedColumns":["Model"]},{"number":"77.1","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["TQA","em"],"associatedMergedColumns":["Model"]},{"number":"15.4","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["WoW","f1"],"associatedMergedColumns":["Model"]},{"number":"44.2","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["NQ","em"],"associatedMergedColumns":["Model"]},{"number":"34.1","isBolded":false,"associatedRows":["Atlas 64 - shot"],"associatedColumns":["HoPo","em"],"associatedMergedColumns":["Model"]},{"number":"51.4","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["HoPo","em"],"associatedMergedColumns":["Model"]},{"number":"21.0","isBolded":false,"associatedRows":["Atlas full dataset"],"associatedColumns":["WoW","f1"],"associatedMergedColumns":["Model"]}]}]