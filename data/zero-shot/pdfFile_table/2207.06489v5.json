[{"caption":"Table 2. The autoencoder adds additional feed-\nback to the segmentation architecture by computing reconstruction loss between \nthe segmentation architecture\u0027s output and ground truth. This adds some extra \ntime during training but the space of saved model and inference time remain \nconstant when compared to networks without the autoencoder post-processing \narchitecture. \n\n","rows":["2","in","the tiles in the center portion . While for the bottom image tilled in","tiling while bottom one shows"],"columns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"mergedAllColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"],"numberCells":[{"number":"480image","isBolded":false,"associatedRows":["the tiles in the center portion . While for the bottom image tilled in"],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]},{"number":"256by","isBolded":false,"associatedRows":["in"],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]},{"number":"256imagesize,therightbottomtilesarealmostallempty.Includingsomeof","isBolded":false,"associatedRows":["in","2"],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]},{"number":"480by","isBolded":false,"associatedRows":["the tiles in the center portion . While for the bottom image tilled in"],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]},{"number":"256","isBolded":false,"associatedRows":[],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]},{"number":"4802tiling.Aswecanseeforthetopimagetilled","isBolded":false,"associatedRows":["in","2","tiling while bottom one shows"],"associatedColumns":["Fig . 3 . Changing the image tiling reduces the number of blank tiles which are mostly"],"associatedMergedColumns":["concentrated towards the edges and some of the intermediate tiles . Top images shows"]}]},{"caption":"Table 1. This table shows training time for UNet with and without APP for ResNet \nfamily of encoders for 50 epochs. We observed that for smaller encoders like ResNet-18 \nand 34 the training time increase is greater as opposed to larger encoders. \n\n","rows":["and"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"34thetrainingtimeincreaseisgreaterasopposedtolargerencoders.","isBolded":false,"associatedRows":["and"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 2. This table shows the IoU score on test set for UNet and UNet++ architectures \nwith and without using cosine learning rate for the autoencoder. Except for ResNet-18 \nand 101 with UNet++, autoencoder always provide an improvement without cosine \nlearning rate. \n\n","rows":["Resnet 18","Resnet 50","Resnet 101","Resnet 34"],"columns":["AE","Encoder","Without","GELU","ReLU","UNet++","With","UNet"],"mergedAllColumns":[],"numberCells":[{"number":"0.4774","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["Encoder","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.3827","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["UNet","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4311","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4187","isBolded":true,"associatedRows":["Resnet 50"],"associatedColumns":["UNet","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4402","isBolded":true,"associatedRows":["Resnet 101"],"associatedColumns":["UNet","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4265","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["UNet++","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.3718","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["Encoder","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4347","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["Encoder","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4707","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.5274","isBolded":true,"associatedRows":["Resnet 18"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4983","isBolded":true,"associatedRows":["Resnet 34"],"associatedColumns":["UNet","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4608","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["UNet","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.3798","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["Encoder","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4074","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["UNet","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4467","isBolded":true,"associatedRows":["Resnet 101"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4535","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["UNet++","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.3745","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4422","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4678","isBolded":true,"associatedRows":["Resnet 34"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4236","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["UNet++","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4685","isBolded":true,"associatedRows":["Resnet 50"],"associatedColumns":["UNet++","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4177","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["UNet++","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4467","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["UNet","With","Without","ReLU","AE","AE"],"associatedMergedColumns":[]},{"number":"0.4788","isBolded":true,"associatedRows":["Resnet 18"],"associatedColumns":["UNet","With","Without","GELU","AE","AE"],"associatedMergedColumns":[]}]},{"caption":"Table 3. This table shows the IoU score on test set for UNet and UNet++ archi-\ntectures. We compared results without, with autoencoder for both ReLU and GELU \nactivations. Except for ResNet-18 with UNet++, autoencoder always provide an im-\nprovement. Within autoencoders we see that using GELU activation is much better \nthan ReLU activation. \n\n","rows":["Resnet 18","Resnet 50","Resnet 101","Resnet 34"],"columns":["With Cosine","Without","LR","UNet++","UNet","Cosine"],"mergedAllColumns":[],"numberCells":[{"number":"0.3665","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.3846","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4265","isBolded":false,"associatedRows":["Resnet 101"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.3965","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4608","isBolded":true,"associatedRows":["Resnet 18"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4187","isBolded":true,"associatedRows":["Resnet 50"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4467","isBolded":true,"associatedRows":["Resnet 34"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4177","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4106","isBolded":false,"associatedRows":["Resnet 18"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4535","isBolded":true,"associatedRows":["Resnet 34"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4345","isBolded":false,"associatedRows":["Resnet 34"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4717","isBolded":true,"associatedRows":["Resnet 18"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4685","isBolded":true,"associatedRows":["Resnet 50"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4074","isBolded":true,"associatedRows":["Resnet 101"],"associatedColumns":["UNet","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4268","isBolded":false,"associatedRows":["Resnet 50"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]},{"number":"0.4518","isBolded":true,"associatedRows":["Resnet 101"],"associatedColumns":["UNet++","Without","With Cosine","Cosine","LR","LR"],"associatedMergedColumns":[]}]},{"caption":"Table 4. We report the F1 score for with ImageNet initialization for latest set of \nCNNs and Transformers. We observed the usual trend of increasing ImageNet perfor-\nmance with increasing size of the model is not followed. Overall the best performance \nis achieved by nfnet-f3 for CNNs. Overall, out of all the tested architectures Swin \nTransformer Base with Patch 4 and Window 12 performed the best \n\n","rows":["( Patch"],"columns":["Efficient - net B3","Efficient - net B4","Efficient - net B1","Efficient - net B2","Resnet - 18","Efficient - net B0","Resnet - 50","nfnet - f3","Resnet - 101","nfnet - f2","nfnet - f1","nfnet - f0","ConvNext - large","Efficient - net B7","nfnet - f6","Resnet - 34","Efficient - net B5","nfnet - f5","Efficient - net B6","nfnet - f4","ConvNext - base","ConvNext - small","ConvNext - tiny"],"mergedAllColumns":["Swin Transformer large","Swin Transformer Base"],"numberCells":[{"number":"4Window12)","isBolded":false,"associatedRows":["( Patch"],"associatedColumns":["Resnet - 18","Resnet - 34","Resnet - 50","Resnet - 101","Efficient - net B0","Efficient - net B1","Efficient - net B2","Efficient - net B3","Efficient - net B4","Efficient - net B5","Efficient - net B6","Efficient - net B7","nfnet - f0","nfnet - f1","nfnet - f2","nfnet - f3","nfnet - f4","nfnet - f5","nfnet - f6","ConvNext - tiny","ConvNext - small","ConvNext - base","ConvNext - large"],"associatedMergedColumns":["Swin Transformer large"]},{"number":"4Window12)","isBolded":false,"associatedRows":["( Patch"],"associatedColumns":["Resnet - 18","Resnet - 34","Resnet - 50","Resnet - 101","Efficient - net B0","Efficient - net B1","Efficient - net B2","Efficient - net B3","Efficient - net B4","Efficient - net B5","Efficient - net B6","Efficient - net B7","nfnet - f0","nfnet - f1","nfnet - f2","nfnet - f3","nfnet - f4","nfnet - f5","nfnet - f6","ConvNext - tiny","ConvNext - small","ConvNext - base","ConvNext - large"],"associatedMergedColumns":["Swin Transformer Base"]}]},{"caption":"Resnet-18 \n0.8635?0.0087 \nResnet-34 \n0.82765?0.0073 \nResnet-50 \n0.8499?0.007 \nResnet-101 \n0.871?0.009 \nEfficient-net B0 \n0.8372?0.0007 \nEfficient-net B1 \n0.8346?0.0026 \nEfficient-net B2 \n0.828?0.00074 \nEfficient-net B3 \n0.8369?0.0094 \nEfficient-net B4 \n0.8418?0.0009 \nEfficient-net B5 \n0.8463?0.00036 \nEfficient-net B6 \n0.8263?0.00147 \nEfficient-net B7 \n0.8129?0.001 \nnfnet-f0 \n0.82035?0.007 \nnfnet-f1 \n0.834?0.007 \nnfnet-f2 \n0.8652?0.0089 \nnfnet-f3 \n0.8898?0.0011 \nnfnet-f4 \n0.8848?0.0109 \nnfnet-f5 \n0.8161?0.0074 \nnfnet-f6 \n0.8378?0.007 \nConvNext-tiny \n0.81355?0.0032 \nConvNext-small \n0.84795?0.00246 \nConvNext-base \n0.80675?0.002 \nConvNext-large \n0.8452?0.000545 \nSwin Transformer large \n(Patch 4 Window 12) 0.8839?0.001 \nSwin Transformer Base \n(Patch 4 Window 12) 0.891?0.0007 \nVit-Base/16 \n0.8426?0.007 \nVit-Base/32 \n0.8507?0.0079 \nVit-large/16 \n0.80495?0.0077 \nVit-large/32 \n0.845?0.0077 \n\nTable 5. We compare the best results provided by our algorithm (in bold) as compared \nto previous benchmark on the same dataset. \n\n","rows":["Vanburen et all [ 23 ]"],"columns":["Test F1 - Score","0 . 8898?0 . 0109"],"mergedAllColumns":["( Patch 4 Window 12 )"],"numberCells":[{"number":"0.63","isBolded":false,"associatedRows":["Vanburen et all [ 23 ]"],"associatedColumns":["Test F1 - Score","0 . 8898?0 . 0109"],"associatedMergedColumns":["( Patch 4 Window 12 )"]}]},{"caption":"Table 6. This table shows the IoU score on the test set for UNet. We compared \nresults without and with autoencoder for both ReLU and GELU activations for UNet \nArchitecture. These results are averaged over five runs with different seed values. We \nobserved that in all cases addition of APP improved performance. GELU activated \nAPP seems out perform the ReLU activated APP in all cases except for ResNet-50. \n\n","rows":["ResNet"],"columns":["AE","0 . 4347?0 . 0006","Encoder","ReLU","0 . 4774?0 . 0004","With"],"mergedAllColumns":["AE"],"numberCells":[{"number":"34","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE","0 . 4347?0 . 0006"],"associatedMergedColumns":["AE"]},{"number":"18","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE"],"associatedMergedColumns":["AE"]},{"number":"50","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE","0 . 4347?0 . 0006","0 . 4774?0 . 0004"],"associatedMergedColumns":["AE"]}]},{"caption":"Encoder \nUNet \n\nWithout \nAE \n\nWith \nReLU \nAE \n\nWith \nGELU \nAE \n\nResNet 18 0.4347?0.0006 0.4608?0.0001 \n0.4788?0.0004 \nResNet 34 0.4774?0.0004 0.4467?0.0012 \n0.4983?0.0008 \nResNet 50 0.3798?0.00072 0.4187?0.0006 0.3827?0.0003 \nResNet 101 0.3718?0.0001 0.4074?0.0012 \n0.4402?0.00018 \n\nTable 7. This table shows the IoU score on the test set for UNet++. These results \nare averaged over five runs with different seed values. We compare results without \nand with autoencoder for both ReLU and GELU activations for UNet++ Architec-\nture. We observed that in most cases, APP improves performance except for UNet++ \nwith Resnet-18, where APP segmentation techniques lag by around 5%. However, as \na counter for ResNet-34 APP-based segmentation techniques are almost 10% better \nthan UNet++ without APP. \n\n","rows":["ResNet"],"columns":["0 . 3745?0 . 0006","AE","0 . 5274?0 . 0004 0 . 4177?0 . 0005","Encoder","ReLU","With"],"mergedAllColumns":["AE"],"numberCells":[{"number":"50","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE","0 . 5274?0 . 0004 0 . 4177?0 . 0005","0 . 3745?0 . 0006"],"associatedMergedColumns":["AE"]},{"number":"18","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE"],"associatedMergedColumns":["AE"]},{"number":"34","isBolded":false,"associatedRows":["ResNet"],"associatedColumns":["Encoder","With","ReLU","AE","0 . 5274?0 . 0004 0 . 4177?0 . 0005"],"associatedMergedColumns":["AE"]}]},{"caption":"Table 8. In this table we report the running time averaged over 5 runs with different \nseeds, for efficient-net encoder family with UNet.The variation is almost negligible(\u003c \n6s). \n\n","rows":["Table 9 . In this table we report the IoU averaged over"],"columns":["1h 29m 04s","1h 58m 40s","2h 19m 59s","1h 40m 33s","Encoder Without APP With APP","1h 50m 02s","1h 34m 27s","2h 10m 08s","1h 33m 42s"],"mergedAllColumns":[],"numberCells":[{"number":"5runswithdifferentseeds,for","isBolded":false,"associatedRows":["Table 9 . In this table we report the IoU averaged over"],"associatedColumns":["Encoder Without APP With APP","1h 29m 04s","1h 33m 42s","1h 34m 27s","1h 40m 33s","1h 50m 02s","1h 58m 40s","2h 10m 08s","2h 19m 59s"],"associatedMergedColumns":[]}]},{"caption":"Encoder Without APP With APP \n\nB0 \n1h 26m 27s \n1h 29m 04s \nB1 \n1h 31m 16s \n1h 33m 42s \nB2 \n1h 32m 12s \n1h 34m 27s \nB3 \n1h 38m \n1h 40m 33s \nB4 \n1h 44m 20s \n1h 50m 02s \nB5 \n1h 55m 46s \n1h 58m 40s \nB6 \n2h 06m 55s \n2h 10m 08s \nB7 \n2h 16m 40s \n2h 19m 59s \n\nTable 9. In this table we report the IoU averaged over 5 runs with different seeds, for \nefficient-net encoder family with UNet architecture. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 10. In this table we report the running time averaged over 5 runs with different \nseeds, for efficient-net encoder family with UNet++. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 11. In this table we report the IoU averaged over 5 runs with different seeds, \nfor efficient-net encoder family with UNet++ architecture. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 12. Using different initialization, we saw that the performance of different en-\ncoders of the EfficientNet family on UNet. We report the IoU over the test set in the \nfollowing table. We observe that while performance gains for smaller models, ImageNet \ninitialisation works better for larger models. Also, the fact that advprop and noisy are \nnot readily available for all models, hence the choice of ImageNet still dominates. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 13. We report the F1 score for different initializations for the EfficientNet family \nof encoders. We reported the average of 6-fold runs on the test set with five different \nseed values. We observed that 0.8463 is the peak with ImageNet, 0.843 with advprop \nand 0.8457 with noisy student initialization. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]}]