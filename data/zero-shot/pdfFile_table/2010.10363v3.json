[{"caption":"Table 1: We compare Bootleg to the best published numbers on three NED benchmarks. \"-\" indicates that \nthe metric was not reported. Bolded numbers indicate the best value for each metric on each benchmark. \n\n","rows":["RSS500","7","F?vry et al . [ 16 ]","KORE50","Hu et al . [ 24 ]","-","Phan et al . [ 40 ]"],"columns":["Precision","Recall","F1"],"mergedAllColumns":["-"],"numberCells":[{"number":"79.8","isBolded":true,"associatedRows":["KORE50","Hu et al . [ 24 ]","7"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"96.7","isBolded":false,"associatedRows":["RSS500","F?vry et al . [ 16 ]"],"associatedColumns":["Recall"],"associatedMergedColumns":["-"]},{"number":"80.0","isBolded":true,"associatedRows":["KORE50","Hu et al . [ 24 ]","7"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"85.7","isBolded":false,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"96.9","isBolded":true,"associatedRows":["RSS500","F?vry et al . [ 16 ]"],"associatedColumns":["Precision"],"associatedMergedColumns":["-"]},{"number":"82.3","isBolded":true,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"79.9","isBolded":true,"associatedRows":["KORE50","Hu et al . [ 24 ]","7"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"82.3","isBolded":true,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"85.4","isBolded":false,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"82.5","isBolded":false,"associatedRows":["KORE50","F?vry et al . [ 16 ]"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"82.3","isBolded":true,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"82.5","isBolded":false,"associatedRows":["KORE50","F?vry et al . [ 16 ]"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"96.8","isBolded":true,"associatedRows":["KORE50","F?vry et al . [ 16 ]"],"associatedColumns":["F1"],"associatedMergedColumns":["-"]},{"number":"82.5","isBolded":false,"associatedRows":["KORE50","F?vry et al . [ 16 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"86.0","isBolded":false,"associatedRows":["KORE50","Phan et al . [ 40 ]"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"96.7","isBolded":false,"associatedRows":["KORE50","F?vry et al . [ 16 ]","-"],"associatedColumns":["Recall"],"associatedMergedColumns":[]}]},{"caption":"Table 2: (top) We compare Bootleg to a BERT-based NED baseline (NED-Base) on validation sets of a \nWikipedia dataset. We report micro-average F1 scores. All torso, tail, and unseen validation sets are filtered \nby the number of entity occurrences in the training data and such that the mention has more than one \ncandidate. \n\n","rows":["NED - Base","Bootleg ( Type - only )","Bootleg","Bootleg ( Ent - only )","Bootleg ( KG - only )"],"columns":["Tail Entities","Unseen Entities","Torso Entities","All Entities"],"mergedAllColumns":[],"numberCells":[{"number":"64.7","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"85.8","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"37.9","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"62.9","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"79.0","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"87.3","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"18.5","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"14.9","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"81.6","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"61.6","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"27.8","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"68.5","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"88.0","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"87.1","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"79.4","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"79.3","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Test micro-average F1 score on revised TACRED dataset. \n\n","rows":["SpanBERT","Bootleg Model","KnowBERT"],"columns":["F1"],"mergedAllColumns":[],"numberCells":[{"number":"79.3","isBolded":false,"associatedRows":["KnowBERT"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"80.3","isBolded":true,"associatedRows":["Bootleg Model"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"78.0","isBolded":false,"associatedRows":["SpanBERT"],"associatedColumns":["F1"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Relative F1 quality of an Overton[45] model with Bootleg embeddings over one without in four \nlanguages. \n\n","rows":["Tail Entities","All Entities"],"columns":["English","French","Spanish","German"],"mergedAllColumns":[],"numberCells":[{"number":"1.03","isBolded":false,"associatedRows":["Tail Entities"],"associatedColumns":["German"],"associatedMergedColumns":[]},{"number":"1.00","isBolded":false,"associatedRows":["All Entities"],"associatedColumns":["German"],"associatedMergedColumns":[]},{"number":"1.03","isBolded":false,"associatedRows":["All Entities"],"associatedColumns":["Spanish"],"associatedMergedColumns":[]},{"number":"1.05","isBolded":false,"associatedRows":["Tail Entities"],"associatedColumns":["French"],"associatedMergedColumns":[]},{"number":"1.08","isBolded":false,"associatedRows":["Tail Entities"],"associatedColumns":["English"],"associatedMergedColumns":[]},{"number":"1.02","isBolded":false,"associatedRows":["All Entities"],"associatedColumns":["French"],"associatedMergedColumns":[]},{"number":"1.08","isBolded":false,"associatedRows":["All Entities"],"associatedColumns":["English"],"associatedMergedColumns":[]},{"number":"1.17","isBolded":false,"associatedRows":["Tail Entities"],"associatedColumns":["Spanish"],"associatedMergedColumns":[]}]},{"caption":"Table 6: We show the micro F1 score over unseen entities for a Wikipedia sample as we vary the entity \nregularization scheme p(e). A scalar percent means a fixed regularization. InvPop (inverse poularity scheme) \napplies less regularization for more popular entities and Pop applies more regularization for more popular \nentities. \n\n","rows":["Unseen Entities"],"columns":["Pop","0%","InvPop","20%","50%","80%"],"mergedAllColumns":[],"numberCells":[{"number":"52.5","isBolded":false,"associatedRows":["Unseen Entities"],"associatedColumns":["20%"],"associatedMergedColumns":[]},{"number":"52.4","isBolded":false,"associatedRows":["Unseen Entities"],"associatedColumns":["Pop"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["Unseen Entities"],"associatedColumns":["80%"],"associatedMergedColumns":[]},{"number":"48.6","isBolded":false,"associatedRows":["Unseen Entities"],"associatedColumns":["0%"],"associatedMergedColumns":[]},{"number":"62.2","isBolded":true,"associatedRows":["Unseen Entities"],"associatedColumns":["InvPop"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["Unseen Entities"],"associatedColumns":["50%"],"associatedMergedColumns":[]}]},{"caption":"Table 7: We report the Overall/Tail F1 scores across each ablation model for a slice of data that exemplifies \na reasoning pattern. Each slice is representative but may not cover every example that contains the reasoning \npattern. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 9: (top) We compare Bootleg to a BERT-based NED baseline (NED-Base) on validation sets of our \nmicro Wikipedia dataset and ablate Bootleg by only training with entity, type, or knowledge graph data. \nWe further ablate (bottom 8 rows) the regularization schemes for the entity embeddings for Bootleg. \n\n","rows":["NED - Base","Bootleg ( InvPopPow )","Bootleg ( InvPopLin )","Bootleg ( p ( e ) \u003d 20% )","Bootleg ( p ( e ) \u003d 80% )","Bootleg ( Type - only )","Bootleg ( p ( e ) \u003d 50% )","Bootleg ( PopPow )","Bootleg ( Ent - only )","Bootleg ( KG - only )","Bootleg ( p ( e ) \u003d 0% )","Bootleg ( InvPopLog )"],"columns":["Tail Entities","Unseen Entities","Torso Entities","All Entities"],"mergedAllColumns":[],"numberCells":[{"number":"65.3","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"90.8","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":false,"associatedRows":["Bootleg ( InvPopPow )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"92.6","isBolded":false,"associatedRows":["Bootleg ( InvPopLin )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":false,"associatedRows":["Bootleg ( InvPopLog )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 80% )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"70.5","isBolded":true,"associatedRows":["Bootleg ( InvPopPow )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"90.4","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"48.3","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"92.9","isBolded":true,"associatedRows":["Bootleg ( p ( e ) \u003d 50% )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"61.1","isBolded":false,"associatedRows":["Bootleg ( InvPopLog )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["Bootleg ( PopPow )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 20% )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":false,"associatedRows":["Bootleg ( PopPow )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"65.9","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["Bootleg ( InvPopLin )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"52.5","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 20% )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"67.7","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 0% )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"62.2","isBolded":true,"associatedRows":["Bootleg ( InvPopPow )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"61.0","isBolded":false,"associatedRows":["Bootleg ( InvPopLin )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"52.4","isBolded":false,"associatedRows":["Bootleg ( PopPow )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"21.5","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 20% )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 50% )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"58.6","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"48.6","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 0% )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 20% )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"91.9","isBolded":false,"associatedRows":["Bootleg ( InvPopLog )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 80% )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"92.3","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 0% )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"92.9","isBolded":true,"associatedRows":["Bootleg ( PopPow )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"91.8","isBolded":false,"associatedRows":["Bootleg ( KG - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["Bootleg ( InvPopLog )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"57.7","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 50% )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"59.9","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 80% )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"91.6","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"15.5","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"91.8","isBolded":false,"associatedRows":["Bootleg ( InvPopLin )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"92.2","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 80% )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":false,"associatedRows":["Bootleg ( p ( e ) \u003d 0% )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"90.2","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"56.8","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":true,"associatedRows":["Bootleg ( p ( e ) \u003d 50% )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"89.1","isBolded":false,"associatedRows":["Bootleg ( Ent - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"50.5","isBolded":false,"associatedRows":["NED - Base"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"91.6","isBolded":false,"associatedRows":["Bootleg ( Type - only )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"92.3","isBolded":false,"associatedRows":["Bootleg ( InvPopPow )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]}]},{"caption":"Table 10: We report the model sizes in MB of each of the five ablation models: NED-Base, Bootleg, \nBootleg (Ent-Only), Bootleg (KG-Only), and Bootleg (Type-Only). \n\n","rows":["5 , 186","5 , 221","5 , 201","Network Size ( MB )","4","5 , 190","Embedding Size ( MB )","5 , 240","Total Size ( MB )"],"columns":["Ent - Only","Type - Only","KG - Only","Bootleg"],"mergedAllColumns":["1"],"numberCells":[{"number":"34","isBolded":false,"associatedRows":["Network Size ( MB )","4","5 , 240","5 , 221"],"associatedColumns":["KG - Only"],"associatedMergedColumns":["1"]},{"number":"13","isBolded":false,"associatedRows":["Embedding Size ( MB )","5 , 186","5 , 201","5 , 186"],"associatedColumns":["Type - Only"],"associatedMergedColumns":[]},{"number":"39","isBolded":false,"associatedRows":["Network Size ( MB )","4"],"associatedColumns":["Bootleg"],"associatedMergedColumns":["1"]},{"number":"38","isBolded":false,"associatedRows":["Network Size ( MB )","4","5 , 240","5 , 221"],"associatedColumns":["Type - Only"],"associatedMergedColumns":["1"]},{"number":"35","isBolded":false,"associatedRows":["Total Size ( MB )","5 , 190","5 , 240","5 , 221"],"associatedColumns":["KG - Only"],"associatedMergedColumns":["1"]},{"number":"35","isBolded":false,"associatedRows":["Network Size ( MB )","4","5 , 240"],"associatedColumns":["Ent - Only"],"associatedMergedColumns":["1"]},{"number":"51","isBolded":false,"associatedRows":["Total Size ( MB )","5 , 190","5 , 240","5 , 221"],"associatedColumns":["Type - Only"],"associatedMergedColumns":["1"]}]},{"caption":"Table 11: We report Bootleg trained with versus without weak labelling on our micro Wikipedia dataset. \nThe slices defined by gold anchor counts (pre-weak labelling). We use the InvPopPow regularization for both. \n\n","rows":["Bootleg","Bootleg ( No WL )"],"columns":["Tail Entities","Unseen Entities","Torso Entities","All Entities"],"mergedAllColumns":[],"numberCells":[{"number":"70.5","isBolded":false,"associatedRows":["Bootleg"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"63.3","isBolded":false,"associatedRows":["Bootleg"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]},{"number":"92.6","isBolded":true,"associatedRows":["Bootleg"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"93.3","isBolded":false,"associatedRows":["Bootleg ( No WL )"],"associatedColumns":["All Entities"],"associatedMergedColumns":[]},{"number":"93.1","isBolded":false,"associatedRows":["Bootleg ( No WL )"],"associatedColumns":["Torso Entities"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":true,"associatedRows":["Bootleg ( No WL )"],"associatedColumns":["Tail Entities"],"associatedMergedColumns":[]},{"number":"60.7","isBolded":true,"associatedRows":["Bootleg ( No WL )"],"associatedColumns":["Unseen Entities"],"associatedMergedColumns":[]}]},{"caption":"Table 12: We rank TACRED examples by the proportion of words that receive Bootleg embedding features \nwhere: Bootleg disambiguates an entity, leverages Wikidata relations for the embedding, and leverages \nWikidata types for the embedding. We take examples where the proportion is greater than 0. For each of \nthese three slices, we report the gap between the SpanBERT model and Bootleg model\u0027s error rates on the \nexamples with above-median proportion (more Bootleg signal) relative to the below-median proportion \n(less Bootleg signal). With more Bootleg information, we see the improvement our SotA model provides \nover SpanBERT increases. \n\n","rows":["Entity","15509","Relation","Type","5400","15323"],"columns":["Gap Above / Below Median"],"mergedAllColumns":[],"numberCells":[{"number":"1.10","isBolded":false,"associatedRows":["Entity","15323"],"associatedColumns":["Gap Above / Below Median"],"associatedMergedColumns":[]},{"number":"4.67","isBolded":false,"associatedRows":["Relation","5400"],"associatedColumns":["Gap Above / Below Median"],"associatedMergedColumns":[]},{"number":"1.35","isBolded":false,"associatedRows":["Type","15509"],"associatedColumns":["Gap Above / Below Median"],"associatedMergedColumns":[]}]},{"caption":"Table 13: We compute the error rate of SpanBERT relative to our Bootleg downstream model for three \nslices of TACRED data where respectively Bootleg disambiguates the subject and/or object, Bootleg \nleverages Wikidata relations for the embedding of the subject and object pair, and Bootleg leverages \nWikidata types for the embedding of the subject and/or object in the example. \n\n","rows":["Entity","Relation","542","12044","12621","Obj Type"],"columns":["BERT / Bootleg Error Rate"],"mergedAllColumns":[],"numberCells":[{"number":"1.20","isBolded":false,"associatedRows":["Obj Type","12044"],"associatedColumns":["BERT / Bootleg Error Rate"],"associatedMergedColumns":[]},{"number":"1.18","isBolded":false,"associatedRows":["Relation","542"],"associatedColumns":["BERT / Bootleg Error Rate"],"associatedMergedColumns":[]},{"number":"1.20","isBolded":false,"associatedRows":["Entity","12621"],"associatedColumns":["BERT / Bootleg Error Rate"],"associatedMergedColumns":[]}]}]