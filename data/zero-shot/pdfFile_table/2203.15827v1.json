[{"caption":"HotpotQA TriviaQA SearchQA NaturalQ NewsQA SQuAD Avg. \n\nBERTtiny \n49.8 \n43.4 \n50.2 \n58.9 \n41.3 \n56.6 \n50.0 \nLinkBERTtiny \n54.6 \n50.0 \n58.6 \n60.3 \n42.8 \n58.0 \n54.1 \n\nBERTbase \n76.0 \n70.3 \n74.2 \n76.5 \n65.7 \n88.7 \n75.2 \nLinkBERTbase \n78.2 \n73.9 \n76.8 \n78.3 \n69.3 \n90.1 \n77.8 \n\nBERTlarge \n78.1 \n73.7 \n78.3 \n79.0 \n70.9 \n91.1 \n78.5 \nLinkBERTlarge \n80.8 \n78.2 \n80.5 \n81.0 \n72.6 \n92.7 \n81.0 \n\nTable 1: Performance (F1) on MRQA question answering datasets. LinkBERT \n\nconsistently outperforms BERT on all datasets across the -tiny, -base, and -large scales. \nThe gain is especially large on datasets that require reasoning with multiple documents \nin the context, such as HotpotQA, TriviaQA, SearchQA. \n\n","rows":["BERTbase","LinkBERTlarge","LinkBERTbase","BERTtiny","LinkBERTtiny","BERTlarge"],"columns":["HotpotQA","NewsQA","SQuAD","SQuAD distract","TriviaQA","Performance ( F1 ) on MRQA question answering datasets .","NaturalQ","SearchQA","Avg ."],"mergedAllColumns":["in the context , such as HotpotQA , TriviaQA , SearchQA ."],"numberCells":[{"number":"78.2","isBolded":true,"associatedRows":["LinkBERTlarge","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"88.7","isBolded":false,"associatedRows":["LinkBERTlarge","BERTbase"],"associatedColumns":["HotpotQA","Performance ( F1 ) on MRQA question answering datasets .","SQuAD"],"associatedMergedColumns":["in the context , such as HotpotQA , TriviaQA , SearchQA ."]},{"number":"56.6","isBolded":false,"associatedRows":["BERTtiny","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":false,"associatedRows":["LinkBERTlarge","BERTbase"],"associatedColumns":["SearchQA","Performance ( F1 ) on MRQA question answering datasets .","SQuAD distract"],"associatedMergedColumns":["in the context , such as HotpotQA , TriviaQA , SearchQA ."]},{"number":"54.6","isBolded":true,"associatedRows":["LinkBERTtiny","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"78.2","isBolded":true,"associatedRows":["LinkBERTbase","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"76.0","isBolded":false,"associatedRows":["BERTbase","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"69.3","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["BERTtiny","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"50.0","isBolded":true,"associatedRows":["LinkBERTtiny","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"74.2","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"77.8","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"65.7","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"80.8","isBolded":true,"associatedRows":["LinkBERTlarge","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"76.8","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"58.6","isBolded":true,"associatedRows":["LinkBERTtiny","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"76.5","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"58.9","isBolded":false,"associatedRows":["BERTtiny","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["HotpotQA","Performance ( F1 ) on MRQA question answering datasets .","SQuAD"],"associatedMergedColumns":["in the context , such as HotpotQA , TriviaQA , SearchQA ."]},{"number":"54.1","isBolded":true,"associatedRows":["LinkBERTtiny","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"89.6","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["SearchQA","Performance ( F1 ) on MRQA question answering datasets .","SQuAD distract"],"associatedMergedColumns":["in the context , such as HotpotQA , TriviaQA , SearchQA ."]},{"number":"73.9","isBolded":true,"associatedRows":["LinkBERTbase","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"50.2","isBolded":false,"associatedRows":["BERTtiny","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["BERTlarge","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["BERTtiny","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["BERTtiny","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":false,"associatedRows":["BERTlarge","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"88.7","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"78.5","isBolded":false,"associatedRows":["BERTlarge","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"42.8","isBolded":true,"associatedRows":["LinkBERTtiny","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"70.3","isBolded":false,"associatedRows":["BERTbase","BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"78.1","isBolded":false,"associatedRows":["BERTlarge","BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"79.0","isBolded":false,"associatedRows":["BERTlarge","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"41.3","isBolded":false,"associatedRows":["BERTtiny","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"75.2","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["Avg ."],"associatedMergedColumns":[]},{"number":"70.9","isBolded":false,"associatedRows":["BERTlarge","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":true,"associatedRows":["LinkBERTtiny","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"80.5","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["SearchQA"],"associatedMergedColumns":[]},{"number":"72.6","isBolded":true,"associatedRows":["LinkBERTlarge","LinkBERTbase"],"associatedColumns":["NewsQA"],"associatedMergedColumns":[]},{"number":"60.3","isBolded":true,"associatedRows":["LinkBERTtiny","LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"91.1","isBolded":false,"associatedRows":["BERTlarge","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Performance on the \n\nGLUE benchmark. LinkBERT \nattains comparable or moderately \nimproved performance. \n\n","rows":["BERTbase","LinkBERTlarge","LinkBERTbase","BERTtiny","LinkBERTtiny","BERTlarge"],"columns":["GLUE score"],"mergedAllColumns":[],"numberCells":[{"number":"64.6","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]},{"number":"64.3","isBolded":false,"associatedRows":["BERTtiny"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]},{"number":"79.2","isBolded":false,"associatedRows":["BERTbase"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]},{"number":"79.6","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]},{"number":"80.7","isBolded":false,"associatedRows":["BERTlarge"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]},{"number":"81.1","isBolded":true,"associatedRows":["LinkBERTlarge"],"associatedColumns":["GLUE score"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Performance (F1) on SQuAD when distracting \n\ndocuments are added to the context. While BERT incurs a \nlarge drop in F1, LinkBERT does not, suggesting its robustness \nin understanding document relations. \n\n","rows":["BERTbase","LinkBERTbase"],"columns":["HotpotQA","SQuAD","SQuAD distract","TriviaQA","NaturalQ"],"mergedAllColumns":[],"numberCells":[{"number":"88.7","isBolded":false,"associatedRows":["BERTbase","BERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["BERTbase","BERTbase"],"associatedColumns":["SQuAD","HotpotQA"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["SQuAD","TriviaQA"],"associatedMergedColumns":[]},{"number":"89.6","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD distract"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD distract","NaturalQ"],"associatedMergedColumns":[]},{"number":"70.5","isBolded":true,"associatedRows":["LinkBERTbase","BERTbase"],"associatedColumns":["SQuAD","HotpotQA"],"associatedMergedColumns":[]},{"number":"79.6","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["SQuAD distract","SQuAD"],"associatedMergedColumns":[]},{"number":"64.8","isBolded":false,"associatedRows":["BERTbase","LinkBERTbase"],"associatedColumns":["SQuAD distract","NaturalQ"],"associatedMergedColumns":[]},{"number":"85.9","isBolded":false,"associatedRows":["LinkBERTbase","BERTbase"],"associatedColumns":["SQuAD distract"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD","TriviaQA"],"associatedMergedColumns":[]},{"number":"82.8","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD distract","SQuAD"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":true,"associatedRows":["LinkBERTbase","LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Few-shot QA performance (F1) when 10% of fine-\n\ntuning data is used. LinkBERT attains large gains, suggesting \nthat it internalizes more knowledge than BERT in pretraining. \n\n","rows":["BERTbase","Change hyperlink to random","Change hyperlink to TF - IDF","No diversity","LinkBERTbase","LinkBERTtiny"],"columns":["HotpotQA","SQuAD","TriviaQA","NaturalQ"],"mergedAllColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"numberCells":[{"number":"59.2","isBolded":false,"associatedRows":["BERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"57.6","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["SQuAD"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"43.4","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"59.6","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"57.8","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["SQuAD"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"66.0","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"82.8","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"54.6","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"58.9","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"79.6","isBolded":false,"associatedRows":["BERTbase"],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["SQuAD"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"70.5","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"48.0","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"60.3","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"48.2","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"64.8","isBolded":false,"associatedRows":["BERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"70.2","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"60.0","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["NaturalQ"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"64.8","isBolded":false,"associatedRows":["BERTbase"],"associatedColumns":["HotpotQA"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"49.8","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]},{"number":"56.6","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["SQuAD"],"associatedMergedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"]}]},{"caption":"Table 5: Ablation study on what linked documents to feed \n\ninto LM pretraining ( ?4.3). \n\n","rows":["Change hyperlink to random","Change hyperlink to TF - IDF","No diversity","LinkBERTtiny"],"columns":["HotpotQA TriviaQA NaturalQ SQuAD"],"mergedAllColumns":[],"numberCells":[{"number":"57.8","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"56.6","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"48.0","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"48.2","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"43.4","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"58.9","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"57.6","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"49.8","isBolded":false,"associatedRows":["Change hyperlink to random"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"53.5","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["No diversity"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"54.6","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"59.6","isBolded":false,"associatedRows":["Change hyperlink to TF - IDF"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"60.3","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"50.0","isBolded":true,"associatedRows":["LinkBERTtiny"],"associatedColumns":["HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Ablation study on the document relation prediction \n\n(DRP) objective in LM pretraining ( ?4.2). \n\n","rows":["No DRP","LinkBERTbase"],"columns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD","distract"],"mergedAllColumns":[],"numberCells":[{"number":"72.5","isBolded":false,"associatedRows":["No DRP"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"89.6","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD","distract"],"associatedMergedColumns":[]},{"number":"77.0","isBolded":false,"associatedRows":["No DRP"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"73.9","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"76.5","isBolded":false,"associatedRows":["No DRP"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"78.3","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"89.3","isBolded":false,"associatedRows":["No DRP"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"78.2","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"90.1","isBolded":true,"associatedRows":["LinkBERTbase"],"associatedColumns":["SQuAD","HotpotQA TriviaQA NaturalQ SQuAD"],"associatedMergedColumns":[]},{"number":"87.0","isBolded":false,"associatedRows":["No DRP"],"associatedColumns":["SQuAD","distract"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Performance on BLURB benchmark. BioLinkBERT \n\nattains improvement on all tasks, establishing new state of \nthe art on BLURB. Gains are notably large on document-level \ntasks such as PubMedQA and BioASQ. \n\n","rows":["BLURB score"],"columns":["( Jin et al . , 2019 )"],"mergedAllColumns":[],"numberCells":[{"number":"94.82","isBolded":false,"associatedRows":[],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]},{"number":"91.43","isBolded":false,"associatedRows":[],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]},{"number":"81.10","isBolded":true,"associatedRows":["BLURB score"],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]},{"number":"83.39","isBolded":false,"associatedRows":["BLURB score"],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]},{"number":"87.56","isBolded":true,"associatedRows":[],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]},{"number":"84.30","isBolded":false,"associatedRows":["BLURB score"],"associatedColumns":["( Jin et al . , 2019 )"],"associatedMergedColumns":[]}]}]