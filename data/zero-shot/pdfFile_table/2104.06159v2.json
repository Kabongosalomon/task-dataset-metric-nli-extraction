[{"caption":"Table 2. Median human-normalized score across 57 Atari games \nfrom the ALE, at 200M frames, for several published baselines. \nThese results are sourced from different papers, thus the agents \ndiffer along multiple dimensions (e.g. network architecture and \namount of experience replay). MuZero and Muesli both use a very \nsimilar network, the same proportion of replay, and both use the \nharder version of the ALE with sticky actions (Machado et al.,  2018). The ? denotes the standard error over 2 random seeds. \n\n","rows":["DreamerV2 ( Hafner et al . , 2020 )","Rainbow ( Hessel et al . , 2018 )","LASER ( Schmitt et al . , 2020 )","IMPALA ( Espeholt et al . , 2018 )","Meta - gradient{? , ?} ( Xu et al . , 2018 )","STAC ( Zahavy et al . , 2020 )"],"columns":["79%","MEDIAN"],"mergedAllColumns":[],"numberCells":[{"number":"192%","isBolded":false,"associatedRows":["IMPALA ( Espeholt et al . , 2018 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]},{"number":"287%","isBolded":false,"associatedRows":["Meta - gradient{? , ?} ( Xu et al . , 2018 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]},{"number":"231%","isBolded":false,"associatedRows":["Rainbow ( Hessel et al . , 2018 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]},{"number":"164%","isBolded":false,"associatedRows":["DreamerV2 ( Hafner et al . , 2020 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]},{"number":"364%","isBolded":false,"associatedRows":["STAC ( Zahavy et al . , 2020 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]},{"number":"431%","isBolded":false,"associatedRows":["LASER ( Schmitt et al . , 2020 )"],"associatedColumns":["MEDIAN","79%"],"associatedMergedColumns":[]}]},{"caption":"Table 4. Atari parameters. In general, we follow the recommendations by Machado et al. (2018). \n\n","rows":["Max episode length","Sticky action probability ?","Action set","Observation size"],"columns":["0","No","Not allowed","VALUE"],"mergedAllColumns":[],"numberCells":[{"number":"0.25","isBolded":false,"associatedRows":["Sticky action probability ?"],"associatedColumns":["VALUE","No"],"associatedMergedColumns":[]},{"number":"96?","isBolded":true,"associatedRows":["Observation size"],"associatedColumns":["VALUE","No","0","Not allowed"],"associatedMergedColumns":[]},{"number":"96","isBolded":true,"associatedRows":["Observation size"],"associatedColumns":["VALUE","No","0","Not allowed"],"associatedMergedColumns":[]},{"number":"18actions","isBolded":false,"associatedRows":["Action set"],"associatedColumns":["VALUE","No","0","Not allowed"],"associatedMergedColumns":[]},{"number":"30minutes(108,000frames)","isBolded":false,"associatedRows":["Max episode length"],"associatedColumns":["VALUE","No","0","Not allowed"],"associatedMergedColumns":[]}]},{"caption":"PARAMETER \nVALUE \n\nRandom modes and difficulties \nNo \nSticky action probability ? \n0.25 \nStart no-ops \n0 \nLife information \nNot allowed \nAction set \n18 actions \nMax episode length \n30 minutes (108,000 frames) \nObservation size \n96 ? 96 \nAction repetitions \n4 \nMax-pool over last N action repeat frames \n4 \nTotal environment frames, including skipped frames 200M \n\nTable 5. Hyperparameters shared by all experiments. \n\n","rows":["Target network update rate ?target","Initial learning rate","Discount","Variance moving average decay ?var","var","3 ?","Reward loss weight","Sequence length","Variance offset","Batch size","KL ( ?CMPO , ? ) estimator","Value loss weight","Retrace EA?? [ q? prior ( s , A ) ] estimator"],"columns":["0","5","6 , 000 , 000 frames","75%","VALUE"],"mergedAllColumns":[],"numberCells":[{"number":"0.995","isBolded":false,"associatedRows":["Discount"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"96sequences","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"30frames","isBolded":false,"associatedRows":["Sequence length"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"16samples","isBolded":false,"associatedRows":["KL ( ?CMPO , ? ) estimator"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"10?4","isBolded":true,"associatedRows":["Initial learning rate","3 ?"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["Value loss weight"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"0.99","isBolded":false,"associatedRows":["Variance moving average decay ?var"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Reward loss weight"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"16samples","isBolded":false,"associatedRows":["Retrace EA?? [ q? prior ( s , A ) ] estimator"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"10?12","isBolded":true,"associatedRows":["Variance offset","var"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Target network update rate ?target"],"associatedColumns":["VALUE","5","75%","6 , 000 , 000 frames","0","0"],"associatedMergedColumns":[]}]},{"caption":"Table 6. Modified hyperparameters for large-scale Atari experiments. The network architecture, discount and replay proportion are based \non MuZero Reanalyze. \n\n","rows":["Discount","Stacked frames","Network architecture","MuZero net with","AdamW weight decay","Retrace ?"],"columns":["768 sequences","95%","VALUE","28 , 800 , 000 frames"],"mergedAllColumns":["? 4"],"numberCells":[{"number":"16ResNetblocks","isBolded":false,"associatedRows":["Network architecture","MuZero net with"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"0.95","isBolded":false,"associatedRows":["Retrace ?"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":["? 4"]},{"number":"16","isBolded":false,"associatedRows":["Stacked frames"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"10","isBolded":true,"associatedRows":["AdamW weight decay"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":[]},{"number":"0.997","isBolded":false,"associatedRows":["Discount"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":["? 4"]}]},{"caption":"Table 7. Modified hyperparameters for 9x9 Go self-play experiments. \n\n","rows":["Discount","Stacked frames","Network architecture","MuZero net with","AdamW weight decay","Retrace ?"],"columns":["768 sequences","95%","VALUE","28 , 800 , 000 frames"],"mergedAllColumns":["? 4"],"numberCells":[{"number":"16ResNetblocks","isBolded":false,"associatedRows":["Network architecture","MuZero net with"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"10","isBolded":true,"associatedRows":["AdamW weight decay"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["Stacked frames"],"associatedColumns":["VALUE"],"associatedMergedColumns":[]},{"number":"0.997","isBolded":false,"associatedRows":["Discount"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":["? 4"]},{"number":"0.95","isBolded":false,"associatedRows":["Retrace ?"],"associatedColumns":["VALUE","768 sequences","95%","28 , 800 , 000 frames"],"associatedMergedColumns":["? 4"]}]},{"caption":"Table 9. Hyperparameters for the different policy losses. \n\n","rows":["CMPO loss weight","TRPO penalty weight","PPO clipping","CMPO clipping threshold c","MPO KL ( ?MPO , ? ) constraint","Total policy loss weight","-","Entropy bonus weight","PPO"],"columns":["Muesli","PG","TRPO penalty","MPO","-","PPO"],"mergedAllColumns":["-"],"numberCells":[{"number":"0","isBolded":false,"associatedRows":["Entropy bonus weight","-","-","-"],"associatedColumns":["MPO"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["TRPO penalty weight","-","-"],"associatedColumns":["PPO"],"associatedMergedColumns":[]},{"number":"0.01","isBolded":false,"associatedRows":["MPO KL ( ?MPO , ? ) constraint","-","-","-"],"associatedColumns":["MPO","-"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Total policy loss weight","-"],"associatedColumns":["TRPO penalty"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Total policy loss weight","-","-"],"associatedColumns":["PPO"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["TRPO penalty weight","-","-","-"],"associatedColumns":["MPO"],"associatedMergedColumns":[]},{"number":"0.0003","isBolded":false,"associatedRows":["Entropy bonus weight","-","-"],"associatedColumns":["PPO"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["TRPO penalty weight"],"associatedColumns":["PG"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["TRPO penalty weight","-","-","-","-"],"associatedColumns":["Muesli"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Total policy loss weight"],"associatedColumns":["PG"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["Entropy bonus weight","-","-","-","-"],"associatedColumns":["Muesli"],"associatedMergedColumns":[]},{"number":"0.0003","isBolded":false,"associatedRows":["Entropy bonus weight","-"],"associatedColumns":["TRPO penalty"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Total policy loss weight","-","-","-"],"associatedColumns":["MPO"],"associatedMergedColumns":[]},{"number":"0.01","isBolded":false,"associatedRows":["TRPO penalty weight","-"],"associatedColumns":["TRPO penalty"],"associatedMergedColumns":[]},{"number":"3.0","isBolded":false,"associatedRows":["Total policy loss weight","-","-","-","-"],"associatedColumns":["Muesli"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["PPO clipping","PPO","-","-"],"associatedColumns":["PPO"],"associatedMergedColumns":[]},{"number":"0.003","isBolded":false,"associatedRows":["Entropy bonus weight"],"associatedColumns":["PG"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":["CMPO loss weight"],"associatedColumns":["PG","-"],"associatedMergedColumns":["-"]},{"number":"1.0","isBolded":false,"associatedRows":["CMPO clipping threshold c","-","-","-","-"],"associatedColumns":["Muesli","-"],"associatedMergedColumns":["-"]},{"number":"0","isBolded":false,"associatedRows":["CMPO loss weight","-","-"],"associatedColumns":["PPO","-"],"associatedMergedColumns":["-"]},{"number":"1.0","isBolded":false,"associatedRows":["CMPO loss weight","-","-","-","-"],"associatedColumns":["Muesli","-"],"associatedMergedColumns":["-"]},{"number":"0","isBolded":false,"associatedRows":["CMPO loss weight","-"],"associatedColumns":["TRPO penalty","-"],"associatedMergedColumns":["-"]}]},{"caption":"Table 10. Median and mean human-normalized score across 57 Atari games, after 200M environment frames. The agents differ in network \nsize, amount of replay, the probability of a sticky action and agent training. The ? indicates the standard error across 2 random seeds. \nWhile DreamerV2 was not evaluated on defender and surround, DreamerV2 median score remains valid on 57 games, if we assume \na high DreamerV2 score on defender. \n\n","rows":["164%","231%","79%","287%","75%","2 , 253 ?120%","1 , 047 ?40%","95%","431%","192%","958%","2 , 524 ?104%","2 , 971 ?115%","Rainbow ( Hessel et al . , 2018 )","LASER ( Schmitt et al . , 2020 )","755 ?27%","MuZero Reanalyse ( Schrittwieser et al . , 2021 )","Muesli with MuZero arch , replay\u003d95%","Meta - gradient{? , ?} ( Xu et al . , 2018 )","1 , 041 ?40%","IQN ( Dabney et al . , 2018 )","Muesli with IMPALA architecture","16","probability","DreamerV2 ( Hafner et al . , 2020 )","Muesli with MuZero arch , replay\u003d80%","-","80%","1 , 981 ?66%","1","4","0%","562 ?3%","IMPALA ( Espeholt et al . , 2018 )","218%","DQN ( Mnih et al . , 2015 )","Win"],"columns":["AGENT","9x9 Go vs GnuGo","REPLAY","STICKY ACTION"],"mergedAllColumns":["PG","TRPO penalty","Muesli / MCTS [ Eval ]"],"numberCells":[{"number":"0.0","isBolded":false,"associatedRows":["probability","DQN ( Mnih et al . , 2015 )","79%","-","4","0%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["probability","Muesli with MuZero arch , replay\u003d95%","1 , 041 ?40%","2 , 524 ?104%","16","95%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"87.5%","isBolded":false,"associatedRows":["probability","LASER ( Schmitt et al . , 2020 )","431%","-","4"],"associatedColumns":["REPLAY"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":true,"associatedRows":["probability"],"associatedColumns":["AGENT"],"associatedMergedColumns":[]},{"number":"87.5%","isBolded":false,"associatedRows":["probability","Rainbow ( Hessel et al . , 2018 )","231%","-","4"],"associatedColumns":["REPLAY"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["probability","Rainbow ( Hessel et al . , 2018 )","231%","-","4","0%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":true,"associatedRows":["Win"],"associatedColumns":["AGENT","9x9 Go vs GnuGo"],"associatedMergedColumns":["TRPO penalty"]},{"number":"0.0","isBolded":true,"associatedRows":["Win"],"associatedColumns":["AGENT","9x9 Go vs GnuGo"],"associatedMergedColumns":["Muesli / MCTS [ Eval ]"]},{"number":"87.5%","isBolded":false,"associatedRows":["probability","IQN ( Dabney et al . , 2018 )","218%","-","4"],"associatedColumns":["REPLAY"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["probability","MuZero Reanalyse ( Schrittwieser et al . , 2021 )","1 , 047 ?40%","2 , 971 ?115%","16","95%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":true,"associatedRows":["Win"],"associatedColumns":["AGENT","9x9 Go vs GnuGo"],"associatedMergedColumns":["PG"]},{"number":"0.0","isBolded":false,"associatedRows":["probability","IMPALA ( Espeholt et al . , 2018 )","192%","958%","4","0%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["probability","DreamerV2 ( Hafner et al . , 2020 )","164%","-","1","-"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["probability","IQN ( Dabney et al . , 2018 )","218%","-","4","0%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["probability","Muesli with MuZero arch , replay\u003d80%","755 ?27%","2 , 253 ?120%","16","80%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["probability","LASER ( Schmitt et al . , 2020 )","431%","-","4","-"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"87.5%","isBolded":false,"associatedRows":["probability","DQN ( Mnih et al . , 2015 )","79%","-","4"],"associatedColumns":["REPLAY"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["probability","Muesli with IMPALA architecture","562 ?3%","1 , 981 ?66%","4","75%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":true,"associatedRows":["probability"],"associatedColumns":["AGENT","9x9 Go vs GnuGo"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":true,"associatedRows":["probability"],"associatedColumns":["AGENT","9x9 Go vs GnuGo"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["probability","Meta - gradient{? , ?} ( Xu et al . , 2018 )","287%","-","4","0%"],"associatedColumns":["STICKY ACTION"],"associatedMergedColumns":[]}]}]