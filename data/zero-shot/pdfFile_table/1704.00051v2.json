[{"caption":"Table 1: Example training data from each QA dataset. In each case we show an associated paragraph \nwhere distant supervision (DS) correctly identified the answer within it, which is highlighted. \n\n","rows":["CuratedTREC","3 , 464","1 , 486 *"],"columns":["71 , 231 10 , 570 ?","Test","DS"],"mergedAllColumns":[],"numberCells":[{"number":"694","isBolded":false,"associatedRows":["CuratedTREC","1 , 486 *","3 , 464"],"associatedColumns":["Test","DS","71 , 231 10 , 570 ?"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Number of questions for each dataset \nused in this paper. DS: distantly supervised train-\ning data.  *  : These training sets are not used as \nis because no paragraph is associated with each \nquestion.  ? : Corresponds to SQuAD development \nset. \n\n","rows":["CuratedTREC","3 , 464","1 , 486 *"],"columns":["71 , 231 10 , 570 ?","Test","DS"],"mergedAllColumns":[],"numberCells":[{"number":"694","isBolded":false,"associatedRows":["CuratedTREC","1 , 486 *","3 , 464"],"associatedColumns":["Test","DS","71 , 231 10 , 570 ?"],"associatedMergedColumns":[]}]},{"caption":"Table 2. \n\n","rows":["SQuAD","CuratedTREC","WebQuestions","WikiMovies"],"columns":["Doc . Retriever","Dataset","plain","Search","+bigrams","Wiki"],"mergedAllColumns":[],"numberCells":[{"number":"54.4","isBolded":false,"associatedRows":["WikiMovies"],"associatedColumns":["Doc . Retriever","plain"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":false,"associatedRows":["CuratedTREC"],"associatedColumns":["Wiki","Search"],"associatedMergedColumns":[]},{"number":"86.0","isBolded":true,"associatedRows":["CuratedTREC"],"associatedColumns":["Doc . Retriever","+bigrams"],"associatedMergedColumns":[]},{"number":"76.1","isBolded":false,"associatedRows":["SQuAD"],"associatedColumns":["Doc . Retriever","plain"],"associatedMergedColumns":[]},{"number":"77.8","isBolded":true,"associatedRows":["SQuAD"],"associatedColumns":["Doc . Retriever","+bigrams"],"associatedMergedColumns":[]},{"number":"62.7","isBolded":false,"associatedRows":["SQuAD"],"associatedColumns":["Wiki","Search"],"associatedMergedColumns":[]},{"number":"61.7","isBolded":false,"associatedRows":["WikiMovies"],"associatedColumns":["Wiki","Search"],"associatedMergedColumns":[]},{"number":"75.5","isBolded":true,"associatedRows":["WebQuestions"],"associatedColumns":["Doc . Retriever","plain"],"associatedMergedColumns":[]},{"number":"74.4","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Doc . Retriever","+bigrams"],"associatedMergedColumns":[]},{"number":"70.3","isBolded":true,"associatedRows":["WikiMovies"],"associatedColumns":["Doc . Retriever","+bigrams"],"associatedMergedColumns":[]},{"number":"4.4","isBolded":true,"associatedRows":[],"associatedColumns":["Dataset","Search"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["Wiki","Search"],"associatedMergedColumns":[]},{"number":"85.2","isBolded":false,"associatedRows":["CuratedTREC"],"associatedColumns":["Doc . Retriever","plain"],"associatedMergedColumns":[]}]},{"caption":"65.4 75.6 66.2 75.9 \nMulti-Perspective Matching (Wang et al., 2016)  ? \n66.1 75.8 65.5 75.1 \nBiDAF (Seo et al., 2016) \n67.7 77.3 68.0 77.3 \nR-net  ? \nn/a n/a 71.3 79.7 \nDrQA (Our model, Document Reader Only) \n69.5 78.8 70.0 79.0 \n\nTable 4: Evaluation results on the SQuAD dataset (single model only).  ? : Test results reflect the SQuAD \nleaderboard (https://stanford-qa.com) as of Feb 6, 2017. \n\n","rows":["n / a","BiDAF ( Seo et al . , 2016 )","Multi - Perspective Matching ( Wang et al . , 2016 ) ?","R - net ?","DrQA ( Our model , Document Reader Only )"],"columns":["EM","F1"],"mergedAllColumns":[],"numberCells":[{"number":"77.3","isBolded":false,"associatedRows":["BiDAF ( Seo et al . , 2016 )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":true,"associatedRows":["DrQA ( Our model , Document Reader Only )"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"71.3","isBolded":false,"associatedRows":["R - net ?","n / a","n / a"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"75.6","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"65.5","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"79.0","isBolded":false,"associatedRows":["DrQA ( Our model , Document Reader Only )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"77.3","isBolded":false,"associatedRows":["BiDAF ( Seo et al . , 2016 )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"67.7","isBolded":false,"associatedRows":["BiDAF ( Seo et al . , 2016 )"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"75.8","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"79.7","isBolded":false,"associatedRows":["R - net ?","n / a","n / a"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["DrQA ( Our model , Document Reader Only )"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"78.8","isBolded":true,"associatedRows":["DrQA ( Our model , Document Reader Only )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"75.9","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"66.1","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["EM"],"associatedMergedColumns":[]},{"number":"75.1","isBolded":false,"associatedRows":["Multi - Perspective Matching ( Wang et al . , 2016 ) ?"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":false,"associatedRows":["BiDAF ( Seo et al . , 2016 )"],"associatedColumns":["EM"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Full Wikipedia results. Top-1 exact-match accuracy (in %, using SQuAD eval script). +Fine-\ntune (DS): Document Reader models trained on SQuAD and fine-tuned on each DS training set inde-\npendently. +Multitask (DS): Document Reader single model trained on SQuAD and all the distant su-\npervision (DS) training sets jointly. YodaQA results are extracted from https://github.com/brmson/ \nyodaqa/wiki/Benchmarks and use additional resources such as Freebase and DBpedia, see Section 2. \n\n","rows":["n / a","CuratedTREC","WebQuestions","WikiMovies","SQuAD ( All Wikipedia )"],"columns":["SQuAD","+Multitask ( DS )","+Fine - tune ( DS )","YodaQA","DrQA"],"mergedAllColumns":[],"numberCells":[{"number":"39.8","isBolded":false,"associatedRows":["WebQuestions"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"28.4","isBolded":false,"associatedRows":["SQuAD ( All Wikipedia )","n / a"],"associatedColumns":["DrQA","+Fine - tune ( DS )"],"associatedMergedColumns":[]},{"number":"27.1","isBolded":false,"associatedRows":["SQuAD ( All Wikipedia )","n / a"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"29.8","isBolded":false,"associatedRows":["SQuAD ( All Wikipedia )","n / a"],"associatedColumns":["DrQA","+Multitask ( DS )"],"associatedMergedColumns":[]},{"number":"31.3","isBolded":false,"associatedRows":["CuratedTREC"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"24.5","isBolded":false,"associatedRows":["WikiMovies","n / a"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"36.5","isBolded":false,"associatedRows":["WikiMovies","n / a"],"associatedColumns":["DrQA","+Multitask ( DS )"],"associatedMergedColumns":[]},{"number":"34.3","isBolded":false,"associatedRows":["WikiMovies","n / a"],"associatedColumns":["DrQA","+Fine - tune ( DS )"],"associatedMergedColumns":[]},{"number":"19.5","isBolded":false,"associatedRows":["WebQuestions","n / a"],"associatedColumns":["DrQA","+Fine - tune ( DS )"],"associatedMergedColumns":[]},{"number":"19.7","isBolded":false,"associatedRows":["CuratedTREC","n / a"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"25.4","isBolded":false,"associatedRows":["CuratedTREC","n / a"],"associatedColumns":["DrQA","+Multitask ( DS )"],"associatedMergedColumns":[]},{"number":"11.8","isBolded":false,"associatedRows":["WebQuestions","n / a"],"associatedColumns":["YodaQA","SQuAD"],"associatedMergedColumns":[]},{"number":"20.7","isBolded":false,"associatedRows":["WebQuestions","n / a"],"associatedColumns":["DrQA","+Multitask ( DS )"],"associatedMergedColumns":[]},{"number":"25.7","isBolded":false,"associatedRows":["CuratedTREC","n / a"],"associatedColumns":["DrQA","+Fine - tune ( DS )"],"associatedMergedColumns":[]}]}]