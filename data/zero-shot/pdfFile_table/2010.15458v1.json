[{"caption":"Language Dataset \nTrain Dev \nTest \n\nEnglish \n\nW16 \n\n#Sent. 2,394 1,000 3,850 \n#Ent. 1,496 661 3,473 \n%Uns. \n-\n52.1 \n80.0 \n\nW17 \n\n#Sent. 3,394 1,008 1,287 \n#Ent. 1,975 835 1,079 \n%Uns. \n-\n34.8 \n84.5 \n\nChinese \nWB \n\n#Sent. 1,350 270 \n270 \n#Ent. 1,885 389 \n414 \n%Uns. \n-\n51.4 \n45.2 \n\nTable 1: The statistics of all benchmark datasets w.r.t. \nthe number of sentences (# Sent.), named entities (# \nEnt.) and the percentage of unseen entities (% Uns.). \n\n","rows":["English","%Uns .","Chinese","WB","W17","-"],"columns":["3 , 850","1 , 079","1 , 287","1 , 000","270","661","1 , 008","Dev","389","Test","414","835","3 , 473"],"mergedAllColumns":[],"numberCells":[{"number":"51.4","isBolded":false,"associatedRows":["Chinese","WB","%Uns .","-"],"associatedColumns":["Dev","1 , 000","661","1 , 008","835","270","389"],"associatedMergedColumns":[]},{"number":"84.5","isBolded":false,"associatedRows":["Chinese","W17","%Uns .","-"],"associatedColumns":["Test","3 , 850","3 , 473","1 , 287","1 , 079"],"associatedMergedColumns":[]},{"number":"80.0","isBolded":false,"associatedRows":["English","W17","%Uns .","-"],"associatedColumns":["Test","3 , 850","3 , 473"],"associatedMergedColumns":[]},{"number":"34.8","isBolded":false,"associatedRows":["Chinese","W17","%Uns .","-"],"associatedColumns":["Dev","1 , 000","661","1 , 008","835"],"associatedMergedColumns":[]},{"number":"45.2","isBolded":false,"associatedRows":["Chinese","WB","%Uns .","-"],"associatedColumns":["Test","3 , 850","3 , 473","1 , 287","1 , 079","270","414"],"associatedMergedColumns":[]},{"number":"52.1","isBolded":false,"associatedRows":["English","W17","%Uns .","-"],"associatedColumns":["Dev","1 , 000","661"],"associatedMergedColumns":[]}]},{"caption":"Table 2: F 1 scores of the baseline model and ours enhanced with semantic augmentation (\"SE\") and the gate \nmodule (\"GA\") on the development (a) and test (b) sets. \"DS\" and \"AU \" represent the direct summation and \nattentive augmentation module, respectively. Y and N denote the use and non-use of corresponding modules. \n\n","rows":["1","2","3","4","AU","5","Y","N","DS"],"columns":["WB","W17","W16"],"mergedAllColumns":[],"numberCells":[{"number":"56.28","isBolded":false,"associatedRows":["3","DS","Y"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"52.98","isBolded":false,"associatedRows":["1","N","N","1","N","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"69.80","isBolded":true,"associatedRows":["5","AU","Y","5","AU","Y"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"48.71","isBolded":false,"associatedRows":["2","DS","N","2","DS","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"50.02","isBolded":true,"associatedRows":["5","AU","Y"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"68.46","isBolded":false,"associatedRows":["4","AU","N","4","AU","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"48.41","isBolded":false,"associatedRows":["1","N","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"54.02","isBolded":false,"associatedRows":["3","DS","Y","3","DS","Y"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"69.32","isBolded":true,"associatedRows":["5","AU","Y"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"54.79","isBolded":false,"associatedRows":["1","N","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"65.36","isBolded":false,"associatedRows":["1","N","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"48.82","isBolded":false,"associatedRows":["1","N","N","1","N","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"49.26","isBolded":false,"associatedRows":["4","AU","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"67.52","isBolded":false,"associatedRows":["3","DS","Y","3","DS","Y"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"50.36","isBolded":true,"associatedRows":["5","AU","Y","5","AU","Y"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"56.86","isBolded":false,"associatedRows":["4","AU","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"49.81","isBolded":false,"associatedRows":["4","AU","N","4","AU","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"55.01","isBolded":true,"associatedRows":["5","AU","Y","5","AU","Y"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"54.29","isBolded":false,"associatedRows":["4","AU","N","4","AU","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"48.36","isBolded":false,"associatedRows":["2","DS","N"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"66.24","isBolded":false,"associatedRows":["3","DS","Y"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"65.78","isBolded":false,"associatedRows":["2","DS","N","2","DS","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"53.11","isBolded":false,"associatedRows":["2","DS","N","2","DS","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"65.01","isBolded":false,"associatedRows":["2","DS","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"68.21","isBolded":false,"associatedRows":["4","AU","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"49.56","isBolded":false,"associatedRows":["3","DS","Y","3","DS","Y"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"57.94","isBolded":true,"associatedRows":["5","AU","Y"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"48.98","isBolded":false,"associatedRows":["3","DS","Y"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"66.02","isBolded":false,"associatedRows":["1","N","N","1","N","N"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"55.03","isBolded":false,"associatedRows":["2","DS","N"],"associatedColumns":["W16"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Comparison of F 1 scores of our best perform-\ning model (the full model with augmentation module \nand gate module) with that reported in previous studies \non all English and Chinese social media datasets. \n\n","rows":["Zhu and Wang ( 2019 )","Akbik et al . ( 2019 )","Ours","Gui et al . ( 2019 )","Yan et al . ( 2019 )","Devlin et al . ( 2019 )","Zhou et al . ( 2019 )","Sui et al . ( 2019 )","Zhang and Yang ( 2018 )","-","Xu et al . ( 2019 )","Meng et al . ( 2019 )"],"columns":["WB","W17","W16"],"mergedAllColumns":["-"],"numberCells":[{"number":"50.36","isBolded":true,"associatedRows":["Ours","-"],"associatedColumns":["W17"],"associatedMergedColumns":["-"]},{"number":"59.31","isBolded":false,"associatedRows":["Zhu and Wang ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"68.93","isBolded":false,"associatedRows":["Xu et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":["-"]},{"number":"54.36","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )"],"associatedColumns":["W16"],"associatedMergedColumns":["-"]},{"number":"67.60","isBolded":false,"associatedRows":["Meng et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":["-"]},{"number":"63.09","isBolded":false,"associatedRows":["Sui et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"48.98","isBolded":false,"associatedRows":["Yan et al . ( 2019 )","-"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"53.43","isBolded":false,"associatedRows":["Zhou et al . ( 2019 )"],"associatedColumns":["W16"],"associatedMergedColumns":["-"]},{"number":"55.01","isBolded":true,"associatedRows":["Ours"],"associatedColumns":["W16"],"associatedMergedColumns":["-"]},{"number":"59.92","isBolded":false,"associatedRows":["Gui et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"67.33","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":["-"]},{"number":"49.52","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )","-"],"associatedColumns":["W17"],"associatedMergedColumns":["-"]},{"number":"42.83","isBolded":false,"associatedRows":["Zhou et al . ( 2019 )","-"],"associatedColumns":["W17"],"associatedMergedColumns":["-"]},{"number":"54.06","isBolded":false,"associatedRows":["Yan et al . ( 2019 )"],"associatedColumns":["W16"],"associatedMergedColumns":[]},{"number":"49.59","isBolded":false,"associatedRows":["Akbik et al . ( 2019 )","-"],"associatedColumns":["W17"],"associatedMergedColumns":[]},{"number":"58.79","isBolded":false,"associatedRows":["Zhang and Yang ( 2018 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":[]},{"number":"69.80","isBolded":true,"associatedRows":["Ours","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":["-"]},{"number":"65.03","isBolded":false,"associatedRows":["Yan et al . ( 2019 )","-","-"],"associatedColumns":["WB"],"associatedMergedColumns":[]}]},{"caption":"Table 4: The recall of our models with and without \nthe attentive semantic augmentation (AU ) and the gate \nmodule (GA) on unseen named entities (whose num-\nbers are also reported at the first row) on all three \ndatasets. The results of our runs of previous models \n(marked with \"  *  \") are also reported for references. \n\n","rows":["Devlin et al . ( 2019 )","Yan et al . ( 2019 )","Baseline","Ours ( +AU +GA )"],"columns":["2778","189","912","WB","W17","W16"],"mergedAllColumns":["*"],"numberCells":[{"number":"49.02","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )"],"associatedColumns":["W16","2778"],"associatedMergedColumns":[]},{"number":"46.89","isBolded":false,"associatedRows":["Yan et al . ( 2019 )"],"associatedColumns":["W17","912"],"associatedMergedColumns":["*"]},{"number":"49.04","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["W16","2778"],"associatedMergedColumns":["*"]},{"number":"46.72","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["W17","912"],"associatedMergedColumns":["*"]},{"number":"45.98","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )"],"associatedColumns":["WB","189"],"associatedMergedColumns":[]},{"number":"51.27","isBolded":true,"associatedRows":["Ours ( +AU +GA )"],"associatedColumns":["W16","2778"],"associatedMergedColumns":["*"]},{"number":"46.73","isBolded":false,"associatedRows":["Devlin et al . ( 2019 )"],"associatedColumns":["W17","912"],"associatedMergedColumns":[]},{"number":"45.71","isBolded":false,"associatedRows":["Yan et al . ( 2019 )"],"associatedColumns":["WB","189"],"associatedMergedColumns":["*"]},{"number":"45.79","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["WB","189"],"associatedMergedColumns":["*"]},{"number":"49.45","isBolded":true,"associatedRows":["Ours ( +AU +GA )"],"associatedColumns":["W17","912"],"associatedMergedColumns":["*"]},{"number":"48.81","isBolded":true,"associatedRows":["Ours ( +AU +GA )"],"associatedColumns":["WB","189"],"associatedMergedColumns":["*"]},{"number":"48.97","isBolded":false,"associatedRows":["Yan et al . ( 2019 )"],"associatedColumns":["W16","2778"],"associatedMergedColumns":["*"]}]},{"caption":"Table 5: Experimental results (F 1 scores) of our ap-\nproach with semantic augmentation (AU ) and gate \nmodule (GA) on all datasets, where only one type of \nembeddings is used in the embedding layer to represent \nthe input sentence. The results of their corresponding \nbaseline without AU and GA are also reported. \n\n","rows":["+AU +GA","Baseline","-"],"columns":["Appendix A : Effect of Using Different","WB","W17","W16"],"mergedAllColumns":["Embeddings","Tencent","-"],"numberCells":[{"number":"52.16","isBolded":false,"associatedRows":["Baseline","+AU +GA"],"associatedColumns":["Appendix A : Effect of Using Different","W16"],"associatedMergedColumns":["Embeddings"]},{"number":"48.76","isBolded":false,"associatedRows":["Baseline","+AU +GA","-"],"associatedColumns":["Appendix A : Effect of Using Different","W17"],"associatedMergedColumns":["-"]},{"number":"54.16","isBolded":true,"associatedRows":["Baseline","+AU +GA"],"associatedColumns":["Appendix A : Effect of Using Different","W16"],"associatedMergedColumns":["-"]},{"number":"47.31","isBolded":false,"associatedRows":["Baseline","+AU +GA","-"],"associatedColumns":["Appendix A : Effect of Using Different","W17"],"associatedMergedColumns":["Embeddings"]},{"number":"48.33","isBolded":false,"associatedRows":["Baseline","-"],"associatedColumns":["Appendix A : Effect of Using Different","W17"],"associatedMergedColumns":["-"]},{"number":"49.57","isBolded":true,"associatedRows":["Baseline","+AU +GA","-"],"associatedColumns":["Appendix A : Effect of Using Different","W17"],"associatedMergedColumns":["-"]},{"number":"60.54","isBolded":false,"associatedRows":["Baseline","-","-"],"associatedColumns":["Appendix A : Effect of Using Different","WB"],"associatedMergedColumns":["-"]},{"number":"66.09","isBolded":false,"associatedRows":["Baseline","-","-"],"associatedColumns":["Appendix A : Effect of Using Different","WB"],"associatedMergedColumns":["Tencent"]},{"number":"52.09","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["Appendix A : Effect of Using Different","W16"],"associatedMergedColumns":["-"]},{"number":"63.12","isBolded":false,"associatedRows":["Baseline","+AU +GA","-","-"],"associatedColumns":["Appendix A : Effect of Using Different","WB"],"associatedMergedColumns":["-"]},{"number":"54.31","isBolded":false,"associatedRows":["Baseline","+AU +GA"],"associatedColumns":["Appendix A : Effect of Using Different","W16"],"associatedMergedColumns":["-"]},{"number":"68.96","isBolded":true,"associatedRows":["Baseline","+AU +GA","-","-"],"associatedColumns":["Appendix A : Effect of Using Different","WB"],"associatedMergedColumns":["Tencent"]}]},{"caption":"Table 6: Experimental results (F 1 scores) of our model \nwith AU and GA on the WB dataset, where BERT or \nZEN is used as one of the two types of embeddings (the \nother one is Tencent Embedding) to represent the input \nsentence for the embedding layer. \n\n","rows":["BERT + Tencent","ZEN + Tencent"],"columns":["WB","Appendix B : Comparison Between BERT"],"mergedAllColumns":["and ZEN on WB"],"numberCells":[{"number":"69.80","isBolded":true,"associatedRows":["ZEN + Tencent"],"associatedColumns":["Appendix B : Comparison Between BERT","WB"],"associatedMergedColumns":["and ZEN on WB"]},{"number":"69.56","isBolded":false,"associatedRows":["BERT + Tencent"],"associatedColumns":["Appendix B : Comparison Between BERT","WB"],"associatedMergedColumns":["and ZEN on WB"]}]},{"caption":"Table 7: Experimental results (F 1 scores) of our best \nperforming models (i.e., the ones with AU and GA) \nusing different types of pre-trained embeddings as the \nsource to extract similar words. The results of baseline \n(the one without AU and GA) are also reported. \n\n","rows":["Word2vec","Ours","GloVe","( +AU +GA )","Tencent","Baseline","-","Giga"],"columns":["Appendix C : Effect of Using Different","WB","W17","W16"],"mergedAllColumns":["Embeddings to Extract Similar Words","-"],"numberCells":[{"number":"69.80","isBolded":true,"associatedRows":["( +AU +GA )","Tencent","-","-"],"associatedColumns":["Appendix C : Effect of Using Different","WB"],"associatedMergedColumns":["-"]},{"number":"49.56","isBolded":false,"associatedRows":["Baseline","Word2vec"],"associatedColumns":["Appendix C : Effect of Using Different","W16"],"associatedMergedColumns":["Embeddings to Extract Similar Words"]},{"number":"55.01","isBolded":true,"associatedRows":["Ours","GloVe"],"associatedColumns":["Appendix C : Effect of Using Different","W16"],"associatedMergedColumns":["-"]},{"number":"69.68","isBolded":false,"associatedRows":["( +AU +GA )","Giga","-","-"],"associatedColumns":["Appendix C : Effect of Using Different","WB"],"associatedMergedColumns":["-"]},{"number":"66.02","isBolded":false,"associatedRows":["Baseline","Word2vec","-","-"],"associatedColumns":["Appendix C : Effect of Using Different","WB"],"associatedMergedColumns":["Embeddings to Extract Similar Words"]},{"number":"50.36","isBolded":true,"associatedRows":["Ours","GloVe","-"],"associatedColumns":["Appendix C : Effect of Using Different","W17"],"associatedMergedColumns":["-"]},{"number":"50.22","isBolded":false,"associatedRows":["( +AU +GA )","Word2vec","-"],"associatedColumns":["Appendix C : Effect of Using Different","W17"],"associatedMergedColumns":["Embeddings to Extract Similar Words"]},{"number":"49.11","isBolded":false,"associatedRows":["Baseline","Word2vec","-"],"associatedColumns":["Appendix C : Effect of Using Different","W17"],"associatedMergedColumns":["Embeddings to Extract Similar Words"]},{"number":"54.94","isBolded":false,"associatedRows":["( +AU +GA )","Word2vec"],"associatedColumns":["Appendix C : Effect of Using Different","W16"],"associatedMergedColumns":["Embeddings to Extract Similar Words"]}]},{"caption":"Table 7. The result \nof the baseline model without AU and GA is also \nreported for reference. The results show that our \napproach can consistently outperforms the baseline \nwith different sources to find similar words, which \ndemonstrates the robustness of our approach. \n\n","rows":["Number of head","# of similar of words ( m )","8 , 16 ,","Dropout rate","Batch size","0 ,","4 , 8 ,","5 , 10 ,"],"columns":[", e ? 4 , e","2","1 , 2 , 4","128","Values","? 4","Best","Appendix D : Hyper - parameter Settings","64 , 128 , 256"],"mergedAllColumns":[],"numberCells":[{"number":"0.2,","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":["# of similar of words ( m )","5 , 10 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4","2","128"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["Number of head","4 , 8 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4","2"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","8 , 16 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4"],"associatedMergedColumns":[]},{"number":"0.1,","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["# of similar of words ( m )","5 , 10 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e","1 , 2 , 4","64 , 128 , 256"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","8 , 16 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["Number of head","4 , 8 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e","1 , 2 , 4"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best"],"associatedMergedColumns":[]}]},{"caption":"Table 8: All values of different hyper-parameters as \nwell as the best one used in our experiments. \n\n","rows":["Number of head","# of similar of words ( m )","8 , 16 ,","Dropout rate","Batch size","0 ,","4 , 8 ,","5 , 10 ,"],"columns":[", e ? 4 , e","2","1 , 2 , 4","128","Values","? 4","Best","Appendix D : Hyper - parameter Settings","64 , 128 , 256"],"mergedAllColumns":[],"numberCells":[{"number":"32","isBolded":false,"associatedRows":["Batch size","8 , 16 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best"],"associatedMergedColumns":[]},{"number":"0.2,","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["Number of head","4 , 8 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e","1 , 2 , 4"],"associatedMergedColumns":[]},{"number":"20","isBolded":false,"associatedRows":["# of similar of words ( m )","5 , 10 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values",", e ? 4 , e","1 , 2 , 4","64 , 128 , 256"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["Batch size","8 , 16 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":["# of similar of words ( m )","5 , 10 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4","2","128"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["Number of head","4 , 8 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Best","? 4","2"],"associatedMergedColumns":[]},{"number":"0.1,","isBolded":false,"associatedRows":["Dropout rate","0 ,"],"associatedColumns":["Appendix D : Hyper - parameter Settings","Values"],"associatedMergedColumns":[]}]}]