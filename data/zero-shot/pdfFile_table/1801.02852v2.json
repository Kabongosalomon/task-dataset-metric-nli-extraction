[{"caption":"Table 1: Hyperparameters of the distributed BA3C implementation \n\nSymbol \nDefault \nvalue \nDescription \n\nn \n64 \nNumber of CPU nodes used for the distributed training \n\nc \n12 \nNumber of cores in each worker CPU \n\n? \n0.001 Learning rate (step-size) \n\nbs \n32 \nNumber of data-points in each training batch (on each node) \n\nps \n4 \nNumber of nodes responsible for holding the model parameters \n\nn_sim \n10 \nNumber of Atari simulators used simultaneously on one worker \n\n? \n10 ?8 Constant used for numerical stability in the Adam optimizer \n?1, ?2 0.8, 0.75 Decay rates of the running averages used in Adam optimizer \n\n","rows":["bs","c","?","?1 , ?2","?","n_sim","n"],"columns":["Description","4","? 8","Symbol","Table 1 : Hyperparameters of the distributed BA3C implementation","Constant used for numerical stability in the Adam optimizer","Number of nodes responsible for holding the model parameters"],"mergedAllColumns":["Learning rate ( step - size )","Number of CPU nodes used for the distributed training","Number of cores in each worker CPU","Number of Atari simulators used simultaneously on one worker","value","Number of data - points in each training batch ( on each node )"],"numberCells":[{"number":"32","isBolded":false,"associatedRows":["bs"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol"],"associatedMergedColumns":["Learning rate ( step - size )"]},{"number":"10","isBolded":true,"associatedRows":["?"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol","4"],"associatedMergedColumns":["Number of Atari simulators used simultaneously on one worker"]},{"number":"0.001","isBolded":false,"associatedRows":["?"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol"],"associatedMergedColumns":["Number of cores in each worker CPU"]},{"number":"0.8,","isBolded":false,"associatedRows":["?1 , ?2"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol","4","? 8"],"associatedMergedColumns":["Number of Atari simulators used simultaneously on one worker"]},{"number":"12","isBolded":false,"associatedRows":["c"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol"],"associatedMergedColumns":["Number of CPU nodes used for the distributed training"]},{"number":"0.75DecayratesoftherunningaveragesusedinAdamoptimizer","isBolded":false,"associatedRows":["?1 , ?2"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Description","Number of nodes responsible for holding the model parameters","Constant used for numerical stability in the Adam optimizer"],"associatedMergedColumns":["Number of Atari simulators used simultaneously on one worker"]},{"number":"64","isBolded":false,"associatedRows":["n"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol"],"associatedMergedColumns":["value"]},{"number":"10","isBolded":false,"associatedRows":["n_sim"],"associatedColumns":["Table 1 : Hyperparameters of the distributed BA3C implementation","Symbol","4"],"associatedMergedColumns":["Number of data - points in each training batch ( on each node )"]}]},{"caption":"Table 2: Number of network parame-\nters when considering different number \nof neurons in the fully connected layer. \n\n","rows":["0","score","loss","total","Fig . 4 : Experiment with a learning rate ? \u003d","16","of 64 , total batch size of 4096 . Increasing the learning rate for the Adam optimizer from","online","50","to","64","32"],"columns":["0","hidden","( b ) Total training loss","80","60","weights","40","neurons","20","time [ minutes ]","network"],"mergedAllColumns":["100%","33%","training loss plot ( figure 4b )","43%","61%"],"numberCells":[{"number":"152","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","16"],"associatedColumns":["0","20","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["33%"]},{"number":"128","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total"],"associatedColumns":["0","0","time [ minutes ]","( b ) Total training loss","hidden","neurons"],"associatedMergedColumns":["100%"]},{"number":"0.05","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","score","loss"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.001","isBolded":true,"associatedRows":["of 64 , total batch size of 4096 . Increasing the learning rate for the Adam optimizer from","64"],"associatedColumns":["0","80","time [ minutes ]","( b ) Total training loss"],"associatedMergedColumns":[]},{"number":"295","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","40","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["100%"]},{"number":"100","isBolded":false,"associatedRows":[],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"200","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"229","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","20","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["61%"]},{"number":"927","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","32"],"associatedColumns":["0","40","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["43%"]},{"number":"538","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","20","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["training loss plot ( figure 4b )"]},{"number":"256","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total"],"associatedColumns":["0","0","time [ minutes ]","( b ) Total training loss","hidden","neurons"],"associatedMergedColumns":["training loss plot ( figure 4b )"]},{"number":"199","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","16"],"associatedColumns":["0","40","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["33%"]},{"number":"?0.15","isBolded":true,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","50","total"],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"0.15","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","loss"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"?0.1","isBolded":true,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total"],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"0.002causeslargeinstabilitiesclearlyvisibleontheonlinescoreplot(figure4a)andthetotal","isBolded":true,"associatedRows":["to"],"associatedColumns":["0","60","time [ minutes ]","( b ) Total training loss"],"associatedMergedColumns":[]},{"number":"150","isBolded":false,"associatedRows":[],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"177","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","32"],"associatedColumns":["0","20","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["43%"]},{"number":"?0.05","isBolded":true,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","online","total"],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","loss"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"?0.2","isBolded":true,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","0","total"],"associatedColumns":["0"],"associatedMergedColumns":[]},{"number":"250","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"119","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","40","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["training loss plot ( figure 4b )"]},{"number":"300","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.002.64nodes,synchronoustraining,localbatchsize","isBolded":true,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d"],"associatedColumns":["0","60","time [ minutes ]","( b ) Total training loss"],"associatedMergedColumns":[]},{"number":"350","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","score","loss"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"383","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","40","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["61%"]},{"number":"400","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"332","isBolded":false,"associatedRows":["Fig . 4 : Experiment with a learning rate ? \u003d","total","64"],"associatedColumns":["0","20","time [ minutes ]","( b ) Total training loss","network","weights"],"associatedMergedColumns":["100%"]}]}]