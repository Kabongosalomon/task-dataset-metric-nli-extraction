1802.05415v2.pdf	Optical Character Recognition#im2latex-100k#BLEU#88.86%$Optical Character Recognition#I2L-140K#BLEU#89.09%$Optical Character Recognition#I2L-140K#BLEU#89%
1704.03549v4.pdf	Optical Character Recognition#FSNS - Test#Sequence error#15.8
1712.05404.pdf	Optical Character Recognition#FSNS - Test#Sequence error#22
1702.03970v1.pdf	Optical Character Recognition#FSNS - Test#Sequence error#27.54
2206.00311v1.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#82.6
1811.00751v2.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#67.3$Scene Text Recognition#ICDAR2015#Accuracy#69.2$Scene Text Recognition#SVT#Accuracy#84.5$Scene Text Recognition#ICDAR2013#Accuracy#91.0
1507.05717v1.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#67.0$Scene Text Recognition#SVT#Accuracy#80.8$Scene Text Recognition#ICDAR 2003#Accuracy#89.4$Scene Text Recognition#ICDAR2013#Accuracy#86.7
2003.12294v1.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#65.0$Scene Text Recognition#SVT#Accuracy#91.5$Scene Text Recognition#ICDAR2013#Accuracy#95.5
1901.03003v1.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#64.3
2005.10977v1.pdf	Optical Character Recognition#Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study#Accuracy (%)#61.2$Scene Text Recognition#ICDAR2015#Accuracy#80$Scene Text Recognition#SVT#Accuracy#89.6$Scene Text Recognition#ICDAR2013#Accuracy#92.8
2201.07459v3.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#95.13
2202.02794v4.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#93.2
1905.03677v1.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#91.01
2006.10219v3.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#90.70
1708.00489v4.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#89.92
2002.09564v3.pdf	Active Learning#CIFAR10 (10,000)#Accuracy#88.45$Active Learning#CIFAR10 (10,000)#Accuracy#85.09
2104.02324v1.pdf	Active Object Detection#COCO#AP#(7.3, 13.8, 16.9, 19.1, 20.8) on 2% ~ 10%$Active Object Detection#PASCAL VOC 07+12#mAP#(47.18, 58.41, 64.02, 67.72, 69.79, 71.07, 72.27) on 5% ~ 20%$Active Object Detection#PASCAL VOC 07+12#mAP#(53.62, 62.86, 66.83, 69.33, 70.80, 72.21, 72.84, 73.74, 74.18, 74.91) on 1k ~ 10k
2110.04075v1.pdf	Handwriting Recognition#KOHTD#CER#6.52$Handwriting Recognition#KOHTD#CER#8.01$Handwriting Recognition#KOHTD#CER#8.22$Handwriting Recognition#KOHTD#CER#8.36
2008.12995v3.pdf	Handwriting Recognition#BanglaLekha Isolated Dataset#Accuracy#96.8$Handwriting Recognition#BanglaLekha Isolated Dataset#Epochs#11$Handwriting Recognition#BanglaLekha Isolated Dataset#Cross Entropy Loss#0.21612$Transfer Learning#BanglaLekha Isolated Dataset#Accuracy#96.12
1510.05067v4.pdf	Handwritten Digit Recognition#MNIST#PERCENTAGE ERROR#0.91$Image Classification#CIFAR-100#Percentage correct#48.75$Image Classification#SVHN#Percentage error#10.16$Image Classification#STL-10#Percentage correct#57.32$Image Classification#CIFAR-10#Percentage correct#80.98
2202.08771v3.pdf	Deblurring#RSBlur (trained on synthetic)#Average PSNR#32.08$Deblurring#RSBlur (trained on synthetic)#Average PSNR#32.06
2201.12288v2.pdf	Deblurring#REDS#Average PSNR#36.79$Deblurring#DVD#PSNR#34.27$Deblurring#GoPro#PSNR#34.81$Deblurring#GoPro#SSIM#0.9724$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#31.01$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.343$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.869$Video Super-Resolution#UDM10 - 4x upscaling#PSNR#41.05$Video Super-Resolution#UDM10 - 4x upscaling#SSIM#0.9737$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#7.628$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.758$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.722$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.902$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#31.669$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#2.778$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.929$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.578$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.245$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.7$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.09$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.662$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.259$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#8.92$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.023$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.217$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.634$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.257$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.329$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.333$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.235$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.652$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.777$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.836$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.496$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.619$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.511$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.425$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.862$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.982$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.003$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#12.289$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.631$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.733$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.075$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#2.797$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.429$Video Frame Interpolation#Vid4 - 4x upscaling#PSNR#27.46$Video Frame Interpolation#Vid4 - 4x upscaling#SSIM#0.8392$Video Frame Interpolation#Vid4 - 4x upscaling#Parameters#4450000$Video Denoising#Set8 sigma50#PSNR#31.22$Video Denoising#Set8 sigma20#PSNR#35.02$Video Denoising#Set8 sigma40#PSNR#32.15$Video Denoising#DAVIS sigma20#PSNR#38.15$Video Denoising#Set8 sigma10#PSNR#37.88$Video Denoising#DAVIS sigma10#PSNR#40.82$Video Denoising#Set8 sigma30#PSNR#33.35$Video Denoising#DAVIS sigma40#PSNR#35.32$Video Denoising#DAVIS sigma50#PSNR#34.36$Video Denoising#DAVIS sigma30#PSNR#36.52$Space-time Video Super-resolution#Vimeo90K-Medium#PSNR#36.01$Space-time Video Super-resolution#Vimeo90K-Medium#SSIM#0.9434$Space-time Video Super-resolution#Vimeo90K-Fast#PSNR#36.98$Space-time Video Super-resolution#Vimeo90K-Fast#SSIM#0.9439
1905.02716v1.pdf	Deblurring#REDS#Average PSNR#34.80$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.35$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.8264$Video Enhancement#MFQE v2#Incremental PSNR#0.75
1711.07064v4.pdf	Deblurring#REDS#Average PSNR#24.09$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.834$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.903
2106.03106v2.pdf	Deblurring#RSBlur#Average PSNR#33.98$Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#29.06$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.884$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#30.83$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.952$Deblurring#GoPro#PSNR#32.97$Deblurring#GoPro#SSIM#0.967$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#36.22$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.957$Image Enhancement#TIP 2018#PSNR#29.28$Image Enhancement#TIP 2018#SSIM#0.917$Image Dehazing#SOTS Indoor#PSNR#31.91$Image Dehazing#SOTS Indoor#SSIM#0.971$Image Dehazing#SOTS Outdoor#PSNR#26.52$Image Dehazing#SOTS Outdoor#SSIM#0.945$Image Denoising#SIDD#PSNR (sRGB)#39.89$Image Denoising#SIDD#SSIM (sRGB)#0.960$Image Denoising#DND#PSNR (sRGB)#39.98$Image Denoising#DND#SSIM (sRGB)#0.955
2111.09881v2.pdf	Deblurring#RSBlur#Average PSNR#33.69$Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.96$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.879$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#31.22$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.942$Deblurring#GoPro#PSNR#32.92$Deblurring#GoPro#SSIM#0.961$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#36.19$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.957$Single Image Deraining#Test100#PSNR#32.00$Single Image Deraining#Test100#SSIM#0.923$Single Image Deraining#Rain100H#PSNR#31.46$Single Image Deraining#Rain100H#SSIM#0.904$Single Image Deraining#Test2800#PSNR#34.18$Single Image Deraining#Test2800#SSIM#0.944$Single Image Deraining#Test1200#PSNR#33.19$Single Image Deraining#Test1200#SSIM#0.926$Single Image Deraining#Rain100L#PSNR#38.99$Single Image Deraining#Rain100L#SSIM#0.978$Image Denoising#SIDD#PSNR (sRGB)#40.02$Image Denoising#SIDD#SSIM (sRGB)#0.960$Image Denoising#DND#PSNR (sRGB)#40.03$Image Denoising#DND#SSIM (sRGB)#0.956$Color Image Denoising#Urban100 sigma25#PSNR#32.96$Color Image Denoising#Kodak24 sigma50#PSNR#30.01$Color Image Denoising#Urban100 sigma50#PSNR#30.02$Grayscale Image Denoising#Urban100 sigma25#PSNR#31.46$Grayscale Image Denoising#Urban100 sigma15#PSNR#33.79$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.96$Grayscale Image Denoising#Urban100 sigma50#PSNR#28.29
2102.02808v2.pdf	Deblurring#RSBlur#Average PSNR#33.61$Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.70$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.873$Deblurring#RealBlur-R#PSNR (sRGB)#39.31$Deblurring#RealBlur-R#SSIM (sRGB)#0.972$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#30.96$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.939$Deblurring#GoPro#PSNR#32.66$Deblurring#GoPro#SSIM#0.959$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#35.99$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.952$Deblurring#RealBlur-J#SSIM (sRGB)#0.922$Deblurring#RealBlur-J#PSNR (sRGB)#31.76$Single Image Deraining#Test100#PSNR#30.27$Single Image Deraining#Test100#SSIM#0.897$Single Image Deraining#Rain100H#PSNR#30.41$Single Image Deraining#Rain100H#SSIM#0.89$Single Image Deraining#Test2800#PSNR#33.64$Single Image Deraining#Test2800#SSIM#0.938$Single Image Deraining#Test1200#PSNR#32.91$Single Image Deraining#Test1200#SSIM#0.916$Single Image Deraining#Rain100L#PSNR#36.40$Single Image Deraining#Rain100L#SSIM#0.965$Image Denoising#SIDD#PSNR (sRGB)#39.71$Image Denoising#SIDD#SSIM (sRGB)#0.958$Image Denoising#DND#PSNR (sRGB)#39.80$Image Denoising#DND#SSIM (sRGB)#0.954
2108.05054v2.pdf	Deblurring#RSBlur#Average PSNR#33.37$Deblurring#RSBlur#Average PSNR#32.73$Deblurring#GoPro#PSNR#32.68$Deblurring#GoPro#SSIM#0.959$Deblurring#RealBlur-J#SSIM (sRGB)#0.921$Deblurring#RealBlur-J#PSNR (sRGB)#32.05
1802.01770v1.pdf	Deblurring#RSBlur#Average PSNR#32.53$Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.56$Deblurring#RealBlur-R#PSNR (sRGB)#38.65$Deblurring#RealBlur-R#SSIM (sRGB)#0.965$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#28.36$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.915$Deblurring#GoPro#SSIM#0.9342$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.947$Deblurring#RealBlur-J#SSIM (sRGB)#0.909$Deblurring#RealBlur-J#PSNR (sRGB)#31.38$Image Relighting#VIDIT’20 validation set#PSNR#16.94$Image Relighting#VIDIT’20 validation set#SSIM#0.5660$Image Relighting#VIDIT’20 validation set#LPIPS#0.4319$Image Relighting#VIDIT’20 validation set#MPS#0.5670$Image Relighting#VIDIT’20 validation set#Runtime(s)#0.87
2201.02973v2.pdf	Deblurring#HIDE#PSNR#32.83$Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.83$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.875$Deblurring#RealBlur-R#PSNR (sRGB)#39.45$Deblurring#RealBlur-R#SSIM#0.961$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#32.83$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.956$Deblurring#GoPro#PSNR#32.86$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#35.78$Deblurring#RealBlur-J#SSIM (sRGB)#0.935$Deblurring#RealBlur-J#PSNR (sRGB)#32.84$Low-Light Image Enhancement#LOL#Average PSNR#23.43$Low-Light Image Enhancement#LOL#SSIM#0.863$Single Image Deraining#Test100#PSNR#31.17$Single Image Deraining#Test100#SSIM#0.922$Single Image Deraining#Rain100H#SSIM#0.903$Single Image Deraining#Test2800#PSNR#33.80$Single Image Deraining#Test1200#SSIM#0.922$Single Image Deraining#Rain100L#SSIM#0.977$Image Dehazing#SOTS Indoor#PSNR#38.11$Image Dehazing#SOTS Outdoor#PSNR#34.19$Image Denoising#SIDD#PSNR (sRGB)#39.96$Image Denoising#SIDD#SSIM (sRGB)#0.960$Image Denoising#DND#PSNR (sRGB)#39.84$Image Denoising#DND#SSIM (sRGB)#0.954
2111.11745v1.pdf	Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.97$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.884$Deblurring#RealBlur-R#PSNR (sRGB)#39.84$Deblurring#RealBlur-R#SSIM (sRGB)#0.972$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#31.42$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.944$Deblurring#GoPro#PSNR#33.23$Deblurring#GoPro#SSIM#0.963$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#36.06$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.954$Deblurring#RealBlur-J#SSIM (sRGB)#0.931$Deblurring#RealBlur-J#PSNR (sRGB)#32.19
2202.09652v3.pdf	Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.79$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.879$Deblurring#RealBlur-R#PSNR (sRGB)#39.76$Deblurring#RealBlur-R#SSIM (sRGB)#0.972$Deblurring#GoPro#PSNR#33.39$Deblurring#GoPro#SSIM#0.964$Deblurring#GoPro#PSNR#33.01$Deblurring#GoPro#SSIM#0.961$Deblurring#GoPro#PSNR#32.02$Deblurring#GoPro#SSIM#0.953$Deblurring#RealBlur-R (trained on GoPro)#PSNR (sRGB)#35.93$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.953$Deblurring#RealBlur-J#SSIM (sRGB)#0.928$Deblurring#RealBlur-J#PSNR (sRGB)#32.1
1908.03826v1.pdf	Deblurring#RealBlur-J (trained on GoPro)#PSNR (sRGB)#28.70$Deblurring#RealBlur-J (trained on GoPro)#SSIM (sRGB)#0.866$Deblurring#RealBlur-R#PSNR (sRGB)#36.44$Deblurring#RealBlur-R#SSIM (sRGB)#0.935$Deblurring#GoPro#PSNR#29.55$Deblurring#GoPro#SSIM#0.934$Deblurring#GoPro#PSNR#28.17$Deblurring#GoPro#SSIM#0.925$Deblurring#GoPro#PSNR#28.03$Deblurring#GoPro#SSIM#0.922$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.944$Deblurring#RealBlur-J#SSIM (sRGB)#0.870$Deblurring#RealBlur-J#PSNR (sRGB)#29.69$Blind Face Restoration#CelebA-Test#LPIPS#40.01$Blind Face Restoration#CelebA-Test#FID#52.69$Blind Face Restoration#CelebA-Test#NIQE#4.917$Blind Face Restoration#CelebA-Test#Deg.#39.64$Blind Face Restoration#CelebA-Test#PSNR#25.91$Blind Face Restoration#CelebA-Test#SSIM#0.6952
2104.07925v1.pdf	Deblurring#Second dialogue state tracking challenge#MAE#0.0377
2204.04627v2.pdf	Deblurring#RealBlur-R#PSNR (sRGB)#39.84$Deblurring#RealBlur-R#SSIM (sRGB)#0.974$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#31.03$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.94$Deblurring#GoPro#PSNR#33.08$Deblurring#GoPro#SSIM#0.962$Deblurring#RealBlur-J#SSIM (sRGB)#0.929$Deblurring#RealBlur-J#PSNR (sRGB)#32.48
2101.07518v4.pdf	Deblurring#RealBlur-R#PSNR (sRGB)#39.55$Deblurring#RealBlur-R#SSIM (sRGB)#0.971$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#30.16$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.93$Deblurring#GoPro#PSNR#32.54$Deblurring#GoPro#SSIM#0.957$Deblurring#RealBlur-J#SSIM (sRGB)#0.923$Deblurring#RealBlur-J#PSNR (sRGB)#32.00
2112.04491v4.pdf	Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#31.49$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.945$Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#31.19$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.942$Deblurring#GoPro#PSNR#33.8$Deblurring#GoPro#SSIM#0.966$Deblurring#GoPro#PSNR#33.57$Deblurring#GoPro#PSNR#33.31$Deblurring#GoPro#SSIM#0.964$Deblurring#GoPro#PSNR#33.08$Deblurring#GoPro#SSIM#0.962$Color Image Denoising#Urban100 sigma30#PSNR#33.06$Color Image Denoising#Urban100 sigma50#PSNR#30.17$Grayscale Image Denoising#Urban100 sigma25#PSNR#31.55$Grayscale Image Denoising#urban100 sigma15#PSNR#33.85$Grayscale Image Denoising#Urban100 sigma50#PSNR#28.41
1911.07410v1.pdf	Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#29.15$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.918$Deblurring#GoPro#PSNR#31.15$Deblurring#GoPro#SSIM#0.945
1904.03468v1.pdf	Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#29.09$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.924$Deblurring#GoPro#PSNR#31.50$Deblurring#GoPro#SSIM#0.9483$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.948
2004.01860v2.pdf	Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#28.94$Deblurring#HIDE (trained on GOPRO)#SSIM (sRGB)#0.915$Deblurring#GoPro#PSNR#31.10$Deblurring#GoPro#SSIM#0.9424
1612.02177v2.pdf	Deblurring#HIDE (trained on GOPRO)#PSNR (sRGB)#25.73$Deblurring#GoPro#PSNR#29.08$Deblurring#GoPro#SSIM#0.9135$Deblurring#RealBlur-R (trained on GoPro)#SSIM (sRGB)#0.841
2201.01893v3.pdf	Deblurring#DVD#PSNR#33.03$Deblurring#GoPro#PSNR#33.03$Deblurring#GoPro#SSIM#0.964
2004.02501v1.pdf	Deblurring#DVD#PSNR#32.13$Deblurring#GoPro#PSNR#31.67$Deblurring#GoPro#SSIM#0.9279
1904.12257v2.pdf	Deblurring#DVD#PSNR#31.27$Deblurring#GoPro#PSNR#28.59$Deblurring#GoPro#SSIM#0.861
2112.00167v2.pdf	Deblurring#GoPro#PSNR#35.46$Deblurring#GoPro#SSIM#0.972
2204.04676v4.pdf	Deblurring#GoPro#PSNR#33.69$Deblurring#GoPro#SSIM#0.967$Image Denoising#SIDD#PSNR (sRGB)#40.30$Image Denoising#SIDD#SSIM (sRGB)#0.962
2112.05150v1.pdf	Deblurring#GoPro#PSNR#33.32$Deblurring#GoPro#SSIM#0.9627
2105.06086v2.pdf	Deblurring#GoPro#PSNR#32.71$Single Image Deraining#Test100#PSNR#30.29$Single Image Deraining#Test100#SSIM#0.906$Single Image Deraining#Rain100H#PSNR#30.65$Single Image Deraining#Rain100H#SSIM#0.894$Single Image Deraining#Test2800#PSNR#33.91$Single Image Deraining#Test2800#SSIM#0.941$Single Image Deraining#Test1200#PSNR#33.05$Single Image Deraining#Test1200#SSIM#0.919$Single Image Deraining#Rain100L#PSNR#37.28$Single Image Deraining#Rain100L#SSIM#0.97$Image Denoising#SIDD#PSNR (sRGB)#39.99$Image Denoising#SIDD#SSIM (sRGB)#0.958
2012.12507v1.pdf	Deblurring#GoPro#PSNR#32.16$Deblurring#GoPro#SSIM#0.953$Deblurring#DVD#PSNR#32.34
1903.11394v4.pdf	Deblurring#GoPro#PSNR#32.15$Deblurring#GoPro#SSIM#0.9560
2004.05343v1.pdf	Deblurring#GoPro#PSNR#32.02$Deblurring#GoPro#SSIM#0.953
2205.10195v2.pdf	Deblurring#GoPro#PSNR#31.82$Deblurring#GoPro#SSIM#0.923$Video Super-Resolution#Vimeo90K#PSNR#37.63$Video Enhancement#MFQE v2#Incremental PSNR#0.93
2004.05794v1.pdf	Deblurring#GoPro#PSNR#31.79$Deblurring#GoPro#SSIM#0.949
2106.16028v2.pdf	Deblurring#GoPro#PSNR#31.07$Deblurring#GoPro#SSIM#0.9023
1804.02913v2.pdf	Deblurring#GoPro#PSNR#30.58$Deblurring#GoPro#SSIM#0.941
1712.04976v2.pdf	Deblurring#GoPro#PSNR#30.12$Deblurring#GoPro#SSIM#0.9021$3D Face Animation#2D-3D-S#1*1#5$2D Semantic Segmentation#Time Series Prediction Benchmarks#1:3 Accuracy#dd
2109.10257v2.pdf	Trajectory Prediction#PROX#FDE#288$Trajectory Prediction#PROX#ADE#280$Trajectory Prediction#PROX#STB#6$Trajectory Prediction#GTA-IM Dataset#FDE#208$Trajectory Prediction#GTA-IM Dataset#ADE#192$Trajectory Prediction#GTA-IM Dataset#STB#11
2103.14107v3.pdf	Trajectory Prediction#HEV-I#ADE(0.5)#6.28$Trajectory Prediction#HEV-I#ADE(1.0)#11.35$Trajectory Prediction#HEV-I#ADE(1.5)#18.27$Trajectory Prediction#HEV-I#FDE(1.5)#39.86$Trajectory Prediction#HEV-I#FIOU(1.5)#0.63$Trajectory Prediction#PIE#MSE(0.5)#34$Trajectory Prediction#PIE#MSE(1.0)#133$Trajectory Prediction#PIE#MSE(1.5)#442$Trajectory Prediction#PIE#C_MSE(1.5)#413$Trajectory Prediction#PIE#CF_MSE(1.5)#1761$Trajectory Prediction#ETH/UCY#ADE-8/12#0.18$Trajectory Prediction#ETH/UCY#FDE-8/12#0.35$Trajectory Prediction#JAAD#MSE(0.5)#82$Trajectory Prediction#JAAD#MSE(1.0)#328$Trajectory Prediction#JAAD#MSE(1.5)#1049$Trajectory Prediction#JAAD#C_MSE(1.5)#996$Trajectory Prediction#JAAD#CF_MSE(1.5)#4076
1903.00618v4.pdf	Trajectory Prediction#HEV-I#ADE(0.5)#6.70$Trajectory Prediction#HEV-I#ADE(1.0)#12.60$Trajectory Prediction#HEV-I#ADE(1.5)#20.40$Trajectory Prediction#HEV-I#FDE(1.5)#44.10$Trajectory Prediction#HEV-I#FIOU(1.5)#0.61$Trajectory Prediction#PIE#MSE(0.5)#147$Trajectory Prediction#PIE#MSE(1.0)#484$Trajectory Prediction#PIE#MSE(1.5)#1374$Trajectory Prediction#PIE#C_MSE(1.5)#1290$Trajectory Prediction#PIE#CF_MSE(1.5)#4924$Trajectory Prediction#JAAD#MSE(0.5)#147$Trajectory Prediction#JAAD#MSE(1.0)#484$Trajectory Prediction#JAAD#MSE(1.5)#1374$Trajectory Prediction#JAAD#C_MSE(1.5)#1290$Trajectory Prediction#JAAD#CF_MSE(1.5)#4924$Traffic Accident Detection#SA#AUC#55.6$Traffic Accident Detection#A3D#AUC#60.1
2012.11717v3.pdf	Trajectory Prediction#TrajNet++#FDE#1.14$Trajectory Prediction#TrajNet++#COL#5.31$Trajectory Prediction#ETH/UCY#ADE-8/12#0.19$Trajectory Prediction#ETH/UCY#FDE-8/12#0.40$Trajectory Forecasting#TrajNet++#FDE#1.14$Trajectory Forecasting#TrajNet++#COL#5.31
2106.04419v2.pdf	Trajectory Prediction#TrajNet++#FDE#1.150$Trajectory Prediction#TrajNet++#COL#6.560$Trajectory Forecasting#TrajNet++#FDE#1.150$Trajectory Forecasting#TrajNet++#COL#6.560
2007.03639v3.pdf	Trajectory Prediction#TrajNet++#FDE#1.17$Trajectory Prediction#TrajNet++#COL#7.59$Trajectory Forecasting#TrajNet++#FDE#1.17$Trajectory Forecasting#TrajNet++#COL#7.59
2005.12661v2.pdf	Trajectory Prediction#STATS SportVu NBA [DEF]#ADE#7.01$Trajectory Prediction#STATS SportVu NBA [DEF]#FDE#9.76$Trajectory Prediction#STATS SportVu NBA [ATK]#ADE#9.18$Trajectory Prediction#STATS SportVu NBA [ATK]#FDE#13.54$Trajectory Prediction#Stanford Drone#ADE (in world coordinates)#0.54$Trajectory Prediction#Stanford Drone#FDE (in world coordinates)#1.05
1704.04394v1.pdf	Trajectory Prediction#PAID#minFDE3#0.59$Trajectory Prediction#PAID#minADE3#0.29$Trajectory Prediction#INTERACTION Dataset - Validation#minADE6#0.32$Trajectory Prediction#INTERACTION Dataset - Validation#minFDE6#0.88$Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#19.25$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#34.05$Trajectory Prediction#Stanford Drone#ADE (8/12) @K=5#19.25$Trajectory Prediction#Stanford Drone#FDE(8/12) @K=5#34.05
1910.05449v1.pdf	Trajectory Prediction#PAID#minFDE3#0.43$Trajectory Prediction#PAID#minADE3#0.23
2008.08294v2.pdf	Trajectory Prediction#PAID#minFDE3#0.32$Trajectory Prediction#PAID#minADE3#0.18$Trajectory Prediction#INTERACTION Dataset - Validation#minADE6#0.21$Trajectory Prediction#INTERACTION Dataset - Validation#minFDE6#0.67$Trajectory Prediction#Stanford Drone#ADE (8/12) @K=5#12.23$Trajectory Prediction#Stanford Drone#FDE(8/12) @K=5#21.16$Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1656$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#2.174$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#4.9593$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.7097$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.9097$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.4457$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9889$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#2.1401
1912.01118v1.pdf	Trajectory Prediction#ApolloScape#ADE#0.005$Trajectory Prediction#Lyft Level 5#ADE#0.008
2007.14558v2.pdf	Trajectory Prediction#PIE#MSE(0.5)#41$Trajectory Prediction#PIE#MSE(1.0)#161$Trajectory Prediction#PIE#MSE(1.5)#511$Trajectory Prediction#PIE#C_MSE(1.5)#481$Trajectory Prediction#PIE#CF_MSE(1.5)#1949$Trajectory Prediction#JAAD#MSE(0.5)#93$Trajectory Prediction#JAAD#MSE(1.0)#378$Trajectory Prediction#JAAD#MSE(1.5)#1206$Trajectory Prediction#JAAD#C_MSE(1.5)#1105$Trajectory Prediction#JAAD#CF_MSE(1.5)#4565
1711.09026v2.pdf	Trajectory Prediction#PIE#MSE(0.5)#159$Trajectory Prediction#PIE#MSE(1.0)#539$Trajectory Prediction#PIE#MSE(1.5)#1535$Trajectory Prediction#PIE#C_MSE(1.5)#1447$Trajectory Prediction#PIE#CF_MSE(1.5)#5615$Trajectory Prediction#JAAD#MSE(0.5)#159$Trajectory Prediction#JAAD#MSE(1.0)#539$Trajectory Prediction#JAAD#MSE(1.5)#1535$Trajectory Prediction#JAAD#C_MSE(1.5)#1447$Trajectory Prediction#JAAD#CF_MSE(1.5)#5615
2203.03057v2.pdf	Trajectory Prediction#ETH#Avg AMD/AMV 8/12#0.90$Trajectory Prediction#Stanford Drone#ADE (in world coordinates)#0.47$Trajectory Prediction#Stanford Drone#FDE (in world coordinates)#0.89$Trajectory Prediction#Stanford Drone#AMD#2.83$Trajectory Prediction#Stanford Drone#AMV#0.077$Trajectory Prediction#Stanford Drone#Avg AMD/AMV 8/12#1.45$Trajectory Prediction#UCY#Avg AMD/AMV 8/12#0.90$Trajectory Prediction#ETH/UCY#ADE-8/12#0.33$Trajectory Prediction#ETH/UCY#FDE-8/12#0.33$Trajectory Prediction#ETH/UCY#Avg AMD/AMV 8/12#0.90
2001.03093v5.pdf	Trajectory Prediction#ETH#Avg AMD/AMV 8/12#1.01$Trajectory Prediction#nuScenes#MinADE_5#1.88$Trajectory Prediction#nuScenes#MinADE_10#1.51$Trajectory Prediction#nuScenes#MissRateTopK_2_5#0.7$Trajectory Prediction#nuScenes#MissRateTopK_2_10#0.57$Trajectory Prediction#nuScenes#MinFDE_1#9.52$Trajectory Prediction#nuScenes#OffRoadRate#0.25$Trajectory Prediction#ETH/UCY#ADE-8/12#0.21$Trajectory Prediction#ETH/UCY#Avg AMD/AMV 8/12#1.01
2002.11927v3.pdf	Trajectory Prediction#ETH#Avg AMD/AMV 8/12#1.26$Trajectory Prediction#ETH/UCY#ADE-8/12#0.44$Trajectory Prediction#ETH/UCY#FDE-8/12#0.75$Trajectory Prediction#ETH/UCY#Avg AMD/AMV 8/12#1.26
1803.10892v1.pdf	Trajectory Prediction#ETH#Avg AMD/AMV 8/12#1.42$Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#27.23$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#41.44$Trajectory Prediction#Stanford Drone#ADE (8/12) @K=5#27.25$Trajectory Prediction#Stanford Drone#FDE(8/12) @K=5#41.44$Trajectory Prediction#ETH/UCY#ADE-8/12#0.58$Trajectory Prediction#ETH/UCY#Avg AMD/AMV 8/12#1.42
1904.09507v2.pdf	Trajectory Prediction#Hotel BIWI Walking Pedestrians dataset#ADE-8/12#0.39$Trajectory Prediction#ETH BIWI Walking Pedestrians dataset#ADE-8/12#0.39$Trajectory Prediction#Stanford Drone#ADE (in world coordinates)#0.62$Trajectory Prediction#Stanford Drone#FDE (in world coordinates)#1.16
1812.04767v4.pdf	Trajectory Prediction#TRAF#RMSE#0.78$Trajectory Prediction#NGSIM#RMSE#5.63
2104.11212v1.pdf	Trajectory Prediction#INTERACTION Dataset - Validation#minADE6#0.17$Trajectory Prediction#INTERACTION Dataset - Validation#minFDE6#0.49
2109.01827v4.pdf	Trajectory Prediction#INTERACTION Dataset - Validation#minFDE6#0.45$Trajectory Prediction#INTERACTION Dataset - Validation#minFDE1#0.61$Trajectory Prediction#nuScenes#MinADE_5#1.42$Trajectory Prediction#nuScenes#MinADE_10#1.15$Trajectory Prediction#nuScenes#MissRateTopK_2_5#0.57$Trajectory Prediction#nuScenes#MissRateTopK_2_10#0.47$Trajectory Prediction#nuScenes#MinFDE_1#6.99$Trajectory Prediction#nuScenes#OffRoadRate#0.04$Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1048$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6887$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.6468$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5724$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.9425$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.4503$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9811$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9834
2106.15004v2.pdf	Trajectory Prediction#nuScenes#MinADE_5#1.27$Trajectory Prediction#nuScenes#MinADE_10#0.94$Trajectory Prediction#nuScenes#MissRateTopK_2_5#0.52$Trajectory Prediction#nuScenes#MissRateTopK_2_10#0.34$Trajectory Prediction#nuScenes#MinFDE_1#7.17$Trajectory Prediction#nuScenes#OffRoadRate#0.03
2110.06607v3.pdf	Trajectory Prediction#nuScenes#MinADE_5#1.33$Trajectory Prediction#nuScenes#MinADE_10#1.04$Trajectory Prediction#nuScenes#MissRateTopK_2_5#0.55$Trajectory Prediction#nuScenes#MissRateTopK_2_10#0.42$Trajectory Prediction#nuScenes#MinFDE_1#6.71$Trajectory Prediction#nuScenes#OffRoadRate#0.03$Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1038$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6686$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.593$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5613$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.9423$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.4388$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9781$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9736
2001.00735v2.pdf	Trajectory Prediction#nuScenes#MinADE_5#1.45$Trajectory Prediction#nuScenes#MinADE_10#1.16$Trajectory Prediction#nuScenes#MissRateTopK_2_5#0.64$Trajectory Prediction#nuScenes#MissRateTopK_2_10#0.46$Trajectory Prediction#nuScenes#MinFDE_1#10.5$Trajectory Prediction#nuScenes#OffRoadRate#0.03$Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#12.58$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#22.07
2103.14023v3.pdf	Trajectory Prediction#nuScenes#MinADE_5#1.86$Trajectory Prediction#nuScenes#MinADE_10#1.45$Trajectory Prediction#ETH/UCY#ADE-8/12#0.23$Trajectory Prediction#ETH/UCY#FDE-8/12#0.39
2109.15158v2.pdf	Trajectory Prediction#TrajAir: A General Aviation Trajectory Dataset#ADE (in world coordinates)#0.73$Trajectory Prediction#TrajAir: A General Aviation Trajectory Dataset#FDE (in world coordinates)#1.42
1811.02146v5.pdf	Trajectory Prediction#Apolloscape Trajectory#ADE#8.5881
2206.15275v1.pdf	Trajectory Prediction#SDD#mADEK @4.8s#14.36$Trajectory Prediction#SDD#mF DEK @4.8s#25.99
1912.06445v3.pdf	Trajectory Prediction#ForkingPaths#ADE#168.9$Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#14.78$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#27.09$Trajectory Prediction#ActEV#ADE-8/12#18.51$Trajectory Prediction#ActEV#FDE-8/12#35.84$Trajectory Forecasting#ForkingPaths#ADE#168.9
2207.10435v1.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#6.52$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#10.61$Trajectory Prediction#ETH/UCY#ADE-8/12#0.17$Trajectory Prediction#ETH/UCY#FDE-8/12#0.24
2110.07288v2.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#7.12$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#11.39$Trajectory Prediction#ETH/UCY#ADE-8/12#0.18$Trajectory Prediction#ETH/UCY#FDE-8/12#0.28
2012.01526v1.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#7.85$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#11.85$Trajectory Prediction#ETH/UCY#ADE-8/12#0.18$Trajectory Prediction#ETH/UCY#FDE-8/12#0.27
2203.11474v1.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#8.56$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#12.66$Trajectory Prediction#ETH/UCY#ADE-8/12#0.21$Trajectory Prediction#ETH/UCY#FDE-8/12#0.35
2006.03340v2.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#8.96$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#17.76$Trajectory Prediction#Stanford Drone#ADE (8/12) @K=5#13.51$Trajectory Prediction#Stanford Drone#FDE(8/12) @K=5#27.34$Trajectory Prediction#ETH/UCY#ADE-8/12#0.32$Trajectory Prediction#ETH/UCY#FDE-8/12#0.65
2004.02025v3.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#9.96$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#15.88$Trajectory Prediction#ETH/UCY#ADE-8/12#0.29$Trajectory Prediction#ETH/UCY#FDE-8/12#0.48
2004.02022v2.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#10.27$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#19.71$Trajectory Prediction#ActEV#ADE-8/12#17.96$Trajectory Prediction#ActEV#FDE-8/12#34.68
1908.09008v3.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#12.60$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#22.30
2003.13924v4.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#13.9$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#22.9
1905.01631v2.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#15.6$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#28.2$Trajectory Prediction#ETH/UCY#ADE-8/12#0.49
1806.01482v2.pdf	Trajectory Prediction#Stanford Drone#ADE-8/12 @K = 20#16.27$Trajectory Prediction#Stanford Drone#FDE-8/12 @K= 20#29.38$Trajectory Prediction#Stanford Drone#ADE (8/12) @K=5#16.27$Trajectory Prediction#Stanford Drone#FDE(8/12) @K=5#29.38$Trajectory Prediction#ETH/UCY#ADE-8/12#0.54
1902.03748v3.pdf	Trajectory Prediction#ActEV#ADE-8/12#17.99$Trajectory Prediction#ActEV#FDE-8/12#37.24$Trajectory Prediction#ETH/UCY#ADE-8/12#0.46$Trajectory Forecasting#ActEV#ADE-8/12#17.99$Activity Prediction#ActEV#mAP#0.192
2003.08111v3.pdf	Trajectory Prediction#ETH/UCY#ADE-8/12#0.31
2012.01884v2.pdf	Trajectory Prediction#ETH/UCY#ADE-8/12#0.37$Trajectory Prediction#ETH/UCY#FDE-8/12#0.71
1907.03395v2.pdf	Trajectory Prediction#ETH/UCY#ADE-8/12#0.48
2003.10432v3.pdf	Depth Estimation#ScanNet#RMSE#0.165$Depth Estimation#ScanNet#RMSE#0.174$Depth Estimation#ScanNet#absolute relative error#0.089$3D Reconstruction#ScanNet#L1#21.1$3D Reconstruction#ScanNet#3DIoU#89.4$3D Reconstruction#ScanNet#Chamfer Distance#37.2
2205.13543v2.pdf	Depth Estimation#NYU-Depth V2#RMS#0.287$Depth Estimation#NYU-Depth V2#RMS#0.304$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.287$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.083$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.949$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.994$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.999$Monocular Depth Estimation#NYU-Depth V2#log 10#0.035$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.050$Monocular Depth Estimation#KITTI Eigen split#RMSE#1.966$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.139$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.075$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.977$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.998$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#1.000$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.052$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.050$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.148$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.078$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.976$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999$Visual Object Tracking#LaSOT#AUC#70.7$Visual Object Tracking#LaSOT#AUC#70$Visual Object Tracking#GOT-10k#Average Overlap#72.9$Visual Object Tracking#GOT-10k#Average Overlap#70.8$Pose Estimation#CrowdPose#AP#75.5$Pose Estimation#CrowdPose#AP#74.9$Pose Estimation#COCO test-dev#AP#77.2$Pose Estimation#COCO test-dev#AP#76.7
1909.05483v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.30
2204.02091v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.356$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.356$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.104$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.898$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.981$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.996$Monocular Depth Estimation#NYU-Depth V2#log 10#0.043
2011.14141v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.364$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.364$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.103$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.903$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.984$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.044$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.058$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.360$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.088$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.964$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.995$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2103.12091v2.pdf	Depth Estimation#NYU-Depth V2#RMS#0.365
1907.10326v6.pdf	Depth Estimation#NYU-Depth V2#RMS#0.407$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.392$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.110$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.885$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.978$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.995$Monocular Depth Estimation#NYU-Depth V2#log 10#0.047$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.064
1904.08601v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.4325$Depth Estimation#NYU-Depth V2#RMS#0.433
1806.02446v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.509$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.509$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.072$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.727$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.120$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.932$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.984$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.994
1704.02157v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.586$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.586
1805.04409v1.pdf	Depth Estimation#NYU-Depth V2#RMS#0.792
2005.09623v1.pdf	Depth Estimation#NYU-Depth V2#RMSE#0.013
1908.09999v1.pdf	Depth Estimation#NYU-Depth V2#mAP#8.61$Hand Pose Estimation#NYU Hands#Average 3D Error#8.61$Hand Pose Estimation#NYU Hands#FPS#105.06$Hand Pose Estimation#K2HPD#PDJ@5mm#76.3$Hand Pose Estimation#ICVL Hands#Average 3D Error#6.461$Hand Pose Estimation#ICVL Hands#FPS#105.06$Hand Pose Estimation#HANDS 2017#Average 3D Error#8.57$Pose Estimation#ITOP front-view#Mean mAP#88.0$3D Pose Estimation#K2HPD#FPS#93.78
2102.03550v2.pdf	Depth Estimation#Matterport3D#Abs Rel#0.1063
2003.08933v2.pdf	Depth Estimation#ScanNetV2#Average mean absolute error#0.144$Depth Estimation#ScanNetV2#absolute relative error#0.087
2110.03575v2.pdf	Depth Estimation#eBDtheque#Abs Rel#0.376$Depth Estimation#eBDtheque#Sq Rel#0.448$Depth Estimation#eBDtheque#RMSE#1.364$Depth Estimation#eBDtheque#RMSE log#0.553$Depth Estimation#DCM#Abs Rel#0.251$Depth Estimation#DCM#Sq Rel#0.318$Depth Estimation#DCM#RMSE#0.971$Depth Estimation#DCM#RMSE log#0.305
1907.01341v3.pdf	Depth Estimation#eBDtheque#Abs Rel#0.419$Depth Estimation#eBDtheque#Sq Rel#0.503$Depth Estimation#eBDtheque#RMSE#1.416$Depth Estimation#eBDtheque#RMSE log#0.659$Depth Estimation#DCM#Abs Rel#0.309$Depth Estimation#DCM#Sq Rel#0.381$Depth Estimation#DCM#RMSE#1.033$Depth Estimation#DCM#RMSE log#0.375
1808.01454v1.pdf	Depth Estimation#eBDtheque#Abs Rel#0.491$Depth Estimation#eBDtheque#Sq Rel#0.555$Depth Estimation#eBDtheque#RMSE#1.459$Depth Estimation#eBDtheque#RMSE log#0.777$Depth Estimation#DCM#Abs Rel#0.351$Depth Estimation#DCM#Sq Rel#0.416$Depth Estimation#DCM#RMSE#1.117$Depth Estimation#DCM#RMSE log#0.415
2007.06153v1.pdf	Depth Estimation#DIODE#Delta < 1.25^3#0.7945$Depth Estimation#DIODE#Delta < 1.25#0.3563$Depth Estimation#DIODE#Delta < 1.25^2#0.5948$Indoor Monocular Depth Estimation#DIODE#Delta < 1.25^3#0.7945
2105.09847v3.pdf	Monocular Depth Estimation#Mid-Air Dataset#Abs Rel#0.1425$Monocular Depth Estimation#Mid-Air Dataset#SQ Rel#3.6798$Monocular Depth Estimation#Mid-Air Dataset#RMSE#8.8641$Monocular Depth Estimation#Mid-Air Dataset#RMSE log#0.24571
1609.03677v3.pdf	Monocular Depth Estimation#Mid-Air Dataset#Abs Rel#0.3136$Monocular Depth Estimation#Mid-Air Dataset#SQ Rel#8.7127$Monocular Depth Estimation#Mid-Air Dataset#RMSE#13.595$Monocular Depth Estimation#Mid-Air Dataset#RMSE log#0.4380$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.133
1908.03706v1.pdf	Monocular Depth Estimation#Mid-Air Dataset#Abs Rel#0.4040$Monocular Depth Estimation#Mid-Air Dataset#SQ Rel#6.3902$Monocular Depth Estimation#Mid-Air Dataset#RMSE#13.685$Monocular Depth Estimation#Mid-Air Dataset#RMSE log#0.4383
1806.01260v4.pdf	Monocular Depth Estimation#Mid-Air Dataset#Abs Rel#0.717$Monocular Depth Estimation#Mid-Air Dataset#SQ Rel#37.164$Monocular Depth Estimation#Mid-Air Dataset#RMSE#74.552$Monocular Depth Estimation#Mid-Air Dataset#RMSE log#0.882$Monocular Depth Estimation#Make3D#Abs Rel#0.322$Monocular Depth Estimation#Make3D#Sq Rel#3.589$Monocular Depth Estimation#Make3D#RMSE#7.417$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.106
2109.12484v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.091$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.207$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.646$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.176$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.901$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.966$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.983$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.099$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.490$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.183$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.183$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.888$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.963$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.982
2110.09482v3.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.094$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.250$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.678$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.172$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.911$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.968$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.984
2112.13047v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.096$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.264$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.694$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.173
2203.15174v2.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.096
2007.10603v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.099$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.427$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.697$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.184$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.889$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.963$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.982$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.104
2103.12209v3.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.101$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.413$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.703$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.882$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.962$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.053$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.101$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.161$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.082$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.969$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.996$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2012.07356v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.101$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.104$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.109
2110.12516v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.102$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.439$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.698$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.180$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.895$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.965$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.983
2110.14347v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.102$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.105$Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.106
2112.06782v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.104$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.494$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.720$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.181$Monocular Depth Estimation#Make3D#Abs Rel#0.424$Monocular Depth Estimation#Make3D#Sq Rel#3.075$Monocular Depth Estimation#Make3D#RMSE#6.757$Monocular Depth Estimation#KITTI#absolute relative error#0.104$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.104$Monocular Depth Estimation#KITTI Eigen split#RMSE#4.494$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.181$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.888$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.965$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.984
1905.02693v4.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.107$Monocular Depth Estimation#KITTI Object Tracking Evaluation 2012#Abs Rel#0.071$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.12
2006.04026v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.109$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#3.77$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.673$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.19$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.864$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.954$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.981$Monocular Depth Estimation#Make3D#Abs Rel#0.377$Monocular Depth Estimation#Make3D#Sq Rel#4.9$Monocular Depth Estimation#Make3D#RMSE#8.388
2103.02451v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.109
1810.01849v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.112
1908.11112v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.113
2206.03799v2.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.115$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE#4.698$Monocular Depth Estimation#KITTI Eigen split unsupervised#Sq Rel#0.785$Monocular Depth Estimation#KITTI Eigen split unsupervised#RMSE log#0.192$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25#0.871$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^2#0.959$Monocular Depth Estimation#KITTI Eigen split unsupervised#Delta < 1.25^3#0.982
1906.05717v1.pdf	Monocular Depth Estimation#KITTI Eigen split unsupervised#absolute relative error#0.1412
2006.02535v1.pdf	Monocular Depth Estimation#Make3D#RMSE#0.232$Monocular Depth Estimation#Make3D#RMSE#0.474$Semantic Segmentation#Cityscapes test#Time (ms)#0.037$Semantic Segmentation#Cityscapes test#Time (ms)#0.195$Semantic Segmentation#Cityscapes test#Time (ms)#0.285
2105.14021v1.pdf	Monocular Depth Estimation#Middlebury 2014#ORD#0.3467$Monocular Depth Estimation#Middlebury 2014#D3R#0.1578$Monocular Depth Estimation#Middlebury 2014#RMSE#0.1557$Monocular Depth Estimation#Middlebury 2014#δ1.25#0.7406$Monocular Depth Estimation#Middlebury 2014#ORD#0.3879$Monocular Depth Estimation#Middlebury 2014#D3R#0.2324$Monocular Depth Estimation#Middlebury 2014#RMSE#0.1973$Monocular Depth Estimation#Middlebury 2014#δ1.25#0.7891$Monocular Depth Estimation#IBims-1#ORD#0.3938$Monocular Depth Estimation#IBims-1#D3R#0.3222$Monocular Depth Estimation#IBims-1#RMSE#0.1598$Monocular Depth Estimation#IBims-1#δ1.25#0.6390$Monocular Depth Estimation#IBims-1#ORD#0.5538$Monocular Depth Estimation#IBims-1#D3R#0.4671$Monocular Depth Estimation#IBims-1#RMSE#0.1965$Monocular Depth Estimation#IBims-1#δ1.25#0.7460
2204.07076v1.pdf	Monocular Depth Estimation#SUN-RGBD#RMSE#0.335$Monocular Depth Estimation#SUN-RGBD#absolute relative error#0.114$Monocular Depth Estimation#SUN-RGBD#log 10#0.034$Monocular Depth Estimation#SUN-RGBD#Delta < 1.25#0.937$Monocular Depth Estimation#SUN-RGBD#Delta < 1.25^2#0.981$Monocular Depth Estimation#SUN-RGBD#Delta < 1.25^3#0.992
2210.09071v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.322$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.090$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.929$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.991$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.998$Monocular Depth Estimation#NYU-Depth V2#log 10#0.039$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.051$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.081$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.149$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.077$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.976$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.997$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2204.00987v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.330$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.094$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.925$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.989$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.040$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.052$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.098$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.151$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.079$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.974$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.997$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2203.01502v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.334$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.095$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.922$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.992$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.998$Monocular Depth Estimation#NYU-Depth V2#log 10#0.041$Monocular Depth Estimation#Matterport3D#absolute relative error#0.0793$Monocular Depth Estimation#Matterport3D#absolute error#0.197$Monocular Depth Estimation#Matterport3D#RMSE#0.4279$Monocular Depth Estimation#Matterport3D#Delta < 1.25#0.9376$Monocular Depth Estimation#Matterport3D#Delta < 1.25^2#0.9812$Monocular Depth Estimation#Matterport3D#Delta < 1.25^3#0.9933$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.052$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.129$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.155$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.079$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.974$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.997$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2203.14211v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.339$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.096$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.921$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.989$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.998$Monocular Depth Estimation#NYU-Depth V2#log 10#0.041$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.052$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.143$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.158$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.079$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.975$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.997$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2201.07436v3.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.344$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.098$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.915$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.988$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.042$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.057$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.297$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.086$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.967$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.996$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2207.04535v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.345$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.100$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.913$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.988$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.042$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.058$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.285$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.187$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.087$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.967$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.996$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999
2203.15132v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.351$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.098$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.91$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.986$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.042
2210.03676v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.352$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.101$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.910$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.985$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.043
2208.10762v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.355$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.098$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.913$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.987$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.998$Monocular Depth Estimation#NYU-Depth V2#log 10#0.042$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.362$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.100$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.907$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.986$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.043
2103.13413v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.357$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.110$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.904$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.988$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.994$Monocular Depth Estimation#NYU-Depth V2#log 10#0.045$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.062$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.573$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.092$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.959$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.995$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.999$Semantic Segmentation#ADE20K#Validation mIoU#49.02$Semantic Segmentation#ADE20K val#mIoU#49.02$Semantic Segmentation#ADE20K val#Pixel Accuracy#83.11$Semantic Segmentation#PASCAL Context#mIoU#60.46
2107.07684v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.375$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.104$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.899$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.985$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.997$Monocular Depth Estimation#NYU-Depth V2#log 10#0.044
1907.12209v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.416$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.111$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.875$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.976$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^3#0.989$Monocular Depth Estimation#NYU-Depth V2#log 10#0.048$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.072
2010.06626v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.429$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.075$Depth Completion#KITTI Depth Completion Eigen Split#REL#0.019$Depth Completion#KITTI Depth Completion Eigen Split#RMSE#1.588$Depth Completion#NYU-Depth V2#RMSE#0.102$Depth Completion#NYU-Depth V2#REL#0.012$Surface Normals Estimation#NYU-Depth V2 Surface Normals#RMSE#12.2
1812.11941v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.465$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.093
1901.10137v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.496
1905.08598v3.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.496
1906.03525v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.497$Semantic Segmentation#NYU Depth v2#Mean IoU#50.4%
1907.06023v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.514
2203.07997v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.5183$Saliency Detection#PASCAL Context#max_F1#84.81$Boundary Detection#PASCAL Context#odsF#73$Boundary Detection#NYU-Depth V2#odsF#78.1$Semantic Segmentation#NYU Depth v2#Mean IoU#53.56%$Surface Normals Estimation#PASCAL Context#Mean Angle Error#14.15$Human Parsing#PASCAL Context#mIoU#67.61
1810.10804v3.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.523$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.525$Monocular Depth Estimation#NYU-Depth V2#RMSE#0.526$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#78.0%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#77.3%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#77.1%
1803.08673v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.530
2006.02708v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.532$Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.138$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.820$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25^2#0.956$Monocular Depth Estimation#NYU-Depth V2#log 10#0.059
1906.05739v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.536
1908.09895v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.565$Scene Segmentation#SUN-RGBD#Mean IoU#33.48$Grayscale Image Denoising#Set12 sigma15#PSNR#32.82$Grayscale Image Denoising#Set12 sigma50#PSNR#27.29$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.34$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.06$Grayscale Image Denoising#Set12 sigma30#PSNR#30.43$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.23
1809.04766v2.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.565$Semantic Segmentation#NYU Depth v2#Mean IoU#42.0%$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#42.0$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#13
2001.05036v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.575$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.110
1909.04594v1.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.604$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.097
1607.00730v4.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.635
1411.4734v4.pdf	Monocular Depth Estimation#NYU-Depth V2#RMSE#0.641
2012.09365v1.pdf	Monocular Depth Estimation#NYU-Depth V2#absolute relative error#0.09$Monocular Depth Estimation#NYU-Depth V2#Delta < 1.25#0.916$Monocular Depth Estimation#IBims-1#ORD#0.196$Monocular Depth Estimation#IBims-1#δ1.25#0.885$Indoor Monocular Depth Estimation#DIODE#Delta < 1.25^3#0.900
2104.00556v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.055$Monocular Depth Estimation#KITTI Eigen split#RMSE#2.273$Monocular Depth Estimation#KITTI Eigen split#Sq Rel#0.224
1908.03127v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.091
1803.02612v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.094
1904.04144v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.096
1905.07542v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.096
1803.08018v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.096
1909.09051v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.096
2003.01360v3.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.112
2004.05560v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.113$Monocular Depth Estimation#KITTI Eigen split#RMSE#4.812$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.191$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.877$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.960$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.981
1905.00401v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.113
2105.11610v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.114$Monocular Depth Estimation#KITTI Eigen split#RMSE#4.706$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.191$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.873$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.960$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.982$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.119$Monocular Depth Estimation#KITTI Eigen split#RMSE#4.950$Monocular Depth Estimation#KITTI Eigen split#RMSE log#0.197$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25#0.863$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^2#0.957$Monocular Depth Estimation#KITTI Eigen split#Delta < 1.25^3#0.981
1808.01606v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.126
1908.10553v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.128$Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.137
1903.00112v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.133
1812.05642v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.133
1811.06152v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.135
1805.09806v3.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.140
1904.01870v1.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.149
1903.10764v2.pdf	Monocular Depth Estimation#KITTI Eigen split#absolute relative error#0.193
2108.09770v1.pdf	Stereo Depth Estimation#sceneflow#Average End-Point Error#0.80$Stereo Depth Estimation#sceneflow#EPE#0.80$Stereo Depth Estimation#sceneflow#Average End-Point Error#1.14$Stereo Depth Estimation#sceneflow#EPE#1.14$Stereo Depth Estimation#KITTI2015#three pixel error#1.69$Stereo Depth Estimation#KITTI2015#three pixel error#2.67
1807.08865v1.pdf	Stereo Depth Estimation#sceneflow#Average End-Point Error#1.1
2111.12502v2.pdf	Stereo Depth Estimation#KITTI 2015#D1-all All#2.35$Stereo Depth Estimation#KITTI 2015#D1-all Noc#2.09$Stereo Depth Estimation#KITTI2015#D1-all All#2.35$Stereo Depth Estimation#KITTI2015#D1-all Noc#2.09
1810.11408v2.pdf	Stereo Depth Estimation#KITTI2012#three pixel error#6.1$Stereo Depth Estimation#KITTI2015#three pixel error#6.2
2007.12140v3.pdf	Stereo Depth Estimation#KITTI2015#three pixel error#2.43
2007.03085v2.pdf	Stereo Depth Estimation#KITTI2015#three pixel error#1.92$3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#54.2
2007.11457v1.pdf	Face Anti-Spoofing#MLFP#HTER#3.4$Face Presentation Attack Detection#WMCA#ACER#0.097
1901.00488v3.pdf	Face Anti-Spoofing#CASIA-MFSD#EER#2.22$Face Anti-Spoofing#CASIA-MFSD#HTER#1.67$Face Anti-Spoofing#Replay-Attack#EER#0.25$Face Anti-Spoofing#Replay-Attack#HTER#0.63
1408.5601v2.pdf	Face Anti-Spoofing#CASIA-MFSD#EER#4.92$Face Anti-Spoofing#Replay-Attack#EER#2.14
2206.06510v1.pdf	Face Anti-Spoofing#MSU-MFSD#Equal Error Rate#0$Face Anti-Spoofing#MSU-MFSD#HTER#0$Face Anti-Spoofing#Replay-Attack#EER#0$Face Anti-Spoofing#Replay-Attack#HTER#0$Face Anti-Spoofing#OULU-NPU#ACER#3.2$Face Anti-Spoofing#OULU-NPU#HTER#2.6
1901.05602v1.pdf	Face Anti-Spoofing#MSU-MFSD#Equal Error Rate#7.5%
1511.06316v1.pdf	Face Anti-Spoofing#MSU-MFSD#Equal Error Rate#10.8%$Face Anti-Spoofing#Replay-Attack#EER#0.40$Face Anti-Spoofing#Replay-Attack#HTER#2.90
2003.04092v1.pdf	Face Anti-Spoofing#OULU-NPU#ACER#6.9
2112.08274v3.pdf	3D Depth Estimation#Relative Human#PCDR#68.27$3D Depth Estimation#Relative Human#PCDR-Baby#60.77$3D Depth Estimation#Relative Human#PCDR-Kid#67.09$3D Depth Estimation#Relative Human#PCDR-Teen#66.07$3D Depth Estimation#Relative Human#PCDR-Adult#69.71$3D Depth Estimation#Relative Human#mPCDK#0.884
2008.12272v4.pdf	3D Depth Estimation#Relative Human#PCDR#54.84$3D Depth Estimation#Relative Human#PCDR-Baby#30.08$3D Depth Estimation#Relative Human#PCDR-Kid#48.41$3D Depth Estimation#Relative Human#PCDR-Teen#51.12$3D Depth Estimation#Relative Human#PCDR-Adult#55.34$3D Depth Estimation#Relative Human#mPCDK#0.866$3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#127.6$3D Human Pose Estimation#3DPW#PA-MPJPE#47.3$3D Human Pose Estimation#3DPW#MPJPE#76.7$3D Human Pose Estimation#3DPW#MPVPE#93.4$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJPE#81.76$3D Multi-Person Mesh Recovery#Relative Human#PCDR#68.27$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#58.6$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#55.6
2006.08586v1.pdf	3D Depth Estimation#Relative Human#PCDR#54.83$3D Depth Estimation#Relative Human#PCDR-Baby#34.74$3D Depth Estimation#Relative Human#PCDR-Kid#48.37$3D Depth Estimation#Relative Human#PCDR-Teen#59.11$3D Depth Estimation#Relative Human#PCDR-Adult#55.47$3D Depth Estimation#Relative Human#mPCDK#0.781$3D Human Reconstruction#AGORA#FB-NMVE#233.9$3D Human Reconstruction#AGORA#B-NMVE#173.4$3D Human Reconstruction#AGORA#FB-NMJE#230.9$3D Human Reconstruction#AGORA#B-NMJE#171.1$3D Human Reconstruction#AGORA#FB-MVE#191.8$3D Human Reconstruction#AGORA#B-MVE#142.2$3D Human Reconstruction#AGORA#F-MVE#50.2$3D Human Reconstruction#AGORA#LH/RH-MVE#49.5/49.0$3D Human Reconstruction#AGORA#FB-MPJPE#189.3$3D Human Reconstruction#AGORA#B-MPJPE#140.3$3D Human Reconstruction#AGORA#F-MPJPE#54.5$3D Human Reconstruction#AGORA#LH/RH-MPJPE#46.4/46.0
2202.08471v2.pdf	Transparent Object Depth Estimation#TransCG#RMSE#0.018$Transparent Object Depth Estimation#TransCG#REL#0.027$Transparent Object Depth Estimation#TransCG#MAE#0.012$Transparent Object Depth Estimation#TransCG#delta < 1.05#83.76$Transparent Object Depth Estimation#TransCG#delta < 1.10#95.67$Transparent Object Depth Estimation#TransCG#Delta < 1.25#99.71
2103.12964v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#636.2
1911.05377v2.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#725.43
1904.02917v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#749.3
1905.02744v3.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#749.3
2007.10042v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#771.8$Depth Completion#KITTI Depth Completion#iRMSE#1.99$Depth Completion#KITTI Depth Completion#iMAE#0.84$Depth Completion#KITTI Depth Completion#RMSE#741.68$Depth Completion#KITTI Depth Completion#MAE#199.59$Depth Completion#KITTI Depth Completion#Runtime [ms]#220$Depth Completion#VOID#MAE#26.736$Depth Completion#VOID#RMSE#79.121$Depth Completion#VOID#iMAE#12.703$Depth Completion#VOID#iRMSE#33.876$Depth Completion#NYU-Depth V2#RMSE#0.092$Depth Completion#NYU-Depth V2#REL#0.012
1908.01238v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#777.78
1803.08669v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#884
2003.06945v3.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#1009.6
1703.04309v1.pdf	Stereo-LiDAR Fusion#KITTI Depth Completion Validation#RMSE#1031.4
2106.05239v3.pdf	Diabetes Prediction#Diabetes#Accuracy#78.78$Breast Cancer Detection#Breast cancer Wisconsin_class 4#Accuracy#96.49$Breast Cancer Detection#Breast cancer Wisconsin_class 4#Average Precision#0.95$Fraud Detection#Kaggle-Credit Card Fraud Dataset#Accuracy#71.33$General Classification#iris#Accuracy#100
2210.03304v2.pdf	Medical Code Prediction#MIMIC-III#Macro-F1#11.8$Medical Code Prediction#MIMIC-III#Micro-F1#59.9$Medical Code Prediction#MIMIC-III#Precision@8#77.1$Medical Code Prediction#MIMIC-III#Precision@15#61.5
2107.10650v1.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#94.8$Medical Code Prediction#MIMIC-III#Micro-AUC#99.2$Medical Code Prediction#MIMIC-III#Macro-F1#12.7$Medical Code Prediction#MIMIC-III#Micro-F1#58.6$Medical Code Prediction#MIMIC-III#Precision@5#82.9$Medical Code Prediction#MIMIC-III#Precision@8#75.4$Medical Code Prediction#MIMIC-III#Precision@15#60.1
2203.01515v2.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#95.0$Medical Code Prediction#MIMIC-III#Micro-AUC#99.2$Medical Code Prediction#MIMIC-III#Macro-F1#10.3$Medical Code Prediction#MIMIC-III#Micro-F1#58.4$Medical Code Prediction#MIMIC-III#Precision@8#75.2$Medical Code Prediction#MIMIC-III#Precision@15#59.9
2007.06351v1.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#92.1$Medical Code Prediction#MIMIC-III#Micro-AUC#98.8$Medical Code Prediction#MIMIC-III#Macro-F1#10.7$Medical Code Prediction#MIMIC-III#Micro-F1#57.5$Medical Code Prediction#MIMIC-III#Precision@5#80.6$Medical Code Prediction#MIMIC-III#Precision@8#73.5$Medical Code Prediction#MIMIC-III#Precision@15#59.0$Medical Code Prediction#MIMIC-III#Macro-AUC#91.9$Medical Code Prediction#MIMIC-III#Macro-F1#9.9$Medical Code Prediction#MIMIC-III#Precision@5#81.3$Medical Code Prediction#MIMIC-III#Precision@8#73.8$Medical Code Prediction#MIMIC-III#Precision@15#59.1
1912.00862v1.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#91.0$Medical Code Prediction#MIMIC-III#Micro-AUC#98.6$Medical Code Prediction#MIMIC-III#Macro-F1#8.5$Medical Code Prediction#MIMIC-III#Micro-F1#55.2$Medical Code Prediction#MIMIC-III#Precision@8#73.4$Medical Code Prediction#MIMIC-III#Precision@15#58.4
1802.05695v2.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#89.5$Medical Code Prediction#MIMIC-III#Micro-AUC#98.6$Medical Code Prediction#MIMIC-III#Macro-F1#8.8$Medical Code Prediction#MIMIC-III#Micro-F1#53.9$Medical Code Prediction#MIMIC-III#Precision@8#70.9$Medical Code Prediction#MIMIC-III#Precision@15#56.1$Medical Code Prediction#MIMIC-III#Macro-AUC#89.7$Medical Code Prediction#MIMIC-III#Micro-AUC#98.5$Medical Code Prediction#MIMIC-III#Macro-F1#8.6$Medical Code Prediction#MIMIC-III#Micro-F1#52.9$Medical Code Prediction#MIMIC-III#Precision@8#69.0$Medical Code Prediction#MIMIC-III#Precision@15#54.8$Medical Code Prediction#MIMIC-III#Micro-F1#44.1$Medical Code Prediction#MIMIC-III#Macro-AUC#80.6$Medical Code Prediction#MIMIC-III#Micro-AUC#96.9$Medical Code Prediction#MIMIC-III#Macro-F1#4.2$Medical Code Prediction#MIMIC-III#Micro-F1#41.9$Medical Code Prediction#MIMIC-III#Precision@8#58.1$Medical Code Prediction#MIMIC-III#Precision@15#44.3$Medical Code Prediction#MIMIC-III#Macro-AUC#82.2$Medical Code Prediction#MIMIC-III#Micro-AUC#97.1$Medical Code Prediction#MIMIC-III#Macro-F1#3.8$Medical Code Prediction#MIMIC-III#Micro-F1#41.7$Medical Code Prediction#MIMIC-III#Precision@8#58.5$Medical Code Prediction#MIMIC-III#Precision@15#44.5$Medical Code Prediction#MIMIC-III#Macro-AUC#56.1$Medical Code Prediction#MIMIC-III#Micro-AUC#93.7$Medical Code Prediction#MIMIC-III#Macro-F1#1.1$Medical Code Prediction#MIMIC-III#Micro-F1#27.2$Medical Code Prediction#MIMIC-III#Precision@8#54.2$Medical Code Prediction#MIMIC-III#Precision@15#41.1
2010.15728v4.pdf	Medical Code Prediction#MIMIC-III#Macro-AUC#88.5$Medical Code Prediction#MIMIC-III#Micro-AUC#98.1$Medical Code Prediction#MIMIC-III#Macro-F1#3.6$Medical Code Prediction#MIMIC-III#Micro-F1#40.7$Medical Code Prediction#MIMIC-III#Precision@8#61.4$Multi-Label Text Classification#MIMIC-III-50#Micro-F1#64.1$Multi-Label Text Classification#MIMIC-III#AUC#0.919$Multi-Label Text Classification#MIMIC-III#Macro F1#57.1$Multi-Label Text Classification#MIMIC-III#P@5#62.5$Multi-Label Text Classification#MIMIC-III#Macro Precision#65$Multi-Label Text Classification#MIMIC-III#Macro Recall#51$Multi-Label Text Classification#MIMIC-III#Micro Precision#72.9$Multi-Label Text Classification#MIMIC-III#Micro Recall#57.3$Multi-Label Text Classification#MIMIC-III#Micro-F1#40.7
2206.06606v1.pdf	Stock Market Prediction#Astock#1:1 Accuracy#66.89$Text-Based Stock Prediction#Astock#1:1 Accuracy#66.89$Stock Price Prediction#Astock#1-1#66.89
2004.10178v2.pdf	Stock Market Prediction#S&P 500#Average daily returns#0.635%
1912.10806v1.pdf	Stock Price Prediction#2019_test set#10 fold Cross validation#22
2110.02834v1.pdf	Link Prediction#CoDEx Small#MRR#0.473$Link Prediction#CoDEx Small#Hits@1#0.375$Link Prediction#CoDEx Small#Hits@3#0.514$Link Prediction#CoDEx Small#Hits@10#0.663$Link Prediction#CoDEx Large#MRR#0.345$Link Prediction#CoDEx Large#Hits@1#0.277$Link Prediction#CoDEx Large#Hits@3#0.377$Link Prediction#CoDEx Large#Hits@10#0.473$Link Prediction#CoDEx Medium#MRR#0.352$Link Prediction#CoDEx Medium#Hits@1#0.277$Link Prediction#CoDEx Medium#Hits@3#0.386$Link Prediction#CoDEx Medium#Hits@10#0.490$Link Prediction#WN18RR#MRR#0.488$Link Prediction#WN18RR#Hits@10#0.578$Link Prediction#WN18RR#Hits@3#0.505$Link Prediction#WN18RR#Hits@1#0.443$Link Prediction#FB15k-237#MRR#0.389$Link Prediction#FB15k-237#Hits@10#0.568$Link Prediction#FB15k-237#Hits@3#0.424$Link Prediction#FB15k-237#Hits@1#0.298$Link Prediction#FB15k-237#MR#163$Link Prediction#FB15k-237#MRR#0.354$Link Prediction#FB15k-237#Hits@10#0.535$Link Prediction#FB15k-237#Hits@3#0.388$Link Prediction#FB15k-237#Hits@1#0.264$Link Prediction#FB15k-237#MRR#0.366$Link Prediction#FB15k-237#Hits@10#0.55$Link Prediction#Aristo-v4#MRR#0.311$Link Prediction#Aristo-v4#Hits@1#0.24$Link Prediction#Aristo-v4#Hits@3#0.336$Link Prediction#Aristo-v4#Hits@10#0.447$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.6701$Link Property Prediction#ogbl-wikikg2#Test MRR#0.6481$Link Property Prediction#ogbl-wikikg2#Number of params#500334800$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.6594$Link Property Prediction#ogbl-wikikg2#Test MRR#0.6364$Link Property Prediction#ogbl-wikikg2#Number of params#250167400$Link Property Prediction#ogbl-biokg#Test MRR#0.8494$Link Property Prediction#ogbl-biokg#Validation MRR#0.8497$Link Property Prediction#ogbl-biokg#Number of params#187750000
2009.07810v2.pdf	Link Prediction#CoDEx Small#MRR#0.444$Link Prediction#CoDEx Small#Hits@1#0.372$Link Prediction#CoDEx Small#Hits@3#0.5038$Link Prediction#CoDEx Small#Hits@10#0.646$Link Prediction#CoDEx Small#Hits@1#0.219$Link Prediction#CoDEx Small#Hits@3#0.4218$Link Prediction#CoDEx Small#Hits@10#0.634$Link Prediction#CoDEx Small#MRR#0.404$Link Prediction#CoDEx Small#Hits@1#0.343$Link Prediction#CoDEx Small#Hits@3#0.4926$Link Prediction#CoDEx Small#Hits@10#0.635$Link Prediction#CoDEx Small#Hits@1#0.293$Link Prediction#CoDEx Small#Hits@3#0.4494$Link Prediction#CoDEx Small#Hits@10#0.623$Link Prediction#CoDEx Small#MRR#0.354$Link Prediction#CoDEx Small#Hits@1#0.339$Link Prediction#CoDEx Small#Hits@3#0.4975$Link Prediction#CoDEx Small#Hits@10#0.638$Link Prediction#CoDEx Large#MRR#0.309$Link Prediction#CoDEx Large#Hits@1#0.244$Link Prediction#CoDEx Large#Hits@3#0.3395$Link Prediction#CoDEx Large#Hits@10#0.430$Link Prediction#CoDEx Large#MRR#0.304$Link Prediction#CoDEx Large#Hits@1#0.242$Link Prediction#CoDEx Large#Hits@3#0.3313$Link Prediction#CoDEx Large#Hits@10#0.419$Link Prediction#CoDEx Large#MRR#0.303$Link Prediction#CoDEx Large#Hits@1#0.240$Link Prediction#CoDEx Large#Hits@3#0.3298$Link Prediction#CoDEx Large#Hits@10#0.420$Link Prediction#CoDEx Large#MRR#0.294$Link Prediction#CoDEx Large#Hits@1#0.237$Link Prediction#CoDEx Large#Hits@3#0.3179$Link Prediction#CoDEx Large#Hits@10#0.400$Link Prediction#CoDEx Large#MRR#0.187$Link Prediction#CoDEx Large#Hits@1#0.116$Link Prediction#CoDEx Large#Hits@3#0.2188$Link Prediction#CoDEx Large#Hits@10#0.317$Link Prediction#CoDEx Medium#MRR#0.337$Link Prediction#CoDEx Medium#Hits@1#0.244$Link Prediction#CoDEx Medium#Hits@3#0.3477$Link Prediction#CoDEx Medium#Hits@10#0.456$Link Prediction#CoDEx Medium#MRR#0.328$Link Prediction#CoDEx Medium#Hits@1#0.223$Link Prediction#CoDEx Medium#Hits@3#0.3363$Link Prediction#CoDEx Medium#Hits@10#0.454$Link Prediction#CoDEx Medium#MRR#0.318$Link Prediction#CoDEx Medium#Hits@1#0.262$Link Prediction#CoDEx Medium#Hits@3#0.3701$Link Prediction#CoDEx Medium#Hits@10#0.476$Link Prediction#CoDEx Medium#MRR#0.317$Link Prediction#CoDEx Medium#Hits@1#0.239$Link Prediction#CoDEx Medium#Hits@3#0.3551$Link Prediction#CoDEx Medium#Hits@10#0.464$Link Prediction#CoDEx Medium#MRR#0.303$Link Prediction#CoDEx Medium#Hits@1#0.259$Link Prediction#CoDEx Medium#Hits@3#0.3599$Link Prediction#CoDEx Medium#Hits@10#0.458
2005.00856v3.pdf	Link Prediction#YAGO37#Hits@1#0.370$Link Prediction#YAGO37#Hits@10#0.622$Link Prediction#YAGO37#Hits@3#0.498$Link Prediction#YAGO37#MRR#0.454$Link Prediction#FB15k#MRR#0.825$Link Prediction#FB15k#Hits@10#0.886$Link Prediction#FB15k#Hits@3#0.841$Link Prediction#FB15k#Hits@1#0.792
1711.11231v1.pdf	Link Prediction#YAGO37#Hits@1#0.34$Link Prediction#YAGO37#Hits@10#0.603$Link Prediction#YAGO37#Hits@3#0.482$Link Prediction#YAGO37#Hits@5#0.541$Link Prediction#YAGO37#MRR#0.431$Link Prediction#FB15k#Hits@10#0.865$Link Prediction#FB15k#Hits@1#0.703$Link Prediction#FB15k#Hits@3#0.815$Link Prediction#FB15k#Hits@5#0.836$Link Prediction#FB15k#MRR#0.768
2110.04375v2.pdf	Link Prediction#Pubmed#AUC#98.7%$Link Prediction#Pubmed#AP#98.7%$Link Prediction#Cora#AUC#95.9%$Link Prediction#Cora#AP#96.0%$Link Prediction#Citeseer#AUC#95.94$Link Prediction#Citeseer#AP#96.04
2108.08046v2.pdf	Link Prediction#Pubmed#AUC#97.6%$Link Prediction#Pubmed#AP#97.6%$Link Prediction#Pubmed#AUC#97.5%$Link Prediction#Pubmed#AP#97.5%$Link Prediction#Cora#AUC#95.6%$Link Prediction#Cora#AP#95.7%$Link Prediction#Cora#AUC#95.4%$Link Prediction#Cora#AP#95.8%$Link Prediction#Citeseer#AUC#97$Link Prediction#Citeseer#AP#97.1$Link Prediction#Citeseer#AUC#96.5$Link Prediction#Citeseer#AP#97
1802.04407v2.pdf	Link Prediction#Pubmed#AUC#96.8%$Link Prediction#Pubmed#AP#97.1%$Link Prediction#Cora#AUC#92.4%$Link Prediction#Cora#AP#93.2%$Link Prediction#Citeseer#AUC#91.9$Link Prediction#Citeseer#AP#93$Graph Clustering#Citeseer#ARI#34.1$Graph Clustering#Citeseer#F1#54.6$Graph Clustering#Citeseer#NMI#0.35$Graph Clustering#Citeseer#Precision#57.3$Graph Clustering#Citeseer#ACC#57.3$Graph Clustering#Citeseer#ARI#24.5$Graph Clustering#Citeseer#F1#52.9$Graph Clustering#Citeseer#NMI#26.1$Graph Clustering#Citeseer#Precision#54.9$Graph Clustering#Citeseer#ACC#54.4$Graph Clustering#Cora#ARI#35.2$Graph Clustering#Cora#F1#61.9$Graph Clustering#Cora#NMI#0.449$Graph Clustering#Cora#Precision#64.6$Graph Clustering#Cora#ACC#64$Graph Clustering#Cora#ARI#37.4$Graph Clustering#Cora#F1#62.7$Graph Clustering#Cora#NMI#45$Graph Clustering#Cora#Precision#62.4$Graph Clustering#Cora#ACC#63.8
1804.00891v3.pdf	Link Prediction#Pubmed#AUC#96.0%$Link Prediction#Pubmed#AP#96.0%$Link Prediction#Cora#AUC#94.1%$Link Prediction#Cora#AP#94.1%$Link Prediction#Citeseer#AUC#94.7$Link Prediction#Citeseer#AP#95.2
1905.08509v4.pdf	Link Prediction#Pubmed#AUC#94.8%$Link Prediction#Pubmed#AP#96.3%$Link Prediction#Cora#AUC#94.1%$Link Prediction#Cora#AP#94.1%$Graph Classification#PTC#Accuracy#73.56%$Graph Classification#PROTEINS#Accuracy#78.97%$Graph Classification#NCI1#Accuracy#83.85%$Graph Classification#MUTAG#Accuracy#94.14%$Graph Classification#20NEWS#Accuracy#47.9$Graph Classification#Digits#Accuracy#92.5$Graph Classification#Citeseer#Accuracy#73.7$Graph Classification#IMDb-B#Accuracy#77.94%$Graph Classification#COLLAB#Accuracy#80.71%$Graph Classification#Wine#Accuracy#98$Graph Classification#Cora#Accuracy#72.3$Graph Classification#IMDb-M#Accuracy#54.52%$Graph Classification#Cancer#Accuracy#95.7
1910.02548v1.pdf	Link Prediction#Pubmed#AUC#94.5%$Link Prediction#Pubmed#AP#94.2%$Link Prediction#Cora#AUC#93.50%$Link Prediction#Cora#AP#93.2%$Link Prediction#Citeseer#AUC#90.9%$Link Prediction#Citeseer#AP#91.8%
2009.06946v1.pdf	Link Prediction#Pubmed#AUC#93.7%$Link Prediction#Pubmed#AP#93.5%$Link Prediction#Cora#AUC#93.7%$Link Prediction#Cora#AP#93.5%$Link Prediction#Citeseer#AUC#97$Link Prediction#Citeseer#AP#96.8$Node Classification#Pubmed#Accuracy#77.4 ± 1.9$Node Classification#Coauthor Phy#Accuracy#93.1 ± 0.7$Node Classification#Citeseer#Accuracy#71.9 ± 1.4$Node Classification#AMZ Photo#Accuracy#90.4 ± 1.0$Node Classification#Coauthor CS#Accuracy#89.4 ± 0.4$Node Classification#Cora: fixed 20 node per class#Accuracy#81.7 ± 1.5$Node Classification#AMZ Comp#Accuracy#81.5 ± 1.0
1811.02798v1.pdf	Link Prediction#Pubmed#Accuracy#94.40%$Link Prediction#Cora#Accuracy#94.60%$Link Prediction#Citeseer#Accuracy#94.90%$Node Classification#Pubmed#Accuracy#80.40%$Node Classification#Pubmed#Training Split#20 per node$Node Classification#Pubmed#Validation#YES$Node Classification#Cora#Accuracy#79.00%$Node Classification#Cora#Validation#YES$Node Classification#Citeseer#Accuracy#71.80%$Node Classification#Citeseer#Validation#YES
1611.07308v1.pdf	Link Prediction#Pubmed#ACC#97.1$Link Prediction#Cora#ACC#92.0$Link Prediction#Citeseer#ACC#91.4$Graph Clustering#Pubmed#ACC#65.48$Graph Clustering#Citeseer#ACC#40.8$Graph Clustering#Cora#ACC#59.6
1910.12933v1.pdf	Link Prediction#PPI#Accuracy#84.5$Node Classification#Pubmed#Accuracy#80.3%$Node Classification#Cora#Accuracy#79.9%
1902.06684v1.pdf	Link Prediction#Douban#AUC#84.2$Link Prediction#Yelp#AUC#90.1$Link Prediction#MIT#AUC#92.6$Link Prediction#DBLP#AUC#84.7
1901.10234v2.pdf	Link Prediction#Douban#AUC#82.3$Link Prediction#Yelp#AUC#86.2$Link Prediction#DBLP#AUC#90.1$Link Prediction#IMDb#AUC#89.4
2110.14923v2.pdf	Link Prediction#GO21#MRR#0.211$Link Prediction#GO21#Hit@1#0.14$Link Prediction#GO21#Hits@3#0.237$Link Prediction#GO21#Hits@10#0.347$Link Prediction#DDB14#MRR#0.231$Link Prediction#DDB14#Hits@1#0.161$Link Prediction#DDB14#Hits@3#0.252$Link Prediction#DDB14#Hits@10#0.364$Link Prediction#WN18RR#MRR#0.496$Link Prediction#WN18RR#Hits@10#0.579$Link Prediction#WN18RR#Hits@3#0.515$Link Prediction#WN18RR#Hits@1#0.453$Link Prediction#FB15k-237#MRR#0.345$Link Prediction#FB15k-237#Hits@10#0.54$Link Prediction#FB15k-237#Hits@3#0.381$Link Prediction#FB15k-237#Hits@1#0.247$Ancestor-descendant prediction#WN18RR#mAP-0%#0.895$Ancestor-descendant prediction#WN18RR#mAP-50%#0.801$Ancestor-descendant prediction#WN18RR#mAP-100%#0.679
1811.00839v2.pdf	Link Prediction#Cit-HepPH#AUC#89.16$Link Prediction#Gnutella#AUC#93.14$Link Prediction#Wiki-Vote#AUC#94.81
2009.10847v1.pdf	Link Prediction#JF17K#MRR#0.574$Link Prediction#JF17K#Hit@1#0.496$Link Prediction#JF17K#Hit@10#0.725$Link Prediction#JF17K#Hit@5#0.658$Link Prediction#WD50K#MRR#0.349$Link Prediction#WD50K#Hit@1#0.271$Link Prediction#WD50K#Hit@10#0.496
2007.06267v2.pdf	Link Prediction#JF17K#MRR#0.560$Link Prediction#JF17K#Hit@1#0.472$Link Prediction#JF17K#Hit@10#0.722$Link Prediction#FB-AUTO#MRR#0.844$Link Prediction#FB-AUTO#Hits@10#0.898$Link Prediction#FB-AUTO#Hits@1#0.814$Link Prediction#FB15k-237#MRR#0.337$Link Prediction#FB15k-237#Hits@10#0.538$Link Prediction#FB15k-237#Hits@1#0.238$Link Prediction#YAGO3-10#MRR#0.567$Link Prediction#YAGO3-10#Hits@10#0.699$Link Prediction#YAGO3-10#Hits@1#0.494
1905.01669v2.pdf	Link Prediction#Twitter#F1-Score#84.96$Link Prediction#Twitter#PR AUC#91.77$Link Prediction#Twitter#ROC AUC#92.3$Link Prediction#YouTube#F1-Score#76.83$Link Prediction#YouTube#PR AUC#81.93$Link Prediction#YouTube#ROC AUC#84.61$Link Prediction#Alibaba-S#F1-Score#62.48$Link Prediction#Alibaba-S#PR AUC#67.55$Link Prediction#Alibaba-S#ROC AUC#66.71$Link Prediction#Alibaba#F1-Score#89.94$Link Prediction#Alibaba#PR AUC#95.04$Link Prediction#Alibaba#ROC AUC#84.2$Link Prediction#Amazon#F1-Score#92.87$Link Prediction#Amazon#PR AUC#97.05$Link Prediction#Amazon#ROC AUC#97.44
1707.01476v6.pdf	Link Prediction#WN18#MRR#0.963$Link Prediction#WN18#Hits@10#0.964$Link Prediction#WN18#Hits@3#0.964$Link Prediction#WN18#Hits@1#0.953$Link Prediction#WN18#MR#740$Link Prediction#WN18#MRR#0.943$Link Prediction#WN18#Hits@10#0.956$Link Prediction#WN18#Hits@3#0.946$Link Prediction#WN18#Hits@1#0.935$Link Prediction#WN18#MR#374$Link Prediction#UMLS#Hits@10#0.990$Link Prediction#UMLS#MR#1.51$Link Prediction#FB15k#MR#2501$Link Prediction#FB15k#MRR#0.660$Link Prediction#FB15k#Hits@10#0.660$Link Prediction#FB15k#Hits@3#0.659$Link Prediction#FB15k#Hits@1#0.658$Link Prediction#FB15k#MR#51$Link Prediction#FB15k#MRR#0.657$Link Prediction#FB15k#Hits@10#0.831$Link Prediction#FB15k#Hits@3#0.723$Link Prediction#FB15k#Hits@1#0.558$Link Prediction#WN18RR#MRR#0.430$Link Prediction#WN18RR#Hits@10#0.520$Link Prediction#WN18RR#Hits@3#0.440$Link Prediction#WN18RR#Hits@1#0.400$Link Prediction#WN18RR#MRR#0.35$Link Prediction#WN18RR#Hits@10#0.35$Link Prediction#WN18RR#Hits@3#0.35$Link Prediction#WN18RR#Hits@1#0.35$Link Prediction#WN18RR#MR#13526$Link Prediction#FB15k-237#MRR#0.325$Link Prediction#FB15k-237#Hits@10#0.501$Link Prediction#FB15k-237#Hits@3#0.356$Link Prediction#FB15k-237#Hits@1#0.237$Link Prediction#FB15k-237#MRR#0.010$Link Prediction#FB15k-237#Hits@10#0.014$Link Prediction#FB15k-237#Hits@3#0.011$Link Prediction#FB15k-237#Hits@1#0.007$Link Prediction#FB15k-237#MR#7030$Link Prediction#YAGO3-10#MRR#0.44$Link Prediction#YAGO3-10#Hits@10#0.62
2004.10037v2.pdf	Link Prediction#WN18#MRR#0.952$Link Prediction#WN18#Hits@10#0.961$Link Prediction#WN18#Hits@3#0.955$Link Prediction#WN18#Hits@1#0.947$Link Prediction#WN18#MR#170$Link Prediction#WN18RR#MRR#0.495$Link Prediction#WN18RR#Hits@10#0.578$Link Prediction#WN18RR#Hits@3#0.509$Link Prediction#WN18RR#Hits@1#0.453$Link Prediction#WN18RR#MR#1644$Link Prediction#FB15k-237#MRR#0.357$Link Prediction#FB15k-237#Hits@10#0.545$Link Prediction#FB15k-237#Hits@3#0.391$Link Prediction#FB15k-237#Hits@1#0.264$Link Prediction#FB15k-237#MR#155$Link Prediction#FB15k#Hits@10#0.906$Link Prediction#FB15k#Hits@1#0.805$Link Prediction#FB15k#Hits@3#0.867$Link Prediction#FB15k#MR#36$Link Prediction#FB15k#MRR#0.843
2105.09002v2.pdf	Link Prediction#WN18#MRR#0.95$Link Prediction#WN18#Hits@10#0.961$Link Prediction#WN18#Hits@3#0.954$Link Prediction#WN18#Hits@1#0.944$Link Prediction#WN18#MR#120$Link Prediction#WN18RR#MRR#0.489$Link Prediction#WN18RR#Hits@10#0.586$Link Prediction#WN18RR#Hits@3#0.509$Link Prediction#WN18RR#Hits@1#0.438$Link Prediction#WN18RR#MR#1977$Link Prediction#FB15k-237#MRR#0.365$Link Prediction#FB15k-237#Hits@10#0.563$Link Prediction#FB15k-237#Hits@3#0.40$Link Prediction#FB15k-237#Hits@1#0.268$Link Prediction#FB15k-237#MR#90
1904.11682v3.pdf	Link Prediction#WN18#MRR#0.952$Link Prediction#WN18#Hits@10#0.961$Link Prediction#FB15k#MRR#0.861$Link Prediction#FB15k#Hits@10#0.914$Link Prediction#WN18RR#MRR#0.490$Link Prediction#WN18RR#Hits@10#0.567$Link Prediction#FB15k-237#MRR#0.365$Link Prediction#FB15k-237#Hits@10#0.555$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.5510 ± 0.0063$Link Property Prediction#ogbl-wikikg2#Test MRR#0.5458 ± 0.0052$Link Property Prediction#ogbl-wikikg2#Number of params#500227800$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-biokg#Test MRR#0.8309 ± 0.0008$Link Property Prediction#ogbl-biokg#Validation MRR#0.8317 ± 0.0007$Link Property Prediction#ogbl-biokg#Number of params#93824000$Link Property Prediction#ogbl-biokg#Ext. data#No
2006.16365v2.pdf	Link Prediction#WN18#MRR#0.951$Link Prediction#WN18#Hits@10#0.960$Link Prediction#WN18#Hits@3#0.953$Link Prediction#WN18#Hits@1#0.946$Link Prediction#WN18#MRR#0.950$Link Prediction#WN18#Hits@10#0.957$Link Prediction#WN18#Hits@3#0.952$Link Prediction#FB15k#MRR#0.806$Link Prediction#FB15k#Hits@10#0.893$Link Prediction#FB15k#Hits@3#0.843$Link Prediction#FB15k#Hits@1#0.754$Link Prediction#WN18RR#MRR#0.481$Link Prediction#WN18RR#Hits@10#0.551$Link Prediction#WN18RR#Hits@3#0.496$Link Prediction#WN18RR#Hits@1#0.444$Link Prediction#KG20C#MRR#0.230$Link Prediction#KG20C#Hits@1#0.157$Link Prediction#KG20C#Hits@3#0.258$Link Prediction#KG20C#Hits@10#0.368$Link Prediction#FB15k-237#MRR#0.365$Link Prediction#FB15k-237#Hits@10#0.552$Link Prediction#FB15k-237#Hits@3#0.402$Link Prediction#FB15k-237#Hits@1#0.271$Link Prediction#FB15k#Hits@10#0.878$Link Prediction#FB15k#Hits@1#0.757$Link Prediction#FB15k#Hits@3#0.823$Link Prediction#FB15k#MRR#0.800$Link Prediction#YAGO3-10#MRR#0.578$Link Prediction#YAGO3-10#Hits@10#0.709$Link Prediction#YAGO3-10#Hits@1#0.505$Link Prediction#YAGO3-10#Hits@3#0.622$Link Prediction#YAGO3-10#MR#756
1806.07297v1.pdf	Link Prediction#WN18#MRR#0.95$Link Prediction#WN18#Hits@10#0.96$Link Prediction#FB15k#MRR#0.86$Link Prediction#FB15k#Hits@10#0.91$Link Prediction#WN18RR#MRR#0.48$Link Prediction#WN18RR#Hits@10#0.57$Link Prediction#YAGO3-10#MRR#0.58$Link Prediction#YAGO3-10#Hits@10#0.71
1904.10281v3.pdf	Link Prediction#WN18#MRR#0.95$Link Prediction#WN18#Hits@10#0.959$Link Prediction#WN18#Hits@3#0.954$Link Prediction#WN18#Hits@1#0.945$Link Prediction#WN18#MR#162$Link Prediction#FB15k#MR#17$Link Prediction#FB15k#MRR#0.833$Link Prediction#FB15k#Hits@10#0.900$Link Prediction#FB15k#Hits@3#0.859$Link Prediction#FB15k#Hits@1#0.800$Link Prediction#WN18RR#MRR#0.488$Link Prediction#WN18RR#Hits@10#0.582$Link Prediction#WN18RR#Hits@3#0.508$Link Prediction#WN18RR#Hits@1#0.438$Link Prediction#WN18RR#MR#2314$Link Prediction#FB15k-237#MRR#0.348$Link Prediction#FB15k-237#Hits@10#0.550$Link Prediction#FB15k-237#Hits@3#0.382$Link Prediction#FB15k-237#Hits@1#0.248$Link Prediction#FB15k-237#MR#87
2008.04548v2.pdf	Link Prediction#WN18#MRR#0.950$Link Prediction#WN18#Hits@10#0.959$Link Prediction#WN18#Hits@3#0.954$Link Prediction#WN18#Hits@1#0.945$Link Prediction#WN18#MR#285$Link Prediction#WN18RR#MRR#0.491$Link Prediction#WN18RR#Hits@10#0.579$Link Prediction#WN18RR#Hits@3#0.508$Link Prediction#WN18RR#Hits@1#0.443$Link Prediction#WN18RR#MR#3052$Link Prediction#FB15k-237#MRR#0.349$Link Prediction#FB15k-237#Hits@10#0.535$Link Prediction#FB15k-237#Hits@3#0.384$Link Prediction#FB15k-237#Hits@1#0.256$Link Prediction#FB15k-237#MR#169$Link Prediction#YAGO3-10#MRR#0.541$Link Prediction#YAGO3-10#Hits@10#0.678$Link Prediction#YAGO3-10#Hits@1#0.465$Link Prediction#YAGO3-10#Hits@3#0.585
1902.10197v1.pdf	Link Prediction#WN18#MRR#0.949$Link Prediction#WN18#Hits@10#0.959$Link Prediction#WN18#Hits@3#0.952$Link Prediction#WN18#Hits@1#0.944$Link Prediction#WN18#MR#309$Link Prediction#WN18#MRR#0.947$Link Prediction#WN18#Hits@10#0.957$Link Prediction#WN18#Hits@3#0.950$Link Prediction#WN18#Hits@1#0.942$Link Prediction#WN18#MR#254$Link Prediction#FB122#HITS@3#70.8$Link Prediction#FB122#Hits@5#73.57$Link Prediction#FB122#Hits@10#77.0$Link Prediction#FB122#MRR#67.8$Link Prediction#FB15k#MR#43$Link Prediction#FB15k#MRR#0.799$Link Prediction#FB15k#Hits@10#0.884$Link Prediction#FB15k#Hits@3#0.829$Link Prediction#FB15k#Hits@1#0.750$Link Prediction#FB15k#MR#40$Link Prediction#FB15k#MRR#0.797$Link Prediction#FB15k#Hits@3#0.830$Link Prediction#FB15k#Hits@1#0.746$Link Prediction#WN18RR#MRR#0.476$Link Prediction#WN18RR#Hits@10#0.571$Link Prediction#WN18RR#Hits@3#0.492$Link Prediction#WN18RR#Hits@1#0.428$Link Prediction#WN18RR#MR#3340$Link Prediction#WN18RR#MRR#0.462$Link Prediction#WN18RR#Hits@10#0.552$Link Prediction#WN18RR#Hits@3#0.479$Link Prediction#WN18RR#Hits@1#0.417$Link Prediction#WN18RR#MR#2923$Link Prediction#FB15k-237#MRR#0.338$Link Prediction#FB15k-237#Hits@10#0.533$Link Prediction#FB15k-237#Hits@3#0.375$Link Prediction#FB15k-237#Hits@1#0.241$Link Prediction#FB15k-237#MR#177$Link Prediction#FB15k-237#MRR#0.328$Link Prediction#FB15k-237#Hits@10#0.524$Link Prediction#FB15k-237#Hits@3#0.365$Link Prediction#FB15k-237#Hits@1#0.23$Link Prediction#FB15k-237#MR#178$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.4353 ± 0.0028$Link Property Prediction#ogbl-wikikg2#Test MRR#0.4332 ± 0.0025$Link Property Prediction#ogbl-wikikg2#Number of params#1250435750$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.2250 ± 0.0035$Link Property Prediction#ogbl-wikikg2#Test MRR#0.2530 ± 0.0034$Link Property Prediction#ogbl-wikikg2#Number of params#250087150$Link Property Prediction#ogbl-biokg#Test MRR#0.7989 ± 0.0004$Link Property Prediction#ogbl-biokg#Validation MRR#0.7997 ± 0.0002$Link Property Prediction#ogbl-biokg#Number of params#187597000$Link Property Prediction#ogbl-biokg#Ext. data#No
1901.09590v2.pdf	Link Prediction#WN18#MRR#0.953$Link Prediction#WN18#Hits@10#0.958$Link Prediction#WN18#Hits@3#0.955$Link Prediction#WN18#Hits@1#0.949$Link Prediction#FB15k#MRR#0.795$Link Prediction#FB15k#Hits@10#0.892$Link Prediction#FB15k#Hits@3#0.833$Link Prediction#FB15k#Hits@1#0.741$Link Prediction#WN18RR#MRR#0.470$Link Prediction#WN18RR#Hits@10#0.526$Link Prediction#WN18RR#Hits@3#0.482$Link Prediction#WN18RR#Hits@1#0.443$Link Prediction#FB15k-237#MRR#0.358$Link Prediction#FB15k-237#Hits@10#0.544$Link Prediction#FB15k-237#Hits@3#0.394$Link Prediction#FB15k-237#Hits@1#0.266
1808.07018v5.pdf	Link Prediction#WN18#MRR#0.951$Link Prediction#WN18#Hits@10#0.958$Link Prediction#WN18#Hits@3#0.955$Link Prediction#WN18#Hits@1#0.947$Link Prediction#FB15k#MRR#0.790$Link Prediction#FB15k#Hits@10#0.885$Link Prediction#FB15k#Hits@3#0.829$Link Prediction#FB15k#Hits@1#0.734$Link Prediction#WN18RR#MRR#0.465$Link Prediction#WN18RR#Hits@10#0.522$Link Prediction#WN18RR#Hits@3#0.477$Link Prediction#WN18RR#Hits@1#0.436$Link Prediction#WN18RR#MR#5796$Link Prediction#FB15k-237#MRR#0.341$Link Prediction#FB15k-237#Hits@10#0.520$Link Prediction#FB15k-237#Hits@3#0.376$Link Prediction#FB15k-237#Hits@1#0.252
1909.11864v1.pdf	Link Prediction#WN18#Hits@10#0.957$Link Prediction#WN18#MR#199$Link Prediction#FB15k#MR#33$Link Prediction#FB15k#Hits@10#0.899
1903.11406v3.pdf	Link Prediction#WN18#MRR#0.941$Link Prediction#WN18#Hits@10#0.956$Link Prediction#WN18#Hits@3#0.950$Link Prediction#WN18#Hits@1#0.931
1905.10702v8.pdf	Link Prediction#WN18#MRR#0.871$Link Prediction#WN18#Hits@10#0.956$Link Prediction#WN18#MR#118$Link Prediction#WN18RR#MRR#0.458$Link Prediction#WN18RR#Hits@10#0.560$Link Prediction#WN18RR#MR#3219$Link Prediction#FB15k-237#MRR#0.344$Link Prediction#FB15k-237#Hits@10#0.531$Link Prediction#FB15k-237#MR#203$Link Prediction#FB15k#Hits@10#0.857$Link Prediction#FB15k#MR#49$Link Prediction#FB15k#MRR#0.652
1903.00757v1.pdf	Link Prediction#WN18#MRR#0.948$Link Prediction#WN18#Hits@10#0.954$Link Prediction#WN18#Hits@3#0.950$Link Prediction#WN18#Hits@1#0.944$Link Prediction#WN18#MR#412$Link Prediction#WN18#training time (s)#1042$Link Prediction#FB15k#MR#74$Link Prediction#FB15k#MRR#0.779$Link Prediction#FB15k#Hits@10#0.876$Link Prediction#FB15k#Hits@3#0.818$Link Prediction#FB15k#Hits@1#0.721$Link Prediction#FB15k#training time (s)#2105$Link Prediction#FB15k-237#MRR#0.314$Link Prediction#FB15k-237#Hits@10#0.511$Link Prediction#FB15k-237#Hits@3#0.347$Link Prediction#FB15k-237#Hits@1#0.217$Link Prediction#FB15k-237#MR#176$Link Prediction#FB15k-237#training time (s)#857$Node Classification#YouTube#runtime (s)#70.09$Node Classification#YouTube#Micro-F1@2%#40.61$Node Classification#YouTube#Macro-F1@2%#33.69
1811.01062v2.pdf	Link Prediction#WN18#MRR#.939$Link Prediction#WN18#Hits@10#.951$Link Prediction#WN18#Hits@3#.945$Link Prediction#WN18#Hits@1#.931$Link Prediction#WN18#MR#183$Link Prediction#FB15k#MR#21$Link Prediction#FB15k#MRR#.796$Link Prediction#FB15k#Hits@10#.901$Link Prediction#FB15k#Hits@3#.848$Link Prediction#FB15k#Hits@1#.727$Link Prediction#FB15k#Hits@10#0.901$Link Prediction#FB15k#Hits@1#0.727$Link Prediction#FB15k#Hits@3#0.848$Link Prediction#FB15k#MRR#0.796$Knowledge Graphs#FB15k#MRR#.796
1510.04935v2.pdf	Link Prediction#WN18#MRR#0.938$Link Prediction#WN18#Hits@10#0.949$Link Prediction#WN18#Hits@3#0.945$Link Prediction#WN18#Hits@1#0.930$Link Prediction#FB15k#Hits@10#0.739$Link Prediction#FB15k#Hits@1#0.402$Link Prediction#FB15k#Hits@3#0.613$Link Prediction#FB15k#MRR#0.524
1908.07141v1.pdf	Link Prediction#WN18#MRR#0.923$Link Prediction#WN18#Hits@10#0.948$Link Prediction#WN18#MR#357$Link Prediction#FB15k#MR#112$Link Prediction#FB15k#MRR#0.766$Link Prediction#FB15k#Hits@10#0.874$Link Prediction#FB15k-237#Hits@10#0.473$Link Prediction#FB15k-237#MR#424
1711.04071v3.pdf	Link Prediction#WN18#MRR#0.779$Link Prediction#WN18#Hits@10#0.948$Link Prediction#WN18RR#MRR#0.215$Link Prediction#WN18RR#Hits@10#0.469$Link Prediction#FB15k-237#MRR#0.277$Link Prediction#FB15k-237#Hits@10#0.458
1705.02426v2.pdf	Link Prediction#WN18#MRR#0.942$Link Prediction#WN18#Hits@10#0.947$Link Prediction#WN18#Hits@3#0.944$Link Prediction#WN18#Hits@1#0.939
1802.04868v2.pdf	Link Prediction#WN18#MRR#0.942$Link Prediction#WN18#Hits@10#0.947$Link Prediction#WN18#Hits@3#0.944$Link Prediction#WN18#Hits@1#0.939$Link Prediction#FB15k#MRR#0.727$Link Prediction#FB15k#Hits@10#0.838$Link Prediction#FB15k#Hits@3#0.773$Link Prediction#FB15k#Hits@1#0.660
1606.06357v1.pdf	Link Prediction#WN18#MRR#0.941$Link Prediction#WN18#Hits@10#0.947$Link Prediction#WN18#Hits@3#0.936$Link Prediction#WN18#Hits@1#0.936$Link Prediction#FB122#HITS@3#67.3$Link Prediction#FB122#Hits@5#69.5$Link Prediction#FB122#Hits@10#71.9$Link Prediction#FB122#MRR#64.1$Link Prediction#UMLS#Hits@10#0.967$Link Prediction#UMLS#MR#2.59$Link Prediction#WN18RR#MRR#0.440$Link Prediction#WN18RR#Hits@10#0.510$Link Prediction#WN18RR#Hits@1#0.410$Link Prediction#FB15k-237#Hits@10#0.428$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.3759 ± 0.0016$Link Property Prediction#ogbl-wikikg2#Test MRR#0.4027 ± 0.0027$Link Property Prediction#ogbl-wikikg2#Number of params#1250569500$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.3534 ± 0.0052$Link Property Prediction#ogbl-wikikg2#Test MRR#0.3804 ± 0.0022$Link Property Prediction#ogbl-wikikg2#Number of params#250113900$Link Property Prediction#ogbl-biokg#Test MRR#0.8095 ± 0.0007$Link Property Prediction#ogbl-biokg#Validation MRR#0.8105 ± 0.0001$Link Property Prediction#ogbl-biokg#Number of params#187648000$Link Property Prediction#ogbl-biokg#Ext. data#No
1812.06410v2.pdf	Link Prediction#WN18#MRR#0.9355$Link Prediction#WN18#Hits@10#0.9398$Link Prediction#WN18#MR#1072$Link Prediction#FB15k#MRR#0.7721$Link Prediction#WN18RR#MRR#0.4463$Link Prediction#WN18RR#Hits@10#0.5089$Link Prediction#WN18RR#MR#5365$Link Prediction#FB15k-237#MRR#0.3021$Link Prediction#FB15k-237#Hits@10#0.4805$Link Prediction#FB15k-237#MR#221$Link Prediction#FB15k#Hits@10#0.8682$Link Prediction#FB15k#MR#82
1610.09369v1.pdf	Link Prediction#WN18#Hits@10#0.939$Link Prediction#WN18#Hits@1#0.761$Link Prediction#WN18#MR#352
1412.6575v4.pdf	Link Prediction#WN18#MRR#0.822$Link Prediction#WN18#Hits@10#0.936$Link Prediction#WN18#Hits@3#0.914$Link Prediction#WN18#Hits@1#0.728$Link Prediction#WN18#MR#902$Link Prediction#UMLS#Hits@10#0.846$Link Prediction#UMLS#MR#5.52$Link Prediction#WN18RR#MRR#0.43$Link Prediction#WN18RR#Hits@1#0.39$Link Prediction#FB15k-237#MRR#0.241$Link Prediction#FB15k-237#Hits@10#0.419$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.3506 ± 0.0042$Link Property Prediction#ogbl-wikikg2#Test MRR#0.3729 ± 0.0045$Link Property Prediction#ogbl-wikikg2#Number of params#1250569500$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.3150 ± 0.0088$Link Property Prediction#ogbl-wikikg2#Test MRR#0.3447 ± 0.0082$Link Property Prediction#ogbl-wikikg2#Number of params#250113900$Link Property Prediction#ogbl-biokg#Test MRR#0.8043 ± 0.0003$Link Property Prediction#ogbl-biokg#Validation MRR#0.8055 ± 0.0003$Link Property Prediction#ogbl-biokg#Number of params#187648000$Link Property Prediction#ogbl-biokg#Ext. data#No
1703.10316v4.pdf	Link Prediction#WN18#Hits@10#0.668$Link Prediction#WN18#MR#215$Link Prediction#FB15k (filtered)#Hits@10#65.7$Link Prediction#FB15k (filtered)#MR#60$Link Prediction#WN18 (filtered)#Hits@10#76.6$Link Prediction#WN18 (filtered)#MR#203$Link Prediction#FB15k#Hits@10#0.468$Link Prediction#FB15k#MR#60
1907.01068v1.pdf	Link Prediction#WN18#MRR#0.911$Link Prediction#FB15k#MRR#0.841$Link Prediction#FB15k#Hits@10#0.914$Link Prediction#WN18RR#MRR#0.455$Link Prediction#FB15k-237#MRR#0.357$Link Prediction#FB15k-237#Hits@10#0.548
2007.14175v2.pdf	Link Prediction#WN18#training time (s)#6$Link Prediction#WN18#training time (s)#10$Link Prediction#WN18#training time (s)#11
2010.11793v3.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.5475$Link Prediction#MovieLens 25M#Hits@10#0.8284$Link Prediction#Yelp#HR@10#0.9128$Link Prediction#Yelp#nDCG@10#0.6641
1708.05027v1.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.5347$Link Prediction#MovieLens 25M#Hits@10#0.8132$Link Prediction#Yelp#HR@10#0.8595$Link Prediction#Yelp#nDCG@10#0.6062
1905.07854v2.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.5236$Link Prediction#MovieLens 25M#Hits@10#0.8147$Link Prediction#Yelp#HR@10#0.8762$Link Prediction#Yelp#nDCG@10#0.6136
1805.03352v2.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.5196$Link Prediction#MovieLens 25M#Hits@10#0.8152$Link Prediction#Yelp#HR@10#0.8729$Link Prediction#Yelp#nDCG@10#0.5826
1905.08108v2.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.4866$Link Prediction#MovieLens 25M#Hits@10#0.7807
1904.12575v1.pdf	Link Prediction#MovieLens 25M#nDCG@10#0.4699$Link Prediction#MovieLens 25M#Hits@10#0.771$Link Prediction#Yelp#HR@10#0.8125$Link Prediction#Yelp#nDCG@10#0.4668$Click-Through Rate Prediction#Last.FM#AUC#0.796$Click-Through Rate Prediction#Last.FM#F1#0.721$Click-Through Rate Prediction#Book-Crossing#AUC#0.738$Click-Through Rate Prediction#Book-Crossing#F1#0.688
2102.12227v1.pdf	Link Prediction#CDCP#F1#29.73$Link Prediction#AbstRCT - Neoplasm#F1#54.43$Link Prediction#DRI Corpus#F1#43.66$Relation Classification#CDCP#Macro F1#42.95$Relation Classification#DRI Corpus#Macro F1#37.72$Relation Classification#AbstRCT - Neoplasm#Macro F1#70.92$Component Classification#CDCP#Macro F1#78.71
2010.08516v1.pdf	Link Prediction#Drug-target interactions#AUPRC#93.7$Link Prediction#Gene-disease interactions#AUPRC#94.1$Link Prediction#Drug-Drug Interactions#AUPRC#89.7$Link Prediction#protein-protein interactions#AUPRC#93
1903.12287v3.pdf	Link Prediction#YouTube#Macro F1#40.9$Link Prediction#YouTube#Micro F1#48$Link Prediction#LiveJournal#Hits@10#0.857$Link Prediction#LiveJournal#MR#245.9$Link Prediction#LiveJournal#MRR#0.749$Link Prediction#FB15k#Hits@10#0.872$Link Prediction#FB15k#MRR#0.79$Link Prediction#FB15k#MRR raw#0.242
2005.09683v2.pdf	Link Prediction#Yelp#HR@10#0.8068$Link Prediction#Yelp#nDCG@10#0.481
1906.12330v1.pdf	Link Prediction#Pubmed (biased evaluation)#AUC#97.67$Link Prediction#Pubmed (biased evaluation)#AP#98.64$Link Prediction#Pubmed (biased evaluation)#Accuracy#98.16$Link Prediction#Citeseer (biased evaluation)#AUC#97.47$Link Prediction#Citeseer (biased evaluation)#AP#97.93$Link Prediction#Citeseer (biased evaluation)#Accuracy#97.7$Link Prediction#Cora (biased evaluation)#AUC#95.65$Link Prediction#Cora (biased evaluation)#AP#96.15$Link Prediction#Cora (biased evaluation)#Accuracy#95.9$Sentiment Analysis#MR#Accuracy#76.6$Sentiment Analysis#IMDb#Accuracy#96.0$Text Classification#20NEWS#Accuracy#86.9$Text Classification#R52#Accuracy#95.00$Text Classification#R8#Accuracy#97.4$Text Classification#Ohsumed#Accuracy#64.2$Graph Classification#PROTEINS#Accuracy#77.90%$Graph Classification#MUTAG#Accuracy#91.2%$Graph Classification#ENZYMES#Accuracy#67.1%$Graph Classification#D&D#Accuracy#79.60%$Node Classification#Pubmed#Accuracy#77.2%$Node Classification#Cora#Accuracy#82.1%$Node Classification#PPI#F1#99.4$Node Classification#Citeseer#Accuracy#71.0
1809.10851v2.pdf	Link Prediction#Pubmed (biased evaluation)#AUC#97.52$Link Prediction#Pubmed (biased evaluation)#AP#97.19$Link Prediction#Citeseer (biased evaluation)#AUC#97.27$Link Prediction#Citeseer (biased evaluation)#AP#97.57$Link Prediction#Cora (biased evaluation)#AUC#94.48$Link Prediction#Cora (biased evaluation)#AP#94.63
2010.03548v2.pdf	Link Prediction#FB122#HITS@3#74.2$Link Prediction#FB122#Hits@5#76.0$Link Prediction#FB122#Hits@10#78.2$Link Prediction#FB122#MRR#72.7$Link Prediction#WN18RR#MRR#0.48$Link Prediction#WN18RR#Hits@10#0.55$Link Prediction#WN18RR#Hits@3#0.49$Link Prediction#WN18RR#Hits@1#0.43$Link Prediction#NELL-995#MRR#0.81$Link Prediction#NELL-995#Hits@1#0.77$Link Prediction#NELL-995#Hits@10#0.89$Link Prediction#NELL-995#HITS@3#0.85
1912.10824v1.pdf	Link Prediction#FB122#HITS@3#69.2$Link Prediction#FB122#Hits@5#71.1$Link Prediction#FB122#Hits@10#73.2$Link Prediction#FB122#MRR#67.8
1804.01882v3.pdf	Link Prediction#WordNet#Accuracy#94.4
1705.08039v2.pdf	Link Prediction#WordNet#Accuracy#77.4$Link Prediction#WordNet#Accuracy#77.0$Link Prediction#WordNet#Accuracy#74.3$Link Prediction#WordNet#Accuracy#68.3
1802.09691v3.pdf	Link Prediction#USAir#AUC#97.09
1607.00653v1.pdf	Link Prediction#USAir#AUC#91.44$Malware Detection#Android Malware Dataset#Accuracy#81.25$Node Classification#Wikipedia#Accuracy#19.10%$Node Classification#Wikipedia#Macro-F1#0.179$Node Classification#Eximtradedata#Accuracy#21.50%$Node Classification#Eximtradedata#Macro-F1#0.206$Link Property Prediction#ogbl-ppa#Test Hits@100#0.2226 ± 0.0083$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.2253 ± 0.0088$Link Property Prediction#ogbl-ppa#Number of params#73878913$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.6141 ± 0.0011$Link Property Prediction#ogbl-citation2#Validation MRR#0.6124 ± 0.0011$Link Property Prediction#ogbl-citation2#Number of params#374911105$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.2326 ± 0.0209$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.3292 ± 0.0121$Link Property Prediction#ogbl-ddi#Number of params#645249$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.4888 ± 0.0054$Link Property Prediction#ogbl-collab#Validation Hits@50#0.5703 ± 0.0052$Link Property Prediction#ogbl-collab#Number of params#30322945$Link Property Prediction#ogbl-collab#Ext. data#No
1912.00536v1.pdf	Link Prediction#Cora (nonstandard variant)#AUC#98.6$Link Prediction#Cora (nonstandard variant)#AP#98.52$Link Prediction#DBLP#AUC#98.55$Link Prediction#DBLP#AP#98.4$Link Prediction#Pubmed (nonstandard variant)#AUC#97.82$Link Prediction#Pubmed (nonstandard variant)#AP#97.49$Link Prediction#Citeseer (nonstandard variant)#AUC#98.43$Link Prediction#Citeseer (nonstandard variant)#AP#98.37$Link Prediction#ACM#AP#98.24$Link Prediction#ACM#AUC#98.34
2205.15678v1.pdf	Link Prediction#TSP/HCP Benchmark set#F1#0.855$Graph Regression#ZINC 100k#MAE#0.136$Graph Classification#CIFAR10 100k#Accuracy (%)#73.90$Node Classification#CLUSTER#Accuracy#77.35
2108.03348v3.pdf	Link Prediction#TSP/HCP Benchmark set#F1#0.853$Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0857$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.0862$Graph Regression#ZINC-500k#MAE#0.108$Graph Regression#ZINC 100k#MAE#0.143$Graph Regression#PCQM4M-LSC#Validation MAE#0.1224$Graph Classification#MNIST#Accuracy#98.173$Graph Classification#CIFAR10 100k#Accuracy (%)#68.702$Node Classification#PATTERN 100k#Accuracy (%)#86.816$Node Classification#PATTERN#Accuracy#86.821$Node Classification#CLUSTER#Accuracy#79.232$Graph Property Prediction#ogbg-molpcba#Test AP#0.2961 ± 0.0024$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.806 ± 0.0065
2003.00982v4.pdf	Link Prediction#TSP/HCP Benchmark set#F1#0.838$Link Prediction#COLLAB#Hits#52.849$Graph Regression#ZINC-500k#MAE#0.214$Graph Regression#ZINC 100k#MAE#0.363$Graph Classification#MNIST#Accuracy#97.340$Graph Classification#CIFAR10 100k#Accuracy (%)#67.312$Node Classification#PATTERN#Accuracy#86.508$Node Classification#CLUSTER#Accuracy#76.08
2201.04843v2.pdf	Link Prediction#UMLS#Hits@10#1.000$Link Prediction#UMLS#MR#1.18$Link Prediction#WN18RR#MRR#0.482$Link Prediction#WN18RR#Hits@10#0.752$Link Prediction#WN18RR#Hits@3#0.563$Link Prediction#WN18RR#Hits@1#0.343$Link Prediction#WN18RR#MR#92$Link Prediction#FB15k-237#MRR#0.31$Link Prediction#FB15k-237#Hits@10#0.490$Link Prediction#FB15k-237#Hits@3#0.336$Link Prediction#FB15k-237#Hits@1#0.223$Link Prediction#FB15k-237#MR#154
2209.08721v1.pdf	Link Prediction#UMLS#Hits@10#0.994$Link Prediction#UMLS#MR#1.39$Link Prediction#WN18RR#Hits@10#0.786$Link Prediction#WN18RR#MR#35$Link Prediction#FB15k-237#Hits@10#0.533$Link Prediction#FB15k-237#MR#108
2004.14781v2.pdf	Link Prediction#UMLS#Hits@10#0.991$Link Prediction#UMLS#MR#1.49$Link Prediction#WN18RR#MRR#0.401$Link Prediction#WN18RR#Hits@10#0.709$Link Prediction#WN18RR#Hits@3#0.491$Link Prediction#WN18RR#Hits@1#0.243$Link Prediction#WN18RR#MR#51$Link Prediction#FB15k-237#MRR#0.365$Link Prediction#FB15k-237#Hits@10#0.562$Link Prediction#FB15k-237#Hits@3#0.404$Link Prediction#FB15k-237#Hits@1#0.266$Link Prediction#FB15k-237#MR#117
1909.03193v2.pdf	Link Prediction#UMLS#Hits@10#0.990$Link Prediction#UMLS#MR#1.47$Link Prediction#WN18RR#Hits@10#0.524$Link Prediction#WN18RR#MR#97$Link Prediction#FB15k-237#Hits@10#0.42$Link Prediction#FB15k-237#MR#153
1803.10459v4.pdf	Link Prediction#Citeseer#AUC#94.1%$Link Prediction#Citeseer#AP#95.4%$Node Classification#Pubmed#Accuracy#79.3 ± 0.03$Node Classification#Cora#Accuracy#82.1% ± 0.06%$Node Classification#Citeseer#Accuracy#71.0 ± 0.07
1910.11583v1.pdf	Link Prediction#FB15k#MRR#0.761$Link Prediction#FB15k#Hits@10#0.883$Link Prediction#FB15k#Hits@3#0.824$Link Prediction#FB15k#Hits@1#0.681$Link Prediction#FB15k-237#MRR#0.29$Link Prediction#FB15k-237#Hits@10#0.479$Link Prediction#FB15k-237#Hits@3#0.319$Link Prediction#FB15k-237#Hits@1#0.199
1702.06879v2.pdf	Link Prediction#FB15k#MRR#0.692$Link Prediction#FB15k#Hits@10#0.840$Link Prediction#FB15k#Hits@3#0.759$Link Prediction#FB15k#Hits@1#0.599$Knowledge Graphs#FB15k#MRR#0.587
1803.04311v3.pdf	Link Prediction#SINS#Scaled time-delay embeddings#213
2005.05035v2.pdf	Link Prediction#Yago11k#MRR#0.2364$Link Prediction#ICEWS14#MRR#0.589$Link Prediction#Wikidata12k#MRR#0.3335$Link Prediction#ICEWS05-15#MRR#0.632
2004.04926v1.pdf	Link Prediction#ICEWS14#MRR#0.62$Link Prediction#ICEWS14#MRR#0.56$Link Prediction#YAGO15k#MRR#0.37$Link Prediction#YAGO15k#MRR#0.35$Link Prediction#ICEWS05-15#MRR#0.67$Link Prediction#ICEWS05-15#MRR#0.60
2203.02167v1.pdf	Link Prediction#WN18RR#MRR#0.671$Link Prediction#WN18RR#Hits@10#0.817$Link Prediction#WN18RR#Hits@3#0.731$Link Prediction#WN18RR#Hits@1#0.588$Link Prediction#FB15k-237#MRR#0.336$Link Prediction#FB15k-237#Hits@10#0.511$Link Prediction#FB15k-237#Hits@3#0.365$Link Prediction#FB15k-237#Hits@1#0.249
2206.12617v1.pdf	Link Prediction#WN18RR#MRR#0.598$Link Prediction#WN18RR#Hits@10#0.806$Link Prediction#WN18RR#Hits@3#0.675$Link Prediction#WN18RR#Hits@1#0.480$Link Prediction#WN18RR#MR#72$Link Prediction#FB15k-237#MRR#0.410$Link Prediction#FB15k-237#Hits@10#0.571$Link Prediction#FB15k-237#Hits@3#0.445$Link Prediction#FB15k-237#Hits@1#0.319$Link Prediction#FB15k-237#MR#132
2009.07058v1.pdf	Link Prediction#WN18RR#MRR#0.5017$Link Prediction#WN18RR#Hits@10#0.611$Link Prediction#WN18RR#Hits@3#0.5418$Link Prediction#WN18RR#Hits@1#0.4391$Link Prediction#WN18RR#MR#1603$Link Prediction#FB15k-237#MRR#0.2591$Link Prediction#FB15k-237#Hits@10#0.4026$Link Prediction#FB15k-237#Hits@3#0.2820$Link Prediction#FB15k-237#Hits@1#0.1871$Link Prediction#FB15k-237#MR#411
2205.10852v4.pdf	Link Prediction#WN18RR#MRR#0.495$Link Prediction#WN18RR#Hits@10#0.591$Link Prediction#WN18RR#Hits@1#0.448$Link Prediction#FB15k-237#MRR#0.371$Link Prediction#FB15k-237#Hits@10#0.481$Link Prediction#FB15k-237#Hits@1#0.314
1808.08644v1.pdf	Link Prediction#WN18RR#MRR#0.4983$Link Prediction#WN18RR#Hits@10#0.5902$Link Prediction#WN18RR#Hits@1#0.4537
2005.00545v1.pdf	Link Prediction#WN18RR#MRR#.496$Link Prediction#WN18RR#Hits@10#0.586$Link Prediction#WN18RR#Hits@3#0.514$Link Prediction#WN18RR#Hits@1#0.449$Link Prediction#FB15k-237#MRR#0.351$Link Prediction#FB15k-237#Hits@10#0.541$Link Prediction#FB15k-237#Hits@3#0.390$Link Prediction#FB15k-237#Hits@1#0.256$Link Prediction#YAGO3-10#MRR#0.577$Link Prediction#YAGO3-10#Hits@10#0.712$Link Prediction#YAGO3-10#Hits@1#0.503$Link Prediction#YAGO3-10#Hits@3#0.621
1911.00055v1.pdf	Link Prediction#WN18RR#MRR#0.486$Link Prediction#WN18RR#Hits@10#0.586$Link Prediction#WN18RR#Hits@3#0.513$Link Prediction#WN18RR#Hits@1#0.425$Link Prediction#FB15k-237#MRR#0.343$Link Prediction#FB15k-237#Hits@10#0.516$Link Prediction#FB15k-237#Hits@3#0.378$Link Prediction#FB15k-237#Hits@1#0.255
2008.12813v2.pdf	Link Prediction#WN18RR#MRR#0.503$Link Prediction#WN18RR#Hits@10#0.584$Link Prediction#WN18RR#Hits@3#0.516$Link Prediction#WN18RR#Hits@1#0.462$Link Prediction#FB15k-237#MRR#0.373$Link Prediction#FB15k-237#Hits@3#0.409$Link Prediction#FB15k-237#Hit@10#0.558$Link Prediction#FB15k-237#Hit@1#0.279
1911.04910v3.pdf	Link Prediction#WN18RR#MRR#0.491$Link Prediction#WN18RR#Hits@10#0.583$Link Prediction#WN18RR#Hits@3#0.511$Link Prediction#WN18RR#Hits@1#0.442$Link Prediction#WN18RR#MR#2715$Link Prediction#FB15k-237#MRR#0.361$Link Prediction#FB15k-237#Hits@10#0.550$Link Prediction#FB15k-237#Hits@3#0.396$Link Prediction#FB15k-237#Hits@1#0.267$Link Prediction#FB15k-237#MR#154
1911.09419v3.pdf	Link Prediction#WN18RR#MRR#0.497$Link Prediction#WN18RR#Hits@10#0.582$Link Prediction#WN18RR#Hits@3#0.516$Link Prediction#WN18RR#Hits@1#0.452$Link Prediction#FB15k-237#MRR#0.346$Link Prediction#FB15k-237#Hits@3#0.381$Link Prediction#FB15k-237#Hits@1#0.25$Link Prediction#YAGO3-10#MRR#0.545$Link Prediction#YAGO3-10#Hits@10#0.694$Link Prediction#YAGO3-10#Hits@1#0.462$Link Prediction#YAGO3-10#Hits@3#0.596$Knowledge Graph Completion#WN18RR#Hits@3#0.516$Knowledge Graph Completion#FB15k-237#Hits@10#54.2
1906.01195v1.pdf	Link Prediction#WN18RR#Hits@10#0.581$Link Prediction#WN18RR#Hits@3#0.483$Link Prediction#WN18RR#Hits@1#0.361$Link Prediction#WN18RR#MRR#0.44$Link Prediction#WN18RR#MR#1940.0$Knowledge Graph Completion#WN18RR#Hits@1#0.361$Knowledge Graph Completion#WN18RR#Hits@3#0.483$Knowledge Graph Completion#WN18RR#Hits@10#0.581$Knowledge Graph Completion#FB15k-237#Hits@3#54$Knowledge Graph Completion#FB15k-237#Hits@10#62.6$Knowledge Graph Completion#FB15k-237#Hits@1#46$Knowledge Graph Completion#FB15k-237#MRR#0.518$Knowledge Graph Completion#FB15k-237#MR#0.210
2109.08002v1.pdf	Link Prediction#WN18RR#MRR#0.502$Link Prediction#WN18RR#Hits@10#0.578$Link Prediction#WN18RR#Hits@1#0.459$Link Prediction#FB15k-237#MRR#0.389$Link Prediction#FB15k-237#Hits@10#0.537$Link Prediction#FB15k-237#Hits@1#0.298$Link Prediction#YAGO3-10#MRR#0.564$Link Prediction#YAGO3-10#Hits@10#0.693$Link Prediction#YAGO3-10#Hits@1#0.492
2209.15597v2.pdf	Link Prediction#WN18RR#MRR#0.499$Link Prediction#WN18RR#Hits@10#0.577$Link Prediction#WN18RR#Hits@3#0.518$Link Prediction#WN18RR#Hits@1#0.458$Link Prediction#FB15k-237#MRR#0.369$Link Prediction#FB15k-237#Hits@10#0.557$Link Prediction#FB15k-237#Hits@3#0.406$Link Prediction#FB15k-237#Hits@1#0.274$Link Prediction#YAGO3-10#MRR#0.585$Link Prediction#YAGO3-10#Hits@10#0.716$Link Prediction#YAGO3-10#Hits@1#0.514$Link Prediction#YAGO3-10#Hits@3#0.625
2110.14450v1.pdf	Link Prediction#WN18RR#MRR#0.457$Link Prediction#WN18RR#Hits@10#0.577$Link Prediction#WN18RR#Hits@3#0.482$Link Prediction#WN18RR#Hits@1#0.397$Link Prediction#FB15k-237#MRR#0.344$Link Prediction#FB15k-237#Hits@10#0.540$Link Prediction#FB15k-237#Hits@3#0.383$Link Prediction#FB15k-237#Hits@1#0.246$Link Prediction#YAGO3-10#MRR#0.542$Link Prediction#YAGO3-10#Hits@10#0.699$Link Prediction#YAGO3-10#Hits@1#0.443$Link Prediction#YAGO3-10#Hits@3#0.596$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.5740 ± 0.0008$Link Property Prediction#ogbl-wikikg2#Test MRR#0.5602 ± 0.0016$Link Property Prediction#ogbl-wikikg2#Number of params#1000669602$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-wikikg2#Validation MRR#0.4174 ± 0.0058$Link Property Prediction#ogbl-wikikg2#Test MRR#0.4277 ± 0.0008
2011.05816v2.pdf	Link Prediction#WN18RR#MRR#0.498$Link Prediction#WN18RR#Hits@10#0.577$Link Prediction#WN18RR#Hits@1#0.455$Link Prediction#WN18RR#MRR#0.478$Link Prediction#WN18RR#Hits@10#0.552$Link Prediction#WN18RR#Hits@1#0.441$Link Prediction#WN18RR#MRR#0.491$Link Prediction#WN18RR#Hits@1#0.449$Link Prediction#FB15k-237#MRR#0.371$Link Prediction#FB15k-237#Hits@10#0.560$Link Prediction#FB15k-237#Hits@1#0.276$Link Prediction#YAGO3-10#MRR#0.584$Link Prediction#YAGO3-10#Hits@10#0.713$Link Prediction#YAGO3-10#Hits@1#0.511$Link Prediction#YAGO3-10#MRR#0.579$Link Prediction#YAGO3-10#Hits@10#0.709$Link Prediction#YAGO3-10#Hits@1#0.506
2109.11800v3.pdf	Link Prediction#WN18RR#MRR#0.484$Link Prediction#WN18RR#Hits@10#0.572$Link Prediction#WN18RR#Hits@3#0.509$Link Prediction#WN18RR#Hits@1#0.446$Link Prediction#WN18RR#MR#3211$Link Prediction#FB15k-237#MRR#0.365$Link Prediction#FB15k-237#Hits@10#0.549$Link Prediction#FB15k-237#Hits@3#0.399$Link Prediction#FB15k-237#Hits@1#0.271$Link Prediction#FB15k-237#MR#157
2106.14233v2.pdf	Link Prediction#WN18RR#MRR#0.448$Link Prediction#WN18RR#Hits@10#0.57$Link Prediction#WN18RR#MR#683$Link Prediction#FB15k-237#MRR#0.302$Link Prediction#FB15k-237#Hits@10#0.489$Link Prediction#FB15k-237#MR#203$Link Prediction#FB15k-237#training time (s)#1100
1905.09791v3.pdf	Link Prediction#WN18RR#MRR#0.481$Link Prediction#WN18RR#Hits@10#0.566$Link Prediction#WN18RR#Hits@3#0.495$Link Prediction#WN18RR#Hits@1#0.440$Link Prediction#FB15k-237#MRR#0.336$Link Prediction#FB15k-237#Hits@10#0.521$Link Prediction#FB15k-237#Hits@3#0.370$Link Prediction#FB15k-237#Hits@1#0.245
1808.04122v3.pdf	Link Prediction#WN18RR#MRR#0.415$Link Prediction#WN18RR#Hits@10#0.56$Link Prediction#WN18RR#MR#719.0
2112.10644v2.pdf	Link Prediction#WN18RR#MRR#0.491$Link Prediction#WN18RR#Hits@10#0.558$Link Prediction#WN18RR#Hits@3#0.508$Link Prediction#WN18RR#Hits@1#0.454$Link Prediction#FB15k-237#MRR#0.36$Link Prediction#FB15k-237#Hits@10#0.545$Link Prediction#FB15k-237#Hits@3#0.396$Link Prediction#FB15k-237#Hits@1#0.268
2104.07824v1.pdf	Link Prediction#WN18RR#MRR#0.491$Link Prediction#WN18RR#Hits@10#0.557$Link Prediction#WN18RR#Hits@3#0.507$Link Prediction#WN18RR#Hits@1#0.455$Link Prediction#FB15k-237#MRR#0.366$Link Prediction#FB15k-237#Hits@10#0.547$Link Prediction#FB15k-237#Hits@3#0.404$Link Prediction#FB15k-237#Hits@1#0.272
1906.00687v1.pdf	Link Prediction#WN18RR#MRR#0.486$Link Prediction#WN18RR#Hits@10#0.557$Link Prediction#WN18RR#Hits@3#0.505$Link Prediction#WN18RR#Hits@1#0.452$Link Prediction#YAGO3-10#MRR#0.472$Link Prediction#YAGO3-10#Hits@10#0.643$Link Prediction#YAGO3-10#Hits@1#0.381$Link Prediction#YAGO3-10#Hits@3#0.523
2106.07250v4.pdf	Link Prediction#WN18RR#MRR#0.481$Link Prediction#WN18RR#Hits@10#0.553$Link Prediction#WN18RR#Hits@3#0.496$Link Prediction#WN18RR#Hits@1#0.444$Link Prediction#WN18RR#MRR#0.477$Link Prediction#WN18RR#Hits@10#0.546$Link Prediction#WN18RR#Hits@3#0.491$Link Prediction#WN18RR#Hits@1#0.441$Link Prediction#FB15k-237#MRR#0.364$Link Prediction#FB15k-237#Hits@10#0.55$Link Prediction#FB15k-237#Hits@3#0.402$Link Prediction#FB15k-237#Hits@1#0.269$Link Prediction#FB15k-237#MRR#0.363$Link Prediction#FB15k-237#Hits@10#0.548$Link Prediction#FB15k-237#Hits@3#0.4
1911.03082v2.pdf	Link Prediction#WN18RR#MRR#0.479$Link Prediction#WN18RR#Hits@10#0.546$Link Prediction#WN18RR#Hits@3#0.494$Link Prediction#WN18RR#Hits@1#0.443$Link Prediction#WN18RR#MR#3533$Link Prediction#FB15k-237#MRR#0.355$Link Prediction#FB15k-237#Hits@10#0.535$Link Prediction#FB15k-237#Hits@3#0.390$Link Prediction#FB15k-237#Hits@1#0.264$Link Prediction#FB15k-237#MR#197
1811.04441v2.pdf	Link Prediction#WN18RR#MRR#0.47$Link Prediction#WN18RR#Hits@10#0.54$Link Prediction#WN18RR#Hits@3#0.48$Link Prediction#WN18RR#Hits@1#0.43$Link Prediction#FB15k-237#MRR#0.35$Link Prediction#FB15k-237#Hits@10#0.54$Link Prediction#FB15k-237#Hits@3#0.39$Link Prediction#FB15k-237#Hits@1#0.26
2202.02113v6.pdf	Link Prediction#WN18RR#Hits@10#0.535$Link Prediction#WN18RR#Hits@3#0.403$Link Prediction#WN18RR#Hits@1#0.287$Link Prediction#FB15k-237#Hits@10#0.439$Link Prediction#FB15k-237#Hits@3#0.355$Link Prediction#FB15k-237#Hits@1#0.192
1911.00219v3.pdf	Link Prediction#WN18RR#MRR#0.463$Link Prediction#WN18RR#Hits@10#0.528$Link Prediction#WN18RR#Hits@1#0.430$Link Prediction#WN18RR#MR#5202$Link Prediction#FB15k-237#MRR#0.354$Link Prediction#FB15k-237#Hits@10#0.535$Link Prediction#FB15k-237#Hits@1#0.263$Link Prediction#FB15k-237#MR#172$Link Prediction#YAGO3-10#MRR#0.541$Link Prediction#YAGO3-10#Hits@10#0.687$Link Prediction#YAGO3-10#Hits@1#0.462
1712.02121v2.pdf	Link Prediction#WN18RR#MRR#0.248$Link Prediction#WN18RR#Hits@10#0.525$Link Prediction#WN18RR#MR#2554.0
1911.04053v2.pdf	Link Prediction#WN18RR#MRR#0.457$Link Prediction#WN18RR#Hits@10#0.515$Link Prediction#WN18RR#Hits@3#0.469$Link Prediction#WN18RR#Hits@1#0.427$Link Prediction#FB15k-237#MRR#0.354$Link Prediction#FB15k-237#Hits@10#0.536$Link Prediction#FB15k-237#Hits@3#0.388$Link Prediction#FB15k-237#Hits@1#0.261
1802.04394v5.pdf	Link Prediction#WN18RR#MRR#0.437$Link Prediction#WN18RR#Hits@3#0.445$Link Prediction#WN18RR#Hits@1#0.414
2201.05575v2.pdf	Link Prediction#FB15k-237-ind#Hits@3#0.32$Link Prediction#FB15k-237-ind#Hits@1#0.223$Link Prediction#FB15k-237-ind#Hits@10#0.431$Link Prediction#FB15k-237-ind#MRR#0.294$Link Prediction#FB15k-237#MRR#0.370$Link Prediction#FB15k-237#Hits@10#0.550$Link Prediction#FB15k-237#Hits@3#0.404$Link Prediction#FB15k-237#Hits@1#0.280$Link Prediction#FB15k-237#MR#185
1811.04588v1.pdf	Link Prediction#YAGO39K#Hits@1#0.298$Link Prediction#YAGO39K#Hits@10#0.698$Link Prediction#YAGO39K#Hits@3#0.502$Link Prediction#YAGO39K#MRR#0.42$Triple Classification#YAGO39K#Accuracy#93.8$Triple Classification#YAGO39K#F1-Score#93.7$Triple Classification#YAGO39K#Precision#94.8$Triple Classification#YAGO39K#Recall#92.7
1802.00543v2.pdf	Link Prediction#Decagon#AUROC#0.872$Link Prediction#Decagon#AUPRC#0.832$Link Prediction#Decagon#mAP@50#0.803
2001.10516v1.pdf	Link Prediction#Decagon#AUROC#0.914$Link Prediction#Decagon#AUPRC#0.890$Link Prediction#Decagon#mAP@50#0.890$Pose Prediction#SUN-Mem#AUPRC#89$Pose Prediction#SUN-Mem#AUROC#0.914$Pose Prediction#SUN-Mem#AP50#89
1908.11513v1.pdf	Link Prediction#NELL-995#MRR#0.253$Link Prediction#NELL-995#Hits@1#0.197$Link Prediction#NELL-995#Hits@10#0.347
1707.06690v3.pdf	Link Prediction#NELL-995#Mean AP#79.6
2206.08164v1.pdf	Link Prediction#PCQM-Contact#Hits@1#0.1355±0.0017$Link Prediction#PCQM-Contact#Hits@3#0.4004±0.0021$Link Prediction#PCQM-Contact#Hits@10#0.8478±0.0044$Link Prediction#PCQM-Contact#MRR#0.3350±0.0003$Link Prediction#PCQM-Contact#Hits@1#0.1337±0.0013$Link Prediction#PCQM-Contact#Hits@3#0.3642±0.0043$Link Prediction#PCQM-Contact#Hits@10#0.8147±0.0062$Link Prediction#PCQM-Contact#MRR#0.3180±0.0027$Link Prediction#PCQM-Contact#Hits@1#0.1321±0.0007$Link Prediction#PCQM-Contact#Hits@3#0.3791±0.0004$Link Prediction#PCQM-Contact#Hits@10#0.8256±0.0006$Link Prediction#PCQM-Contact#MRR#0.3234±0.0006$Link Prediction#PCQM-Contact#Hits@1#0.1312±0.0016$Link Prediction#PCQM-Contact#Hits@3#0.4030±0.0008$Link Prediction#PCQM-Contact#Hits@10#0.8550±0.0024$Link Prediction#PCQM-Contact#MRR#0.3341±0.0006$Link Prediction#PCQM-Contact#Hits@1#0.1288±0.0013$Link Prediction#PCQM-Contact#Hits@3#0.3808±0.0006$Link Prediction#PCQM-Contact#Hits@10#0.8517±0.0005$Link Prediction#PCQM-Contact#MRR#0.3242±0.0008$Link Prediction#PCQM-Contact#Hits@1#0.1279±0.0018$Link Prediction#PCQM-Contact#Hits@3#0.3783±0.0004$Link Prediction#PCQM-Contact#Hits@10#0.8433±0.0011$Link Prediction#PCQM-Contact#MRR#0.3218±0.0011$Link Prediction#PCQM-Contact#Hits@1#0.1221±0.0011$Link Prediction#PCQM-Contact#Hits@3#0.3679±0.0033$Link Prediction#PCQM-Contact#Hits@10#0.8517±0.0039$Link Prediction#PCQM-Contact#MRR#0.3174±0.0020$Graph Regression#Peptides-struct#MAE#0.2529±0.0016$Graph Regression#Peptides-struct#MAE#0.2545±0.0012$Graph Regression#Peptides-struct#MAE#0.2683±0.0043$Graph Regression#Peptides-struct#MAE#0.3357±0.0006$Graph Regression#Peptides-struct#MAE#0.3420±0.0013$Graph Regression#Peptides-struct#MAE#0.3496±0.0013$Graph Regression#Peptides-struct#MAE#0.3547±0.0045$Graph Classification#Peptides-func#AP#0.6439±0.0075$Graph Classification#Peptides-func#AP#0.6384±0.0121$Graph Classification#Peptides-func#AP#0.6326±0.0126$Graph Classification#Peptides-func#AP#0.6069±0.0035$Graph Classification#Peptides-func#AP#0.5930±0.0023$Graph Classification#Peptides-func#AP#0.5864±0.0077$Graph Classification#Peptides-func#AP#0.5498±0.0079$Node Classification#PascalVOC-SP#macro F1#0.3230±0.0039$Node Classification#PascalVOC-SP#macro F1#0.3216±0.0027$Node Classification#PascalVOC-SP#macro F1#0.2873±0.0219$Node Classification#PascalVOC-SP#macro F1#0.2860±0.0085$Node Classification#PascalVOC-SP#macro F1#0.2694±0.0098$Node Classification#PascalVOC-SP#macro F1#0.1268±0.0060$Node Classification#PascalVOC-SP#macro F1#0.1265±0.0076$Node Classification#COCO-SP#macro F1#0.2641±0.0045$Node Classification#COCO-SP#macro F1#0.2618±0.0031$Node Classification#COCO-SP#macro F1#0.2592±0.0158$Node Classification#COCO-SP#macro F1#0.2574±0.0034$Node Classification#COCO-SP#macro F1#0.2434±0.0156$Node Classification#COCO-SP#macro F1#0.1339±0.0044$Node Classification#COCO-SP#macro F1#0.0841±0.0010
2203.02424v2.pdf	Link Prediction#FB15k-237#MRR#0.238$Link Prediction#FB15k-237#Hits@10#0.412$Link Prediction#FB15k-237#Hits@3#0.256$Link Prediction#FB15k-237#Hits@1#0.157$Node Classification#DMG777K#Accuracy#63.97$Node Classification#DMG777K#Accuracy#62.51$Node Classification#AIFB#Accuracy#95.83$Node Classification#AIFB#Accuracy#86.11$Node Classification#DBLP#Accuracy#70.61$Node Classification#DBLP#Accuracy#68.51$Node Classification#AM#Accuracy#91.31$Node Classification#AM#Accuracy#84.8$Node Classification#AM#Accuracy#84.65$Node Classification#AMPLUS#Accuracy#84.54$Node Classification#AMPLUS#Accuracy#83.81$Node Classification#BGS#Accuracy#84.14$Node Classification#BGS#Accuracy#78.97$Node Classification#MDGENRE#Accuracy#67.33$Node Classification#MDGENRE#Accuracy#67.15$Node Classification#DMGFULL#Accuracy#63.38$Node Classification#DMGFULL#Accuracy#57.52$Node Classification#MUTAG#Accuracy#79.41
1911.03903v3.pdf	Link Prediction#FB15k-237#MRR#.309$Link Prediction#FB15k-237#Hits@10#.421$Link Prediction#FB15k-237#MR#309$Link Prediction#FB15k-237#MRR#.157$Link Prediction#FB15k-237#Hits@10#.331$Link Prediction#FB15k-237#MR#270$Link Prediction#FB15k-237#MRR#.032$Link Prediction#FB15k-237#Hits@10#.057$Link Prediction#FB15k-237#MR#446
1803.07828v2.pdf	Link Prediction#AKSW-bib#Hits@1#0.0384$Link Prediction#AKSW-bib#Hits@10#0.1923$Link Prediction#AKSW-bib#Hits@3#0.0979
2002.01680v2.pdf	Link Prediction#Last.FM#AP#98.93$Link Prediction#Last.FM#AUC#98.91
2203.01520v2.pdf	Inductive Link Prediction#ILPC22-Small#MRR#0.1326$Inductive Link Prediction#ILPC22-Small#Hits@100#0.4705$Inductive Link Prediction#ILPC22-Small#Hits@10#0.2509$Inductive Link Prediction#ILPC22-Small#Hits@5#0.1899$Inductive Link Prediction#ILPC22-Small#Hits@3#0.1396$Inductive Link Prediction#ILPC22-Small#Hits@1#0.0763$Inductive Link Prediction#ILPC22-Small#AMRI#0.730$Inductive Link Prediction#ILPC22-Small#MRR#0.0381$Inductive Link Prediction#ILPC22-Small#Hits@100#0.4678$Inductive Link Prediction#ILPC22-Small#Hits@10#0.0917$Inductive Link Prediction#ILPC22-Small#Hits@5#0.0500$Inductive Link Prediction#ILPC22-Small#Hits@3#0.0219$Inductive Link Prediction#ILPC22-Small#Hits@1#0.007$Inductive Link Prediction#ILPC22-Small#AMRI#0.666$Inductive Link Prediction#ILPC22-Large#MRR#0.0705$Inductive Link Prediction#ILPC22-Large#Hits@100#0.374$Inductive Link Prediction#ILPC22-Large#Hits@10#0.1458$Inductive Link Prediction#ILPC22-Large#Hits@5#0.099$Inductive Link Prediction#ILPC22-Large#Hits@3#0.073$Inductive Link Prediction#ILPC22-Large#Hits@1#0.0319$Inductive Link Prediction#ILPC22-Large#AMRI#0.682$Inductive Link Prediction#ILPC22-Large#MRR#0.0651$Inductive Link Prediction#ILPC22-Large#Hits@100#0.287$Inductive Link Prediction#ILPC22-Large#Hits@10#0.1246$Inductive Link Prediction#ILPC22-Large#Hits@5#0.0809$Inductive Link Prediction#ILPC22-Large#Hits@3#0.0542$Inductive Link Prediction#ILPC22-Large#Hits@1#0.0373$Inductive Link Prediction#ILPC22-Large#AMRI#0.646
1908.09710v3.pdf	Dynamic Link Prediction#DBLP Temporal#AUC#85.95$Dynamic Link Prediction#DBLP Temporal#AP#87.77$Dynamic Link Prediction#DBLP Temporal#AUC#85.45$Dynamic Link Prediction#DBLP Temporal#AP#88.36$Dynamic Link Prediction#Enron Email Dataset#AUC#94.44$Dynamic Link Prediction#Enron Email Dataset#AP#93.93$Dynamic Link Prediction#Enron Email Dataset#AUC#93.29$Dynamic Link Prediction#Enron Email Dataset#AP#93.10
1902.10191v3.pdf	Dynamic Link Prediction#DBLP Temporal#AUC#80.80$Dynamic Link Prediction#DBLP Temporal#AP#83.87$Dynamic Link Prediction#DBLP Temporal#AUC#78.63$Dynamic Link Prediction#DBLP Temporal#AP#81.43$Dynamic Link Prediction#Enron Email Dataset#AUC#89.33$Dynamic Link Prediction#Enron Email Dataset#AP#88.29$Dynamic Link Prediction#Enron Email Dataset#AUC#86.55$Dynamic Link Prediction#Enron Email Dataset#AP#84.28
1809.02657v2.pdf	Dynamic Link Prediction#DBLP Temporal#AUC#76.06$Dynamic Link Prediction#DBLP Temporal#AP#81.84$Dynamic Link Prediction#Enron Email Dataset#AUC#89.37$Dynamic Link Prediction#Enron Email Dataset#AP#87.43
2002.00743v2.pdf	Word Alignment#en-it#P@1#81.45$Word Alignment#MUSE en-de#P@1#74.08$Word Alignment#en-es#P@1#84.26$Word Alignment#es-en#P@1#83.5$Word Alignment#MUSE en-pt#P@1#84.65$Word Alignment#fr-en#P@1#83.23$Word Alignment#en-fr#P@1#82.94
1710.04087v3.pdf	Word Alignment#en-es#P@1#81.7$Word Alignment#es-en#P@1#83.3$Word Alignment#fr-en#P@1#82.1$Word Alignment#en-fr#P@1#82.3
2112.01905v1.pdf	Super-Resolution#CEST MRI#SSIM#0.85$Super-Resolution#CEST MRI#SSIM#0.83$Super-Resolution#CEST MRI#SSIM#0.73
2107.02630v1.pdf	Super-Resolution#Pavia Centre#Average PSNR#38.65$Super-Resolution#Botswana#Average PSNR#32.12$Image Super-Resolution#Chikusei Dataset#PSNR#43.53
2204.04218v3.pdf	Super-Resolution#IXI#PSNR 2x T2w#40.43$Super-Resolution#IXI#SSIM for 2x T2w#0.9877$Super-Resolution#IXI#SSIM 4x T2w#0.9469$Super-Resolution#IXI#PSNR 4x T2w#32.70
1810.06453v3.pdf	Super-Resolution#IXI#PSNR 2x T2w#39.71$Super-Resolution#IXI#SSIM for 2x T2w#0.9863$Super-Resolution#IXI#SSIM 4x T2w#0.9413$Super-Resolution#IXI#PSNR 4x T2w#32.05
1803.09454v1.pdf	Super-Resolution#IXI#PSNR 2x T2w#39.09$Super-Resolution#IXI#SSIM for 2x T2w#0.9846$Super-Resolution#IXI#SSIM 4x T2w#0.9312$Super-Resolution#IXI#PSNR 4x T2w#31.37$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.41$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7632$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.25$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7730$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.82$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8903$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.41$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7297
1802.08797v2.pdf	Super-Resolution#IXI#PSNR 2x T2w#38.75$Super-Resolution#IXI#SSIM for 2x T2w#0.9838$Super-Resolution#IXI#SSIM 4x T2w#0.9324$Super-Resolution#IXI#PSNR 4x T2w#31.45$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.00$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9151$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.61$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8028$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.81$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7871$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.47$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8990$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.72$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7419$Color Image Denoising#CBSD68 sigma50#PSNR#28.34
2001.01330v3.pdf	Super-Resolution#IXI#PSNR 2x T2w#38.67$Super-Resolution#IXI#SSIM for 2x T2w#0.9837$Super-Resolution#IXI#SSIM 4x T2w#0.9210$Super-Resolution#IXI#PSNR 4x T2w#30.57
1511.04587v2.pdf	Super-Resolution#IXI#PSNR 2x T2w#38.65$Super-Resolution#IXI#SSIM for 2x T2w#0.9836$Super-Resolution#IXI#SSIM 4x T2w#0.9240$Super-Resolution#IXI#PSNR 4x T2w#30.79$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.03$Image Super-Resolution#VggFace2 - 8x upscaling#PSNR#22.50$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#30.76$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.53$Image Super-Resolution#WebFace - 8x upscaling#PSNR#23.65$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#25.89$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.917$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#36.46
1501.00092v3.pdf	Super-Resolution#IXI#PSNR 2x T2w#37.32$Super-Resolution#IXI#SSIM for 2x T2w#0.9796$Super-Resolution#IXI#SSIM 4x T2w#0.9052$Super-Resolution#IXI#PSNR 4x T2w#29.69$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#147.21$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.900$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#23.12$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.688$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#27.58$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.8555$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#31.84$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.924$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#27.40$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.801$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#24.52$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7221$Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.50$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7513$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.49$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8628$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#26.90$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7101$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.68$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.929$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#51.21$Video Super-Resolution#Ultra Video Group HD - 4x upscaling#Average PSNR#37.52$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#24.68$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.7158$Video Super-Resolution#Vid4 - 4x upscaling#MOVIE#6.90$Video Super-Resolution#Xiph HD - 4x upscaling#Average PSNR#31.47
2106.06742v3.pdf	Super-Resolution#IXI#PSNR 2x T2w#29.38$Super-Resolution#IXI#SSIM for 2x T2w#0.8720$Super-Resolution#IXI#SSIM 4x T2w#0.8500$Super-Resolution#IXI#PSNR 4x T2w#28.66
2205.04437v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.74$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.9066$Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.69$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.9060$Image Super-Resolution#Set14 - 2x upscaling#PSNR#35.29$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9293$Image Super-Resolution#Set14 - 2x upscaling#PSNR#35.13$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9282$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#33.09$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9335$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#32.87$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9319$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#36.02$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9576$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#35.84$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9567$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.63$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.8191$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.59$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.8177$Image Super-Resolution#Set14 - 3x upscaling#PSNR#31.47$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8584$Image Super-Resolution#Set14 - 3x upscaling#PSNR#31.33$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8576$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#30.92$Image Super-Resolution#Urban100 - 3x upscaling#SSIM#0.8981$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#30.70$Image Super-Resolution#Urban100 - 3x upscaling#SSIM#0.8949$Image Super-Resolution#Set5 - 3x upscaling#PSNR#35.28$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9345$Image Super-Resolution#Set5 - 3x upscaling#PSNR#35.16$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9335$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#35.09$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9505$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#34.81$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9489$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#41.01$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9831$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#40.71$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9819$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#28.60$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8498$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#28.37$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8447$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.47$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.8015$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.38$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.8001$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.91$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9646$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.73$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9637$Image Super-Resolution#Set5 - 4x upscaling#PSNR#33.30$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9083$Image Super-Resolution#Set5 - 4x upscaling#PSNR#33.18$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9073$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#28.09$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7551$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#28.05$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7534
2208.11247v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.64$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.9054$Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.93$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9276$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#32.83$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9314$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#35.77$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9563$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.55$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.8169$Image Super-Resolution#Set14 - 3x upscaling#PSNR#31.24$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8566$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#30.43$Image Super-Resolution#Urban100 - 3x upscaling#SSIM#0.8913$Image Super-Resolution#Set5 - 3x upscaling#PSNR#35.15$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.933$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#34.57$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9473$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#40.61$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9816$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#28.12$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8393$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.36$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7993$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.65$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9633$Image Super-Resolution#Set5 - 4x upscaling#PSNR#33.2$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9068$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#28.03$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.752$Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#26.92$Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#SSIM#0.8148$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.74$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#SSIM#0.8206$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#24.14$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#SSIM#0.7560$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#30.14$Stereo Image Super-Resolution#Middlebury - 4x upscaling#SSIM#0.8582$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#31.48$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#SSIM#0.9281$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#35.84$Stereo Image Super-Resolution#Middlebury - 2x upscaling#SSIM#0.9543$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#29.62$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#SSIM#0.9199$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#31.23$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#SSIM#0.9382
2012.00364v4.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.48$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.85$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#29.49$Single Image Deraining#Rain100L#PSNR#41.62$Single Image Deraining#Rain100L#SSIM#0.988$Color Image Denoising#CBSD68 sigma50#PSNR#29.39$Color Image Denoising#McMaster sigma50#PSNR#29.98$Color Image Denoising#Urban100 sigma50#PSNR#29.71
1906.12021v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.47$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.9032$Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.43$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9247$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.78$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9211$Image Super-Resolution#Manga109 - 8x upscaling#PSNR#25.55$Image Super-Resolution#Manga109 - 8x upscaling#SSIM#0.8087$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#34.94$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9518$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.4$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.8125$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.8$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8498$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#29.37$Image Super-Resolution#Urban100 - 3x upscaling#SSIM#0.8746$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.86$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9307$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#33.54$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9402$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.75$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9792$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.14$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8149$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.02$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7914$Image Super-Resolution#Set14 - 8x upscaling#PSNR#25.4$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.6547$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.34$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9619$Image Super-Resolution#Set5 - 8x upscaling#PSNR#27.46$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.7916$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#25.06$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.607$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.74$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9013$Image Super-Resolution#Urban100 - 8x upscaling#PSNR#23.24$Image Super-Resolution#Urban100 - 8x upscaling#SSIM#0.6523$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.87$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7453
2008.08767v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.45$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.8431$Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.24$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9224$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.73$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9207$Image Super-Resolution#Manga109 - 8x upscaling#PSNR#25.54$Image Super-Resolution#Manga109 - 8x upscaling#SSIM#0.8080$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#34.87$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9509$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.41$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.8116$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.79$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8487$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#29.21$Image Super-Resolution#Urban100 - 3x upscaling#SSIM#0.8710$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.85$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9300$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#33.53$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9398$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.62$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9787$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.02$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8131$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.99$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7907$Image Super-Resolution#Set14 - 8x upscaling#PSNR#25.39$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.6552$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.33$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9299$Image Super-Resolution#Set5 - 8x upscaling#PSNR#27.47$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.7920$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#25.04$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.6075$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.75$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9016$Image Super-Resolution#Urban100 - 8x upscaling#PSNR#23.20$Image Super-Resolution#Urban100 - 8x upscaling#SSIM#0.6518$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.85$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7454
2111.08918v6.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.44$Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.25$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.39$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.8$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#29.41$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.89$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#33.5$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.24$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.06$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.33$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.81$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.86
2006.01424v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.4$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.9024$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9223$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.43$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9201$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#33.25$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9386$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.37$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9785$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.22$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8168$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.95$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7888$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.28$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9616$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.68$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9004$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.8$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7439
1906.06874v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.33$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.902$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.78$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.921$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.57$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.92$Image Super-Resolution#Manga109 - 8x upscaling#PSNR#25.24$Image Super-Resolution#Manga109 - 8x upscaling#SSIM#0.802$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#33.12$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.938$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.3$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.979$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.3$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.818$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.67$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.785$Image Super-Resolution#Set14 - 8x upscaling#PSNR#24.96$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.642$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.13$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.961$Image Super-Resolution#Set5 - 8x upscaling#PSNR#27.17$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.785$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#24.93$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.602$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.55$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9$Image Super-Resolution#Urban100 - 8x upscaling#PSNR#23.04$Image Super-Resolution#Urban100 - 8x upscaling#SSIM#0.647$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.77$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.743
1903.09814v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.29$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#132.59$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.895$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#21.96$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.693$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.82$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.15$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9160$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#29.577$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.827$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.953$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.066$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.0984$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#20.032$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.2406$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#13.901$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#34.18$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.24$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.1$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#17.14$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.931$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#27.90$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.822$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#28.73$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.70$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.62$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.08$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.6$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8015$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.81$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7868$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.11$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.47$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8983$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.72$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7409
1805.07071v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.23$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.7$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.12$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.16$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#28.13$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.17$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.3$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.27$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7890$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.41$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7816$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.91$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.12$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8941$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.62$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7355$JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#PSNR#34.27$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#32.04$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.83$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8989$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.80$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.78$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.877$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR#34.11$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR-B#34.69$JPEG Artifact Correction#ICB (Quality 30 Color)#SSIM#0.845$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.69$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.39$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8357$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR#34.12$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR-B#34.06$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#SSIM#0.884$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#PSNR#34.45$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#32.79$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#33.32$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.812$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#30.76$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#31.21$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.779$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR#36.56$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR-B#36.44$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#SSIM#0.902$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR#33.45$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR#33.43$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR#32.16$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#30.01$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.45$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.44$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.808$Grayscale Image Denoising#Set12 sigma15#PSNR#33.15$Grayscale Image Denoising#Urban100 sigma25#PSNR#30.66$Grayscale Image Denoising#Set12 sigma50#PSNR#27.74$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.53$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.41$Grayscale Image Denoising#Set12 sigma25#PSNR#30.79$Grayscale Image Denoising#Urban100 sigma15#PSNR#33.17$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.86$Grayscale Image Denoising#Urban100 sigma50#PSNR#27.42
1909.11856v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.19$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.63$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#30.45$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#33.61$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#29.09$Image Super-Resolution#Set14 - 3x upscaling#PSNR#30.32$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#28.17$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.36$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.17$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#38.88$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.04$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.58$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.00$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.21$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.56
1901.07261v3.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.12$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.55$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#31.93$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.82
1803.08664v5.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#32.09$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.52$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.26$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.07$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7837$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.60$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7806$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.76$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.13$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8937$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.58$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7349
1606.08921v3.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.99$Image Super-Resolution#BSD100 - 2x upscaling#SSIM#0.8974$Image Super-Resolution#Set14 - 2x upscaling#PSNR#32.94$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9144$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#28.93$Image Super-Resolution#BSD100 - 3x upscaling#SSIM#0.7994$Image Super-Resolution#Set14 - 3x upscaling#PSNR#29.61$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8341$Image Super-Resolution#Set5 - 3x upscaling#PSNR#33.82$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.923$Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.86$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7718$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.66$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9599$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.51$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8869$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.4$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.729$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.73$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.35$Grayscale Image Denoising#BSD200 sigma10#PSNR#33.63$Grayscale Image Denoising#BSD200 sigma10#SSIM#0.9319$Grayscale Image Denoising#BSD200 sigma30#PSNR#27.95$Grayscale Image Denoising#BSD200 sigma30#SSIM#0.8019$Grayscale Image Denoising#BSD200 sigma70#PSNR#24.37$Grayscale Image Denoising#BSD200 sigma70#SSIM#0.6551$Grayscale Image Denoising#BSD200 sigma50#PSNR#25.75$Grayscale Image Denoising#BSD200 sigma50#SSIM#0.7167
1902.05694v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.96$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#29.76$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.8979$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#32.8$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9381$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#28.91$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.04$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9233$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#37.93$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9746$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.66$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9585$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.79$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8886$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.42
1608.03981v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.9$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.03$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#28.85$Image Super-Resolution#Set14 - 3x upscaling#PSNR#29.81$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#27.15$Image Super-Resolution#Set5 - 3x upscaling#PSNR#33.75$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#30.74$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.2$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7521$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.04$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7672$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.58$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.4$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8845$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.29$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7253$JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#PSNR#33.77$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.59$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.19$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#PSNR#33.96$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR#32.98$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR#32.91$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR#31.63$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#29.4$Denoising#Darmstadt Noise Dataset#PSNR#32.43$Color Image Denoising#CBSD68 sigma35#PSNR#28.74$Color Image Denoising#BSD68 sigma25#PSNR#29.02$Color Image Denoising#BSD68 sigma15#PSNR#31.46$Grayscale Image Denoising#Urban100 sigma25#PSNR#29.97$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.23$Grayscale Image Denoising#Urban100 sigma15#PSNR#32.67
1910.08853v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.86$Image Super-Resolution#BSD100 - 3x upscaling#PSNR#28.76$Image Super-Resolution#Set5 - 3x upscaling#PSNR#33.43$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.42$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.01$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.21$Grayscale Image Denoising#BSD200 sigma10#PSNR#36.36$Grayscale Image Denoising#BSD200 sigma30#PSNR#33.57$Grayscale Image Denoising#BSD200 sigma70#PSNR#31.17$Grayscale Image Denoising#BSD200 sigma50#PSNR#32.48
1511.04491v2.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.85$Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.04$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#30.75$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.02$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.8074$Image Super-Resolution#Set14 - 4x upscaling#MOS#2.84$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.63$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.52$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8938$Image Super-Resolution#Set5 - 4x upscaling#MOS#3.26$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.21$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7493$Image Super-Resolution#BSD100 - 4x upscaling#MOS#2.12
1608.00367v1.pdf	Image Super-Resolution#BSD100 - 2x upscaling#PSNR#31.53$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#139.78$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.930$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#22.45$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.709$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#23.97$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.951$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#24.71$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.804
2005.05005v2.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#5.36$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.971$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#28.65$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.816$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#30.824$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.838$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.971$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.071$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.0716$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#1.898$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.0723$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#6.961$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#1.978$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.975$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#33.04$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.875$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#FID#11.389$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#LPIPS#0.2449$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#NIQE#6.767$Blind Face Restoration#CelebA-Test#LPIPS#47.7$Blind Face Restoration#CelebA-Test#FID#66.09$Blind Face Restoration#CelebA-Test#NIQE#4.916$Blind Face Restoration#CelebA-Test#Deg.#42.18$Blind Face Restoration#CelebA-Test#PSNR#24.92$Blind Face Restoration#CelebA-Test#SSIM#0.6195
1910.08761v1.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#74.43$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.958$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#27.42$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.816$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#12.4$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.971$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#34.1$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.906
1612.07919v2.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#116.38$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.897$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#23.64$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.701$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#19.07$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.934$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#29.42$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.832$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.66$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7703$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.42$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7774$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.74$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8869$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.50$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7326
1707.02921v1.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#129.14$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.901$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#22.47$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.706$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.02$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9148$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#30.188$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.824$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.961$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.003$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.0843$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#20.605$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.2475$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#13.636$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#15.54$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.933$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#28.34$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.827$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.64$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8033$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.80$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7876$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.46$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8968$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.71$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7420
1609.04802v5.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#156.07$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.757$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#17.57$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.415$Image Super-Resolution#PIRM-test#NIQE#2.71$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#27.494$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.735$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.935$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.269$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.1097$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#4.396$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.1313$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#7.378$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#60.67$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.807$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#21.49$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.515$Image Super-Resolution#VggFace2 - 8x upscaling#PSNR#23.01$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.49$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.8184$Image Super-Resolution#Set14 - 4x upscaling#MOS#2.98$Image Super-Resolution#Set14 - 4x upscaling#PSNR#26.02$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7397$Image Super-Resolution#Set14 - 4x upscaling#MOS#3.72$Image Super-Resolution#Set14 - 4x upscaling#PSNR#25.99$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7486$Image Super-Resolution#Set14 - 4x upscaling#MOS#1.80$Image Super-Resolution#Set14 - 4x upscaling#PSNR#24.64$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7100$Image Super-Resolution#Set14 - 4x upscaling#MOS#1.20$Image Super-Resolution#WebFace - 8x upscaling#PSNR#24.49$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.05$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9019$Image Super-Resolution#Set5 - 4x upscaling#MOS#3.37$Image Super-Resolution#Set5 - 4x upscaling#PSNR#29.40$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8472$Image Super-Resolution#Set5 - 4x upscaling#MOS#3.58$Image Super-Resolution#Set5 - 4x upscaling#PSNR#28.43$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8211$Image Super-Resolution#Set5 - 4x upscaling#MOS#1.97$Image Super-Resolution#Set5 - 4x upscaling#PSNR#26.26$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.7552$Image Super-Resolution#Set5 - 4x upscaling#MOS#1.28$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.58$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7620$Image Super-Resolution#BSD100 - 4x upscaling#MOS#2.29$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#25.94$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6935$Image Super-Resolution#BSD100 - 4x upscaling#MOS#1.47$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#25.16$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6688$Image Super-Resolution#BSD100 - 4x upscaling#MOS#3.56$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#25.02$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6606$Image Super-Resolution#BSD100 - 4x upscaling#MOS#1.11
1809.00219v2.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#FID#166.36$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#MS-SSIM#0.747$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#15.43$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.267$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.66$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9196$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#24.89$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.7866$Image Super-Resolution#PIRM-test#NIQE#2.55$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#27.134$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.741$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.935$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.261$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.1107$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#3.503$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.1221$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#6.984$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#FID#72.73$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#MS-SSIM#0.782$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#PSNR#19.84$Image Super-Resolution#FFHQ 1024 x 1024 - 4x upscaling#SSIM#0.353$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.03$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8153$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#23.14$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.6577$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.99$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7917$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.73$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9011$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.85$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7455$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#27.29$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.936$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#56.69$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.353$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.735$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.808$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#27.33$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.004$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.948$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#FID#50.901$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#LPIPS#0.3928$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#NIQE#15.383
2012.04567v5.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#24.16$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.70$Image Inpainting#FFHQ 1024 x 1024#LPIPS#0.19$Image Inpainting#FFHQ 1024 x 1024#RMSE#24.28$Image Inpainting#FFHQ 1024 x 1024#PSNR#21.33$Image Inpainting#FFHQ 1024 x 1024#SSIM#0.84$Image Inpainting#FFHQ 1024 x 1024#LPIPS#0.24$Image Inpainting#FFHQ 1024 x 1024#RMSE#30.75$Image Inpainting#FFHQ 1024 x 1024#PSNR#19.67$Image Inpainting#FFHQ 1024 x 1024#SSIM#0.82$Image Denoising#FFHQ 64x64 - 4x upscaling#LPIPS#0.24$Image Denoising#FFHQ#LPIPS#0.24
2003.03808v3.pdf	Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#PSNR#15.74$Image Super-Resolution#FFHQ 256 x 256 - 4x upscaling#SSIM#0.37
1903.05784v3.pdf	Image Super-Resolution#KITTI 2012 - 4x upscaling#PSNR#26.26$Image Super-Resolution#KITTI 2015 - 4x upscaling#PSNR#25.43$Image Super-Resolution#KITTI 2012 - 2x upscaling#PSNR#30.65$Image Super-Resolution#Middlebury - 2x upscaling#PSNR#34.05$Image Super-Resolution#Middlebury - 4x upscaling#PSNR#28.63$Image Super-Resolution#KITTI 2015 - 2x upscaling#PSNR#29.78$Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#26.34$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.08$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#23.31$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#28.72$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#34.23$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#28.38$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#30.60$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#30.81
1907.12904v2.pdf	Image Super-Resolution#Set14 - 2x upscaling#PSNR#35.61$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9404$Image Super-Resolution#DIV2K val - 4x upscaling#PSNR#32.82$Image Super-Resolution#DIV2K val - 4x upscaling#SSIM#0.8837$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#35.24$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9572$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.94$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9658$Image Super-Resolution#DIV2K val - 2x upscaling#PSNR#38.26$Image Super-Resolution#DIV2K val - 2x upscaling#SSIM#0.9599$Image Super-Resolution#Set5 - 4x upscaling#PSNR#0.3388$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9174$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#29.15$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.8001
2008.10329v2.pdf	Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.34$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9240$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.47$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7720$Image Super-Resolution#Set14 - 8x upscaling#PSNR#24.30$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.614$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.45$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9570$Image Super-Resolution#Set5 - 8x upscaling#PSNR#25.74$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.715$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.01$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8702$Image Super-Resolution#BSD200 - 2x upscaling#PSNR#32.92$Image Super-Resolution#BSD200 - 2x upscaling#SSIM#0.9122
1904.05677v2.pdf	Image Super-Resolution#Set14 - 2x upscaling#PSNR#34.09$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.921$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.74$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.921$Image Super-Resolution#BSDS100 - 2x upscaling#PSNR#32.31$Image Super-Resolution#BSDS100 - 2x upscaling#SSIM#0.901$Image Super-Resolution#BSDS100 - 8x upscaling#PSNR#25.05$Image Super-Resolution#BSDS100 - 8x upscaling#SSIM#0.607$Image Super-Resolution#BSDS100 - 4x upscaling#PSNR#27.82$Image Super-Resolution#BSDS100 - 4x upscaling#SSIM#0.744$Image Super-Resolution#Manga109 - 8x upscaling#PSNR#25.71$Image Super-Resolution#Manga109 - 8x upscaling#SSIM#0.813$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.92$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.935$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.28$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.977$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.08$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.814$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.03$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.791$Image Super-Resolution#Set14 - 8x upscaling#PSNR#25.41$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.657$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.08$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.96$Image Super-Resolution#Set5 - 8x upscaling#PSNR#27.51$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.793$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.65$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.899$Image Super-Resolution#Urban100 - 8x upscaling#PSNR#23.2$Image Super-Resolution#Urban100 - 8x upscaling#SSIM#0.652
2008.01116v1.pdf	Image Super-Resolution#Set14 - 2x upscaling#PSNR#33.62$Image Super-Resolution#Set14 - 2x upscaling#SSIM#0.9178$Image Super-Resolution#BSDS100 - 2x upscaling#PSNR#32.21$Image Super-Resolution#BSDS100 - 2x upscaling#SSIM#0.9001$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.07$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9277$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.05$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9606
1704.03264v1.pdf	Image Super-Resolution#Set14 - 2x upscaling#PSNR#30.79$Image Super-Resolution#Set14 - 3x upscaling#PSNR#27.72$Image Super-Resolution#Set5 - 3x upscaling#PSNR#31.26$Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.59$Image Super-Resolution#Set5 - 2x upscaling#PSNR#35.05$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.92$Color Image Denoising#BSD68 sigma25#PSNR#31.16$Color Image Denoising#CBSD68 sigma50#PSNR#27.86$Color Image Denoising#BSD68 sigma35#PSNR#29.5$Color Image Denoising#BSD68 sigma5#PSNR#40.36$Color Image Denoising#BSD68 sigma15#PSNR#33.86$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.19$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.15$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.63
2108.10257v1.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#32.22$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9273$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.45$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8254$Image Super-Resolution#Set14 - 4x upscaling#PSNR#29.15$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7958$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.93$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9043$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#28.86$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.183$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.830$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#28.55$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.189$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.845$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#4.799$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.618$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.782$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#25.12$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.407$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.895$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#0.76$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.304$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.642$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.268$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.736$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#0.559$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.575$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.346$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.304$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#8.13$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.641$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.474$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.803$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.639$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.848$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.411$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.671$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#10.854$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.835$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#3.32$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#7.105$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.566$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.624$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.35$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.887$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#8.971$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#5.758$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.552$Color Image Denoising#Urban100 sigma25#PSNR#32.9$Color Image Denoising#Kodak24 sigma50#PSNR#29.79$Color Image Denoising#Urban100 sigma10#PSNR#35.13$Color Image Denoising#Urban100 sigma50#PSNR#29.82$Grayscale Image Denoising#Urban100 sigma25#PSNR#31.3$Grayscale Image Denoising#Urban100 sigma15#PSNR#33.70$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.97$Grayscale Image Denoising#Urban100 sigma50#PSNR#27.98
1907.10399v2.pdf	Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9211$Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.59$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.01$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8169$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.95$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7946$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.71$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9022$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.83$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7515
1910.04476v1.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.79$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.921$Image Super-Resolution#DIV8K val - 16x upscaling#PSNR#26.71$Image Super-Resolution#DIV8K val - 16x upscaling#SSIM#0.65$Image Super-Resolution#Manga109 - 8x upscaling#PSNR#25.29$Image Super-Resolution#Manga109 - 8x upscaling#SSIM#0.802$Image Super-Resolution#Manga109 - 16x upscaling#PSNR#21.25$Image Super-Resolution#Manga109 - 16x upscaling#SSIM#0.673$Image Super-Resolution#DIV2K val - 16x upscaling#PSNR#24.38$Image Super-Resolution#DIV2K val - 16x upscaling#SSIM#0.641$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#27.06$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.811$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.94$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.789$Image Super-Resolution#Set14 - 8x upscaling#PSNR#25.08$Image Super-Resolution#Set14 - 8x upscaling#SSIM#0.638$Image Super-Resolution#Set5 - 8x upscaling#PSNR#27.25$Image Super-Resolution#Set5 - 8x upscaling#SSIM#0.786$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#24.99$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.604$Image Super-Resolution#Urban100 - 16x upscaling#PSNR#20.39$Image Super-Resolution#Urban100 - 16x upscaling#SSIM#0.515$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.69$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9$Image Super-Resolution#Urban100 - 8x upscaling#PSNR#23.04$Image Super-Resolution#Urban100 - 8x upscaling#SSIM#0.641$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.82$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.743$Image Super-Resolution#BSD100 - 16x upscaling#PSNR#22.72$Image Super-Resolution#BSD100 - 16x upscaling#SSIM#0.512
1907.04253v2.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.24$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9174$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.69$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8048$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.84$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7888$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.55$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8991$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.74$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7421
1807.02758v2.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.22$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9173$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.82$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.8087$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.87$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7889$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.63$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9002$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.77$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7436
2007.09552v3.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#31.07$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.9144$Image Super-Resolution#Manga109 - 3x upscaling#PSNR#34.1$Image Super-Resolution#Manga109 - 3x upscaling#SSIM#0.9480$Image Super-Resolution#Set14 - 3x upscaling#PSNR#29.24$Image Super-Resolution#Set14 - 3x upscaling#SSIM#0.8087$Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.65$Image Super-Resolution#Set5 - 3x upscaling#SSIM#0.9289$Image Super-Resolution#Urban100 - 2x upscaling#PSNR#32.78$Image Super-Resolution#Urban100 - 2x upscaling#SSIM#0.9342$Image Super-Resolution#Manga109 - 2x upscaling#PSNR#39.15$Image Super-Resolution#Manga109 - 2x upscaling#SSIM#0.9781$Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.72$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7405$Image Super-Resolution#Set5 - 2x upscaling#PSNR#38.22$Image Super-Resolution#Set5 - 2x upscaling#SSIM#0.9612$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.47$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8984
1803.02735v1.pdf	Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.914$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.795$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.82$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.786$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.47$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.898$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.72$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.740$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.37$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.737
1708.02209v1.pdf	Image Super-Resolution#Manga109 - 4x upscaling#PSNR#29.42$Image Super-Resolution#Manga109 - 4x upscaling#SSIM#0.8942$Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.50$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7630$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.26$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7723$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.74$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8893$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.40$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7281$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.83$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.74$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8970$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.76$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.75$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.877$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.45$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.39$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8327$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#29.69$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.33$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.34$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.810$Color Image Denoising#CBSD68 sigma50#PSNR#26.33
2106.10437v4.pdf	Image Super-Resolution#DIV8K val - 16x upscaling#LPIPS#0.321$Image Super-Resolution#Urban100 - 4x upscaling#LPIPS#0.1007$Image Super-Resolution#Set14 - 4x upscaling#LPIPS#0.1104$Image Super-Resolution#Set5 - 4x upscaling#LPIPS#0.04998$Image Super-Resolution#BSD100 - 4x upscaling#LPIPS#0.1209
2005.12597v1.pdf	Image Super-Resolution#DIV8K val - 16x upscaling#PSNR#24.03$Image Super-Resolution#DIV8K val - 16x upscaling#LPIPS#0.345$Image Super-Resolution#DIV8K test - 16x upscaling#PSNR#23.38$Image Super-Resolution#DIV8K test - 16x upscaling#LPIPS#0.348
1908.06382v2.pdf	Image Super-Resolution#PIRM-test#NIQE#2.51
2007.03107v2.pdf	Image Super-Resolution#EPFL NIR-VIS#Average#98.75$Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.9336790819983855$Video Super-Resolution#Ultra Video Group HD - 4x upscaling#Average PSNR#99.13$Video Super-Resolution#Ultra Video Group HD - 4x upscaling#Average PSNR#98.58
1712.02765v2.pdf	Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#PSNR#25.463$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#SSIM#0.729$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#MS-SSIM#0.913$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LLE#2.333$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FED#0.1416$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#FID#14.811$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#LPIPS#0.2357$Image Super-Resolution#FFHQ 512 x 512 - 4x upscaling#NIQE#8.719$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#FID#63.693$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#LPIPS#0.4411$Face Hallucination#FFHQ 512 x 512 - 16x upscaling#NIQE#7.444
2201.04898v3.pdf	Image Super-Resolution#General100 - 8x upscaling#PSNR#24$Image Super-Resolution#General100 - 8x upscaling#SSIM#0.6534$Image Super-Resolution#General100 - 8x upscaling#LRPSNR#41.36$Image Super-Resolution#General100 - 8x upscaling#LPIPS#0.2058$Image Super-Resolution#General100 - 8x upscaling#DISTS#0.1716$Image Super-Resolution#General100 - 8x upscaling#NIQE#5.46$Image Super-Resolution#General100 - 8x upscaling#PSNR#25.42$Image Super-Resolution#General100 - 8x upscaling#SSIM#0.7097$Image Super-Resolution#General100 - 8x upscaling#LRPSNR#44.28$Image Super-Resolution#General100 - 8x upscaling#LPIPS#0.2924$Image Super-Resolution#General100 - 8x upscaling#DISTS#0.2134$Image Super-Resolution#General100 - 8x upscaling#NIQE#6.09$Image Super-Resolution#DIV2K val - 8x upscaling#PSNR#23.56$Image Super-Resolution#DIV2K val - 8x upscaling#SSIM#0.6241$Image Super-Resolution#DIV2K val - 8x upscaling#LRPSNR#42.66$Image Super-Resolution#DIV2K val - 8x upscaling#LPIPS#0.2403$Image Super-Resolution#DIV2K val - 8x upscaling#NIQE#3.61$Image Super-Resolution#DIV2K val - 8x upscaling#DISTS#0.119$Image Super-Resolution#DIV2K val - 8x upscaling#PSNR#25.6$Image Super-Resolution#DIV2K val - 8x upscaling#SSIM#0.6989$Image Super-Resolution#DIV2K val - 8x upscaling#LRPSNR#46.96$Image Super-Resolution#DIV2K val - 8x upscaling#LPIPS#0.3857$Image Super-Resolution#DIV2K val - 8x upscaling#NIQE#4.41$Image Super-Resolution#DIV2K val - 8x upscaling#DISTS#0.1953$Image Super-Resolution#DIV2K val - 4x upscaling#PSNR#27.51$Image Super-Resolution#DIV2K val - 4x upscaling#SSIM#0.789$Image Super-Resolution#DIV2K val - 4x upscaling#LPIPS#0.1028$Image Super-Resolution#DIV2K val - 4x upscaling#LRPSNR#50.54$Image Super-Resolution#DIV2K val - 4x upscaling#NIQE#2.81$Image Super-Resolution#DIV2K val - 4x upscaling#DISTS#0.0513$Image Super-Resolution#DIV2K val - 4x upscaling#PSNR#29.24$Image Super-Resolution#DIV2K val - 4x upscaling#SSIM#0.8383$Image Super-Resolution#DIV2K val - 4x upscaling#LPIPS#0.239$Image Super-Resolution#DIV2K val - 4x upscaling#LRPSNR#53.3$Image Super-Resolution#DIV2K val - 4x upscaling#NIQE#4.11$Image Super-Resolution#DIV2K val - 4x upscaling#DISTS#0.1169$Image Super-Resolution#General100 - 4x upscaling#PSNR#28.44$Image Super-Resolution#General100 - 4x upscaling#SSIM#0.8229$Image Super-Resolution#General100 - 4x upscaling#LRPSNR#49.82$Image Super-Resolution#General100 - 4x upscaling#LPIPS#0.0784$Image Super-Resolution#General100 - 4x upscaling#NIQE#4.54$Image Super-Resolution#General100 - 4x upscaling#DISTS#0.0831$Image Super-Resolution#General100 - 4x upscaling#PSNR#29.94$Image Super-Resolution#General100 - 4x upscaling#SSIM#0.8629$Image Super-Resolution#General100 - 4x upscaling#LRPSNR#52.22$Image Super-Resolution#General100 - 4x upscaling#LPIPS#0.1519$Image Super-Resolution#General100 - 4x upscaling#NIQE#6.05$Image Super-Resolution#General100 - 4x upscaling#DISTS#0.1205$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#23.6$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.5728$Image Super-Resolution#BSD100 - 8x upscaling#LRPSNR#47.12$Image Super-Resolution#BSD100 - 8x upscaling#NIQE#5.49$Image Super-Resolution#BSD100 - 8x upscaling#LPIPS#0.5079$Image Super-Resolution#BSD100 - 8x upscaling#DISTS#0.2753$Image Super-Resolution#BSD100 - 8x upscaling#PSNR#21.93$Image Super-Resolution#BSD100 - 8x upscaling#SSIM#0.5039$Image Super-Resolution#BSD100 - 8x upscaling#LRPSNR#42.41$Image Super-Resolution#BSD100 - 8x upscaling#NIQE#4.58$Image Super-Resolution#BSD100 - 8x upscaling#LPIPS#0.3129$Image Super-Resolution#BSD100 - 8x upscaling#DISTS#0.1972$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#26.38$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.738$Image Super-Resolution#BSD100 - 4x upscaling#LPIPS#0.3433$Image Super-Resolution#BSD100 - 4x upscaling#LRPSNR#52.48$Image Super-Resolution#BSD100 - 4x upscaling#NIQE#5.1$Image Super-Resolution#BSD100 - 4x upscaling#DISTS#0.1921$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#24.77$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6817$Image Super-Resolution#BSD100 - 4x upscaling#LPIPS#0.1572$Image Super-Resolution#BSD100 - 4x upscaling#LRPSNR#49.24$Image Super-Resolution#BSD100 - 4x upscaling#NIQE#3.3$Image Super-Resolution#BSD100 - 4x upscaling#DISTS#0.116
2110.05031v2.pdf	Image Super-Resolution#WLFW#Loss#99.53
1909.03573v1.pdf	Image Super-Resolution#BSD100 - 3x upscaling#PSNR#28.87$Image Super-Resolution#Set14 - 3x upscaling#PSNR#29.87$Image Super-Resolution#Urban100 - 3x upscaling#PSNR#27.24$Image Super-Resolution#Set5 - 3x upscaling#PSNR#33.99
1909.05305v1.pdf	Image Super-Resolution#Celeb-HQ 4x upscaling#PSNR#28.23$Image Super-Resolution#Celeb-HQ 4x upscaling#SSIM#0.912$Image Super-Resolution#Set14 - 4x upscaling#PSNR#25.19$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.894$Image Super-Resolution#Set5 - 4x upscaling#PSNR#28.59$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.965$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#24.25$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.851
1904.08118v3.pdf	Image Super-Resolution#Set5 - 3x upscaling#PSNR#34.34$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.13$Color Image Denoising#CBSD68 sigma15#PSNR#34.1$Color Image Denoising#CBSD68 sigma75#PSNR#26.35
1810.12575v1.pdf	Image Super-Resolution#Set5 - 3x upscaling#PSNR#33.84$Image Super-Resolution#Set5 - 2x upscaling#PSNR#37.57$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.5$Grayscale Image Denoising#Urban100 sigma25#PSNR#30.19$Grayscale Image Denoising#Urban100 sigma25#SSIM#0.892$Grayscale Image Denoising#Set12 sigma50#PSNR#27.43$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.39$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.3$Grayscale Image Denoising#BSD68 sigma70#PSNR#25.14$Grayscale Image Denoising#Set12 sigma25#PSNR#30.55$Grayscale Image Denoising#Urban100 sigma70#PSNR#25.15$Grayscale Image Denoising#Set12 sigma70#PSNR#25.9$Grayscale Image Denoising#Urban100 sigma50#PSNR#26.82
1906.07078v1.pdf	Image Super-Resolution#VggFace2 - 8x upscaling#PSNR#25.57$Image Super-Resolution#WebFace - 8x upscaling#PSNR#27.11
1804.04829v2.pdf	Image Super-Resolution#VggFace2 - 8x upscaling#PSNR#24.10$Image Super-Resolution#WebFace - 8x upscaling#PSNR#27.21
1607.05046v1.pdf	Image Super-Resolution#VggFace2 - 8x upscaling#PSNR#21.84$Image Super-Resolution#WebFace - 8x upscaling#PSNR#23.10
1804.02900v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.89$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.94$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.79
1611.06345v4.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.42$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7940$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.80$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7856$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.23$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8952$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.66$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7380$Color Image Denoising#CBSD68 sigma50#PSNR#28.01
1811.12043v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.05$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7834$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.54$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7800$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.13$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8932$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.56$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7350
1811.12546v1.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#26.03$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7835$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.56$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7803$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.14$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8937$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.57$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7353
1806.02919v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.79$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7729$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.36$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7745$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.92$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8916$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.48$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7306$Denoising#Darmstadt Noise Dataset#PSNR#30.8$Grayscale Image Denoising#Set12 sigma15#PSNR#33.16$Grayscale Image Denoising#Urban100 sigma25#PSNR#30.94$Grayscale Image Denoising#BSD200 sigma30#PSNR#28.2$Grayscale Image Denoising#Set12 sigma50#PSNR#27.64$Grayscale Image Denoising#BSD200 sigma70#PSNR#24.62$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.47$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.41$Grayscale Image Denoising#BSD200 sigma50#PSNR#25.97$Grayscale Image Denoising#Urban100 sigma15#PSNR#33.45$Grayscale Image Denoising#Set12 sigma30#PSNR#30.8$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.88$Grayscale Image Denoising#Urban100 sigma50#PSNR#27.49
1712.06116v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.68$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.773$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.35$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.777$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.96$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.893$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.49$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.734$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.96$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.349$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.852$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#3.468$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.594$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.834$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#27.672$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#5.882$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.877
1812.11950v1.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.59$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.7680$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.29$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7741$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.82$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8907$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.44$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7302
1903.00834v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.5$Image Super-Resolution#CUFED5 - 4x upscaling#PSNR#26.24$Image Super-Resolution#Sun80 - 4x upscaling#PSNR#28.54
1801.10319v1.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.42$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.771$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.32$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.784$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.84$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.891$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.42$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.737
1704.03915v2.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.21$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.756$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.19$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.772$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.32$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.728
1805.02704v1.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#25.08$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.747$Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.07$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.770$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.40$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.883$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.25$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.724
2003.13081v1.pdf	Image Super-Resolution#Urban100 - 4x upscaling#PSNR#24.799$Image Super-Resolution#Urban100 - 4x upscaling#SSIM#0.9481$Image Super-Resolution#Urban100 - 4x upscaling#Perceptual Index#3.5511$Image Super-Resolution#Urban100 - 4x upscaling#LPIPS#0.1184$Image Super-Resolution#Set14 - 4x upscaling#PSNR#26.64$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7930$Image Super-Resolution#Set14 - 4x upscaling#Perceptual Index#2.9036$Image Super-Resolution#Set14 - 4x upscaling#LPIPS#0.1318$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.40$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8627$Image Super-Resolution#Set5 - 4x upscaling#Perceptual Index#3.2743$Image Super-Resolution#Set5 - 4x upscaling#LPIPS#0.0644$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#25.505$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6576$Image Super-Resolution#BSD100 - 4x upscaling#Perceptual Index#2.351$Image Super-Resolution#BSD100 - 4x upscaling#LPIPS#0.1611
1811.11482v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.98$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7904$Image Super-Resolution#Set5 - 4x upscaling#PSNR#32.74$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.9021
1712.06087v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#28.01$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7651$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.13$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8796$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.12$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7211
1511.02228v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.88$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.10$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.16
1707.07128v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.83$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7631$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.10$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8777
1508.02848v2.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.68$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.85$Denoising#Darmstadt Noise Dataset#PSNR#33.65$Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#33.65$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.8306$Grayscale Image Denoising#BSD68 sigma25#PSNR#28.92$Grayscale Image Denoising#Urban100 sigma15#PSNR#31.98$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.42
1609.05158v2.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.66$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.8004$Image Super-Resolution#Set14 - 4x upscaling#MOS#2.52$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.76$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8784$Image Super-Resolution#Set5 - 4x upscaling#MOS#2.89$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.02$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7442$Image Super-Resolution#BSD100 - 4x upscaling#MOS#2.01$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.25$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.926$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#47.19$Video Super-Resolution#Ultra Video Group HD - 4x upscaling#Average PSNR#37.91$Video Super-Resolution#Ultra Video Group HD - 4x upscaling#Average PSNR#36.20$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#2.099$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.521$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.811$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#26.714$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#3.333$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.765$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.06$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.7394$Video Super-Resolution#Vid4 - 4x upscaling#MOVIE#6.54$Video Super-Resolution#Xiph HD - 4x upscaling#Average PSNR#31.67$Video Super-Resolution#Xiph HD - 4x upscaling#Average PSNR#30.30
1903.10176v3.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.63$Image Super-Resolution#Set14 - 8x upscaling#PSNR#24.28$Image Super-Resolution#Set5 - 8x upscaling#PSNR#26.04$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.72
1809.04789v2.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.6222$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.7419$Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.0846$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8652$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#26.5707$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6900
1704.02738v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.57$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.76$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.96$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.87$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.99$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.933$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#51.96$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.88$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.774
1712.05248v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.48$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.45$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#26.91
1708.09200v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#27.37$Image Super-Resolution#Set5 - 4x upscaling#PSNR#30.24$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#26.87
1709.03749v2.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#26.22$Image Super-Resolution#Set5 - 4x upscaling#PSNR#29.16
1804.02815v1.pdf	Image Super-Resolution#Set14 - 4x upscaling#PSNR#26.13$Image Super-Resolution#Set14 - 4x upscaling#SSIM#0.694$Image Super-Resolution#Set5 - 4x upscaling#PSNR#29.82$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.840$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#25.33$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.651
1909.09437v3.pdf	Image Super-Resolution#USR-248 - 4x upscaling#PSNR#24.62$Image Super-Resolution#USR-248 - 4x upscaling#SSIM#0.69$Image Super-Resolution#USR-248 - 4x upscaling#UIQM#2.48
1603.09056v2.pdf	Image Super-Resolution#Set5 - 4x upscaling#PSNR#31.51$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.8869$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#27.40$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.7290
1603.08155v1.pdf	Image Super-Resolution#Set5 - 4x upscaling#PSNR#27.09$Image Super-Resolution#Set5 - 4x upscaling#SSIM#0.768$Image Super-Resolution#BSD100 - 4x upscaling#PSNR#24.95$Image Super-Resolution#BSD100 - 4x upscaling#SSIM#0.6317$Nuclear Segmentation#Cell17#F1-score#0.7413$Nuclear Segmentation#Cell17#Dice#0.6165$Nuclear Segmentation#Cell17#Hausdorff#25.9102
2105.12409v1.pdf	Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.9313717296835213
1808.08718v2.pdf	Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.9411827883122681$Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.9462525077016232
2002.06460v1.pdf	Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.947388637793901
1907.06490v2.pdf	Multi-Frame Super-Resolution#PROBA-V#Normalized cPSNR#0.948844910272775
2204.08332v2.pdf	Burst Image Super-Resolution#SyntheticBurst#PSNR#43.62$Burst Image Super-Resolution#SyntheticBurst#SSIM#0.975$Burst Image Super-Resolution#SyntheticBurst#LPIPS#0.025$Burst Image Super-Resolution#SyntheticBurst#PSNR#42.72$Burst Image Super-Resolution#SyntheticBurst#SSIM#0.971$Burst Image Super-Resolution#SyntheticBurst#LPIPS#0.031$Burst Image Super-Resolution#BurstSR#PSNR#48.57$Burst Image Super-Resolution#BurstSR#SSIM#0.986$Burst Image Super-Resolution#BurstSR#LPIPS#0.021$Burst Image Super-Resolution#BurstSR#PSNR#48.48$Burst Image Super-Resolution#BurstSR#SSIM#0.985
2110.03680v2.pdf	Burst Image Super-Resolution#SyntheticBurst#PSNR#41.93$Burst Image Super-Resolution#SyntheticBurst#SSIM#0.96$Burst Image Super-Resolution#BurstSR#PSNR#48.49$Burst Image Super-Resolution#BurstSR#SSIM#0.985
2108.08286v1.pdf	Burst Image Super-Resolution#SyntheticBurst#PSNR#41.56$Burst Image Super-Resolution#SyntheticBurst#SSIM#0.964$Burst Image Super-Resolution#SyntheticBurst#LPIPS#0.045$Burst Image Super-Resolution#BurstSR#PSNR#48.33$Burst Image Super-Resolution#BurstSR#SSIM#0.985$Burst Image Super-Resolution#BurstSR#LPIPS#0.023
2101.10997v2.pdf	Burst Image Super-Resolution#SyntheticBurst#PSNR#39.17$Burst Image Super-Resolution#SyntheticBurst#SSIM#0.946$Burst Image Super-Resolution#SyntheticBurst#LPIPS#0.081$Burst Image Super-Resolution#BurstSR#PSNR#47.70$Burst Image Super-Resolution#BurstSR#SSIM#0.984$Burst Image Super-Resolution#BurstSR#LPIPS#0.029
2204.08714v2.pdf	Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#27.12$Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#27.08$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.96$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.91$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#24.17$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#24.07$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#30.20$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#30.04$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#35.88$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#35.68$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#29.68$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#29.54$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#31.25$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#31.22$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#31.60$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#31.55
2106.00985v1.pdf	Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#26.70$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.43$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#23.59$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#29.38$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#35.09$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#28.85$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#30.90$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#31.23
2011.03802v2.pdf	Stereo Image Super-Resolution#KITTI2012 - 4x upscaling#PSNR#26.56$Stereo Image Super-Resolution#KITTI2015 - 4x upscaling#PSNR#26.32$Stereo Image Super-Resolution#Flickr1024 - 4x upscaling#PSNR#23.44$Stereo Image Super-Resolution#Middlebury - 4x upscaling#PSNR#29.16$Stereo Image Super-Resolution#Middlebury - 2x upscaling#PSNR#34.51$Stereo Image Super-Resolution#Flickr1024 - 2x upscaling#PSNR#28.60$Stereo Image Super-Resolution#KITTI2015 - 2x upscaling#PSNR#30.81$Stereo Image Super-Resolution#KITTI2012 - 2x upscaling#PSNR#31.11
2008.05765v2.pdf	Video Super-Resolution#SPMCS - 4x upscaling#PSNR#29.84$Video Super-Resolution#SPMCS - 4x upscaling#SSIM#0.8690$Video Super-Resolution#UDM10 - 4x upscaling#PSNR#38.97$Video Super-Resolution#UDM10 - 4x upscaling#SSIM#0.9534$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.35$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.627$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.557$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.79$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#24.252$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#2.567$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.842$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.02$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.617$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.549$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.789$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#23.786$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#2.74$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.856$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.69$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.8209
2006.11161.pdf	Video Super-Resolution#Vimeo90K#PSNR#40.17$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#27.42$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.939$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#57.91$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#6.809$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.748$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.629$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.896$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#31.104$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.045$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.741$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.43$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.835
2103.14006v2.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#29.27$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.177$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.836$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.19$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.301$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.859
2107.10833v2.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#29.14$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.181$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.855$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#28.82$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.185$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.850$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#28.71$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.244$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.830$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.01$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.280$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.868$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.52$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.296$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.878$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#25.52$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.333$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.795$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.392$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.663$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.774$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#24.441$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.01$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.895$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#3.697$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.598$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.824$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#27.195$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.019$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.871$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#5.58$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.335$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.698$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#7.874$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.881$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#0.733$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.328$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.64$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.464$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#8.113$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#5.393$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#12.689$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#11.584$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.398$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#2.712$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#6.857$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.957$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#7.225$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.417$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#2.122$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.612$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#2.633$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.712$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#3.8$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#14.561$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#5.95$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#12.744
2111.12704v1.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#29.54$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.201$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.838
2105.01237v2.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.97$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.291$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.871$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.637$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.654$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.619$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.84$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#26.708$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.613$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.879$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#0.969$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.367$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.302$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.081$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.672$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.118$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.246$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.701$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#8.105$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#11.497$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#6.024$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.026$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#8.139$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#0.741$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#6.363$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.678$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.793$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#12.998$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#3.427$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.229$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#9.47$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.761$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#7.711$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#3.851$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#11.177$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.943$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.67$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#11.303$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.801
2104.13371v1.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#30.98$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#LPIPS#0.334$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.881$Video Enhancement#MFQE v2#Incremental PSNR#1.10
2011.04482v1.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.12$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.916$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#56.86$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#6.136$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.709$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.557$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.865$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#28.377$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.177$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.884$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#4.359$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.643$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.549$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.864$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#29.011$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.15$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.859
2107.05307v2.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.33$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.929$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#60.39$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.029$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.519$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.595$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.196$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.226$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#10.1$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.337$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#8.194$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.0$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#12.917$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#6.497$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.701$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#5.548$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#10.748$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.684$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.163$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#11.543$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#6.209$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#10.643$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#16.733$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.67$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#11.643$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#5.67
1611.05250v2.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.92$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.932$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#53.96$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.35$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.7557$Video Super-Resolution#Vid4 - 4x upscaling#MOVIE#5.82$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#23.82$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.6548$Video Super-Resolution#Vid4 - 4x upscaling#MOVIE#9.31
1811.09393v4.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#26.60$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.933$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#61.20$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.89$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#25.57
1801.04590v4.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#27.23$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.936$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#57.14$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#26.69$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.822
2003.04716v1.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#27.28$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.937$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#57.39$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#6.947$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.737$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.629$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.894$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#31.071$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.241$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.921$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#15.988$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.842$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.698$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.765$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.898$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.435$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.606$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.75$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.082$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.714$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.293$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#7.0$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.83$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.845$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#2.396$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.371$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.145$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.383$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.607$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.438$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.211$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.476$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#2.093$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.296$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#3.886$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.916
2001.02129v1.pdf	Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#PSNR#27.14$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#SSIM#0.937$Video Super-Resolution#MSU Video Upscalers: Quality Enhancement#VMAF#56.45$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#4.863$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.647$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.557$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.831$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#25.986$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.699$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.895$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#4.805$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.66$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.872$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#29.381$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.571$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.904$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#26$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.772$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#4.981$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.273$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.083$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.058$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.764$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.26$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.545$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.244$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#3.565$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#9.07$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.558$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.236$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.844$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.822$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#4.527$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#9.245$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.882$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.273$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#12.808$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.84$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#5.398$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#11.314$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#6.833$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.82$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#5.299$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#3.196$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#5.361$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.917$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#6.82$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.23$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.544$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.213$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#2.763$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.843$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.262$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#11.458$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#6.596$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#8.658$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#3.566$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.007$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.098$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#4.346$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#3.274$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.825$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.141$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#15.11$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#7.464$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#13.076$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#7.546$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.034$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#15.958$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#6.41$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#8.027$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#2.112$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.494
2012.00595v3.pdf	Video Super-Resolution#TbD-3D#SSIM#0.699$Video Super-Resolution#TbD-3D#PSNR#26.23$Video Super-Resolution#TbD-3D#TIoU#0.879$Video Super-Resolution#TbD#SSIM#0.602$Video Super-Resolution#TbD#PSNR#25.57$Video Super-Resolution#TbD#TIoU#0.550$Video Super-Resolution#Falling Objects#SSIM#0.753$Video Super-Resolution#Falling Objects#PSNR#26.83$Video Super-Resolution#Falling Objects#TIoU#0.684
1911.10927v1.pdf	Video Super-Resolution#TbD-3D#SSIM#0.651$Video Super-Resolution#TbD-3D#PSNR#23.13$Video Super-Resolution#TbD-3D#TIoU#0.598$Video Super-Resolution#TbD#SSIM#0.674$Video Super-Resolution#TbD#PSNR#25.21$Video Super-Resolution#TbD#TIoU#0.542$Video Super-Resolution#Falling Objects#SSIM#0.671$Video Super-Resolution#Falling Objects#PSNR#23.42$Video Super-Resolution#Falling Objects#TIoU#0.539
1905.03633v2.pdf	Video Super-Resolution#TbD-3D#SSIM#0.504$Video Super-Resolution#TbD-3D#PSNR#18.84$Video Super-Resolution#TbD-3D#TIoU#0.598$Video Super-Resolution#TbD#SSIM#0.605$Video Super-Resolution#TbD#PSNR#23.22$Video Super-Resolution#TbD#TIoU#0.542$Video Super-Resolution#Falling Objects#SSIM#0.591$Video Super-Resolution#Falling Objects#PSNR#20.53$Video Super-Resolution#Falling Objects#TIoU#0.539
2012.02181v2.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#7.186$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.75$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.709$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.9$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#31.443$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#2.128$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.934$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.659$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.49$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.714$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.212$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.751$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.289$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#8.921$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.238$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.272$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.906$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.48$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.198$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.333$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.659$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.676$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.781$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.919$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.561$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#14.568$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.673$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.857$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#11.428$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.128$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.938$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#8.251$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.724$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.523$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.833$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#2.261$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.383
1903.10128v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#7.068$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.746$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.629$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.899$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#31.407$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.043$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.74$Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.12$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.818$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.599$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#1.498$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.733$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.127$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.729$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.335$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.185$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.282$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.324$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.89$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.438$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.237$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.572$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.7$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.996$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#10.89$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#3.089$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#5.821$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.314$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.719$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.689$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#5.783$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.884$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#11.777$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#7.133$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over Subjective Score#2.944$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#0.702$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#6.301$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#2.263$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.859
2104.10642v2.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#6$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.712$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.549$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.885$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#30.364$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.136$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.931$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#1.879$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.061$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#1.481$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#0.844$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#1.377$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.187$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#3.487$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#4.317$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#5.015$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.577$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#2.009$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#7.046$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.735$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.485$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#21.303$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.795$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#9.43$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.813$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.988$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#21.798$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#4.667$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#10.322$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#6.276
2008.00455v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.566$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.667$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.619$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.826$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#25.321$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.961$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.819$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#6.58$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#1.5$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#13.348$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#1.023$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#10.775$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#13.416$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#6.467$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#13.403$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#5.682$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.232$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#14.95$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.145$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#14.061$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#9.138$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#4.866$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#18.327$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#9.796$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over PSNR#15.144$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over MS-SSIM#11.643$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#13.844$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over ERQA#20.617$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over VMAF#10.67$Video Super-Resolution#MSU Super-Resolution for Video Compression#BSQ-rate over LPIPS#14.574
2007.10595v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.529$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.669$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.549$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.831$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#25.786$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.706$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.859
1812.02898v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.454$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.706$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.609$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.883$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#30.244$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.493$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.721
2004.02803v5.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#5.066$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.674$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0.549$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.876$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#29.703$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.041$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.915
2108.05301v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#4.262$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.713$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.791$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#26.067$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.066$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.923
2101.04061v2.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#2.686$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.538$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.745$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#24.195$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#1.562$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.793$Blind Face Restoration#CelebA-Test#LPIPS#36.46$Blind Face Restoration#CelebA-Test#FID#42.62$Blind Face Restoration#CelebA-Test#NIQE#4.077$Blind Face Restoration#CelebA-Test#Deg.#34.60$Blind Face Restoration#CelebA-Test#PSNR#25.08$Blind Face Restoration#CelebA-Test#SSIM#0.6777
2008.00418v1.pdf	Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#Subjective score#0.277$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#ERQAv1.0#0.339$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#QRCRv1.0#0$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#SSIM#0.759$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#PSNR#24.832$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#FPS#0.909$Video Super-Resolution#MSU Video Super Resolution Benchmark: Detail Restoration#1 - LPIPS#0.623
2207.08494v2.pdf	Video Super-Resolution#Vid4 - 4x upscaling#PSNR#28.07$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.8485
2206.02146v2.pdf	Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.99$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.8462
1809.08573v2.pdf	Video Super-Resolution#Vid4 - 4x upscaling#PSNR#26.01$Video Super-Resolution#Vid4 - 4x upscaling#SSIM#0.771$Video Super-Resolution#Vid4 - 4x upscaling#MOVIE#4.32
1909.08080v1.pdf	Video Super-Resolution#Vid4 - 4x upscaling#PSNR#27.55
2111.15288v2.pdf	Video Super-Resolution#Vimeo-90K#Average PSNR#37.84
2203.14537v1.pdf	Reference-based Video Super-Resolution#RealMCVSR#PSNR#34.86$Reference-based Video Super-Resolution#RealMCVSR#PSNR#34.74$Reference-based Video Super-Resolution#RealMCVSR#PSNR#33.88$Reference-based Video Super-Resolution#RealMCVSR#PSNR#33.80$Reference-based Video Super-Resolution#RealMCVSR#PSNR#33.66$Reference-based Video Super-Resolution#RealMCVSR#PSNR#33.47$Reference-based Video Super-Resolution#RealMCVSR#PSNR#33.26$Reference-based Video Super-Resolution#RealMCVSR#PSNR#32.43$Reference-based Video Super-Resolution#RealMCVSR#PSNR#31.07$Reference-based Video Super-Resolution#RealMCVSR#PSNR#30.83
1906.01704v1.pdf	EEG#SEED-IV#Accuracy#74.35$Emotion Recognition#MPED#Accuracy#40.34
2005.11577v1.pdf	Attention Score Prediction#PhyAAt#MAE#29.65$Noise Level Prediction#PhyAAt#MAE#4.75$Semanticity prediction#PhyAAt#Accuracy#56$LWR Classification#PhyAAt#Accuracy#81
2106.12871v1.pdf	Semanticity prediction#VizNet#F1 score#0.925
2101.03581v3.pdf	Breast Cancer Detection#Breast Cancer Coimbra Data Set#Mean Accuracy#79.17$Diabetic Retinopathy Detection#Diabetic Retinopathy Debrecen Data Set#Mean Accuracy#74.72$Cervical cancer biopsy identification#Cervical Cancer (Risk Factors) Data Set#Mean Accuracy#97.09$Breast Tissue Identification#Breast Tissue Data Set#Mean Accuracy#100.00
2203.07707v2.pdf	Breast Cancer Histology Image Classification#BreakHis#Accuracy (Inter-Patient)#92.15$Breast Cancer Histology Image Classification#BreakHis#1:1 Accuracy#92.23$Breast Cancer Histology Image Classification (20% labels)#BreakHis#1:1 Accuracy#88.77$Breast Cancer Histology Image Classification (20% labels)#BreakHis#Accuracy (Inter-Patient)#88.77
2210.04883v1.pdf	Reconstruction#CelebAMask-HQ#PSNR#21.9$Reconstruction#CelebAMask-HQ#R-FID#15.5$Reconstruction#iDesigner#PSNR#21.4$Reconstruction#iDesigner#R-FID#13.2$Reconstruction#ADE20K#PSNR#20$Pose Transfer#iDesigner#S-FID#26.9$Pose Transfer#CelebAMask-HQ#S-FID#19.8$Pose Transfer#ADE20K#FID#27.5
2112.09127v2.pdf	3D Human Reconstruction#CAPE#Chamfer (cm)#1.142$3D Human Reconstruction#CAPE#P2S (cm)#1.065$3D Human Reconstruction#CAPE#NC#0.066$3D Human Reconstruction#CAPE#Chamfer (cm)#1.187$3D Human Reconstruction#CAPE#P2S (cm)#1.110$3D Human Reconstruction#CAPE#NC#0.060$3D Human Reconstruction#CAPE#Chamfer (cm)#1.424$3D Human Reconstruction#CAPE#P2S (cm)#1.351$3D Human Reconstruction#CAPE#NC#0.101$3D Human Reconstruction#CAPE#Chamfer (cm)#1.533$3D Human Reconstruction#CAPE#P2S (cm)#1.431$3D Human Reconstruction#CAPE#NC#0.090
2205.04992v2.pdf	3D Human Reconstruction#CAPE#Chamfer (cm)#1.539$3D Human Reconstruction#CAPE#P2S (cm)#1.358$3D Human Reconstruction#CAPE#NC#0.109
2007.03858v2.pdf	3D Human Reconstruction#CAPE#Chamfer (cm)#2.122$3D Human Reconstruction#CAPE#P2S (cm)#1.495$3D Human Reconstruction#CAPE#NC#0.088
2004.00452v1.pdf	3D Human Reconstruction#CAPE#Chamfer (cm)#3.237$3D Human Reconstruction#CAPE#P2S (cm)#3.123$3D Human Reconstruction#CAPE#NC#0.112$3D Human Reconstruction#CAPE#Chamfer (cm)#3.627$3D Human Reconstruction#CAPE#P2S (cm)#3.729$3D Human Reconstruction#CAPE#NC#0.116$3D Object Reconstruction From A Single Image#BUFF#Point-to-surface distance (cm)#0.25$3D Object Reconstruction From A Single Image#BUFF#Chamfer (cm)#1.525$3D Object Reconstruction From A Single Image#BUFF#Surface normal consistency#0.22$3D Object Reconstruction From A Single Image#BUFF#Point-to-surface distance (cm)#1.63$3D Object Reconstruction From A Single Image#BUFF#Chamfer (cm)#1.73$3D Object Reconstruction From A Single Image#BUFF#Surface normal consistency#0.133$3D Object Reconstruction From A Single Image#RenderPeople#Chamfer (cm)#1.525
1905.05172v3.pdf	3D Human Reconstruction#CAPE#Chamfer (cm)#3.573$3D Human Reconstruction#CAPE#P2S (cm)#1.483$3D Human Reconstruction#CAPE#NC#0.186$3D Object Reconstruction#RenderPeople#Surface normal consistency#0.094$3D Object Reconstruction#RenderPeople#Point-to-surface distance (cm)#0.554$3D Object Reconstruction#RenderPeople#Chamfer (cm)#0.567$3D Object Reconstruction From A Single Image#BUFF#Point-to-surface distance (cm)#1.15$3D Object Reconstruction From A Single Image#BUFF#Chamfer (cm)#1.14$3D Object Reconstruction From A Single Image#BUFF#Surface normal consistency#0.0928$3D Object Reconstruction From A Single Image#RenderPeople#Point-to-surface distance (cm)#1.52$3D Object Reconstruction From A Single Image#RenderPeople#Chamfer (cm)#1.5$3D Object Reconstruction From A Single Image#RenderPeople#Surface normal consistency#0.084
2006.05734v2.pdf	3D Human Reconstruction#Surreal#MPVPE#43.5$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.3
1712.01337v1.pdf	3D Human Reconstruction#Surreal#MPVPE#74.5$3D Human Pose Estimation#Surreal#MPJPE#64.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#98.4
2008.09062v1.pdf	3D Human Reconstruction#AGORA#FB-NMVE#265.0$3D Human Reconstruction#AGORA#B-NMVE#184.8$3D Human Reconstruction#AGORA#FB-NMJE#263.3$3D Human Reconstruction#AGORA#B-NMJE#183.4$3D Human Reconstruction#AGORA#FB-MVE#217.3$3D Human Reconstruction#AGORA#B-MVE#151.5$3D Human Reconstruction#AGORA#F-MVE#51.1$3D Human Reconstruction#AGORA#LH/RH-MVE#74.9/71.3$3D Human Reconstruction#AGORA#FB-MPJPE#215.9$3D Human Reconstruction#AGORA#B-MPJPE#150.4$3D Human Reconstruction#AGORA#F-MPJPE#55.2$3D Human Reconstruction#AGORA#LH/RH-MPJPE#72.5/68.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF).#All#54.5$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), whole body#54.5$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), body only#52.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), left hand#13.1$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), face#5.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), whole body#65.7$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), body only#76.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), left hand#31.2$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), face#15.9$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE-14#62.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE, left hand#13.5$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#mean P2S#28.9$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#median P2S#18$3D Human Pose Estimation#3DPW#PA-MPJPE#60.7$3D Human Pose Estimation#3DPW#MPJPE#93.4$3D Multi-Person Mesh Recovery#AGORA#FB-NMVE#265.0$3D Multi-Person Mesh Recovery#AGORA#B-NMVE#184.8$3D Multi-Person Mesh Recovery#AGORA#FB-NMJE#263.3$3D Multi-Person Mesh Recovery#AGORA#B-NMJE#183.4$3D Multi-Person Mesh Recovery#AGORA#FB-MVE#217.3$3D Multi-Person Mesh Recovery#AGORA#B-MVE#151.5$3D Multi-Person Mesh Recovery#AGORA#F-MVE#51.1$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MVE#74.9/71.3$3D Multi-Person Mesh Recovery#AGORA#FB-MPJPE#215.9$3D Multi-Person Mesh Recovery#AGORA#B-MPJPE#150.4$3D Multi-Person Mesh Recovery#AGORA#F-MPJPE#55.2$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MPJPE#72.5/68.8$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#11.8$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#12.2$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#48.4$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#91.8
1904.05866v1.pdf	3D Human Reconstruction#AGORA#FB-NMVE#333.1$3D Human Reconstruction#AGORA#B-NMVE#263.3$3D Human Reconstruction#AGORA#FB-NMJE#326.5$3D Human Reconstruction#AGORA#B-NMJE#256.5$3D Human Reconstruction#AGORA#FB-MVE#236.5$3D Human Reconstruction#AGORA#B-MVE#187.0$3D Human Reconstruction#AGORA#F-MVE#48.9$3D Human Reconstruction#AGORA#LH/RH-MVE#48.3/51.4$3D Human Reconstruction#AGORA#FB-MPJPE#231.8$3D Human Reconstruction#AGORA#B-MPJPE#182.1$3D Human Reconstruction#AGORA#F-MPJPE#52.9$3D Human Reconstruction#AGORA#LH/RH-MPJPE#46.5/49.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), body only#75.4$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), left hand#11.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), face#4.9$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), whole body#93.0$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), body only#116.1$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), left hand#23.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), face#11.5$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE-14#87.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE, left hand#12.2$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#mean P2S#36.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#median P2S#23.0$3D Multi-Person Mesh Recovery#AGORA#FB-NMVE#333.1$3D Multi-Person Mesh Recovery#AGORA#B-NMVE#263.3$3D Multi-Person Mesh Recovery#AGORA#FB-NMJE#326.5$3D Multi-Person Mesh Recovery#AGORA#B-NMJE#256.5$3D Multi-Person Mesh Recovery#AGORA#FB-MVE#236.5$3D Multi-Person Mesh Recovery#AGORA#B-MVE#187.0$3D Multi-Person Mesh Recovery#AGORA#F-MVE#48.9$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MVE#48.3/51.4$3D Multi-Person Mesh Recovery#AGORA#FB-MPJPE#231.8$3D Multi-Person Mesh Recovery#AGORA#B-MPJPE#182.1$3D Multi-Person Mesh Recovery#AGORA#F-MPJPE#52.9$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MPJPE#46.5/49.6
2011.11534v4.pdf	3D Human Reconstruction#AGORA#PA-MPVPE#73.2$3D Human Pose Estimation#3DPW#PA-MPJPE#54.4$Hand Pose Estimation#3DPW#MPJPE#86.6$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#7.7$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#7.7$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#66.4$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#97.1
2105.05301v2.pdf	3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), whole body#55$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), body only#53$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), left hand#11.2$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), face#4.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), whole body#67.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), body only#75.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), left hand#25.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), face#14.2$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE-14#61.5$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE, left hand#11.7$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#mean P2S#29.9$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#median P2S#18.4$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.49$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.25$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.18$3D Multi-Person Mesh Recovery#AGORA#FB-NMVE#233.9$3D Multi-Person Mesh Recovery#AGORA#B-NMVE#173.4$3D Multi-Person Mesh Recovery#AGORA#FB-NMJE#230.9$3D Multi-Person Mesh Recovery#AGORA#B-NMJE#171.1$3D Multi-Person Mesh Recovery#AGORA#FB-MVE#191.8$3D Multi-Person Mesh Recovery#AGORA#B-MVE#142.2$3D Multi-Person Mesh Recovery#AGORA#F-MVE#50.2$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MVE#49.5/49.0$3D Multi-Person Mesh Recovery#AGORA#FB-MPJPE#189.3$3D Multi-Person Mesh Recovery#AGORA#B-MPJPE#140.3$3D Multi-Person Mesh Recovery#AGORA#F-MPJPE#54.5$3D Multi-Person Mesh Recovery#AGORA#LH/RH-MPJPE#46.4/46.0$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#12.1$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#12$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#46.8$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#91.9
2108.06428v1.pdf	3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), body only#52.7$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#PA V2V (mm), left hand#12.8$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), whole body#76.9$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), body only#80.1$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#TR V2V (mm), left hand#32.1$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE-14#62.3$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#MPJPE, left hand#13.2$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#mean P2S#31.6$3D Human Reconstruction#Expressive hands and faces dataset (EHF)#median P2S#19.2$3D Human Pose Estimation#3DPW#PA-MPJPE#60$3D Human Pose Estimation#3DPW#MPJPE#94.3
1912.07109v2.pdf	Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6674$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6464$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6234$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.612$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6015
2103.03390v2.pdf	Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6474$3D Reconstruction#ShapeNet#Mean#2.82$3D Reconstruction#ShapeNet#Mean IoU#65.43
1904.01786v1.pdf	Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6464$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.6015$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.5736$Single-View 3D Reconstruction#ShapeNet#3DIoU#0.4766$3D Object Reconstruction#ShapeNet#3DIoU#0.6464
1908.01210v2.pdf	Single-View 3D Reconstruction#ShapeNet#3DIoU#0.612$Single-View 3D Reconstruction#ShapeNet#F-Score#0.558
1905.10711v4.pdf	Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0.57$Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0.564$Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0.546$Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0.487$Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0.473$Single-View 3D Reconstruction#ShapeNetCore#3DIoU#0,3
2112.00726v2.pdf	3D Semantic Scene Completion from a single RGB image#NYUv2#mIoU#26.94$3D Semantic Scene Completion from a single RGB image#SemanticKITTI#mIoU#11.08$3D Semantic Scene Completion#NYUv2#mIoU#26.94$3D Semantic Scene Completion#SemanticKITTI#mIoU#11.08
2003.14052v1.pdf	3D Semantic Scene Completion from a single RGB image#NYUv2#mIoU#22.91$3D Semantic Scene Completion from a single RGB image#SemanticKITTI#mIoU#6.23$3D Semantic Scene Completion#NYUv2#mIoU#41.1
2004.02122v1.pdf	3D Semantic Scene Completion from a single RGB image#NYUv2#mIoU#18.15$3D Semantic Scene Completion#NYUv2#mIoU#33.3
2008.10559v2.pdf	3D Semantic Scene Completion from a single RGB image#NYUv2#mIoU#15.88$3D Semantic Scene Completion from a single RGB image#SemanticKITTI#mIoU#7.09$3D Semantic Scene Completion#NYUv2#mIoU#28.4$3D Semantic Scene Completion#SemanticKITTI#mIoU#17.6$3D Semantic Scene Completion#SemanticKITTI#mIoU#17
2012.03762v1.pdf	3D Semantic Scene Completion from a single RGB image#SemanticKITTI#mIoU#8.97$3D Semantic Scene Completion#SemanticKITTI#mIoU#23.8$3D Semantic Segmentation#SemanticKITTI#mIoU#66.0%$LIDAR Semantic Segmentation#nuScenes#mIOU#0.74
1912.11463v1.pdf	Single-Image-Based Hdr Reconstruction#City Scene Dataset#PSNR#32.54$Single-Image-Based Hdr Reconstruction#City Scene Dataset#SSIM#0.95$Single-Image-Based Hdr Reconstruction#City Scene Dataset#HDR-VDP2 Q SCORE#67.18
2006.13026v2.pdf	Face Recognition#CFP-FP#Accuracy#0.98986$Face Recognition#CFP-FF#Accuracy#99.886$Face Recognition#LFW#Accuracy#0.99833$Face Verification#MegaFace#Accuracy#98.95%$Face Identification#MegaFace#Accuracy#98.78%$Conditional Image Generation#CIFAR-10#Inception score#7.5$Conditional Image Generation#CIFAR-10#FID#36.77$Image Generation#CIFAR-10#Inception score#8.49$Image Generation#CIFAR-10#FID#16.79$Image Generation#CIFAR-10#Inception score#6.95$Image Generation#CIFAR-10#FID#40.45$Image Classification#ImageNet#Top 1 Accuracy#77.17%$Image Classification#ImageNet#Top 5 Accuracy#93.56%$Image Classification#CIFAR-10#Percentage correct#94.9
2111.13475v3.pdf	Face Recognition#CFP-FP#Accuracy#0.9874$Face Recognition#XQLFW#Accuracy#0.8395$Face Recognition#AgeDB-30#Accuracy#0.9850$Face Recognition#LFW#Accuracy#0.9983$Face Verification#CFP-FP#Accuracy#0.9874$Face Verification#IJB-B#TAR @ FAR=0.01#97.72%$Face Verification#IJB-B#TAR @ FAR=0.001#96.48$Face Verification#IJB-B#TAR@FAR=0.0001#94.7$Face Verification#IJB-C#TAR @ FAR=1e-2#98.51$Face Verification#IJB-C#TAR @ FAR=1e-3#97.62$Face Verification#IJB-C#TAR @ FAR=1e-4#96.19%$Face Verification#AgeDB-30#Accuracy#0.9850
2109.09416v4.pdf	Face Recognition#CFP-FP#Accuracy#0.9867$Face Recognition#IJB-B#TAR @ FAR=0.0001#0.953$Face Recognition#CPLFW#Accuracy#0.9327$Face Recognition#AgeDB-30#Accuracy#0.9835$Face Recognition#CALFW#Accuracy#0.9617$Face Verification#MegaFace#Accuracy#98.81%$Face Verification#Labeled Faces in the Wild#Accuracy#99.82%$Face Verification#IJB-C#TAR @ FAR=1e-4#96.57%$Face Verification#IJB-C#training dataset#MS1M V2$Face Verification#IJB-C#model#R100
2002.10857v2.pdf	Face Recognition#CFP-FP#Accuracy#0.9602$Face Recognition#LFW#Accuracy#0.9973$Face Verification#IJB-C#TAR @ FAR=1e-3#96.29%$Face Verification#IJB-C#TAR @ FAR=1e-4#93.95%$Face Verification#IJB-C#TAR @ FAR=1e-5#89.60%$Face Verification#IJB-C#training dataset#MS1M Cleaned$Face Verification#IJB-C#model#R100$Person Re-Identification#MSMT17#Rank-1#76.9$Person Re-Identification#MSMT17#mAP#52.1$Person Re-Identification#MSMT17#Rank-1#76.3$Person Re-Identification#MSMT17#mAP#50.2$Person Re-Identification#Market-1501#Rank-1#96.1$Person Re-Identification#Market-1501#mAP#87.4$Person Re-Identification#Market-1501#Rank-1#94.2$Person Re-Identification#Market-1501#mAP#84.9$Metric Learning#Stanford Online Products#R@1#78.3$Metric Learning#CARS196#R@1#83.4
2105.11113v1.pdf	Face Recognition#CFP-FP#Accuracy#0.9287$Face Recognition#AgeDB-30#Accuracy#0.9823$Face Recognition#LFW#Accuracy#0.998
2210.02579v1.pdf	Face Recognition#CFP-FP#Accuracy#0.8981$Face Recognition#AgeDB#Accuracy#0.811$Face Recognition#CPLFW#Accuracy#0.8223$Face Recognition#LFW#Accuracy#0.9617$Face Recognition#CALFW#Accuracy#0.8255
1810.11160v1.pdf	Face Recognition#Color FERET (Online Open Set)#Average Accuracy (10 times)#83.79$Face Recognition#Color FERET (Online Open Set)#Average Accuracy (10 times)#80.72$Face Recognition#LFW (Online Open Set)#Average Accuracy (10 times)#76.46$Face Recognition#LFW (Online Open Set)#Average Accuracy (10 times)#53.97$Face Recognition#Adience (Online Open Set)#Average Accuracy (10 times)#84.3$Face Recognition#Adience (Online Open Set)#Average Accuracy (10 times)#80.6
2207.10180v1.pdf	Face Recognition#IJB-B#TAR @ FAR=1e-5#0.9095$Face Recognition#IJB-B#TAR @ FAR=1e-4#0.9461$Face Recognition#IJB-B#TAR @ FAR=1e-3#0.9621$Face Recognition#IJB-B#Rank-1#0.9496$Face Recognition#IJB-B#Rank-5#0.9684$Face Verification#IJB-S#Rank-1 (Video2Single)#72.54$Face Verification#IJB-S#Rank-1 (Video2Booking)#72.65$Face Verification#IJB-S#Rank-1 (Video2Video)#39.14$Face Verification#IJB-S#Rank-1 (Video2Single)#63.86$Face Verification#IJB-S#Rank-1 (Video2Booking)#65.95$Face Verification#IJB-S#Rank-1 (Video2Video)#21.38$Face Verification#IJB-C#TAR @ FAR=1e-4#95.9%$Face Verification#IJB-C#TAR @ FAR=1e-5#94.06%$Face Verification#IJB-C#TAR @ FAR=1e-6#89.34%$Face Verification#IJB-C#Rank-1#96.31$Face Verification#IJB-C#Rank-5#97.48
2207.06726v1.pdf	Face Recognition#XQLFW#Accuracy#0.9512$Face Recognition#LFW#Accuracy#0.9973$Face Verification#LFW#Accuracy#99.73%$Face Verification#Labeled Faces in the Wild#Accuracy#99.73%
2203.15565v1.pdf	Face Recognition#MFR#MFR-ALL#97.85$Face Recognition#MFR#MFR-MASK#90.88$Face Recognition#MFR#African#98.07$Face Recognition#MFR#Caucasian#98.81$Face Recognition#MFR#South Asian#98.66$Face Recognition#MFR#East Asian#89.97$Face Verification#CFP-FP#Accuracy#0.9951$Face Verification#IJB-B#TAR@FAR=0.0001#96.71$Face Verification#IJB-C#TAR @ FAR=1e-4#98.00%$Face Verification#IJB-C#TAR @ FAR=1e-5#97.23%$Face Verification#IJB-C#training dataset#WebFace42M$Face Verification#IJB-C#model#ViT-L$Face Verification#IJB-C#TAR @ FAR=1e-4#97.97%$Face Verification#IJB-C#TAR @ FAR=1e-5#96.93%$Face Verification#IJB-C#model#R200$Face Verification#AgeDB-30#Accuracy#0.9870
2109.01745v5.pdf	Face Recognition#CASIA-WebFace+masks#Accuracy#91.47$Face Recognition#CASIA-WebFace+masks#Accuracy#88.06$Face Recognition#CASIA-WebFace+masks#Accuracy#86.85$Face Recognition#CelebA+masks#Accuracy#95.43$Face Recognition#CelebA+masks#Accuracy#93.58$Face Recognition#CelebA+masks#Accuracy#91.51
1801.07698v4.pdf	Face Recognition#CASIA-WebFace+masks#Accuracy#87.95$Face Recognition#CelebA+masks#Accuracy#91.78$Face Verification#Trillion Pairs Dataset#Accuracy#57.45$Face Verification#YouTube Faces DB#Accuracy#98.02%$Face Verification#MegaFace#Accuracy#98.48%$Face Verification#Labeled Faces in the Wild#Accuracy#99.83%$Face Verification#IJB-C#TAR @ FAR=1e-5#96.07%$Face Verification#IJB-C#training dataset#IBUG-500K$Face Verification#IJB-C#model#R100$Face Identification#MegaFace#Accuracy#98.35%$Face Identification#Trillion Pairs Dataset#Accuracy#57.48
1503.03832v3.pdf	Face Recognition#CASIA-WebFace+masks#Accuracy#84.21$Face Recognition#CelebA+masks#Accuracy#90.96$Face Verification#YouTube Faces DB#Accuracy#95.12%$Face Verification#Labeled Faces in the Wild#Accuracy#99.63%$Face Verification#IJB-C#TAR @ FAR=1e-2#66.5%$Disguised Face Verification#MegaFace#Accuracy#86.47$Face Identification#MegaFace#Accuracy#70.49%
2002.04219v1.pdf	Face Recognition#Carl#Rank-1#85$Face Recognition#EURECOM#Rank-1#88.33$Face Recognition#UND-X1#Rank-1#87.2
1601.05347v2.pdf	Face Recognition#Carl#Rank-1#71$Face Recognition#UND-X1#Rank-1#83.73
2109.05804v2.pdf	Face Recognition#MLFW#Accuracy#91.57$Face Recognition#MLFW#Accuracy#90.57$Face Recognition#MLFW#Accuracy#90.43$Face Recognition#MLFW#Accuracy#85.95$Face Recognition#MLFW#Accuracy#82.52$Face Recognition#MLFW#Accuracy#77.20
2011.12427v1.pdf	Face Recognition#UHDB31#Rank-1#84.32$Image Classification#Imbalanced CUB-200-2011#Accuracy#99.67
1809.00338v2.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#99.76%$Age-Invariant Face Recognition#CACDVS#Accuracy#99.38%$Age-Invariant Face Recognition#FG-NET#Accuracy#93.2%$Age-Invariant Face Recognition#MORPH Album2#Rank-1 Recognition Rate#99.65%$Age-Invariant Face Recognition#MORPH Album2#Rank-1 Recognition Rate#99.13%$Age-Invariant Face Recognition#CAFR#Accuracy#84.81%$Face Verification#IJB-C#TAR @ FAR=1e-2#93.5%
2103.01520v2.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#99.55%$Age-Invariant Face Recognition#FG-NET#Accuracy#94.78%
1904.04972v1.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#99.4%
1810.07599v1.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#99.2%$Age-Invariant Face Recognition#MORPH Album2#Rank-1 Recognition Rate#98.55%
1703.08388v2.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#99.13%
1511.02683v4.pdf	Age-Invariant Face Recognition#CACDVS#Accuracy#97.95%$Age-Invariant Face Recognition#CAFR#Accuracy#73.56%$Face Verification#YouTube Faces DB#Accuracy#95.54%$Face Verification#MegaFace#Accuracy#85.133%$Face Verification#Labeled Faces in the Wild#Accuracy#99.33%$Face Identification#MegaFace#Accuracy#73.749%
2003.09373v1.pdf	Face Quality Assessement#LFW#Equal Error Rate#0.007$Face Quality Assessement#Adience#Equal Error Rate#0.026
2104.14124v1.pdf	Face Detection#WIDER Face#Average Precision#93.86$Face Detection#FDDB#Accuracy#91.82
1911.05341v1.pdf	Face Detection#WIDER Face#GFLOPs#0.1079$Face Detection#WIDER Face (Hard)#AP#0.906
2104.14126v1.pdf	Face Detection#ADE20K#mIoU#42.86$Semantic Segmentation#PASCAL Context#mIoU#52.76
2104.14125v1.pdf	Face Detection#WIDER FACE#Average Top-1 Accuracy#68.98
1905.00641v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.96175$Face Detection#WIDER Face (Easy)#AP#0.96942$Face Detection#WIDER Face (Hard)#AP#0.91857
2107.02859v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.9571$Face Detection#WIDER Face (Hard)#AP#0.9276
1905.01585v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.957$Face Detection#WIDER Face (Easy)#AP#0.965$Face Detection#WIDER Face (Hard)#AP#0.912
1810.10220v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.953$Face Detection#FDDB#AP#0.991$Face Detection#WIDER Face (Easy)#AP#0.960$Face Detection#WIDER Face (Hard)#AP#0.900
2011.13183v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.952$Face Detection#WIDER Face (Easy)#AP#0.959$Face Detection#WIDER Face (Hard)#AP#0.924
1811.11662v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.949$Face Detection#WIDER Face (Easy)#AP#0.957$Face Detection#WIDER Face (Hard)#AP#0.897
1809.02693v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.948$Face Detection#FDDB#AP#0.988$Face Detection#WIDER Face (Easy)#AP#0.959$Face Detection#PASCAL Face#AP#0.9909$Face Detection#WIDER Face (Hard)#AP#0.896$Face Detection#Annotated Faces in the Wild#AP#0.9987
1803.07737v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.946$Face Detection#FDDB#AP#0.987$Face Detection#WIDER Face (Easy)#AP#0.961$Face Detection#WIDER Face (Hard)#AP#0.889
1802.02142v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.939$Face Detection#WIDER Face (Easy)#AP#0.950$Face Detection#WIDER Face (Hard)#AP#0.896
1904.13300v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.9341$Face Detection#WIDER Face (Hard)#AP#0.8723$Object Detection#COCO test-dev#box AP#38.1$Head Detection#Rebar Head#F1#98.83%
1709.05256v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.931$Face Detection#FDDB#AP#0.990$Face Detection#WIDER Face (Easy)#AP#0.943$Face Detection#WIDER Face (Hard)#AP#0.876
1708.05237v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.924$Face Detection#FDDB#AP#0.983$Face Detection#WIDER Face (Easy)#AP#0.937$Face Detection#PASCAL Face#AP#0.9849$Face Detection#WIDER Face (Hard)#AP#0.852
1911.03599v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.921$Face Detection#WIDER Face (Easy)#AP#0.932$Face Detection#WIDER Face (Hard)#AP#0.873
1612.04402v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.908$Face Detection#WIDER Face (Hard)#AP#0.823
1906.06579v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.903$Face Detection#WIDER Face (Hard)#AP#0.850
2002.11921v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.89$Face Detection#WIDER Face (Hard)#AP#0.70
2012.07791v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.890$Face Detection#WIDER Face (Easy)#AP#0.9$Face Detection#WIDER Face (Hard)#AP#0.839$Head Pose Estimation#BIWI#MAE (trained with other data)#3.786$Head Pose Estimation#BIWI#MAE (trained with other data)#4.578$Head Pose Estimation#AFLW2000#MAE#3.913$Head Pose Estimation#AFLW2000#MAE_t#0.099$Head Pose Estimation#AFLW2000#MAE#4.839$Head Pose Estimation#AFLW2000#MAE_t#0.114
1606.05413v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.874$Face Detection#WIDER Face (Hard)#AP#0.643
1904.10633v3.pdf	Face Detection#WIDER Face (Medium)#AP#0.865$Face Detection#FDDB#AP#0.973$Face Detection#WIDER Face (Easy)#AP#0.896$Face Detection#WIDER Face (Hard)#AP#0.770
1604.02878v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.820$Face Detection#WIDER Face (Easy)#AP#0.851$Face Detection#WIDER Face (Hard)#AP#0.607
1701.01692v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.772$Face Detection#WIDER Face (Hard)#AP#0.564
1511.06523v1.pdf	Face Detection#WIDER Face (Medium)#AP#0.636$Face Detection#WIDER Face (Medium)#AP#0.604$Face Detection#WIDER Face (Medium)#AP#0.589$Face Detection#WIDER Face (Hard)#AP#0.400$Face Detection#WIDER Face (Hard)#AP#0.315$Face Detection#WIDER Face (Hard)#AP#0.304
1407.4023v2.pdf	Face Detection#WIDER Face (Medium)#AP#0.588$Face Detection#WIDER Face (Hard)#AP#0.290
1708.05234v4.pdf	Face Detection#FDDB#AP#0.960$Face Detection#PASCAL Face#AP#0.9630$Face Detection#Annotated Faces in the Wild#AP#0.9891
1603.01249v3.pdf	Face Detection#FDDB#AP#0.901$Face Detection#PASCAL Face#AP#0.9620$Face Detection#Annotated Faces in the Wild#AP#0.9940
1408.1656v3.pdf	Face Detection#FDDB#AP#0.864$Face Detection#PASCAL Face#AP#0.9029$Face Detection#Annotated Faces in the Wild#AP#0.9721
1911.08076v1.pdf	Face Detection#FDDB#AP#0.84$Image Classification#ImageNet#Top 5 Accuracy#78.0%
2106.04269v2.pdf	Face Detection#COCO-WholeBody#AP#56.4$Face Detection#COCO-WholeBody#AP50#82.4$Face Detection#COCO-WholeBody#AP75#67.1$Face Detection#COCO-WholeBody#APM#43.4$Face Detection#COCO-WholeBody#APL#63.3$Face Detection#COCO-WholeBody#AP#55.8$Face Detection#COCO-WholeBody#AP50#82.3$Face Detection#COCO-WholeBody#AP75#66.2$Face Detection#COCO-WholeBody#APM#40$Face Detection#COCO-WholeBody#APL#63.6$Facial Landmark Detection#COCO-WholeBody#keypoint AP#75.4$Facial Landmark Detection#COCO-WholeBody#keypoint AP#74.6$Hand Pose Estimation#COCO-WholeBody#keypoint AP#50.4$Hand Pose Estimation#COCO-WholeBody#keypoint AP#47$Multi-Person Pose Estimation#COCO-WholeBody#keypoint AP#59.4$Multi-Person Pose Estimation#COCO-WholeBody#keypoint AP#55.2$2D Human Pose Estimation#COCO-WholeBody#WB#34.8$2D Human Pose Estimation#COCO-WholeBody#body#59.4$2D Human Pose Estimation#COCO-WholeBody#foot#53.0$2D Human Pose Estimation#COCO-WholeBody#face#75.4$2D Human Pose Estimation#COCO-WholeBody#hand#50.4
1607.05477v1.pdf	Face Detection#PASCAL Face#AP#0.9410$Face Detection#Annotated Faces in the Wild#AP#0.9835
1607.07155v1.pdf	Face Detection#WIDER Face (Hard)#AP#0.809$Pedestrian Detection#Caltech#Reasonable Miss Rate#9.95
1707.09531v2.pdf	Face Detection#Annotated Faces in the Wild#AP#0.9917
1606.00850v3.pdf	Face Detection#Annotated Faces in the Wild#AP#0.9597
1711.07246v2.pdf	Occluded Face Detection#MAFA#MAP#88.3%
1709.05188v6.pdf	Occluded Face Detection#MAFA#MAP#77.3%
2205.12010v1.pdf	Face Verification#CPLFW#Accuracy#91.05%$Face Verification#CALFW#Accuracy#93.95%$Face Verification#LFW#Accuracy#99.60%$Face Verification#Labeled Faces in the Wild#Accuracy#99.60%
1903.10203v3.pdf	Face Verification#BUAA-VisNir#TAR @ FAR=0.001#97.3$Face Verification#BUAA-VisNir#TAR @ FAR=0.01#98.5$Face Verification#CASIA NIR-VIS 2.0#TAR @ FAR=0.001#99.8$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.001#92.9$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.01#98.5$Face Verification#IIIT-D Viewed Sketch#TAR @ FAR=0.01#97.86
1809.01936v3.pdf	Face Verification#BUAA-VisNir#TAR @ FAR=0.001#96.9$Face Verification#BUAA-VisNir#TAR @ FAR=0.01#98.5$Face Verification#CASIA NIR-VIS 2.0#TAR @ FAR=0.001#99.6$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.001#84.9$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.01#97.2
1708.02412v1.pdf	Face Verification#BUAA-VisNir#TAR @ FAR=0.001#91.9$Face Verification#BUAA-VisNir#TAR @ FAR=0.01#96.0$Face Verification#CASIA NIR-VIS 2.0#TAR @ FAR=0.001#98.4$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.001#54.6$Face Verification#Oulu-CASIA NIR-VIS#TAR @ FAR=0.01#81.5
1812.11317v1.pdf	Face Verification#Trillion Pairs Dataset#Accuracy#72.71$Face Verification#MegaFace#Accuracy#97.38%$Face Identification#MegaFace#Accuracy#97.2%$Face Identification#Trillion Pairs Dataset#Accuracy#73.56
1801.05599v4.pdf	Face Verification#Trillion Pairs Dataset#Accuracy#61.61$Face Identification#Trillion Pairs Dataset#Accuracy#61.80
1704.08063v4.pdf	Face Verification#Trillion Pairs Dataset#Accuracy#43.76$Face Verification#CK+#Accuracy#93.80$Face Verification#YouTube Faces DB#Accuracy#95.0%$Face Verification#MegaFace#Accuracy#89.142%$Face Verification#MegaFace#Accuracy#85.561%$Face Verification#Labeled Faces in the Wild#Accuracy#99.42%$Face Identification#MegaFace#Accuracy#75.766%$Face Identification#MegaFace#Accuracy#72.729%$Face Identification#Trillion Pairs Dataset#Accuracy#43.89
1708.02002v2.pdf	Face Verification#Trillion Pairs Dataset#Accuracy#37.14$Face Identification#Trillion Pairs Dataset#Accuracy#39.80$Pedestrian Detection#TJU-Ped-campus#R (miss rate)#34.73$Pedestrian Detection#TJU-Ped-campus#RS (miss rate)#82.99$Pedestrian Detection#TJU-Ped-campus#HO (miss rate)#71.31$Pedestrian Detection#TJU-Ped-campus#R+HO (miss rate)#42.26$Pedestrian Detection#TJU-Ped-campus#ALL (miss rate)#44.34$Pedestrian Detection#TJU-Ped-traffic#R (miss rate)#23.89$Pedestrian Detection#TJU-Ped-traffic#RS (miss rate)#37.92$Pedestrian Detection#TJU-Ped-traffic#HO (miss rate)#61.60$Pedestrian Detection#TJU-Ped-traffic#R+HO (miss rate)#28.45$Pedestrian Detection#TJU-Ped-traffic#ALL (miss rate)#41.40$Long-tail Learning#EGTEA#Average Precision#59.09$Long-tail Learning#EGTEA#Average Recall#59.17$Object Counting#CARPK#MAE#24.58$Object Detection#COCO test-dev#box AP#40.8$Object Detection#COCO test-dev#AP50#61.1$Object Detection#COCO test-dev#AP75#44.1$Object Detection#COCO test-dev#APS#24.1$Object Detection#COCO test-dev#APM#44.2$Object Detection#COCO test-dev#APL#51.2$Object Detection#COCO test-dev#Hardware Burden#4G$Object Detection#COCO test-dev#box AP#39.1$Object Detection#COCO test-dev#AP50#59.1$Object Detection#COCO test-dev#AP75#42.3$Object Detection#COCO test-dev#APS#21.8$Object Detection#COCO test-dev#APM#42.7$Object Detection#COCO test-dev#APL#50.2$Dense Object Detection#SKU-110K#AP#45.5$Dense Object Detection#SKU-110K#AP75#.389
1604.03540v1.pdf	Face Verification#Trillion Pairs Dataset#Accuracy#34.46$Face Identification#Trillion Pairs Dataset#Accuracy#36.75$Object Detection#PASCAL VOC 2007#MAP#78.9%
1910.04985v4.pdf	Face Verification#CFP-FP#Accuracy#0.985$Face Verification#Labeled Faces in the Wild#Accuracy#99.85%$Face Verification#AgeDB-30#Accuracy#0.9815
1908.09124v3.pdf	Face Verification#CFP-FP#Accuracy#0.9307$Face Verification#Labeled Faces in the Wild#Accuracy#99.65%$Face Verification#AgeDB-30#Accuracy#0.9685
1907.05653v2.pdf	Face Verification#CFP-FP#Accuracy#0.89829$Face Verification#Labeled Faces in the Wild#Accuracy#99.733%$Face Verification#AgeDB-30#Accuracy#0.97333
2203.11593v1.pdf	Face Verification#IJB-B#TAR @ FAR=0.01#97.7%$Face Verification#IJB-B#TAR @ FAR=0.001#96.6$Face Verification#IJB-B#TAR@FAR=0.0001#95.04$Face Verification#IJB-B#TAR @ FAR=0.01#97.63%$Face Verification#IJB-B#TAR @ FAR=0.001#96.5$Face Verification#IJB-B#TAR@FAR=0.0001#95.21$Face Verification#IJB-B#TAR @ FAR=0.01#97.36%$Face Verification#IJB-B#TAR@FAR=0.0001#94.99$Face Verification#IJB-C#TAR @ FAR=1e-5#94.7%$Face Verification#IJB-C#TAR @ FAR=1e-3#97.57$Face Verification#IJB-C#TAR @ FAR=1e-4#96.38%$Face Verification#IJB-C#TAR @ FAR=1e-5#94.47%$Face Verification#IJB-C#training dataset#MS1MV2$Face Verification#IJB-C#model#R100$Face Verification#IJB-C#TAR @ FAR=1e-3#97.51$Face Verification#IJB-C#TAR @ FAR=1e-4#96.33%$Face Identification#MegaFace#Accuracy#99.27%$Face Identification#MegaFace#Accuracy#98.82%$Face Identification#MegaFace#Accuracy#98.03%
1708.07517v2.pdf	Face Verification#IJB-B#TAR @ FAR=0.01#96.5%$Face Verification#IJB-A#TAR @ FAR=0.01#90.1%$Facial Landmark Detection#300W#Mean Error Rate#0.1043$Face Identification#IJB-B#Accuracy#91.1%$Face Identification#IJB-A#Accuracy#91.4%
1810.09951v1.pdf	Face Verification#IJB-B#TAR @ FAR=0.01#96.4%$Face Verification#IJB-A#TAR @ FAR=0.01#97.2%
1710.08092v2.pdf	Face Verification#IJB-B#TAR @ FAR=0.01#95.6%$Face Verification#IJB-B#TAR @ FAR=0.001#90.8$Face Verification#IJB-C#TAR @ FAR=1e-2#96.7%$Face Verification#IJB-C#TAR @ FAR=1e-3#92.7%$Face Verification#IJB-C#training dataset#Vggface2$Face Verification#IJB-C#model#R50$Face Verification#IJB-A#TAR @ FAR=0.01#96.8%$Face Verification#IJB-A#TAR @ FAR=0.001#92.1$Face Verification#IJB-A#TAR @ FAR=0.1#0.99
2204.00964v1.pdf	Face Verification#IJB-B#TAR@FAR=0.0001#96.03$Face Verification#IJB-B#TAR@FAR=0.0001#95.84$Face Verification#IJB-B#TAR@FAR=0.0001#95.67$Face Verification#IJB-C#TAR @ FAR=1e-4#97.39%$Face Verification#IJB-C#TAR @ FAR=1e-4#97.09%$Face Verification#IJB-C#TAR @ FAR=1e-4#96.89%
1803.06524v2.pdf	Face Verification#YouTube Faces DB#Accuracy#98.12%$Face Verification#Labeled Faces in the Wild#Accuracy#99.03%
1801.09414v2.pdf	Face Verification#YouTube Faces DB#Accuracy#97.6%$Face Verification#MegaFace#Accuracy#96.65%$Face Verification#Labeled Faces in the Wild#Accuracy#99.73%$Face Identification#MegaFace#Accuracy#82.72%
1904.09658v4.pdf	Face Verification#YouTube Faces DB#Accuracy#97.36%$Face Verification#MegaFace#Accuracy#92.51%$Face Verification#Labeled Faces in the Wild#Accuracy#99.82%$Face Verification#IJB-C#TAR @ FAR=1e-2#97.17%$Face Verification#IJB-C#TAR @ FAR=1e-3#95.49%$Face Verification#IJB-C#training dataset#MS1M V2$Face Verification#IJB-C#model#SphereFace64$Face Verification#IJB-A#TAR @ FAR=0.01#97.5%$Face Verification#IJB-A#TAR @ FAR=0.001#95.25
1704.03373v1.pdf	Face Verification#YouTube Faces DB#Accuracy#96.17%
1807.08512v4.pdf	Face Verification#YouTube Faces DB#Accuracy#95.30%$Face Verification#Labeled Faces in the Wild#Accuracy#99.30%
1412.1265v1.pdf	Face Verification#YouTube Faces DB#Accuracy#93.2%$Face Verification#Oulu-CASIA#Accuracy#96.50$Face Verification#Labeled Faces in the Wild#Accuracy#99.47%
1612.04904v1.pdf	Face Verification#YouTube Faces DB#Accuracy#88.80%$Face Verification#Labeled Faces in the Wild#Accuracy#92.35%$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#2.33$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#2.05$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.84$3D Face Reconstruction#Florence#Average 3D Error#1.93
1905.00292v2.pdf	Face Verification#MegaFace#Accuracy#97.41%$Face Verification#Labeled Faces in the Wild#Accuracy#99.73%
1502.00873v1.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#99.53%
1803.00130v1.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#99.52%
1910.06562v3.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#99.30%$Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#63.57$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#-$Age And Gender Classification#Adience Age#Accuracy (5-fold)#57.66$Age And Gender Classification#Adience Gender#Accuracy (5-fold)#89.66$Continual Learning#CUBS (Fine-grained 6 Tasks)#Accuracy#83.59$Continual Learning#CUBS (Fine-grained 6 Tasks)#Pretrained#Yes$Continual Learning#Cifar100 (20 tasks)#Average Accuracy#80.9$Continual Learning#Flowers (Fine-grained 6 Tasks)#Accuracy#96.62$Continual Learning#Wikiart (Fine-grained 6 Tasks)#Accuracy#77.15$Continual Learning#Stanford Cars (Fine-grained 6 Tasks)#Accuracy#92.80$Continual Learning#Sketch (Fine-grained 6 Tasks)#Accuracy#80.33$Continual Learning#ImageNet (Fine-grained 6 Tasks)#Accuracy#75.81
1406.4773v1.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#99.15%
1609.03892v1.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#98.62%
1404.3840v3.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#98.52%
1804.03675v1.pdf	Face Verification#Labeled Faces in the Wild#Accuracy#94.9%$Face Verification#IJB-A#TAR @ FAR=0.01#53.507%$Face Verification#IJB-A#TAR @ FAR=0.001#18.768
2201.06945v2.pdf	Face Verification#IJB-C#TAR @ FAR=1e-4#95.64%$Face Verification#IJB-C#TAR @ FAR=1e-5#93.73%$Face Verification#IJB-C#TAR @ FAR=1e-6#90.24%$Face Verification#IJB-C#training dataset#MS1M V3$Face Verification#IJB-C#model#MobileFaceNet$Face Verification#IJB-C#TAR @ FAR=1e-4#95.48%$Face Verification#IJB-C#TAR @ FAR=1e-5#93.50%$Face Verification#IJB-C#TAR @ FAR=1e-6#89.82%
2103.06627v4.pdf	Face Verification#IJB-C#TAR @ FAR=1e-4#95.97%$Face Verification#IJB-C#TAR @ FAR=1e-5#90.36%$Face Verification#IJB-C#training dataset#MS1MV2$Face Verification#IJB-C#model#R100
2103.04098v1.pdf	Face Verification#IJB-C#TAR @ FAR=1e-4#97.7%$Face Verification#IJB-C#training dataset#WebFace42M$Face Verification#IJB-C#model#R100
2105.10375v5.pdf	Face Verification#IJB-C#TAR @ FAR=1e-4#97.31%$Face Verification#IJB-C#training dataset#WebFace42M$Face Verification#IJB-C#model#R100
2004.00288v1.pdf	Face Verification#IJB-C#TAR @ FAR=1e-4#96.1%
1807.09192v1.pdf	Face Verification#IJB-C#TAR @ FAR=1e-2#92.70%
1804.07573v4.pdf	Face Verification#2019_test set#99.46%#90
1703.09507v3.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#97%
1803.00839v1.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#94.40%$Face Identification#IJB-A#Accuracy#94.60%
1603.05474v4.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#94.10%
1603.03958v3.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#93.90%
1611.00851v1.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#92.20%
1604.05417v3.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#90%
1603.07057v2.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#88.60%
1508.01722v2.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#83.80%
1603.07388v1.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#78.70%
1507.07242v2.pdf	Face Verification#IJB-A#TAR @ FAR=0.01#73.30%
1804.09669v2.pdf	Disguised Face Verification#Disguised Faces in the Wild#GAR @0.1% FAR#23.25$Disguised Face Verification#Disguised Faces in the Wild#GAR @1% FAR#60.89$Disguised Face Verification#Disguised Faces in the Wild#GAR @10% FAR#98.99
1811.08837v1.pdf	Disguised Face Verification#Disguised Faces in the Wild#GAR @0.1% FAR#17.73$Disguised Face Verification#Disguised Faces in the Wild#GAR @1% FAR#33.76
2210.10473v2.pdf	Face Swapping#AFLW2000-3D#ID retrieval#98.5$Face Swapping#AFLW2000-3D#pose#14.97$Face Swapping#AFLW2000-3D#exp embedding L2#7.07$Face Swapping#AFLW2000-3D#ID retrieval#97.95$Face Swapping#AFLW2000-3D#pose#5.86$Face Swapping#AFLW2000-3D#exp embedding L2#5.74$Face Swapping#AFLW2000-3D#ID retrieval#97.65$Face Swapping#AFLW2000-3D#pose#5.82$Face Swapping#AFLW2000-3D#exp embedding L2#4.13$Face Swapping#AFLW2000-3D#ID retrieval#97.10$Face Swapping#AFLW2000-3D#pose#5.75$Face Swapping#AFLW2000-3D#exp embedding L2#4.15$Face Swapping#FaceForensics++#ID retrieval#98.84$Face Swapping#FaceForensics++#pose#2.04$Face Swapping#FaceForensics++#exp embedding L2#7.97$Face Swapping#FaceForensics++#ID retrieval#98.19$Face Swapping#FaceForensics++#pose#2.15$Face Swapping#FaceForensics++#exp embedding L2#5.70$Face Swapping#FaceForensics++#ID retrieval#98.54$Face Swapping#FaceForensics++#pose#2.24$Face Swapping#FaceForensics++#exp embedding L2#8.52
2005.05535v5.pdf	Face Swapping#FaceForensics++#pose#1.12$Face Swapping#FaceForensics++#SSIM#0.73$Face Swapping#FaceForensics++#perceptual loss#0.39$Face Swapping#FaceForensics++#verification#0.61$Face Swapping#FaceForensics++#landmarks#0.73$Face Swapping#FaceForensics++#pose#4.75$Face Swapping#FaceForensics++#SSIM#0.71$Face Swapping#FaceForensics++#perceptual loss#0.41$Face Swapping#FaceForensics++#verification#0.69$Face Swapping#FaceForensics++#landmarks#1.15$Face Swapping#FaceForensics++#pose#6.01$Face Swapping#FaceForensics++#SSIM#0.65$Face Swapping#FaceForensics++#perceptual loss#0.5$Face Swapping#FaceForensics++#verification#0.66$Face Swapping#FaceForensics++#landmarks#0.35
2106.06340v1.pdf	Face Swapping#FaceForensics++#pose#1.22$Face Swapping#FaceForensics++#ID retrieval#96.57
2106.09965v1.pdf	Face Swapping#FaceForensics++#ID retrieval#98.48$Face Swapping#FaceForensics++#pose#2.63
2105.04932v2.pdf	Face Swapping#FaceForensics++#ID retrieval#90.83$Face Swapping#FaceForensics++#pose#2.64$Face Swapping#FaceForensics++#expression#2.96
2102.11464v1.pdf	Face Swapping#FaceForensics++#FID#3.51$Face Swapping#FaceForensics++#FID#3.81$Face Swapping#FaceForensics++#FID#4.05$Face Swapping#FaceForensics++#FID#4.29$Face Swapping#FaceForensics++#FID#4.35
2205.04442v1.pdf	Facial Expression Recognition#RAF-DB#Overall Accuracy#87.54$Facial Expression Recognition#RAF-DB#Avg. Accuracy#77.30
1905.04075v2.pdf	Facial Expression Recognition#RAF-DB#Overall Accuracy#86.9$Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#-$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#59.5$Facial Expression Recognition#FERPlus#Accuracy(pretrained)#89.16$Facial Expression Recognition#SFEW#Accuracy#56.4
2105.03790v1.pdf	Facial Expression Recognition#RAF-DB#Avg. Accuracy#78$Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#65.40
1811.05027v2.pdf	Facial Expression Recognition#RAF-DB#Avg. Accuracy#77.5$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#60.40
1910.04855v1.pdf	Facial Expression Recognition#RAF-DB#Avg. Accuracy#76$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#63
1509.05371v2.pdf	Facial Expression Recognition#MMI#Accuracy#98.63%
1902.08788v2.pdf	Facial Expression Recognition#MMI#Accuracy#82.74%$Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#61.52$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#-
1805.04855v1.pdf	Facial Expression Recognition#Real-World Affective Faces#Accuracy#87.0%$Facial Expression Recognition#Static Facial Expressions in the Wild#Accuracy#58.14%
2110.15028v1.pdf	Facial Expression Recognition#Real-World Affective Faces#Accuracy#79.26%
1609.06591v2.pdf	Facial Expression Recognition#CK+#Accuracy (8 emotion)#96.8$Facial Expression Recognition#CK+#Accuracy (7 emotion)#-$Facial Expression Recognition#CK+#Accuracy (6 emotion)#98.6
2107.03107v4.pdf	Facial Expression Recognition#CK+#Accuracy (8 emotion)#-$Facial Expression Recognition#CK+#Accuracy (7 emotion)#99.8$Facial Expression Recognition#JAFFE#Accuracy#94.83$Facial Expression Recognition#RaFD#Accuracy#87.22$Facial Expression Recognition#SFEW#Accuracy#54.29
1907.00193v2.pdf	Facial Expression Recognition#CK+#Accuracy (7 emotion)#99.7$Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#51.181%
2105.06421v3.pdf	Facial Expression Recognition#CK+#Accuracy (7 emotion)#98.23$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#61.72$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#61.32$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#61.09$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#60.35$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#60.34$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#55.36$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#54.98$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#52.46
1902.01019v1.pdf	Facial Expression Recognition#CK+#Accuracy (7 emotion)#98$Facial Expression Recognition#JAFFE#Accuracy#92.8$Facial Expression Recognition#FERG#Accuracy#99.3$Facial Expression Recognition#FER2013#Accuracy#70.02
1505.04026v1.pdf	Facial Expression Recognition#JAFFE#Accuracy#91.8
2012.13912v1.pdf	Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#65.5%$Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#63.7%$Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#61.1%$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#53.925$Facial Expression Recognition#FER+#Accuracy#89.257
2207.10299v2.pdf	Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#65.32%
2103.17107.pdf	Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#59.27$Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#65.74$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#61.32
2008.02655v2.pdf	Facial Expression Recognition#Acted Facial Expressions In The Wild (AFEW)#Accuracy(on validation set)#55.17%
1701.01879v2.pdf	Facial Expression Recognition#Cohn-Kanade#Accuracy#88.7%
2109.07270v4.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#65.69$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#62.09
2103.09154v2.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#65.4$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#61.60
1804.10892v7.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#63.31$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#59.58$Facial Expression Recognition#FERPlus#Accuracy(pretrained)#87.76$Facial Expression Recognition#FER+#Accuracy#87.76$Facial Expression Recognition#FER2013#Accuracy#75.42
2001.06338v1.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#-$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#59.3$Facial Expression Recognition#FER+#Accuracy#87.15
1708.03985v4.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#-$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#58.0
2106.03487v2.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#66.46
1807.11215v2.pdf	Facial Expression Recognition#AffectNet#Accuracy (7 emotion)#61.7$Facial Expression Recognition#AffectNet#Accuracy (8 emotion)#-
2103.16554v2.pdf	Facial Expression Recognition#BP4D#ICC#0.719$Facial Expression Recognition#DISFA#ICC#0.598$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.57$Face Alignment#COFW#NME#3.32$Face Alignment#AFLW-19#NME_diag (%, Full)#1.55$3D Face Reconstruction#AFLW2000-3D#Mean NME#3.42%
1808.05561v1.pdf	Facial Expression Recognition#FERPlus#Accuracy(pretrained)#88.88
1610.02255v1.pdf	Facial Expression Recognition#Static Facial Expressions in the Wild#Accuracy#54.82%
1710.03144v3.pdf	Facial Expression Recognition#SFEW#Accuracy#52.52
1307.0414v1.pdf	Facial Expression Recognition#FER2013#Accuracy#76.82$Facial Expression Recognition#FER2013#Accuracy#74.14$Facial Expression Recognition#FER2013#Accuracy#67.48
2111.07224v2.pdf	Facial Expression Recognition#FER2013#Accuracy#74.42
2105.03588v1.pdf	Facial Expression Recognition#FER2013#Accuracy#73.28
1612.02903v1.pdf	Facial Expression Recognition#FER2013#Accuracy#72.7$Facial Expression Recognition#FER2013#Accuracy#72.4$Facial Expression Recognition#FER2013#Accuracy#71.6
1911.03281v1.pdf	Facial Expression Recognition#Oulu-CASIA#Accuracy (10-fold)#89.6
1607.06997v2.pdf	Facial Expression Recognition#Oulu-CASIA#Accuracy (10-fold)#84.59
1802.00542v1.pdf	3D Facial Expression Recognition#2017_test set#14 gestures accuracy#2$3D Face Reconstruction#REALY (side-view)#@nose#2.508 (±0.491)$3D Face Reconstruction#REALY (side-view)#all#2.476$3D Face Reconstruction#REALY (side-view)#@mouth#2.160 (±0.448)$3D Face Reconstruction#REALY (side-view)#@forehead#3.393 (±1.076)$3D Face Reconstruction#REALY (side-view)#@cheek#1.842 (±0.609)$3D Face Reconstruction#REALY#@nose#2.509 (±0.486)$3D Face Reconstruction#REALY#@mouth#1.912 (±0.450)$3D Face Reconstruction#REALY#@forehead#3.084 (±1.005)$3D Face Reconstruction#REALY#@cheek#1.717 (±0.590)$3D Face Reconstruction#REALY#all#2.306
1602.00172v2.pdf	Smile Recognition#DISFA#Accuracy#99.45%
2110.09772v2.pdf	Face Alignment#AFLW#Mean NME#4.06$Face Alignment#AFLW2000-3D#Mean NME#2.65%$Face Alignment#AFLW2000-3D#Mean NME#3.41%$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.59$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.31$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.27$3D Face Reconstruction#REALY (side-view)#@nose#2.008 (±0.526)$3D Face Reconstruction#REALY (side-view)#all#2.008$3D Face Reconstruction#REALY (side-view)#@mouth#1.725 (±0.533)$3D Face Reconstruction#REALY (side-view)#@forehead#2.638 (±0.719)$3D Face Reconstruction#REALY (side-view)#@cheek#1.662 (±0.627)$3D Face Reconstruction#REALY#@nose#2.026 (±0.532)$3D Face Reconstruction#REALY#@mouth#1.731 (±0.502)$3D Face Reconstruction#REALY#@forehead#2.679 (±0.741)$3D Face Reconstruction#REALY#@cheek#1.647 (±0.622)$3D Face Reconstruction#REALY#all#2.021$Head Pose Estimation#AFLW2000#MAE#3.35
2009.09960v2.pdf	Face Alignment#AFLW#Mean NME#4.43$Face Alignment#AFLW2000-3D#Mean NME#3.51%$3D Face Reconstruction#Stirling-HQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#1.91$3D Face Reconstruction#AFLW2000-3D#Mean NME#3.56%$3D Face Reconstruction#Stirling-LQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#2.10$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.57$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.39$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.23$3D Face Reconstruction#REALY (side-view)#@nose#1.883 (±0.499)$3D Face Reconstruction#REALY (side-view)#all#1.943$3D Face Reconstruction#REALY (side-view)#@mouth#1.642 (±0.501)$3D Face Reconstruction#REALY (side-view)#@forehead#2.465 (±0.622)$3D Face Reconstruction#REALY (side-view)#@cheek#1.781 (±0.636)$3D Face Reconstruction#Florence#Mean NME#3.56$3D Face Reconstruction#REALY#@nose#1.903 (±0.517)$3D Face Reconstruction#REALY#@mouth#1.597 (±0.478)$3D Face Reconstruction#REALY#@forehead#2.447 (±0.647)$3D Face Reconstruction#REALY#@cheek#1.757 (±0.642)$3D Face Reconstruction#REALY#all#1.926
1804.01005v1.pdf	Face Alignment#AFLW#Mean NME#4.55$Face Alignment#300W#NME_inter-ocular (%, Full)#5.63$Face Alignment#300W#NME_inter-ocular (%, Common)#5.09$Face Alignment#300W#NME_inter-ocular (%, Challenge)#8.07$Face Alignment#300W#NME_inter-pupil (%, Full)#7.01$Face Alignment#300W#NME_inter-pupil (%, Common)#6.15$Face Alignment#300W#NME_inter-pupil (%, Challenge)#10.59$Face Alignment#AFLW2000-3D#Mean NME#3.79%
2004.02980v1.pdf	Face Alignment#300W (Common)#NME#2.76$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.37$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#57.7$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#3.12$Face Alignment#Menpo#NME (box)#2.04$Face Alignment#Menpo#AUC (box)#71.9$Face Alignment#MERL-RAV#NME (box)#1.61$Face Alignment#MERL-RAV#AUC@7 (box)#77.08$Face Alignment#300W Split 2#NME (box)#2.24$Face Alignment#300W Split 2#AUC@7 (box)#68.3$Face Alignment#AFLW-19#NME_diag (%, Full)#1.39$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.19$Face Alignment#AFLW-19#NME_box (%, Full)#2.28$Face Alignment#AFLW-19#AUC_box@0.07 (%, Full)#68.0$Face Alignment#COFW-68#NME (box)#2.57$Face Alignment#COFW-68#AUC@7 (box)#63.4$Face Alignment#COFW-68#NME (box)#2.75$Face Alignment#COFW-68#AUC@7 (box)#60.8
2112.03109v3.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#2.88$Face Alignment#300W#NME_inter-ocular (%, Common)#2.50$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.42$Face Alignment#300W#NME_inter-pupil (%, Full)#4.05$Face Alignment#300W#NME_inter-pupil (%, Common)#3.46$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.38$Face Alignment#300W#NME_inter-ocular (%, Full)#2.93$Face Alignment#300W#NME_inter-ocular (%, Common)#2.56$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.45$Face Alignment#300W#NME_inter-pupil (%, Full)#4.11$Face Alignment#300W#NME_inter-pupil (%, Common)#3.53$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.42$Face Alignment#WFLW#NME_inter-ocular (%, all)#3.96$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#61.16$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#1.76$Face Alignment#AFLW-19#NME_diag (%, Full)#0.943$Face Alignment#AFLW-19#NME_diag (%, Frontal)#0.821$Face Alignment#AFLW-19#NME_box (%, Full)#1.334$Face Alignment#AFLW-19#AUC_box@0.07 (%, Full)#81.3$Face Parsing#LaPa#Mean F1#93.88$Face Parsing#CelebAMask-HQ#Mean F1#89.56
2109.05721v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#2.93$Face Alignment#300W#NME_inter-ocular (%, Common)#2.53$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.58$Face Alignment#300W#NME_inter-pupil (%, Full)#4.08$Face Alignment#300W#NME_inter-pupil (%, Common)#3.51$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.47$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.14$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#60.22$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.72
2111.02360v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#2.94$Face Alignment#300W#NME_inter-ocular (%, Common)#2.61$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.13$Face Alignment#WFLW#NME_inter-ocular (%, all)#3.72$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#63.1$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#1.55$Face Alignment#COFW#Mean Error Rate#3.02%$Face Alignment#AFLW-19#NME_diag (%, Full)#1.31$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.12$Face Alignment#AFLW-19#NME_box (%, Full)#2.14$Face Alignment#AFLW-19#AUC_box@0.07 (%, Full)#70.0
2210.07233v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#2.99$Face Alignment#300W#NME_inter-ocular (%, Common)#2.59$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.66$Face Alignment#300W#NME_inter-pupil (%, Full)#4.20$Face Alignment#300W#NME_inter-pupil (%, Common)#3.59$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.73$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.06$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#60.56$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.08$Face Alignment#MERL-RAV#NME (box)#1.51$Face Alignment#MERL-RAV#AUC@7 (box)#78.47$Face Alignment#300W Split 2#NME (box)#2.03$Face Alignment#300W Split 2#AUC@7 (box)#71.0$Face Alignment#300W Split 2#NME (inter-ocular)#3.43$Face Alignment#300W Split 2#AUC@8 (inter-ocular)#57.27$Face Alignment#300W Split 2#FR@8 (inter-ocular)#0.67$Face Alignment#COFW-68#NME (box)#2.52$Face Alignment#COFW-68#AUC@7 (box)#64.1$Face Alignment#COFW-68#NME (inter-ocular)#3.93$Facial Landmark Detection#300W#NME#2.99$Pose Estimation#MERL-RAV#MAE mean (º)#2.39$Pose Estimation#MERL-RAV#MAE yaw (º)#3.23$Pose Estimation#MERL-RAV#MAE pitch (º)#2.24$Pose Estimation#MERL-RAV#MAE roll (º)#1.71$Pose Estimation#300W (Full)#MAE mean (º)#1.29$Pose Estimation#300W (Full)#MAE yaw (º)#1.41$Pose Estimation#300W (Full)#MAE pitch (º)#1.70$Pose Estimation#300W (Full)#MAE roll (º)#0.77$Head Pose Estimation#WFLW#MAE mean (º)#1.52$Head Pose Estimation#WFLW#MAE yaw (º)#1.78$Head Pose Estimation#WFLW#MAE pitch (º)#1.86$Head Pose Estimation#WFLW#MAE roll (º)#0.93
1904.07399v3.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.07$Face Alignment#300W#NME_inter-ocular (%, Common)#2.72$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.52$Face Alignment#300W#NME_inter-pupil (%, Full)#4.31$Face Alignment#300W#NME_inter-pupil (%, Common)#3.77$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.52$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.36$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#57.19$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.84
2104.03100v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.09$Face Alignment#300W#NME_inter-ocular (%, Common)#2.65$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.89$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.08$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#60.5$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.60$Face Alignment#COFW#Mean Error Rate#3.21%
1902.01831v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.13$Face Alignment#300W#NME_inter-ocular (%, Common)#2.69$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.92$Face Alignment#300W#NME_inter-pupil (%, Full)#4.39$Face Alignment#300W#NME_inter-pupil (%, Common)#3.73$Face Alignment#300W#NME_inter-pupil (%, Challenge)#7.10$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.68$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#55.44$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#5.04$Face Alignment#COFW#Mean Error Rate#5.11%$Face Alignment#300W Split 2#NME (inter-ocular)#3.73$Face Alignment#300W Split 2#AUC@8 (inter-ocular)#53.94$Face Alignment#300W Split 2#FR@8 (inter-ocular)#2.33$Facial Landmark Detection#AFLW-Full#Mean NME#2.01$Facial Landmark Detection#300W#NME#3.13
2203.06541v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.17$Face Alignment#300W#NME_inter-ocular (%, Common)#2.75$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.90$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.14$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#59.5$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.76$Face Alignment#COFW#Mean Error Rate#3.32$Face Alignment#COFW-68#NME (inter-ocular)#4.10
2010.09035v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.30$Face Alignment#300W#NME_inter-ocular (%, Common)#2.93$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.84$Face Alignment#300W#NME_inter-pupil (%, Full)#4.63$Face Alignment#300W#NME_inter-pupil (%, Common)#4.06$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.98$Facial Landmark Detection#300W#NME#3.30
1904.04514v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.32$Face Alignment#300W#NME_inter-ocular (%, Common)#2.87$Face Alignment#300W#NME_inter-ocular (%, Challenge)#5.15$Face Alignment#COFW#Mean Error Rate#3.45%$Face Alignment#AFLW-19#NME_diag (%, Full)#1.57$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.46$Semantic Segmentation#ADE20K#Validation mIoU#43.2$Semantic Segmentation#ADE20K val#mIoU#42.99$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.6%$Semantic Segmentation#LIP val#mIoU#55.90%
1904.02549v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.39$Face Alignment#300W#NME_inter-ocular (%, Common)#2.93$Face Alignment#300W#NME_inter-ocular (%, Challenge)#5.26$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.62$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#56.3$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#4.84
1706.01789v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.44$Face Alignment#300W#NME_inter-ocular (%, Common)#3.09$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.88$Face Alignment#300W#NME_inter-pupil (%, Full)#4.83$Face Alignment#300W#NME_inter-pupil (%, Common)#4.29$Face Alignment#300W#NME_inter-pupil (%, Challenge)#7.05$Face Alignment#300W Split 2#NME (inter-ocular)#4.30$Face Alignment#300W Split 2#AUC@8 (inter-ocular)#47.00$Face Alignment#300W Split 2#FR@8 (inter-ocular)#2.67
1805.10483v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.49$Face Alignment#300W#NME_inter-ocular (%, Common)#2.98$Face Alignment#300W#NME_inter-ocular (%, Challenge)#5.19$Face Alignment#300W#NME_inter-pupil (%, Full)#4.12$Face Alignment#300W#NME_inter-pupil (%, Common)#3.42$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.98$Face Alignment#WFLW#NME_inter-ocular (%, all)#5.27$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#53.2$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#7.56$Face Alignment#AFLW-19#NME_diag (%, Full)#1.25$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.14$Face Alignment#AFLW-19#NME_diag (%, Full)#1.85$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.62
2007.03221v3.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.72$Face Alignment#300W#NME_inter-ocular (%, Common)#3.12$Face Alignment#300W#NME_inter-ocular (%, Challenge)#6.19$Face Alignment#AFLW-Full#Mean NME#1.56$Face Alignment#WFLW#NME_inter-ocular (%, all)#4.32$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#57.69$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#2.96$Face Alignment#AFLW-19#NME_diag (%, Full)#1.56$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.38$Facial Landmark Detection#AFLW-Front#Mean NME#1.38$Facial Landmark Detection#AFLW-Full#Mean NME#1.56$Facial Landmark Detection#300W#NME#3.12$Facial Landmark Detection#300W (Full)#Mean NME#3.72
2203.15835v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.75$Face Alignment#300W#NME_inter-ocular (%, Common)#3.36$Face Alignment#300W#NME_inter-ocular (%, Challenge)#5.36$Face Alignment#COFW#Mean Error Rate#3.47%
1911.10448v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#3.82$Face Alignment#300W#NME_inter-ocular (%, Common)#3.36$Face Alignment#300W#NME_inter-ocular (%, Challenge)#5.74$Face Alignment#AFLW-19#NME_box (%, Full)#1.84
2111.07047v1.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#4.06$Face Alignment#300W#NME_inter-ocular (%, Common)#3.56$Face Alignment#300W#NME_inter-ocular (%, Challenge)#6.13$Face Alignment#COFW#Mean Error Rate#3.81%$Face Alignment#COFW#Mean Error Rate#4.11%
2103.00119v3.pdf	Face Alignment#300W#NME_inter-ocular (%, Full)#4.59$Face Alignment#300W#NME_inter-ocular (%, Common)#3.88$Face Alignment#300W#NME_inter-ocular (%, Challenge)#7.35$Face Alignment#300W#NME_inter-ocular (%, Full)#5.50$Face Alignment#300W#NME_inter-ocular (%, Common)#4.82$Face Alignment#300W#NME_inter-ocular (%, Challenge)#8.2$Face Alignment#WFLW#NME_inter-ocular (%, all)#10.77$Face Alignment#WFLW#NME_inter-ocular (%, all)#9.41$Pose Estimation#300W (Full)#MAE yaw (º)#1.62$Pose Estimation#300W (Full)#MAE pitch (º)#1.80$Pose Estimation#300W (Full)#MAE roll (º)#1.24$Head Pose Estimation#WFLW#MAE yaw (º)#2.97$Head Pose Estimation#WFLW#MAE roll (º)#2.21$Head Pose Estimation#COFW#MAE yaw (º)#2.91$Head Pose Estimation#COFW#MAE pitch (º)#2.72
2109.15102v2.pdf	Face Alignment#300W#NME_inter-ocular (%, Common)#3.09$Face Alignment#300W#NME_inter-ocular (%, Challenge)#4.86$Face Parsing#LaPa#Mean F1#90.9$Face Parsing#LaPa#Mean F1#90.1$Face Parsing#Helen#Mean F1#92$Face Parsing#Helen#Mean F1#91.6
1903.10661v1.pdf	Face Alignment#300W#NME_inter-pupil (%, Full)#4.02$Face Alignment#300W#NME_inter-pupil (%, Common)#3.45$Face Alignment#300W#NME_inter-pupil (%, Challenge)#6.38
1711.06753v5.pdf	Face Alignment#300W#NME_inter-pupil (%, Full)#4.04$Face Alignment#300W#NME_inter-pupil (%, Common)#3.27$Face Alignment#300W#NME_inter-pupil (%, Challenge)#7.18$Face Alignment#WFLW#NME_inter-ocular (%, all)#5.11$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#55.4$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#6.00$Face Alignment#AFLW-19#NME_diag (%, Full)#1.65$Face Alignment#AFLW-19#NME_box (%, Full)#3.56$Face Alignment#AFLW-19#AUC_box@0.07 (%, Full)#53.5
1803.06598v1.pdf	Face Alignment#300W#NME_inter-pupil (%, Full)#5.04$Face Alignment#300W#NME_inter-pupil (%, Common)#4.29$Face Alignment#300W#NME_inter-pupil (%, Challenge)#8.14
1703.00862v2.pdf	Face Alignment#AFLW-Full#Mean NME#2.85
1703.07332v3.pdf	Face Alignment#300-VW (C)#AUC0.07#64.1%$Face Alignment#LS3D-W Balanced#AUC0.07#72.3%$Head Pose Estimation#BIWI#MAE (trained with other data)#7.882$Head Pose Estimation#AFLW2000#MAE#9.116
1803.07835v1.pdf	Face Alignment#AFLW-LFPA#Mean NME#2.93%$Face Alignment#AFLW2000-3D#Mean NME#3.62%$3D Face Reconstruction#Stirling-HQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#2.06$3D Face Reconstruction#AFLW2000-3D#Mean NME#3.9625%$3D Face Reconstruction#Stirling-LQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#2.38$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.98$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.88$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.50$3D Face Reconstruction#REALY (side-view)#@nose#1.868 (±0.510)$3D Face Reconstruction#REALY (side-view)#all#2.032$3D Face Reconstruction#REALY (side-view)#@mouth#1.856 (±0.607)$3D Face Reconstruction#REALY (side-view)#@forehead#2.445 (±0.570)$3D Face Reconstruction#REALY (side-view)#@cheek#1.960 (±0.731)$3D Face Reconstruction#Florence#Mean NME#3.7551%$3D Face Reconstruction#REALY#@nose#1.923 (±0.518)$3D Face Reconstruction#REALY#@mouth#1.838 (±0.637)$3D Face Reconstruction#REALY#@forehead#2.429 (±0.588)$3D Face Reconstruction#REALY#@cheek#1.863 (±0.698)$3D Face Reconstruction#REALY#all#2.013
1709.01442v1.pdf	Face Alignment#AFLW-LFPA#Mean NME#3.86%$Face Alignment#AFLW2000-3D#Mean NME#4.50%$3D Face Reconstruction#AFLW2000-3D#Mean NME#5.6454%
1808.04803v1.pdf	Face Alignment#AFLW-LFPA#NME#3.02$Pose Estimation#MPII Human Pose#PCKh-0.5#81.3
2106.03021v1.pdf	Face Alignment#AFLW2000-3D#Mean NME#3.46%$3D Face Reconstruction#AFLW2000-3D#Mean NME#3.25%$3D Face Reconstruction#REALY (side-view)#@nose#1.771 (±0.521)$3D Face Reconstruction#REALY (side-view)#all#1.958$3D Face Reconstruction#REALY (side-view)#@mouth#1.560 (±0.462)$3D Face Reconstruction#REALY (side-view)#@forehead#2.490 (±0.566)$3D Face Reconstruction#REALY (side-view)#@cheek#2.010 (±0.715)$3D Face Reconstruction#REALY#@nose#1.791 (±0.542)$3D Face Reconstruction#REALY#@mouth#1.591 (±0.488)$3D Face Reconstruction#REALY#@forehead#2.413 (±0.537)$3D Face Reconstruction#REALY#@cheek#1.856 (±0.701)$3D Face Reconstruction#REALY#all#1.913$Head Pose Estimation#AFLW2000-3D#Average 3D Error#3.82
1903.09359v2.pdf	Face Alignment#AFLW2000-3D#Mean NME#3.53%
1707.05653v2.pdf	Face Alignment#AFLW2000-3D#Mean NME#4.49%
1511.07212v1.pdf	Face Alignment#AFLW2000-3D#Mean NME#4.94%$Face Alignment#AFLW2000#Error rate#8.250$3D Face Reconstruction#AFLW2000-3D#Mean NME#5.3695%$3D Face Reconstruction#Florence#Mean NME#6.3833%$Facial Landmark Detection#300W#NME#5.76$Facial Landmark Detection#300W#NME#7.01$Head Pose Estimation#BIWI#MAE (trained with other data)#19.068$Head Pose Estimation#AFLW2000#MAE#7.393
2202.02299v1.pdf	Face Alignment#AFLW2000-3D#Mean NME#2.56$Face Alignment#COFW#Mean Error Rate#5.04%$Face Alignment#COFW#Recall at 80% precision (Landmarks Visibility)#72.12$Face Alignment#COFW#Mean Error Rate#5.65%$Pose Estimation#300W (Full)#MAE mean (º)#1.56$Head Pose Estimation#BIWI#MAE (trained with other data)#3.66$Head Pose Estimation#AFLW2000-3D#MAE yaw (º)#3.78$Head Pose Estimation#AFLW#MAE#3.22
1908.06440v1.pdf	Face Alignment#WFLW#NME_inter-ocular (%, all)#4.39$Face Alignment#WFLW#AUC_inter-ocular@0.1 (%, all)#59.13$Face Alignment#WFLW#FR_inter-ocular@0.1(%, all)#4.08
1609.09545v1.pdf	Face Alignment#3DFAW#CVGTCE#3.4767%$Face Alignment#3DFAW#GTE#4.5623
1908.08239v1.pdf	Face Alignment#CelebA + AFLW Unaligned#MOS#3.73$Face Alignment#CelebA + AFLW Unaligned#MS-SSIM#0.897$Face Alignment#CelebA + AFLW Unaligned#PSNR#22.96$Face Alignment#CelebA + AFLW Unaligned#SSIM#0.695$Face Alignment#CelebA Aligned#MOS#3.73$Face Alignment#CelebA Aligned#MS-SSIM#0.902$Face Alignment#CelebA Aligned#PSNR#22.66$Face Alignment#CelebA Aligned#SSIM#0.685
1812.01936v1.pdf	Face Alignment#COFW#Mean Error Rate#5.55%$Face Alignment#IBUG#Mean Error Rate#6.73%
1802.06713v3.pdf	Face Alignment#COFW#Mean Error Rate#5.77%
1804.03786v3.pdf	Face Alignment#AFLW2000#Error rate#4.70
1808.01558v2.pdf	Face Alignment#AFLW2000#Error rate#5.38
2208.10808v1.pdf	Face Alignment#300W Split 2#NME (box)#2.05$Face Alignment#300W Split 2#AUC@7 (box)#70.9
2010.08722v1.pdf	Face Alignment#AFLW-19#NME_diag (%, Full)#1.38$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.19
1803.04108v4.pdf	Face Alignment#AFLW-19#NME_diag (%, Full)#1.91$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.85$Face Alignment#AFLW-19#NME_box (%, Full)#4.04$Face Alignment#AFLW-19#AUC_box@0.07 (%, Full)#54.0$Facial Landmark Detection#AFLW-Front#Mean NME#1.85$Facial Landmark Detection#AFLW-Full#Mean NME#1.91$Facial Landmark Detection#300W#NME#3.98
1611.05396v2.pdf	Face Alignment#AFLW-19#NME_diag (%, Full)#2.21$Face Alignment#AFLW-19#NME_diag (%, Frontal)#1.81
1903.11633v2.pdf	Face Alignment#AFLW-19#NME_box (%, Full)#1.97
2004.08190v6.pdf	Face Alignment#COFW-68#NME (inter-ocular)#4.22
1908.07919v2.pdf	Face Alignment#COFW-68#NME (inter-ocular)#5.06$Semantic Segmentation#DADA-seg#mIoU#27.5$Semantic Segmentation#Cityscapes val#mIoU#81.1$Semantic Segmentation#SynPASS#mIoU#34.09%$Semantic Segmentation#PASCAL Context#mIoU#54.0$Semantic Segmentation#PASCAL Context#mIoU#54$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.6$Thermal Image Segmentation#MFN Dataset#mIOU#51.7$Object Detection#COCO test-dev#box AP#47.3$Object Detection#COCO test-dev#AP50#65.9$Object Detection#COCO test-dev#AP75#51.2$Object Detection#COCO test-dev#APS#28.0$Object Detection#COCO test-dev#APM#49.7$Object Detection#COCO test-dev#APL#59.8$Object Detection#COCO test-dev#Hardware Burden#15G$Object Detection#COCO test-dev#Operations per network pass#71.7G$Object Detection#COCO test-dev#box AP#46.1$Object Detection#COCO test-dev#AP50#64.0$Object Detection#COCO test-dev#AP75#50.3$Object Detection#COCO test-dev#APS#27.1$Object Detection#COCO test-dev#APM#48.6$Object Detection#COCO test-dev#APL#58.3$Object Detection#COCO test-dev#Operations per network pass#61.8G$Object Detection#COCO test-dev#box AP#43.5$Object Detection#COCO test-dev#AP75#46.5$Object Detection#COCO test-dev#APS#22.2$Object Detection#COCO test-dev#APL#57.8$Object Detection#COCO test-dev#Hardware Burden#16G$Object Detection#COCO test-dev#Operations per network pass#21.7G$Object Detection#COCO test-dev#box AP#42.4$Object Detection#COCO test-dev#AP50#63.6$Object Detection#COCO test-dev#AP75#46.4$Object Detection#COCO test-dev#APS#24.9$Object Detection#COCO test-dev#APM#44.6$Object Detection#COCO test-dev#APL#53.0$Object Detection#COCO test-dev#Operations per network pass#20.8G$Object Detection#COCO test-dev#box AP#40.5$Object Detection#COCO test-dev#AP50#59.3$Object Detection#COCO test-dev#APS#23.4$Object Detection#COCO test-dev#APM#42.6$Object Detection#COCO test-dev#APL#51.0$Object Detection#COCO test-dev#Operations per network pass#27.3G$Object Detection#COCO test-dev#AP50#62.5$Object Detection#COCO test-dev#AP75#48.6$Object Detection#COCO test-dev#APL#56.3$Object Detection#COCO test-dev#Operations per network pass#50.6G$Object Detection#COCO test-dev#APS#26.0$Object Detection#COCO test-dev#APM#47.3$Object Detection#COCO minival#box AP#47.0$Object Detection#COCO minival#APS#28.8$Object Detection#COCO minival#APM#50.3$Object Detection#COCO minival#APL#62.2$Object Detection#COCO minival#box AP#46.0$Object Detection#COCO minival#APS#27.5$Object Detection#COCO minival#APL#60.1$Object Detection#COCO minival#box AP#45.3$Object Detection#COCO minival#APS#27.0$Object Detection#COCO minival#APM#48.4$Object Detection#COCO minival#APL#59.5$Object Detection#COCO minival#box AP#44.6$Object Detection#COCO minival#AP50#62.7$Object Detection#COCO minival#AP75#48.7$Object Detection#COCO minival#APS#26.3$Object Detection#COCO minival#APM#48.1$Object Detection#COCO minival#APL#58.5$Object Detection#COCO minival#box AP#43.7$Object Detection#COCO minival#AP50#61.7$Object Detection#COCO minival#AP75#47.7$Object Detection#COCO minival#APS#25.6$Object Detection#COCO minival#APM#46.5$Object Detection#COCO minival#APL#57.4$Object Detection#COCO minival#box AP#43.1$Object Detection#COCO minival#APS#26.6$Object Detection#COCO minival#APM#46.0$Object Detection#COCO minival#box AP#42.3$Object Detection#COCO minival#APS#25.0$Object Detection#COCO minival#APM#45.4$Object Detection#COCO minival#box AP#41.8$Object Detection#COCO minival#AP50#62.8$Object Detection#COCO minival#AP75#45.9$Object Detection#COCO minival#APM#44.7$Object Detection#COCO minival#APL#54.6$Object Detection#COCO minival#box AP#41.3$Object Detection#COCO minival#AP50#59.2$Object Detection#COCO minival#AP75#44.9$Object Detection#COCO minival#APS#23.7$Object Detection#COCO minival#APM#44.2$Object Detection#COCO minival#APL#54.1$Object Detection#COCO minival#box AP#40.9$Object Detection#COCO minival#AP50#61.8$Object Detection#COCO minival#AP75#44.8$Object Detection#COCO minival#APS#24.4$Object Detection#COCO minival#APM#43.7$Object Detection#COCO minival#APL#53.3$Object Detection#COCO minival#box AP#39.2$Object Detection#COCO minival#APM#41.7$Object Detection#COCO minival#APL#51.0$Object Detection#COCO minival#box AP#38.0$Object Detection#COCO minival#AP50#58.9$Object Detection#COCO minival#AP75#41.5$Object Detection#COCO minival#APS#22.6$Object Detection#COCO minival#APM#40.8$Object Detection#COCO minival#APL#49.6$Object Detection#COCO minival#APS#26.1$Object Detection#COCO minival#APM#47.9$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.668$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.579$Dichotomous Image Segmentation#DIS-TE1#MAE#0.088$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.742$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.797$Dichotomous Image Segmentation#DIS-TE1#HCE#262$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.747$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.664$Dichotomous Image Segmentation#DIS-TE2#MAE#0.087$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.784$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.840$Dichotomous Image Segmentation#DIS-TE2#HCE#555$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.784$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.700$Dichotomous Image Segmentation#DIS-TE3#MAE#0.080$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.805$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.869$Dichotomous Image Segmentation#DIS-TE3#HCE#1049$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.772$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.687$Dichotomous Image Segmentation#DIS-TE4#MAE#0.092$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.792$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.854$Dichotomous Image Segmentation#DIS-TE4#HCE#3864$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.726$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.641$Dichotomous Image Segmentation#DIS-VD#MAE#0.095$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.767$Dichotomous Image Segmentation#DIS-VD#E-measure#0.824$Dichotomous Image Segmentation#DIS-VD#HCE#1560$Instance Segmentation#BDD100K#AP#22.5$Instance Segmentation#BDD100K val#AP#22.5$Instance Segmentation#COCO minival#mask AP#41.0
2003.00418v1.pdf	Talking Face Generation#LRW#LMD#0.60$Talking Face Generation#LRW#SSIM#0.96
2004.09169v1.pdf	Talking Head Generation#VoxCeleb2 - 8-shot learning#FID#24.9$Talking Head Generation#VoxCeleb2 - 1-shot learning#FID#35.0
1905.08233v2.pdf	Talking Head Generation#VoxCeleb2 - 8-shot learning#FID#42.2$Talking Head Generation#VoxCeleb1 - 32-shot learning#FID#29.5$Talking Head Generation#VoxCeleb1 - 8-shot learning#FID#38.0$Talking Head Generation#VoxCeleb1 - 1-shot learning#FID#43.0$Talking Head Generation#VoxCeleb2 - 32-shot learning#FID#30.6$Talking Head Generation#VoxCeleb2 - 1-shot learning#FID#48.5
1912.06078v1.pdf	Talking Head Generation#100 sleep nights of 8 caregivers#10%#12
2008.10174v1.pdf	Talking Head Generation#VoxCeleb2 - 1-shot learning#LPIPS#0.358$Talking Head Generation#VoxCeleb2 - 1-shot learning#SSIM#0.508$Talking Head Generation#VoxCeleb2 - 1-shot learning#CSIM#0.653$Talking Head Generation#VoxCeleb2 - 1-shot learning#Normalized Pose Error#43.3$Talking Head Generation#VoxCeleb2 - 1-shot learning#inference time (ms)#4$Talking Head Generation#VoxCeleb2 - 1-shot learning#LPIPS#0.311$Talking Head Generation#VoxCeleb2 - 1-shot learning#SSIM#0.553$Talking Head Generation#VoxCeleb2 - 1-shot learning#CSIM#0.638$Talking Head Generation#VoxCeleb2 - 1-shot learning#Normalized Pose Error#47.8$Talking Head Generation#VoxCeleb2 - 1-shot learning#inference time (ms)#13$Talking Head Generation#VoxCeleb2 - 1-shot learning#LPIPS#0.368$Talking Head Generation#VoxCeleb2 - 1-shot learning#SSIM#0.419$Talking Head Generation#VoxCeleb2 - 1-shot learning#CSIM#0.604$Talking Head Generation#VoxCeleb2 - 1-shot learning#Normalized Pose Error#46.1$Talking Head Generation#VoxCeleb2 - 1-shot learning#inference time (ms)#22
2008.10010v1.pdf	Unconstrained Lip-synchronization#LRW#LSE-D#6.774$Unconstrained Lip-synchronization#LRW#LSE-C#7.263$Unconstrained Lip-synchronization#LRW#FID#2.475$Unconstrained Lip-synchronization#LRW#LSE-D#6.512$Unconstrained Lip-synchronization#LRW#LSE-C#7.49$Unconstrained Lip-synchronization#LRW#FID#3.189$Unconstrained Lip-synchronization#LRS3#LSE-D#6.986$Unconstrained Lip-synchronization#LRS3#LSE-C#7.574$Unconstrained Lip-synchronization#LRS3#FID#4.35$Unconstrained Lip-synchronization#LRS3#LSE-D#6.652$Unconstrained Lip-synchronization#LRS3#LSE-C#7.887$Unconstrained Lip-synchronization#LRS3#FID#4.844$Unconstrained Lip-synchronization#LRS2#LSE-D#6.469$Unconstrained Lip-synchronization#LRS2#FID#4.446$Unconstrained Lip-synchronization#LRS2#LSE-D#6.386$Unconstrained Lip-synchronization#LRS2#LSE-C#7.781$Unconstrained Lip-synchronization#LRS2#FID#4.887
2012.04012v2.pdf	3D Face Reconstruction#Stirling-HQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#1.89$3D Face Reconstruction#Stirling-LQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#1.91$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.38$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.18$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.09$3D Face Reconstruction#REALY (side-view)#@nose#1.903 (±1.050)$3D Face Reconstruction#REALY (side-view)#all#2.107$3D Face Reconstruction#REALY (side-view)#@mouth#2.472 (±1.079)$3D Face Reconstruction#REALY (side-view)#@forehead#2.423 (±0.720)$3D Face Reconstruction#REALY (side-view)#@cheek#1.630 (±1.135)$3D Face Reconstruction#REALY (side-view)#@nose#2.286 (±1.103)$3D Face Reconstruction#REALY (side-view)#all#2.261$3D Face Reconstruction#REALY (side-view)#@mouth#2.684 (±1.041)$3D Face Reconstruction#REALY (side-view)#@forehead#2.519 (±0.718)$3D Face Reconstruction#REALY (side-view)#@cheek#1.555 (±0.822)$3D Face Reconstruction#REALY#@nose#1.697 (±0.355)$3D Face Reconstruction#REALY#@mouth#2.516 (±0.839)$3D Face Reconstruction#REALY#@forehead#2.394 (±0.576)$3D Face Reconstruction#REALY#@cheek#1.479 (±0.535)$3D Face Reconstruction#REALY#all#2.010$3D Face Reconstruction#REALY#@nose#2.138 (±0.461)$3D Face Reconstruction#REALY#@mouth#2.802 (±0.868)$3D Face Reconstruction#REALY#@forehead#2.457 (±0.559)$3D Face Reconstruction#REALY#@cheek#1.443 (±0.498)$3D Face Reconstruction#REALY#all#2.210
1905.06817v1.pdf	3D Face Reconstruction#Stirling-HQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#2.02$3D Face Reconstruction#Stirling-LQ (FG2018 3D face reconstruction challenge)#Mean Reconstruction Error (mm)#2.08$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.53$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.31$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.21$3D Face Reconstruction#REALY (side-view)#@nose#1.921 (±0.451)$3D Face Reconstruction#REALY (side-view)#all#2.256$3D Face Reconstruction#REALY (side-view)#@mouth#1.994 (±0.604)$3D Face Reconstruction#REALY (side-view)#@forehead#3.081 (±0.950)$3D Face Reconstruction#REALY (side-view)#@cheek#2.027 (±0.710)$3D Face Reconstruction#REALY#@nose#1.934 (±0.458)$3D Face Reconstruction#REALY#@mouth#2.074 (±0.616)$3D Face Reconstruction#REALY#@forehead#2.995 (±0.908)$3D Face Reconstruction#REALY#@cheek#2.028 (±0.720)$3D Face Reconstruction#REALY#all#2.258
2105.14857v2.pdf	3D Face Reconstruction#AFLW2000-3D#Mean NME#3.51%
2204.06607v2.pdf	3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.11$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#0.92$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#0.90
2106.09614v2.pdf	3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.30$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.10$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.04
1903.08527v2.pdf	3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.41$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.21$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.11$3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.54$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.29$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.23$3D Face Reconstruction#REALY (side-view)#@nose#1.749 (±0.343)$3D Face Reconstruction#REALY (side-view)#all#1.657$3D Face Reconstruction#REALY (side-view)#@mouth#1.411 (±0.395)$3D Face Reconstruction#REALY (side-view)#@forehead#2.074 (±0.486)$3D Face Reconstruction#REALY (side-view)#@cheek#1.528 (±0.517)$3D Face Reconstruction#REALY#@nose#1.719 (±0.354)$3D Face Reconstruction#REALY#@mouth#1.368 (±0.439)$3D Face Reconstruction#REALY#@forehead#2.015 (±0.449)$3D Face Reconstruction#REALY#@cheek#1.528 (±0.501)$3D Face Reconstruction#REALY#all#1.657
2103.15432v3.pdf	3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.57$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#1.31$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.26
2007.12494v1.pdf	3D Face Reconstruction#NoW Benchmark#Mean Reconstruction Error (mm)#1.87$3D Face Reconstruction#NoW Benchmark#Stdev Reconstruction Error (mm)#2.63$3D Face Reconstruction#NoW Benchmark#Median Reconstruction Error#1.31$3D Face Reconstruction#REALY (side-view)#@nose#1.827 (±0.383)$3D Face Reconstruction#REALY (side-view)#all#1.787$3D Face Reconstruction#REALY (side-view)#@mouth#1.409 (±0.418)$3D Face Reconstruction#REALY (side-view)#@forehead#2.248 (±0.508)$3D Face Reconstruction#REALY (side-view)#@cheek#1.665 (±0.644)$3D Face Reconstruction#REALY#@nose#1.827 (±0.383)$3D Face Reconstruction#REALY#@mouth#1.409 (±0.418)$3D Face Reconstruction#REALY#@forehead#2.248 (±0.508)$3D Face Reconstruction#REALY#@cheek#1.665 (±0.644)$3D Face Reconstruction#REALY#all#1.787
1703.07834v2.pdf	3D Face Reconstruction#Florence#Mean NME#5.2667%
1902.05978v2.pdf	3D Face Reconstruction#Florence#Average 3D Error#0.95$3D Face Reconstruction#REALY#@nose#1.928 (±0.490)$3D Face Reconstruction#REALY#@mouth#1.812 (±0.544)$3D Face Reconstruction#REALY#@forehead#2.402 (±0.545)$3D Face Reconstruction#REALY#@cheek#1.329 (±0.504)$3D Face Reconstruction#REALY#all#1.868
1806.06098v1.pdf	3D Face Reconstruction#Florence#Average 3D Error#1.50
1701.05360v1.pdf	3D Face Reconstruction#Florence#Average 3D Error#1.82
2110.04800v1.pdf	3D Face Reconstruction#REALY#@nose#2.779 (±0.835)$3D Face Reconstruction#REALY#@mouth#1.448 (±0.406)$3D Face Reconstruction#REALY#@forehead#2.384 (±0.578)$3D Face Reconstruction#REALY#@cheek#1.456 (±0.485)$3D Face Reconstruction#REALY#all#2.017
1904.04933v1.pdf	3D Face Reconstruction#REALY#@nose#2.936 (±0.810)$3D Face Reconstruction#REALY#@mouth#2.375 (±0.599)$3D Face Reconstruction#REALY#@forehead#4.582 (±1.488)$3D Face Reconstruction#REALY#@cheek#1.918 (±0.801)$3D Face Reconstruction#REALY#all#2.953
2203.13122v1.pdf	Age Estimation#FGNET#MAE#2.23$Age Estimation#ChaLearn 2015#MAE#2.95$Age Estimation#UTKFace#MAE#4.37$Age Estimation#CACD#MAE#4.41$Age Estimation#MORPH Album2#MAE#2.00$Age Estimation#MORPH Album2#CS#95.0$Age And Gender Classification#Adience Age#Accuracy (5-fold)#62.6
1904.05059v2.pdf	Age Estimation#FGNET#MAE#2.95$Age Estimation#FGNET#MAE#52
1804.02740v1.pdf	Age Estimation#FGNET#MAE#3.62$Age Estimation#FGNET#MAE#4.58$Age Estimation#MORPH#MAE#1.48
2106.11145v2.pdf	Age Estimation#IMDB-Clean#Average mean absolute error#4.68$Age Estimation#KANFace#Average mean absolute error#6.81
2007.01771v2.pdf	Age Estimation#ChaLearn 2016#MAE#3.452$Age Estimation#ChaLearn 2015#MAE#3.135$Age Estimation#MORPH Album2#MAE#1.969
1611.01731v2.pdf	Age Estimation#ChaLearn 2015#MAE#3.51$Age Estimation#MORPH Album2#MAE#2.42±0.01$Age Estimation#MORPH Album2#MAE#2.42$Semantic Segmentation#PASCAL VOC 2012#Mean IoU#67.1$Semantic Segmentation#PASCAL VOC 2011#Mean IoU#67.6$Head Pose Estimation#Pointing'04#MAE#4.64$Head Pose Estimation#AFLW#MAE#9.78$Head Pose Estimation#BJUT-3D#MAE#0.09$Multi-Label Classification#PASCAL VOC 2007#mAP#93.4$Multi-Label Classification#PASCAL VOC 2012#mAP#92.4
2006.15864v1.pdf	Age Estimation#UTKFace#MAE#4.55$Head Pose Estimation#BIWI#MAE (trained with BIWI data)#2.54$Historical Color Image Dating#HCI#MAE#0.67
1901.07884v7.pdf	Age Estimation#UTKFace#MAE#5.39$Age Estimation#CACD#MAE#5.35$Age Estimation#MORPH Album2#MAE#2.59$Age Estimation#AFAD#MAE#3.48
1908.10737v1.pdf	Age Estimation#CACD#MAE#4.60
2103.09882v1.pdf	Age Estimation#MORPH Album2#MAE#1.13$Age Estimation#MORPH Album2#MAE#2.53
1708.09687v2.pdf	Age Estimation#MORPH Album2#MAE#2.52$Age Estimation#MORPH Album2#MAE#2.87$Age And Gender Classification#Adience Age#Accuracy (5-fold)#56.01
1908.01070v1.pdf	Facial Landmark Detection#300W#NME#3.31
1908.02116v3.pdf	Facial Landmark Detection#300W#NME#3.49$Facial Landmark Detection#300W (Full)#Mean NME#3.49
1707.06286v1.pdf	Facial Landmark Detection#300W#NME#6.30
1807.00966v2.pdf	Facial Landmark Detection#300-VW (C)#AUC0.08 private#59.39$Facial Landmark Detection#300-VW (C)#AUC0.08 private#58.22
1801.09242v1.pdf	Facial Landmark Detection#AFLW2000-3D#GTE#7.28$3D Facial Landmark Localization#AFLW2000-3D#GTE#7.28$3D Facial Landmark Localization#3DFAW#CVGTCE#3.46$3D Facial Landmark Localization#3DFAW#GTE#4.35
2103.15812v3.pdf	Unsupervised Facial Landmark Detection#CelebA#MSE normalized by inter-ocular distance#5.85%$Image Quality Assessment#CelebA-HQ#FID-50k#11.94
2205.15821v2.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#2.43
1806.07823v2.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#2.54$Unsupervised Facial Landmark Detection#AFLW (Zhang CVPR 2018 crops)#NME#6.31
1908.06427v1.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#2.86$Unsupervised Facial Landmark Detection#AFLW-MTFL#NME#7.53$Unsupervised Facial Landmark Detection#300W#NME#4.65$Unsupervised Facial Landmark Detection#AFLW (Zhang CVPR 2018 crops)#NME#6.54
1804.04412v1.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#3.15$Unsupervised Facial Landmark Detection#AFLW (Zhang CVPR 2018 crops)#NME#6.58
1808.06882v1.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#3.44$Unsupervised Facial Landmark Detection#300W#NME#5.71
1706.02932v2.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#4.02$Unsupervised Facial Landmark Detection#AFLW-MTFL#NME#10.99$Unsupervised Facial Landmark Detection#300W#NME#8.23$Unsupervised Facial Landmark Detection#AFLW (Zhang CVPR 2018 crops)#NME#10.14
1806.06503v1.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#5.45
1705.02193v2.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#6.67$Unsupervised Facial Landmark Detection#AFLW-MTFL#NME#10.53$Unsupervised Facial Landmark Detection#300W#NME#7.97
1408.3967v4.pdf	Unsupervised Facial Landmark Detection#MAFL#NME#7.95
2010.05222v2.pdf	Face Identification#MegaFace#Accuracy#99.10%
2002.02609v2.pdf	Facial Inpainting#FFHQ#LPIPS#0.0457$Facial Inpainting#FFHQ#PSNR#26.49$Facial Inpainting#FFHQ#SSIM#0.8985
1812.07741v1.pdf	Facial Inpainting#VggFace2#PSNR#27.81$Facial Inpainting#WebFace#PSNR#27.22
1805.10445v2.pdf	Age And Gender Classification#Adience Age#Accuracy (5-fold)#67.47
1710.02985v1.pdf	Age And Gender Classification#Adience Age#Accuracy (5-fold)#66.74
2011.07607v2.pdf	Age And Gender Classification#Adience Age#Accuracy (5-fold)#61
2108.08186v2.pdf	Age And Gender Classification#Adience Age#Accuracy (5-fold)#60.86$Age And Gender Classification#Adience Gender#Accuracy (5-fold)#90.66
1806.02023v1.pdf	Age And Gender Classification#Adience Age#Accuracy (5-fold)#44.26$Age And Gender Classification#Adience Gender#Accuracy (5-fold)#85.16
2205.01782v2.pdf	Facial Action Unit Detection#DISFA#Average F1#63.1$Facial Action Unit Detection#DISFA#Average AUC#92.9$Facial Action Unit Detection#DISFA#Average F1#62.4$Facial Action Unit Detection#DISFA#Average AUC#92.1$Facial Action Unit Detection#BP4D#Average F1#65.5$Facial Action Unit Detection#BP4D#Average AUC#83.1$Facial Action Unit Detection#BP4D#Average F1#64.7$Facial Action Unit Detection#BP4D#Average AUC#82.6$Facial Action Unit Detection#BP4D#Average F1#62.6$Facial Action Unit Detection#BP4D#Average F1#59.1
1803.05588v2.pdf	Facial Action Unit Detection#DISFA#Average F1#56.0$Facial Action Unit Detection#BP4D#Average F1#60.0
1704.07863v2.pdf	Facial Action Unit Detection#BP4D#Average F1#63.0
1812.05788v2.pdf	Action Unit Detection#BP4D#Avg F1#63.1
1712.00899v4.pdf	Face Sketch Synthesis#CUFSF#FSIM#72.9%$Face Sketch Synthesis#CUFSF#FID#18.2$Face Sketch Synthesis#CUFSF#NLDA#78$Face Sketch Synthesis#CUFSF#FSIM#72.7%$Face Sketch Synthesis#CUFSF#FID#19.6$Face Sketch Synthesis#CUFSF#NLDA#78.1$Face Sketch Synthesis#CUFS#FSIM#71.6%$Face Sketch Synthesis#CUFS#FID#34.2$Face Sketch Synthesis#CUFS#NLDA#95.7$Face Sketch Synthesis#CUFS#FSIM#71.2%$Face Sketch Synthesis#CUFS#FID#39.7$Face Sketch Synthesis#CUFS#NLDA#95.6$Face Sketch Synthesis#CUFS#FID#32.8
1812.04929v2.pdf	Face Sketch Synthesis#CUFSF#FSIM#71.59%$Face Sketch Synthesis#CUFSF#SSIM#40.85%$Face Sketch Synthesis#CUFS#FSIM#72.56%$Face Sketch Synthesis#CUFS#SSIM#54.63%$Face Sketch Synthesis#CUHK#SSIM#63.28%$Face Sketch Synthesis#CUHK#FSIM#74.23%
1710.10182v2.pdf	Face Sketch Synthesis#CUHK#SSIM#61.56%$Face Sketch Synthesis#CUHK#FSIM#73.61%
2207.10077v2.pdf	Facial Attribute Classification#bFFHQ#Bias-Conflicting Accuracy#62.8$Action Recognition#BAR#Accuracy#69.88
2210.05247v1.pdf	Facial Attribute Classification#bFFHQ#Bias-Conflicting Accuracy#60.35
2108.10008v1.pdf	Facial Attribute Classification#bFFHQ#Bias-Conflicting Accuracy#58.87$Action Recognition#BAR#Accuracy#52.44
1908.04913v1.pdf	Facial Attribute Classification#FairFace#race-top1#93.7$Facial Attribute Classification#FairFace#gender-top1#94.2$Facial Attribute Classification#FairFace#age-top1#59.7
1803.07253v1.pdf	Facial Beauty Prediction#SCUT-FBP#MAE#0.2595$Facial Beauty Prediction#ECCV HotOrNot#Pearson Correlation#0.468
1801.06345v1.pdf	Facial Beauty Prediction#SCUT-FBP#MAE#0.3931
2007.13124v1.pdf	Autonomous Vehicles#ApolloCar3D#A3DP#20.21$Autonomous Driving#ApolloCar3D#A3DP#20.21$3D Car Instance Understanding#ApolloCar3D#A3DP#20.21$3D Reconstruction#ApolloCar3D#A3DP#20.21$Pose Estimation#ApolloCar3D#A3DP#20.21$Keypoint Detection#ApolloCar3D#A3DP#20.21$3D Pose Estimation#ApolloCar3D#A3DP#20.21$6D Pose Estimation#ApolloCar3D#A3DP#20.21$6D Pose Estimation using RGB#ApolloCar3D#A3DP#20.21$Vehicle Pose Estimation#ApolloCar3D#A3DP#20.21$3D Shape Reconstruction#ApolloCar3D#A3DP#20.21$3D Shape Reconstruction From A Single 2D Image#ApolloCar3D#A3DP#20.21$Vehicle Key-Point and Orientation Estimation#ApolloCar3D#A3DP#20.21
2104.09224v1.pdf	Autonomous Driving#Town05 Short#RC#86.91$Autonomous Driving#Town05 Short#RC#78.41$Autonomous Driving#Town05 Short#DS#54.52$Autonomous Driving#Town05 Long#RC#69.17$Autonomous Driving#Town05 Long#RC#56.36$Autonomous Driving#Town05 Long#DS#33.15$Autonomous Driving#CARLA Leaderboard#Driving Score#16.93$Autonomous Driving#CARLA Leaderboard#Route Completion#51.82$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.42
2207.14024v3.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#76.18$Autonomous Driving#CARLA Leaderboard#Route Completion#88.23$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.84
2206.08129v2.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#75.14$Autonomous Driving#CARLA Leaderboard#Route Completion#85.63$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.87
2203.11934v3.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#61.846$Autonomous Driving#CARLA Leaderboard#Route Completion#94.459$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.640
2205.15997v1.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#61.181$Autonomous Driving#CARLA Leaderboard#Route Completion#86.694$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.714$Autonomous Driving#CARLA Leaderboard#Driving Score#45.20$Autonomous Driving#CARLA Leaderboard#Route Completion#66.31$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.72
2111.08575v2.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#36.79$Autonomous Driving#CARLA Leaderboard#Route Completion#61.85$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.6$CARLA MAP Leaderboard#CARLA#Driving score#33.785$CARLA MAP Leaderboard#CARLA#Route completion#57.442$CARLA MAP Leaderboard#CARLA#Infraction penalty#0.568
2105.00636v3.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#31.37$Autonomous Driving#CARLA Leaderboard#Route Completion#57.65$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.56
1911.10868v2.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#24.98$Autonomous Driving#CARLA Leaderboard#Route Completion#46.97$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.52
2109.04456v1.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#21.83$Autonomous Driving#CARLA Leaderboard#Route Completion#41.71$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.65
1912.12294v1.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#8.94$Autonomous Driving#CARLA Leaderboard#Route Completion#17.54$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.73
1904.08980v1.pdf	Autonomous Driving#CARLA Leaderboard#Driving Score#5.37$Autonomous Driving#CARLA Leaderboard#Route Completion#14.40$Autonomous Driving#CARLA Leaderboard#Infraction penalty#0.55
2209.09723v1.pdf	Motion Forecasting#Argoverse 2 Motion Forecasting#brier-minFDE (K=6)#1.96$Motion Forecasting#Argoverse 2 Motion Forecasting#minFDE (K=6)#1.34$Motion Forecasting#Argoverse 2 Motion Forecasting#minADE (K=6)#0.72$Motion Forecasting#Argoverse 2 Motion Forecasting#MR (K=6)#0.17$Motion Forecasting#Argoverse 2 Motion Forecasting#minFDE (K=1)#4.48$Motion Forecasting#Argoverse 2 Motion Forecasting#minADE (K=1)#1.77$Motion Forecasting#Argoverse 2 Motion Forecasting#MR (K=1)#0.59$Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1179$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.5921$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.4548$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5499$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.806$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.1605$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9899$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.7899
2207.05844v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1186$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.636$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.6559$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5716$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.7676$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.1616$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9893$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.7408
2204.05859v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1094$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.4768$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.2515$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5322$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.7659$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.135$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9902$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.7564
2111.14973v3.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1324$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6235$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.6141$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5645$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.7897$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2144$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9876$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.7932
2207.00170v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1237$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.7111$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.7477$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5748$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8221$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2285$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9906$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.8394
2105.10968v2.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.0846$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6986$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.681$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5723$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8904$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2919$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.983$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.8601
2206.08809v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1303$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.5692$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.4284$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5496$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8123$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2227$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9865$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9172
2207.00255v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1528$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.7716$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.9031$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5984$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8607$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.3055$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9837$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9285
2103.03067v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1333$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.5752$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.4872$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5601$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8153$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2442$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9884$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9286
2109.06446v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1429$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.735$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.9007$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.6023$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8372$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2905$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9852$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9393
2206.14116v3.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1326$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6342$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.5643$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5671$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.8401$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.2493$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9844$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#1.9433
2101.06653v1.pdf	Motion Forecasting#Argoverse CVPR 2020#MR (K=6)#0.1232$Motion Forecasting#Argoverse CVPR 2020#minADE (K=1)#1.6852$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=1)#3.6916$Motion Forecasting#Argoverse CVPR 2020#MR (K=1)#0.5685$Motion Forecasting#Argoverse CVPR 2020#minADE (K=6)#0.9038$Motion Forecasting#Argoverse CVPR 2020#minFDE (K=6)#1.4526$Motion Forecasting#Argoverse CVPR 2020#DAC (K=6)#0.9903$Motion Forecasting#Argoverse CVPR 2020#brier-minFDE (K=6)#2.147
1909.11944v2.pdf	Multiple Object Forecasting#Citywalks#ADE#26.7$Multiple Object Forecasting#Citywalks#AIOU#54.3
2207.00186v2.pdf	CARLA MAP Leaderboard#CARLA#Driving score#22.80$CARLA MAP Leaderboard#CARLA#Route completion#47.22$CARLA MAP Leaderboard#CARLA#Infraction penalty#0.63
2010.12598v1.pdf	CARLA MAP Leaderboard#CARLA#Driving score#15.55$CARLA MAP Leaderboard#CARLA#Route completion#40.63$CARLA MAP Leaderboard#CARLA#Infraction penalty#0.47
1907.08320v1.pdf	Autonomous Flight (Dense Forest)#mtrl-auto-uav#NI#31
2111.00273v4.pdf	Pedestrian Detection#FLIR-aligned#mAP#40.0$Pedestrian Detection#LLVIP#AP#0.636$Pedestrian Detection#LLVIP#log average miss rate#5.40%$Multispectral Object Detection#FLIR-aligned#mAP#40.2$Multispectral Object Detection#FLIR-aligned#mAP50#78.7
2108.10831v3.pdf	Pedestrian Detection#LLVIP#AP#0.527$Pedestrian Detection#LLVIP#log average miss rate#22.59%$Pedestrian Detection#LLVIP#AP#0.466$Pedestrian Detection#LLVIP#log average miss rate#37.70%$Thermal Infrared Pedestrian Detection#LLVIP#AP#0.670$Thermal Infrared Pedestrian Detection#LLVIP#AP#0.582$Image-to-Image Translation#LLVIP#PSNR#10.769$Image-to-Image Translation#LLVIP#SSIM#0.1757$Image Generation#LLVIP#PSNR#10.769$Image Generation#LLVIP#SSIM#0.1757
2003.08799v7.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#7.5$Pedestrian Detection#CityPersons#Heavy MR^-2#33.9$Pedestrian Detection#CityPersons#Partial MR^-2#5.7$Pedestrian Detection#CityPersons#Bare MR^-2#6.2$Pedestrian Detection#CityPersons#Small MR^-2#8.0$Pedestrian Detection#CityPersons#Medium MR^-2#3.0$Pedestrian Detection#CityPersons#Large MR^-2#4.3$Pedestrian Detection#Caltech#Reasonable Miss Rate#1.76$Pedestrian Detection#Caltech#Heavy MR^-2#25.7
2203.02331v2.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#7.8$Pedestrian Detection#CityPersons#Heavy MR^-2#26.23$Pedestrian Detection#CityPersons#Small MR^-2#9.43$Pedestrian Detection#CityPersons#Test Time#0.44s/img$Pedestrian Detection#CityPersons#Reasonable MR^-2#8.7$Pedestrian Detection#CityPersons#Heavy MR^-2#32.6$Pedestrian Detection#CityPersons#Small MR^-2#11.3$Pedestrian Detection#Caltech#Reasonable Miss Rate#1.71$Pedestrian Detection#Caltech#Heavy MR^-2#20.42$Pedestrian Detection#Caltech#Reasonable Miss Rate#2.2$Pedestrian Detection#Caltech#Heavy MR^-2#38.7
2002.09053v2.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#9.3$Pedestrian Detection#CityPersons#Heavy MR^-2#46.3$Pedestrian Detection#CityPersons#Partial MR^-2#8.7$Pedestrian Detection#CityPersons#Bare MR^-2#5.6$Pedestrian Detection#CityPersons#Heavy MR^-2#42.5$Pedestrian Detection#CityPersons#Partial MR^-2#6.9$Pedestrian Detection#CityPersons#Bare MR^-2#4.9
2106.02426v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#10.08$Pedestrian Detection#Caltech#Reasonable Miss Rate#2.92
2210.12758v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#10.6$Pedestrian Detection#CityPersons#Heavy MR^-2#47.1$Pedestrian Detection#CityPersons#Partial MR^-2#10.3$Pedestrian Detection#CityPersons#Bare MR^-2#6.4$Object Detection#CrowdHuman (full body)#AP#89.6$Object Detection#CrowdHuman (full body)#mMR#40.3
1805.00123v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#10.67$Pedestrian Detection#Caltech#Reasonable Miss Rate#3.46$Object Detection#CrowdHuman (full body)#AP#84.95$Object Detection#CrowdHuman (full body)#mMR#50.49
2007.13376v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#10.8$Pedestrian Detection#CityPersons#Heavy MR^-2#53.0$Pedestrian Detection#CityPersons#Partial MR^-2#11.2$Pedestrian Detection#CityPersons#Bare MR^-2#6.6$Object Detection#CrowdHuman (full body)#AP#89.0$Object Detection#CrowdHuman (full body)#mMR#43.9
1904.02948v4.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#11.0$Pedestrian Detection#CityPersons#Heavy MR^-2#49.3$Pedestrian Detection#CityPersons#Partial MR^-2#10.4$Pedestrian Detection#CityPersons#Bare MR^-2#7.3$Pedestrian Detection#CityPersons#Small MR^-2#16.0$Pedestrian Detection#CityPersons#Medium MR^-2#3.7$Pedestrian Detection#CityPersons#Large MR^-2#6.5$Pedestrian Detection#CityPersons#Test Time#0.33s/img$Pedestrian Detection#Caltech#Reasonable Miss Rate#3.8$Pedestrian Detection#Caltech#Reasonable Miss Rate#4.5
1807.08407v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#12.8$Pedestrian Detection#CityPersons#Heavy MR^-2#55.7$Pedestrian Detection#CityPersons#Partial MR^-2#15.3$Pedestrian Detection#CityPersons#Bare MR^-2#6.7$Pedestrian Detection#Caltech#Reasonable Miss Rate#4.1
1711.07752v2.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#13.2$Pedestrian Detection#CityPersons#Heavy MR^-2#56.9$Pedestrian Detection#CityPersons#Partial MR^-2#16.8$Pedestrian Detection#CityPersons#Bare MR^-2#7.6$Pedestrian Detection#Caltech#Reasonable Miss Rate#4.0$Pedestrian Detection#Caltech#Reasonable Miss Rate#5.0
1807.01438v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#14.4$Pedestrian Detection#CityPersons#Heavy MR^-2#52.0$Pedestrian Detection#CityPersons#Partial MR^-2#15.9$Pedestrian Detection#CityPersons#Bare MR^-2#9.2$Pedestrian Detection#CityPersons#Reasonable MR^-2#15.5$Pedestrian Detection#CityPersons#Heavy MR^-2#53.6$Pedestrian Detection#CityPersons#Partial MR^-2#17.2$Pedestrian Detection#CityPersons#Bare MR^-2#10.0
1702.05693v1.pdf	Pedestrian Detection#CityPersons#Reasonable MR^-2#14.8$Pedestrian Detection#CityPersons#Small MR^-2#22.6$Pedestrian Detection#CityPersons#Medium MR^-2#6.7$Pedestrian Detection#CityPersons#Large MR^-2#8.0$Pedestrian Detection#CityPersons#Reasonable MR^-2#15.4$Pedestrian Detection#CityPersons#Small MR^-2#25.6$Pedestrian Detection#CityPersons#Medium MR^-2#7.2$Pedestrian Detection#CityPersons#Large MR^-2#7.9$Pedestrian Detection#Caltech#Reasonable Miss Rate#5.1$Pedestrian Detection#Caltech#Reasonable Miss Rate#5.8
2111.08974v3.pdf	Pedestrian Detection#TJU-Ped-campus#R (miss rate)#24.84$Pedestrian Detection#TJU-Ped-campus#RS (miss rate)#-$Pedestrian Detection#TJU-Ped-campus#HO (miss rate)#65.27$Pedestrian Detection#TJU-Ped-campus#R+HO (miss rate)#32.39$Pedestrian Detection#TJU-Ped-campus#ALL (miss rate)#34.87$Pedestrian Detection#TJU-Ped-traffic#R (miss rate)#19.73$Pedestrian Detection#TJU-Ped-traffic#RS (miss rate)#-$Pedestrian Detection#TJU-Ped-traffic#HO (miss rate)#60.05$Pedestrian Detection#TJU-Ped-traffic#R+HO (miss rate)#24.19$Pedestrian Detection#TJU-Ped-traffic#ALL (miss rate)#35.76
2003.09163v2.pdf	Pedestrian Detection#TJU-Ped-campus#R (miss rate)#25.73$Pedestrian Detection#TJU-Ped-campus#RS (miss rate)#-$Pedestrian Detection#TJU-Ped-campus#HO (miss rate)#66.38$Pedestrian Detection#TJU-Ped-campus#R+HO (miss rate)#33.63$Pedestrian Detection#TJU-Ped-campus#ALL (miss rate)#35.90$Pedestrian Detection#TJU-Ped-traffic#R (miss rate)#20.82$Pedestrian Detection#TJU-Ped-traffic#RS (miss rate)#-$Pedestrian Detection#TJU-Ped-traffic#HO (miss rate)#61.22$Pedestrian Detection#TJU-Ped-traffic#R+HO (miss rate)#25.28$Pedestrian Detection#TJU-Ped-traffic#ALL (miss rate)#36.94$Object Detection#CrowdHuman (full body)#AP#90.7$Object Detection#CrowdHuman (full body)#mMR#41.4
1612.03144v2.pdf	Pedestrian Detection#TJU-Ped-campus#R (miss rate)#27.92$Pedestrian Detection#TJU-Ped-campus#RS (miss rate)#67.52$Pedestrian Detection#TJU-Ped-campus#HO (miss rate)#73.14$Pedestrian Detection#TJU-Ped-campus#R+HO (miss rate)#35.67$Pedestrian Detection#TJU-Ped-campus#ALL (miss rate)#38.08$Pedestrian Detection#TJU-Ped-traffic#R (miss rate)#22.30$Pedestrian Detection#TJU-Ped-traffic#RS (miss rate)#35.19$Pedestrian Detection#TJU-Ped-traffic#HO (miss rate)#60.30$Pedestrian Detection#TJU-Ped-traffic#R+HO (miss rate)#26.71$Pedestrian Detection#TJU-Ped-traffic#ALL (miss rate)#37.78$Object Detection#COCO test-dev#box AP#36.2$Object Detection#COCO test-dev#Hardware Burden#2G$Object Detection#COCO minival#box AP#39.8$Object Detection#COCO minival#AP50#61.3$Object Detection#COCO minival#AP75#43.3$Object Detection#COCO minival#APS#22.9$Object Detection#COCO minival#APM#43.3$Object Detection#COCO minival#APL#52.6
1904.01355v5.pdf	Pedestrian Detection#TJU-Ped-campus#R (miss rate)#31.89$Pedestrian Detection#TJU-Ped-campus#RS (miss rate)#69.04$Pedestrian Detection#TJU-Ped-campus#HO (miss rate)#81.28$Pedestrian Detection#TJU-Ped-campus#R+HO (miss rate)#39.38$Pedestrian Detection#TJU-Ped-campus#ALL (miss rate)#41.62$Pedestrian Detection#TJU-Ped-traffic#R (miss rate)#24.35$Pedestrian Detection#TJU-Ped-traffic#RS (miss rate)#37.40$Pedestrian Detection#TJU-Ped-traffic#HO (miss rate)#63.73$Pedestrian Detection#TJU-Ped-traffic#R+HO (miss rate)#28.86$Pedestrian Detection#TJU-Ped-traffic#ALL (miss rate)#40.02$Object Detection#COCO test-dev#box AP#44.7$Object Detection#COCO test-dev#AP50#64.1$Object Detection#COCO test-dev#AP75#48.4$Object Detection#COCO test-dev#APS#27.6$Object Detection#COCO test-dev#APM#47.5$Object Detection#COCO test-dev#APL#55.6$Object Detection#COCO test-dev#box AP#43.2$Object Detection#COCO test-dev#AP50#62.8$Object Detection#COCO test-dev#AP75#46.6$Object Detection#COCO test-dev#APS#26.5$Object Detection#COCO test-dev#APM#46.2$Object Detection#COCO test-dev#APL#53.3$Object Detection#COCO test-dev#box AP#42.7$Object Detection#COCO test-dev#AP50#62.2$Object Detection#COCO test-dev#AP75#46.1$Object Detection#COCO test-dev#APS#26.0$Object Detection#COCO test-dev#APM#45.6$Object Detection#COCO test-dev#APL#52.6$Object Detection#COCO test-dev#box AP#42.0$Object Detection#COCO test-dev#AP50#60.4$Object Detection#COCO test-dev#AP75#45.3$Object Detection#COCO test-dev#APS#25.4$Object Detection#COCO test-dev#APM#45.0$Object Detection#COCO test-dev#APL#51.0$Object Detection#COCO minival#box AP#38.6$Object Detection#COCO minival#AP50#57.4$Object Detection#COCO minival#AP75#41.4$Object Detection#COCO minival#APS#22.3$Object Detection#COCO minival#APM#42.5$Object Detection#COCO minival#APL#49.8
1705.02757v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#5.5
1607.07032v2.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#7.3$Pedestrian Detection#Caltech#Reasonable Miss Rate#8.7
1706.08564v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#7.36
1610.03466v2.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#8.18
1510.08160v3.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#9.68
1603.00124v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#10.40
1507.05348v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#11.75
1810.00689v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#12.4
1511.08058v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#16.20
1501.05759v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#17.1
1412.0069v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#20.9
1501.05790v1.pdf	Pedestrian Detection#Caltech#Reasonable Miss Rate#23.3
1710.06288v1.pdf	Lane Detection#Caltech Lanes Washington#F1#0.869$Lane Detection#Caltech Lanes Cordova#F1#0.884
1504.01716v3.pdf	Lane Detection#Caltech Lanes Washington#F1#0.861$Lane Detection#Caltech Lanes Cordova#F1#0.866
2103.12040v4.pdf	Lane Detection#LLAMAS#F1#0.9601$Lane Detection#TuSimple#Accuracy#95.64%$Lane Detection#TuSimple#F1 score#96.49$Lane Detection#CULane#F1 score#77.41$Lane Detection#CULane#F1 score#75.63$Lane Detection#CULane#F1 score#74.24
2203.02431v1.pdf	Lane Detection#LLAMAS#F1#0.9517$Lane Detection#LLAMAS#F1#0.9491$Lane Detection#TuSimple#Accuracy#95.65%$Lane Detection#TuSimple#Accuracy#95.41%$Lane Detection#CULane#F1 score#75.57$Lane Detection#CULane#F1 score#73.67
2010.12035v2.pdf	Lane Detection#LLAMAS#F1#0.9374$Lane Detection#LLAMAS#F1#0.9354$Lane Detection#LLAMAS#F1#0.9346$Lane Detection#TuSimple#Accuracy#96.10%$Lane Detection#TuSimple#F1 score#96.06$Lane Detection#TuSimple#Accuracy#95.63%$Lane Detection#TuSimple#F1 score#96.77$Lane Detection#TuSimple#Accuracy#95.57%$Lane Detection#TuSimple#F1 score#96.71$Lane Detection#CULane#F1 score#77.02$Lane Detection#CULane#F1 score#76.68$Lane Detection#CULane#F1 score#75.13
2004.10924v2.pdf	Lane Detection#LLAMAS#F1#0.8840$Lane Detection#TuSimple#Accuracy#93.36%$Lane Detection#TuSimple#F1 score#90.62
2110.11048v2.pdf	Lane Detection#K-Lane#F1#82.12
2208.11434v1.pdf	Lane Detection#BDD100K#Accuracy#87.8%$Drivable Area Detection#BDD100K#mIoU#93.2
2203.09035v1.pdf	Lane Detection#BDD100K#Accuracy#85.4%$Drivable Area Detection#BDD100K#mIoU#90.5
2108.11250v7.pdf	Lane Detection#BDD100K#Accuracy#70.5%$Drivable Area Detection#BDD100K#mIoU#91.5
1908.00821v1.pdf	Lane Detection#BDD100K#Accuracy#36.6%$Lane Detection#TuSimple#Accuracy#96.64%$Lane Detection#TuSimple#F1 score#95.92$Lane Detection#CULane#F1 score#70.8
2110.04079v5.pdf	Lane Detection#TuSimple#Accuracy#98.19%$Lane Detection#TuSimple#F1-Measure#0.918
2203.12301v1.pdf	Lane Detection#TuSimple#Accuracy#96.93
2105.13680v1.pdf	Lane Detection#TuSimple#Accuracy#96.92$Lane Detection#CULane#F1 score#78.8
2203.10350v1.pdf	Lane Detection#TuSimple#Accuracy#96.9%$Lane Detection#TuSimple#F1 score#97.82$Lane Detection#TuSimple#Accuracy#96.82%$Lane Detection#TuSimple#F1 score#97.89$Lane Detection#TuSimple#F1 score#97.62$Lane Detection#CULane#F1 score#80.47$Lane Detection#CULane#F1 score#80.13$Lane Detection#CULane#F1 score#79.73$Lane Detection#CULane#F1 score#79.58
2008.13719v2.pdf	Lane Detection#TuSimple#Accuracy#96.82$Lane Detection#TuSimple#F1 score#96.93$Lane Detection#CULane#F1 score#75.3
2008.08311v2.pdf	Lane Detection#TuSimple#Accuracy#96.58%$Lane Detection#TuSimple#F1 score#96.38
2105.05003v2.pdf	Lane Detection#TuSimple#Accuracy#96.54%$Lane Detection#TuSimple#F1 score#97.24$Lane Detection#TuSimple#Accuracy#95.48%$Lane Detection#TuSimple#Accuracy#95.37%$Lane Detection#TuSimple#F1 score#96.98$Lane Detection#TuSimple#F1 score#97.01$Lane Detection#CULane#F1 score#79.48$Lane Detection#CULane#F1 score#78.74$Lane Detection#CULane#F1 score#78.14$Lane Detection#CurveLanes#F1 score#86.10$Lane Detection#CurveLanes#Precision#88.98$Lane Detection#CurveLanes#Recall#83.41$Lane Detection#CurveLanes#GFLOPs#44.9$Lane Detection#CurveLanes#FPS#48$Lane Detection#CurveLanes#F1 score#85.92$Lane Detection#CurveLanes#Precision#88.29$Lane Detection#CurveLanes#Recall#83.68$Lane Detection#CurveLanes#GFLOPs#19.7$Lane Detection#CurveLanes#FPS#109$Lane Detection#CurveLanes#F1 score#85.09$Lane Detection#CurveLanes#Precision#87.75$Lane Detection#CurveLanes#Recall#82.58$Lane Detection#CurveLanes#GFLOPs#10.3$Lane Detection#CurveLanes#FPS#154
1803.06459v1.pdf	Lane Detection#TuSimple#Accuracy#96.50%$Lane Detection#TuSimple#F1 score#94.31
1806.05525v2.pdf	Lane Detection#TuSimple#Accuracy#96.40%$Lane Detection#TuSimple#F1 score#96.26
1802.05591v1.pdf	Lane Detection#TuSimple#Accuracy#96.4%$Lane Detection#TuSimple#F1 score#94.80
1708.02551v1.pdf	Lane Detection#TuSimple#Accuracy#96.40%$Instance Segmentation#Cityscapes test#Average Precision#17.5$Multi-Human Parsing#MHP v1.0#AP 0.5#47.76%
1905.03704v1.pdf	Lane Detection#TuSimple#Accuracy#96.29%$Lane Detection#TuSimple#F1 score#95.23$Lane Detection#CULane#F1 score#68.8
2005.08630v1.pdf	Lane Detection#TuSimple#Accuracy#96.22%$Lane Detection#TuSimple#F1 score#96.58$Lane Detection#TuSimple#Accuracy#96.11%$Lane Detection#TuSimple#F1 score#96.37$Lane Detection#TuSimple#Accuracy#96.02%$Lane Detection#TuSimple#F1 score#96.25$Lane Detection#CULane#F1 score#74$Lane Detection#CULane#F1 score#71.9
2011.04233v2.pdf	Lane Detection#TuSimple#Accuracy#96.18$Lane Detection#TuSimple#F1 score#96.68
2203.15302v1.pdf	Lane Detection#TuSimple#Accuracy#95.62%$Lane Detection#CULane#F1 score#77.2$Lane Detection#CULane#F1 score#76.5
1907.01294v2.pdf	Lane Detection#TuSimple#Accuracy#95.24%$Lane Detection#TuSimple#F1 score#90.82
2204.07335v1.pdf	Lane Detection#TuSimple#F1 score#97.71$Lane Detection#TuSimple#F1 score#97.68$Lane Detection#TuSimple#F1 score#97.45$Lane Detection#CULane#F1 score#79.63$Lane Detection#CULane#F1 score#79.39$Lane Detection#CULane#F1 score#78.79
2203.04067v1.pdf	Lane Detection#CULane#F1 score#78.08$Lane Detection#CULane#F1 score#77.63
2105.05403v2.pdf	Lane Detection#CULane#F1 score#77.27
2007.12147v1.pdf	Lane Detection#CULane#F1 score#74.8$Lane Detection#CULane#F1 score#73.5$Lane Detection#CULane#F1 score#71.4$Lane Detection#CurveLanes#F1 score#82.29$Lane Detection#CurveLanes#Precision#91.11$Lane Detection#CurveLanes#Recall#75.03$Lane Detection#CurveLanes#GFLOPs#20.7$Lane Detection#CurveLanes#F1 score#81.8$Lane Detection#CurveLanes#Precision#93.49$Lane Detection#CurveLanes#Recall#72.71$Lane Detection#CurveLanes#GFLOPs#11.6$Lane Detection#CurveLanes#F1 score#81.12$Lane Detection#CurveLanes#Precision#93.58$Lane Detection#CurveLanes#Recall#71.59$Lane Detection#CurveLanes#GFLOPs#7.4$Lane Detection#CurveLanes#F1 score#78.47$Lane Detection#CurveLanes#Precision#86.33$Lane Detection#CurveLanes#Recall#72.91$Lane Detection#CurveLanes#GFLOPs#14.8$Lane Detection#CurveLanes#F1 score#65.02$Lane Detection#CurveLanes#Precision#76.13$Lane Detection#CurveLanes#Recall#56.74$Lane Detection#CurveLanes#GFLOPs#328.4$Lane Detection#CurveLanes#F1 score#50.31$Lane Detection#CurveLanes#Precision#63.6$Lane Detection#CurveLanes#Recall#41.6$Lane Detection#CurveLanes#GFLOPs#3.9
2002.06604v4.pdf	Lane Detection#CULane#F1 score#74.4
2102.07037v3.pdf	Lane Detection#CULane#F1 score#74.2
2110.11779v1.pdf	Lane Detection#CULane#F1 score#74.03
2004.05304v1.pdf	Lane Detection#CULane#F1 score#72.4$Semantic Segmentation#ApolloScape#mIoU#43.2
2004.11757v4.pdf	Lane Detection#CULane#F1 score#72.3$Lane Detection#CULane#F1 score#68.4
1712.06080v1.pdf	Lane Detection#CULane#F1 score#71.6
2009.08020v2.pdf	Lane Detection#DET#event-based F1 score#75.58$Lane Detection#DET#Average IOU#62.79
2203.11089v3.pdf	3D Lane Detection#OpenLane#All#47.8$3D Lane Detection#OpenLane#Up & Down#42.4$3D Lane Detection#OpenLane#Curve#52.8$3D Lane Detection#OpenLane#Extreme Weather#48.7$3D Lane Detection#OpenLane#Night#46.0$3D Lane Detection#OpenLane#Intersection#37.9$3D Lane Detection#OpenLane#Merge & Split#44.6$3D Lane Detection#OpenLane#All#40.2$3D Lane Detection#OpenLane#Up & Down#37.7$3D Lane Detection#OpenLane#Curve#43.2$3D Lane Detection#OpenLane#Extreme Weather#43.0$3D Lane Detection#OpenLane#Night#39.3$3D Lane Detection#OpenLane#Intersection#29.3$3D Lane Detection#OpenLane#Merge & Split#36.5$3D Lane Detection#OpenLane#All#29.7$3D Lane Detection#OpenLane#Up & Down#24.2$3D Lane Detection#OpenLane#Curve#31.1$3D Lane Detection#OpenLane#Extreme Weather#26.4$3D Lane Detection#OpenLane#Night#17.5$3D Lane Detection#OpenLane#Intersection#19.7$3D Lane Detection#OpenLane#Merge & Split#27.4
2102.03539v3.pdf	Traffic Sign Recognition#BelgaLogos#Accuracy#89.48$Traffic Sign Recognition#FlickrLogos-32#Accuracy#95.80$Traffic Sign Recognition#Chinese Traffic Sign Database#Accuracy#97.19$Traffic Sign Recognition#TopLogo-10#Accuracy#89.66$Traffic Sign Recognition#GTSRB#Accuracy#99.68%$Traffic Sign Recognition#Belgian Traffic Sign Classification#Accuracy#98.97$Traffic Sign Recognition#Tsinghua-Tencent 100K#Accuracy#99.53$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#91.09$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#89.14$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#87.73$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#96.28$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#94.73$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#82.99
1904.00649v1.pdf	Traffic Sign Recognition#Swedish traffic-sign dataset (STSD)#mAP@0.50#95.2$Traffic Sign Recognition#Swedish traffic-sign dataset (STSD)#mAP@0.50#94.3$Traffic Sign Recognition#DFG traffic-sign dataset#mAP@0.50#95.5$Traffic Sign Recognition#DFG traffic-sign dataset#mAP @0.5:0.95#84.4$Traffic Sign Recognition#DFG traffic-sign dataset#mAP@0.50#95.2$Traffic Sign Recognition#DFG traffic-sign dataset#mAP@0.50#93.0$Traffic Sign Recognition#DFG traffic-sign dataset#mAP @0.5:0.95#82.3$Traffic Sign Recognition#DFG traffic-sign dataset#mAP@0.50#92.4$Traffic Sign Recognition#DFG traffic-sign dataset#mAP @0.5:0.95#80.4$Traffic Sign Recognition#DFG traffic-sign dataset#mAP @0.5:0.95#82.0
1804.00497v3.pdf	Traffic Sign Recognition#GTSRB#Accuracy#98.9%
2202.08360v2.pdf	Traffic Sign Recognition#GTSRB#Accuracy#90.71%$Domain Generalization#ImageNet-A#Top-1 accuracy %#52.7$Domain Generalization#ImageNet-R#Top-1 Error Rate#43.9$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#45.6$Action Classification#Kinetics-700#Top-1 Accuracy#51.9$Image Classification#CIFAR-100#Percentage correct#81.53$Image Classification#Places205#Top 1 Accuracy#69.0$Image Classification#iNaturalist 2018#Top-1 Accuracy#84.7%$Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#10000M$Image Classification#DTD#Accuracy#80.5$Image Classification#SVHN#Percentage error#13.6$Image Classification#ImageNet ReaL#Accuracy#89.8%$Image Classification#ImageNet ReaL#Params#10000M$Image Classification#CLEVR/Count#Top 1 Accuracy#89.28$Image Classification#CLEVR/Count#Top 1 Accuracy#87.98$Image Classification#CLEVR/Dist#Top 1 Accuracy#74.98$Image Classification#CLEVR/Dist#Top 1 Accuracy#72.67$Image Classification#STL-10#Percentage correct#97.3$Image Classification#STL-10#PARAMS#10000M$Image Classification#ObjectNet#Top-1 Accuracy#60.2$Image Classification#ImageNet V2#Top 1 Accuracy#76.2$Image Classification#MNIST#Percentage error#0.58$Image Classification#MNIST#Accuracy#99.42$Image Classification#EuroSAT#Accuracy (%)#97.5$Image Classification#RESISC45#Top 1 Accuracy#95.61$Image Classification#RESISC45#Top 1 Accuracy#94.73$Image Classification#RESISC45#Top 1 Accuracy#93.97$Image Classification#RESISC45#Top 1 Accuracy#93.35$Image Classification#RESISC45#Top 1 Accuracy#92.7$Image Classification#RESISC45#Top 1 Accuracy#92.48$Image Classification#RESISC45#Top 1 Accuracy#89.77$Image Classification#RESISC45#Top 1 Accuracy#88.56$Image Classification#RESISC45#Top 1 Accuracy#85.4$Image Classification#KITTI-Dist#Top 1 Accuracy#78.34$Image Classification#Flowers-102#Accuracy#96.3$Image Classification#CIFAR-10#Percentage correct#90$Image Classification#Food-101#Accuracy (%)#90.3$Fine-Grained Image Classification#Stanford Cars#Accuracy#68.03%$Fine-Grained Image Classification#SUN397#Accuracy#80.0$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#9.0%$Fine-Grained Image Classification#Caltech-101#Accuracy#91.0$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#54.82%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#85.3%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#78.8%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#62.4%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#10000M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#85.8%$Meme Classification#Hateful Memes#ROC-AUC#0.734
1806.07987v2.pdf	Traffic Sign Recognition#Bosch Small Traffic Lights#MAP#0.46$Traffic Sign Recognition#Bosch Small Traffic Lights#MAP#0.45$Traffic Sign Recognition#Bosch Small Traffic Lights#MAP#0.41$Traffic Sign Recognition#Tsinghua-Tencent 100K#MAP#0.32$Traffic Sign Recognition#Tsinghua-Tencent 100K#MAP#0.31$Traffic Sign Recognition#Tsinghua-Tencent 100K#MAP#0.30
1910.04562v1.pdf	Pedestrian Attribute Recognition#PETA#Accuracy#79.52%$Pedestrian Attribute Recognition#RAP#Accuracy#68.17%$Pedestrian Attribute Recognition#PA-100K#Accuracy#77.08%
2005.11909v2.pdf	Pedestrian Attribute Recognition#PETA#Accuracy#79.52%$Pedestrian Attribute Recognition#PETA#Accuracy#79.14%$Pedestrian Attribute Recognition#PA-100K#Accuracy#79.44$Pedestrian Attribute Recognition#PA-100K#Accuracy#78.56
1709.09930v1.pdf	Pedestrian Attribute Recognition#PETA#Accuracy#76.13%$Pedestrian Attribute Recognition#RAP#Accuracy#65.39%$Pedestrian Attribute Recognition#PA-100K#Accuracy#72.19%
1608.06993v5.pdf	Pedestrian Attribute Recognition#UAV-Human#Gender#75.0$Pedestrian Attribute Recognition#UAV-Human#Hat#67.2$Pedestrian Attribute Recognition#UAV-Human#UCC#49.8$Pedestrian Attribute Recognition#UAV-Human#UCS#73.0$Pedestrian Attribute Recognition#UAV-Human#LCC#54.6$Pedestrian Attribute Recognition#UAV-Human#LCS#68.9$Pedestrian Attribute Recognition#UAV-Human#Backpack#63.9$Crowd Counting#UCF-QNRF#MAE#163$Image Classification#CIFAR-100#Percentage correct#82.82$Image Classification#CIFAR-100#Percentage correct#82.62$Image Classification#ImageNet#Top 1 Accuracy#77.85%$Image Classification#ImageNet#Top 5 Accuracy#93.88%$Image Classification#ImageNet#Top 1 Accuracy#77.42%$Image Classification#ImageNet#Top 5 Accuracy#93.66%$Image Classification#ImageNet#Top 1 Accuracy#76.2%$Image Classification#ImageNet#Top 5 Accuracy#93.15%$Image Classification#ImageNet#Top 1 Accuracy#74.98%$Image Classification#ImageNet#Top 5 Accuracy#92.29%$Image Classification#SVHN#Percentage error#1.59$Image Classification#GasHisSDB#Accuracy#96.90$Image Classification#GasHisSDB#Precision#99.91$Image Classification#GasHisSDB#F1-Score#98.38$Image Classification#CIFAR-10#Percentage correct#96.54$Breast Tumour Classification#PCam#AUC#0.921$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#94.41$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#96.90$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.87$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.30
1512.03385v1.pdf	Pedestrian Attribute Recognition#UAV-Human#Gender#74.7$Pedestrian Attribute Recognition#UAV-Human#Hat#65.2$Pedestrian Attribute Recognition#UAV-Human#UCC#44.4$Pedestrian Attribute Recognition#UAV-Human#UCS#68.9$Pedestrian Attribute Recognition#UAV-Human#LCC#49.7$Pedestrian Attribute Recognition#UAV-Human#LCS#69.3$Pedestrian Attribute Recognition#UAV-Human#Backpack#63.5$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#41.7$Synthetic-to-Real Translation#Syn2Real-C#Accuracy#52.4$Domain Adaptation#Office-31#Average Accuracy#76.1$Unsupervised Domain Adaptation#Office-Home#Accuracy#59.9$Domain Generalization#ImageNet-A#Top-1 accuracy %#4.2$Domain Generalization#ImageNet-R#Top-1 Error Rate#63.9$Retinal OCT Disease Classification#OCT2017#Acc#99.3$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.3$Retinal OCT Disease Classification#Srinivasan2014#Acc#94.92$Person Re-Identification#SYSU-30k#Rank-1#20.1$Crowd Counting#UCF-QNRF#MAE#190$Semantic Segmentation#DADA-seg#mIoU#23.60$Semantic Segmentation#DADA-seg#mIoU#18.96$Semantic Segmentation#Cityscapes val#mIoU#75.7$Object Detection#COCO test-dev#box AP#34.9$Object Detection#COCO minival#box AP#46.3$Object Detection#COCO minival#AP50#64.3$Object Detection#COCO minival#AP75#50.5$Object Detection#COCO minival#box AP#44.5$Object Detection#COCO minival#AP50#63.0$Object Detection#COCO minival#AP75#48.3$Object Detection#COCO minival#box AP#43.5$Object Detection#COCO minival#AP50#61.9$Object Detection#COCO minival#AP75#47.0$Image Classification#ImageNet#Top 1 Accuracy#78.57%$Image Classification#ImageNet#Top 5 Accuracy#94.29$Image Classification#ImageNet#GFLOPs#11.3$Image Classification#ImageNet#Top 1 Accuracy#78.25%$Image Classification#ImageNet#Top 5 Accuracy#93.95$Image Classification#ImageNet#Number of params#40M$Image Classification#ImageNet#GFLOPs#7.6$Image Classification#ImageNet#Top 1 Accuracy#75.3%$Image Classification#ImageNet#Top 5 Accuracy#93.29$Image Classification#ImageNet#Number of params#25M$Image Classification#ImageNet#GFLOPs#3.8$Image Classification#OmniBenchmark#Average Top-1 Accuracy#37.4$Image Classification#OmniBenchmark#Average Top-1 Accuracy#34.3$Image Classification#GasHisSDB#Accuracy#98.56$Image Classification#GasHisSDB#Precision#99.94$Image Classification#GasHisSDB#F1-Score#99.24$Image Classification#GasHisSDB#Accuracy#98.47$Image Classification#GasHisSDB#F1-Score#99.19$Image Classification#CIFAR-10#Percentage correct#86.65$Breast Tumour Classification#PCam#AUC#0.948$Breast Tumour Classification#PCam#AUC#0.942$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#94.72$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#97.09$Medical Image Classification#NCT-CRC-HE-100K#Precision#100.00$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.34$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#92.66$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#95.23$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.90$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.08
2112.13985v2.pdf	Text-to-Image Generation#GeNeVA (i-CLEVR)#F1-score#97.26±1.56$Text-to-Image Generation#GeNeVA (i-CLEVR)#rsim#83.21± 1.70$Text-to-Image Generation#GeNeVA (CoDraw)#F1-score#77.51± 0.52$Text-to-Image Generation#GeNeVA (CoDraw)#rsim#54.16± 0.21
1811.09845v3.pdf	Text-to-Image Generation#GeNeVA (i-CLEVR)#F1-score#88.39$Text-to-Image Generation#GeNeVA (i-CLEVR)#rsim#74.02$Text-to-Image Generation#GeNeVA (CoDraw)#F1-score#58.83$Text-to-Image Generation#GeNeVA (CoDraw)#rsim#35.41
2207.09814v2.pdf	Text-to-Image Generation#LHQC#Block-FID#9.71$Image Outpainting#LHQC#Block-FID  (Right Extend)#6.43$Image Outpainting#LHQC#Block-FID (Left Extend)#6.71$Image Outpainting#LHQC#Block-FID (Down Extend)#11.47$Image Outpainting#LHQC#Block-FID (Up Extend)#8.03$Image Outpainting#LHQC#Block-FID  (Right Extend)#6.45$Image Outpainting#LHQC#Block-FID (Left Extend)#6.72$Image Outpainting#LHQC#Block-FID (Down Extend)#9.84$Image Outpainting#LHQC#Block-FID (Up Extend)#7.43
2202.04200v1.pdf	Text-to-Image Generation#LHQC#Block-FID#24.33$Image Outpainting#LHQC#Block-FID  (Right Extend)#14.68$Image Outpainting#LHQC#Block-FID (Left Extend)#14.81$Image Outpainting#LHQC#Block-FID (Down Extend)#25.57$Image Outpainting#LHQC#Block-FID (Up Extend)#25.38$Image Generation#ImageNet 256x256#FID#4.02$Image Generation#ImageNet 256x256#Inception score#355.6$Image Generation#ImageNet 256x256#FID#6.18$Image Generation#ImageNet 256x256#Inception score#182.1$Image Generation#ImageNet 512x512#FID#4.46$Image Generation#ImageNet 512x512#Inception score#342.0$Image Generation#ImageNet 512x512#FID#7.32$Image Generation#ImageNet 512x512#Inception score#156.0
2012.09841v3.pdf	Text-to-Image Generation#LHQC#Block-FID#38.89$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#22.4$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#35.5$Image Outpainting#LHQC#Block-FID  (Right Extend)#22.53$Image Outpainting#LHQC#Block-FID (Left Extend)#-$Image Outpainting#LHQC#Block-FID (Down Extend)#26.38$Image Outpainting#LHQC#Block-FID (Up Extend)#-$Image Generation#CelebA 256x256#FID#10.2$Image Generation#FFHQ 256 x 256#FID#9.6$Image Generation#CelebA-HQ 256x256#FID#10.2$Image Generation#ImageNet 256x256#FID#5.2$Image Generation#ImageNet 256x256#Inception score#280.3$Image Generation#ImageNet 256x256#FID#6.59$Image Generation#ImageNet 256x256#Inception score#402.7
2210.15257v1.pdf	Text-to-Image Generation#COCO#FID#6.75
2206.10789v1.pdf	Text-to-Image Generation#COCO#FID#7.23
2205.11487v1.pdf	Text-to-Image Generation#COCO#FID#7.27
2111.13792v3.pdf	Text-to-Image Generation#COCO#FID#8.12$Text-to-Image Generation#COCO#Inception score#32.34$Text-to-Image Generation#COCO#SOA-C#61.09$Text-to-Image Generation#COCO#FID#26.94$Text-to-Image Generation#COCO#Inception score#26.02$Text-to-Image Generation#COCO#FID-1#22.97$Text-to-Image Generation#COCO#FID-8#14.79$Text-to-Image Generation#COCO#FID-2#18.70$Text-to-Image Generation#COCO#FID-4#15.72$Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#12.54$Text-to-Image Generation#CUB#FID#10.48$Text-to-Image Generation#CUB#Inception score#5.97
2101.04702v5.pdf	Text-to-Image Generation#COCO#FID#9.33
2204.06125v1.pdf	Text-to-Image Generation#COCO#FID#10.39
2112.10741v3.pdf	Text-to-Image Generation#COCO#FID#12.24
2111.14822v3.pdf	Text-to-Image Generation#COCO#FID#13.86$Text-to-Image Generation#COCO#FID#19.75$Text-to-Image Generation#CUB#FID#10.32$Text-to-Image Generation#CUB#FID#11.94$Text-to-Image Generation#CUB#FID#12.97$Text-to-Image Generation#Oxford 102 Flowers#FID#14.1$Text-to-Image Generation#Oxford 102 Flowers#FID#14.88$Text-to-Image Generation#Oxford 102 Flowers#FID#14.95
2204.10482v1.pdf	Text-to-Image Generation#COCO#FID#14.6$Text-to-Image Generation#CUB#FID#10.21$Text-to-Image Generation#CUB#Inception score#5.36$Text-to-Image Generation#Oxford 102 Flowers#FID#16.04$Text-to-Image Generation#Oxford 102 Flowers#Inception score#4.09
2112.15283v1.pdf	Text-to-Image Generation#COCO#FID#14.7
2102.12092v2.pdf	Text-to-Image Generation#COCO#FID#17.89
2107.02423v2.pdf	Text-to-Image Generation#COCO#FID#20.79$Text-to-Image Generation#COCO#Inception score#33.34$Text-to-Image Generation#COCO#FID#23.93$Text-to-Image Generation#COCO#Inception score#25.70$Text-to-Image Generation#CUB#FID#14.38$Text-to-Image Generation#CUB#Inception score#4.77$Text-to-Image Generation#CUB#FID#16.34$Text-to-Image Generation#CUB#Inception score#4.42
2112.01573v1.pdf	Text-to-Image Generation#COCO#FID#21.16$Text-to-Image Generation#COCO#Inception score#34.26$Text-to-Image Generation#COCO#FID#21.89$Text-to-Image Generation#COCO#Inception score#34.67
1910.13321v2.pdf	Text-to-Image Generation#COCO#FID#24.70$Text-to-Image Generation#COCO#Inception score#27.88$Text-to-Image Generation#COCO#SOA-C#35.85
2105.13290v3.pdf	Text-to-Image Generation#COCO#FID#27.1$Text-to-Image Generation#COCO#Inception score#18.2$Text-to-Image Generation#COCO#FID-1#19.4$Text-to-Image Generation#COCO#FID-8#23.6$Text-to-Image Generation#COCO#FID-2#13.9$Text-to-Image Generation#COCO#FID-4#19.4
2010.03182v3.pdf	Text-to-Image Generation#COCO#FID#29.26$Text-to-Image Generation#COCO#Inception score#28.18$Text-to-Image Generation#COCO#FID#32.37$Text-to-Image Generation#COCO#Inception score#32.37$Text-to-Image Generation#COCO#Inception score#10.38
1904.01310v1.pdf	Text-to-Image Generation#COCO#FID#32.64$Text-to-Image Generation#COCO#Inception score#30.49$Text-to-Image Generation#COCO#SOA-C#33.44$Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#131.05$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.544$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#16.4$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#16.9$Text-to-Image Generation#CUB#Inception score#4.75
1901.00686v1.pdf	Text-to-Image Generation#COCO#FID#33.35$Text-to-Image Generation#COCO#Inception score#24.76$Text-to-Image Generation#COCO#SOA-C#25.46$Text-to-Image Generation#COCO#FID#55.30$Text-to-Image Generation#COCO#Inception score#12.12
1711.10485v1.pdf	Text-to-Image Generation#COCO#FID#35.49$Text-to-Image Generation#COCO#Inception score#25.89$Text-to-Image Generation#COCO#SOA-C#25.88$Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#125.98$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.512$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#13.0$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#11.9$Text-to-Image Generation#CUB#Inception score#4.36
2111.11133v10.pdf	Text-to-Image Generation#COCO#FID#37.2$Text-to-Image Generation#COCO#FID-1#31.6$Text-to-Image Generation#COCO#FID-8#21.1$Text-to-Image Generation#COCO#FID-2#25.7$Text-to-Image Generation#COCO#FID-4#21.4$Text-to-Image Generation#COCO#FID#45.8$Text-to-Image Generation#COCO#FID-1#41.9$Text-to-Image Generation#COCO#FID-8#29.83$Text-to-Image Generation#COCO#FID-2#35.5$Text-to-Image Generation#COCO#FID-4#30.2$Image Captioning#COCO Captions#BLEU-4#39.9$Image Captioning#COCO Captions#METEOR#31.4$Image Captioning#COCO Captions#ROUGE-L#60.4$Image Captioning#COCO Captions#CIDEr-D#102.2$Image Captioning#COCO Captions#SPICE#23.3$Image Reconstruction#ImageNet 256x256#FID#1.04$Image Reconstruction#ImageNet 256x256#FID#3.28
1710.10916v3.pdf	Text-to-Image Generation#COCO#FID#74.05$Text-to-Image Generation#COCO#Inception score#8.45$Text-to-Image Generation#CUB#FID#15.30$Text-to-Image Generation#CUB#Inception score#3.82$Text-to-Image Generation#CUB#FID#51.89$Text-to-Image Generation#CUB#Inception score#3.70$Text-to-Image Generation#Oxford 102 Flowers#FID#48.68$Text-to-Image Generation#Oxford 102 Flowers#Inception score#3.26$Text-to-Image Generation#Oxford 102 Flowers#FID#55.28$Text-to-Image Generation#Oxford 102 Flowers#Inception score#3.20$Image Generation#LSUN Bedroom 256 x 256#FID#35.61
1802.08216v1.pdf	Text-to-Image Generation#COCO#Inception score#9.74
2104.08910v1.pdf	Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#101.42$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.461$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#20.4$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#21.0
2012.03308v3.pdf	Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#106.37$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.456$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#18.4$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#22.6
1909.07083v2.pdf	Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#116.32$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.522$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#14.6$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#13.1$Text-to-Image Generation#CUB#Inception score#4.58
2008.05865v4.pdf	Text-to-Image Generation#Multi-Modal-CelebA-HQ#FID#137.60$Text-to-Image Generation#Multi-Modal-CelebA-HQ#LPIPS#0.581$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Acc#17.3$Text-to-Image Generation#Multi-Modal-CelebA-HQ#Real#14.5$Text-to-Image Generation#CUB#Inception score#4.86
1903.05854v1.pdf	Text-to-Image Generation#CUB#Inception score#4.56
1612.03242v2.pdf	Text-to-Image Generation#CUB#Inception score#3.7$Text-to-Image Generation#Oxford 102 Flowers#Inception score#3.2
1610.02454v1.pdf	Text-to-Image Generation#CUB#FID#67.22$Text-to-Image Generation#CUB#Inception score#3.62
2111.12417v1.pdf	Text-to-Image Generation#COCO 256 x 256#FID-0#9.3$Text-to-Image Generation#COCO 256 x 256#IS#30.5$Text-to-Image Generation#COCO 256 x 256#FID-0#12.9$Text-to-Image Generation#COCO 256 x 256#IS#27.2$Text-to-Image Generation#COCO 256 x 256#FID-0#26.0$Text-to-Image Generation#COCO 256 x 256#IS#32.2$Text-to-Image Generation#COCO 256 x 256#IS#18.7$Text-to-Image Generation#COCO 256 x 256#FID-0#27.1$Text-to-Image Generation#COCO 256 x 256#IS#18.2$Text-to-Image Generation#COCO 256 x 256#FID-0#27.5$Text-to-Image Generation#COCO 256 x 256#IS#17.9$Text-to-Image Generation#COCO 256 x 256#FID-0#35.2$Text-to-Image Generation#COCO 256 x 256#IS#23.3$Video Generation#BAIR Robot Pushing#FVD score#86.9$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15$Text-to-Video Generation#Kinetics#Accuracy#77.9
1707.03692v1.pdf	Hand Gesture Recognition#BUAA#Accuracy#99.25$Hand Gesture Recognition#SmartWatch#Accuracy#97.4$Hand Gesture Recognition#MGB#Accuracy#98.04
1804.07187v2.pdf	Hand Gesture Recognition#ChaLean test#Accuracy#56.7$Hand Gesture Recognition#ChaLearn val#Accuracy#57.4$Hand Gesture Recognition#Jester val#Top 1 Accuracy#96.33$Hand Gesture Recognition#Jester val#Top 5 Accuracy#99.86$Hand Gesture Recognition#NVGesture#Accuracy#84.7$Hand Gesture Recognition#Jester test#Top 1 Accuracy#96.6
1701.01814v1.pdf	Hand Gesture Recognition#ChaLearn val#Accuracy#39.23
1702.08652v3.pdf	Hand Gesture Recognition#ChaLearn val#Accuracy#36.27
1907.08871v1.pdf	Hand Gesture Recognition#DHG-28#Accuracy#88$Hand Gesture Recognition#DHG-14#Accuracy#91.9$Hand Gesture Recognition#SHREC 2017#14 gestures accuracy#94.4$Hand Gesture Recognition#SHREC 2017#28 gestures accuracy#90.7
1708.03278v1.pdf	Hand Gesture Recognition#DHG-28#Accuracy#80.32$Hand Gesture Recognition#DHG-14#Accuracy#84.68
2008.05732v1.pdf	Hand Gesture Recognition#DHG-14#Accuracy#86.11
2007.11983v1.pdf	Hand Gesture Recognition#DHG-14#Accuracy#85.46$Hand Gesture Recognition#DHG-14#Accuracy#85.36$Hand Gesture Recognition#DHG-14#Accuracy#81.86
1901.04622v1.pdf	Hand Gesture Recognition#Cambridge#Accuracy#98.23%$Hand Gesture Recognition#Northwestern University#Accuracy#96.89
1303.6021v1.pdf	Hand Gesture Recognition#Cambridge#Accuracy#93%
1912.03647v2.pdf	Hand Gesture Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#14 gestures accuracy#73121216$Hand-Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy#77.5$Hand-Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy#6.86$Hand-Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy-CN#2303240$Hand-Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy-CN#-13585591$Quantization#CIFAR-10#MAP#160327.04$Quantization#Knowledge-based:#All#84809664
1907.09658v8.pdf	Hand Gesture Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#14 gestures accuracy#94.6$Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#-$Skeleton Based Action Recognition#J-HMDB#Accuracy (pose)#77.2$Skeleton Based Action Recognition#JHMDB (2D poses only)#Accuracy#78.0 (average of 3 split train/test)$Skeleton Based Action Recognition#JHMDB (2D poses only)#Average accuracy of 3 splits#77.2$Skeleton Based Action Recognition#JHMDB (2D poses only)#No. parameters#1.82 M$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#Accuracy#94.6 (14  gestures) , 91.9 (28 gestures )$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#28 gestures accuracy#91.9$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#14 gestures accuracy#94.6$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#No. parameters#1.82M$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#Speed  (FPS)#2,200
1901.10323v3.pdf	Hand Gesture Recognition#EgoGesture#Accuracy#94.03$Hand Gesture Recognition#NVGesture#Accuracy#83.82
1812.06145v2.pdf	Hand Gesture Recognition#EgoGesture#Accuracy#93.87$Hand Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy#86.08$Hand Gesture Recognition#NVGesture#Accuracy#86.93
1911.08670v2.pdf	Hand Gesture Recognition#EgoGesture#Accuracy#93.51$Hand Gesture Recognition#NVGesture#Accuracy#86.93$Action Recognition#NTU RGB+D#Accuracy (CS)#91.99
1705.07750v3.pdf	Hand Gesture Recognition#EgoGesture#Accuracy#92.78$Hand Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy#83.1$Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#84.1$Video Object Tracking#CATER#Top 1 Accuracy#60.2$Video Object Tracking#CATER#Top 5 Accuracy#81.8$Video Object Tracking#CATER#L1#1.2$Action Recognition#UCF101#3-fold Accuracy#98.0$Action Recognition#UCF101#3-fold Accuracy#97.8$Action Recognition#UCF101#3-fold Accuracy#96.7$Action Recognition#UCF101#3-fold Accuracy#96.5$Action Recognition#UCF101#3-fold Accuracy#95.6$Action Recognition#UCF101#3-fold Accuracy#95.1$Action Recognition#UCF101#3-fold Accuracy#93.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#80.9$Action Recognition#HMDB-51#Average accuracy of 3 splits#80.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#77.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#77.1$Action Recognition#HMDB-51#Average accuracy of 3 splits#74.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#74.3$Action Classification#Toyota Smarthome dataset#CS#53.4$Action Classification#Toyota Smarthome dataset#CV1#34.9$Action Classification#Toyota Smarthome dataset#CV2#45.1$Action Classification#Moments in Time#Top 1 Accuracy#29.51%$Action Classification#Moments in Time#Top 5 Accuracy#56.06%$Action Classification#Charades#MAP#32.9$Action Classification#Kinetics-400#Acc@1#71.1$Action Classification#Kinetics-400#Acc@5#89.3
1406.2199v2.pdf	Hand Gesture Recognition#VIVA Hand Gestures Dataset#Accuracy#68$Action Recognition#UCF101#3-fold Accuracy#88.0$Action Recognition#HMDB-51#Average accuracy of 3 splits#59.4$Action Classification#Charades#MAP#18.6
1711.08496v2.pdf	Hand Gesture Recognition#Jester test#Top 1 Accuracy#94.78$Action Recognition#Something-Something V1#Top 1 Accuracy#42.01$Action Recognition#Something-Something V1#Top 1 Accuracy#34.4$Action Recognition#Jester#Val#95.31$Action Recognition#Something-Something V2#Top-1 Accuracy#55.52$Action Recognition#Something-Something V2#Top-5 Accuracy#83.06$Action Classification#Moments in Time#Top 1 Accuracy#28.27%$Action Classification#Moments in Time#Top 5 Accuracy#53.87%$Action Classification#Charades#MAP#25.2
2107.08580v1.pdf	Skeleton Based Action Recognition#UPenn Action#Accuracy#97.9$Action Classification#Toyota Smarthome dataset#CS#64.3$Action Classification#Toyota Smarthome dataset#CV1#36.1$Action Classification#Toyota Smarthome dataset#CV2#65.0
1912.01001v4.pdf	Skeleton Based Action Recognition#UPenn Action#Accuracy#97.5$Video Alignment#UPenn Action#Kendall's Tau#0.7476$Pose Retrieval#Human3.6M#Hit@1#76.2$Pose Retrieval#Human3.6M#Hit@10#95.6$Pose Retrieval#MPI-INF-3DHP#Hit@1#26.4$Pose Retrieval#MPI-INF-3DHP#Hit@10#58.6
1704.00616v2.pdf	Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#76.1$Skeleton Based Action Recognition#J-HMDB#Accuracy (pose)#56.8$Skeleton Based Action Recognition#JHMDB (2D poses only)#Average accuracy of 3 splits#56.8
1902.10024v1.pdf	Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#64.3$Multimodal Activity Recognition#UTD-MHAD#Accuracy (CS)#90
1411.6031v1.pdf	Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#62.5
1904.09140v1.pdf	Skeleton Based Action Recognition#J-HMDB#Accuracy (RGB+pose)#-$Skeleton Based Action Recognition#J-HMDB#Accuracy (pose)#65.5$Skeleton Based Action Recognition#JHMDB (2D poses only)#Average accuracy of 3 splits#65.5
1909.09300v1.pdf	Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CV)#94.4$Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CS)#92.9$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#91.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.8$RF-based Pose Estimation#RF-MMD#mAP (@0.1, Through-wall)#86.5$RF-based Pose Estimation#RF-MMD#mAP (@0.1, Visible)#90.1
1804.06055v1.pdf	Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CV)#94.2$Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CS)#92.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#91.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.5$RF-based Pose Estimation#RF-MMD#mAP (@0.1, Through-wall)#78.5$RF-based Pose Estimation#RF-MMD#mAP (@0.1, Visible)#82,5
1704.07595v1.pdf	Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CV)#93.7$Skeleton Based Action Recognition#PKU-MMD#mAP@0.50 (CS)#90.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#89.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#83.2
1210.1207v2.pdf	Skeleton Based Action Recognition#CAD-120#Accuracy#86.0%
1511.05298v3.pdf	Skeleton Based Action Recognition#CAD-120#Accuracy#85.4%$Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#1.30$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#2.13
1612.00593v2.pdf	Skeleton Based Action Recognition#CAD-120#Accuracy#69.1%$3D Semantic Segmentation#KITTI-360#miou Class#13.07$3D Semantic Segmentation#KITTI-360#mIoU Category#30.42$3D Semantic Segmentation#SemanticKITTI#mIoU#14.6%$Semantic Segmentation#S3DIS Area5#mAcc#49.0$Semantic Segmentation#S3DIS#mAcc#66.2$Scene Segmentation#ScanNet#Average Accuracy#60.2%$3D Part Segmentation#IntrA#IoU (V)#75.23$3D Part Segmentation#IntrA#DSC (V)#85.00$3D Part Segmentation#IntrA#IoU (A)#37.75$3D Part Segmentation#IntrA#DSC (A)#49.59$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#83.7$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.684$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.283$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#68.2$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#63.4$3D Point Cloud Classification#ModelNet40#Overall Accuracy#89.2$3D Point Cloud Classification#ModelNet40#Mean Accuracy#86.0$3D Point Cloud Classification#ModelNet40#Number of params#3.47M$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.422$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.178
1604.02808v1.pdf	Skeleton Based Action Recognition#CAD-120#Accuracy#68.1%$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#70.27$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#62.93$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#67.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#60.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#25.5%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#26.3%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#60%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#13%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#33%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#33%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#50%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#56%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#16%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#31%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#31%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#68%
2103.02303v3.pdf	Skeleton Based Action Recognition#First-Person Hand Action Benchmark#1:3 Accuracy#92.9$Skeleton Based Action Recognition#First-Person Hand Action Benchmark#1:1 Accuracy#95.93$Skeleton Based Action Recognition#First-Person Hand Action Benchmark#3:1 Accuracy#96.76$Skeleton Based Action Recognition#First-Person Hand Action Benchmark#Cross-person Accuracy#88.70$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#28 gestures accuracy#91.43$Skeleton Based Action Recognition#SHREC 2017 track on 3D Hand Gesture Recognition#14 gestures accuracy#93.57
2101.11529v4.pdf	Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers joints)#91.78$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body joints)#89.56$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers + Face joints)#89.64$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers joints)#91.76$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body joints)#91.26$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers + Face joints)#91.12$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers joints)#91.64$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body joints)#89.98$Skeleton Based Action Recognition#NTU60-X#Accuracy (Body + Fingers + Face joints)#89.79
1802.09834v1.pdf	Skeleton Based Action Recognition#Florence 3D#Accuracy#99.1%
1811.12013v2.pdf	Skeleton Based Action Recognition#Florence 3D#Accuracy#98.4%$Skeleton Based Action Recognition#UT-Kinect#Accuracy#98.5%$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#94.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#87.5$Skeleton Based Action Recognition#SYSU 3D#Accuracy#77.9%
2012.14371v3.pdf	Skeleton Based Action Recognition#Florence 3D#Accuracy#97.45$Skeleton Based Action Recognition#Florence 3D#Accuracy#95.23$Skeleton Based Action Recognition#UT-Kinect#Accuracy#99.2$Skeleton Based Action Recognition#UT-Kinect#Accuracy#98.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#94.75$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.56$Action Recognition#HMDB-51#Average accuracy of 3 splits#86.11
2006.11812v1.pdf	Skeleton Based Action Recognition#Florence 3D#Accuracy#95.81%$Skeleton Based Action Recognition#UT-Kinect#Accuracy#99.50%$Skeleton Based Action Recognition#HDM05#Accuracy#89.80%$Skeleton Based Action Recognition#Gaming 3D (G3D)#Accuracy#92.91%$Skeleton Based Action Recognition#MSRC-12#Accuracy#99.08%$Skeleton Based Action Recognition#MSR ActionPairs#Accuracy#98.02%$Skeleton Based Action Recognition#MSR Action3D#Accuracy#88.51%
2104.13586v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#94.1$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#49.1$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#47.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#86.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.3$Action Recognition#NTU RGB+D#Accuracy (CS)#97.0$Action Recognition#NTU RGB+D#Accuracy (CV)#99.6$Action Recognition#Volleyball#Accuracy#91.3$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#96.4$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#95.3$Group Activity Recognition#Volleyball#Accuracy#91.3
2208.10741v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#93.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#90.1$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#91.6$Skeleton Based Action Recognition#N-UCLA#Accuracy#97.0
2208.05318v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#89.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#91.1$Skeleton Based Action Recognition#N-UCLA#Accuracy#97.2
2208.05775v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#89.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.6
2208.08599v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.8$Skeleton Based Action Recognition#Kinetics-400#Actions Top-1 (S1)#39.2$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.4
2205.15936v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.8$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#89.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.8
2205.09443v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#97.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#98.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.6$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.8
2107.12213v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.8$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.6$Skeleton Based Action Recognition#N-UCLA#Accuracy#96.5
2106.15125v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.5$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.9$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#94.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.1$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#87.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#88.0$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#85.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#84.3
2108.04536v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#92.0$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#38.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.2$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.3
2105.01563v5.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#88.2%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.2%
2108.07181v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.6$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#87.5$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#46.2$3D Human Pose Estimation#MPI-INF-3DHP#PCK#82.1
2007.03263v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.5$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#86.6%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.0 %
2003.14111v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.5$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#38.0$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#86.9%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#88.4%$3D Action Recognition#Assembly101#Actions Top-1#28.7$3D Action Recognition#Assembly101#Verbs Top-1#65.7$3D Action Recognition#Assembly101#Object Top-1#36.3
2007.14690v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.5$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.9
2003.08951v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.5$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#91.0$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#38.6
2010.09978v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.9$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#87.3$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#88.3
1801.07455v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.5$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#88.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#81.5$Skeleton Based Action Recognition#UAV-Human#CSv1(%)#30.25$Skeleton Based Action Recognition#UAV-Human#CSv2(%)#56.14$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#86.2$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#88.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#84.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#89.0$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#71%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#25%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#56%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#53%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#43%$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57.4$Action Recognition#ICVL-4#Accuracy#80.23%$Action Recognition#IRD#Accuracy#74.03%$Multimodal Activity Recognition#EV-Action#Accuracy#79.6$Multimodal Activity Recognition#EV-Action#Accuracy#50.7
2003.03007v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.3$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.5
1912.11521v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.3
2003.07564v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.2$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#85.4%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#87.4%
1910.02212v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.1
1912.06971v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#90.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.4$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.8$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.4
2008.07404v4.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.9$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.4$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#82.7%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#84.7%
2007.15678v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#96$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.7$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#80.5%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#83.2%
1911.04131v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.4$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#37.1
1804.07453v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.4$Skeleton Based Action Recognition#SBU#Accuracy#98.3%$Skeleton Based Action Recognition#SYSU 3D#Accuracy#86.7%$Skeleton Based Action Recognition#UWA3D#Accuracy#81.4%$Skeleton Based Action Recognition#N-UCLA#Accuracy#88.1%
1902.09130v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.2
1811.04237v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#94.9$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#89.1$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#36.6
1805.07694v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#95.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#88.5
1809.04983v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#87.5$Action Recognition#NTU RGB+D#Accuracy (CS)#87.5$Action Recognition#NTU RGB+D#Accuracy (CV)#93.2
2008.03791v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#87.3$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#81.1%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#82.7%
1912.08435v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#92.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#87.2
1904.12659v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#94.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.8$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#34.8
1910.06251v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.97$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.70$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.18$Language Modelling#Penn Treebank (Word Level)#Test perplexity#50.97$Language Modelling#Penn Treebank (Word Level)#Test perplexity#56.37$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.48%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#97.2%
1904.01189v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#86.6$Skeleton Based Action Recognition#SYSU 3D#Accuracy#86.9%$Skeleton Based Action Recognition#N-UCLA#Accuracy#92.5%
1905.06774v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.5$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.9$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.8
2003.07514v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.6$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#34.8
1912.09745v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#92.8$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.3$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#78.3%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#79.8%$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#79.2$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#78.3
2010.07367v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#91.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.2$Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#33.7
1704.05645v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#85.0
1805.02335v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#92.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#84.8
1906.09955v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#88.84$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#83.36$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#89$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#83
1804.08254v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#93.22$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#82.67
1803.04831v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#88.0$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#81.8$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.19$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#96%
1707.00823v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#86.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#80.9
1805.02556v4.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#88.8$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#80.7
1909.01939v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#88.4$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#80.7$Skeleton Based Action Recognition#SYSU 3D#Accuracy#85.7%$Skeleton Based Action Recognition#N-UCLA#Accuracy#90.7%
1807.04445v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#87.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#79.8
1703.03492v3.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#84.8$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#79.6$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#58.4%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#57.9%
1805.11790v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#84.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#79.6
1703.08274v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#87.6$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#79.2$Skeleton Based Action Recognition#SYSU 3D#Accuracy#77.5%
1907.13025v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#84.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#76.5$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#67.7%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#66.9%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#62.9%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#63.0%$Action Recognition#NTU RGB+D#Accuracy (CS)#76.5$Action Recognition#NTU RGB+D#Accuracy (CV)#84.7$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#67.7$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#66.9
1704.04516v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#83.1$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#74.3$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#63%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#14%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#48%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#48%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#68%$Multimodal Activity Recognition#EV-Action#Accuracy#80.1$Multimodal Activity Recognition#EV-Action#Accuracy#64.1
1611.06067v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#81.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#73.4
1909.05704v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#80.3$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#73.3$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#67.9%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#62.8%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#65.5%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#59.7%$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#62.8$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#67.9
1704.02581v2.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#79.5$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#71.3
1607.07043v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#77.7$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#69.2$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#75.50$Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CS)#61.70$Skeleton Based Action Recognition#SBU#Accuracy#93.3%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#55.7%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#57.9%
1705.00835v1.pdf	Skeleton Based Action Recognition#NTU RGB+D#Accuracy (CV)#82.31
2204.11511v2.pdf	Skeleton Based Action Recognition#Drive&Act#mean per-class accuracy#34.61$Skeleton Based Action Recognition#TCG-dataset#Acc#85.99$Skeleton Based Action Recognition#TCG-dataset#Jaccard Index#67.88$Skeleton Based Action Recognition#TCG-dataset#F1-Score#80.05
2007.02072v2.pdf	Skeleton Based Action Recognition#Skeletics-152#Accuracy (Cross-Subject)#57.01 %$Skeleton Based Action Recognition#Skeleton-Mimetics#Accuracy (%)#57.37 %$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#87.22%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#88.8%
1904.01693v1.pdf	Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.1#58.4$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.2#78.1$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.3#85.9$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.4#89.8$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.5#92.4
1806.09594v2.pdf	Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.1#45.2$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.2#69.6$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.3#80.8$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.4#87.5$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.5#91.4
1612.01925v1.pdf	Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.1#45.2$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.2#62.9$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.3#73.5$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.4#80.6$Skeleton Based Action Recognition#JHMDB Pose Tracking#PCK@0.5#85.5$Optical Flow Estimation#KITTI 2015 (train)#F1-all#30.0$Optical Flow Estimation#KITTI 2015 (train)#EPE#10.08$Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.96$Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#5.99$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#15.55$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#17.09$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#22.13$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#30.68
1805.07694v3.pdf	Skeleton Based Action Recognition#UAV-Human#CSv1(%)#34.84$Skeleton Based Action Recognition#UAV-Human#CSv2(%)#66.68$3D Action Recognition#Assembly101#Actions Top-1#26.7$3D Action Recognition#Assembly101#Verbs Top-1#64.4$3D Action Recognition#Assembly101#Object Top-1#33.9
1612.09401v1.pdf	Skeleton Based Action Recognition#Gaming 3D (G3D)#Accuracy#96.0
2010.08164v2.pdf	Skeleton Based Action Recognition#JHMDB (2D poses only)#Average accuracy of 3 splits#68.55$Action Recognition#AVA v2.1#mAP (Val)#28.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#84.53$Action Recognition#HMDB-51#Average accuracy of 3 splits#54.2$Action Recognition#Mimetics#mAP#40$Action Recognition#Mimetics#mAP#38.3$Action Classification#Charades#MAP#43.23$Action Classification#Charades#MAP#16.2
1911.00029v1.pdf	Skeleton Based Action Recognition#Kinetics-Skeleton dataset#Accuracy#30.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.4
1606.09375v3.pdf	Skeleton Based Action Recognition#SBU#Accuracy#96.00%$Node Classification#Cora (3%)#Accuracy#62.1%$Node Classification#Pubmed#Accuracy#74.4%$Node Classification#CiteSeer (1%)#Accuracy#59.4%$Node Classification#Cora#Accuracy#81.2%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#70.1%$Node Classification#Citeseer#Accuracy#69.8%$Node Classification#PubMed (0.05%)#Accuracy#48.2%$Node Classification#PubMed (0.03%)#Accuracy#45.3%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#78.0%$Node Classification#CiteSeer (0.5%)#Accuracy#45.3%$Node Classification#Cora (0.5%)#Accuracy#33.9%$Node Classification#PubMed (0.1%)#Accuracy#55.2%$Node Classification#Cora (1%)#Accuracy#44.2%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#69.8%$Graph Property Prediction#ogbg-molpcba#Test AP#0.2306 ± 0.0016$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2372 ± 0.0018$Graph Property Prediction#ogbg-molpcba#Number of params#1475003$Graph Property Prediction#ogbg-molpcba#Ext. data#No
1901.01343v7.pdf	Skeleton Based Action Recognition#SBU#Accuracy#96.00%$Graph Regression#Lipophilicity#RMSE#0.894
1810.12514v4.pdf	Skeleton Based Action Recognition#SBU#Accuracy#95.7%
1902.07153v2.pdf	Skeleton Based Action Recognition#SBU#Accuracy#94.0%$Relation Extraction#TACRED#F1#67.0$Sentiment Analysis#MR#Accuracy#75.9$Text Classification#20NEWS#Accuracy#88.5$Text Classification#R52#Accuracy#94.0$Text Classification#R8#Accuracy#97.2$Text Classification#Ohsumed#Accuracy#68.5$Graph Regression#Lipophilicity#RMSE#0.998$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#72.62 ± 9.92$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#70.98 ± 8.39$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#74.75 ± 2.89$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#70.38 ± 2.85$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#83.28 ± 5.43$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#81.31 ± 3.3$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#59.73±0.12
1706.08276v1.pdf	Skeleton Based Action Recognition#SYSU 3D#Accuracy#73.4%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#58.2%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#60.9%$One-Shot 3D Action Recognition#NTU RGB+D 120#Accuracy#42.9%
2007.03056v1.pdf	Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#86.3$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#87.8$Skeleton Based Action Recognition#N-UCLA#Accuracy#93.5$Action Recognition#NTU RGB+D#Accuracy (CS)#95.5$Action Recognition#NTU RGB+D#Accuracy (CV)#98.0$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#87.8$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#86.3$Action Classification#Toyota Smarthome dataset#CS#60.8$Action Classification#Toyota Smarthome dataset#CV1#43.8$Action Classification#Toyota Smarthome dataset#CV2#53.5
2003.06156v2.pdf	Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#70.8%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#71.6%$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#71.59$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#70.8$Multimodal Activity Recognition#UTD-MHAD#Accuracy (CS)#93.33
1908.08286v2.pdf	Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#68.3%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#67.2%
1707.05740v5.pdf	Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#61.2%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#63.3%
1902.03084v2.pdf	Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#59.9%$Skeleton Based Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#62.4%
2007.16072v1.pdf	Skeleton Based Action Recognition#TCG-dataset#Acc#87.24$Skeleton Based Action Recognition#TCG-dataset#Jaccard Index#67.00$Skeleton Based Action Recognition#TCG-dataset#F1-Score#78.48
1904.10681v1.pdf	Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#76%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#29%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#71%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#57%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#75%
1611.05267v1.pdf	Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CS)#56%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV I)#16%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (CV II)#43%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV I)#43%$Skeleton Based Action Recognition#Varying-view RGB-D Action-Skeleton#Accuracy (AV II)#64%$Action Segmentation#GTEA#F1@10%#72.2$Action Segmentation#GTEA#F1@50%#56.0$Action Segmentation#GTEA#Acc#64.0$Action Segmentation#GTEA#Edit#-$Action Segmentation#GTEA#F1@25%#69.3
1802.03145v1.pdf	Skeleton Based Action Recognition#J-HMBD Early Action#10%#60.6
1710.10903v3.pdf	Skeleton Based Action Recognition#J-HMBD Early Action#10%#58.1$Document Classification#Cora#Accuracy#83.0%$Graph Regression#Lipophilicity#RMSE#0.95$Graph Regression#ZINC 100k#MAE#0.463$Graph Classification#CIFAR10 100k#Accuracy (%)#65.48$Node Classification#Cora (3%)#Accuracy#56.8%$Node Classification#Flickr#Accuracy#0.359$Node Classification#Pubmed#Accuracy#79.0$Node Classification#Pubmed#Training Split#fixed 20 per node$Node Classification#Pubmed#Validation#YES$Node Classification#Wiki-Vote#Accuracy#59.4$Node Classification#CiteSeer (1%)#Accuracy#46.5%$Node Classification#PATTERN 100k#Accuracy (%)#75.824$Node Classification#USA Air-Traffic#Accuracy#58.5$Node Classification#Cora#Accuracy#83.0% ± 0.7%$Node Classification#Cora#Training Split#fixed 20 per node$Node Classification#Cora#Validation#YES$Node Classification#Brazil Air-Traffic#Accuracy#0.382$Node Classification#PPI#F1#97.3$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72.5 ± 0.7%$Node Classification#Citeseer#Accuracy#72.5 ± 0.7%$Node Classification#Citeseer#Training Split#fixed 20 per node$Node Classification#Citeseer#Validation#YES$Node Classification#PubMed (0.05%)#Accuracy#50.4%$Node Classification#PubMed (0.03%)#Accuracy#50.9%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.0 ± 0.7%$Node Classification#CiteSeer (0.5%)#Accuracy#38.2%$Node Classification#Europe Air-Traffic#Accuracy#42.4$Node Classification#Cora (0.5%)#Accuracy#41.4%$Node Classification#PubMed (0.1%)#Accuracy#59.6%$Node Classification#Cora (1%)#Accuracy#48.6%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#79.0%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#76.00 ± 1.01$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#71.01 ± 4.66$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#78.87 ± 0.86$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#61.09±0.77
2007.15244v1.pdf	Skeleton Based Action Recognition#N-UCLA#Accuracy#93.99$Action Recognition#NTU RGB+D#Accuracy (CS)#95.66$Action Recognition#NTU RGB+D#Accuracy (CV)#98.79
2105.08141v1.pdf	Skeleton Based Action Recognition#N-UCLA#Accuracy#93.5$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#92.5$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#90.7$Action Classification#Toyota Smarthome dataset#CS#71.0$Action Classification#Toyota Smarthome dataset#CV2#58.1
1812.05770v2.pdf	Skeleton Based Action Recognition#N-UCLA#Accuracy#92.3%$Action Recognition#NTU RGB+D#Accuracy (CS)#94.3$Action Recognition#NTU RGB+D#Accuracy (CV)#97.2$Action Recognition#UTD-MHAD#Accuracy#92.5$Multimodal Activity Recognition#MSR Daily Activity3D dataset#Accuracy#93.0$Multimodal Activity Recognition#UTD-MHAD#Accuracy (CS)#92.5
1802.07898v4.pdf	Skeleton Based Action Recognition#N-UCLA#Accuracy#87.6%$Action Recognition#NTU RGB+D#Accuracy (CS)#86.6$Action Recognition#NTU RGB+D#Accuracy (CV)#93.2
1711.09020v3.pdf	Image-to-Image Translation#RaFD#Classification Error#2.12%
1610.05586v2.pdf	Image-to-Image Translation#RaFD#Classification Error#4.10%
1703.10593v7.pdf	Image-to-Image Translation#RaFD#Classification Error#5.99%$Image-to-Image Translation#photo2vangogh#Frechet Inception Distance#151.4$Image-to-Image Translation#photo2vangogh#Number of params#28.2M$Image-to-Image Translation#horse2zebra#Frechet Inception Distance#89.7$Image-to-Image Translation#horse2zebra#Number of params#28.2M$Image-to-Image Translation#zebra2horse#Frechet Inception Distance#110.5$Image-to-Image Translation#zebra2horse#Number of params#28.2M$Image-to-Image Translation#vangogh2photo#Frechet Inception Distance#163.4$Image-to-Image Translation#vangogh2photo#Number of Params#28.2M$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-pixel Accuracy#58%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-class Accuracy#22%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Class IOU#0.16$Image-to-Image Translation#Cityscapes Labels-to-Photo#Class IOU#0.11$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-class Accuracy#17%$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#52%$Unsupervised Image-To-Image Translation#Freiburg Forest Dataset#PSNR#18.57$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Quality#40.8%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Diversity#0.012$Multimodal Unsupervised Image-To-Image Translation#EPFL NIR-VIS#PSNR#17.38$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Quality#36.0%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Diversity#0.010$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#CIS#0.076$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#IS#0.813
1611.06355v1.pdf	Image-to-Image Translation#RaFD#Classification Error#8.07%
1907.10830v4.pdf	Image-to-Image Translation#portrait2photo#Kernel Inception Distance#1.69$Image-to-Image Translation#anime-to-selfie#Kernel Inception Distance#11.52$Image-to-Image Translation#photo2vangogh#Kernel Inception Distance#4.28$Image-to-Image Translation#horse2zebra#Kernel Inception Distance#7.06$Image-to-Image Translation#cat2dog#Kernel Inception Distance#7.07$Image-to-Image Translation#selfie-to-anime#Kernel Inception Distance#11.61$Image-to-Image Translation#zebra2horse#Kernel Inception Distance#7.47$Image-to-Image Translation#photo2portrait#Kernel Inception Distance#1.79$Image-to-Image Translation#vangogh2photo#Kernel Inception Distance#5.61$Image-to-Image Translation#dog2cat#Kernel Inception Distance#8.15$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#24.5$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00131
2004.02088v2.pdf	Image-to-Image Translation#anime-to-selfie#Kernel Inception Distance#10.23$Image-to-Image Translation#selfie-to-anime#Kernel Inception Distance#11.40$Conditional Image Generation#ImageNet 128x128#FID#13.77$Conditional Image Generation#ImageNet 128x128#Inception score#54.36$Conditional Image Generation#CIFAR-100#Inception Score#9.74$Conditional Image Generation#CIFAR-100#FID#7.15$Conditional Image Generation#ImageNet64x64#Inception Score#25.96$Conditional Image Generation#ImageNet64x64#FID#9.67$Conditional Image Generation#CIFAR-10#Inception score#8.50$Conditional Image Generation#CIFAR-10#FID#5.34$Image Generation#FFHQ 1024 x 1024#FID#3.19
2008.05763v1.pdf	Image-to-Image Translation#photo2vangogh#Frechet Inception Distance#152.7$Image-to-Image Translation#photo2vangogh#Number of params#15.9M$Image-to-Image Translation#horse2zebra#Frechet Inception Distance#53.0$Image-to-Image Translation#horse2zebra#Number of params#15.9M$Image-to-Image Translation#zebra2horse#Frechet Inception Distance#112.3$Image-to-Image Translation#zebra2horse#Number of params#15.9M$Image-to-Image Translation#vangogh2photo#Frechet Inception Distance#134.4$Image-to-Image Translation#vangogh2photo#Number of Params#15.9M
2106.06561v1.pdf	Image-to-Image Translation#cat2dog#DFID#26.1$Image-to-Image Translation#cat2dog#FID#26.9$Image-to-Image Translation#cat2dog#DFID#53.6$Image-to-Image Translation#cat2dog#FID#44.2$Image-to-Image Translation#cat2dog#DFID#160.1$Image-to-Image Translation#cat2dog#FID#91.5$Image-to-Image Translation#cat2dog#DFID#172.5$Image-to-Image Translation#cat2dog#FID#90.8$Image-to-Image Translation#selfie2anime#DFID#35.6$Image-to-Image Translation#selfie2anime#FID#34.4$Image-to-Image Translation#selfie2anime#LPIPS#0.505$Image-to-Image Translation#selfie2anime#DFID#56.2$Image-to-Image Translation#selfie2anime#FID#38.1$Image-to-Image Translation#selfie2anime#LPIPS#0.43$Image-to-Image Translation#selfie2anime#DFID#83.0$Image-to-Image Translation#selfie2anime#FID#59.8$Image-to-Image Translation#selfie2anime#LPIPS#0.427$Image-to-Image Translation#selfie2anime#DFID#94.6$Image-to-Image Translation#selfie2anime#FID#63.8$Image-to-Image Translation#selfie2anime#LPIPS#0.201
2102.04699v1.pdf	Image-to-Image Translation#Zebra and Horses#Kernel Inception Distance#5.8$Image-to-Image Translation#Apples and Oranges#Kernel Inception Distance#4.4
2205.12952v1.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#15.6
2112.05130v1.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#15.8
2012.04781v3.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#44.1$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#17.0$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#69.3$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#47.7$Image-to-Image Translation#Cityscapes Labels-to-Photo#LPIPS#0.275$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#mIoU#40.4$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#48.6$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#48.8$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#28.3$Image-to-Image Translation#ADE20K Labels-to-Photos#LPIPS#0.265
2011.12636v3.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#42.1$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#71.5$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#19.1$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#21.9$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#54.1$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#54.2$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#63.1$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#52.1$Image-to-Image Translation#Cityscapes Labels-to-Photo#Accuracy#93.5$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#58$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#72.7$Image-to-Image Translation#Cityscapes Labels-to-Photo#Accuracy#92.7$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#44$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#83%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#32.6$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#77.9%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#41.5
1910.06809v3.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#41.6$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#70.7%$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#19.2$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#82.3%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#65.5$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#54.3$Image-to-Image Translation#Cityscapes Labels-to-Photo#LPIPS#0.073$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#43.7$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#82.9%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#31.7$Image-to-Image Translation#ADE20K Labels-to-Photos#LPIPS#0.098
1903.07291v2.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#37.4$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#67.9%$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#22.6$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#81.9%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#62.3$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#71.8$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#mIoU#30.8$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#Accuracy#82.9%$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#63.3$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#38.5$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#79.9%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#33.9$Image-to-Image Translation#ADE20K Labels-to-Photos#LPIPS#0
1707.09405v1.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#23.7$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#40.4%$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#70.4$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#77.1%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#52.4$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#104.7$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#mIoU#16.5$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#Accuracy#68.6%$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#99.0$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#22.4$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#68.8%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#73.3
1711.11585v2.pdf	Image-to-Image Translation#COCO-Stuff Labels-to-Photos#mIoU#14.6$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#Accuracy#45.8%$Image-to-Image Translation#COCO-Stuff Labels-to-Photos#FID#111.5$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#81.4%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#58.3$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#95$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#mIoU#17.4$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#Accuracy#71.6%$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#97.8$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#20.3$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#69.2%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#81.8$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#42.8$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00258
1908.03047v1.pdf	Image-to-Image Translation#KITTI Object Tracking Evaluation 2012#Average PSNR#21.12$Image Inpainting#StreetView#SSIM#0.79
2204.11425v2.pdf	Image-to-Image Translation#BCI#Average PSNR#21.160$Image-to-Image Translation#BCI#SSIM#0.477$Image-to-Image Translation#BCI#Average PSNR#19.634$Image-to-Image Translation#BCI#SSIM#0.471$Image-to-Image Translation#BCI#Average PSNR#19.328$Image-to-Image Translation#BCI#SSIM#0.440$Image-to-Image Translation#BCI#Average PSNR#16.203$Image-to-Image Translation#BCI#SSIM#0.373$Image-to-Image Translation#LLVIP#PSNR#12.191$Image-to-Image Translation#LLVIP#SSIM#0.278$Image-to-Image Translation#LLVIP#PSNR#11.22$Image-to-Image Translation#LLVIP#SSIM#0.214$Image-to-Image Translation#LLVIP#PSNR#11.156$Image-to-Image Translation#LLVIP#SSIM#0.228
2204.13132v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#72.4$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#73.8$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#73.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#72.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#65.8$Domain Adaptation#GTA5 to Cityscapes#mIoU#73.8$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#65.8$Domain Adaptation#Cityscapes to ACDC#mIoU#68.0$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#73.8$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#72.4$Semantic Segmentation#Dark Zurich#mIoU#55.9$Semantic Segmentation#SYNTHIA-to-Cityscapes#Mean IoU#65.8$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#73.8
2204.08808v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#71.4$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#70.3$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#70.3$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#61.0$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#71.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#64.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#66.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#58.1$Domain Adaptation#GTA5 to Cityscapes#mIoU#70.3$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#64.3$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#58.1$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#70.3$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#71.4$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#66.5$Semantic Segmentation#Dark Zurich#mIoU#54.2$Semantic Segmentation#Dark Zurich#mIoU#45.4$Semantic Segmentation#SYNTHIA-to-Cityscapes#Mean IoU#64.3$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#70.3
2108.03557v3.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#69.2$Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#59.7$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#70.0$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#55.2$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#70.0$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#55.2$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#69.2$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#59.7$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#70.0$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#55.2
2204.11891v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#68.2$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#69.4$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#69.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#61.6$Domain Adaptation#GTA5 to Cityscapes#mIoU#69.4$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#61.6$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#69.4$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#68.2$Semantic Segmentation#SYNTHIA-to-Cityscapes#Mean IoU#61.6$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#69.4
2111.14887v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#67.4$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#68.3$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#68.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#67.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#60.9$Domain Adaptation#GTA5 to Cityscapes#mIoU#68.3$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#60.9$Domain Adaptation#Cityscapes to ACDC#mIoU#55.4$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#68.3$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#67.4$Semantic Segmentation#DensePASS#mIoU#54.67%$Semantic Segmentation#Dark Zurich#mIoU#53.8$Semantic Segmentation#SYNTHIA-to-Cityscapes#Mean IoU#60.9$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#68.3
2203.07988v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#66.3$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#63.9$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#63.9$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#66.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#59.3$Domain Adaptation#GTA5 to Cityscapes#mIoU#63.9$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#63.9$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#66.3$Semantic Segmentation#SYNTHIA-to-Cityscapes#Mean IoU#59.3$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#63.9
2203.09744v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#65.3$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#60.8$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#60.8
2109.06422v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#63.7$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#58.6$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#58.6$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#63.7$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#56.9$Domain Adaptation#GTA5 to Cityscapes#mIoU#58.6$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#56.9$Domain Adaptation#Synscapes-to-Cityscapes#mIoU#60.2$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#58.6
2101.10979v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#62.0$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#57.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#57.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#62.0$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#55.5$Domain Adaptation#GTA5 to Cityscapes#mIoU#57.5$Semantic Segmentation#GTAV-to-Cityscapes Labels#mIoU#57.5
2008.12197v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#57.0$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#51.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#57.0$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#49.8$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#49.8
1908.09547v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#53.3$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#48$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#46.7$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#35.9
2007.09222v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#52.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#50.1$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#52.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#45.2$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#45.2$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#39.5
1904.10620v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#51.4$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#41.3$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#48.5$Semantic Segmentation#DADA-seg#mIoU#29.66
1904.01886v3.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#49.8
1908.09822v3.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#48.7$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#49.8$Domain Adaptation#VisDA2017#Accuracy#78.1$Domain Adaptation#Office-31#Average Accuracy#86.8$Semantic Segmentation#DensePASS#mIoU#31.67%
1903.04064v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#48.1$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#44.5$Domain Adaptation#VisDA2017#Accuracy#76.4
1811.12833v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#48$Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#44.8$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#45.5$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#41.2
1802.10349v3.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#46.7$Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#45.9$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#42.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#46.7$Domain Adaptation#Synscapes-to-Cityscapes#mIoU#52.7
1901.05427v4.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#46.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#46.5
1910.13049v2.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#44.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#50.2$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#52.6$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#44.5
1903.12212v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#41.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#45.4
1812.09953v3.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#29.7$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#31.4
1707.09465v5.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#29.0$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#28.9
1612.02649v1.pdf	Image-to-Image Translation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#20.2$Image-to-Image Translation#SYNTHIA Fall-to-Winter#mIoU#59.6$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#27.1
2209.07695v3.pdf	Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#62.7$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#62.7$Domain Adaptation#GTA5 to Cityscapes#mIoU#62.7$Domain Adaptation#GTAV to Cityscapes+Mapillary#mIoU#58.6$Domain Adaptation#GTAV+Synscapes to Cityscapes#mIoU#69.0
2208.06100v1.pdf	Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#62.0$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#62.0$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#58.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#69.2$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#61.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#64.6$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#57.8$Domain Adaptation#GTA5 to Cityscapes#mIoU#62.0
1409.1556v6.pdf	Image-to-Image Translation#GTAV-to-Cityscapes Labels#mIoU#41.3$Activity Recognition In Videos#DogCentric#Accuracy#59.9$Image Classification#ImageNet#Top 1 Accuracy#74.5%$Image Classification#ImageNet#Top 5 Accuracy#92.0$Image Classification#ImageNet#Number of params#144M$Image Classification#ImageNet#Hardware Burden#31G$Image Classification#ImageNet#Top 1 Accuracy#74.4%$Image Classification#ImageNet#Top 5 Accuracy#91.9$Image Classification#ImageNet#Number of params#138M$Image Classification#ImageNet ReaL#Accuracy#80.60%$Image Classification#ImageNet ReaL#Accuracy#79.01%
2106.16031v3.pdf	Image-to-Image Translation#BRATS#PSNR#26.90$Image-to-Image Translation#IXI#PSNR#35.71 ± 1.77$Image-to-Image Translation#IXI#PSNR#33.95 ± 1.67$Image-to-Image Translation#IXI#PSNR#33.71 ± 1.61$Image-to-Image Translation#IXI#PSNR#33.62 ± 2.07$Image-to-Image Translation#IXI#PSNR#32.49 ± 1.74$Image-to-Image Translation#IXI#PSNR#32.43 ± 1.74
2103.06878v1.pdf	Image-to-Image Translation#Deep-Fashion#FID#9.97$Image-to-Image Translation#Cityscapes Labels-to-Photo#LPIPS#0.248$Image-to-Image Translation#ADE20K Labels-to-Photos#LPIPS#0.400
2004.05571v1.pdf	Image-to-Image Translation#Deep-Fashion#FID#14.4$Image-to-Image Translation#CelebA-HQ#FID#14.3$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#42.4$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#26.4
1611.07004v3.pdf	Image-to-Image Translation#Aerial-to-Map#Per-pixel Accuracy#70.0%$Image-to-Image Translation#Aerial-to-Map#Per-class Accuracy#46.0%$Image-to-Image Translation#Aerial-to-Map#Class IOU#0.26$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-pixel Accuracy#85.0%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-class Accuracy#40.0%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Class IOU#0.32$Image-to-Image Translation#Cityscapes Labels-to-Photo#Class IOU#0.18$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-class Accuracy#25.0$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#71.0$Image-to-Image Translation#Cityscapes Labels-to-Photo#LPIPS#0$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#48.6$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SSIM#0.4808$Cross-View Image-to-Image Translation#Dayton (256×256) - ground-to-aerial#SSIM#0.2693$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.418$Cross-View Image-to-Image Translation#Dayton (64x64) - ground-to-aerial#SSIM#0.3675$Cross-View Image-to-Image Translation#cvusa#SSIM#0.3923$Cross-View Image-to-Image Translation#Ego2Top#SSIM#0.2213$Nuclear Segmentation#Cell17#F1-score#0.6208$Nuclear Segmentation#Cell17#Dice#0.6351$Nuclear Segmentation#Cell17#Hausdorff#19.1441$Image Reconstruction#Edge-to-Handbags#FID#96.31$Image Reconstruction#Edge-to-Handbags#LPIPS#0.234$Image Reconstruction#Edge-to-Shoes#FID#197.492$Image Reconstruction#Edge-to-Shoes#LPIPS#0.238$Colorization#ImageNet val#FID-5K#24.41
1704.02510v4.pdf	Image-to-Image Translation#Aerial-to-Map#Per-pixel Accuracy#42%$Image-to-Image Translation#Aerial-to-Map#Per-class Accuracy#22%$Image-to-Image Translation#Aerial-to-Map#Class IOU#0.09
1606.07536v2.pdf	Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-pixel Accuracy#45%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-class Accuracy#11%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Class IOU#0.08$Image-to-Image Translation#Cityscapes Labels-to-Photo#Class IOU#0.06$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-class Accuracy#10%$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#40%
1606.00704v3.pdf	Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-pixel Accuracy#41%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-class Accuracy#13%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Class IOU#0.07$Image-to-Image Translation#Cityscapes Labels-to-Photo#Class IOU#0.02$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-class Accuracy#6%$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#19%$Image Generation#CIFAR-10#Inception score#5.34
1612.07828v2.pdf	Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-pixel Accuracy#47%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Per-class Accuracy#11%$Image-to-Image Translation#Cityscapes Photo-to-Labels#Class IOU#0.07$Image-to-Image Translation#Cityscapes Labels-to-Photo#Class IOU#0.04$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-class Accuracy#10%$Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#20%
1912.01865v2.pdf	Image-to-Image Translation#CelebA-HQ#FID#13.73$Image-to-Image Translation#CelebA-HQ#LPIPS#0.428$Image-to-Image Translation#AFHQ#FID#24.4$Image-to-Image Translation#AFHQ#LPIPS#0.524$Multimodal Unsupervised Image-To-Image Translation#AFHQ#FID#16.2$Multimodal Unsupervised Image-To-Image Translation#CelebA-HQ#FID#13.73$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#27.7$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00118
2205.02087v1.pdf	Image-to-Image Translation#CelebA-HQ#FID#16.54$Image-to-Image Translation#CelebA-HQ#LPIPS#0.29$Image-to-Image Translation#CelebA-HQ#FID#16.63$Image-to-Image Translation#CelebA-HQ#LPIPS#0.33
2107.11262v1.pdf	Image-to-Image Translation#CelebA-HQ#FID#23.8
2004.04977v2.pdf	Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#82.5%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#66$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#54.2$Image-to-Image Translation#ADE20K Labels-to-Photos#mIoU#49$Image-to-Image Translation#ADE20K Labels-to-Photos#Accuracy#85.5%$Image-to-Image Translation#ADE20K Labels-to-Photos#FID#31.9
2012.12821v3.pdf	Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#82.5%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#64.2$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#59.5
1804.10992v1.pdf	Image-to-Image Translation#Cityscapes Labels-to-Photo#Per-pixel Accuracy#75.5%$Image-to-Image Translation#Cityscapes Labels-to-Photo#mIoU#47.2$Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#49.7$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#mIoU#13.1$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#Accuracy#74.7%$Image-to-Image Translation#ADE20K-Outdoor Labels-to-Photos#FID#67.7
1911.11357v1.pdf	Image-to-Image Translation#Cityscapes Labels-to-Photo#FID#60.39$Image-to-Image Translation#ADE-Indoor Labels-to-Photo#FID#48.15$Image Generation#Cityscapes-5K 256x512#FID#65.49$Image Generation#Cityscapes-25K 256x512#FID#62.97$Image Generation#ADE-Indoor#FID#85.27
1711.03213v3.pdf	Image-to-Image Translation#SYNTHIA Fall-to-Winter#mIoU#63.3$Image-to-Image Translation#SYNTHIA Fall-to-Winter#Per-pixel Accuracy#92.1%$Image-to-Image Translation#SYNTHIA Fall-to-Winter#fwIOU#85.7$Unsupervised Image-To-Image Translation#SVNH-to-MNIST#Classification Accuracy#90.4%$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#39.5$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#fwIOU#72.4$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#Per-pixel Accuracy#82.3%$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#34.8$Domain Adaptation#SVHN-to-MNIST#Accuracy#90.4
1811.09117v1.pdf	Image-to-Image Translation#2017_test set#10 way 1~2 shot#457$Medical Report Generation#300W (Full)#10 fold Cross validation#No
1812.10889v2.pdf	Image-to-Image Translation#Object Transfiguration (sheep-to-giraffe)#classification score#78.1$Image-to-Image Translation#Object Transfiguration (sheep-to-giraffe)#classification score#59.4
2003.12943v2.pdf	Image-to-Image Translation#Cityscapes-to-Foggy Cityscapes#mAP#38.8$Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#38.8$Weakly Supervised Object Detection#Watercolor2k#MAP#56.0
1910.11319v1.pdf	Image-to-Image Translation#Cityscapes-to-Foggy Cityscapes#mAP#36.9
1905.05396v1.pdf	Image-to-Image Translation#Cityscapes-to-Foggy Cityscapes#mAP#34.6$Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#34.6
1803.03243v1.pdf	Image-to-Image Translation#Cityscapes-to-Foggy Cityscapes#mAP#27.6$Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#26.1
1611.02200v1.pdf	Unsupervised Image-To-Image Translation#SVNH-to-MNIST#Classification Accuracy#84.4%
1702.05464v1.pdf	Unsupervised Image-To-Image Translation#SVNH-to-MNIST#Classification Accuracy#76.0%$Domain Adaptation#MNIST-to-USPS#Accuracy#90.1$Domain Adaptation#SVHN-to-MNIST#Accuracy#80.1$Unsupervised Domain Adaptation#EPIC-KITCHENS-100#Average Accuracy#37.4$Unsupervised Domain Adaptation#UCF-HMDB#Accuracy#79.17$Unsupervised Domain Adaptation#HMDB-UCF#Accuracy#88.44$Unsupervised Domain Adaptation#Jester#Accuracy#52.3
1409.7495v2.pdf	Unsupervised Image-To-Image Translation#SVNH-to-MNIST#Classification Accuracy#73.6%$Domain Adaptation#Olympic-to-HMDBsmall#Accuracy#90.00$Domain Adaptation#UCF-to-HMDBsmall#Accuracy#99.33$Domain Adaptation#HMDBsmall-to-UCF#Accuracy#98.41$Domain Adaptation#HMDBfull-to-UCF#Accuracy#74.44$Domain Adaptation#UCF-to-Olympic#Accuracy#98.15$Domain Adaptation#UCF-to-HMDBfull#Accuracy#74.44$Transfer Learning#Office-Home#Accuracy#57.6$Multi-target Domain Adaptation#Office-Home#Accuracy#57.9$Multi-target Domain Adaptation#Office-31#Accuracy#73.4
1711.09334v1.pdf	Unsupervised Image-To-Image Translation#Freiburg Forest Dataset#PSNR#21.65$Multimodal Unsupervised Image-To-Image Translation#EPFL NIR-VIS#PSNR#23.11
1703.00848v6.pdf	Unsupervised Image-To-Image Translation#Freiburg Forest Dataset#PSNR#9.42$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Quality#37.3%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Diversity#0.023$Multimodal Unsupervised Image-To-Image Translation#EPFL NIR-VIS#PSNR#15.33$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Quality#37.4%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Diversity#0.011$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#CIS#0.115$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#IS#0.826
1911.12036v2.pdf	Synthetic-to-Real Translation#Syn2Real-C#Accuracy#79.8$Domain Adaptation#Office-31#Average Accuracy#89
1711.01575v3.pdf	Synthetic-to-Real Translation#Syn2Real-C#Accuracy#74.8
1902.08727v1.pdf	Synthetic-to-Real Translation#Syn2Real-C#Accuracy#73.3
1712.02560v4.pdf	Synthetic-to-Real Translation#Syn2Real-C#Accuracy#71.9$Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#94.4$Domain Adaptation#USPS-to-MNIST#Accuracy#95.7$Domain Adaptation#MNIST-to-USPS#Accuracy#93.8$Domain Adaptation#SVHN-to-MNIST#Accuracy#95.8$Domain Adaptation#HMDBfull-to-UCF#Accuracy#79.34$Domain Adaptation#UCF-to-HMDBfull#Accuracy#73.89
1505.07818v4.pdf	Synthetic-to-Real Translation#Syn2Real-C#Accuracy#57.4$Domain Adaptation#SVNH-to-MNIST#Accuracy#70.7$Domain Adaptation#Synth Digits-to-SVHN#Accuracy#90.3$Domain Adaptation#MNIST-to-MNIST-M#Accuracy#77.4$Unsupervised Domain Adaptation#EPIC-KITCHENS-100#Average Accuracy#39.2$Unsupervised Domain Adaptation#UCF-HMDB#Accuracy#80.83$Unsupervised Domain Adaptation#HMDB-UCF#Accuracy#88.09$Unsupervised Domain Adaptation#Office-Home#Accuracy#76.8$Unsupervised Domain Adaptation#Jester#Accuracy#55.4$Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#75.40$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#71.43$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#77.67$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#80.53$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#76.26
2208.14227v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#74.4$Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#70.11$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#67.2$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#74.4$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#67.2$Unsupervised Domain Adaptation#GTA5-to-Cityscapes#mIoU#74.4
2204.07730v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#61.2$Domain Adaptation#GTA5 to Cityscapes#mIoU#61.2$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#61.2
2112.00295v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#58.2
2104.13613v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#56.6$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#62.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#55.0$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#55.0
2103.13041v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#56.1$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#55.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#48.2
2107.09600v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#55.0$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#59.9$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#51.0
2105.00097v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#53.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#59.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#52.6$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#52.6$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#49.1
2110.05170v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#53.5
2108.06337v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#53.3
2111.15300v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#53.3
2109.08912v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#52.8
2007.08702v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#52.14$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#54.81$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#48.34$Domain Adaptation#Cityscapes to ACDC#mIoU#41.2
2103.05254v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#52.1$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#52.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#45.1
2111.12358v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#52.1
2107.06235v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#51.66$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#46.45$Domain Generalization#WildDash#Mean IoU#31.2
2105.02001v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#51.6$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#57.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#49.8
2010.05785v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#51.5
2103.15685v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#50.9$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#57.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#50.4$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#52.9$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#45.9$Domain Adaptation#GTA5 to Cityscapes#mIoU#49.0$Domain Adaptation#GTA5+Synscapes to Cityscapes#mIoU#50.8$Domain Adaptation#GTAV+Synscapes to Cityscapes#mIoU#50.8$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#50.9$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#57.5$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#50.4$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#52.9$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#45.9$Unsupervised Domain Adaptation#Cityscapes-to-OxfordCar#mIoU#75.2$Unsupervised Domain Adaptation#Cityscapes-to-OxfordCar#mIoU#73.7$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.05±0.12
2105.08128v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#50.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#54.5$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#46.1
2003.03773v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#50.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#54.9$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#47.9$Domain Adaptation#GTA5 to Cityscapes#mIoU#50.3$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#50.3$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#54.9$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#47.9$Unsupervised Domain Adaptation#Cityscapes-to-OxfordCar#mIoU#74.4
1909.13776v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#49
1912.11164v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#48.3$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#53.8$Domain Adaptation#GTA5 to Cityscapes#mIoU#48.3$Domain Adaptation#GTA5+Synscapes to Cityscapes#mIoU#47.6$Domain Adaptation#GTAV+Synscapes to Cityscapes#mIoU#47.6$Domain Adaptation#SYNTHIA-to-Cityscapes Labels#mIoU#46.5$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#45.5$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#50.2$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#43.2$Unsupervised Domain Adaptation#Cityscapes-to-OxfordCar#mIoU#73.9
2011.00147v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#47.8$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#54.0$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (16 classes)#46.8
1810.07911v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#47.0
2004.07703v4.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#46.3$Domain Adaptation#Synscapes-to-Cityscapes#mIoU#54.2
1808.00948v1.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#43.2$Multimodal Unsupervised Image-To-Image Translation#AFHQ#FID#95.6$Multimodal Unsupervised Image-To-Image Translation#CelebA-HQ#FID#52.1
1809.09478v3.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#43.2$Synthetic-to-Real Translation#SYNTHIA-to-Cityscapes#MIoU (13 classes)#47.8$Semantic Segmentation#DADA-seg#mIoU#28.76$Semantic Segmentation#DensePASS#mIoU#31.46%
1909.11825v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#41.2
1911.12796v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#40.5$Domain Adaptation#USPS-to-MNIST#Accuracy#98.3$Domain Adaptation#MNIST-to-USPS#Accuracy#97.1$Domain Adaptation#SVHN-to-MNIST#Accuracy#97.5
1711.11556v2.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#39.4
1904.09739v4.pdf	Synthetic-to-Real Translation#GTAV-to-Cityscapes Labels#mIoU#35.7
1804.04732v2.pdf	Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Quality#50.0%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Diversity#0.175$Multimodal Unsupervised Image-To-Image Translation#AFHQ#FID#41.5$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Quality#50.0%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Diversity#0.109$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#CIS#1.039$Multimodal Unsupervised Image-To-Image Translation#Cats-and-Dogs#IS#1.050$Multimodal Unsupervised Image-To-Image Translation#CelebA-HQ#FID#31.4
1711.11586v4.pdf	Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Quality#51.2%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Handbags#Diversity#0.140$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Quality#56.7%$Multimodal Unsupervised Image-To-Image Translation#Edge-to-Shoes#Diversity#0.104
1903.05628v6.pdf	Multimodal Unsupervised Image-To-Image Translation#AFHQ#FID#61.4$Multimodal Unsupervised Image-To-Image Translation#CelebA-HQ#FID#33.1$Image Generation#CIFAR-10#FID#28.73
2104.06757v3.pdf	Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#17.3$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00053
2007.09191v1.pdf	Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#20.7$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00392$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#24.6$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00087$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#47.5$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00595
2005.05267v2.pdf	Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#FID#30.3$Fundus to Angiography Generation#Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients#Kernel Inception Distance#0.00184
1904.06807v2.pdf	Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SSIM#0.6865$Cross-View Image-to-Image Translation#Dayton (256×256) - ground-to-aerial#SSIM#0.3284$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.5938$Cross-View Image-to-Image Translation#Dayton (64x64) - ground-to-aerial#SSIM#0.5118$Cross-View Image-to-Image Translation#cvusa#SSIM#0.5323$Cross-View Image-to-Image Translation#Ego2Top#SSIM#0.6024
1803.03396v2.pdf	Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SSIM#0.5171$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SSIM#0.4921$Cross-View Image-to-Image Translation#Dayton (256×256) - ground-to-aerial#SSIM#0.2725$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.5031$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.4963$Cross-View Image-to-Image Translation#Dayton (64x64) - ground-to-aerial#SSIM#0.3682$Cross-View Image-to-Image Translation#Dayton (64x64) - ground-to-aerial#SSIM#0.3663$Cross-View Image-to-Image Translation#cvusa#SSIM#0.4356$Cross-View Image-to-Image Translation#cvusa#SSIM#0.4231$Cross-View Image-to-Image Translation#Ego2Top#SSIM#0.2740$Cross-View Image-to-Image Translation#Ego2Top#SSIM#0.2738
1912.06112v2.pdf	Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SSIM#0.5064$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#KL#2.16$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#LPIPS#0.3817$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#PSNR#23.3632$Cross-View Image-to-Image Translation#Dayton (64×64) - aerial-to-ground#SD#16.4788$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.3357$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#KL#5.17$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#PSNR#22.0273$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SD#17.6542$Cross-View Image-to-Image Translation#Dayton (64x64) - ground-to-aerial#LPIPS#0.4527$Cross-View Image-to-Image Translation#cvusa#SSIM#0.5366$Cross-View Image-to-Image Translation#cvusa#KL#2.6$Cross-View Image-to-Image Translation#cvusa#PSNR#22.8223$Cross-View Image-to-Image Translation#cvusa#SD#19.8276$Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#32.6574$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.3783$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#29.3$Gesture-to-Gesture Translation#NTU Hand Digit#FID#6.7493$Gesture-to-Gesture Translation#NTU Hand Digit#FRD#1.7401$Gesture-to-Gesture Translation#Senz3D#PSNR#31.542$Gesture-to-Gesture Translation#Senz3D#IS#2.2159$Gesture-to-Gesture Translation#Senz3D#AMT#27.6$Gesture-to-Gesture Translation#Senz3D#FID#12.4465$Gesture-to-Gesture Translation#Senz3D#FRD#2.2104
1808.05469v2.pdf	Cross-View Image-to-Image Translation#Dayton (256×256) - ground-to-aerial#SSIM#0.2763
1912.12215v3.pdf	Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SSIM#0.5457$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#KL#2.18$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#PSNR#22.9949$Cross-View Image-to-Image Translation#Dayton (256×256) - aerial-to-ground#SD#19.6145$Cross-View Image-to-Image Translation#cvusa#SSIM#0.5238$Cross-View Image-to-Image Translation#cvusa#KL#2.55$Cross-View Image-to-Image Translation#cvusa#PSNR#22.5766$Cross-View Image-to-Image Translation#cvusa#SD#19.744
1612.02709v1.pdf	Cross-View Image-to-Image Translation#cvusa#SSIM#0.4147
2005.04078v1.pdf	Cross-View Image-to-Image Translation#Cam2BEV#Mean IoU#71.92$Semantic Segmentation#Cam2BEV#Mean IoU#71.92
2104.01867v1.pdf	Facial Makeup Transfer#CPM-Synt-2#MS-SSIM#0.977$Facial Makeup Transfer#CPM-Synt-1#mIOU#0.788
2206.08083v3.pdf	Domain Adaptation#MoLane#Lane Accuracy (LA)#93.94$Domain Adaptation#MoLane#Lane Accuracy (LA)#93.82$Domain Adaptation#MoLane#Lane Accuracy (LA)#93.53$Domain Adaptation#MoLane#Lane Accuracy (LA)#93.31$Domain Adaptation#MoLane#Lane Accuracy (LA)#92.85$Domain Adaptation#MoLane#Lane Accuracy (LA)#92.39$Domain Adaptation#MoLane#Lane Accuracy (LA)#90.91$Domain Adaptation#MoLane#Lane Accuracy (LA)#87.65$Domain Adaptation#MuLane#Lane Accuracy (LA)#91.63$Domain Adaptation#MuLane#Lane Accuracy (LA)#91.57$Domain Adaptation#MuLane#Lane Accuracy (LA)#91.55$Domain Adaptation#MuLane#Lane Accuracy (LA)#90.71$Domain Adaptation#MuLane#Lane Accuracy (LA)#90.22$Domain Adaptation#MuLane#Lane Accuracy (LA)#89.83$Domain Adaptation#MuLane#Lane Accuracy (LA)#88.76$Domain Adaptation#MuLane#Lane Accuracy (LA)#86.01$Domain Adaptation#TuLane#Lane Accuracy (LA)#93.29$Domain Adaptation#TuLane#Lane Accuracy (LA)#92.04$Domain Adaptation#TuLane#Lane Accuracy (LA)#91.70$Domain Adaptation#TuLane#Lane Accuracy (LA)#91.55$Domain Adaptation#TuLane#Lane Accuracy (LA)#91.39$Domain Adaptation#TuLane#Lane Accuracy (LA)#91.06$Domain Adaptation#TuLane#Lane Accuracy (LA)#90.72$Domain Adaptation#TuLane#Lane Accuracy (LA)#88.74
1905.10861v5.pdf	Domain Adaptation#Olympic-to-HMDBsmall#Accuracy#92.92$Domain Adaptation#UCF-to-HMDBsmall#Accuracy#99.33$Domain Adaptation#HMDBsmall-to-UCF#Accuracy#99.47$Domain Adaptation#HMDBfull-to-UCF#Accuracy#81.79$Domain Adaptation#UCF-to-Olympic#Accuracy#98.15$Domain Adaptation#UCF-to-HMDBfull#Accuracy#78.33
2108.10840v1.pdf	Domain Adaptation#MSDA#Average Accuracy#42%$Scene Text Recognition#MSDA#Average Accuracy#42%
2006.12770v5.pdf	Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#97.5$Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#96.8$Domain Adaptation#USPS-to-MNIST#Accuracy#96.6$Domain Adaptation#USPS-to-MNIST#Accuracy#96.2$Domain Adaptation#ImageCLEF-DA#Accuracy#90.2$Domain Adaptation#ImageCLEF-DA#Accuracy#89.1$Domain Adaptation#MNIST-to-USPS#Accuracy#98.6$Domain Adaptation#MNIST-to-USPS#Accuracy#97.9$Domain Adaptation#SVHN-to-MNIST#Accuracy#98.9$Domain Adaptation#SVHN-to-MNIST#Accuracy#98.2$Transfer Learning#Office-Home#Accuracy#69.2$Transfer Learning#Office-Home#Accuracy#69.1
1905.10748v4.pdf	Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#93.61$Domain Adaptation#SVNH-to-MNIST#Accuracy#98.91$Domain Adaptation#USPS-to-MNIST#Accuracy#95.03$Domain Adaptation#MNIST-to-USPS#Accuracy#94.76$Domain Adaptation#Office-31#Average Accuracy#73.5
1502.02791v2.pdf	Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#91.1$Domain Adaptation#SVNH-to-MNIST#Accuracy#71.1$Domain Adaptation#Synth Digits-to-SVHN#Accuracy#88.0$Domain Adaptation#ImageCLEF-DA#Accuracy#76.9$Domain Adaptation#Synth Signs-to-GTSRB#Accuracy#91.1$Domain Adaptation#Office-Caltech#Average Accuracy#90.1$Domain Adaptation#MNIST-to-MNIST-M#Accuracy#76.9$Unsupervised Domain Adaptation#Office-Home#Accuracy#74.3
1708.00938v1.pdf	Domain Adaptation#SYNSIG-to-GTSRB#Accuracy#82.8
2002.08546v6.pdf	Domain Adaptation#SVNH-to-MNIST#Accuracy#98.9$Domain Adaptation#VisDA2017#Accuracy#82.9$Domain Adaptation#USPS-to-MNIST#Accuracy#98.4$Domain Adaptation#MNIST-to-USPS#Accuracy#98.0$Domain Adaptation#SVHN-to-MNIST#Accuracy#98.9$Domain Adaptation#Office-Home#Accuracy#71.8$Domain Adaptation#Office-31#Average Accuracy#88.6$Partial Domain Adaptation#Office-Home#Accuracy (%)#78.3
1903.09980v2.pdf	Domain Adaptation#SVNH-to-MNIST#Accuracy#98.8$Domain Adaptation#USPS-to-MNIST#Accuracy#96.3$Domain Adaptation#ImageCLEF-DA#Accuracy#80.7$Domain Adaptation#MNIST-to-USPS#Accuracy#96$Domain Adaptation#Office-31#Average Accuracy#80.1
1909.07618v1.pdf	Domain Adaptation#SVNH-to-MNIST#Accuracy#92.5$Domain Adaptation#USPS-to-MNIST#Accuracy#98.3$Domain Adaptation#MNIST-to-USPS#Accuracy#96.1
1608.06019v1.pdf	Domain Adaptation#SVNH-to-MNIST#Accuracy#82.7$Domain Adaptation#Synth Digits-to-SVHN#Accuracy#91.2$Domain Adaptation#Synth Signs-to-GTSRB#Accuracy#93.1$Domain Adaptation#Synth Objects-to-LINEMOD#Classification Accuracy#100$Domain Adaptation#Synth Objects-to-LINEMOD#Mean Angle Error#53.27$Domain Adaptation#MNIST-to-MNIST-M#Accuracy#83.2$Domain Generalization#PACS#Average Accuracy#67.37
2210.04831v1.pdf	Domain Adaptation#VisDA2017#Accuracy#90.7
2206.08213v1.pdf	Domain Adaptation#VisDA2017#Accuracy#89.8$Domain Adaptation#Office-Home#Accuracy#84.3
2111.13353v3.pdf	Domain Adaptation#VisDA2017#Accuracy#88.5$Domain Adaptation#Office-Home#Accuracy#73.1$Domain Adaptation#Office-31#Average Accuracy#91.8$Unsupervised Domain Adaptation#PACS#Average Accuracy#93.52
2109.06165v4.pdf	Domain Adaptation#VisDA2017#Accuracy#88.4$Domain Adaptation#Office-Home#Accuracy#80.5$Domain Adaptation#Office-31#Average Accuracy#92.6$Unsupervised Domain Adaptation#Office-Home#Accuracy#80.5
2011.09230v2.pdf	Domain Adaptation#VisDA2017#Accuracy#87.2$Domain Adaptation#Office-Home#Accuracy#72.7$Domain Adaptation#Office-31#Average Accuracy#91.4
1901.00976v2.pdf	Domain Adaptation#VisDA2017#Accuracy#87.2$Domain Adaptation#Office-31#Average Accuracy#90.6
2106.15326v1.pdf	Domain Adaptation#VisDA2017#Accuracy#86.0$Domain Adaptation#Office-Home#Accuracy#71.6$Domain Adaptation#Office-31#Average Accuracy#89.9
1706.05208v4.pdf	Domain Adaptation#VisDA2017#Accuracy#85.4$Domain Adaptation#USPS-to-MNIST#Accuracy#98.07$Domain Adaptation#Synth Signs-to-GTSRB#Accuracy#98.66$Domain Adaptation#MNIST-to-USPS#Accuracy#98.26$Domain Adaptation#SVHN-to-MNIST#Accuracy#99.18
2204.03838v1.pdf	Domain Adaptation#VisDA2017#Accuracy#83.7$Domain Adaptation#ImageCLEF-DA#Accuracy#90.7$Domain Adaptation#Office-Home#Accuracy#72.6$Domain Adaptation#Office-31#Average Accuracy#90.4
1910.05562v1.pdf	Domain Adaptation#VisDA2017#Accuracy#81.5
2012.11460v2.pdf	Domain Adaptation#VisDA2017#Accuracy#76.7$Domain Adaptation#Office-Home#Accuracy#72.2
1811.07456v2.pdf	Domain Adaptation#VisDA2017#Accuracy#76.1$Domain Adaptation#ImageCLEF-DA#Accuracy#88.9$Domain Adaptation#Office-31#Average Accuracy#87.1$Partial Domain Adaptation#Office-Home#Accuracy (%)#71.8
1705.10667v4.pdf	Domain Adaptation#VisDA2017#Accuracy#73.7$Domain Adaptation#USPS-to-MNIST#Accuracy#98.0$Domain Adaptation#SVHN-to-MNIST#Accuracy#89.2
1605.06636v2.pdf	Domain Adaptation#VisDA2017#Accuracy#58.3$Domain Adaptation#HMDBfull-to-UCF#Accuracy#79.69$Domain Adaptation#UCF-to-HMDBfull#Accuracy#74.72$Unsupervised Domain Adaptation#Office-Home#Accuracy#76.8
2201.02588v3.pdf	Domain Adaptation#SYNTHIA-to-FoggyCityscapes#mIoU#45.2$Domain Adaptation#Cityscapes-to-FoggyDriving#mIoU#53.4$Domain Adaptation#GTA-to-FoggyCityscapes#mIoU#45$Domain Adaptation#Cityscapes-to-FoggyZurich#mIoU#50.6$Foggy Scene Segmentation#foggy zurich#mIoU (val)#50.6
2204.01587v1.pdf	Domain Adaptation#Cityscapes-to-FoggyDriving#mIoU#50.7$Domain Adaptation#Cityscapes-to-FoggyZurich#mIoU#48.4
1901.01415v2.pdf	Domain Adaptation#Cityscapes-to-FoggyDriving#mIoU#49.8$Domain Adaptation#Cityscapes-to-FoggyZurich#mIoU#46.8
1511.05547v2.pdf	Domain Adaptation#Synth Digits-to-SVHN#Accuracy#85.2$Domain Adaptation#Synth Signs-to-GTSRB#Accuracy#86.9
2207.06654v1.pdf	Domain Adaptation#GTA5 to Cityscapes#mIoU#56.3$Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#59.6
2108.11249v1.pdf	Domain Adaptation#GTA5 to Cityscapes#mIoU#53.4$Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#60.1$Domain Generalization#GTA5-to-Cityscapes#mIoU#43.5
2103.04717v3.pdf	Domain Adaptation#GTA5+Synscapes to Cityscapes#mIoU#59.0$Domain Adaptation#GTAV+Synscapes to Cityscapes#mIoU#59.0
1910.12181v1.pdf	Domain Adaptation#GTA5+Synscapes to Cityscapes#mIoU#55.7$Domain Adaptation#GTAV+Synscapes to Cityscapes#mIoU#55.7
2006.06570v1.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#51.2
2108.03267v1.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#46.2$Unsupervised Domain Adaptation#GTAV-to-Cityscapes Labels#mIoU#47.3
2009.01166v1.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#41.5
2003.04614v3.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#41.1
2003.04010v1.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#40.8
2004.05498v1.pdf	Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU#40.5$Domain Adaptation#Cityscapes to ACDC#mIoU#45.7$Semantic Segmentation#DADA-seg#mIoU#24.45
2103.13447v2.pdf	Domain Adaptation#USPS-to-MNIST#Accuracy#97.8$Domain Adaptation#MNIST-to-USPS#Accuracy#98.2$Domain Adaptation#MNIST-M-to-MNIST#Accuracy#99.3$Domain Adaptation#MNIST-to-MNIST-M#Accuracy#98.7
2208.07365v1.pdf	Domain Adaptation#UCF --> HMDB (full)#Accuracy#87.78$Domain Adaptation#HMDB --> UCF (full)#Accuracy#98.95$Unsupervised Domain Adaptation#EPIC-KITCHENS-100#Average Accuracy#52.6$Unsupervised Domain Adaptation#UCF-HMDB#Accuracy#87.78$Unsupervised Domain Adaptation#HMDB-UCF#Accuracy#98.95$Unsupervised Domain Adaptation#Jester#Accuracy#66.1
2110.15128v1.pdf	Domain Adaptation#UCF --> HMDB (full)#Accuracy#86.66$Unsupervised Domain Adaptation#EPIC-KITCHENS-100#Average Accuracy#43.2$Unsupervised Domain Adaptation#UCF-HMDB#Accuracy#86.66$Unsupervised Domain Adaptation#HMDB-UCF#Accuracy#93.87$Unsupervised Domain Adaptation#Jester#Accuracy#64.7
1907.12743v6.pdf	Domain Adaptation#UCF --> HMDB (full)#Accuracy#78.33$Domain Adaptation#HMDB --> UCF (full)#Accuracy#81.79$Unsupervised Domain Adaptation#EPIC-KITCHENS-100#Average Accuracy#39.9$Unsupervised Domain Adaptation#UCF-HMDB#Accuracy#81.38$Unsupervised Domain Adaptation#HMDB-UCF#Accuracy#90.54$Unsupervised Domain Adaptation#Jester#Accuracy#55.5
1807.07258v2.pdf	Domain Adaptation#Office-Caltech-10#Accuracy (%)#92.8$Domain Adaptation#Office-Caltech#Average Accuracy#92.8$Transfer Learning#Office-Home#Accuracy#60.3
1911.07982v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#90.3$Domain Adaptation#Office-Caltech#Average Accuracy#93$Domain Adaptation#Office-Home#Accuracy#71$Domain Adaptation#Office-31#Average Accuracy#89.6
2001.00153v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#89.3$Domain Adaptation#Office-31#Average Accuracy#88
2002.01690v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#88.9$Domain Adaptation#Office-Home#Accuracy#69.5$Domain Adaptation#Office-31#Average Accuracy#89.2
1909.08531v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#88.9$Domain Adaptation#Office-Home#Accuracy#67.6$Domain Adaptation#Office-31#Average Accuracy#85.7
1906.03502v2.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#88.3$Domain Adaptation#Office-Home#Accuracy#70.2$Domain Adaptation#Office-31#Average Accuracy#89.5
1904.01376v2.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#88.2$Transfer Learning#Office-Home#Accuracy#63.3
1904.01341v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#80.6$Domain Adaptation#Office-Home#Accuracy#49.46$Domain Adaptation#Office-31#Average Accuracy#78.5
1911.12983v1.pdf	Domain Adaptation#ImageCLEF-DA#Accuracy#80.2$Domain Adaptation#Office-Home#Accuracy#48.19$Domain Adaptation#Office-31#Average Accuracy#78.3$Domain Generalization#PACS#Average Accuracy#71.98
1905.07720v3.pdf	Domain Adaptation#Noisy-Amazon (45%)#Average Accuracy#56.01$Domain Adaptation#Noisy-SYND-to-MNIST#Average Accuracy#94.09$Domain Adaptation#Noisy-Amazon (20%)#Average Accuracy#71.53$Domain Adaptation#Noisy-MNIST-to-SYND#Average Accuracy#57.55$Wildly Unsupervised Domain Adaptation#Noisy-SYND-to-MNIST#Average Accuracy#94.09$Wildly Unsupervised Domain Adaptation#Noisy-Amazon (20%)#Average Accuracy#71.53$Wildly Unsupervised Domain Adaptation#Noisy-Amazon (45%)#Average Accuracy#56.01$Wildly Unsupervised Domain Adaptation#Noisy-MNIST-to-SYND#Average Accuracy#57.55
2007.01807v2.pdf	Domain Adaptation#Rotating MNIST#Accuracy (%)#87.1%$Domain Adaptation#Rotating MNIST#Accuracy (%)#85.7%$Continuously Indexed Domain Adaptation#Circle#Accuracy (%)#94%$Continuously Indexed Domain Adaptation#Indexed Rotating MNIST#Accuracy (%)#87.1%$Continuously Indexed Domain Adaptation#Indexed Rotating MNIST#Accuracy (%)#85.7%$Continuously Indexed Domain Adaptation#Sine#Accuracy (%)#95%
2007.15829v1.pdf	Domain Adaptation#HMDB --> UCF (full)#Accuracy#85.11
2203.06811v1.pdf	Domain Adaptation#GTAV to Cityscapes+Mapillary#mIoU#47.5
2106.03418v1.pdf	Domain Adaptation#GTAV to Cityscapes+Mapillary#mIoU#46.8
1811.08585v2.pdf	Domain Adaptation#SVHN-to-MNIST#Accuracy#93.9
1705.08824v2.pdf	Domain Adaptation#SVHN-to-MNIST#Accuracy#76.1
1903.10601v2.pdf	Domain Adaptation#Office-Caltech#Average Accuracy#91.8
1705.05498v1.pdf	Domain Adaptation#Office-Caltech#Average Accuracy#90.0
1412.3474v1.pdf	Domain Adaptation#Office-Caltech#Average Accuracy#88.2
1510.04373v2.pdf	Domain Adaptation#Office-Caltech#Average Accuracy#85.9
1612.01939v1.pdf	Domain Adaptation#Office-Caltech#Average Accuracy#84.7
2111.06021v3.pdf	Domain Adaptation#Office-Home#Accuracy#74.5$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#5.88±1.19$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#42.38±2.52
2103.13561v1.pdf	Domain Adaptation#Office-Home#Accuracy#73.9$Unsupervised Domain Adaptation#Market to Duke#mAP#71.4$Unsupervised Domain Adaptation#Duke to Market#mAP#84.3$Partial Domain Adaptation#Office-Home#Accuracy (%)#80.2
1907.08375v2.pdf	Domain Adaptation#Office-Home#Accuracy#69.8$Domain Adaptation#Office-31#Average Accuracy#85.4
2207.06825v2.pdf	Domain Adaptation#Cityscapes to ACDC#mIoU#72.1$Domain Adaptation#Cityscapes to ACDC#mIoU#65.5$Semantic Segmentation#Nighttime Driving#mIoU#58.0$Semantic Segmentation#Nighttime Driving#mIoU#56.8$Semantic Segmentation#Dark Zurich#mIoU#63.9$Semantic Segmentation#Dark Zurich#mIoU#56.2
2104.10834v1.pdf	Domain Adaptation#Cityscapes to ACDC#mIoU#50.0$Semantic Segmentation#Nighttime Driving#mIoU#47.70$Semantic Segmentation#Nighttime Driving#mIoU#44.98$Semantic Segmentation#Nighttime Driving#mIoU#42.36$Semantic Segmentation#Dark Zurich#mIoU#42.5$Semantic Segmentation#Dark Zurich#mIoU#36.76
2005.14553v2.pdf	Domain Adaptation#Cityscapes to ACDC#mIoU#48.7$Semantic Segmentation#Nighttime Driving#mIoU#49.4$Semantic Segmentation#Dark Zurich#mIoU#42.5
2112.00484v1.pdf	Domain Adaptation#Cityscapes-to-FoggyZurich#mIoU#49.1
1904.02322v2.pdf	Domain Adaptation#Office-31#Average Accuracy#89.8
1704.01705v4.pdf	Domain Adaptation#Office-31#Average Accuracy#86.5
1809.02176v1.pdf	Domain Adaptation#Office-31#Average Accuracy#85.2
2004.11262v4.pdf	Domain Adaptation#Office-31#Average Accuracy#82.77$Domain Adaptation#Office-31#Average Accuracy#82.17$Domain Adaptation#Office-31#Average Accuracy#81.63
1907.10628v2.pdf	Domain Adaptation#Office-31#Average Accuracy#79.5
2103.11520v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#72.6$Unsupervised Domain Adaptation#Market to Duke#rank-1#85.0$Unsupervised Domain Adaptation#Market to Duke#rank-5#92.1$Unsupervised Domain Adaptation#Market to Duke#rank-10#93.9$Unsupervised Domain Adaptation#Duke to MSMT#mAP#34.5$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#63.9$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#75.3$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#79.6$Unsupervised Domain Adaptation#Market to MSMT#mAP#33.2$Unsupervised Domain Adaptation#Market to MSMT#rank-1#62.3$Unsupervised Domain Adaptation#Market to MSMT#rank-5#74.1$Unsupervised Domain Adaptation#Market to MSMT#rank-10#78.5$Unsupervised Domain Adaptation#Duke to Market#mAP#78.4$Unsupervised Domain Adaptation#Duke to Market#rank-1#92.9$Unsupervised Domain Adaptation#Duke to Market#rank-5#96.9$Unsupervised Domain Adaptation#Duke to Market#rank-10#97.8
2006.06525v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#71.0$Unsupervised Domain Adaptation#Market to Duke#rank-1#83.4$Unsupervised Domain Adaptation#Market to Duke#rank-5#91.7$Unsupervised Domain Adaptation#Market to Duke#rank-10#93.8$Unsupervised Domain Adaptation#Duke to MSMT#mAP#30.7$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#62.7$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#74.5$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#79.0$Unsupervised Domain Adaptation#Market to MSMT#mAP#30.6$Unsupervised Domain Adaptation#Market to MSMT#rank-1#61.4$Unsupervised Domain Adaptation#Market to MSMT#rank-5#73.3$Unsupervised Domain Adaptation#Market to MSMT#rank-10#78.2$Unsupervised Domain Adaptation#Duke to Market#mAP#80.6$Unsupervised Domain Adaptation#Duke to Market#rank-1#92.9$Unsupervised Domain Adaptation#Duke to Market#rank-5#97.2$Unsupervised Domain Adaptation#Duke to Market#rank-10#98.2
2006.02713v2.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#68.8$Unsupervised Domain Adaptation#Market to Duke#rank-1#82.9$Unsupervised Domain Adaptation#Market to Duke#rank-5#90.1$Unsupervised Domain Adaptation#Market to Duke#rank-10#92.5$Unsupervised Domain Adaptation#Duke to MSMT#mAP#26.5$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#53.1$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#65.8$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#70.5$Unsupervised Domain Adaptation#Market to MSMT#mAP#25.4$Unsupervised Domain Adaptation#Market to MSMT#rank-1#51.6$Unsupervised Domain Adaptation#Market to MSMT#rank-5#64.3$Unsupervised Domain Adaptation#Market to MSMT#rank-10#69.7$Unsupervised Domain Adaptation#Duke to Market#mAP#76.7$Unsupervised Domain Adaptation#Duke to Market#rank-1#90.3$Unsupervised Domain Adaptation#Duke to Market#rank-5#96.2$Unsupervised Domain Adaptation#Duke to Market#rank-10#97.7$Unsupervised Person Re-Identification#Market-1501#Rank-1#87.7$Unsupervised Person Re-Identification#Market-1501#MAP#72.6$Unsupervised Person Re-Identification#Market-1501#Rank-10#96.9$Unsupervised Person Re-Identification#Market-1501#Rank-5#95.2$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#81.2$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#92.2$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#90.3$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#65.3
2001.01526v2.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#65.1$Unsupervised Domain Adaptation#Market to Duke#rank-1#78.0$Unsupervised Domain Adaptation#Market to Duke#rank-5#88.8$Unsupervised Domain Adaptation#Market to Duke#rank-10#92.5$Unsupervised Domain Adaptation#Duke to MSMT#mAP#23.3$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#50.1$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#63.9$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#69.8$Unsupervised Domain Adaptation#Market to MSMT#mAP#22.9$Unsupervised Domain Adaptation#Market to MSMT#rank-1#49.2$Unsupervised Domain Adaptation#Market to MSMT#rank-5#63.1$Unsupervised Domain Adaptation#Market to MSMT#rank-10#68.8$Unsupervised Domain Adaptation#Duke to Market#mAP#71.2$Unsupervised Domain Adaptation#Duke to Market#rank-1#87.7$Unsupervised Domain Adaptation#Duke to Market#rank-5#94.9$Unsupervised Domain Adaptation#Duke to Market#rank-10#96.9$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#65.1$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#78.0$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-10#88.8$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-5#92.5$Unsupervised Person Re-Identification#Market-1501->MSMT17#mAP#22.9$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-1#49.2$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#71.2$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Top-1 (%)#87.7$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#mAP#23.5$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Top-1 (%)#50.0
2003.06650v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#61.4$Unsupervised Domain Adaptation#Market to Duke#rank-1#76.5$Unsupervised Domain Adaptation#Market to Duke#rank-5#86.6$Unsupervised Domain Adaptation#Market to Duke#rank-10#89.7$Unsupervised Domain Adaptation#Duke to MSMT#mAP#25.6$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#54.4$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#66.4$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#71.3$Unsupervised Domain Adaptation#Market to MSMT#mAP#23.2$Unsupervised Domain Adaptation#Market to MSMT#rank-1#49.5$Unsupervised Domain Adaptation#Market to MSMT#rank-5#62.2$Unsupervised Domain Adaptation#Market to MSMT#rank-10#67.7$Unsupervised Domain Adaptation#Duke to Market#mAP#70.0$Unsupervised Domain Adaptation#Duke to Market#rank-1#86.9$Unsupervised Domain Adaptation#Duke to Market#rank-5#94.4$Unsupervised Domain Adaptation#Duke to Market#rank-10#96.3
2005.11037v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#58.1$Unsupervised Domain Adaptation#Market to Duke#rank-1#76.3$Unsupervised Domain Adaptation#Market to Duke#rank-5#-$Unsupervised Domain Adaptation#Market to Duke#rank-10#-$Unsupervised Domain Adaptation#Duke to Market#mAP#61.7$Unsupervised Domain Adaptation#Duke to Market#rank-1#82.8$Unsupervised Domain Adaptation#Duke to Market#rank-5#-$Unsupervised Domain Adaptation#Duke to Market#rank-10#-
1912.01349v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#54.5$Unsupervised Domain Adaptation#Market to Duke#rank-1#72.4$Unsupervised Domain Adaptation#Market to Duke#rank-5#-$Unsupervised Domain Adaptation#Market to Duke#rank-10#-$Unsupervised Domain Adaptation#Duke to Market#mAP#60.6$Unsupervised Domain Adaptation#Duke to Market#rank-1#80.5$Unsupervised Domain Adaptation#Duke to Market#rank-5#-$Unsupervised Domain Adaptation#Duke to Market#rank-10#-
1908.00485v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#54.4$Unsupervised Domain Adaptation#Market to Duke#rank-1#74.0$Unsupervised Domain Adaptation#Market to Duke#rank-5#83.7$Unsupervised Domain Adaptation#Market to Duke#rank-10#87.4$Unsupervised Domain Adaptation#Duke to MSMT#mAP#16.0$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#42.5$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#55.9$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#61.5$Unsupervised Domain Adaptation#Market to MSMT#mAP#15.2$Unsupervised Domain Adaptation#Market to MSMT#rank-1#40.4$Unsupervised Domain Adaptation#Market to MSMT#rank-5#53.1$Unsupervised Domain Adaptation#Market to MSMT#rank-10#58.7$Unsupervised Domain Adaptation#Duke to Market#mAP#63.8$Unsupervised Domain Adaptation#Duke to Market#rank-1#84.1$Unsupervised Domain Adaptation#Duke to Market#rank-5#92.8$Unsupervised Domain Adaptation#Duke to Market#rank-10#95.4
1907.13315v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#54.3$Unsupervised Domain Adaptation#Market to Duke#rank-1#72.4$Unsupervised Domain Adaptation#Duke to Market#mAP#54.6$Unsupervised Domain Adaptation#Duke to Market#rank-1#78.4
2004.08787v2.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#54.1$Unsupervised Domain Adaptation#Market to Duke#rank-1#72.6$Unsupervised Domain Adaptation#Market to Duke#rank-5#82.5$Unsupervised Domain Adaptation#Market to Duke#rank-10#85.5$Unsupervised Domain Adaptation#Duke to Market#mAP#68.3$Unsupervised Domain Adaptation#Duke to Market#rank-1#86.7$Unsupervised Domain Adaptation#Duke to Market#rank-5#94.4$Unsupervised Domain Adaptation#Duke to Market#rank-10#96.5
1811.10144v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#53.4$Unsupervised Domain Adaptation#Market to Duke#rank-1#73.0$Unsupervised Domain Adaptation#Market to Duke#rank-5#80.6$Unsupervised Domain Adaptation#Market to Duke#rank-10#83.2$Unsupervised Domain Adaptation#Duke to MSMT#mAP#13.3$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#32.2$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#-$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#51.2$Unsupervised Domain Adaptation#Market to MSMT#mAP#13.2$Unsupervised Domain Adaptation#Market to MSMT#rank-1#31.6$Unsupervised Domain Adaptation#Market to MSMT#rank-5#-$Unsupervised Domain Adaptation#Market to MSMT#rank-10#49.6$Unsupervised Domain Adaptation#Duke to Market#mAP#58.3$Unsupervised Domain Adaptation#Duke to Market#rank-1#80.0$Unsupervised Domain Adaptation#Duke to Market#rank-5#90.0$Unsupervised Domain Adaptation#Duke to Market#rank-10#92.4$Unsupervised Person Re-Identification#Market-1501#Rank-1#87.5$Unsupervised Person Re-Identification#Market-1501#MAP#71.5$Unsupervised Person Re-Identification#Market-1501#Rank-10#96.8$Unsupervised Person Re-Identification#Market-1501#Rank-5#95.2$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#72.4$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#87.7$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#84$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#55.9$Unsupervised Person Re-Identification#Market-1501->MSMT17#mAP#11.8$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-1#27.6$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-10#45.7$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#mAP#23.6$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-1#43.6$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-10#61.8
2004.09228v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#51.4$Unsupervised Domain Adaptation#Market to Duke#rank-1#72.4$Unsupervised Domain Adaptation#Market to Duke#rank-5#82.9$Unsupervised Domain Adaptation#Market to Duke#rank-10#85.0$Unsupervised Domain Adaptation#Duke to MSMT#mAP#16.2$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#43.6$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#54.3$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#58.9$Unsupervised Domain Adaptation#Market to MSMT#mAP#15.1$Unsupervised Domain Adaptation#Market to MSMT#rank-1#40.8$Unsupervised Domain Adaptation#Market to MSMT#rank-5#51.8$Unsupervised Domain Adaptation#Market to MSMT#rank-10#56.7$Unsupervised Domain Adaptation#Duke to Market#mAP#60.4$Unsupervised Domain Adaptation#Duke to Market#rank-1#84.4$Unsupervised Domain Adaptation#Duke to Market#rank-5#92.8$Unsupervised Domain Adaptation#Duke to Market#rank-10#95.0
1807.11334v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#49.0$Unsupervised Domain Adaptation#Market to Duke#rank-1#68.4$Unsupervised Domain Adaptation#Market to Duke#rank-5#80.1$Unsupervised Domain Adaptation#Market to Duke#rank-10#83.5$Unsupervised Domain Adaptation#Duke to Market#mAP#53.7$Unsupervised Domain Adaptation#Duke to Market#rank-1#75.8$Unsupervised Domain Adaptation#Duke to Market#rank-5#89.5$Unsupervised Domain Adaptation#Duke to Market#rank-10#93.2
1909.09675v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#45.1$Unsupervised Domain Adaptation#Market to Duke#rank-1#63.2$Unsupervised Domain Adaptation#Market to Duke#rank-5#77.0$Unsupervised Domain Adaptation#Market to Duke#rank-10#82.5$Unsupervised Domain Adaptation#Duke to Market#mAP#47.6$Unsupervised Domain Adaptation#Duke to Market#rank-1#75.2$Unsupervised Domain Adaptation#Duke to Market#rank-5#86.3$Unsupervised Domain Adaptation#Duke to Market#rank-10#90.2
2001.08680v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#44.9$Unsupervised Domain Adaptation#Market to Duke#rank-1#68$Unsupervised Domain Adaptation#Market to Duke#rank-5#80$Unsupervised Domain Adaptation#Market to Duke#rank-10#83.9$Unsupervised Domain Adaptation#Duke to Market#mAP#52$Unsupervised Domain Adaptation#Duke to Market#rank-1#81.7$Unsupervised Domain Adaptation#Duke to Market#rank-5#91.9$Unsupervised Domain Adaptation#Duke to Market#rank-10#94.7$Person Re-Identification#DukeMTMC-reID#Rank-1#84.8$Person Re-Identification#DukeMTMC-reID#Rank-5#92.5$Person Re-Identification#DukeMTMC-reID#Rank-10#95.2$Person Re-Identification#DukeMTMC-reID#mAP#70.1$Person Re-Identification#DukeMTMC-reID#Rank-1#82.5$Person Re-Identification#DukeMTMC-reID#Rank-5#91.7$Person Re-Identification#DukeMTMC-reID#Rank-10#94.1$Person Re-Identification#DukeMTMC-reID#mAP#67.3$Person Re-Identification#MSMT17#Rank-1#72.8$Person Re-Identification#MSMT17#mAP#42.9$Person Re-Identification#Market-1501#Rank-1#94.3$Person Re-Identification#Market-1501#Rank-5#97.9$Person Re-Identification#Market-1501#Rank-10#98.7$Person Re-Identification#Market-1501#mAP#83.6$Person Re-Identification#Market-1501#Rank-1#91.3$Person Re-Identification#Market-1501#Rank-5#97.1$Person Re-Identification#Market-1501#Rank-10#98.4$Person Re-Identification#Market-1501#mAP#77.3
1904.01990v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#40.4$Unsupervised Domain Adaptation#Market to Duke#rank-1#63.3$Unsupervised Domain Adaptation#Duke to MSMT#mAP#10.2$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#30.2$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#41.5$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#46.8$Unsupervised Domain Adaptation#Market to MSMT#mAP#8.5$Unsupervised Domain Adaptation#Market to MSMT#rank-1#25.3$Unsupervised Domain Adaptation#Market to MSMT#rank-5#36.3$Unsupervised Domain Adaptation#Market to MSMT#rank-10#42.1$Unsupervised Domain Adaptation#Duke to Market#mAP#43.0$Unsupervised Domain Adaptation#Duke to Market#rank-1#75.1$Unsupervised Person Re-Identification#Market-1501#Rank-1#75.1$Unsupervised Person Re-Identification#Market-1501#MAP#43$Unsupervised Person Re-Identification#Market-1501#Rank-10#91.6$Unsupervised Person Re-Identification#Market-1501#Rank-5#87.6$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#40.4$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#63.3$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-10#80.4$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-20#84.2$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-5#75.8$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#63.3$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#80.4$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#75.8$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#40.4$Unsupervised Person Re-Identification#Market-1501->MSMT17#mAP#8.5$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-1#25.3$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-10#42.1$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-5#36.3$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#43$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-1#75.1$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-10#91.6$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-5#87.6$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-20#94.5$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#mAP#10.2$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-1#30.2$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-10#46.8$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-5#41.5
1904.03425v2.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#31.0$Unsupervised Domain Adaptation#Market to Duke#rank-1#47.7$Unsupervised Domain Adaptation#Market to Duke#rank-5#-$Unsupervised Domain Adaptation#Market to Duke#rank-10#-$Unsupervised Domain Adaptation#Duke to Market#mAP#30.9$Unsupervised Domain Adaptation#Duke to Market#rank-1#60.4$Unsupervised Domain Adaptation#Duke to Market#rank-5#-$Unsupervised Domain Adaptation#Duke to Market#rank-10#-
1812.02605v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#27.3$Unsupervised Domain Adaptation#Market to Duke#rank-1#49.8$Unsupervised Domain Adaptation#Market to Duke#rank-5#-$Unsupervised Domain Adaptation#Market to Duke#rank-10#-$Unsupervised Domain Adaptation#Duke to Market#mAP#28.3$Unsupervised Domain Adaptation#Duke to Market#rank-1#61.2$Unsupervised Domain Adaptation#Duke to Market#rank-5#-$Unsupervised Domain Adaptation#Duke to Market#rank-10#-
1904.07223v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#24.25$Unsupervised Domain Adaptation#Market to Duke#rank-1#42.62$Unsupervised Domain Adaptation#Market to Duke#rank-5#58.57$Unsupervised Domain Adaptation#Market to Duke#rank-10#64.63$Unsupervised Domain Adaptation#Duke to MSMT#mAP#6.35$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#20.59$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#31.67$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#37.04$Unsupervised Domain Adaptation#Market to MSMT#mAP#5.41$Unsupervised Domain Adaptation#Market to MSMT#rank-1#17.11$Unsupervised Domain Adaptation#Market to MSMT#rank-5#26.66$Unsupervised Domain Adaptation#Market to MSMT#rank-10#31.62$Unsupervised Domain Adaptation#Duke to Market#mAP#26.83$Unsupervised Domain Adaptation#Duke to Market#rank-1#56.12$Unsupervised Domain Adaptation#Duke to Market#rank-5#72.18$Unsupervised Domain Adaptation#Duke to Market#rank-10#78.12$Person Re-Identification#DukeMTMC-reID#Rank-1#90.26$Person Re-Identification#DukeMTMC-reID#mAP#88.31$Person Re-Identification#DukeMTMC-reID#Rank-1#86.6$Person Re-Identification#DukeMTMC-reID#mAP#74.8$Person Re-Identification#CUHK03#MAP#61.1$Person Re-Identification#CUHK03#Rank-1#65.6$Person Re-Identification#MSMT17#Rank-1#77.2$Person Re-Identification#MSMT17#mAP#52.3$Person Re-Identification#MSMT17#Rank-5#87.4$Person Re-Identification#MSMT17#Rank-10#90.5$Person Re-Identification#Market-1501#Rank-1#95.4$Person Re-Identification#Market-1501#mAP#92.49$Person Re-Identification#Market-1501#Rank-1#94.8$Person Re-Identification#Market-1501#mAP#86.0$Person Re-Identification#UAV-Human#mAP#61.97$Person Re-Identification#UAV-Human#Rank-1#65.81$Person Re-Identification#UAV-Human#Rank-5#85.71$Person Re-Identification#Market-1501-C#Rank-1#31.75$Person Re-Identification#Market-1501-C#mAP#9.96$Person Re-Identification#Market-1501-C#mINP#0.35$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-1#61.76$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-10#83.25$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-5#77.67$Unsupervised Person Re-Identification#MSMT17->Market-1501#mAP#33.62
1803.09786v1.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#23.0$Unsupervised Domain Adaptation#Market to Duke#rank-1#44.3$Unsupervised Domain Adaptation#Market to Duke#rank-5#59.6$Unsupervised Domain Adaptation#Market to Duke#rank-10#65.0$Unsupervised Domain Adaptation#Duke to Market#mAP#26.5$Unsupervised Domain Adaptation#Duke to Market#rank-1#58.2$Unsupervised Domain Adaptation#Duke to Market#rank-5#74.8$Unsupervised Domain Adaptation#Duke to Market#rank-10#81.1
1711.07027v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#22.3$Unsupervised Domain Adaptation#Market to Duke#rank-1#41.1$Unsupervised Domain Adaptation#Market to Duke#rank-5#56.6$Unsupervised Domain Adaptation#Market to Duke#rank-10#63.0$Unsupervised Domain Adaptation#Duke to Market#mAP#22.8$Unsupervised Domain Adaptation#Duke to Market#rank-1#51.5$Unsupervised Domain Adaptation#Duke to Market#rank-5#70.1$Unsupervised Domain Adaptation#Duke to Market#rank-10#76.8$Person Re-Identification#DukeMTMC-reID#Rank-1#46.4$Person Re-Identification#DukeMTMC-reID#mAP#26.2$Unsupervised Person Re-Identification#Market-1501#Rank-1#57.7$Unsupervised Person Re-Identification#Market-1501#MAP#26.7$Unsupervised Person Re-Identification#Market-1501#Rank-10#82.4$Unsupervised Person Re-Identification#Market-1501#Rank-5#75.8$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#46.4$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#68.0$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#62.3$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#26.2$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-1#46.4$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-10#68.0$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-5#62.3$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#mAP#26.2
2006.04569v3.pdf	Unsupervised Domain Adaptation#Market to Duke#mAP#13.7$Unsupervised Domain Adaptation#Market to Duke#rank-1#26.4$Unsupervised Domain Adaptation#Market to Duke#rank-5#-$Unsupervised Domain Adaptation#Market to Duke#rank-10#-$Unsupervised Domain Adaptation#Duke to MSMT#mAP#1.9$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#6.8$Unsupervised Domain Adaptation#Duke to Market#mAP#14.7$Unsupervised Domain Adaptation#Duke to Market#rank-1#36.4$Unsupervised Domain Adaptation#Duke to Market#rank-5#-$Unsupervised Domain Adaptation#Duke to Market#rank-10#-$Person Re-Identification#DukeMTMC-reID#Rank-1#76.66$Person Re-Identification#DukeMTMC-reID#mAP#57.89$Person Re-Identification#MSMT17#Rank-1#47.71$Person Re-Identification#MSMT17#mAP#23.01$Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#16.3$Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#31.3$Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#17.2$Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-1#41.4$Person Re-Identification#Market-1501#Rank-1#87.74$Person Re-Identification#Market-1501#mAP#69.52$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-1#40.1$Unsupervised Person Re-Identification#MSMT17->Market-1501#mAP#17.6$Unsupervised Person Re-Identification#Market-1501->MSMT17#mAP#1.7$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-1#5.9$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.3$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.5$3D Point Cloud Classification#ModelNet40#Number of params#1.22M
1711.08565v2.pdf	Unsupervised Domain Adaptation#Duke to MSMT#mAP#3.3$Unsupervised Domain Adaptation#Duke to MSMT#rank-1#11.8$Unsupervised Domain Adaptation#Duke to MSMT#rank-5#-$Unsupervised Domain Adaptation#Duke to MSMT#rank-10#27.4$Unsupervised Domain Adaptation#Market to MSMT#mAP#2.9$Unsupervised Domain Adaptation#Market to MSMT#rank-1#10.2$Unsupervised Domain Adaptation#Market to MSMT#rank-5#-$Unsupervised Domain Adaptation#Market to MSMT#rank-10#24.4$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#27.4$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#50.7
2002.11361v1.pdf	Unsupervised Domain Adaptation#Portraits (over time)#Accuracy (%)#83.8
2007.10315v1.pdf	Unsupervised Domain Adaptation#Market to MSMT#mAP#22.1$Unsupervised Domain Adaptation#Market to MSMT#rank-1#48.4$Unsupervised Domain Adaptation#Market to MSMT#rank-5#60.9$Unsupervised Domain Adaptation#Market to MSMT#rank-10#66.1
2108.03553v2.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#45.2
2110.01428v1.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#43.3$Unsupervised Domain Adaptation#SIM10K to Cityscapes#mAP@0.5#49.3$Unsupervised Domain Adaptation#Kitti to Cityscapes#mAP@0.5#47.6
2011.07205v1.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#42.5
2201.01929v1.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#42.3
2008.01882v3.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#41.87$Unsupervised Domain Adaptation#UDA-CH#mAP@0.50#58.01
2003.12979v3.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#40.9
1812.04798v3.pdf	Unsupervised Domain Adaptation#Cityscapes to Foggy Cityscapes#mAP@0.5#34.8$Unsupervised Domain Adaptation#SIM10K to BDD100K#mAP@0.5#42.9
1804.09347v1.pdf	Unsupervised Domain Adaptation#Duke to Market#mAP#39.4$Unsupervised Domain Adaptation#Duke to Market#rank-1#70.3$Unsupervised Domain Adaptation#Duke to Market#rank-5#80.4$Unsupervised Domain Adaptation#Duke to Market#rank-10#86.3
1802.07222v1.pdf	Unsupervised Domain Adaptation#SYNTHIA-to-Cityscapes#mIoU (13 classes)#59.7$3D Face Animation#Celeb-DF#1'"#1$Text-to-Face Generation#10,000 People - Human Pose Recognition Data#10%#1000$Image Generation#100DOH#-1#1$Image Generation#10,000 People - Human Pose Recognition Data#0..5sec#30$Image Inpainting#CelebA-HQ#FID#10.82$Image Inpainting#CelebA-HQ#P-IDS#1.94$Image Inpainting#CelebA-HQ#U-IDS#6.97$Image Inpainting#0#0..5sec#dd$Federated Lifelong Person ReID#TVPR#0..5sec#1$Multi-Object Tracking#MOT20#MOTA#68.6$Multi-Object Tracking#MOT20#IDF1#65.7$Multi-Object Tracking#MOT20#HOTA#54.7$Action Classification#Kinetics-400#Acc@1#80.2$Action Classification#Kinetics-400#Acc@5#94.7$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#13.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#48.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#75.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#83.9$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2.0$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#15.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#44.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#71.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#81.7$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSVD#text-to-video R@1#46.4$Video Retrieval#MSVD#text-to-video R@5#76.5$Video Retrieval#MSVD#text-to-video R@10#84.8$Video Retrieval#MSVD#text-to-video Median Rank#2$Video Retrieval#MSVD#text-to-video Mean Rank#9.0$Video Frame Interpolation#10,000 People - Human Pose Recognition Data#10-way 5~10-shot#60fps$Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#97.48$Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#84.89$Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#82.67$Question Answering#Children's Book Test#Accuracy-CN#93.30%$Question Answering#Children's Book Test#Accuracy-NE#89.05%$Language Modelling#100 sleep nights of 8 caregivers#10%#1$Semantic Segmentation#Cityscapes val#mIoU#80.2$Named Entity Recognition#DaNE#Micro-average F1#82.9$Image Captioning#COCO Captions#BLEU-4#41.4$Image Captioning#COCO Captions#METEOR#30.4$Image Captioning#COCO Captions#ROUGE-L#60.4$Image Captioning#COCO Captions#CIDER#139.9$Image Captioning#COCO Captions#SPICE#24.0$Image Captioning#COCO Captions#BLEU-1#83.4$Document Image Classification#RVL-CDIP#Accuracy#93.45%$Document Image Classification#RVL-CDIP#Accuracy#89.80%$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.751$Readmission Prediction#.#0..5sec#KAMPANAT THUMWONG$Conversational Response Selection#E-commerce#R10@1#0.685$Conversational Response Selection#E-commerce#R10@2#0.864$Conversational Response Selection#E-commerce#R10@5#0.982$Graph Classification#PTC#Accuracy#85.7%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#61.56±0.51
2106.07165v1.pdf	Unsupervised Domain Adaptation#MSCOCO to FLIR ADAS#Accuracy (%)#91.2
2104.12928v2.pdf	Unsupervised Domain Adaptation#ImageNet-A#Top 1 Error#14.8$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#22.0$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#23.0$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#34.8$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#35.5$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#40.8$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#40.9$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#43.2$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#44.3$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#50.5$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#51.6$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#17.4$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#19.7$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#54.1$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#56.1
2006.04996v1.pdf	Unsupervised Domain Adaptation#Office-Home#Avg accuracy#69.5$Unsupervised Domain Adaptation#Office-Home (RS-UT imbalance)#Average Per-Class Accuracy#61.67$Unsupervised Domain Adaptation#Office-Home (RS-UT imbalance)#Average Per-Class Accuracy#58.4$Unsupervised Domain Adaptation#Office-Home (RS-UT imbalance)#Average Per-Class Accuracy#56.91$Unsupervised Domain Adaptation#Office-Home (RS-UT imbalance)#Average Per-Class Accuracy#55.44$Unsupervised Domain Adaptation#Office-Home (RS-UT imbalance)#Average Per-Class Accuracy#52.81$Unsupervised Domain Adaptation#VisDA2017#Accuracy#75.8$Unsupervised Domain Adaptation#Office-31#Avg accuracy#88.8
2003.07071v2.pdf	Unsupervised Domain Adaptation#SIM10K to BDD100K#mAP@0.5#45.3
2107.14447v1.pdf	Unsupervised Domain Adaptation#PACS#Average Accuracy#91.25
1907.04275v3.pdf	Unsupervised Domain Adaptation#PACS#Average Accuracy#90.38$Domain Generalization#PACS#Average Accuracy#86.64$Domain Generalization#PACS#Average Accuracy#85.11
2006.16971v2.pdf	Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#38.0$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#40.7$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#45.4$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#48.4$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#62.2$Unsupervised Domain Adaptation#ImageNet-C#mean Corruption Error (mCE)#65.0$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#44.0$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#48.9$Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#59.9$Image Classification#ObjectNet#Top-5 Accuracy#50.2$Image Classification#ObjectNet#Top-1 Accuracy#29.2$Image Classification#ObjectNet#Top-5 Accuracy#48.6$Image Classification#ObjectNet#Top-1 Accuracy#28.5
2203.05482v3.pdf	Unsupervised Domain Adaptation#ImageNet-R#Top 1 Error#4.54$Domain Generalization#ImageNet-A#Top-1 accuracy %#94.17$Domain Generalization#ImageNet-A#Top-1 accuracy %#92.67$Domain Generalization#ImageNet-R#Top-1 Error Rate#3.90$Domain Generalization#ImageNet-R#Top-1 Error Rate#4.54$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#77.18$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#74.24$Image Classification#ImageNet#Top 1 Accuracy#90.98%$Image Classification#ImageNet#Number of params#2440M$Image Classification#ImageNet#Top 1 Accuracy#90.94%$Image Classification#ImageNet#Number of params#1843M$Image Classification#ImageNet ReaL#Accuracy#91.78%$Image Classification#ImageNet ReaL#Accuracy#91.20%$Image Classification#ImageNet ReaL#Params#1843M$Image Classification#ImageNet ReaL#Accuracy#91.03%$Image Classification#ImageNet ReaL#Params#2440M$Image Classification#ObjectNet#Top-1 Accuracy#79.03$Image Classification#ObjectNet#Top-1 Accuracy#78.52$Image Classification#ImageNet V2#Top 1 Accuracy#84.63$Image Classification#ImageNet V2#Top 1 Accuracy#84.22
1911.02744v1.pdf	Unsupervised Domain Adaptation#PreSIL to KITTI#AP@0.7#17.1
1905.08955v1.pdf	Unsupervised Domain Adaptation#PreSIL to KITTI#AP@0.7#16.5
2006.07500v3.pdf	Domain Generalization#Rotated Fashion-MNIST#Accuracy#82.8$Domain Generalization#PACS#Average Accuracy#87.52$Domain Generalization#PACS#Average Accuracy#84.35
2003.12815v2.pdf	Domain Generalization#Rotated Fashion-MNIST#Accuracy#78.9$Domain Generalization#PACS#Average Accuracy#80.69$Domain Generalization#LipitK#Accuracy#87.3
2110.10832v4.pdf	Domain Generalization#Office-Home#Average Accuracy#83.9$Domain Generalization#Office-Home#Average Accuracy#80.2$Domain Generalization#Office-Home#Average Accuracy#72.5$Domain Generalization#DomainNet#Average Accuracy#60.9$Domain Generalization#DomainNet#Average Accuracy#54.6$Domain Generalization#DomainNet#Average Accuracy#47.4$Domain Generalization#PACS#Average Accuracy#95.8$Domain Generalization#PACS#Average Accuracy#93.2$Domain Generalization#PACS#Average Accuracy#88.6$Domain Generalization#TerraIncognita#Average Accuracy#61.1$Domain Generalization#TerraIncognita#Average Accuracy#55.2$Domain Generalization#TerraIncognita#Average Accuracy#52.3$Domain Generalization#VLCS#Average Accuracy#81.1$Domain Generalization#VLCS#Average Accuracy#80.4$Domain Generalization#VLCS#Average Accuracy#79.1
2203.10789v2.pdf	Domain Generalization#Office-Home#Average Accuracy#83.3$Domain Generalization#Office-Home#Average Accuracy#72.4$Domain Generalization#DomainNet#Average Accuracy#60.7$Domain Generalization#DomainNet#Average Accuracy#47.0$Domain Generalization#PACS#Average Accuracy#96.8$Domain Generalization#PACS#Average Accuracy#88.4$Domain Generalization#TerraIncognita#Average Accuracy#64.3$Domain Generalization#TerraIncognita#Average Accuracy#52.9$Domain Generalization#VLCS#Average Accuracy#81.7$Domain Generalization#VLCS#Average Accuracy#79.6
2203.04600v1.pdf	Domain Generalization#Office-Home#Average Accuracy#80.7$Domain Generalization#Office-Home#Average Accuracy#79.9$Domain Generalization#DomainNet#Average Accuracy#54.7$Domain Generalization#DomainNet#Average Accuracy#46.3$Domain Generalization#PACS#Average Accuracy#96.1$Domain Generalization#PACS#Average Accuracy#84.1$Domain Generalization#TerraIncognita#Average Accuracy#56.8$Domain Generalization#VLCS#Average Accuracy#82.2$Domain Generalization#VLCS#Average Accuracy#79.8
2203.17067v2.pdf	Domain Generalization#Office-Home#Average Accuracy#79.9$Domain Generalization#DomainNet#Average Accuracy#51.6$Domain Generalization#PACS#Average Accuracy#94.6$Domain Generalization#TerraIncognita#Average Accuracy#55.7$Domain Generalization#VLCS#Average Accuracy#82.2
2102.08604v4.pdf	Domain Generalization#Office-Home#Average Accuracy#70.6$Domain Generalization#DomainNet#Average Accuracy#46.5$Domain Generalization#PACS#Average Accuracy#88.1$Domain Generalization#TerraIncognita#Average Accuracy#50.0$Domain Generalization#VLCS#Average Accuracy#79.1
2112.04766v2.pdf	Domain Generalization#Office-Home#Average Accuracy#69.4$Domain Generalization#Office-Home#Average Accuracy#67.7$Domain Generalization#DomainNet#Average Accuracy#46.7$Domain Generalization#DomainNet#Average Accuracy#43.3$Domain Generalization#PACS#Average Accuracy#89.2$Domain Generalization#PACS#Average Accuracy#87.0$Domain Generalization#TerraIncognita#Average Accuracy#50.6$Domain Generalization#TerraIncognita#Average Accuracy#48.1$Domain Generalization#VLCS#Average Accuracy#79.6$Domain Generalization#VLCS#Average Accuracy#78.9
2109.02934v3.pdf	Domain Generalization#Office-Home#Average Accuracy#68.2$Domain Generalization#DomainNet#Average Accuracy#41.8$Domain Generalization#PACS#Average Accuracy#86.9$Domain Generalization#TerraIncognita#Average Accuracy#47.4$Domain Generalization#VLCS#Average Accuracy#78.2
2108.08596v1.pdf	Domain Generalization#Office-Home#Average Accuracy#66.2
2007.02454v1.pdf	Domain Generalization#Office-Home#Average Accuracy#63.12$Domain Generalization#PACS#Average Accuracy#87.83$Domain Generalization#PACS#Average Accuracy#85.2$Domain Generalization#PACS#Average Accuracy#85.15$Domain Generalization#PACS#Average Accuracy#76.05$Domain Generalization#VLCS#Average Accuracy#75.43
2209.07326v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#84.53$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#82.5$Scene Classification#UC Merced Land Use Dataset#Accuracy (%)#100$Image Classification#iNaturalist 2018#Top-1 Accuracy#80.97%$Image Classification#CARS196#Accuracy#87.18$Image Classification#DTD#Accuracy#82.23$Image Classification#Imagenette#Accuracy#100$Image Classification#PlantVillage#Accuracy#99.89$Image Classification#Stanford Online Products#Accuracy#89.47$Image Classification#STL-10#Percentage correct#99.64$Image Classification#ImageNet-Sketch#Accuracy#88.6$Image Classification#Malaria Dataset#Acc. (test)#97.46%$Image Classification#EuroSAT#Accuracy (%)#99.22$Image Classification#EMNIST-Letters#Accuracy#95.03$Image Classification#cats_vs_dogs#Accuracy#99.83$Image Classification#Places365#Top 1 Accuracy#59.15$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#4.06%$Fine-Grained Image Classification#Food-101#Accuracy#91.47$Fine-Grained Image Classification#Oxford-IIIT Pets#Accuracy#95.5$Fine-Grained Image Classification#Stanford Dogs#Accuracy#93.5%
2111.06377v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#76.7$Domain Generalization#ImageNet-R#Top-1 Error Rate#33.5$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#50.9$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#33.8$Domain Generalization#ImageNet-C#Number of params#632M$Semantic Segmentation#ADE20K#Validation mIoU#53.6$Semantic Segmentation#ADE20K#Validation mIoU#48.1$Object Detection#COCO minival#box AP#53.3$Object Detection#COCO minival#box AP#50.3$Image Classification#Places205#Top 1 Accuracy#66.8$Image Classification#iNaturalist 2018#Top-1 Accuracy#86.8%$Image Classification#ImageNet#Top 1 Accuracy#87.8%$Image Classification#ImageNet#Number of params#656M$Image Classification#ImageNet#Top 1 Accuracy#86.9%$Image Classification#ImageNet#Top 1 Accuracy#85.9%$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#iNaturalist 2019#Top-1 Accuracy#88.3$Image Classification#OmniBenchmark#Average Top-1 Accuracy#30.6$Image Classification#iNaturalist#Top 1 Accuracy#83.4$Image Classification#Places365-Standard#Top 1 Accuracy#60.3$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.6%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.8%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#68.0%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#632M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#87.8%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#86.9%
2204.12451v3.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#74.5$Domain Generalization#ImageNet-R#Top-1 Error Rate#28.9$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#35.8$Domain Generalization#ImageNet-C#Top 1 Accuracy#73.6$Domain Generalization#ImageNet-C#Number of params#77M$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#41.0$Domain Generalization#ImageNet-C#Top 1 Accuracy#70.5$Domain Generalization#ImageNet-C#Number of params#50M$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#43.0$Domain Generalization#ImageNet-C#Top 1 Accuracy#67.7$Semantic Segmentation#Cityscapes val#mIoU#82.3$Semantic Segmentation#DensePASS#mIoU#42.54%$Object Detection#COCO minival#box AP#55.1$Image Classification#ImageNet#Top 1 Accuracy#87.1%$Image Classification#ImageNet#Number of params#76.8M
2201.03545v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#69.3$Domain Generalization#ImageNet-R#Top-1 Error Rate#31.8$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#55.0$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#38.8$Domain Generalization#ImageNet-C#Number of params#350M$Real-Time Object Detection#COCO#FPS (V100, b=1)#8.6$Real-Time Object Detection#COCO#box AP#55.2$Real-Time Object Detection#COCO#FPS (V100, b=1)#10$Real-Time Object Detection#COCO#box AP#54.8$Real-Time Object Detection#COCO#FPS (V100, b=1)#11.5$Real-Time Object Detection#COCO#box AP#54$Real-Time Object Detection#COCO#FPS (V100, b=1)#9.2$Real-Time Object Detection#COCO#box AP#53.9$Real-Time Object Detection#COCO#FPS (V100, b=1)#11.4$Real-Time Object Detection#COCO#box AP#52.7$Real-Time Object Detection#COCO#FPS (V100, b=1)#12$Real-Time Object Detection#COCO#box AP#51.9$Semantic Segmentation#ADE20K#Validation mIoU#54$Semantic Segmentation#ADE20K#Params (M)#391$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#3335$Semantic Segmentation#ADE20K#Validation mIoU#53.7$Semantic Segmentation#ADE20K#Params (M)#235$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#2458$Semantic Segmentation#ADE20K#Validation mIoU#53.1$Semantic Segmentation#ADE20K#Params (M)#122$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1828$Semantic Segmentation#ADE20K#Validation mIoU#49.9$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1170$Semantic Segmentation#ADE20K#Validation mIoU#49.6$Semantic Segmentation#ADE20K#Params (M)#82$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1027$Semantic Segmentation#ADE20K#Validation mIoU#46.7$Semantic Segmentation#ADE20K#Params (M)#60$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#939$Image Classification#ImageNet#Top 1 Accuracy#87.8%$Image Classification#ImageNet#Number of params#350M$Image Classification#ImageNet#GFLOPs#179$Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Number of params#198M$Image Classification#ImageNet#GFLOPs#101$Image Classification#ImageNet#Top 1 Accuracy#82.1%$Image Classification#ImageNet#Number of params#29M$Image Classification#ImageNet#GFLOPs#4.5
2209.07735v1.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#68.92$Domain Generalization#ImageNet-R#Top-1 Error Rate#34.39$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#50.03$Domain Generalization#Stylized-ImageNet#Top 1 Accuracy#32.77$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#31.4$Domain Generalization#ImageNet-C#Number of params#632M$Image Classification#ImageNet#Top 1 Accuracy#87.02%
2111.15121v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#62.44$Domain Generalization#ImageNet-A#Top-1 accuracy %#36.41$Domain Generalization#ImageNet-R#Top-1 Error Rate#42.16$Domain Generalization#ImageNet-R#Top-1 Error Rate#46.08$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#46.03$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#41.04$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#36.80$Domain Generalization#ImageNet-C#Number of params#87M$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#41.42$Image Classification#ObjectNet#Top-1 Accuracy#49.39$Image Classification#ObjectNet#Top-1 Accuracy#47.53$Image Classification#ObjectNet#Top-1 Accuracy#46.68$Image Classification#ObjectNet#Top-1 Accuracy#39.79$Image Classification#ObjectNet#Top-1 Accuracy#37.41$Image Classification#ObjectNet#Top-1 Accuracy#35.59$Image Classification#ObjectNet#Top-1 Accuracy#34.83$Image Classification#ObjectNet#Top-1 Accuracy#34.12$Image Classification#ObjectNet#Top-1 Accuracy#32.92$Image Classification#ObjectNet#Top-1 Accuracy#30.98$Image Classification#ObjectNet#Top-1 Accuracy#30.28$Image Classification#ObjectNet#Top-1 Accuracy#30.11$Image Classification#ObjectNet#Top-1 Accuracy#29.95$Image Classification#ObjectNet#Top-1 Accuracy#29.41$Image Classification#ObjectNet#Top-1 Accuracy#29.3$Image Classification#ObjectNet#Top-1 Accuracy#28.72$Image Classification#ObjectNet#Top-1 Accuracy#28.6$Image Classification#ObjectNet#Top-1 Accuracy#25.9$Image Classification#ObjectNet#Top-1 Accuracy#25.65$Image Classification#ObjectNet#Top-1 Accuracy#24.75$Image Classification#ObjectNet#Top-1 Accuracy#21.61$Image Classification#ObjectNet#Top-1 Accuracy#17.36
2205.01972v3.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#35.5$Domain Generalization#ImageNet-R#Top-1 Error Rate#51.9$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#35.8$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#48.9$Image Classification#ImageNet#Top 1 Accuracy#84.6%$Image Classification#ImageNet#Number of params#54M$Image Classification#ImageNet#GFLOPs#50.7$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#GFLOPs#16.6$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#38M$Image Classification#ImageNet#GFLOPs#11.1$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#8.4$Image Classification#ImageNet ReaL#Accuracy#87.9$Image Classification#ImageNet V2#Top 1 Accuracy#73.4
2105.07926v4.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#28.5$Domain Generalization#ImageNet-A#Top-1 accuracy %#25.7$Domain Generalization#ImageNet-A#Top-1 accuracy %#14.4$Domain Generalization#ImageNet-R#Top-1 Error Rate#51.3$Domain Generalization#ImageNet-R#Top-1 Error Rate#52.3$Domain Generalization#ImageNet-R#Top-1 Error Rate#56.1$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#46.8$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#49.4$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#57.0$Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Top 5 Accuracy#96.5$Image Classification#ImageNet#Number of params#91.8M$Image Classification#ImageNet#GFLOPs#17.7$Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#Top 5 Accuracy#95.8$Image Classification#ImageNet#Number of params#23.3M$Image Classification#ImageNet#GFLOPs#4.7$Image Classification#ImageNet#Top 1 Accuracy#79.2%$Image Classification#ImageNet#Top 5 Accuracy#94.7$Image Classification#ImageNet#Number of params#10.9M$Image Classification#ImageNet#GFLOPs#1.3
2107.00645v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#14.3$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#53.8$Image Classification#CIFAR-100#Percentage correct#90.3$Image Classification#CIFAR-100#PARAMS#54M$Image Classification#ImageNet#Top 1 Accuracy#82.9%$Image Classification#ImageNet#Top 5 Accuracy#96.2%$Image Classification#ImageNet#Number of params#54M$Image Classification#ImageNet#GFLOPs#8.6$Image Classification#Stanford Cars#Accuracy#93.2$Image Classification#Flowers-102#Accuracy#98.8$Image Classification#Flowers-102#PARAMS#54M$Image Classification#CIFAR-10#Percentage correct#99.0$Image Classification#CIFAR-10#PARAMS#54M
2002.11102v3.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#8.4
1905.04899v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#7.3$Image Captioning#COCO#BLEU-1#64.2$Image Captioning#COCO#BLEU-2#46.3$Image Captioning#COCO#BLEU-3#33.6$Image Captioning#COCO#BLEU-4#24.9$Image Captioning#COCO#CIDEr#77.6$Image Captioning#COCO#METEOR#23.1$Image Captioning#COCO#ROUGE#49$Image Classification#CIFAR-100#Percentage correct#86.19$Image Classification#ImageNet#Top 1 Accuracy#80.53%$Image Classification#ImageNet#Top 5 Accuracy#94.97%$Image Classification#ImageNet#Top 1 Accuracy#78.4%$Image Classification#ImageNet#Top 5 Accuracy#94.10%$Image Classification#OmniBenchmark#Average Top-1 Accuracy#31.1$Image Classification#CIFAR-10#Percentage correct#97.12
1710.09412v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#6.6$Image Classification#CIFAR-100#Percentage correct#83.20$Image Classification#Kuzushiji-MNIST#Accuracy#98.41$Image Classification#CIFAR-10#Percentage correct#97.3$Image Classification#CIFAR-10#PARAMS#25.6M$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#60.03$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#47.43
1708.04552v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#4.4$Image Classification#SVHN#Percentage error#1.30$Image Classification#STL-10#Percentage correct#87.26$Semi-Supervised Image Classification#STL-10#Accuracy#87.26
1811.12231v2.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#2.3$Domain Generalization#ImageNet-R#Top-1 Error Rate#58.5$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#69.3
1907.07174v4.pdf	Domain Generalization#ImageNet-A#Top-1 accuracy %#0
2206.04046v4.pdf	Domain Generalization#DomainNet#Average Accuracy#52.0$Domain Generalization#DomainNet#Average Accuracy#48.4
2210.03885v1.pdf	Domain Generalization#DomainNet#Average Accuracy#44.2$Domain Generalization#PACS#Average Accuracy#86.9
2008.12839v1.pdf	Domain Generalization#DomainNet#Average Accuracy#43.63$Domain Generalization#DomainNet#Average Accuracy#43.62$Domain Generalization#PACS#Average Accuracy#83.37$Domain Generalization#PACS#Average Accuracy#81.46$Domain Generalization#PACS#Average Accuracy#73.32
2209.12400v1.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#39.7$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#48.3$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#39.0$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#63.2$Long-tail Learning#Places-LT#Top-1 Accuracy#41.7$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#79.8%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#78.1%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#75.4%$Semantic Segmentation#ADE20K#Validation mIoU#54.3$Semantic Segmentation#PASCAL Context#mIoU#56.2$Image Classification#iNaturalist 2018#Top-1 Accuracy#78.1%$Image Classification#iNaturalist 2018#Top-1 Accuracy#75.4%$Image Classification#ImageNet#Top 1 Accuracy#86.01%$Image Classification#ImageNet#Top 1 Accuracy#84.0%$Image Classification#ImageNet#Top 1 Accuracy#79.7%
2204.00993v3.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#40.3$Domain Generalization#Stylized-ImageNet#Top 1 Accuracy#25.9$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#38.4$Domain Generalization#ImageNet-C#Number of params#296M$Image Classification#ImageNet#Top 1 Accuracy#87.3%$Image Classification#ImageNet#Number of params#295.5M$Image Classification#ImageNet#GFLOPs#412
2111.10493v2.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#44.74$Domain Generalization#ImageNet-Sketch#Top-1 accuracy#44.72$Domain Generalization#Stylized-ImageNet#Top 1 Accuracy#22.19$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#38.74$Domain Generalization#ImageNet-C#Number of params#87M$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#46.22$Image Classification#ImageNet#Top 1 Accuracy#85.07%$Image Classification#ObjectNet#Top-1 Accuracy#46.62
2006.16241v3.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#53.2$Domain Generalization#ImageNet-R#Top-1 Error Rate#57.8$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#60.4
2112.13547v2.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#53.7$Domain Generalization#ImageNet-R#Top-1 Error Rate#57.1$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#51.3$Domain Generalization#ImageNet-C#Top 1 Accuracy#59.9$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#55.5$Domain Generalization#ImageNet-C#Top 1 Accuracy#56.4$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#57.5$Domain Generalization#ImageNet-C#Top 1 Accuracy#55.0
1912.02781v2.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#58.9$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#65.3
2106.01548v3.pdf	Domain Generalization#ImageNet-R#Top-1 Error Rate#71.9$Domain Generalization#ImageNet-R#Top-1 Error Rate#73.6$Domain Generalization#ImageNet-R#Top-1 Error Rate#76.5$Domain Generalization#ImageNet-C#Top 1 Accuracy#56.5$Domain Generalization#ImageNet-C#Top 1 Accuracy#55$Domain Generalization#ImageNet-C#Top 1 Accuracy#48.9$Image Classification#CIFAR-100#Percentage correct#89.1$Image Classification#CIFAR-100#Percentage correct#87.8$Image Classification#CIFAR-100#Percentage correct#87.6$Image Classification#CIFAR-100#Percentage correct#86.4$Image Classification#CIFAR-100#Percentage correct#85.2$Image Classification#CIFAR-100#Percentage correct#82.4$Image Classification#ImageNet#Top 1 Accuracy#81.1%$Image Classification#ImageNet#Number of params#236M$Image Classification#ImageNet#Top 1 Accuracy#79.9%$Image Classification#ImageNet#Number of params#87M$Image Classification#ImageNet#Top 1 Accuracy#79%$Image Classification#ImageNet#Number of params#64M$Image Classification#ImageNet ReaL#Accuracy#86.4%$Image Classification#ImageNet ReaL#Accuracy#85.2%$Image Classification#ImageNet ReaL#Accuracy#84.4%$Image Classification#ImageNet V2#Top 1 Accuracy#69.6$Image Classification#ImageNet V2#Top 1 Accuracy#67.5$Image Classification#ImageNet V2#Top 1 Accuracy#65.5$Image Classification#Flowers-102#Accuracy#91.8$Image Classification#Flowers-102#Accuracy#91.5$Image Classification#Flowers-102#Accuracy#91.1$Image Classification#Flowers-102#Accuracy#90$Image Classification#Flowers-102#Accuracy#87.9$Image Classification#CIFAR-10#Percentage correct#98.6$Image Classification#CIFAR-10#PARAMS#87M$Image Classification#CIFAR-10#Percentage correct#98.2$Image Classification#CIFAR-10#Percentage correct#97.8$Image Classification#CIFAR-10#Percentage correct#97.4$Image Classification#CIFAR-10#PARAMS#25M$Image Classification#CIFAR-10#Percentage correct#96.1$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#93.3%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#93.1%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#92.9%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#92.5%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#91.6%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#88.7%
2203.01522v2.pdf	Domain Generalization#PACS#Average Accuracy#88.6$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.4$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#55.7$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#74.1%
2112.07517v1.pdf	Domain Generalization#PACS#Average Accuracy#86.6
2007.09316v1.pdf	Domain Generalization#PACS#Average Accuracy#85.84$Domain Generalization#PACS#Average Accuracy#82.15
2007.01434v1.pdf	Domain Generalization#PACS#Average Accuracy#85.50
2104.07876v1.pdf	Domain Generalization#PACS#Average Accuracy#84.69$Domain Generalization#VLCS#Average Accuracy#77.65
2006.11207v2.pdf	Domain Generalization#PACS#Average Accuracy#84.64$Domain Generalization#PACS#Average Accuracy#76.62
2001.00677v1.pdf	Domain Generalization#PACS#Average Accuracy#84.6
1909.08245v2.pdf	Domain Generalization#PACS#Average Accuracy#84.46$Domain Generalization#PACS#Average Accuracy#79.15
1911.08731v2.pdf	Domain Generalization#PACS#Average Accuracy#84.4$Domain Generalization#NICO Animal#Accuracy#77.61$Domain Generalization#NICO Vehicle#Accuracy#77.61
2101.09060v2.pdf	Domain Generalization#PACS#Average Accuracy#84.32$Domain Generalization#PACS#Average Accuracy#77.31
2109.02038v1.pdf	Domain Generalization#PACS#Average Accuracy#84.23$Domain Generalization#NICO Animal#Accuracy#88.72$Domain Generalization#NICO Vehicle#Accuracy#81.59
2104.02008v1.pdf	Domain Generalization#PACS#Average Accuracy#83.7
2104.09841v1.pdf	Domain Generalization#PACS#Average Accuracy#83.62
1911.00804v6.pdf	Domain Generalization#PACS#Average Accuracy#83.34$Domain Generalization#PACS#Average Accuracy#73.55
1910.11645v4.pdf	Domain Generalization#PACS#Average Accuracy#83.25$Domain Generalization#PACS#Average Accuracy#82.3$Domain Generalization#PACS#Average Accuracy#75.52
2011.12672v3.pdf	Domain Generalization#PACS#Average Accuracy#83.1
2003.06054v1.pdf	Domain Generalization#PACS#Average Accuracy#83.1
2007.03304v3.pdf	Domain Generalization#PACS#Average Accuracy#82.8
1910.13580v1.pdf	Domain Generalization#PACS#Average Accuracy#82.67$Domain Generalization#PACS#Average Accuracy#81.04$Domain Generalization#PACS#Average Accuracy#75.21
2010.01007v1.pdf	Domain Generalization#PACS#Average Accuracy#82.4
2012.09382v1.pdf	Domain Generalization#PACS#Average Accuracy#82.39$Domain Generalization#NICO Animal#Accuracy#85.23$Domain Generalization#NICO Vehicle#Accuracy#80.12$Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#69.60
1911.07661v1.pdf	Domain Generalization#PACS#Average Accuracy#81.83$Domain Generalization#PACS#Average Accuracy#74.38
2006.12009v1.pdf	Domain Generalization#PACS#Average Accuracy#81.7
2007.12256v2.pdf	Domain Generalization#PACS#Average Accuracy#81.6
1902.00113v3.pdf	Domain Generalization#PACS#Average Accuracy#81.5$Domain Generalization#PACS#Average Accuracy#72.00
2004.01377v1.pdf	Domain Generalization#PACS#Average Accuracy#81.5
2007.12368v2.pdf	Domain Generalization#PACS#Average Accuracy#81.41$Domain Generalization#PACS#Average Accuracy#74.08
1809.10966v1.pdf	Domain Generalization#PACS#Average Accuracy#80.72$Domain Generalization#PACS#Average Accuracy#71.20
1804.10745v2.pdf	Domain Generalization#PACS#Average Accuracy#80.7
1903.06864v2.pdf	Domain Generalization#PACS#Average Accuracy#80.51$Domain Generalization#PACS#Average Accuracy#79.05$Domain Generalization#PACS#Average Accuracy#73.38$Domain Generalization#PACS#Average Accuracy#71.52$Domain Generalization#NICO Animal#Accuracy#84.95$Domain Generalization#NICO Vehicle#Accuracy#77.39$Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#11.91
1709.10190v1.pdf	Domain Generalization#PACS#Average Accuracy#79.4
1905.13549v2.pdf	Domain Generalization#PACS#Average Accuracy#72.08
2003.00688v5.pdf	Domain Generalization#PACS#Average Accuracy#71.14$Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#68.70
2007.13003v3.pdf	Domain Generalization#PACS#Average Accuracy#70.53
1901.11448v3.pdf	Domain Generalization#PACS#Average Accuracy#70.40
1806.05810v1.pdf	Domain Generalization#PACS#Average Accuracy#70.30
1903.06256v1.pdf	Domain Generalization#PACS#Average Accuracy#70.20
1710.03463v1.pdf	Domain Generalization#PACS#Average Accuracy#70.01
1812.08974v1.pdf	Domain Generalization#PACS#Average Accuracy#69.45
2003.13525v1.pdf	Domain Generalization#PACS#Average Accuracy#69.32
1710.03077v1.pdf	Domain Generalization#PACS#Average Accuracy#69.21$Domain Generalization#PACS#Average Accuracy#58.99$Domain Generalization#PACS#Average Accuracy#58.74
2109.05671v1.pdf	Domain Generalization#PACS#Average Accuracy#47.45
2108.08487v1.pdf	Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#57.5$Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#65.0$Out-of-Distribution Detection#CIFAR-10#AUROC#98.1
2103.02152v3.pdf	Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#69.6
1903.12261v1.pdf	Domain Generalization#ImageNet-C#mean Corruption Error (mCE)#76.7
1607.01719v1.pdf	Domain Generalization#NICO Animal#Accuracy#80.27$Domain Generalization#NICO Vehicle#Accuracy#71.64
2003.02541v2.pdf	Partial Domain Adaptation#DomainNet#Accuracy (%)#60.63$Partial Domain Adaptation#Office-Home#Accuracy (%)#76.0$Partial Domain Adaptation#ImageNet-Caltech#Accuracy (%)#83.7$Partial Domain Adaptation#Office-31#Accuracy (%)#97.8
1808.04205v1.pdf	Partial Domain Adaptation#DomainNet#Accuracy (%)#37.41
2012.03358v1.pdf	Partial Domain Adaptation#Office-Home#Accuracy (%)#75.29$Partial Domain Adaptation#VisDA2017#Accuracy (%)#84.61$Partial Domain Adaptation#ImageNet-Caltech#Accuracy (%)#81.86$Partial Domain Adaptation#Office-31#Accuracy (%)#98.38
1912.03699v3.pdf	Partial Domain Adaptation#Office-Home#Accuracy (%)#75.1$Multi-target Domain Adaptation#DomainNet#Accuracy#28.8
1905.10756v4.pdf	Partial Domain Adaptation#Office-Home#Accuracy (%)#72.3$Partial Domain Adaptation#Office-31#Accuracy (%)#96.9
1903.12230v2.pdf	Partial Domain Adaptation#Office-Home#Accuracy (%)#70.5$Partial Domain Adaptation#ImageNet-Caltech#Accuracy (%)#79.1$Partial Domain Adaptation#Office-31#Accuracy (%)#96.7
2006.11477v3.pdf	Speech Recognition#Libri-Light test-clean#Word Error Rate (WER)#2.5$Speech Recognition#TIMIT#Percentage error#8.3$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.3$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.1$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.8$Speech Recognition#Libri-Light test-other#Word Error Rate (WER)#5.0
1912.07875v1.pdf	Speech Recognition#Libri-Light test-clean#Word Error Rate (WER)#29.3$Speech Recognition#Libri-Light test-clean#Word Error Rate (WER)#43.9$Speech Recognition#Libri-Light test-clean#ABX-within#5.83$Speech Recognition#Libri-Light test-clean#ABX-across#7.56$Speech Recognition#Libri-Light test-other#Word Error Rate (WER)#56.6$Speech Recognition#Libri-Light test-other#Word Error Rate (WER)#69.5$Speech Recognition#Libri-Light test-other#ABX-within#8.14$Speech Recognition#Libri-Light test-other#ABX-across#13.42
2005.14578v1.pdf	Speech Recognition#Libri-Light test-clean#ABX-within#9.33$Speech Recognition#Libri-Light test-clean#ABX-across#13.53$Speech Recognition#Libri-Light test-other#ABX-within#12.05$Speech Recognition#Libri-Light test-other#ABX-across#20.6
2104.02133v3.pdf	Speech Recognition#Switchboard SWBD#Word Error Rate (WER)#4.7$Speech Recognition#CHiME-6 dev_gss12#Word Error Rate (WER)#31.9$Speech Recognition#WSJ eval92#Word Error Rate (WER)#1.3$Speech Recognition#AMI SDM1#Word Error Rate (WER)#21.7$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.3$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.0$Speech Recognition#AMI IMH#Word Error Rate (WER)#9$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.7$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.0$Speech Recognition#CHiME-6 eval#Word Error Rate (WER)#38.9$Speech Recognition#Switchboard CallHome#Word Error Rate (WER)#8.3$Speech Recognition#Tedlium#Word Error Rate (WER)#5.3$Speech Recognition#Common Voice#Test WER#10.8%
2004.10799v3.pdf	Speech Recognition#CHiME-6 dev_gss12#Word Error Rate (WER)#55
2104.02014v2.pdf	Speech Recognition#SPGISpeech#Word Error Rate (WER)#5.7
1910.05453v3.pdf	Speech Recognition#TIMIT#Percentage error#11.6
1811.07453v2.pdf	Speech Recognition#TIMIT#Percentage error#14.2$Speech Recognition#TIMIT#Percentage error#14.5$Speech Recognition#TIMIT#Percentage error#14.9$Speech Recognition#TIMIT#Percentage error#15.9$Speech Recognition#TIMIT#Percentage error#16.0$Speech Recognition#TIMIT#Percentage error#16.3$Speech Recognition#TIMIT#Percentage error#16.5$Speech Recognition#TIMIT#Percentage error#16.6$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#6.2$Distant Speech Recognition#DIRHA English WSJ#Word Error Rate (WER)#23.9$Noisy Speech Recognition#CHiME real#Percentage error#14.6
1904.05862v4.pdf	Speech Recognition#TIMIT#Percentage error#14.7
1803.10225v1.pdf	Speech Recognition#TIMIT#Percentage error#14.9$Speech Recognition#TIMIT#Percentage error#16.7
1603.00223v2.pdf	Speech Recognition#TIMIT#Percentage error#17.3
1506.07503v1.pdf	Speech Recognition#TIMIT#Percentage error#17.6
1303.5778v1.pdf	Speech Recognition#TIMIT#Percentage error#17.7
1806.07789v1.pdf	Speech Recognition#TIMIT#Percentage error#19.64
1704.00784v2.pdf	Speech Recognition#TIMIT#Percentage error#20.1
1907.01914v1.pdf	Speech Recognition#TIMIT#Percentage error#20.4
1803.09574v4.pdf	Speech Recognition#TIMIT#Percentage error#33.2
2010.11430v1.pdf	Speech Recognition#LibriSpeech train-clean-100 test-other#Word Error Rate (WER)#3.6$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.1$Speech Recognition#LibriSpeech train-clean-100 test-clean#Word Error Rate (WER)#2.8$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.7
2207.11697v1.pdf	Speech Recognition#AISHELL-1#Word Error Rate (WER)#4.1
2012.05481v2.pdf	Speech Recognition#AISHELL-1#Word Error Rate (WER)#4.72
2005.13326v2.pdf	Speech Recognition#AISHELL-1#Word Error Rate (WER)#6.34$Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.2$Speech Recognition#WSJ dev93#Word Error Rate (WER)#5.7$Speech Recognition#Hub5'00 SwitchBoard#CallHome#18.4$Speech Recognition#Hub5'00 SwitchBoard#SwitchBoard#9.7$Speech Recognition#Hub5'00 SwitchBoard#Hub5'00#14.1$Speech Recognition#Hub5'00 FISHER-SWBD#Word Error Rate (WER)#12
1909.06317v2.pdf	Speech Recognition#AISHELL-1#Word Error Rate (WER)#6.7$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.7$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.6
1808.10088v2.pdf	Speech Recognition#AISHELL-1#Word Error Rate (WER)#18.7
2011.05649v1.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#2.77$Speech Recognition#WSJ dev93#Word Error Rate (WER)#5.68
2107.01275v2.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.19$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#6.85
1909.08723v3.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.4$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#8.7$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.8$Speech Recognition#Hub5'00 SwitchBoard#Eval2000#9.2$Speech Recognition#Hub5'00 CallHome#Word Error Rate (WER)#19.1
1504.01482v1.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.5
1812.06864v2.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.5$Speech Recognition#WSJ dev93#Word Error Rate (WER)#6.8$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#10.47$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#3.26$Speech Recognition#WSJ eval93#Word Error Rate (WER)#6.8
1512.02595v1.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#3.60$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#13.25$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#5.33$Speech Recognition#WSJ eval93#Word Error Rate (WER)#4.98$Accented Speech Recognition#VoxForge Commonwealth#Percentage error#13.56$Accented Speech Recognition#VoxForge Indian#Percentage error#22.44$Accented Speech Recognition#VoxForge European#Percentage error#17.55$Accented Speech Recognition#VoxForge American-Canadian#Percentage error#7.55$Noisy Speech Recognition#CHiME real#Percentage error#21.79$Noisy Speech Recognition#CHiME clean#Percentage error#3.34
1904.03288v3.pdf	Speech Recognition#WSJ eval92#Word Error Rate (WER)#6.9$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#7.84$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#8.79$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.84$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.95$Speech Recognition#Hub5'00 SwitchBoard#CallHome#16.2$Speech Recognition#Hub5'00 SwitchBoard#SwitchBoard#7.8
2112.07156v2.pdf	Speech Recognition#Google Speech Commands - Musan#Error rate - SNR 0dB#13.3$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#95$Keyword Spotting#Google Speech Commands#Google Speech Command-Musan#86.7
2105.00982v1.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#6.8$Speech Recognition#Switchboard + Hub500#Percentage error#4.3
2001.07263v3.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#7.8$Speech Recognition#Switchboard + Hub500#Percentage error#4.7
1703.02136v1.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#10.3$Speech Recognition#Switchboard + Hub500#Percentage error#5.5
1609.03528v2.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#11.9$Speech Recognition#Switchboard + Hub500#Percentage error#6.2$Speech Recognition#Switchboard + Hub500#Percentage error#6.3$Speech Recognition#Switchboard + Hub500#Percentage error#6.9
1604.08242v2.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#12.2$Speech Recognition#Switchboard + Hub500#Percentage error#6.6$Speech Recognition#Switchboard + Hub500#Percentage error#6.9
1412.5567v2.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#16$Speech Recognition#Switchboard + Hub500#Percentage error#12.6$Speech Recognition#Switchboard + Hub500#Percentage error#20$Accented Speech Recognition#VoxForge Commonwealth#Percentage error#28.46$Accented Speech Recognition#VoxForge Indian#Percentage error#45.35$Accented Speech Recognition#VoxForge European#Percentage error#31.20$Accented Speech Recognition#VoxForge American-Canadian#Percentage error#15.01$Noisy Speech Recognition#CHiME real#Percentage error#67.94$Noisy Speech Recognition#CHiME clean#Percentage error#6.3
1406.7806v2.pdf	Speech Recognition#swb_hub_500 WER fullSWBCH#Percentage error#19.1$Speech Recognition#Switchboard + Hub500#Percentage error#15$Speech Recognition#Switchboard + Hub500#Percentage error#16
2108.06209v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#2.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.4
2010.10504v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#2.6$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.4
2106.07447v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#2.9$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.8
2005.09629v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.4$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.7
2202.03555v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.7$Natural Language Inference#QNLI#Accuracy#91.1%$Natural Language Inference#RTE#Accuracy#69.9%$Paraphrase Identification#Quora Question Pairs#Accuracy#92.4$Image Classification#ImageNet#Top 1 Accuracy#86.6%$Linguistic Acceptability#CoLA#Accuracy#60.3%
2005.09267v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.83$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.10
2005.08100v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#3.9$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.3$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.0$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.9$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.1
2005.03191v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.1$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.5$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.9$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.3
1911.08460v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.11$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.18$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.03$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.31
2005.09150v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.20$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.10
2011.03109v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.20$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.0
2005.10469v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.46$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.75
1910.09799v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#4.85$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.26
1905.03072v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.0$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.3
2104.03006v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.6$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.23
1904.08779v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.8$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#6.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.7$Speech Recognition#Hub5'00 SwitchBoard#CallHome#14.6$Speech Recognition#Hub5'00 SwitchBoard#SwitchBoard#6.8$Speech Recognition#Hub5'00 SwitchBoard#CallHome#14$Speech Recognition#Hub5'00 SwitchBoard#SwitchBoard#7.1
1910.00716v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.80$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.20
2206.00888v2.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#5.97$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.47
1910.10261v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#7.25$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#2.69
2002.10336v1.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#15.28$Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#20.84$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#7.19
1805.10190v3.pdf	Speech Recognition#LibriSpeech test-other#Word Error Rate (WER)#16.5$Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#6.4
2110.07982v1.pdf	Speech Recognition#TUDA#Test WER#10.2%$Speech Recognition#Common Voice Spanish#Test WER#5.68%$Speech Recognition#Common Voice Spanish#Test WER#7.46 %$Speech Recognition#Common Voice Spanish#Test WER#10.0%$Speech Recognition#Common Voice Spanish#Test WER#10.5%$Speech Recognition#Common Voice French#Test WER#8.13%$Speech Recognition#Common Voice French#Test WER#10.19 %$Speech Recognition#Common Voice French#Test WER#11.0%$Speech Recognition#Common Voice French#Test WER#12.1%$Speech Recognition#Common Voice German#Test WER#4.05%$Speech Recognition#Common Voice German#Test CER#1.37%$Speech Recognition#Common Voice German#Test WER#6.6%$Speech Recognition#Common Voice German#Test CER#2.7%$Speech Recognition#Common Voice German#Test WER#7.33%$Speech Recognition#Common Voice German#Test CER#2.05%$Speech Recognition#Common Voice German#Test WER#7.7%$Speech Recognition#Common Voice German#Test CER#3.2%$Speech Recognition#Common Voice Italian#Test WER#11.5%
1908.04743v1.pdf	Speech Recognition#TUDA#Test WER#12.0%
2007.09127v1.pdf	Speech Recognition#TUDA#Test WER#12.8%
1807.10311v1.pdf	Speech Recognition#TUDA#Test WER#14.4%
1610.05256v2.pdf	Speech Recognition#Switchboard + Hub500#Percentage error#5.8$Speech Recognition#Switchboard + Hub500#Percentage error#6.6
1505.05899v1.pdf	Speech Recognition#Switchboard + Hub500#Percentage error#8.0
1509.08967v2.pdf	Speech Recognition#Switchboard + Hub500#Percentage error#12.2
2204.03178v2.pdf	Speech Recognition#WenetSpeech#Character Error Rate (CER)#7.19$Speech Recognition#WenetSpeech#Character Error Rate (CER)#7.49$Speech Recognition#WenetSpeech#Character Error Rate (CER)#7.67
2110.03370v5.pdf	Speech Recognition#WenetSpeech#Character Error Rate (CER)#8.88$Speech Recognition#WenetSpeech#Character Error Rate (CER)#9.07$Speech Recognition#WenetSpeech#Character Error Rate (CER)#9.7
2103.09903v1.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#1.9
1902.01955v2.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#3.60
1805.03294v1.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#3.82
1712.09444v2.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#4.8
1712.07101v1.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#5.42
2108.01553v1.pdf	Speech Recognition#LibriSpeech test-clean#Word Error Rate (WER)#8.6
1909.09577v1.pdf	Speech Recognition#Common Voice Spanish#Test WER#5.5%$Speech Recognition#Common Voice Spanish#Test WER#6.9%$Speech Recognition#Common Voice French#Test WER#9.16%$Speech Recognition#Common Voice French#Test WER#9.63%$Speech Recognition#Common Voice German#Test WER#6.03%$Speech Recognition#Common Voice German#Test WER#6.68%
2101.00390v2.pdf	Speech Recognition#Common Voice Spanish#Test WER#10.0%$Speech Recognition#Common Voice French#Test WER#9.6%$Speech Recognition#Common Voice German#Test WER#7.8%
2106.06909v1.pdf	Speech Recognition#GigaSpeech#Word Error Rate (WER)#10.90$Speech Recognition#GigaSpeech DEV#Word Error Rate (WER)#10.90$Speech Recognition#GigaSpeech TEST#Word Error Rate (WER)#10.80
2103.16193v1.pdf	Speech Recognition#MediaSpeech#WER for Arabic#0.1300$Speech Recognition#MediaSpeech#WER for French#0.1915$Speech Recognition#MediaSpeech#WER for Turkish#0.1422$Speech Recognition#MediaSpeech#WER for Spanish#0.1826$Speech Recognition#MediaSpeech#WER for Arabic#0.2333$Speech Recognition#MediaSpeech#WER for French#0.1759$Speech Recognition#MediaSpeech#WER for Turkish#0.0768$Speech Recognition#MediaSpeech#WER for Spanish#0.0879$Speech Recognition#MediaSpeech#WER for Arabic#0.3016$Speech Recognition#MediaSpeech#WER for French#0.1683$Speech Recognition#MediaSpeech#WER for Turkish#0.2296$Speech Recognition#MediaSpeech#WER for Spanish#0.1296$Speech Recognition#MediaSpeech#WER for Arabic#0.3085$Speech Recognition#MediaSpeech#WER for French#0.2111$Speech Recognition#MediaSpeech#WER for Turkish#0.3050$Speech Recognition#MediaSpeech#WER for Spanish#0.1970$Speech Recognition#MediaSpeech#WER for Arabic#0.4464$Speech Recognition#MediaSpeech#WER for French#0.2385$Speech Recognition#MediaSpeech#WER for Turkish#0.2707$Speech Recognition#MediaSpeech#WER for Spanish#0.2176$Speech Recognition#MediaSpeech#WER for Arabic#0.9596$Speech Recognition#MediaSpeech#WER for French#0.3113$Speech Recognition#MediaSpeech#WER for Turkish#0.5812$Speech Recognition#MediaSpeech#WER for Spanish#0.2469$Speech Recognition#MediaSpeech#WER for French#0.4741$Speech Recognition#MediaSpeech#WER for Spanish#0.4236$Speech Recognition#MediaSpeech#WER for Spanish#0.3070
2206.12693v1.pdf	Speech Recognition#Common Voice German#Test WER#3.64%$Speech Recognition#Common Voice German#Test CER#1.54%$Speech Recognition#Common Voice German#Test WER#3.70%$Speech Recognition#Common Voice German#Test WER#4.38%$Speech Recognition#Common Voice German#Test CER#1.62%$Speech Recognition#Common Voice German#Test WER#10.10%$Speech Recognition#Common Voice German#Test WER#12.06%
2111.10367v3.pdf	Speech Recognition#SLUE#VoxPopuli (Dev)#21.6$Speech Recognition#SLUE#VoxPopuli (Test)#22.4$Speech Recognition#SLUE#VoxCeleb (Dev)#29.9$Speech Recognition#SLUE#VoxCeleb (Test)#33.4$Speech Recognition#SLUE#VoxPopuli (Dev)#18.6$Speech Recognition#SLUE#VoxPopuli (Test)#19.1$Speech Recognition#SLUE#VoxCeleb (Dev)#19.6$Speech Recognition#SLUE#VoxCeleb (Test)#21.2$Speech Recognition#SLUE#VoxPopuli (Dev)#17.2$Speech Recognition#SLUE#VoxPopuli (Test)#17.9$Speech Recognition#SLUE#VoxCeleb (Dev)#17.2$Speech Recognition#SLUE#VoxCeleb (Test)#20.5$Speech Recognition#SLUE#VoxPopuli (Dev)#14.6$Speech Recognition#SLUE#VoxPopuli (Test)#15.2$Speech Recognition#SLUE#VoxCeleb (Dev)#15.2$Speech Recognition#SLUE#VoxCeleb (Test)#18.2$Speech Recognition#SLUE#VoxPopuli (Dev)#14.0$Speech Recognition#SLUE#VoxPopuli (Test)#12.1$Speech Recognition#SLUE#VoxCeleb (Dev)#11.0$Speech Recognition#SLUE#VoxCeleb (Test)#13.5$Speech Recognition#SLUE#VoxPopuli (Dev)#12.0$Speech Recognition#SLUE#VoxPopuli (Test)#12.5$Speech Recognition#SLUE#VoxCeleb (Dev)#11.8$Speech Recognition#SLUE#VoxCeleb (Test)#13.8$Speech Recognition#SLUE#VoxPopuli (Test)#12.2$Speech Recognition#SLUE#VoxCeleb (Dev)#13.2$Speech Recognition#SLUE#VoxCeleb (Test)#15.8$Speech Recognition#SLUE#VoxPopuli (Dev)#9.1$Speech Recognition#SLUE#VoxPopuli (Test)#9.3$Speech Recognition#SLUE#VoxCeleb (Dev)#9.1$Speech Recognition#SLUE#VoxCeleb (Test)#10.8$Sentiment Analysis#SLUE#Recall (%)#60.4$Sentiment Analysis#SLUE#F1 (%)#63.3$Sentiment Analysis#SLUE#Text model#DeBERTa-L$Sentiment Analysis#SLUE#Recall (%)#60.2$Sentiment Analysis#SLUE#Recall (%)#60.0$Sentiment Analysis#SLUE#F1 (%)#62.9$Sentiment Analysis#SLUE#Recall (%)#59.0$Sentiment Analysis#SLUE#F1 (%)#61.8$Sentiment Analysis#SLUE#Recall (%)#49.2$Sentiment Analysis#SLUE#F1 (%)#48.5$Sentiment Analysis#SLUE#Text model#N/A$Sentiment Analysis#SLUE#Recall (%)#47.5$Sentiment Analysis#SLUE#F1 (%)#48.0$Sentiment Analysis#SLUE#Recall (%)#46.0$Sentiment Analysis#SLUE#F1 (%)#46.6$Sentiment Analysis#SLUE#Recall (%)#38.7$Sentiment Analysis#SLUE#F1 (%)#38.4$Named Entity Recognition#SLUE#F1 (%)#69.6$Named Entity Recognition#SLUE#label-F1 (%)#82.2$Named Entity Recognition#SLUE#Text model#DeBERTa-L$Named Entity Recognition#SLUE#F1 (%)#68.0$Named Entity Recognition#SLUE#label-F1 (%)#79.8$Named Entity Recognition#SLUE#F1 (%)#64.8$Named Entity Recognition#SLUE#label-F1 (%)#73.3$Named Entity Recognition#SLUE#Text model#N/A$Named Entity Recognition#SLUE#F1 (%)#63.4$Named Entity Recognition#SLUE#label-F1 (%)#71.7$Named Entity Recognition#SLUE#F1 (%)#61.9$Named Entity Recognition#SLUE#label-F1 (%)#70.3$Named Entity Recognition#SLUE#F1 (%)#61.8$Named Entity Recognition#SLUE#label-F1 (%)#69.8$Named Entity Recognition#SLUE#F1 (%)#57.8$Named Entity Recognition#SLUE#label-F1 (%)#78.8$Named Entity Recognition#SLUE#F1 (%)#50.9$Named Entity Recognition#SLUE#label-F1 (%)#64.7$Named Entity Recognition#SLUE#Text model#-$Named Entity Recognition#SLUE#F1 (%)#50.2$Named Entity Recognition#SLUE#label-F1 (%)#64.0$Named Entity Recognition#SLUE#F1 (%)#49.8$Named Entity Recognition#SLUE#label-F1 (%)#62.9$Named Entity Recognition#SLUE#F1 (%)#49.5$Named Entity Recognition#SLUE#label-F1 (%)#74.2$Named Entity Recognition#SLUE#F1 (%)#47.9$Named Entity Recognition#SLUE#label-F1 (%)#60.8
2203.07996v2.pdf	Automatic Speech Recognition#LRS2#Test WER#2.7$Audio-Visual Speech Recognition#LRS2#Test WER#2.6$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#85.0$Lipreading#LRS2#Word Error Rate (WER)#43.2%
2102.06657v1.pdf	Automatic Speech Recognition#LRS2#Test WER#3.9$Audio-Visual Speech Recognition#LRS2#Test WER#3.7$Audio-Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#2.3$Lipreading#LRS3-TED#Word Error Rate (WER)#43.3$Lipreading#LRS2#Word Error Rate (WER)#39.1%
2001.01656v1.pdf	Automatic Speech Recognition#LRS2#Test WER#6.7$Audio-Visual Speech Recognition#LRS2#Test WER#5.9$Lipreading#LRS2#Word Error Rate (WER)#48.86%
1810.00108v1.pdf	Automatic Speech Recognition#LRS2#Test WER#8.2$Audio-Visual Speech Recognition#LRS2#Test WER#7.0$Lipreading#LRS2#Word Error Rate (WER)#50%
1809.02108v2.pdf	Automatic Speech Recognition#LRS2#Test WER#9.7$Automatic Speech Recognition#LRS2#Test WER#10.1$Audio-Visual Speech Recognition#LRS2#Test WER#8.2$Audio-Visual Speech Recognition#LRS2#Test WER#8.5$Audio-Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#7.2$Lipreading#LRS3-TED#Word Error Rate (WER)#58.9$Lipreading#LRS2#Word Error Rate (WER)#48.3%$Lipreading#LRS2#Word Error Rate (WER)#54.7%
2110.07603v2.pdf	Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#30.7$Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#40.6$Visual Speech Recognition#LRS2#Word Error Rate (WER)#22.6$Visual Speech Recognition#LRS2#Word Error Rate (WER)#28.9$Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#89.2%$Lipreading#LRS3-TED#Word Error Rate (WER)#30.7$Lipreading#LRS3-TED#Word Error Rate (WER)#40.6$Lipreading#LRS2#Word Error Rate (WER)#22.6%$Lipreading#LRS2#Word Error Rate (WER)#28.9%
2005.08209v1.pdf	Lip to Speech Synthesis#LRW#STOI#0.543$Lip to Speech Synthesis#LRW#ESTOI#0.344$Lip to Speech Synthesis#LRW#PESQ#1.197$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chem)#STOI#0.416$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chem)#ESTOI#0.284$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chem)#PESQ#1.3$Speaker-Specific Lip to Speech Synthesis#GRID corpus (mixed-speech)#STOI#0.731$Speaker-Specific Lip to Speech Synthesis#GRID corpus (mixed-speech)#ESTOI#0.535$Speaker-Specific Lip to Speech Synthesis#GRID corpus (mixed-speech)#PESQ#1.772$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (DL)#STOI#0.282$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (DL)#ESTOI#0.183$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (DL)#PESQ#1.671$Speaker-Specific Lip to Speech Synthesis#TCD-TIMIT corpus (mixed-speech)#STOI#0.558$Speaker-Specific Lip to Speech Synthesis#TCD-TIMIT corpus (mixed-speech)#ESTOI#36.5$Speaker-Specific Lip to Speech Synthesis#TCD-TIMIT corpus (mixed-speech)#PESQ#1.35$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chess)#STOI#0.418$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chess)#ESTOI#0.29$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (Chess)#PESQ#1.4$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (EH)#STOI#0.369$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (EH)#ESTOI#0.22$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (EH)#PESQ#1.367$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (HS)#STOI#0.446$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (HS)#ESTOI#0.311$Speaker-Specific Lip to Speech Synthesis#Lip2Wav (HS)#PESQ#1.29$Lip Reading#GRID corpus (mixed-speech)#WER#14.08$Lip Reading#TCD-TIMIT corpus (mixed-speech)#WER#31.26$Lip Reading#LRW#WER#34.2
1803.10109v1.pdf	Distant Speech Recognition#CHiME-4 real 6ch#Word Error Rate (WER)#2.74$Noisy Speech Recognition#CHiME real#Percentage error#11.4
1904.03416v1.pdf	Distant Speech Recognition#DIRHA English WSJ#Word Error Rate (WER)#29.8
1811.09725v2.pdf	Distant Speech Recognition#DIRHA English WSJ#Word Error Rate (WER)#38.2
2204.07580v1.pdf	Part-Of-Speech Tagging#XGLUE#Avg. F1#0.56$Natural Language Inference#XWINO#Accuracy#0.562$Cross-Lingual Natural Language Inference#XNLI#Accuracy#40.6$Few-shot NER#XGLUE#Avg F1#0.85$Cross-Lingual Transfer#XCOPA#Accuracy#55.5
2010.05006v4.pdf	Part-Of-Speech Tagging#ARK#Acc#94.4$Part-Of-Speech Tagging#Ritter#Acc#93.4$Part-Of-Speech Tagging#Tweebank#Acc#95.8$Semantic Dependency Parsing#DM#In-domain#95.6$Semantic Dependency Parsing#DM#Out-of-domain#92.6$Semantic Dependency Parsing#PAS#In-domain#95.8$Semantic Dependency Parsing#PAS#Out-of-domain#94.6$Semantic Dependency Parsing#PSD#In-domain#83.8$Semantic Dependency Parsing#PSD#Out-of-domain#83.4$Dependency Parsing#Penn Treebank#UAS#97.2$Dependency Parsing#Penn Treebank#LAS#95.8$Aspect Extraction#SemEval-2016 Task 5 Subtask 1#F1#81.3$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Russian)#F1#79.4$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Dutch)#F1#80.5$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Spanish)#F1#79.9$Aspect Extraction#SemEval 2015 Task 12#Restaurant (F1)#80.3$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop (F1)#87.4$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant (F1)#92.0$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Turkish)#F1#81.9$Named Entity Recognition#CoNLL 2002 (Dutch)#F1#95.7$Named Entity Recognition#CoNLL 2002 (Dutch)#F1#94.6$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#95.9$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#91.7$Named Entity Recognition#CoNLL 2003 (German) Revised#F1#91.7$Named Entity Recognition#CoNLL 2003 (German) Revised#F1#90.5$Named Entity Recognition#CoNLL 2003 (German)#F1#88.38$Named Entity Recognition#CoNLL 2003 (German)#F1#87.0$Named Entity Recognition#CoNLL 2003 (English)#F1#94.6$Named Entity Recognition#CoNLL 2003 (English)#F1#93.64$Chunking#CoNLL 2003 (German)#F1#95.0$Chunking#CoNLL 2003 (English)#F1#92.5$Chunking#CoNLL 2000#Exact Span F1#97.3$Chunking#Penn Treebank#F1 score#97.3
1805.08237v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.96
1508.02096v2.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.78$Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.36
1809.08370v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.76$Machine Translation#IWSLT2015 English-Vietnamese#BLEU#29.6$Dependency Parsing#Penn Treebank#UAS#96.61$Dependency Parsing#Penn Treebank#LAS#95.02$Named Entity Recognition#Ontonotes v5 (English)#F1#88.81$Named Entity Recognition#CoNLL 2003 (English)#F1#92.61$CCG Supertagging#CCGbank#Accuracy#96.1
1911.03822v2.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.7$Relation Extraction#SemEval-2010 Task 8#F1#87.4$Relation Extraction#WLPC#F1#65.5$Semantic Role Labeling (predicted predicates)#CoNLL 2012#F1#82.4$Dependency Parsing#Penn Treebank#UAS#96.44$Dependency Parsing#Penn Treebank#LAS#94.70$Named Entity Recognition#CoNLL 2003 (English)#F1#92.2$Named Entity Recognition#WLPC#F1#79.2$Constituency Parsing#Penn Treebank#F1 score#95.5
1908.08676v3.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.65$Part-Of-Speech Tagging#UD#Avg accuracy#96.88$Named Entity Recognition#Ontonotes v5 (English)#F1#88.16$CCG Supertagging#CCGbank#Accuracy#94.7
1711.04903v2.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.59$Part-Of-Speech Tagging#UD#Avg accuracy#96.65$Named Entity Recognition#CoNLL 2003 (English)#F1#91.56$Chunking#CoNLL 2000#Exact Span F1#95.25$Chunking#CoNLL 2000#Exact Span F1#95.18
1810.12443v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.58$Named Entity Recognition#CoNLL 2003 (English)#F1#91.64$Chunking#Penn Treebank#F1 score#95.29
1703.06345v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.55$Named Entity Recognition#CoNLL 2003 (English)#F1#91.26
1603.01354v5.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.55$Named Entity Recognition#CoNLL++#F1#91.87$Named Entity Recognition#CoNLL 2003 (English)#F1#91.21
1805.02474v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.55$Sentiment Analysis#MR#Accuracy#76.2$Sentiment Analysis#IMDb#Accuracy#87.15$Named Entity Recognition#CoNLL 2003 (English)#F1#91.57
1709.04109v4.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.53$Named Entity Recognition#CoNLL 2003 (English)#F1#91.24
1806.05626v2.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.49$Named Entity Recognition#CoNLL 2003 (English)#F1#91.35$Chunking#Penn Treebank#F1 score#95.06
1704.07156v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.43$Grammatical Error Detection#FCE#F0.5#48.48$Grammatical Error Detection#CoNLL-2014 A1#F0.5#17.86$Grammatical Error Detection#CoNLL-2014 A2#F0.5#25.88
1611.04361v1.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.27$Grammatical Error Detection#FCE#F0.5#41.88
1604.05529v3.pdf	Part-Of-Speech Tagging#Penn Treebank#Accuracy#97.22$Part-Of-Speech Tagging#UD#Avg accuracy#96.40
2005.10200v2.pdf	Part-Of-Speech Tagging#Ritter#Acc#90.1$Part-Of-Speech Tagging#Tweebank#Acc#95.2$Sentiment Analysis#TweetEval#Emoji#33.4$Sentiment Analysis#TweetEval#Emotion#79.3$Sentiment Analysis#TweetEval#Irony#82.1$Sentiment Analysis#TweetEval#Offensive#79.5$Sentiment Analysis#TweetEval#Sentiment#73.4$Sentiment Analysis#TweetEval#Stance#71.2$Sentiment Analysis#TweetEval#ALL#67.9$Named Entity Recognition#WNUT 2017#F1#56.5$Named Entity Recognition#WNUT 2016#F1#52.1
2101.03289v5.pdf	Part-Of-Speech Tagging#UD2.5 test#Macro-averaged F1#95.65$Part-Of-Speech Tagging#UD2.5 test#Macro-averaged F1#94.21$Dependency Parsing#UD2.5 test#Macro-averaged F1#87.06$Dependency Parsing#UD2.5 test#Macro-averaged F1#83.06
1911.03894v3.pdf	Part-Of-Speech Tagging#Spoken Corpus#UPOS#96.68$Part-Of-Speech Tagging#ParTUT#UPOS#97.63$Part-Of-Speech Tagging#Sequoia Treebank#UPOS#99.21$Part-Of-Speech Tagging#French GSD#UPOS#98.19$Natural Language Inference#XNLI French#Accuracy#81.2$Dependency Parsing#French GSD#LAS#92.47$Dependency Parsing#French GSD#UAS#94.82$Dependency Parsing#ParTUT#LAS#92.9$Dependency Parsing#ParTUT#UAS#95.21$Dependency Parsing#Sequoia Treebank#LAS#94.39$Dependency Parsing#Sequoia Treebank#UAS#95.56$Dependency Parsing#Spoken Corpus#LAS#81.37$Dependency Parsing#Spoken Corpus#UAS#86.05$Named Entity Recognition#French Treebank#F1#87.93$Named Entity Recognition#French Treebank#Precision#88.35$Named Entity Recognition#French Treebank#Recall#87.46
1906.01569v1.pdf	Part-Of-Speech Tagging#UD#Avg accuracy#96.62
1705.05952v2.pdf	Part-Of-Speech Tagging#UD#Avg accuracy#95.55
1904.03595v1.pdf	Part-Of-Speech Tagging#Social media#Accuracy#91.46
2107.05295v1.pdf	Part-Of-Speech Tagging#DaNE#Accuracy (%)#98.37$Dependency Parsing#DaNE#UAS#90.85$Dependency Parsing#DaNE#LAS#88.44$Named Entity Recognition#DaNE#Micro-average F1#84.39
2004.05388v1.pdf	Dialogue Generation#Persona-Chat#Avg F1#19.77
1901.08149v2.pdf	Dialogue Generation#Persona-Chat#Avg F1#19.09
1409.0473v7.pdf	Dialogue Generation#Persona-Chat#Avg F1#16.18$Machine Translation#WMT2014 English-French#BLEU score#36.2$Machine Translation#IWSLT2015 German-English#BLEU score#28.53
1801.07243v5.pdf	Dialogue Generation#Persona-Chat#Avg F1#11.9
2005.00743v3.pdf	Dialogue Generation#Persona-Chat#BLEU-1#14.7$Dialogue Generation#Persona-Chat#ROUGE-L#14.79$Dialogue Generation#Persona-Chat#METEOR#6.39$Dialogue Generation#Persona-Chat#CIDr#19.09$Machine Translation#WMT2014 English-French#BLEU score#41.85$Machine Translation#WMT2014 English-German#BLEU score#28.47$Semantic Textual Similarity#MRPC Dev#Accuracy#91.2$Document Summarization#CNN / Daily Mail#ROUGE-1#38.57$Document Summarization#CNN / Daily Mail#ROUGE-2#16.24$Document Summarization#CNN / Daily Mail#ROUGE-L#35.95$Linguistic Acceptability#CoLA Dev#Accuracy#53.3
2109.04137v3.pdf	Dialogue Generation#FusedChat#Slot Accuracy#0.973$Dialogue Generation#FusedChat#Joint SA#0.600$Dialogue Generation#FusedChat#Inform#75.1$Dialogue Generation#FusedChat#Inform_mct#90.8$Dialogue Generation#FusedChat#Success#60.9$Dialogue Generation#FusedChat#Success_mct#74.4$Dialogue Generation#FusedChat#BLEU#12.17$Dialogue Generation#FusedChat#PPL#10.50$Dialogue Generation#FusedChat#Sensibleness#0.58$Dialogue Generation#FusedChat#Specificity#0.51$Dialogue Generation#FusedChat#SSA#0.55$Dialogue Generation#FusedChat#Slot Accuracy#0.972$Dialogue Generation#FusedChat#Joint SA#0.592$Dialogue Generation#FusedChat#Inform#70.4$Dialogue Generation#FusedChat#Inform_mct#90.1$Dialogue Generation#FusedChat#Success#57.0$Dialogue Generation#FusedChat#Success_mct#72.7$Dialogue Generation#FusedChat#BLEU#12.05$Dialogue Generation#FusedChat#PPL#10.49$Dialogue Generation#FusedChat#Sensibleness#0.52$Dialogue Generation#FusedChat#Specificity#0.47$Dialogue Generation#FusedChat#SSA#0.50
1606.00776v2.pdf	Dialogue Generation#Ubuntu Dialogue (Cmd)#Accuracy#95.04%$Dialogue Generation#Twitter Dialogue (Tense)#Accuracy#34.48%$Dialogue Generation#Ubuntu Dialogue (Tense)#Accuracy#29.01%$Dialogue Generation#Twitter Dialogue (Noun)#Precision#4.82$Dialogue Generation#Twitter Dialogue (Noun)#Recall#5.22$Dialogue Generation#Twitter Dialogue (Noun)#F1#4.63$Dialogue Generation#Ubuntu Dialogue (Entity)#Precision#4.91$Dialogue Generation#Ubuntu Dialogue (Entity)#Recall#3.36$Dialogue Generation#Ubuntu Dialogue (Entity)#F1#3.72$Dialogue Generation#Ubuntu Dialogue (Activity)#Precision#16.84$Dialogue Generation#Ubuntu Dialogue (Activity)#Recall#9.72$Dialogue Generation#Ubuntu Dialogue (Activity)#F1#11.43
2109.00301v3.pdf	Dialogue Generation#CMU-DoG#F1#9.01$Dialogue Generation#CMU-DoG#ROUGE-1#15.37$Dialogue Generation#CMU-DoG#Rouge-L#12.56$Dialogue Generation#CMU-DoG#Meteor#7.55$Dialogue Generation#WikiText-103#Perplexity#32.48$Language Modelling#WikiText-103#Test perplexity#16.61$Language Modelling#WikiText-103#Test perplexity#24.22
1902.11205v3.pdf	Dialogue Generation#Reddit (multi-ref)#relevance (human)#2.72$Dialogue Generation#Reddit (multi-ref)#interest (human)#2.53
1701.06547v5.pdf	Dialogue Generation#Amazon-5#1 in 10 R@2#5
2109.12761v2.pdf	Multi-modal Dialogue Generation#OpenViDial 2.0#BLEU#1.99$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-1#0.0056$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-2#0.0431$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-3#0.125$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-4#0.2215$Multi-modal Dialogue Generation#OpenViDial 2.0#BLEU#1.97$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-1#0.0041$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-2#0.0353$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-3#0.0999$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-4#0.1726$Multi-modal Dialogue Generation#OpenViDial 2.0#BLEU#1.96$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-1#0.0039$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-2#0.0311$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-3#0.0953$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-4#0.163$Multi-modal Dialogue Generation#OpenViDial 2.0#BLEU#1.95$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-1#0.0037$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-2#0.0302$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-3#0.0929$Multi-modal Dialogue Generation#OpenViDial 2.0#Dis-4#0.1711
2109.07506v1.pdf	Dialogue State Tracking#MULTIWOZ 2.2#MultiWOZ (Joint Goal Acc)#57.6$Dialogue State Tracking#MULTIWOZ 2.2#MultiWOZ (Joint Goal Acc)#56.3$Dialogue State Tracking#MULTIWOZ 2.1#MultiWOZ (Joint Goal Acc)#56.66$Dialogue State Tracking#MULTIWOZ 2.1#MultiWOZ (Joint Goal Acc)#56.12
2205.06983v2.pdf	Dialogue State Tracking#CoSQL#question match accuracy#55.7$Dialogue State Tracking#CoSQL#interaction match accuracy#26.5$Text-To-Sql#SParC#interaction match accuracy#45.2$Text-To-Sql#SParC#question match accuracy#67.7$Text-To-Sql#SPIDER#Exact Match Accuracy (in Dev)#75.3$Text-To-Sql#SPIDER#Execution Accuracy (in Dev)#80.5$Text-To-Sql#SPIDER#Exact Match Accuracy (in Dev)#72.6$Text-To-Sql#SPIDER#Execution Accuracy (in Dev)#76.6
2109.05093v1.pdf	Dialogue State Tracking#CoSQL#question match accuracy#54.6$Dialogue State Tracking#CoSQL#interaction match accuracy#23.7$Semantic Parsing#spider#Accuracy#71.9$Text-To-Sql#spider#Accuracy (Dev)#75.5$Text-To-Sql#spider#Accuracy (Test)#71.9$Text-To-Sql#SPIDER#Exact Match Accuracy (in Dev)#75.5$Text-To-Sql#SPIDER#Execution Accuracy (in Dev)#79.3$Text-To-Sql#SPIDER#Exact Match Accuracy (in Dev)#71.5$Text-To-Sql#SPIDER#Execution Accuracy (in Dev)#74.4
2101.01686v1.pdf	Dialogue State Tracking#CoSQL#question match accuracy#46.8$Dialogue State Tracking#CoSQL#interaction match accuracy#17.0
1909.00786v2.pdf	Dialogue State Tracking#CoSQL#question match accuracy#40.8$Dialogue State Tracking#CoSQL#interaction match accuracy#13.7$Text-To-Sql#SParC#interaction match accuracy#25.3$Text-To-Sql#SParC#question match accuracy#47.9
2009.07396v3.pdf	Dialogue State Tracking#CoSQL#question match accuracy#39.7$Dialogue State Tracking#CoSQL#interaction match accuracy#12.8$Text-To-Sql#SParC#interaction match accuracy#23.5$Text-To-Sql#SParC#question match accuracy#45.9
1909.05378v1.pdf	Dialogue State Tracking#CoSQL#question match accuracy#14.1$Dialogue State Tracking#CoSQL#interaction match accuracy#2.2$Dialogue State Tracking#CoSQL#question match accuracy#13.9$Dialogue State Tracking#CoSQL#interaction match accuracy#2.6
2110.15659v1.pdf	Dialogue State Tracking#Wizard-of-Oz#Joint#91.37
2011.09553v2.pdf	Dialogue State Tracking#Wizard-of-Oz#Joint#91.2$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#85$Classification#SGD#F1 (Seqeval)#2020
2108.13990v2.pdf	Dialogue State Tracking#Wizard-of-Oz#Joint#91$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#73.6
1910.12995v3.pdf	Dialogue State Tracking#Wizard-of-Oz#Request#97.6$Dialogue State Tracking#Wizard-of-Oz#Joint#90.5
1810.09587v1.pdf	Dialogue State Tracking#Wizard-of-Oz#Joint#88.9$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#75.5
1910.09942v1.pdf	Dialogue State Tracking#Wizard-of-Oz#Request#96.9$Dialogue State Tracking#Wizard-of-Oz#Joint#88.7
1812.00899v1.pdf	Dialogue State Tracking#Wizard-of-Oz#Request#97.4$Dialogue State Tracking#Wizard-of-Oz#Joint#88.5
1805.09655v3.pdf	Dialogue State Tracking#Wizard-of-Oz#Request#97.1$Dialogue State Tracking#Wizard-of-Oz#Joint#88.1$Dialogue State Tracking#Second dialogue state tracking challenge#Request#97.5$Dialogue State Tracking#Second dialogue state tracking challenge#Area#-$Dialogue State Tracking#Second dialogue state tracking challenge#Food#-$Dialogue State Tracking#Second dialogue state tracking challenge#Price#-$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#74.5
1606.03777v2.pdf	Dialogue State Tracking#Wizard-of-Oz#Request#96.5$Dialogue State Tracking#Wizard-of-Oz#Joint#84.4$Dialogue State Tracking#Second dialogue state tracking challenge#Request#96.5$Dialogue State Tracking#Second dialogue state tracking challenge#Area#90$Dialogue State Tracking#Second dialogue state tracking challenge#Food#84$Dialogue State Tracking#Second dialogue state tracking challenge#Price#94$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#73.4
1804.06512v1.pdf	Dialogue State Tracking#Second dialogue state tracking challenge#Request#-$Dialogue State Tracking#Second dialogue state tracking challenge#Area#90$Dialogue State Tracking#Second dialogue state tracking challenge#Food#84$Dialogue State Tracking#Second dialogue state tracking challenge#Price#92$Dialogue State Tracking#Second dialogue state tracking challenge#Joint#72
2201.05966v3.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#70.07$Semantic Parsing#WikiTableQuestions#Accuracy (Dev)#50.65$Semantic Parsing#WikiTableQuestions#Accuracy (Test)#49.29$Table-based Fact Verification#TabFact#Test#83.68$Table-based Fact Verification#TabFact#Val#83.97
2010.05740v4.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#63.6$Task-Oriented Dialogue Systems#KVRET#BLEU#17.3
2004.11019v3.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#62.5$Task-Oriented Dialogue Systems#KVRET#BLEU#15.2$Task-Oriented Dialogue Systems#Kvret#Entity F1#62.7
1901.04713v2.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#59.97$Task-Oriented Dialogue Systems#KVRET#BLEU#14.79
1909.06762v2.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#53.7$Task-Oriented Dialogue Systems#KVRET#BLEU#13.9
1806.04441v1.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#51.9$Task-Oriented Dialogue Systems#KVRET#BLEU#12.7
1705.05414v2.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#48.0$Task-Oriented Dialogue Systems#KVRET#BLEU#13.2
1804.08217v3.pdf	Task-Oriented Dialogue Systems#KVRET#Entity F1#33.4$Task-Oriented Dialogue Systems#KVRET#BLEU#12.6
2102.01672v3.pdf	Task-Oriented Dialogue Systems#SGD#METEOR#0.331$Task-Oriented Dialogue Systems#SGD#METEOR#0.089$Text Generation#DART#METEOR#0.115$Text Generation#DART#METEOR#0.107$Text Generation#CommonGen#METEOR#0.301$Text Generation#CommonGen#METEOR#0.291$Text Generation#Czech restaurant information#METEOR#0.167$Text Generation#Czech restaurant information#METEOR#0.152$Text Generation#Czech restaurant information#METEOR#0.151$Data-to-Text Generation#WebNLG ru#METEOR#0.613$Data-to-Text Generation#WebNLG ru#METEOR#0.180$Data-to-Text Generation#ToTTo#METEOR#0.363$Data-to-Text Generation#Cleaned E2E NLG Challenge#METEOR (Validation set)#0.394$Data-to-Text Generation#Cleaned E2E NLG Challenge#METEOR (Validation set)#0.391$Data-to-Text Generation#Cleaned E2E NLG Challenge#METEOR (Validation set)#0.373$Data-to-Text Generation#Cleaned E2E NLG Challenge#METEOR (Validation set)#0.369$Data-to-Text Generation#WebNLG en#METEOR#0.462$Data-to-Text Generation#WebNLG en#METEOR#0.287$Text Simplification#ASSET#METEOR#0.581$Text Simplification#ASSET#METEOR#0.560$Text Simplification#TurkCorpus#METEOR#0.649$Text Simplification#TurkCorpus#METEOR#0.556$Abstractive Text Summarization#MLSUM de#METEOR#0.437$Abstractive Text Summarization#MLSUM es#METEOR#0.210$Extreme Summarization#GEM-XSum#ROUGE-2#23.2$Extreme Summarization#GEM-XSum#Parameters#568 M$Extreme Summarization#XSum#METEOR#0.216
2203.10759v1.pdf	SSTOD#SSD_NAME#Joint Acc#84.96$SSTOD#SSD_NAME#Slot Acc#93.12$SSTOD#SSD_NAME#Dialogue Success Rate#57.73$SSTOD#automata#Dialogue Success Rate#45.8
2010.01082v1.pdf	Visual Dialog#ConvAI2#F1#18.4$Visual Dialog#ConvAI2#BLEU-4#1.1$Visual Dialog#ConvAI2#ROUGE-L#22.6$Visual Dialog#Wizard of Wikipedia#F1#18.6$Visual Dialog#Wizard of Wikipedia#BLEU-4#2.2$Visual Dialog#Wizard of Wikipedia#ROUGE-L#17.4$Visual Dialog#BlendedSkillTalk#F1#17.8$Visual Dialog#BlendedSkillTalk#BLEU-4#1$Visual Dialog#BlendedSkillTalk#ROUGE-L#19.3$Visual Dialog#Image-Chat#F1#13.1$Visual Dialog#Image-Chat#BLEU-4#40$Visual Dialog#Image-Chat#ROUGE-L#18$Visual Dialog#EmpatheticDialogues#F1#19.2$Visual Dialog#EmpatheticDialogues#BLEU-4#1.5$Visual Dialog#EmpatheticDialogues#ROUGE-L#24.5
1911.11390v2.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#74.88$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#52.14$Visual Dialog#Visual Dialog v1.0 test-std#R@1#38.92$Visual Dialog#Visual Dialog v1.0 test-std#R@5#66.6$Visual Dialog#Visual Dialog v1.0 test-std#R@10#80.65$Visual Dialog#Visual Dialog v1.0 test-std#Mean#6.53
2104.07511v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#72.83$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#69.92$Visual Dialog#Visual Dialog v1.0 test-std#R@1#58.3$Visual Dialog#Visual Dialog v1.0 test-std#R@5#81.55$Visual Dialog#Visual Dialog v1.0 test-std#R@10#89.6$Visual Dialog#Visual Dialog v1.0 test-std#Mean#3.84$Visual Dialog#VisDial v1.0 test-std#MRR#0.7124$Visual Dialog#VisDial v1.0 test-std#Mean Rank#2.96$Visual Dialog#VisDial v1.0 test-std#R@1#58.28$Visual Dialog#VisDial v1.0 test-std#R@10#94.45$Visual Dialog#VisDial v1.0 test-std#R@5#87.55$Visual Dialog#VisDial v1.0 test-std#MRR#0.7041$Visual Dialog#VisDial v1.0 test-std#Mean Rank#3.66$Visual Dialog#VisDial v1.0 test-std#NDCG#72.16$Visual Dialog#VisDial v1.0 test-std#R@1#58.18$Visual Dialog#VisDial v1.0 test-std#R@10#90.83$Visual Dialog#VisDial v1.0 test-std#R@5#83.85$Visual Dialog#VisDial v1.0 test-std#NDCG#64.04
2004.14025v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#59.37$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#64.84$Visual Dialog#Visual Dialog v1.0 test-std#R@1#51.45$Visual Dialog#Visual Dialog v1.0 test-std#R@5#81.12$Visual Dialog#Visual Dialog v1.0 test-std#R@10#90.65$Visual Dialog#Visual Dialog v1.0 test-std#Mean#3.97$Visual Dialog#VisDial v0.9 val#MRR#0.6765$Visual Dialog#VisDial v0.9 val#Mean Rank#3.73$Visual Dialog#VisDial v0.9 val#R@1#54.65$Visual Dialog#VisDial v0.9 val#R@10#91.47$Visual Dialog#VisDial v0.9 val#R@5#83.85
1704.05526v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#58.1$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#58.8$Visual Dialog#Visual Dialog v1.0 test-std#R@1#44.15$Visual Dialog#Visual Dialog v1.0 test-std#R@5#76.88$Visual Dialog#Visual Dialog v1.0 test-std#R@10#86.88$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.4$Visual Question Answering#VQA v2 test-dev#Accuracy#64.9
1902.09368v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#57.59$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#63.2$Visual Dialog#Visual Dialog v1.0 test-std#R@1#49.63$Visual Dialog#Visual Dialog v1.0 test-std#R@5#79.75$Visual Dialog#Visual Dialog v1.0 test-std#R@10#89.35$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.3$Visual Dialog#VisDial v0.9 val#MRR#66.38$Visual Dialog#VisDial v0.9 val#Mean Rank#4.04$Visual Dialog#VisDial v0.9 val#R@1#53.33$Visual Dialog#VisDial v0.9 val#R@10#90.38$Visual Dialog#VisDial v0.9 val#R@5#82.42
1902.09774v1.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#57.32$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#62.20$Visual Dialog#Visual Dialog v1.0 test-std#R@1#47.90$Visual Dialog#Visual Dialog v1.0 test-std#R@5#80.43$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.17
1904.05880v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#57.20$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#69.3$Visual Dialog#Visual Dialog v1.0 test-std#R@1#55.65$Visual Dialog#Visual Dialog v1.0 test-std#R@5#86.73$Visual Dialog#Visual Dialog v1.0 test-std#R@10#94.05$Visual Dialog#Visual Dialog v1.0 test-std#Mean#3.14$Visual Dialog#VisDial v0.9 val#MRR#68.92$Visual Dialog#VisDial v0.9 val#Mean Rank#3.39$Visual Dialog#VisDial v0.9 val#R@1#55.16$Visual Dialog#VisDial v0.9 val#R@10#92.95$Visual Dialog#VisDial v0.9 val#R@5#86.26
1902.09326v3.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#57.17$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#64.22$Visual Dialog#Visual Dialog v1.0 test-std#R@1#50.88$Visual Dialog#Visual Dialog v1.0 test-std#R@5#80.63$Visual Dialog#Visual Dialog v1.0 test-std#R@10#89.45$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.20$Visual Dialog#VisDial v0.9 val#MRR#0.6792$Visual Dialog#VisDial v0.9 val#Mean Rank#3.97$Visual Dialog#VisDial v0.9 val#R@1#54.76$Visual Dialog#VisDial v0.9 val#R@10#90.68$Visual Dialog#VisDial v0.9 val#R@5#83.03
2004.02194v1.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#56.64$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#63.49$Visual Dialog#Visual Dialog v1.0 test-std#R@1#49.85$Visual Dialog#Visual Dialog v1.0 test-std#R@5#80.63$Visual Dialog#Visual Dialog v1.0 test-std#R@10#90.15$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.11$Visual Dialog#VisDial v0.9 val#MRR#0.6756$Visual Dialog#VisDial v0.9 val#Mean Rank#3.75$Visual Dialog#VisDial v0.9 val#R@1#54.64$Visual Dialog#VisDial v0.9 val#R@10#91.48$Visual Dialog#VisDial v0.9 val#R@5#83.72
1911.07251v1.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#56.32$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#63.23$Visual Dialog#Visual Dialog v1.0 test-std#R@1#49.25$Visual Dialog#Visual Dialog v1.0 test-std#R@5#80.23$Visual Dialog#Visual Dialog v1.0 test-std#R@10#89.7$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.11$Visual Dialog#VisDial v0.9 val#MRR#62.94$Visual Dialog#VisDial v0.9 val#Mean Rank#4.17$Visual Dialog#VisDial v0.9 val#R@1#48.64$Visual Dialog#VisDial v0.9 val#R@10#89.94$Visual Dialog#VisDial v0.9 val#R@5#80.89
1812.02664v2.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#55.59$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#63.03$Visual Dialog#Visual Dialog v1.0 test-std#R@1#49.03$Visual Dialog#Visual Dialog v1.0 test-std#R@5#80.40$Visual Dialog#Visual Dialog v1.0 test-std#R@10#89.83$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.18$Visual Dialog#VisDial v0.9 val#MRR#0.6634$Visual Dialog#VisDial v0.9 val#Mean Rank#3.93$Visual Dialog#VisDial v0.9 val#R@1#52.71$Visual Dialog#VisDial v0.9 val#R@10#90.73$Visual Dialog#VisDial v0.9 val#R@5#82.97
1809.01816v1.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#54.70$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#61.50$Visual Dialog#Visual Dialog v1.0 test-std#R@1#47.55$Visual Dialog#Visual Dialog v1.0 test-std#R@5#78.10$Visual Dialog#Visual Dialog v1.0 test-std#R@10#88.80$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.40$Visual Dialog#VisDial v0.9 val#MRR#64.1$Visual Dialog#VisDial v0.9 val#Mean Rank#4.45$Visual Dialog#VisDial v0.9 val#R@1#50.92$Visual Dialog#VisDial v0.9 val#R@10#88.81$Visual Dialog#VisDial v0.9 val#R@5#80.18$Visual Dialog#VisDial v0.9 val#MRR#63.6$Visual Dialog#VisDial v0.9 val#Mean Rank#4.53$Visual Dialog#VisDial v0.9 val#R@1#50.24$Visual Dialog#VisDial v0.9 val#R@10#88.51$Visual Dialog#VisDial v0.9 val#R@5#79.81$Common Sense Reasoning#Visual Dialog v0.9#1 in 10 R@5#80.1
1904.05548v2.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#52.82$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#61.37$Visual Dialog#Visual Dialog v1.0 test-std#R@1#47.33$Visual Dialog#Visual Dialog v1.0 test-std#R@5#77.98$Visual Dialog#Visual Dialog v1.0 test-std#R@10#87.83$Visual Dialog#Visual Dialog v1.0 test-std#Mean#4.57$Visual Dialog#VisDial v0.9 val#MRR#0.6285$Visual Dialog#VisDial v0.9 val#Mean Rank#4.57$Visual Dialog#VisDial v0.9 val#R@1#48.95$Visual Dialog#VisDial v0.9 val#R@10#88.36$Visual Dialog#VisDial v0.9 val#R@5#79.65
1611.08669v5.pdf	Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#47.5$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#55.5$Visual Dialog#Visual Dialog v1.0 test-std#R@1#40.98$Visual Dialog#Visual Dialog v1.0 test-std#R@5#72.30$Visual Dialog#Visual Dialog v1.0 test-std#R@10#83.30$Visual Dialog#Visual Dialog v1.0 test-std#Mean#5.92$Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#45.5$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#54.2$Visual Dialog#Visual Dialog v1.0 test-std#R@1#39.93$Visual Dialog#Visual Dialog v1.0 test-std#R@5#70.45$Visual Dialog#Visual Dialog v1.0 test-std#R@10#81.50$Visual Dialog#Visual Dialog v1.0 test-std#Mean#6.41$Visual Dialog#Visual Dialog v1.0 test-std#NDCG (x 100)#45.3$Visual Dialog#Visual Dialog v1.0 test-std#MRR (x 100)#55.4$Visual Dialog#Visual Dialog v1.0 test-std#R@1#40.95$Visual Dialog#Visual Dialog v1.0 test-std#R@5#72.45$Visual Dialog#Visual Dialog v1.0 test-std#R@10#82.83$Visual Dialog#Visual Dialog v1.0 test-std#Mean#5.95$Visual Dialog#VisDial v0.9 val#MRR#0.5965$Visual Dialog#VisDial v0.9 val#Mean Rank#5.46$Visual Dialog#VisDial v0.9 val#R@1#45.55$Visual Dialog#VisDial v0.9 val#R@10#85.37$Visual Dialog#VisDial v0.9 val#R@5#76.22$Visual Dialog#VisDial v0.9 val#MRR#0.5846$Visual Dialog#VisDial v0.9 val#Mean Rank#5.72$Visual Dialog#VisDial v0.9 val#R@1#44.67$Visual Dialog#VisDial v0.9 val#R@10#84.22$Visual Dialog#VisDial v0.9 val#R@5#74.50$Visual Dialog#VisDial v0.9 val#MRR#0.5807$Visual Dialog#VisDial v0.9 val#Mean Rank#5.78$Visual Dialog#VisDial v0.9 val#R@1#43.82$Visual Dialog#VisDial v0.9 val#R@10#84.07$Visual Dialog#VisDial v0.9 val#R@5#74.68
1711.07613v1.pdf	Visual Dialog#VisDial v0.9 val#MRR#63.98$Visual Dialog#VisDial v0.9 val#Mean Rank#4.47$Visual Dialog#VisDial v0.9 val#R@1#50.29$Visual Dialog#VisDial v0.9 val#R@10#88.81$Visual Dialog#VisDial v0.9 val#R@5#80.71
1803.11186v1.pdf	Visual Dialog#VisDial v0.9 val#MRR#62.42$Visual Dialog#VisDial v0.9 val#Mean Rank#4.70$Visual Dialog#VisDial v0.9 val#R@1#48.55$Visual Dialog#VisDial v0.9 val#R@10#87.75$Visual Dialog#VisDial v0.9 val#R@5#78.96
1706.01554v2.pdf	Visual Dialog#VisDial v0.9 val#MRR#62.22$Visual Dialog#VisDial v0.9 val#Mean Rank#4.81$Visual Dialog#VisDial v0.9 val#R@1#48.48$Visual Dialog#VisDial v0.9 val#R@10#87.59$Visual Dialog#VisDial v0.9 val#R@5#78.75
1606.00061v5.pdf	Visual Dialog#VisDial v0.9 val#MRR#57.88$Visual Dialog#VisDial v0.9 val#Mean Rank#5.84$Visual Dialog#VisDial v0.9 val#R@1#43.51$Visual Dialog#VisDial v0.9 val#R@10#83.96$Visual Dialog#VisDial v0.9 val#R@5#74.49$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#66.1$Visual Question Answering#VQA v1 test-dev#Accuracy#61.8$Visual Question Answering#VQA v1 test-std#Accuracy#62.1$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#62.1
1709.07992v3.pdf	Visual Dialog#VisDial v0.9 val#Mean Rank#4.86$Visual Dialog#VisDial v0.9 val#R@1#48.53$Visual Dialog#VisDial v0.9 val#R@10#87.43$Visual Dialog#VisDial v0.9 val#R@5#78.66
2001.10468v1.pdf	Goal-Oriented Dialog#Kvret#BLEU#0.1831$Goal-Oriented Dialog#Kvret#Embedding Average#95.5$Goal-Oriented Dialog#Kvret#Vector Extrema#97.4$Goal-Oriented Dialog#Kvret#Greedy Matching#62.5
2206.14589v1.pdf	Spoken Language Understanding#Timers and Such#Accuracy (%)#95.4$Spoken Language Understanding#Timers and Such#Accuracy (%)#90.0$Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#88.0$Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#84.8$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-EN (%)#80.4$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-FR (%)#78.3$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-EN (%)#77.6$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-FR (%)#77.8$Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.7$Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.5$Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.2$Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#98.7$Intent Classification#SLURP#Accuracy (%)#53.11$Intent Classification#SLURP#Accuracy (%)#43.15$Slot Filling#SLURP#F1#0.395$Slot Filling#SLURP#F1#0.313
2104.01604v2.pdf	Spoken Language Understanding#Timers and Such#Accuracy (%)#81.6
2012.08549v1.pdf	Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#84.9$Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.5
1810.12735v2.pdf	Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#84.2$Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#79.3$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-EN (%)#68.7$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-FR (%)#75.1$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-EN (%)#47.8$Spoken Language Understanding#Snips-SmartSpeaker#Accuracy-FR (%)#42.3
1910.09463v1.pdf	Spoken Language Understanding#Snips-SmartLights#Accuracy (%)#71.4
2204.14272v1.pdf	Spoken Language Understanding#Spoken-SQuAD#F1 score#77.1
1910.11559v4.pdf	Spoken Language Understanding#Spoken-SQuAD#F1 score#71.75
1904.07904v1.pdf	Spoken Language Understanding#Spoken-SQuAD#F1 score#63.11
1804.00320v1.pdf	Spoken Language Understanding#Spoken-SQuAD#F1 score#58.71
2010.13105v2.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.7
2104.07253v2.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.7
2102.06283v1.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.7
2111.14842v1.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.6
2106.09009v2.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.4
2106.04660v1.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.3
2008.01994v1.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.2
2111.00400v1.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#99.0
1904.03670v2.pdf	Spoken Language Understanding#Fluent Speech Commands#Accuracy (%)#98.8
2110.03427v2.pdf	Spoken language identification#YouTube News dataset (White Noise)#Accuracy#0.912$Spoken language identification#YouTube News dataset (White Noise)#Accuracy#0.888$Spoken language identification#YouTube News dataset (White Noise)#Accuracy#0.871$Spoken language identification#YouTube News dataset (No Noise)#Accuracy#0.967$Spoken language identification#YouTube News dataset (No Noise)#Accuracy#0.966$Spoken language identification#YouTube News dataset (No Noise)#Accuracy#0.948$Spoken language identification#IndicTTS#Classification Accuracy#0.987$Spoken language identification#IndicTTS#Classification Accuracy#0.983
1708.04811v1.pdf	Spoken language identification#YouTube News dataset (White Noise)#F1 Score#0.91$Spoken language identification#YouTube News dataset (White Noise)#Accuracy#0.91$Spoken language identification#YouTube News dataset (White Noise)#F1 Score#0.63$Spoken language identification#YouTube News dataset (White Noise)#Accuracy#0.63$Spoken language identification#YouTube News dataset (No Noise)#F1 Score#0.96$Spoken language identification#YouTube News dataset (No Noise)#Accuracy#0.96$Spoken language identification#YouTube News dataset (No Noise)#F1 Score#0.91$Spoken language identification#YouTube News dataset (No Noise)#Accuracy#0.91$Spoken language identification#YouTube News dataset (Background Music)#F1 Score#0.89$Spoken language identification#YouTube News dataset (Background Music)#Accuracy#0.89$Spoken language identification#YouTube News dataset (Background Music)#F1 Score#0.70$Spoken language identification#YouTube News dataset (Background Music)#Accuracy#0.70$Spoken language identification#YouTube News dataset (Crackling Noise)#F1 Score#0.93$Spoken language identification#YouTube News dataset (Crackling Noise)#Accuracy#0.93$Spoken language identification#YouTube News dataset (Crackling Noise)#F1 Score#0.83$Spoken language identification#YouTube News dataset (Crackling Noise)#Accuracy#0.82
1910.04269v1.pdf	Spoken language identification#VoxForge Commonwealth#Accuracy (%)#95.4$Spoken language identification#VoxForge Commonwealth#Accuracy (%)#95.0$Spoken language identification#VoxForge Commonwealth#Accuracy (%)#94.3$Spoken language identification#VoxForge Commonwealth#Accuracy (%)#93.7$Spoken language identification#VoxForge European#Accuracy (%)#96.3$Spoken language identification#VoxForge European#Accuracy (%)#96.0$Spoken language identification#VoxForge European#Accuracy (%)#94.7$Spoken language identification#VoxForge European#Accuracy (%)#94.4$Spoken language identification#VoxForge European#Accuracy (%)#93.7$Keyword Spotting#VoxForge#Accuracy (%)#93.7$Keyword Spotting#VoxForge#Accuracy (%)#95.4
2011.12998.pdf	Spoken language identification#LRE07#3 sec#8.25$Spoken language identification#LRE07#10 sec#2.61$Spoken language identification#LRE07#30 sec#1.16$Spoken language identification#LRE07#Average#4.00$Spoken language identification#LRE07#3 sec#8.59$Spoken language identification#LRE07#10 sec#2.49$Spoken language identification#LRE07#30 sec#1.09$Spoken language identification#LRE07#Average#4.06$Spoken language identification#LRE07#3 sec#9.39$Spoken language identification#LRE07#10 sec#3.14$Spoken language identification#LRE07#30 sec#1.90$Spoken language identification#LRE07#Average#4.81$Spoken language identification#LRE07#3 sec#10.58$Spoken language identification#LRE07#10 sec#3.33$Spoken language identification#LRE07#30 sec#1.72$Spoken language identification#LRE07#Average#5.21$Spoken language identification#LRE07#3 sec#15.29$Spoken language identification#LRE07#10 sec#4.54$Spoken language identification#LRE07#30 sec#1.30$Spoken language identification#LRE07#Average#7.04$Spoken language identification#LRE07#3 sec#17.28$Spoken language identification#LRE07#10 sec#5.90$Spoken language identification#LRE07#30 sec#2.10$Spoken language identification#LRE07#Average#8.42$Spoken language identification#LRE07#3 sec#18.59$Spoken language identification#LRE07#10 sec#6.28$Spoken language identification#LRE07#30 sec#1.34$Spoken language identification#LRE07#Average#8.73$Spoken language identification#LRE07#3 sec#19.67$Spoken language identification#LRE07#10 sec#7.84$Spoken language identification#LRE07#30 sec#3.31$Spoken language identification#LRE07#Average#10.27$Spoken language identification#LRE07#3 sec#26.04$Spoken language identification#LRE07#10 sec#11.93$Spoken language identification#LRE07#30 sec#4.52$Spoken language identification#LRE07#Average#14.17$Spoken language identification#KALAKA-3#PC#0.041$Spoken language identification#KALAKA-3#PO#0.056$Spoken language identification#KALAKA-3#EC#0.022$Spoken language identification#KALAKA-3#EO#0.058$Spoken language identification#KALAKA-3#PC#0.055$Spoken language identification#KALAKA-3#PO#0.083$Spoken language identification#KALAKA-3#EC#0.033$Spoken language identification#KALAKA-3#EO#0.059$Spoken language identification#VOXLINGUA107#0..5sec#12.3$Spoken language identification#VOXLINGUA107#5..20sec#6.1$Spoken language identification#VOXLINGUA107#Average#7.1$Spoken language identification#VOXLINGUA107#0..5sec#13.4$Spoken language identification#VOXLINGUA107#5..20sec#6.6$Spoken language identification#VOXLINGUA107#Average#7.6
1509.06928v2.pdf	Spoken language identification#Untranscribed mixed-speech dataset#ACC#45.2%$Spoken language identification#Untranscribed mixed-speech dataset#PRC#44.8%$Spoken language identification#Untranscribed mixed-speech dataset#RCL#45.4%$Spoken language identification#Untranscribed mixed-speech dataset#ACC#40.4%$Spoken language identification#Untranscribed mixed-speech dataset#PRC#40.2%$Spoken language identification#Untranscribed mixed-speech dataset#RCL#41.3%$Spoken language identification#Untranscribed mixed-speech dataset#ACC#40%$Spoken language identification#Untranscribed mixed-speech dataset#PRC#40%$Spoken language identification#Untranscribed mixed-speech dataset#RCL#40.6%$Spoken language identification#Untranscribed mixed-speech dataset#ACC#37.9%$Spoken language identification#Untranscribed mixed-speech dataset#PRC#37.5%$Spoken language identification#Untranscribed mixed-speech dataset#RCL#50.2%
2202.01374v1.pdf	Spoken language identification#Fleurs#Accuracy (%)#77.7
2205.12688v2.pdf	Dialogue Safety Prediction#ProsocialDialog#Accuracy#77.08
2009.11152v3.pdf	Dialogue Act Classification#ICSI Meeting Recorder Dialog Act (MRDA) corpus#Accuracy#92.4$Dialogue Act Classification#Switchboard corpus#Accuracy#79.2$Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#65.37$Emotion Recognition in Conversation#IEMOCAP#Accuracy#66.05$Emotion Recognition in Conversation#SEMAINE#MAE (Valence)#0.16$Emotion Recognition in Conversation#SEMAINE#MAE (Arousal)#0.16$Emotion Recognition in Conversation#SEMAINE#MAE (Expectancy)#0.16$Emotion Recognition in Conversation#SEMAINE#MAE (Power)#7.70$Emotion Recognition in Conversation#MELD#Weighted-F1#61.90$Emotion Recognition in Conversation#DailyDialog#Micro-F1#60.14$Text Classification#SILICONE Benchmark#1:1 Accuracy#71.25
1711.05568v1.pdf	Dialogue Act Classification#ICSI Meeting Recorder Dialog Act (MRDA) corpus#Accuracy#91.7$Dialogue Act Classification#Switchboard corpus#Accuracy#81.3
2002.08801v2.pdf	Dialogue Act Classification#ICSI Meeting Recorder Dialog Act (MRDA) corpus#Accuracy#91.6$Dialogue Act Classification#Switchboard corpus#Accuracy#85.0
1904.02594v2.pdf	Dialogue Act Classification#ICSI Meeting Recorder Dialog Act (MRDA) corpus#Accuracy#91.1$Dialogue Act Classification#Switchboard corpus#Accuracy#82.9
1709.04250v2.pdf	Dialogue Act Classification#ICSI Meeting Recorder Dialog Act (MRDA) corpus#Accuracy#90.9$Dialogue Act Classification#Switchboard corpus#Accuracy#79.2
1810.09154v3.pdf	Dialogue Act Classification#Switchboard corpus#Accuracy#82.3
1811.05021v1.pdf	Dialogue Act Classification#Switchboard corpus#Accuracy#81.5
1805.06242v2.pdf	Dialogue Act Classification#Switchboard corpus#Accuracy#77.42
1805.06280v1.pdf	Dialogue Act Classification#Switchboard corpus#Accuracy#77.34
1603.03827v1.pdf	Dialogue Act Classification#Switchboard corpus#Accuracy#73.1
2204.11320v1.pdf	Empathetic Response Generation#EmpatheticDialogues#BLEU#0.225
2111.14592v8.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Success)#86.20$End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Inform)#95.30$End-To-End Dialogue Modelling#MULTIWOZ 2.1#BLEU#20.01$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#85.3$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#94.4$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#20.5
2009.08115v3.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Success)#67.1$End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Inform)#78.1$End-To-End Dialogue Modelling#MULTIWOZ 2.1#BLEU#18.3
2102.05126v3.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Success)#72.9$End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Inform)#91.4$End-To-End Dialogue Modelling#MULTIWOZ 2.1#BLEU#17.2$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#75.5$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#90.2$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#17.2
2005.00796v4.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Success)#70.5$End-To-End Dialogue Modelling#MULTIWOZ 2.1#MultiWOZ (Inform)#85.0$End-To-End Dialogue Modelling#MULTIWOZ 2.1#BLEU#15.2$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#70.1$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#84.4$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#15.0
2103.10518v1.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#76.2$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#86.9$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#20.6
2005.05298v4.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#72.9$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#85.5$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#16.5
1911.10484v2.pdf	End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Success)#60.4$End-To-End Dialogue Modelling#MULTIWOZ 2.0#MultiWOZ (Inform)#76.3$End-To-End Dialogue Modelling#MULTIWOZ 2.0#BLEU#18.6
1810.11118v2.pdf	Conversation Disentanglement#Linux IRC (Ch2 Kummerfeld)#1-1#59.7$Conversation Disentanglement#Linux IRC (Ch2 Elsner)#1-1#52.1$Conversation Disentanglement#Linux IRC (Ch2 Elsner)#Local#77.8$Conversation Disentanglement#Linux IRC (Ch2 Elsner)#Shen F-1#53.8$Conversation Disentanglement#irc-disentanglement#VI#91.5$Conversation Disentanglement#irc-disentanglement#1-1#76.0$Conversation Disentanglement#irc-disentanglement#P#36.3$Conversation Disentanglement#irc-disentanglement#R#39.7$Conversation Disentanglement#irc-disentanglement#F#38.0$Conversation Disentanglement#irc-disentanglement#VI#91.3$Conversation Disentanglement#irc-disentanglement#1-1#75.6$Conversation Disentanglement#irc-disentanglement#P#34.6$Conversation Disentanglement#irc-disentanglement#R#38.0$Conversation Disentanglement#irc-disentanglement#F#36.2$Conversation Disentanglement#irc-disentanglement#VI#69.3$Conversation Disentanglement#irc-disentanglement#1-1#26.6$Conversation Disentanglement#irc-disentanglement#P#67.0$Conversation Disentanglement#irc-disentanglement#R#21.1$Conversation Disentanglement#irc-disentanglement#F#32.1
2004.01940v1.pdf	Conversation Disentanglement#irc-disentanglement#VI#93.3$Conversation Disentanglement#irc-disentanglement#P#44.3$Conversation Disentanglement#irc-disentanglement#R#49.6$Conversation Disentanglement#irc-disentanglement#F#46.8
2105.02482v2.pdf	Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Overall Human Rating#4.15$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Coherent#2.8017$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Error Recovery#2.7518$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Consistent#0.9390$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Diversity#2.7441$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Topic Depth#2.7678$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Likeable#2.7878$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Understanding#2.8285$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Flexible#2.8000$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Informative#2.7881$Interactive Evaluation of Dialog#DSTC9 Track 3 - Task 2#Inquisitive#2.7949
2109.12212v2.pdf	Multimodal GIF Dialog#GIF Reply Dataset#nDCG@10#0.8145
2108.05271v2.pdf	Problem-Solving Deliberation#DeliData#AUC#0.62$Problem-Solving Deliberation#DeliData#AUC#0.53$Problem-Solving Deliberation#DeliData#AUC#0.50
2010.04062v1.pdf	Text-To-Speech Synthesis#20000 utterances#10-keyword Speech Commands dataset#16
1904.03446v3.pdf	Text-To-Speech Synthesis#CMUDict 0.7b#Word Error Rate (WER)#19.88%$Text-To-Speech Synthesis#CMUDict 0.7b#Phoneme Error Rate#4.6%
2205.04421v2.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.56$Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.43
2105.06337v2.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.37
2005.11129v1.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.34
2006.04558v8.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.32
2204.09934v1.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.28$Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#4.03
1809.08895v3.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#3.88
1905.09263v5.pdf	Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#3.84$Text-To-Speech Synthesis#LJSpeech#Audio Quality MOS#2.4
2005.05957v3.pdf	Text-To-Speech Synthesis#LJSpeech#Pleasantness MOS#3.665$Text-To-Speech Synthesis#LJSpeech#Pleasantness MOS#3.521
1908.02262v1.pdf	Prosody Prediction#Helsinki Prosody Corpus#Accuracy#83.2$Prosody Prediction#Helsinki Prosody Corpus#Accuracy#82.1$Prosody Prediction#Helsinki Prosody Corpus#Accuracy#81.8$Prosody Prediction#Helsinki Prosody Corpus#Accuracy#80.8
2104.01797v2.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#89.6$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#48.0
2205.00748v3.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#89.6$3D Human Pose Estimation#3DPW#PA-MPJPE#61.7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#34.95$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.31$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#JTA#F1(t=0.4m)#58.15$3D Human Pose Estimation#JTA#F1(t=0.8m)#69.32$3D Human Pose Estimation#JTA#F1(t=1.2m)#74.19$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#48.1
2012.11806v3.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#87.5$3D Human Pose Estimation#3DPW#PA-MPJPE#64.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#40.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#30.4$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#45.7$3D Absolute Human Pose Estimation#Human3.6M#MRPE#88.1
2204.04913v2.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#85.8$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#49.8$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#44.1
2011.00250v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#85.3$3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#MPJPE#103$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#85.3
2007.08943v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#83.7$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#35.2
2104.03520v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#83.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#48.7
2004.03989v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#82.7$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#37.3
2203.07697v4.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#82.7$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#53.8$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#39.2
2010.05302v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#82.5
2008.00206v2.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#82.0$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#48.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#30.5$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#51.6$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#43.8
1907.11346v2.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#81.8$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#53.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.4$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJPE#84.28$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJAE#21.25$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#31.5$3D Absolute Human Pose Estimation#Human3.6M#MRPE#120.0
2008.11469v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#73.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.1$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#61.8$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#35.4
1712.03453v3.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#3DPCK#65$3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#MPJPE#132$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#69.9$3D Human Pose Estimation#MPI-INF-3DHP#AUC#37.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#122.2$3D Human Pose Estimation#MPI-INF-3DHP#PCK#75.2
1904.05947v1.pdf	3D Multi-Person Pose Estimation (root-relative)#MuPoTS-3D#MPJPE#120$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#MPJPE#292
2010.04829v2.pdf	Relation Extraction#SemEval-2010 Task 8#F1#91.9$Relation Extraction#TACRED#F1#74.8
2004.03786v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#91
1912.01858v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#90.36
2104.07650v6.pdf	Relation Extraction#SemEval-2010 Task 8#F1#90.3$Dialog Relation Extraction#DialogRE#F1 (v1)#66.0
1906.03158v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#89.5$Relation Extraction#TACRED#F1#71.5$Relation Extraction#TACRED#F1 (1% Few-Shot)#43.4$Relation Extraction#TACRED#F1 (10% Few-Shot)#64.8
1905.08284v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#89.25$Relation Extraction#TACRED#F1#69.4
1909.04164v2.pdf	Relation Extraction#SemEval-2010 Task 8#F1#89.1$Relation Extraction#TACRED#F1#71.5$Entity Linking#AIDA-CoNLL#Micro-F1 strong#73.7
1902.01030v2.pdf	Relation Extraction#SemEval-2010 Task 8#F1#89.0
1906.03088v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#87.1$Relation Extraction#SemEval-2010 Task 8#F1#87:1$Relation Extraction#TACRED#F1#67.4
1901.08163v1.pdf	Relation Extraction#SemEval-2010 Task 8#F1#85.2
1504.06580v2.pdf	Relation Extraction#SemEval-2010 Task 8#F1#84.1
2107.09332v2.pdf	Relation Extraction#Re-TACRED#F1#91.4$Relation Extraction#TACRED#F1#75.0
2102.01373v4.pdf	Relation Extraction#Re-TACRED#F1#91.1$Relation Extraction#TACRED#F1#74.6
1907.10529v3.pdf	Relation Extraction#Re-TACRED#F1#85.3$Relation Extraction#TACRED#F1#70.8$Question Answering#SQuAD1.1#EM#88.8$Question Answering#SQuAD1.1#F1#94.6$Question Answering#SQuAD1.1#Hardware Burden#586G$Question Answering#SQuAD2.0 dev#F1#86.8$Question Answering#SQuAD2.0#EM#85.7$Question Answering#SQuAD2.0#F1#88.7$Question Answering#NaturalQA#F1#82.5$Question Answering#TriviaQA#F1#83.6$Question Answering#NewsQA#F1#73.6$Open-Domain Question Answering#SearchQA#F1#84.8$Natural Language Inference#QNLI#Accuracy#94.3%$Natural Language Inference#RTE#Accuracy#79.0%$Natural Language Inference#MultiNLI#Matched#88.1$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.899$Semantic Textual Similarity#MRPC#Accuracy#90.9%$Paraphrase Identification#Quora Question Pairs#Accuracy#89.5$Paraphrase Identification#Quora Question Pairs#F1#71.9$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.8$Coreference Resolution#OntoNotes#F1#79.6$Linguistic Acceptability#CoLA#Accuracy#64.3%
1809.10185v1.pdf	Relation Extraction#Re-TACRED#F1#80.3$Relation Extraction#TACRED#F1#68.2$Relation Extraction#TACRED#F1#67.1$Relation Extraction#TACRED#F1#66.4$Relation Extraction#TACRED#F1#64.0
2109.06067v5.pdf	Relation Extraction#ACE 2004#RE Micro F1#69.7$Relation Extraction#ACE 2004#NER Micro F1#90.4$Relation Extraction#ACE 2004#RE+ Micro F1#66.5$Relation Extraction#ACE 2004#Cross Sentence#Yes$Relation Extraction#ACE 2005#RE Micro F1#73.0$Relation Extraction#ACE 2005#NER Micro F1#91.1$Relation Extraction#ACE 2005#RE+ Micro F1#71.1$Relation Extraction#ACE 2005#Sentence Encoder#ALBERT$Relation Extraction#ACE 2005#Cross Sentence#Yes$Joint Entity and Relation Extraction#SciERC#Entity F1#69.9$Joint Entity and Relation Extraction#SciERC#Relation F1#53.2$Joint Entity and Relation Extraction#SciERC#RE+ Micro F1#41.6$Joint Entity and Relation Extraction#SciERC#Cross Sentence#Yes$Named Entity Recognition#Ontonotes v5 (English)#F1#91.9$Named Entity Recognition#Ontonotes v5 (English)#Precision#92.0$Named Entity Recognition#Ontonotes v5 (English)#Recall#91.7$Named Entity Recognition#Few-NERD (SUP)#Precision#71.2$Named Entity Recognition#Few-NERD (SUP)#Recall#70.6$Named Entity Recognition#Few-NERD (SUP)#F1-Measure#70.9$Named Entity Recognition#CoNLL 2003 (English)#F1#94.0
2108.12202v8.pdf	Relation Extraction#ACE 2004#NER Micro F1#89.3$Relation Extraction#ACE 2004#RE+ Micro F1#62.5$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#ACE 2005#NER Micro F1#89.0$Relation Extraction#ACE 2005#RE+ Micro F1#66.8$Relation Extraction#ACE 2005#Sentence Encoder#ALBERT$Relation Extraction#ACE 2005#Cross Sentence#No$Relation Extraction#SciERC#RE+ Micro F1#38.4$Relation Extraction#SciERC#NER Micro F1#66.8$Relation Extraction#ADE Corpus#NER Macro F1#91.3$Relation Extraction#ADE Corpus#RE+ Macro F1#83.2$Relation Extraction#NYT#F1#92.4$Relation Extraction#NYT#NER Micro F1#95.8$Relation Extraction#WebNLG#F1#93.6$Relation Extraction#WebNLG#NER Micro F1#98.0$Joint Entity and Relation Extraction#SciERC#Entity F1#66.8$Joint Entity and Relation Extraction#SciERC#RE+ Micro F1#38.4$Joint Entity and Relation Extraction#SciERC#Cross Sentence#No
2010.12812v2.pdf	Relation Extraction#ACE 2004#RE Micro F1#66.1$Relation Extraction#ACE 2004#NER Micro F1#90.3$Relation Extraction#ACE 2004#RE+ Micro F1#62.2$Relation Extraction#ACE 2004#Cross Sentence#Yes$Relation Extraction#ACE 2005#RE Micro F1#69.4$Relation Extraction#ACE 2005#NER Micro F1#90.9$Relation Extraction#ACE 2005#RE+ Micro F1#67.0$Relation Extraction#ACE 2005#Sentence Encoder#ALBERT$Relation Extraction#ACE 2005#Cross Sentence#Yes$Joint Entity and Relation Extraction#ACE 2005#Relation F1#62.2$Joint Entity and Relation Extraction#SciERC#Entity F1#68.9$Joint Entity and Relation Extraction#SciERC#Relation F1#50.1$Joint Entity and Relation Extraction#SciERC#RE+ Micro F1#36.7$Joint Entity and Relation Extraction#SciERC#Cross Sentence#Yes$Named Entity Recognition#ACE 2004#F1#90.3$Named Entity Recognition#ACE 2004#Multi-Task Supervision#y$Named Entity Recognition#SciERC#F1#68.2$Named Entity Recognition#ACE 2005#F1#90.9
2010.03851v1.pdf	Relation Extraction#ACE 2004#RE Micro F1#63.3$Relation Extraction#ACE 2004#NER Micro F1#88.6$Relation Extraction#ACE 2004#RE+ Micro F1#59.6$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#ACE 2005#RE Micro F1#67.6$Relation Extraction#ACE 2005#NER Micro F1#89.5$Relation Extraction#ACE 2005#RE+ Micro F1#64.3$Relation Extraction#ACE 2005#Sentence Encoder#ALBERT$Relation Extraction#ACE 2005#Cross Sentence#No$Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#80.1$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#89.7$Relation Extraction#Adverse Drug Events (ADE) Corpus#RE Macro F1#80.1$Relation Extraction#CoNLL04#NER Macro F1#86.9$Relation Extraction#CoNLL04#RE+ Micro F1#73.6$Relation Extraction#CoNLL04#RE+ Macro F1#75.4$Relation Extraction#CoNLL04#NER Micro F1#90.1$Zero-shot Relation Triplet Extraction#FewRel#Avg. F1#6.37$Zero-shot Relation Triplet Extraction#Wiki-ZSL#Avg. F1#6.4
1905.05529v4.pdf	Relation Extraction#ACE 2004#NER Micro F1#83.6$Relation Extraction#ACE 2004#RE+ Micro F1#49.4$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#ACE 2005#NER Micro F1#84.8$Relation Extraction#ACE 2005#RE+ Micro F1#60.2$Relation Extraction#ACE 2005#Sentence Encoder#BERT base$Relation Extraction#ACE 2005#Cross Sentence#No$Relation Extraction#CoNLL04#RE+ Micro F1#68.9$Relation Extraction#CoNLL04#NER Micro F1#87.8
1601.00770v3.pdf	Relation Extraction#ACE 2004#NER Micro F1#81.8$Relation Extraction#ACE 2004#RE+ Micro F1#48.4$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#NYT11-HRL#F1#0.531$Relation Extraction#ACE 2005#NER Micro F1#83.4$Relation Extraction#ACE 2005#RE+ Micro F1#55.6$Relation Extraction#ACE 2005#Sentence Encoder#biLSTM$Relation Extraction#ACE 2005#Cross Sentence#No
1808.06876v3.pdf	Relation Extraction#ACE 2004#NER Micro F1#81.64$Relation Extraction#ACE 2004#RE+ Micro F1#47.45$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#75.52$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#86.73$Relation Extraction#CoNLL04#NER Macro F1#83.6$Relation Extraction#CoNLL04#RE+ Macro F1#61.95
1804.07847v3.pdf	Relation Extraction#ACE 2004#NER Micro F1#81.16$Relation Extraction#ACE 2004#RE+ Micro F1#47.14$Relation Extraction#ACE 2004#Cross Sentence#No$Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#74.58$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#86.40$Relation Extraction#CoNLL04#NER Macro F1#83.9$Relation Extraction#CoNLL04#RE+ Macro F1#62.04
1904.03296v1.pdf	Relation Extraction#ACE 2004#RE Micro F1#59.7$Relation Extraction#ACE 2004#NER Micro F1#87.4$Relation Extraction#ACE 2004#Cross Sentence#Yes$Relation Extraction#ACE 2005#RE Micro F1#63.2$Relation Extraction#ACE 2005#NER Micro F1#88.4$Relation Extraction#ACE 2005#Sentence Encoder#ELMo$Relation Extraction#ACE 2005#Cross Sentence#Yes$Relation Extraction#WLPC#F1#64.1$Joint Entity and Relation Extraction#SciERC#Entity F1#65.2$Joint Entity and Relation Extraction#SciERC#Relation F1#41.6$Joint Entity and Relation Extraction#SciERC#Cross Sentence#Yes$Named Entity Recognition#WLPC#F1#79.5
2205.10475v1.pdf	Relation Extraction#TACRED#F1#76.8$Relation Extraction#FewRel#F1#98.4$Relation Extraction#FewRel#F1 (5-way 5-shot#100$Relation Extraction#FewRel#F1 (10-way 1-shot)#97.8$Relation Extraction#FewRel#F1 (10-way 5-shot)#99.8$Relation Extraction#ADE Corpus#RE+ Micro F1#83.8$Relation Extraction#ADE Corpus#NER Micro F1#60.7$Relation Extraction#ADE Corpus#RE+ Micro F1#10.6$Relation Extraction#NYT#F1#93.9$Relation Extraction#NYT#NER Micro F1#95.9$Relation Extraction#CoNLL04#RE+ Micro F1#78.3$Relation Extraction#CoNLL04#NER Micro F1#90.7$Relation Extraction#CoNLL04#RE+ Micro F1#25.8$Relation Extraction#CoNLL04#NER Micro F1#48.3$Relation Extraction#CoNLL04#NER Micro F1#91.1$Open Information Extraction#OIE2016#F1#71.3$Open Information Extraction#NYT#F1#45$Open Information Extraction#Penn Treebank#F1#54.5
2105.08393v1.pdf	Relation Extraction#TACRED#F1#75.2
2205.09837v2.pdf	Relation Extraction#TACRED#F1#75.1$Relation Extraction#TACRED#F1 (Zero-Shot)#20.6$Relation Extraction#TACRED#F1 (1% Few-Shot)#52$Relation Extraction#TACRED#F1 (5% Few-Shot)#64.9$Relation Extraction#TACRED#F1 (10% Few-Shot)#70.7
2109.03659v1.pdf	Relation Extraction#TACRED#F1#73.9$Relation Extraction#TACRED#F1 (Zero-Shot)#62.8$Relation Extraction#TACRED#F1 (1% Few-Shot)#63.7$Relation Extraction#TACRED#F1 (5% Few-Shot)#69.0$Relation Extraction#TACRED#F1 (10% Few-Shot)#67.9$Relation Extraction#TACRED#F1#71.0
2104.08656v2.pdf	Relation Extraction#TACRED#F1#73.0$Named Entity Recognition#CoNLL++#F1#95.88$Named Entity Recognition#CoNLL++#F1#94.04$Named Entity Recognition#CoNLL 2003 (English)#F1#94.22
2010.01057v1.pdf	Relation Extraction#TACRED#F1#72.7$Relation Extraction#TACRED#F1 (1% Few-Shot)#17.0$Relation Extraction#TACRED#F1 (5% Few-Shot)#51.6$Relation Extraction#TACRED#F1 (10% Few-Shot)#60.6$Question Answering#SQuAD1.1#EM#90.202$Question Answering#SQuAD1.1#F1#95.379$Question Answering#SQuAD1.1#EM#90.2$Question Answering#SQuAD1.1#F1#95.4$Question Answering#TACRED#Relation F1#72.7$Question Answering#SQuAD2.0#EM#87.429$Question Answering#SQuAD2.0#F1#90.163$Question Answering#SQuAD1.1 dev#EM#89.8$Question Answering#SQuAD1.1 dev#F1#95$Named Entity Recognition#CoNLL 2003 (English)#F1#93.91
2002.01808v5.pdf	Relation Extraction#TACRED#F1#72.04$Relation Extraction#TACRED#F1 (1% Few-Shot)#13.8$Relation Extraction#TACRED#F1 (5% Few-Shot)#45.1$Relation Extraction#TACRED#F1 (10% Few-Shot)#56.0$Entity Typing#Open Entity#F1#77.6916$Entity Typing#Open Entity#Precision#79.6712$Entity Typing#Open Entity#Recall#75.8081$Entity Typing#Open Entity#F1#77.6127$Entity Typing#Open Entity#Precision#78.9956$Entity Typing#Open Entity#Recall#76.2774
1911.06136v3.pdf	Relation Extraction#TACRED#F1#71.7$Inductive knowledge graph completion#Wikidata5m-ind#Hits@10#0.73$Inductive knowledge graph completion#Wikidata5m-ind#MRR#0.402$Inductive knowledge graph completion#Wikidata5m-ind#Hits@1#0.222$Inductive knowledge graph completion#Wikidata5m-ind#Hits@3#0.514
2004.03636v1.pdf	Relation Extraction#TACRED#F1#71.5
2012.06780v1.pdf	Relation Extraction#TACRED#F1#70.5$Dialog Relation Extraction#DialogRE#F1 (v1)#64.9$Dialog Relation Extraction#DialogRE#F1c (v1)#60.1
2010.01923v2.pdf	Relation Extraction#TACRED#F1#69.5
1906.07510v8.pdf	Relation Extraction#TACRED#F1#68.2$Relation Extraction#TACRED#F1#65.1
1905.07129v3.pdf	Relation Extraction#TACRED#F1#67.97$Relation Extraction#FewRel#F1#88.32$Relation Extraction#FewRel#Precision#88.49$Relation Extraction#FewRel#Recall#88.44$Natural Language Inference#QNLI#Accuracy#91.3%$Natural Language Inference#RTE#Accuracy#68.8%$Natural Language Inference#MultiNLI#Matched#84.0$Natural Language Inference#MultiNLI#Mismatched#83.2$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.832$Semantic Textual Similarity#MRPC#Accuracy#88.2%$Paraphrase Identification#Quora Question Pairs#F1#71.2$Sentiment Analysis#SST-2 Binary classification#Accuracy#93.5$Entity Linking#FIGER#Accuracy#57.19$Entity Linking#FIGER#Macro F1#76.51$Entity Linking#FIGER#Micro F1#73.39$Linguistic Acceptability#CoLA#Accuracy#52.3%$Entity Typing#Open Entity#F1#75.56$Entity Typing#Open Entity#Precision#78.42$Entity Typing#Open Entity#Recall#72.9
1904.05255v1.pdf	Relation Extraction#TACRED#F1#67.8
2105.10158v1.pdf	Relation Extraction#NYT11-HRL#F1#51.25$Relation Extraction#NYT11-HRL#F1#0.5623$Relation Extraction#NYT11-HRL#F1#0.5547$Relation Extraction#NYT11-HRL#F1#0.538$Relation Extraction#NYT10-HRL#F1#73.95$Relation Extraction#NYT10-HRL#F1#73.4$Relation Extraction#NYT10-HRL#F1#72.45$Relation Extraction#NYT10-HRL#F1#71.93$Relation Extraction#NYT10-HRL#F1#70.11$Relation Extraction#NYT10-HRL#F1#64.4$Relation Extraction#NYT21#F1#59.62$Relation Extraction#NYT21#F1#58.88$Relation Extraction#NYT21#F1#57.33$Relation Extraction#NYT21#F1#54.78$Relation Extraction#SKE#F1#87.21$Relation Extraction#SKE#F1#86.45$Relation Extraction#SKE#F1#84.32
2010.13415v1.pdf	Relation Extraction#NYT11-HRL#F1#0.5567$Relation Extraction#NYT11-HRL#F1#0.5528$Relation Extraction#NYT10-HRL#F1#72.45$Relation Extraction#NYT10-HRL#F1#71.93$Relation Extraction#NYT#F1#91.9$Relation Extraction#WebNLG#F1#91.9
1909.03227v4.pdf	Relation Extraction#NYT11-HRL#F1#0.539$Relation Extraction#NYT11-HRL#F1#0.5125$Relation Extraction#NYT10-HRL#F1#70.11$Relation Extraction#NYT#F1#89.6$Relation Extraction#WebNLG#F1#91.8
1811.03925v1.pdf	Relation Extraction#NYT11-HRL#F1#0.538$Relation Extraction#NYT10-HRL#F1#64.4$Relation Extraction#NYT24#F1#77.6$Relation Extraction#NYT29#F1#64.3
1706.05075v1.pdf	Relation Extraction#NYT11-HRL#F1#0.479$Relation Extraction#NYT#F1#42.0$Relation Extraction#NYT-single#F1#49.5$Relation Extraction#WebNLG#F1#28.3
1610.08763v2.pdf	Relation Extraction#NYT11-HRL#F1#0.43
2203.15827v1.pdf	Relation Extraction#GAD#Micro F1#84.90$Relation Extraction#GAD#F1#84.90$Relation Extraction#ChemProt#F1#79.98$Relation Extraction#ChemProt#Micro F1#79.98$Relation Extraction#DDI#Micro F1#83.35$Relation Extraction#DDI#F1#83.35$Question Answering#PubMedQA#Accuracy#72.2$Question Answering#PubMedQA#Accuracy#70.2$Question Answering#SQuAD1.1#EM#87.45$Question Answering#SQuAD1.1#F1#92.7$Question Answering#BioASQ#Accuracy#94.8$Question Answering#BioASQ#Accuracy#91.4$Question Answering#MedQA-USMLE#Accuracy#44.6$Question Answering#MedQA-USMLE#Accuracy#40.0$Question Answering#TriviaQA#F1#78.2$Question Answering#MRQA#Average F1#81.0$Question Answering#BLURB#Accuracy#83.5$Question Answering#BLURB#Accuracy#80.81$Question Answering#NewsQA#F1#72.6$Semantic Similarity#BIOSSES#Pearson Correlation#0.9363$Semantic Similarity#BIOSSES#Pearson Correlation#0.9325$Medical Relation Extraction#DDI extraction 2013 corpus#F1#83.35$Named Entity Recognition#BC5CDR#F1#90.22$Named Entity Recognition#BC2GM#F1#85.18$Named Entity Recognition#BC5CDR-chemical#F1#94.04$Named Entity Recognition#BC5CDR-disease#F1#86.39$Named Entity Recognition#NCBI-disease#F1#88.76$Named Entity Recognition#JNLPBA#F1#80.06$Text Classification#BLURB#F1#84.88$Text Classification#BLURB#F1#84.35$Document Classification#HOC#F1#88.1$Document Classification#HOC#Micro F1#84.87$PICO#EBM PICO#Macro F1 word level#74.19$PICO#EBM PICO#Macro F1 word level#73.97
2104.10344v1.pdf	Relation Extraction#GAD#F1#84.3$Relation Extraction#ChemProt#F1#77.5$Relation Extraction#DDI#F1#81.9$Named Entity Recognition#BC2GM#F1#85.1$Named Entity Recognition#BC5CDR-chemical#F1#93.3$Named Entity Recognition#BC5CDR-disease#F1#86.1$Named Entity Recognition#NCBI-disease#F1#89.1$Named Entity Recognition#JNLPBA#F1#82.0
2007.15779v6.pdf	Relation Extraction#GAD#Micro F1#82.34$Relation Extraction#ChemProt#Micro F1#77.24$Relation Extraction#DDI#Micro F1#82.36$Question Answering#PubMedQA#Accuracy#55.84$Question Answering#BioASQ#Accuracy#87.56$Question Answering#BLURB#Accuracy#71.7$Participant Intervention Comparison Outcome Extraction#EBM-NLP#F1#73.38$Named Entity Recognition#BC2GM#F1#84.52$Named Entity Recognition#NCBI-disease#F1#87.82$Named Entity Recognition#JNLPBA#F1#79.1$Text Classification#BLURB#F1#82.32$Document Classification#HOC#Micro F1#82.32$PICO#EBM PICO#Macro F1 word level#73.38
2106.03598v1.pdf	Relation Extraction#ChemProt#F1#88.95$Natural Language Inference#MedNLI#Accuracy#86.57$Drug–drug Interaction Extraction#DDI extraction 2013 corpus#F1#0.8367$Drug–drug Interaction Extraction#DDI extraction 2013 corpus#Micro F1#83.67$Named Entity Recognition#Species-800#F1#76.55$Named Entity Recognition#BC5CDR-chemical#F1#94.76$Named Entity Recognition#BC5CDR-disease#F1#87.62$Named Entity Recognition#NCBI-disease#F1#89.39$Named Entity Recognition#JNLPBA#F1#77.55$Document Classification#HOC#F1#86.08
1903.10676v3.pdf	Relation Extraction#ChemProt#F1#83.64$Relation Extraction#ChemProt#F1#73.7$Relation Extraction#SciERC#F1#74.64$Relation Extraction#SciERC#F1#74.42$Relation Extraction#JNLPBA#F1#76.09$Participant Intervention Comparison Outcome Extraction#EBM-NLP#F1#71.18$Participant Intervention Comparison Outcome Extraction#EBM-NLP#F1#70.82$Dependency Parsing#GENIA - UAS#F1#92.46$Dependency Parsing#GENIA - UAS#F1#92.32$Dependency Parsing#GENIA - LAS#F1#91.41$Dependency Parsing#GENIA - LAS#F1#91.26$Named Entity Recognition#BC5CDR#F1#88.94$Named Entity Recognition#BC5CDR#F1#88.11$Named Entity Recognition#SciERC#F1#67.57$Named Entity Recognition#SciERC#F1#65.24$Named Entity Recognition#NCBI-disease#F1#86.88$Named Entity Recognition#NCBI-disease#F1#86.45$Named Entity Recognition#JNLPBA#F1#75.77$Sentence Classification#ACL-ARC#F1#70.98$Sentence Classification#SciCite#F1#84.9$Sentence Classification#PubMed 20k RCT#F1#86.81$Sentence Classification#ScienceCite#F1#84.99$Sentence Classification#ScienceCite#F1#84.43$Sentence Classification#Paper Field#F1#65.71$Sentence Classification#Paper Field#F1#64.02$Citation Intent Classification#SciCite#F1#84.99
2010.06060v2.pdf	Relation Extraction#ChemProt#F1#77.0$Named Entity Recognition#BC5CDR-chemical#F1#92.9$Named Entity Recognition#BC5CDR-disease#F1#88.5$Named Entity Recognition#NCBI-disease#F1#87.8
1901.08746v4.pdf	Relation Extraction#ChemProt#F1#76.46$Question Answering#MedQA-USMLE#Accuracy#36.7$Question Answering#MedQA-USMLE#Accuracy#34.1$Named Entity Recognition#NCBI-disease#F1#89.71$Named Entity Recognition#JNLPBA#F1#77.59$Representation Learning#SciDocs#Avg.#58.8
1906.05474v2.pdf	Relation Extraction#ChemProt#F1#74.4$Natural Language Inference#MedNLI#F1#84$Semantic Similarity#BIOSSES#Pearson Correlation#0.9159999999999999$Semantic Similarity#MedSTS#Pearson Correlation#0.848$Medical Relation Extraction#DDI extraction 2013 corpus#F1#79.9$Named Entity Recognition#BC5CDR-chemical#F1#93.5$Named Entity Recognition#BC5CDR-disease#F1#86.6$Medical Named Entity Recognition#ShARe/CLEF eHealth corpus#F1#0.792$Document Classification#HOC#F1#87.3
2104.09585v1.pdf	Relation Extraction#ChemProt#F1#72.94$Drug–drug Interaction Extraction#DDI extraction 2013 corpus#Micro F1#79.13$Named Entity Recognition#BC5CDR#F1#90.03$Named Entity Recognition#NCBI-disease#F1#87.54
2010.10392v3.pdf	Relation Extraction#ChemProt#Micro F1#73.44$Natural Language Inference#MedNLI#Accuracy#84.95$Semantic Similarity#ClinicalSTS#Pearson Correlation#85.62$Drug–drug Interaction Extraction#DDI extraction 2013 corpus#Micro F1#80.38$Clinical Concept Extraction#2010 i2b2/VA#Exact Span F1#89.24
2010.14576v3.pdf	Relation Extraction#WNUT 2020#Precision#80.1$Relation Extraction#WNUT 2020#Recall#66.21$Relation Extraction#WNUT 2020#F1#72.5$Named Entity Recognition#WNUT 2020#Precision#70.06$Named Entity Recognition#WNUT 2020#Recall#61.91$Named Entity Recognition#WNUT 2020#F1#65.73
2101.10213v3.pdf	Relation Extraction#ACE 2005#RE Micro F1#66.49$Relation Extraction#ACE 2005#NER Micro F1#87.61$Relation Extraction#ACE 2005#RE+ Micro F1#62.77$Relation Extraction#ACE 2005#Sentence Encoder#BERT base$Relation Extraction#ACE 2005#Cross Sentence#Yes$Relation Extraction#CoNLL04#RE+ Micro F1#72.35$Relation Extraction#CoNLL04#NER Micro F1#90.3
2010.07522v2.pdf	Relation Extraction#ACE 2005#RE Micro F1#66.1$Relation Extraction#ACE 2005#NER Micro F1#88.0$Relation Extraction#ACE 2005#RE+ Micro F1#62.4$Relation Extraction#ACE 2005#Sentence Encoder#BERT base$Relation Extraction#ACE 2005#Cross Sentence#No$Relation Extraction#CoNLL04#RE+ Micro F1#72.6$Relation Extraction#CoNLL04#NER Micro F1#90.2
1909.03546v2.pdf	Relation Extraction#ACE 2005#RE Micro F1#63.4$Relation Extraction#ACE 2005#NER Micro F1#88.6$Relation Extraction#ACE 2005#Sentence Encoder#BERT base$Relation Extraction#ACE 2005#Cross Sentence#Yes$Joint Entity and Relation Extraction#SciERC#Entity F1#67.50$Joint Entity and Relation Extraction#SciERC#Relation F1#48.40$Joint Entity and Relation Extraction#SciERC#Cross Sentence#Yes
1811.06031v2.pdf	Relation Extraction#ACE 2005#RE Micro F1#62.7$Relation Extraction#ACE 2005#NER Micro F1#87.5$Relation Extraction#ACE 2005#Sentence Encoder#ELMo$Relation Extraction#ACE 2005#Cross Sentence#No
2103.03509v1.pdf	Relation Extraction#ACE 2005#Relation classification F1#80.8$Relation Extraction#ACE 2005#Cross Sentence#No
1511.05926v1.pdf	Relation Extraction#ACE 2005#Relation classification F1#67.7$Relation Extraction#ACE 2005#Cross Sentence#No
1902.07023v2.pdf	Relation Extraction#ACE 2005#Relation classification F1#64.2$Relation Extraction#ACE 2005#Cross Sentence#No
1505.02419v3.pdf	Relation Extraction#ACE 2005#Relation classification F1#58.2$Relation Extraction#ACE 2005#Cross Sentence#No
2106.15838v1.pdf	Relation Extraction#ACE 2005#Relation F1#68.2$Relation Extraction#ACE 2005#Sentence Encoder#ALBERT$Relation Extraction#ACE 2005#Cross Sentence#No
1810.05102v2.pdf	Relation Extraction#MUC6#Average F1#.940
2203.10900v1.pdf	Relation Extraction#DocRED#F1#67.28$Relation Extraction#DocRED#Ign F1#65.24
2102.10249v1.pdf	Relation Extraction#DocRED#F1#65.92$Relation Extraction#DocRED#Ign F1#63.78$Relation Extraction#DocRED#F1#61.42$Relation Extraction#DocRED#Ign F1#59.47$Relation Extraction#DocRED#F1#59.94$Relation Extraction#DocRED#Ign F1#57.71$Relation Extraction#DocRED#F1#58.16$Relation Extraction#DocRED#Ign F1#55.84$Relation Extraction#GDA#F1#83.9$Relation Extraction#CDR#F1#68.7
2109.12093v2.pdf	Relation Extraction#DocRED#F1#65.11$Relation Extraction#DocRED#Ign F1#63.44$Relation Extraction#DocRED#F1#62.77$Relation Extraction#DocRED#Ign F1#60.96$Relation Extraction#GDA#F1#87.1$Relation Extraction#CDR#F1#79
2106.08657v2.pdf	Relation Extraction#DocRED#F1#64.79$Relation Extraction#DocRED#Ign F1#62.85$Relation Extraction#DocRED#F1#62.47$Relation Extraction#DocRED#Ign F1#60.42
2106.03618v2.pdf	Relation Extraction#DocRED#F1#64.55$Relation Extraction#DocRED#Ign F1#62.4$Relation Extraction#GDA#F1#85.3$Relation Extraction#CDR#F1#76.3
2201.04826v1.pdf	Relation Extraction#DocRED#F1#63.89$Relation Extraction#DocRED#Ign F1#61.96$Relation Extraction#DocRED#F1#62.06$Relation Extraction#DocRED#Ign F1#60.24$Relation Extraction#GDA#F1#84.7$Relation Extraction#CDR#F1#73.8
2010.11304v3.pdf	Relation Extraction#DocRED#F1#63.40$Relation Extraction#DocRED#Ign F1#61.39$Relation Extraction#DocRED#F1#61.30$Relation Extraction#DocRED#Ign F1#59.31$Relation Extraction#GDA#F1#83.9$Relation Extraction#CDR#F1#69.4
2204.09851v2.pdf	Relation Extraction#DocRED#F1#63.15$Relation Extraction#DocRED#Ign F1#61.03$Relation Extraction#GDA#F1#86.4$Relation Extraction#CDR#F1#76.6
2009.13752v1.pdf	Relation Extraction#DocRED#F1#62.76$Relation Extraction#DocRED#Ign F1#60.31$Relation Extraction#DocRED#F1#61.24$Relation Extraction#DocRED#Ign F1#59.00$Relation Extraction#DocRED#F1#55.08$Relation Extraction#DocRED#Ign F1#52.66
2203.13953v1.pdf	Relation Extraction#DocRED#F1#62.55$Relation Extraction#DocRED#Ign F1#60.46$Relation Extraction#GDA#F1#86.44$Relation Extraction#CDR#F1#77.06
2008.12283v1.pdf	Relation Extraction#DocRED#F1#62.50$Relation Extraction#DocRED#Ign F1#60.30$Relation Extraction#DocRED#F1#58.72$Relation Extraction#DocRED#Ign F1#55.22
2204.12679v1.pdf	Relation Extraction#DocRED#F1#62.29$Relation Extraction#DocRED#Ign F1#59.87$Dialog Relation Extraction#DialogRE#F1 (v1)#61.8$Dialog Relation Extraction#DialogRE#F1c (v1)#58.4
2106.01709v1.pdf	Relation Extraction#DocRED#F1#62.05$Relation Extraction#DocRED#Ign F1#60.18$Relation Extraction#DocRED#F1#55.96$Relation Extraction#DocRED#Ign F1#54.04
2111.05407v1.pdf	Relation Extraction#DocRED#F1#61.45$Relation Extraction#DocRED#Ign F1#59.48$Relation Extraction#DocRED#F1#60.61$Relation Extraction#DocRED#Ign F1#58.62
2207.11433v1.pdf	Relation Extraction#DocRED#F1#61.39$Relation Extraction#DocRED#Ign F1#59.35
2106.01562v1.pdf	Relation Extraction#DocRED#F1#61.37$Relation Extraction#DocRED#Ign F1#59.15$Relation Extraction#DocRED#F1#56.33$Relation Extraction#DocRED#Ign F1#54.35
2205.10511v1.pdf	Relation Extraction#DocRED#F1#61.36$Relation Extraction#DocRED#Ign F1#59.08
2202.10744v1.pdf	Relation Extraction#DocRED#F1#60.82$Relation Extraction#DocRED#Ign F1#60.78
2102.05980v2.pdf	Relation Extraction#DocRED#F1#60.40$Relation Extraction#DocRED#Ign F1#58.44$Joint Entity and Relation Extraction#DocRED#Relation F1#40.38
2004.06870v2.pdf	Relation Extraction#DocRED#F1#60.25$Relation Extraction#DocRED#Ign F1#57.90$Relation Extraction#DocRED#F1#58.83$Relation Extraction#DocRED#Ign F1#56.40$Relation Extraction#DocRED#F1#56.96$Relation Extraction#DocRED#Ign F1#54.54
2012.02507v2.pdf	Relation Extraction#DocRED#F1#59.82$Relation Extraction#DocRED#Ign F1#57.89$Relation Extraction#DocRED#F1#55.75$Relation Extraction#DocRED#Ign F1#53.43
2012.11384v1.pdf	Relation Extraction#DocRED#F1#59.45$Relation Extraction#DocRED#Ign F1#57.12$Relation Extraction#DocRED#F1#55.23$Relation Extraction#DocRED#Ign F1#53.27
2205.12491v2.pdf	Relation Extraction#DocRED#F1#59.4$Relation Extraction#DocRED#Ign F1#57.1
2205.14393v1.pdf	Relation Extraction#DocRED#F1#59.29$Relation Extraction#DocRED#Ign F1#57.02
2005.06312v3.pdf	Relation Extraction#DocRED#F1#59.05$Relation Extraction#DocRED#Ign F1#56.97$Relation Extraction#DocRED#F1#54.18$Relation Extraction#DocRED#Ign F1#52.15$Relation Extraction#GDA#F1#82.2$Relation Extraction#CDR#F1#64.8
2009.10359v1.pdf	Relation Extraction#DocRED#F1#59.0$Relation Extraction#DocRED#Ign F1#56.8
2011.11851v1.pdf	Relation Extraction#DocRED#F1#57.74
2106.01793v1.pdf	Relation Extraction#DocRED#F1#56.23
2003.12754v1.pdf	Relation Extraction#DocRED#F1#55.60$Relation Extraction#DocRED#Ign F1#53.70$Relation Extraction#DocRED#F1#53.30$Relation Extraction#DocRED#Ign F1#51.15
1909.11898v1.pdf	Relation Extraction#DocRED#F1#53.92$Relation Extraction#DocRED#Ign F1#54.42$Relation Extraction#DocRED#F1#53.22$Relation Extraction#DocRED#Ign F1#56.17
1906.06127v3.pdf	Relation Extraction#DocRED#F1#51.06$Relation Extraction#DocRED#Ign F1#44.73$Relation Extraction#DocRED#F1#50.64$Relation Extraction#DocRED#Ign F1#43.93$Relation Extraction#DocRED#F1#50.12$Relation Extraction#DocRED#Ign F1#43.60$Relation Extraction#DocRED#F1#42.33$Relation Extraction#DocRED#Ign F1#36.44
2106.00459v2.pdf	Relation Extraction#NYT Corpus#P@10%#92.3$Relation Extraction#NYT Corpus#P@30%#86.7$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@10%#92.3$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@30%#86.7
2009.08694v2.pdf	Relation Extraction#NYT Corpus#P@10%#87.5$Relation Extraction#NYT Corpus#P@30%#74.1$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@10%#87.5$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@30%#74.1
1903.10126v3.pdf	Relation Extraction#NYT Corpus#P@10%#84.9$Relation Extraction#NYT Corpus#P@30%#72.8
2104.08225v1.pdf	Relation Extraction#NYT Corpus#P@10%#75.9$Relation Extraction#NYT Corpus#P@30%#63.3
1812.04361v2.pdf	Relation Extraction#NYT Corpus#P@10%#73.6$Relation Extraction#NYT Corpus#P@30%#59.5
2008.13339v3.pdf	Relation Extraction#DuIE#F1#76.9$Relation Extraction#NYT#F1#88.9
2002.06424v1.pdf	Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#83.74$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#89.48$Relation Extraction#CoNLL04#NER Macro F1#87$Relation Extraction#CoNLL04#RE+ Micro F1#71.08$Relation Extraction#CoNLL04#RE+ Macro F1#72.63$Relation Extraction#CoNLL04#NER Micro F1#89.78
2109.00840v2.pdf	Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#79.97$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#88.3
1909.07755v4.pdf	Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#79.24$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#89.25$Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#78.84$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#89.28$Relation Extraction#CoNLL04#NER Macro F1#86.25$Relation Extraction#CoNLL04#RE+ Micro F1#71.47$Relation Extraction#CoNLL04#RE+ Macro F1#72.87$Relation Extraction#CoNLL04#NER Micro F1#88.94$Joint Entity and Relation Extraction#SciERC#Entity F1#70.3$Joint Entity and Relation Extraction#SciERC#Relation F1#50.84$Joint Entity and Relation Extraction#SciERC#Cross Sentence#No$Joint Entity and Relation Extraction#SciERC#Entity F1#70.33$Named Entity Recognition#SciERC#F1#70.33
1905.07458v4.pdf	Relation Extraction#Adverse Drug Events (ADE) Corpus#RE+ Macro F1#77.19$Relation Extraction#Adverse Drug Events (ADE) Corpus#NER Macro F1#87.02$Relation Extraction#CoNLL04#NER Macro F1#84.15$Relation Extraction#CoNLL04#RE+ Macro F1#62.29
2112.13259v1.pdf	Relation Extraction#2010 i2b2/VA#Macro F1#69.1$Relation Extraction#2012 i2b2 Temporal Relations#Macro F1#73.6$Relation Extraction#2018 n2c2 posology#Macro F1#96.7$Relation Extraction#PGR#Macro F1#87.9
1806.01733v2.pdf	Relation Extraction#SemEval 2018 Task 10#F1-Score#0.74
1804.11251v1.pdf	Relation Extraction#SemEval 2018 Task 10#F1-Score#0.73
1909.05363v1.pdf	Relation Extraction#SemEval 2018 Task 10#F1-Score#0.69
2106.01559v1.pdf	Relation Extraction#NYT#F1#92.5$Relation Extraction#NYT#F1 (strict)#90.2
2011.01675v2.pdf	Relation Extraction#NYT#F1#92.5$Relation Extraction#WebNLG#F1#93.4$Joint Entity and Relation Extraction#NYT#F1#92.5$Joint Entity and Relation Extraction#WebNLG#F1#93.4
2010.14255v2.pdf	Relation Extraction#NYT#F1#90$Denoising#iris#Average#84.61
2009.06207v8.pdf	Relation Extraction#NYT#F1#89.1$Relation Extraction#WebNLG#F1#83.4
2005.00162v2.pdf	Relation Extraction#NYT#F1#87.8$Relation Extraction#WebNLG#F1#90.1
1909.04273v3.pdf	Relation Extraction#NYT#F1#78$Relation Extraction#NYT-single#F1#59$Relation Extraction#WebNLG#F1#83.1
1911.10438v2.pdf	Relation Extraction#NYT#F1#72.2$Relation Extraction#WebNLG#F1#60.5
1911.09886v1.pdf	Relation Extraction#NYT24#F1#84.4$Relation Extraction#NYT29#F1#71.6$Relation Extraction#NYT29#F1#67.3
2107.02286v1.pdf	Relation Extraction#DWIE#F1-Hard#52.1$Named Entity Recognition#DWIE#F1-Hard#75.0$Coreference Resolution#DWIE#Avg. F1#91.5
2009.12626v2.pdf	Relation Extraction#DWIE#F1-Hard#50.4$Named Entity Recognition#DWIE#F1-Hard#74.8$Coreference Resolution#DWIE#Avg. F1#91.6
2204.04263v2.pdf	Relation Extraction#BioRED#F1#58.9$Binary Relation Extraction#BioRED#F1#72.9$NER#BioRED#F1#89.3$NER#BioRED#F1#88.7$NER#BioRED#F1#87.1
2101.04158v1.pdf	Relation Extraction#BioRED#F1#56.5$Binary Relation Extraction#BioRED#F1#72.1
2201.01647v4.pdf	Relation Extraction#Dataset: Relationship extraction for knowledge graph creation from biomedical literature (Gene-Disease relationships) n#F1#89$Relation Extraction#Dataset: Relationship extraction for knowledge graph creation from biomedical literature (Gene-Disease relationships)#F1#91$Relation Extraction#Dataset: Relationship extraction for knowledge graph creation from biomedical literature (Gene-Disease relationships)#F1#88
2204.01098v2.pdf	Relation Extraction#GDA#F1#84.9$Relation Extraction#CDR#F1#67.2$Joint Entity and Relation Extraction#CDR#Relation F1#40.2$Joint Entity and Relation Extraction#GDA#Relation F1#55.2$Joint Entity and Relation Extraction#DocRED#Relation F1#38.2
1812.11275v1.pdf	Relation Extraction#CoNLL04#NER Macro F1#86.2$Relation Extraction#CoNLL04#RE+ Macro F1#64.4
2101.05779v3.pdf	Relation Extraction#CoNLL04#RE+ Micro F1#72.6$Relation Classification#TACRED#F1#61.9$Relation Classification#TACRED#F1#71.9
1903.11850v1.pdf	Relation Classification#Discovery Dataset#1:1 Accuracy#20.6
2109.11171v1.pdf	Relation Classification#TACRED#F1#49.2$Relation Classification#TACRED#F1#76.4$Relation Classification#FewRel#F1#48.8$Relation Classification#FewRel#F1#92.9$Open Information Extraction#OIE2016#F1#72.6$Open Information Extraction#OIE2016#AUC#58.6$Open Information Extraction#NYT#F1#85.5$Open Information Extraction#NYT#AUC#72.5$Open Information Extraction#Web#F1#91.2$Open Information Extraction#Web#AUC#82.4$Open Information Extraction#Penn Treebank#F1#88.5$Open Information Extraction#Penn Treebank#AUC#81.5
1601.03651v2.pdf	Relation Classification#SemEval 2010 Task 8#F1#86.1
1506.07650v1.pdf	Relation Classification#SemEval 2010 Task 8#F1#85.6
1508.03720v1.pdf	Relation Classification#SemEval 2010 Task 8#F1#83.7
1507.04646v1.pdf	Relation Classification#SemEval 2010 Task 8#F1#83.6
2205.02048v2.pdf	Few-Shot Relation Classification#DocRED#F1 (1-Doc)#7.05$Few-Shot Relation Classification#DocRED#F1 (3-Doc)#8.42$Few-Shot Relation Classification#SciERC#F1 (1-Doc)#2.85$Few-Shot Relation Classification#SciERC#F1 (3-Doc)#3.72$Few-Shot Relation Classification#FREDo#F1 (1-Doc)#7.05$Few-Shot Relation Classification#FREDo#F1 (3-Doc)#8.42$Few-Shot Relation Classification#FREDo (cross-domain)#F1 (1-Doc)#2.85$Few-Shot Relation Classification#FREDo (cross-domain)#F1 (3-Doc)#3.72
2210.09163v1.pdf	Joint Entity and Relation Extraction#KPI-EDGAR#Relation F1#43.76
2203.05325v2.pdf	Joint Entity and Relation Extraction#SemEval 2022 Task 12: Symlink - Linking Mathematical Symbols to their Descriptions#Relation F1#32.28$Joint Entity and Relation Extraction#SemEval 2022 Task 12: Symlink - Linking Mathematical Symbols to their Descriptions#Entity F1 (partial)#41.21
1808.09602v1.pdf	Joint Entity and Relation Extraction#SciERC#Entity F1#64.20$Joint Entity and Relation Extraction#SciERC#Relation F1#39.30$Joint Entity and Relation Extraction#SciERC#Cross Sentence#No$Named Entity Recognition#SciERC#F1#64.20
2205.01909v1.pdf	Joint Entity and Relation Extraction#DocRED#Relation F1#40.62
2012.02553v1.pdf	Dialog Relation Extraction#DDRel#Session-level 4-class Acc#47.1$Dialog Relation Extraction#DDRel#Session-level 6-class Acc#41.87$Dialog Relation Extraction#DDRel#Session-level 13-class Acc#39.4$Dialog Relation Extraction#DDRel#Pair-level 4-class Acc#58.13$Dialog Relation Extraction#DDRel#Pair-level 6-class Acc#42.33$Dialog Relation Extraction#DDRel#Pair-level 13-class Acc#39.73
2208.12494v4.pdf	Dialog Relation Extraction#DialogRE#F1 (v1)#75.1$Dialog Relation Extraction#DialogRE#F1c (v1)#66.7$Dialog Relation Extraction#DialogRE#F1c (v2)#67.8$Dialog Relation Extraction#DialogRE#F1 (v2)#75.5$Dialog Relation Extraction#DialogRE#F1 (v1)#69.2$Dialog Relation Extraction#DialogRE#F1c (v1)#62.4$Dialog Relation Extraction#DialogRE#F1c (v2)#61.7$Dialog Relation Extraction#DialogRE#F1 (v2)#69.0$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#40.0$Emotion Recognition in Conversation#MELD#Weighted-F1#65.6
2109.04008v1.pdf	Dialog Relation Extraction#DialogRE#F1c (v2)#65.9$Dialog Relation Extraction#DialogRE#F1 (v2)#73.1$Dialog Relation Extraction#DialogRE#F1c (v2)#60.2$Dialog Relation Extraction#DialogRE#F1 (v2)#65.5$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#39.24$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#36.01$Emotion Recognition in Conversation#MELD#Weighted-F1#65.36$Emotion Recognition in Conversation#MELD#Weighted-F1#62.47$Emotion Recognition in Conversation#DailyDialog#Micro-F1#61.91$Emotion Recognition in Conversation#DailyDialog#Micro-F1#58.34
2106.01006v3.pdf	Dialog Relation Extraction#DialogRE#F1c (v2)#66.5$Dialog Relation Extraction#DialogRE#F1 (v2)#69.1
2109.05126v2.pdf	Dialog Relation Extraction#DialogRE#F1 (v2)#67.2$Dialog Relation Extraction#DialogRE#F1 (v2)#65.2
2105.10188v2.pdf	Dialog Relation Extraction#DialogRE#F1 (v1)#67.3$Dialog Relation Extraction#DialogRE#F1c (v1)#61.4$Dialog Relation Extraction#DialogRE#F1c (v2)#61.1$Dialog Relation Extraction#DialogRE#F1 (v2)#67.1
2012.13873v2.pdf	Dialog Relation Extraction#DialogRE#F1 (v1)#66.3$Dialog Relation Extraction#DialogRE#F1c (v2)#63.3$Dialog Relation Extraction#DialogRE#F1 (v2)#66.7$Dialog Relation Extraction#DialogRE#F1 (Chinese)#65.2
2004.08056v1.pdf	Dialog Relation Extraction#DialogRE#F1 (v1)#61.2$Dialog Relation Extraction#DialogRE#F1c (v1)#55.4$Dialog Relation Extraction#DialogRE#F1 (v1)#48.6$Dialog Relation Extraction#DialogRE#F1c (v1)#45
2009.05092v3.pdf	Dialog Relation Extraction#DialogRE#F1 (v1)#56.1$Dialog Relation Extraction#DialogRE#F1c (v1)#50.7
2105.11225v4.pdf	Relationship Extraction (Distant Supervised)#New York Times Corpus#P@10%#84.5$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@30%#71.5$Relationship Extraction (Distant Supervised)#New York Times Corpus#AUC#0.52
1804.06987v1.pdf	Relationship Extraction (Distant Supervised)#New York Times Corpus#P@10%#70.9$Relationship Extraction (Distant Supervised)#New York Times Corpus#P@30%#52.4
2102.01156v1.pdf	Relationship Extraction (Distant Supervised)#New York Times Corpus#AUC#0.424
1808.06738v2.pdf	Relationship Extraction (Distant Supervised)#New York Times Corpus#AUC#0.390$Relationship Extraction (Distant Supervised)#New York Times Corpus#Average Precision#0.390
2012.04334v2.pdf	Relationship Extraction (Distant Supervised)#NYT#PR AUC#0.595$Relationship Extraction (Distant Supervised)#NYT#P@100#0.939$Relationship Extraction (Distant Supervised)#NYT#P@200#0.889$Relationship Extraction (Distant Supervised)#NYT#P@300#0.873
2109.04901v1.pdf	Binary Relation Extraction#SciREX#Avg. F1#14.47$4-ary Relation Extraction#SciREX#Avg. F1#3.55$Role-filler Entity Extraction#MUC-4#Avg. F1#57.76
2111.00611v1.pdf	DrugProt#DrugProt#F1 (micro)#55.67
2203.09101v1.pdf	Zero-shot Relation Triplet Extraction#FewRel#Avg. F1#24.61$Zero-shot Relation Triplet Extraction#Wiki-ZSL#Avg. F1#31.19
2102.04680v1.pdf	Music Auto-Tagging#TimeTravel#0..5sec#5
2103.09410v2.pdf	Music Auto-Tagging#MagnaTagATune#ROC AUC#88.5$Music Auto-Tagging#MagnaTagATune#PR-AUC#35.4$Music Auto-Tagging#Million Song Dataset#PR-AUC#25.0$Music Auto-Tagging#Million Song Dataset#ROC-AUC#85.7
1904.07846v1.pdf	Video Alignment#UPenn Action#Kendall's Tau#0.7672$Video Alignment#UPenn Action#Kendall's Tau#0.7286
1704.06888v3.pdf	Video Alignment#UPenn Action#Kendall's Tau#0.7353
1805.10465v1.pdf	Hypernym Discovery#General#MAP#5.77$Hypernym Discovery#General#MRR#10.56$Hypernym Discovery#General#P@5#5.96$Hypernym Discovery#Music domain#MAP#4.71$Hypernym Discovery#Music domain#MRR#9.15$Hypernym Discovery#Music domain#P@5#4.91$Hypernym Discovery#Medical domain#MAP#11.69$Hypernym Discovery#Medical domain#MRR#25.95$Hypernym Discovery#Medical domain#P@5#11.69
1612.04460v2.pdf	Hypernym Discovery#General#MAP#1.36$Hypernym Discovery#General#MRR#3.18$Hypernym Discovery#General#P@5#1.30$Hypernym Discovery#Music domain#MAP#1.95$Hypernym Discovery#Music domain#MRR#5.01$Hypernym Discovery#Music domain#P@5#2.15$Hypernym Discovery#Medical domain#MAP#0.91$Hypernym Discovery#Medical domain#MRR#2.10$Hypernym Discovery#Medical domain#P@5#1.08
1912.01823v3.pdf	Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#96.36$Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#96.2$Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#96.14$Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#95.92$Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#95.89$Stochastic Optimization#CIFAR-10 WRN-28-10 - 200 Epochs#Accuracy#94.6$Stochastic Optimization#Penn Treebank (Character Level) 3x1000 LSTM - 500 Epochs#Bit per Character (BPC)#1.175$Stochastic Optimization#Penn Treebank (Character Level) 3x1000 LSTM - 500 Epochs#Bit per Character (BPC)#1.23$Stochastic Optimization#Penn Treebank (Character Level) 3x1000 LSTM - 500 Epochs#Bit per Character (BPC)#1.274$Stochastic Optimization#Penn Treebank (Character Level) 3x1000 LSTM - 500 Epochs#Bit per Character (BPC)#2.863$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#81.24$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#81.12$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#81.04$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#80.95$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#79.87$Stochastic Optimization#CIFAR-100 WRN-28-10 - 200 Epochs#Accuracy#77.24$Stochastic Optimization#ImageNet ResNet-50 - 90 Epochs#Top 1 Accuracy#76.51$Stochastic Optimization#ImageNet ResNet-50 - 90 Epochs#Top 1 Accuracy#75.99$Stochastic Optimization#ImageNet ResNet-50 - 90 Epochs#Top 1 Accuracy#72.9$Stochastic Optimization#ImageNet ResNet-50 - 90 Epochs#Top 1 Accuracy#72.01
2206.13424v3.pdf	Stochastic Optimization#CIFAR-10 ResNet-18 - 200 Epochs#Accuracy#95.55$Image Classification#SVHN#Percentage error#2.65$Image Classification#CIFAR-10#Percentage correct#95.55
1907.08610v2.pdf	Stochastic Optimization#CIFAR-10 ResNet-18 - 200 Epochs#Accuracy#95.27$Stochastic Optimization#CIFAR-10 ResNet-18 - 200 Epochs#Accuracy#95.23$Stochastic Optimization#CIFAR-10 ResNet-18 - 200 Epochs#Accuracy#94.84$Stochastic Optimization#ImageNet ResNet-50 - 50 Epochs#Top 1 Accuracy#75.13%$Stochastic Optimization#ImageNet ResNet-50 - 50 Epochs#Top 5 Accuracy#92.15%$Stochastic Optimization#ImageNet ResNet-50 - 60 Epochs#Top 1 Accuracy#75.49%$Stochastic Optimization#ImageNet ResNet-50 - 60 Epochs#Top 5 Accuracy#92.53$Stochastic Optimization#ImageNet ResNet-50 - 60 Epochs#Top 1 Accuracy#75.15%$Stochastic Optimization#ImageNet ResNet-50 - 60 Epochs#Top 5 Accuracy#92.56
2011.08042v1.pdf	Stochastic Optimization#CoLA#Accuracy (mean)#87.66$Stochastic Optimization#CoLA#Accuracy (max)#86.34$Stochastic Optimization#CIFAR-100#Accuracy (mean)#58.01$Stochastic Optimization#CIFAR-100#Accuracy (max)#58.48$Stochastic Optimization#CIFAR-100#Accuracy (mean)#53.06$Stochastic Optimization#CIFAR-100#Accuracy (max)#54.5$Stochastic Optimization#CIFAR-10#Accuracy (mean)#85.89$Stochastic Optimization#CIFAR-10#Accuracy (max)#86.85$Stochastic Optimization#CIFAR-10#Accuracy (mean)#85.75$Stochastic Optimization#CIFAR-10#Accuracy (max)#86.14$Stochastic Optimization#AG News#Accuracy (mean)#93.86$Stochastic Optimization#AG News#Accuracy (max)#93.99
1705.07795v3.pdf	Stochastic Optimization#MNIST#NLL#0.0541
2203.12257v3.pdf	Claim Extraction with Stance Classification (CESC)#IAM Dataset#Macro F1#60.25$Claim-Evidence Pair Extraction (CEPE)#IAM Dataset#F1#35.92
2210.12903v2.pdf	Person Search#PRW#mAP#58.3$Person Search#PRW#Top-1#92.4$Person Search#PRW#mAP#57.6$Person Search#PRW#Top-1#89.5$Person Search#CUHK-SYSU#MAP#96.4$Person Search#CUHK-SYSU#Top-1#97.0$Person Search#CUHK-SYSU#MAP#96.1$Person Search#CUHK-SYSU#Top-1#96.5
2109.00211v1.pdf	Person Search#PRW#mAP#51.6$Person Search#PRW#Top-1#84.4$Person Search#CUHK-SYSU#MAP#95.4$Person Search#CUHK-SYSU#Top-1#96.0
2112.02500v3.pdf	Person Search#PRW#mAP#47.8$Person Search#PRW#Top-1#87.8$Person Search#PRW#mAP#46.7$Person Search#PRW#Top-1#84.9$Person Search#CUHK-SYSU#MAP#95.8$Person Search#CUHK-SYSU#Top-1#96.2$Person Search#CUHK-SYSU#MAP#95.5$Person Search#CUHK-SYSU#Top-1#96.1
2103.10148v1.pdf	Person Search#PRW#mAP#47.6$Person Search#PRW#Top-1#87.6$Person Search#PRW#mAP#46.7$Person Search#PRW#Top-1#83.4$Person Search#PRW#mAP#46.6$Person Search#PRW#Top-1#84.9$Person Search#PRW#mAP#45.8$Person Search#PRW#Top-1#81.7$Person Search#CUHK-SYSU#MAP#94.8$Person Search#CUHK-SYSU#Top-1#95.7$Person Search#CUHK-SYSU#MAP#94.3$Person Search#CUHK-SYSU#Top-1#95.0$Person Search#CUHK-SYSU#MAP#93.8$Person Search#CUHK-SYSU#Top-1#94.6$Person Search#CUHK-SYSU#MAP#93.4$Person Search#CUHK-SYSU#Top-1#94.1
2103.11617v2.pdf	Person Search#PRW#mAP#46.1$Person Search#PRW#Top-1#82.1$Person Search#PRW#mAP#45.9$Person Search#PRW#Top-1#81.9$Person Search#CUHK-SYSU#MAP#94$Person Search#CUHK-SYSU#Top-1#94.5$Person Search#CUHK-SYSU#MAP#93.1$Person Search#CUHK-SYSU#Top-1#93.4
2010.11267v6.pdf	Keyword Spotting#Google Speech Commands V2 12#Accuracy#95.3$Keyword Spotting#Google Speech Commands V2 12#Latency (STM32F746ZG)#0.610128$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#95.3
2101.04792v4.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#98.56$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.37$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#97.0
2106.04140v3.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#98.0$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.7
2008.09606v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.8
2104.00769v3.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.49 ±0.15$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.56 ±0.07$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#97.69 ±0.09$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.27 ±0.08$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.43±0.08$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#97.74 ±0.03$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.26±0.18$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.08±0.10$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#96.95±0.14
2004.08531v2.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.48$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#97.63$Time Series#Speech Commands#% Test Accuracy#97.40
2201.05863v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.3$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98.2
2005.06720v2.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.2$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#98
2009.00165v2.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#97.06$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 6#97.22
1808.08929v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 20#94.5$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#95.6$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#96.9$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 2#99.2$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 20#94.1$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 35#94.3$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 2#99.4$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#93.9
1711.07128v3.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#94.4$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#94.0$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#93.5$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#92.9$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#92.0$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#91.6$Keyword Spotting#Google Speech Commands#Google Speech Commands V1 12#84.6
2002.01322v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#97.7$Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#97.4
1904.03814v2.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#96.6
2104.06666v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 12#95.55
1907.04536v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 20#93.72
2210.14648v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#98.5$Speaker Identification#VoxCeleb1#Top-1 (%)#95.3$Speaker Identification#VoxCeleb1#Accuracy#95.3$Speaker Identification#VoxCeleb1#Top-1 (%)#94.8$Speaker Identification#VoxCeleb1#Accuracy#94.8$Audio Classification#ESC-50#Top-1 Accuracy#95.0$Audio Classification#ESC-50#Accuracy (5-fold)#95.0
2204.11479v5.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#98.15$Audio Classification#ESC-50#Top-1 Accuracy#96.3$Audio Classification#ESC-50#PRE-TRAINING DATASET#AudioSet$Audio Classification#ESC-50#Accuracy (5-fold)#96.3$Audio Classification#ESC-50#Top-1 Accuracy#95.25$Audio Classification#ESC-50#Accuracy (5-fold)#95.25$Audio Classification#ESC-50#Top-1 Accuracy#92.15$Audio Classification#ESC-50#Accuracy (5-fold)#92.15$Audio Classification#AudioSet#Test mAP#0.426$Audio Classification#AudioSet#Test mAP#0.405$Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#90$Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#88.1$Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#85.5
2104.01778v3.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#98.11$Speech Emotion Recognition#CREMA-D#Accuracy#67.81$Audio Classification#ESC-50#Top-1 Accuracy#95.7$Audio Classification#ESC-50#PRE-TRAINING DATASET#AudioSet, ImageNet$Audio Classification#ESC-50#Accuracy (5-fold)#95.7$Audio Classification#AudioSet#Test mAP#0.485$Audio Classification#AudioSet#Test mAP#0.459$Audio Tagging#AudioSet#mean average precision#0.485$Time Series#Speech Commands#% Test Accuracy#98.11
2202.00874v1.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#98.0$Audio Classification#ESC-50#Top-1 Accuracy#97.0$Audio Classification#ESC-50#PRE-TRAINING DATASET#AudioSet$Audio Classification#ESC-50#Accuracy (5-fold)#97.0$Audio Classification#AudioSet#Test mAP#0.487$Sound Event Detection#DESED#event-based F1 score#50.7
2110.07749v3.pdf	Keyword Spotting#Google Speech Commands#Google Speech Commands V2 35#97.56
2010.13309v2.pdf	Keyword Spotting#Google Speech Commands#10-keyword Speech Commands dataset#95.12
1807.04353v2.pdf	Keyword Spotting#Google Speech Commands#10-keyword Speech Commands dataset#94.3
2104.01271v2.pdf	Keyword Spotting#Google Speech Commands#10-keyword Speech Commands dataset#92.37
2103.13620v1.pdf	Keyword Spotting#Google Speech Commands#% Test Accuracy#95.4% ±0.22$Keyword Spotting#Google Speech Commands#% Test Accuracy#96.8% ±0.13$Keyword Spotting#Google Speech Commands#% Test Accuracy#97.5% ±0.15$Keyword Spotting#TAU Urban Acoustic Scenes 2019#Accuracy#83.6% ±0.07$Keyword Spotting#TAU Urban Acoustic Scenes 2019#Accuracy#84.1% ±0.20
1804.03209v1.pdf	Keyword Spotting#TensorFlow#TFMA#89.7$Keyword Spotting#TensorFlow#TFMA#85.4
2012.15695v1.pdf	Keyword Spotting#FKD#Accuracy#95.88$Keyword Spotting#FKD#Accuracy#95.83
2110.15957v1.pdf	Visual Keyword Spotting#LRS3-TED#Top-1 Accuracy#52$Visual Keyword Spotting#LRS3-TED#Top-5 Accuracy#77.1$Visual Keyword Spotting#LRS3-TED#mAP#55.4$Visual Keyword Spotting#LRS3-TED#mAP IOU@0.5#53.6$Visual Keyword Spotting#LRW#Top-1 Accuracy#85.8$Visual Keyword Spotting#LRW#Top-5 Accuracy#99.6$Visual Keyword Spotting#LRW#mAP#64.1$Visual Keyword Spotting#LRS2#Top-1 Accuracy#65$Visual Keyword Spotting#LRS2#Top-5 Accuracy#87.1$Visual Keyword Spotting#LRS2#mAP#69.2$Visual Keyword Spotting#LRS2#mAP IOU@0.5#68.3
2010.13302v1.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#19.2$3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#13.55$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#19.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
2208.11960v1.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#22.5
2003.11163v2.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#24.6$3D Absolute Human Pose Estimation#Total Capture#MPJPE#24.6
2004.02186v2.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#27.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#21.0$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.2
1912.04071v1.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#28.9$3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#32.7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#37.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
1909.01203v1.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#29.0$3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#41.0$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#26.21$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#31.17
2110.05092v2.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#29.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#28.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#29.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.4$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.7
1807.01511v1.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#35
1602.00134v4.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#99$Pose Estimation#Leeds Sports Poses#PCK#90.5%$Pose Estimation#J-HMDB#Mean PCK@0.2#91.9$Pose Estimation#FLIC Elbows#PCK@0.2#97.59%$Pose Estimation#MPII Human Pose#PCKh-0.5#88.52$Pose Estimation#FLIC Wrists#PCK@0.2#95.03%$Car Pose Estimation#ApolloCar3D#Detection Rate#75.4
1803.02622v2.pdf	3D Human Pose Estimation#Total Capture#Average MPJPE (mm)#112
2203.09287v1.pdf	3D Human Pose Estimation#AIST++#MPJPE#33.3$3D Human Pose Estimation#3DPW#MPJPE#72.1$Pose Estimation#3DPW#PCK@0.2#80.5$Pose Estimation#3DPW#Acceleration Error#5.4
2203.08713v2.pdf	3D Human Pose Estimation#AIST++#MPJPE#67.2$3D Human Pose Estimation#AIST++#Single-view#Y$3D Human Pose Estimation#3DPW#PA-MPJPE#46.4$3D Human Pose Estimation#3DPW#MPJPE#75.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#53.1$Pose Estimation#J-HMDB#Mean PCK@0.2#99.0$Pose Estimation#J-HMDB#Mean PCK@0.1#94.6$Pose Estimation#J-HMDB#Mean PCK@0.05#80.6$2D Human Pose Estimation#JHMDB (2D poses only)#PCK#98.8
1905.05754v1.pdf	3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#13.7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#17.7$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#20.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.9
2205.12602v1.pdf	3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#17.62$3D Multi-Person Pose Estimation#Shelf#PCP3D#97.3$3D Multi-Person Pose Estimation#Shelf#MPJPE#56.3$3D Multi-Person Pose Estimation#Campus#PCP3D#96.3$3D Multi-Person Pose Estimation#Campus#Mean mAP#80.1
2004.00329v1.pdf	3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#69$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#43.4
2205.12583v2.pdf	3D Human Pose Estimation#Panoptic#Average MPJPE (mm)#127.8$3D Human Pose Estimation#3DPW#PA-MPJPE#60.5$3D Human Pose Estimation#3DPW#MPJPE#87$3D Human Pose Estimation#3DPW#MPVPE#106.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#38.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#48.5$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#76.27
2208.00571v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#32.8$3D Human Pose Estimation#3DPW#MPJPE#52.8$3D Human Pose Estimation#3DPW#MPVPE#61.5$3D Human Pose Estimation#3DPW#PA-MPJPE#43$3D Human Pose Estimation#3DPW#MPJPE#69$3D Human Pose Estimation#3DPW#MPVPE#81.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.1$3D Human Pose Estimation#Human3.6M#PA-MPJPE#32.7
2111.04017v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#40.4$3D Human Pose Estimation#3DPW#MPJPE#65.5$3D Human Pose Estimation#3DPW#MPVPE#82.0$3D Human Pose Estimation#Surreal#PA-MPJPE#34$3D Human Pose Estimation#Surreal#PVE#70.7$3D Human Pose Estimation#MPI-INF-3DHP#AUC#43.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#101.5$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#66.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#79.5$3D Absolute Human Pose Estimation#Surreal#MPJPE#55.2
2207.13820v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#44.6$3D Human Pose Estimation#3DPW#MPJPE#73.5$3D Human Pose Estimation#3DPW#MPVPE#84.1$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.2$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#33.7$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#6.5$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#98.2
2011.14672v4.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#45.0$3D Human Pose Estimation#3DPW#MPJPE#74.1$3D Human Pose Estimation#3DPW#MPVPE#86.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#33.6$3D Human Pose Estimation#MPI-INF-3DHP#AUC#46.9$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#91.0$3D Human Pose Estimation#MPI-INF-3DHP#PCK#87.5
2207.06400v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#45.3$3D Human Pose Estimation#3DPW#MPJPE#74.2$3D Human Pose Estimation#3DPW#MPVPE#87.0$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.2$3D Human Pose Estimation#Human3.6M#PA-MPJPE#37.2
2104.00272v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#45.6$3D Human Pose Estimation#3DPW#MPJPE#74.7$3D Human Pose Estimation#3DPW#MPVPE#87.7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.2$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#34.5$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#5.9$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#6$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#76.4$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#98.6
2109.02303v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#45.7$3D Human Pose Estimation#3DPW#MPJPE#79.1$3D Human Pose Estimation#3DPW#MPVPE#92.6$3D Human Pose Estimation#3DPW#Acceleration Error#17.6$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#38.7$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#83.6$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#56.2
2205.15448v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#45.9$3D Human Pose Estimation#3DPW#MPJPE#73.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#32.8
2208.03431v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#46$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#40.2$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#48.4
2104.08527v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#46.5$3D Human Pose Estimation#3DPW#MPJPE#74.5$3D Human Pose Estimation#3DPW#MPVPE#88.6$3D Human Pose Estimation#AGORA#B-NMVE#167.7$3D Human Pose Estimation#AGORA#B-NMJE#174.0$3D Human Pose Estimation#AGORA#B-MVE#140.9$3D Human Pose Estimation#AGORA#B-MPJPE#146.2$3D Multi-Person Pose Estimation#AGORA#B-NMVE#167.7$3D Multi-Person Pose Estimation#AGORA#B-NMJE#174.0$3D Multi-Person Pose Estimation#AGORA#B-MVE#140.9$3D Multi-Person Pose Estimation#AGORA#B-MPJPE#146.2
2012.09760v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#47.9$3D Human Pose Estimation#3DPW#MPJPE#77.1$3D Human Pose Estimation#3DPW#MPVPE#88.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#36.7$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#6.7$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#6.8$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#71.7$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#98.1
2204.08680v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#49.3$3D Human Pose Estimation#3DPW#MPJPE#80.6$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.8
2103.16449v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#49.5$3D Human Pose Estimation#3DPW#MPJPE#77.2$3D Human Pose Estimation#3DPW#MPVPE#91.2
2007.07227v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#49.7$3D Human Pose Estimation#3DPW#MPJPE#68.8$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.3±0.7$3D Human Pose Estimation#MPI-INF-3DHP#AUC#56.2±0.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#74.9±1.4$3D Human Pose Estimation#MPI-INF-3DHP#PCK#90.6±0.4$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJPE#68.83
2003.10350v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#49.8$3D Human Pose Estimation#3DPW#MPJPE#80.2
2110.11680v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#50.3$3D Human Pose Estimation#3DPW#MPJPE#76.7$3D Human Pose Estimation#3DPW#MPVPE#93.5$3D Human Pose Estimation#3DPW#Acceleration Error#11$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#60.5$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.3$3D Human Pose Estimation#Human3.6M#Acceleration Error#5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#93.4$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#62.2$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#11.9
2103.14182v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#50.4$3D Human Pose Estimation#3DPW#MPJPE#85.8$3D Human Pose Estimation#3DPW#MPVPE#100.6$3D Human Pose Estimation#3DPW#Acceleration Error#77.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#38.7$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#94.3$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#60.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#90.1
2104.13502v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#51.1$3D Human Pose Estimation#3DPW#MPVPE#97.0$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40.2
2107.12847v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#51.2$3D Human Pose Estimation#3DPW#MPJPE#81.7$3D Human Pose Estimation#3DPW#MPVPE#93.6$3D Human Pose Estimation#3DPW#Acceleration Error#15.6$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#94.6$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#62.4
2004.03686v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#51.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#46.8$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#67.5
2110.03480v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#51.7$3D Human Pose Estimation#3DPW#MPJPE#85.7$3D Human Pose Estimation#3DPW#MPVPE#99.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#60.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#104.7$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#66.7
1912.05656v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#51.9$3D Human Pose Estimation#3DPW#MPJPE#82.9$3D Human Pose Estimation#3DPW#MPVPE#99.1$3D Human Pose Estimation#3DPW#Acceleration Error#23.4$3D Human Pose Estimation#3DPW#Number of parameters (M)#72.43$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#65.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.4$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#96.6$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#64.6$3D Human Pose Estimation#MPI-INF-3DHP#PCK#89.3$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#65.6$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#16$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2203.08534v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#52.1$3D Human Pose Estimation#3DPW#MPJPE#84.3$3D Human Pose Estimation#3DPW#MPVPE#99.7$3D Human Pose Estimation#3DPW#Acceleration Error#7.4$3D Human Pose Estimation#3DPW#Number of parameters (M)#39.63$3D Human Pose Estimation#3DPW#FLOPs (G)#4.45$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#69.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#47.4$3D Human Pose Estimation#Human3.6M#Acceleration Error#3.6$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#96.7$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#62.8$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#9.6
2207.12537v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#52.3$3D Human Pose Estimation#3DPW#MPJPE#84.6$3D Human Pose Estimation#3DPW#MPVPE#100.3$3D Human Pose Estimation#3DPW#Acceleration Error#11.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#68.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#47.1$3D Human Pose Estimation#Human3.6M#Acceleration Error#12.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#96.2$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#63.1$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#16.7
2112.12917v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#52.34$3D Human Pose Estimation#3DPW#MPJPE#81.98$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.88$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.59
2011.08627v4.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#52.7$3D Human Pose Estimation#3DPW#MPJPE#86.5$3D Human Pose Estimation#3DPW#MPVPE#102.9$3D Human Pose Estimation#3DPW#Acceleration Error#7.1$3D Human Pose Estimation#3DPW#PA-MPJPE#55.8$3D Human Pose Estimation#3DPW#MPJPE#95$3D Human Pose Estimation#3DPW#MPVPE#111.5$3D Human Pose Estimation#3DPW#Acceleration Error#7$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.1$3D Human Pose Estimation#Human3.6M#Acceleration Error#5.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#73.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#52$3D Human Pose Estimation#Human3.6M#Acceleration Error#3.9$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#97.3$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#63.5$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#8.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#97.4$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#62.8$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#8
2110.09243v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#52.9$3D Human Pose Estimation#3DPW#MPJPE#89.4$3D Human Pose Estimation#3DPW#MPVPE#103.8$3D Human Pose Estimation#3DPW#Acceleration Error#8.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#97.4$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#63.3$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#8.7
2110.00620v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#53.2$3D Human Pose Estimation#AGORA#B-NMVE#126.8$3D Human Pose Estimation#AGORA#B-NMJE#133.7$3D Human Pose Estimation#AGORA#B-MVE#106.5$3D Human Pose Estimation#AGORA#B-MPJPE#112.3$3D Multi-Person Pose Estimation#AGORA#B-NMVE#126.8$3D Multi-Person Pose Estimation#AGORA#B-NMJE#133.7$3D Multi-Person Pose Estimation#AGORA#B-MVE#106.5$3D Multi-Person Pose Estimation#AGORA#B-MPJPE#112.3
2110.00990v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#53.6$3D Human Pose Estimation#3DPW#MPJPE#84.9
2008.03789v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#54.7$3D Human Pose Estimation#3DPW#MPJPE#86.9$3D Human Pose Estimation#3DPW#Acceleration Error#11.6$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#76$3D Human Pose Estimation#Human3.6M#PA-MPJPE#53.2$3D Human Pose Estimation#Human3.6M#Acceleration Error#15.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#96.4$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#65.4$3D Human Pose Estimation#MPI-INF-3DHP#Acceleration Error#11.1
1912.13344v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#54.8$3D Human Pose Estimation#3DPW#MPJPE#85.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.9
2108.11944v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#55.1$3D Human Pose Estimation#3DPW#PA-MPJPE#59.9$3D Human Pose Estimation#3DPW#PA-MPJPE#65$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.2
2104.03176v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#55.5$3D Human Pose Estimation#3DPW#MPJPE#84.9
2104.07300v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#55.8$3D Human Pose Estimation#3DPW#MPJPE#85.8$3D Human Pose Estimation#3DPW#MPVPE#108.5$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#72.7
2008.06910v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#57.5$3D Human Pose Estimation#3DPW#MPJPE#81.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#91.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#66
2108.00351v5.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#57.9
2008.09047v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.3$3D Human Pose Estimation#3DPW#MPJPE#88.9$3D Human Pose Estimation#3DPW#MPVPE#106.3$3D Human Pose Estimation#3DPW#Acceleration Error#22.6$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#48.7$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#7.8$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#7.7$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#67.4$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#96.9
2203.13349v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.3$3D Human Pose Estimation#3DPW#MPJPE#89.7$3D Human Pose Estimation#3DPW#MPVPE#107.1
2008.03713v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.6$3D Human Pose Estimation#3DPW#MPJPE#93.2$3D Human Pose Estimation#3DPW#MPVPE#110.1$3D Human Pose Estimation#3DPW#Acceleration Error#30.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#55.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.7$3D Hand Pose Estimation#FreiHAND#PA-MPVPE#7.6$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#7.4$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#68.1$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#97.3
2111.12696v3.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.9$3D Human Pose Estimation#3DPW#MPJPE#88.5$3D Human Pose Estimation#3DPW#MPVPE#106.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#45.4
2103.16507v4.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.9$3D Human Pose Estimation#3DPW#MPJPE#92.8$3D Human Pose Estimation#3DPW#MPVPE#110.1$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40.5
2007.13666v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#58.98$3D Human Pose Estimation#3DPW#MPJPE#96.36$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#103.36$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#70.01
1909.12828v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#59.2$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.1$3D Human Pose Estimation#MPI-INF-3DHP#AUC#55.6$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#67.5$3D Human Pose Estimation#MPI-INF-3DHP#PCK#92.5$3D Human Pose Estimation#MPI-INF-3DHP#AUC#37.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#105.2$3D Human Pose Estimation#MPI-INF-3DHP#PCK#76.4$3D Human Pose Estimation#AGORA#B-NMVE#216.3$3D Human Pose Estimation#AGORA#B-NMJE#223.1$3D Human Pose Estimation#AGORA#B-MVE#168.7$3D Human Pose Estimation#AGORA#B-MPJPE#175.1$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJPE#102.56$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJAE#25.42$3D Multi-Person Pose Estimation#AGORA#B-NMVE#216.3$3D Multi-Person Pose Estimation#AGORA#B-NMJE#223.1$3D Multi-Person Pose Estimation#AGORA#B-MVE#168.7$3D Multi-Person Pose Estimation#AGORA#B-MPJPE#175.1
2009.06549v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#59.7$3D Human Pose Estimation#3DPW#MPJPE#83.2$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJPE#83.15$3D Human Pose Estimation#3D Poses in the Wild Challenge#MPJAE#19.69
2103.10978v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#61$3D Human Pose Estimation#3DPW#MPJPE#90.9
2206.07036v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#62.6$3D Human Pose Estimation#3DPW#MPJPE#95.2
2003.03473v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#63.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.0$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#59.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#43.2$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#102.4$3D Human Pose Estimation#MPI-INF-3DHP#PCK#81.9
2105.02467v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#63.8$3D Human Pose Estimation#3DPW#MPJPE#104.1$3D Human Pose Estimation#3DPW#MPVPE#119.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#51.3$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#73.83$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#135.4
2004.03143v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#65.2$3D Human Pose Estimation#3DPW#MPJPE#89.7$3D Human Pose Estimation#Surreal#MPJPE#37.1$3D Human Pose Estimation#Surreal#PCK#97.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.5$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE#53.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#90.3$3D Human Pose Estimation#MPI-INF-3DHP#PCK#84.3$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.0$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2105.10996v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#66.1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#104.1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#50.4
2009.10013v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#66.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#55.4
2103.09009v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#66.9$3D Human Pose Estimation#3DPW#MPJPE#87.8$3D Human Pose Estimation#3DPW#MPVPE#108.6$3D Human Pose Estimation#Surreal#MPJPE#51.7$3D Human Pose Estimation#Surreal#PA-MPJPE#37.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#37.3
2203.15625v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#69.5$3D Human Pose Estimation#3DPW#MPJPE#115$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#68.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#78$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#PA-MPJPE#51.8$3D Human Pose Estimation#MPI-INF-3DHP#AUC#53.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#79.5$3D Human Pose Estimation#MPI-INF-3DHP#PCK#89.1
1908.07172v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#69.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#59.1$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.4$3D Human Pose Estimation#Human3.6M#Acceleration Error#6.8
2004.11822v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#71.8$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#40.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#30.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#84.1$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#13.5$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#40.1$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Monocular 3D Human Pose Estimation#Human3.6M#PA-MPJPE#30.7
2204.01971v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#72.1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57.6$Weakly-supervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#48.2$Unsupervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#86.2$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#97.8
1905.04266v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#72.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#77.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.3$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#190$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1812.01601v4.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#72.6$3D Human Pose Estimation#3DPW#MPJPE#116.5$3D Human Pose Estimation#3DPW#Acceleration Error#15.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#83.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#56.9
2105.02465v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#73.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#36.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#38.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.2$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.8$3D Human Pose Estimation#MPI-INF-3DHP#AUC#57.9$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#71.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#89.2$3D Human Pose Estimation#MPI-INF-3DHP#AUC#57.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#73$3D Human Pose Estimation#MPI-INF-3DHP#PCK#88.6$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#73.2$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#76.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.2$Monocular 3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.1$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
2007.02054v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#75.8
2112.11153v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#76.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.1$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.8$3D Human Pose Estimation#MPI-INF-3DHP#AUC#40.6$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#115.0$3D Human Pose Estimation#MPI-INF-3DHP#PCK#76.1
2004.05275v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#78.2
1711.09250v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#92.2$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.1$3D Human Pose Estimation#Human3.6M#PA-MPJPE#36.3$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.1$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#20$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1607.08128v1.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#106.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#82.3$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#79.9
1705.03098v2.pdf	3D Human Pose Estimation#3DPW#PA-MPJPE#157.0$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#67.5$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#24.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1712.06584v2.pdf	3D Human Pose Estimation#3DPW#Acceleration Error#37.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#87.97$3D Human Pose Estimation#Human3.6M#PA-MPJPE#58.1$3D Human Pose Estimation#MPI-INF-3DHP#AUC#36.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#124.2$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#89.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#72.9$3D Human Pose Estimation#AGORA#B-NMVE#217.0$3D Human Pose Estimation#AGORA#B-NMJE#226.0$3D Human Pose Estimation#AGORA#B-MVE#173.6$3D Human Pose Estimation#AGORA#B-MPJPE#180.5$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$3D Multi-Person Pose Estimation#AGORA#B-NMVE#217.0$3D Multi-Person Pose Estimation#AGORA#B-NMJE#226.0$3D Multi-Person Pose Estimation#AGORA#B-MVE#173.6$3D Multi-Person Pose Estimation#AGORA#B-MPJPE#180.5$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1804.04875v3.pdf	3D Human Pose Estimation#Surreal#MPJPE#49.1$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.6
2208.11251v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#17.59$3D Human Pose Estimation#Human3.6M#MPVE (mm)#23.7$3D Human Pose Estimation#Human3.6M#Angular Error#11.33$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.56$3D Human Pose Estimation#Human3.6M#MPVE (mm)#42.28$3D Human Pose Estimation#Human3.6M#Angular Error#14.61$3D Human Pose Estimation#MPI-INF-3DHP#AUC#77.09$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#33.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#99.37$3D Human Pose Estimation#MPI-INF-3DHP#AUC#71.57$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#45.87$3D Human Pose Estimation#MPI-INF-3DHP#PCK#96.59
2005.04551v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#19.0$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#26.9$3D Hand Pose Estimation#InterHand2.6M#MPJPE#4.91
2203.00859v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#21.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#25.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#39.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#40.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#66.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#54.9$3D Human Pose Estimation#MPI-INF-3DHP#PCK#94.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#63.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#57.9$3D Human Pose Estimation#MPI-INF-3DHP#PCK#94.2$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#16.1$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#39.8$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#243$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2107.07797v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#22.7$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#41.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#69.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#42.5$3D Human Pose Estimation#MPI-INF-3DHP#PCK#97.9
2106.14729v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#23.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#29.8$3D Multi-Person Pose Estimation#Shelf#PCP3D#97.4$3D Multi-Person Pose Estimation#Campus#PCP3D#97
2209.08194v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#24.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
2105.01937v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#24.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No
2004.13985v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#25.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#62.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#68.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#86.9
2110.09554v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#25.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
2203.13387v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#28.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.7$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#57.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#76.3$3D Human Pose Estimation#MPI-INF-3DHP#PCK#89.1
2103.14304v8.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#28.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.7$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.9$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#12.2$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#18.9
2110.00280v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#29.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
2203.07628v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#29.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#PA-MPJPE#34.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.1$3D Human Pose Estimation#MPI-INF-3DHP#AUC#75.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#32.2$3D Human Pose Estimation#MPI-INF-3DHP#PCK#97.9$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.1$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#243$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2107.13994v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.3$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#243$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2111.12707v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#30.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#63.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#58$3D Human Pose Estimation#MPI-INF-3DHP#PCK#93.8
2109.07353v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#31.2$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.3$3D Human Pose Estimation#MPI-INF-3DHP#AUC#53.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#76$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#19.5$Pose Estimation#Leeds Sports Poses#PCK#87.5%
2103.10455v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#31.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#56.4$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#77.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#88.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.3
2007.09389v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#32$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#33.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.9$3D Human Pose Estimation#MPI-INF-3DHP#AUC#43.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#77.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2002.10322v5.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#32.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#54$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#78.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#87.9$3D Human Pose Estimation#MPI-INF-3DHP#AUC#53.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#79.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#87.8$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.1$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#243$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2106.14706v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#32.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#35.4$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.4
2205.12256v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#33.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#21.9
2103.03170v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#33.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#15.4
2206.01867v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#33.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.3
2208.03704v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#34$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No
2203.11471v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#34.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.7$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#84.4$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#46.6$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#9$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2206.06420v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#35.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#48$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No
2103.16385v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#35.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#45.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#80.1
2203.10554v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#36.2$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.1$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No
2107.11291v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#36.3$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular
1904.05512v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#37.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#33.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#71.2
1910.12029v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#38.38$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#28.78$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.1$3D Human Pose Estimation#MPI-INF-3DHP#AUC#45.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#84
2107.03000v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#38.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
1911.09245v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#39$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#MPI-INF-3DHP#AUC#42.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#112.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#80.6
1910.12032v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#39.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#27.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.1$3D Human Pose Estimation#MPI-INF-3DHP#AUC#38$3D Human Pose Estimation#MPI-INF-3DHP#PCK#75.3$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#15.2$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#39.9$Monocular 3D Human Pose Estimation#Human3.6M#PA-MPJPE#27.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1907.06968v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular
2110.07578v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.0$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#MPI-INF-3DHP#AUC#50.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#93.0$3D Human Pose Estimation#MPI-INF-3DHP#PCK#81.0
2103.15507v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#MPI-INF-3DHP#AUC#42.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#80.5
2205.05980v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.5$3D Human Pose Estimation#MPI-INF-3DHP#AUC#48.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#78
1904.03345v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#43.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57.6$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2107.13788v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.3$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#84.3
1908.09464v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#44.4$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View
2003.14179v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#35.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.2$3D Human Pose Estimation#Human3.6M#PA-MPJPE#36$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49$3D Human Pose Estimation#Human3.6M#PA-MPJPE#37.4$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#21.2
2002.11251v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#45.9
1908.08289v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#MPI-INF-3DHP#AUC#51.4$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#79.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#83.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.6$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#50$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Pose Estimation#Leeds Sports Poses#PCK#83.6
1811.11742v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.8$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#36.5$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.8$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#243$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#243
1904.01324v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.8$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#23.9$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.0$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.8$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average PMPJPE (mm)#37.3
1912.08077v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#48.6
2108.04869v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49$3D Human Pose Estimation#SkiPose#MPJPE#53$3D Human Pose Estimation#SkiPose#P-MPJPE#42$3D Human Pose Estimation#SkiPose#MPJPE#54$3D Human Pose Estimation#SkiPose#P-MPJPE#30$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56
2003.02953v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.3±0.7
2110.08825v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.5$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.1
1711.08229v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40.6$Pose Estimation#MPII Human Pose#PCKh-0.5#91.0
1904.05547v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.6$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.7$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.6$3D Human Pose Estimation#MPI-INF-3DHP#PCK#67.9$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.7$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.7$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average PMPJPE (mm)#42.6
1908.03030v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#49.9
2009.01998v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.2$3D Human Pose Estimation#MPI-INF-3DHP#AUC#44.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#96.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#83.2
2006.07778v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.9$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#MPI-INF-3DHP#AUC#46.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#99.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#81.2$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.9$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
1902.09868v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.9$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#89.9$3D Human Pose Estimation#MPI-INF-3DHP#AUC#58.5$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#97.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#82.5$3D Human Pose Estimation#MPI-INF-3DHP#AUC#54.8$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#92.5$3D Human Pose Estimation#MPI-INF-3DHP#PCK#81.8$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#89.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#89.9$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
2111.15056v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.4
2111.11927v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.8$3D Human Pose Estimation#MPI-INF-3DHP#AUC#52.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#85.2
1903.02330v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.83$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#108.99$3D Human Pose Estimation#MPI-INF-3DHP#PCK#77.5$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#60.56$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#65.35$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#76.6$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#2$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
1905.03244v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#51.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#51.9$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#74.7$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2204.11548v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.7
1808.01525v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#52.8
1802.09232v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#53.2
2112.12867v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#53.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39$3D Human Pose Estimation#HSPACE#PA-MPJPE#47$3D Human Pose Estimation#HSPACE#MPJPE#71$3D Human Pose Estimation#HSPACE#PA-MPVPE#58$3D Human Pose Estimation#HSPACE#MPVPE#81
1809.04987v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.2
2205.00508v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.7$3D Absolute Human Pose Estimation#Human3.6M#PA-MPJPE#38.4
2111.00950v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#54.8
2106.09336v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#55$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39.8$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#87$3D Human Pose Estimation#Human3.6M#PA-MPJPE#62.2
1806.01484v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#55.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#39$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#57$3D Human Pose Estimation#Human3.6M#PA-MPJPE#40.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#47$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#91.3$3D Human Pose Estimation#MPI-INF-3DHP#PCK#85.4
1808.09316v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.1
2003.07581v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#110.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#80.2$Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#113.8$Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#79.1$Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#122.4$Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#76.5$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#59.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#67.4
1805.04095v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.2$3D Human Pose Estimation#MPI-INF-3DHP#AUC#35.3$3D Human Pose Estimation#MPI-INF-3DHP#PCK#71.9$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#18.3$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1806.09241v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.5
2104.00683v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#41.6$3D Human Pose Estimation#Human3.6M#Acceleration Error#6.7
1704.04793v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#56.9$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#118.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1812.01598v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.3$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.3$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#NO$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1711.08585v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.5$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Monocular$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#22
1803.09722v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#58.6$3D Human Pose Estimation#Human3.6M#PA-MPJPE#37.7$3D Human Pose Estimation#MPI-INF-3DHP#AUC#32.0$3D Human Pose Estimation#MPI-INF-3DHP#PCK#69.0$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Pose Estimation#MPII Single Person#PCKh@0.5#88.6
1704.00159v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#59.1$3D Human Pose Estimation#Human3.6M#PA-MPJPE#48.3$3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#92.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#67.5$Pose Estimation#MPII Human Pose#PCKh-0.5#86.4
1710.06513v6.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#60.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#45.7$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#22.9$3D Absolute Human Pose Estimation#Human3.6M#Average MPJPE (mm)#60.4
1809.07217v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.1
2110.08472v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.2$3D Human Pose Estimation#Human3.6M#PA-MPJPE#35.4
2004.09989v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#61.3
2108.07777v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.0$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#No$3D Human Pose Estimation#Human3.6M#Multi-View or Monocular#Multi-View$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.0$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
2004.04400v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#50.8$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#99.2
1907.00837v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.6$3D Human Pose Estimation#MPI-INF-3DHP#AUC#45.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#98.4$3D Human Pose Estimation#MPI-INF-3DHP#PCK#82.8$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.6$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#75.8
1901.03798v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.67
1811.04989v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#63.7$3D Human Pose Estimation#Human3.6M#PA-MPJPE#46.6$3D Human Pose Estimation#MPI-INF-3DHP#AUC#32.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#64.6
1704.02447v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.9$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE (CS)#99.4$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE (CA)#89.2$3D Human Pose Estimation#Geometric Pose Affordance#PCK3D (CS)#81.3$3D Human Pose Estimation#Geometric Pose Affordance#PCK3D (CA)#83.6$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.9$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2008.01388v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#67.9$3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#78.4
1904.04812v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#68.0$3D Human Pose Estimation#MPI-INF-3DHP#AUC#36.3$3D Human Pose Estimation#MPI-INF-3DHP#PCK#71.1
1611.05708v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#69.73
1812.11328v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#69.95$3D Human Pose Estimation#Human3.6M#PA-MPJPE#61.4
1611.07828v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#71.9$3D Human Pose Estimation#Human3.6M#PA-MPJPE#51.9$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#24.3
2108.12384v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#72.3$3D Human Pose Estimation#Human3.6M#PA-MPJPE#42.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#40.7$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#97.2$3D Human Pose Estimation#MPI-INF-3DHP#PA-MPJPE#62.5
1611.09813v5.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#72.88$3D Human Pose Estimation#MPI-INF-3DHP#AUC#39.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#117.6$3D Human Pose Estimation#MPI-INF-3DHP#PCK#75.7$3D Human Pose Estimation#MPI-INF-3DHP#AUC#40.8$3D Human Pose Estimation#MPI-INF-3DHP#PCK#64.7$Pose Estimation#Leeds Sports Poses#PCK#75.7
1707.09695v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#73.1$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#30.8
2011.14679v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#74.3$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#104$3D Human Pose Estimation#MPI-INF-3DHP#PCK#77$3D Human Pose Estimation#SkiPose#MPJPE#128.1$3D Human Pose Estimation#SkiPose#P-MPJPE#89.6$3D Human Pose Estimation#SkiPose#PCK#67.1$3D Human Pose Estimation#SkiPose#CPS#108.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#74.3$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1910.00116v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#76.8$3D Human Pose Estimation#Human3.6M#PA-MPJPE#48$3D Human Pose Estimation#MPI-INF-3DHP#AUC#41.1$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#114.2$3D Human Pose Estimation#MPI-INF-3DHP#PCK#76.9
1705.01583v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#80.5$3D Human Pose Estimation#MPI-INF-3DHP#AUC#41.6$3D Human Pose Estimation#MPI-INF-3DHP#PCK#79.4$3D Human Pose Estimation#MPI-INF-3DHP#AUC#40.4$3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#124.7$3D Human Pose Estimation#MPI-INF-3DHP#PCK#76.6$Pose Estimation#Leeds Sports Poses#PCK#79.4
2008.05770v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#81.1$3D Human Pose Estimation#MPI-INF-3DHP#PCK#79.3$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#73.9$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average PMPJPE (mm)#44.3
1612.06524v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#82.72
2205.12292v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#84$3D Human Pose Estimation#Human3.6M#PA-MPJPE#56
1701.00295v4.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#88.39$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#88.39$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#88.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1509.06720v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#97.39$3D Human Pose Estimation#Human3.6M#Using 2D ground-truth joints#Yes$3D Human Pose Estimation#Human3.6M#PA-MPJPE#108.3$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#38.9
2206.09106v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#103.4$3D Human Pose Estimation#Human3.6M#PA-MPJPE#73.7$3D Human Pose Estimation#Human3.6M#Acceleration Error#12.4
1609.05317v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#107.26
1511.09439v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#113.01$3D Human Pose Estimation#Human3.6M#PA-MPJPE#106.7$Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#113.01$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#Yes$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#300$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
2104.10609v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#116.4$3D Human Pose Estimation#DHP19#MPJPE3D#92.09
1608.03075v2.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#117.34
1609.00036v3.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#119
1508.06708v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#121.31
1605.05180v1.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#125.0
1504.08200.pdf	3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#125.28
2003.10873v2.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#47.6
1808.05942v1.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#59.9$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#64$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Monocular 3D Human Pose Estimation#Human3.6M#PA-MPJPE#59.9
1805.04092v1.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#75.9
1611.09010v1.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#76.5$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#26.9
1701.02468v3.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#80.7$3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#74.5$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No$Monocular 3D Human Pose Estimation#Human3.6M#PA-MPJPE#80.7
2105.10837v2.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#85.1
1607.02046v2.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#87.3
1509.04309v3.pdf	3D Human Pose Estimation#Human3.6M#PA-MPJPE#106.7
1905.07718v2.pdf	3D Human Pose Estimation#Geometric Pose Affordance#PCK3D (CS)#82.0$3D Human Pose Estimation#Geometric Pose Affordance#PCK3D (CA)#84.8$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE (CS)#97.8$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE (CA)#85.6$3D Human Pose Estimation#Geometric Pose Affordance#MPJPE#94.1$3D Human Pose Estimation#Geometric Pose Affordance#PCK#82.9
2206.04511v2.pdf	3D Human Pose Estimation#DHP19#MPJPE2D#6.46$3D Human Pose Estimation#DHP19#MPJPE3D#73.37$3D Human Pose Estimation#DHP19#Params (M)#3.65$3D Human Pose Estimation#DHP19#GFLOPs#10.06
1701.08985v1.pdf	3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#33.7
1406.2282v1.pdf	3D Human Pose Estimation#HumanEva-I#Mean Reconstruction Error (mm)#71.3
1809.06079v1.pdf	3D Human Pose Estimation#CHALL H80K#MPJPE#55.3
1705.02883v2.pdf	Monocular 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#97.39$Monocular 3D Human Pose Estimation#Human3.6M#Use Video Sequence#No$Monocular 3D Human Pose Estimation#Human3.6M#Frames Needed#1$Monocular 3D Human Pose Estimation#Human3.6M#Need Ground Truth 2D Pose#No
1909.01818v1.pdf	Pose Prediction#Filtered NTU RGB+D#MSE#0.1210$Pose Prediction#Filtered NTU RGB+D#MAE#1.1651$Pose Prediction#Filtered NTU RGB+D#MSE#0.1354$Pose Prediction#Filtered NTU RGB+D#MAE#1.4063$Pose Prediction#Gaming 3D (G3D)#MSE#0.1199$Pose Prediction#Gaming 3D (G3D)#MAE#1.1101$Pose Prediction#Gaming 3D (G3D)#MSE#0.1434$Pose Prediction#Gaming 3D (G3D)#MAE#1.4038
2108.10378v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#98.1
2104.02273v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.9$3D Multi-Person Pose Estimation#Campus#PCP3D#97$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#16.75
2109.05885v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.7$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#15.84
2002.12625v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.6
2207.10955v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.6$3D Multi-Person Pose Estimation#Campus#PCP3D#96.2$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#18.26
2111.04076v2.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.4$3D Multi-Person Pose Estimation#Campus#PCP3D#96.6$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#15.8
2106.11589v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.39$3D Multi-Person Pose Estimation#Campus#PCP3D#96.79
2108.02452v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97.1$3D Multi-Person Pose Estimation#Campus#PCP3D#96.7$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#18.49
2004.06239v4.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#97$3D Multi-Person Pose Estimation#Campus#PCP3D#96.7$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#17.68
1901.04111v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#96.9$3D Multi-Person Pose Estimation#Campus#PCP3D#96.3
2110.02330v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#96.9
2003.03972v3.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#96.8$3D Multi-Person Pose Estimation#Campus#PCP3D#96.6
2004.02688v1.pdf	3D Multi-Person Pose Estimation#Shelf#PCP3D#89.8$3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#38.59
1909.10854v1.pdf	3D Multi-Person Pose Estimation#MuPoTS-3D#3DPCK#74.2
2007.10986v1.pdf	3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#50
2207.09949v1.pdf	3D Multi-Person Pose Estimation#Panoptic#Average MPJPE (mm)#58.9$3D Multi-Person Pose Estimation (absolute)#MuPoTS-3D#3DPCK#44
2203.15865v3.pdf	Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#118.4$Weakly-supervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#73.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#64.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#52.1
2112.11593v2.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#42.5$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#27$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
2109.09166v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#47.3$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#82.1
2203.15293v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#59.4$Weakly-supervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#49.6$Unsupervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#88.9$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#103.2
2105.06599v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#62.9$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Views#1$Weakly-supervised 3D Human Pose Estimation#Human3.6M#Number of Frames Per View#27$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1908.06377v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#83.0$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#No
1910.11322v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#110.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
1804.01110v1.pdf	Weakly-supervised 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#131.7$Weakly-supervised 3D Human Pose Estimation#Human3.6M#3D Annotations#S1
2107.10060v5.pdf	Conditional Image Generation#Tiny ImageNet#FID#19.02$Conditional Image Generation#Tiny ImageNet#Intra-FID#63.05$Conditional Image Generation#ImageNet 128x128#FID#8.02$Conditional Image Generation#ImageNet 128x128#Inception score#108.10$Conditional Image Generation#CIFAR-100#FID#8.12$Conditional Image Generation#CIFAR-100#Intra-FID#49.24$Conditional Image Generation#CIFAR-10#FID#5.66$Conditional Image Generation#CIFAR-10#Intra-FID#40.45
2006.06676v2.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#2.625$Conditional Image Generation#CIFAR-10#Inception score#10.14$Conditional Image Generation#CIFAR-10#FID#2.42$Image Generation#FFHQ 1024 x 1024#FID#3.62$Image Generation#Pokemon 256x256#FID#40.38$Image Generation#AFHQ Dog#clean-KID#1.28 ± .02$Image Generation#AFHQ Dog#clean-FID#7.61 ± .02$Image Generation#AFHQ Dog#FID#7.41$Image Generation#AFHQ Wild#clean-KID#0.44 ± .01$Image Generation#AFHQ Wild#clean-FID#3.00 ± .01$Image Generation#AFHQ Wild#FID#3.05$Image Generation#FFHQ 256 x 256#FID#3.62$Image Generation#AFHQ Cat#clean-KID#0.71 ± .02$Image Generation#AFHQ Cat#clean-FID#3.28 ± .02$Image Generation#AFHQ Cat#FID#3.55
2111.01118v1.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#3.175$Conditional Image Generation#ImageNet 128x128#FID#8.206$Conditional Image Generation#ImageNet 128x128#Inception score#96.299$Conditional Image Generation#CIFAR-10#Inception score#10.51$Conditional Image Generation#CIFAR-10#FID#2.26$Image Generation#CIFAR-10#FID#2.236$Image Generation#CIFAR-10#FID#2.316$Image Generation#CIFAR-10#FID#2.325
1809.11096v2.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#4.055$Conditional Image Generation#ImageNet 128x128#FID#5.7$Conditional Image Generation#ImageNet 128x128#Inception score#124.5$Conditional Image Generation#ImageNet 128x128#FID#8.7$Conditional Image Generation#ImageNet 128x128#Inception score#98.8$Conditional Image Generation#CIFAR-10#Inception score#9.22$Conditional Image Generation#CIFAR-10#FID#14.73$Image Generation#CIFAR-10#Inception score#9.22$Image Generation#CIFAR-10#FID#14.73$Image Generation#ImageNet 256x256#FID#8.1$Image Generation#ImageNet 128x128#FID#5.7$Image Generation#ImageNet 128x128#IS#124.5$Image Generation#ImageNet 128x128#FID#8.7$Image Generation#ImageNet 128x128#IS#98.8
1912.04958v2.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#4.491$Image Generation#FFHQ 1024 x 1024#FID#2.84$Image Generation#LSUN Car 512 x 384#FID#2.32$Image Generation#LSUN Horse 256 x 256#FID#3.43$Image Generation#LSUN Horse 256 x 256#Clean-FID (trainfull)#4.06 ± 0.03$Image Generation#LSUN Cat 256 x 256#FID#6.93$Image Generation#LSUN Cat 256 x 256#Clean-FID (trainfull)#6.97 ± 0.16$Image Generation#LSUN Churches 256 x 256#FID#3.86$Image Generation#LSUN Churches 256 x 256#Clean-FID (trainfull)#4.28 ± 0.03$Image Generation#LSUN Car 256 x 256#FID#2.32
1910.12027v2.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#4.647$Conditional Image Generation#ImageNet 128x128#FID#6.66$Conditional Image Generation#CIFAR-10#FID#11.67$Image Generation#CIFAR-10#Inception score#8.40$Image Generation#CIFAR-10#FID#14.56$Image Generation#CelebA-HQ 128x128#FID#16.97$Image Generation#ImageNet 128x128#FID#6.66
2111.01007v1.pdf	Conditional Image Generation#ArtBench-10 (32x32)#FID#11.837$Image Generation#Cityscapes#FID-10k-training-steps#3.41$Image Generation#Pokemon 256x256#FID#26.36$Image Generation#Pokemon 1024x1024#FID#33.96$Image Generation#Stanford Cars#FID#2.09$Image Generation#CUB 128 x 128#FID#2.79$Image Generation#AFHQ Dog#FID#4.52$Image Generation#AFHQ Wild#FID#2.17$Image Generation#CLEVR#FID-5k-training-steps#0.89$Image Generation#LSUN Horse 256 x 256#FID#2.17$Image Generation#LSUN Bedroom 256 x 256#FID#1.52$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#1.52$Image Generation#Oxford 102 Flowers 256 x 256#FID#3.86$Image Generation#LSUN Cat 256 x 256#FID#3.89$Image Generation#LSUN Churches 256 x 256#FID#1.59$Image Generation#AFHQ Cat#FID#2.16$Image Generation#Stanford Dogs#FID#11.75$Image Generation#ADE-Indoor#FID#6.7
2206.11474v5.pdf	Conditional Image Generation#ImageNet 128x128#FID#2.63$Conditional Image Generation#ImageNet 128x128#Inception score#159.72$Conditional Image Generation#ImageNet 128x128#FID#2.68$Conditional Image Generation#ImageNet 128x128#Inception score#169.24$Conditional Image Generation#ImageNet 256x256#FID#3.96$Conditional Image Generation#ImageNet 256x256#Inception score#217.25$Conditional Image Generation#ImageNet 256x256#FID#4.09$Conditional Image Generation#ImageNet 256x256#Inception score#221.57$Image Generation#ImageNet 256x256#FID#3.96$Image Generation#ImageNet 256x256#Inception score#217.25$Image Generation#ImageNet 256x256#FID#4.09$Image Generation#ImageNet 256x256#Inception score#221.57
2105.05233v4.pdf	Conditional Image Generation#ImageNet 128x128#FID#2.97$Conditional Image Generation#ImageNet 256x256#FID#4.59$Conditional Image Generation#ImageNet 256x256#Inception score#186.7$Image Generation#ImageNet 64x64#FID#2.07$Image Generation#LSUN Horse 256 x 256#FID#2.57$Image Generation#LSUN Bedroom 256 x 256#FID#1.90$Image Generation#LSUN Cat 256 x 256#FID#5.57$Image Generation#ImageNet 256x256#FID#3.94$Image Generation#ImageNet 256x256#Inception score#215.84$Image Generation#ImageNet 256x256#FID#4.59$Image Generation#ImageNet 256x256#Inception score#186.7$Image Generation#ImageNet 512x512#FID#3.85$Image Generation#ImageNet 512x512#Inception score#221.72$Image Generation#ImageNet 512x512#FID#7.72$Image Generation#ImageNet 512x512#Inception score#172.71$Image Generation#ImageNet 128x128#FID#2.97
2011.13074v3.pdf	Conditional Image Generation#ImageNet 128x128#FID#6.53$Conditional Image Generation#ImageNet 128x128#Inception score#262.85$Conditional Image Generation#ImageNet 128x128#FID#8.30$Conditional Image Generation#ImageNet 128x128#Inception score#190.94
1903.02271v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#7.7$Conditional Image Generation#ImageNet 128x128#Inception score#83.1
2109.05070v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#9.5$Conditional Image Generation#ImageNet 128x128#Inception score#108.6$Conditional Image Generation#ImageNet 64x64#FID#6.7$Conditional Image Generation#ImageNet 64x64#Inception score#45.9±0.3$Conditional Image Generation#ImageNet 64x64#FID#10.2±0.1$Conditional Image Generation#ImageNet 64x64#Inception score#30.1±0.1$Conditional Image Generation#ImageNet 256x256#FID#8.1$Conditional Image Generation#ImageNet 256x256#Inception score#144.2$Conditional Image Generation#ImageNet 256x256#FID#8.2±0.1$Conditional Image Generation#ImageNet 256x256#Inception score#173.8±0.9
2007.15255v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#9.61$Conditional Image Generation#ImageNet 128x128#Inception score#114.32$Conditional Image Generation#ImageNet64x64#Inception Score#37.10$Conditional Image Generation#ImageNet64x64#FID#9.07
2109.04553v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#14.80$Conditional Image Generation#ImageNet 128x128#Inception score#58.75$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#85.9%$Semantic Segmentation#ADE20K#Validation mIoU#51.5$Semantic Segmentation#ADE20K#Params (M)#61.1$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#71.8$Semantic Segmentation#ADE20K#Validation mIoU#51.0$Semantic Segmentation#ADE20K#Params (M)#45.6$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#55.0$Semantic Segmentation#ADE20K#Validation mIoU#49.6$Semantic Segmentation#ADE20K#Params (M)#27.4$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#34.4$Semantic Segmentation#ADE20K#Validation mIoU#46.8$Semantic Segmentation#ADE20K#Validation mIoU#45.2$Semantic Segmentation#ADE20K#Params (M)#13.8$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#15.8$Semantic Segmentation#ADE20K val#mIoU#51.5$Semantic Segmentation#ADE20K val#mIoU#51.0$Semantic Segmentation#ADE20K val#mIoU#49.6$Semantic Segmentation#PASCAL Context#mIoU#55.2
1911.12287v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#15.94$Conditional Image Generation#ImageNet 128x128#Inception score#57.22
1805.08318v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#18.65$Conditional Image Generation#ImageNet 128x128#Inception score#52.52
1802.05637v2.pdf	Conditional Image Generation#ImageNet 128x128#FID#27.62$Conditional Image Generation#ImageNet 128x128#Inception score#36.8$Conditional Image Generation#CIFAR-10#Inception score#8.62$Conditional Image Generation#CIFAR-10#FID#17.5
1610.09585v4.pdf	Conditional Image Generation#ImageNet 128x128#Inception score#28.5$Conditional Image Generation#CIFAR-10#Inception score#8.25
1907.02690v4.pdf	Conditional Image Generation#CIFAR-100#Inception Score#9.34$Conditional Image Generation#CIFAR-100#FID#7.22
2012.03149v2.pdf	Conditional Image Generation#CIFAR-100#Inception Score#11.22$Conditional Image Generation#CIFAR-100#FID#10.23$Conditional Image Generation#CIFAR-100#Inception Score#9.48$Conditional Image Generation#CIFAR-100#FID#14$Conditional Image Generation#CIFAR-10#Inception score#9.52$Conditional Image Generation#CIFAR-10#FID#6.89$Conditional Image Generation#CIFAR-10#Inception score#9$Conditional Image Generation#CIFAR-10#FID#8.03$Image Generation#CIFAR-10#Inception score#9.01$Image Generation#CIFAR-10#FID#11.82$Image Generation#CIFAR-10#Inception score#8.53$Image Generation#CIFAR-10#FID#12.32$Image Generation#CIFAR-100#FID#19$Image Generation#CIFAR-100#Inception Score#8.9$Image Generation#CIFAR-100#FID#19.08$Image Generation#CIFAR-100#Inception Score#8.31$Image Generation#STL-10#FID#26.32$Image Generation#STL-10#Inception score#9.59$Image Generation#STL-10#FID#34.72$Image Generation#STL-10#Inception score#9.61
1912.04216v2.pdf	Conditional Image Generation#CIFAR-100#Inception Score#14.36$Conditional Image Generation#CIFAR-100#FID#17.3$Conditional Image Generation#CIFAR-10#Inception score#9.58$Conditional Image Generation#CIFAR-10#FID#7.5
2002.12655v2.pdf	Conditional Image Generation#COCO-Animals#FID#13.73$Conditional Image Generation#COCO-Animals#IS#12.29$Conditional Image Generation#COCO-Animals#FID#16.37$Conditional Image Generation#COCO-Animals#IS#11.77$Image Generation#CelebA 128x128#FID#2.95$Image Generation#CelebA 128x128#Inception score#3.43$Image Generation#CelebA-HQ 128x128#FID#2.03$Image Generation#CelebA-HQ 128x128#Inception score#3.33$Image Generation#FFHQ 256 x 256#FID#7.48$Image Generation#FFHQ 256 x 256#IS#4.46$Image Generation#FFHQ 256 x 256#FID#11.48$Image Generation#FFHQ 256 x 256#IS#3.97
2007.06418v2.pdf	Conditional Image Generation#CIFAR-10#Inception score#10.21$Conditional Image Generation#CIFAR-10#FID#3.6$Image Generation#CIFAR-10#Inception score#9.67$Image Generation#CIFAR-10#FID#8.17
1709.07359v2.pdf	Conditional Image Generation#CIFAR-10#Inception score#8.87$Image Generation#CIFAR-10#Inception score#7.90
1704.00028v3.pdf	Conditional Image Generation#CIFAR-10#Inception score#8.67$Image Generation#CAT 256x256#FID#155.46$Image Generation#CIFAR-10#Inception score#7.86$Image Generation#CIFAR-10#FID#29.3
1612.04357v4.pdf	Conditional Image Generation#CIFAR-10#Inception score#8.59
1606.03498v1.pdf	Conditional Image Generation#CIFAR-10#Inception score#8.09$Image Generation#CIFAR-10#Inception score#6.86$Image Classification#SVHN#Percentage error#8.11$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#91.89$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#15.59
1703.01560v3.pdf	Conditional Image Generation#CIFAR-10#Inception score#7.17$Image Generation#CIFAR-10#Inception score#7.17$Image Generation#Stanford Cars#FID#88.80$Image Generation#Stanford Cars#Inception score#5.25$Image Generation#CUB 128 x 128#FID#34.91$Image Generation#CUB 128 x 128#Inception score#13.50$Image Generation#Stanford Dogs#FID#54.91$Image Generation#Stanford Dogs#Inception score#10.22
1702.01691v2.pdf	Conditional Image Generation#CIFAR-10#Inception score#7.07$Image Generation#CIFAR-10#Inception score#7.07
1511.06434v2.pdf	Conditional Image Generation#CIFAR-10#Inception score#6.58$Image Clustering#Imagenet-dog-15#Accuracy#0.174$Image Clustering#Imagenet-dog-15#NMI#0.121$Image Clustering#ImageNet-10#Accuracy#0.346$Image Clustering#ImageNet-10#NMI#0.225$Image Clustering#CIFAR-100#Accuracy#0.151$Image Clustering#CIFAR-100#NMI#0.120$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#Tiny-ImageNet#Accuracy#0.041$Image Clustering#Tiny-ImageNet#NMI#0.135$Image Clustering#STL-10#Accuracy#0.298$Image Clustering#STL-10#NMI#0.210$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#CIFAR-10#Accuracy#0.315$Image Clustering#CIFAR-10#NMI#0.265$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.176$Image Clustering#CIFAR-10#Backbone#GAN$Image Classification#SVHN#Percentage error#22.48$Image Classification#SVHN#Percentage error#28.87$Image Classification#SVHN#Percentage error#66.55$Image Classification#SVHN#Percentage error#77.93$Image Classification#CIFAR-10#Percentage correct#82.8$Image Classification#CIFAR-10#Percentage correct#80.6
1611.01722v2.pdf	Conditional Image Generation#CIFAR-10#Inception score#6.35
2102.05113v1.pdf	Conditional Image Generation#CIFAR-10#FID#9.42$Image Generation#CIFAR-10#FID#12.61$Image Generation#CIFAR-100#FID#19.72
2006.12681v3.pdf	Conditional Image Generation#CIFAR-10#FID#10.30
2005.06723v1.pdf	Image Outpainting#Places365-Standard#MSE#0.7814$Image Outpainting#Places365-Standard#Adversarial#0.0941$Image Outpainting#Places365-Standard#L1#0.08
2010.13668v1.pdf	Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average MPJPE (mm)#46.2$Multi-Hypotheses 3D Human Pose Estimation#Human3.6M#Average PMPJPE (mm)#36.3
1610.09075v2.pdf	Imputation#Adult Data Set#Test error#0.144 ± 0.06$General Classification#CVR#Test error#0.027 ± 0.006
2006.07027v2.pdf	Imputation#Sprites#MSE#0.002$Imputation#PhysioNet Challenge 2012#AUROC#0.743$Imputation#HMNIST#NLL#0.251$Imputation#HMNIST#MSE#0.092$Imputation#HMNIST#AUROC#0.962$Time Series Classification#NetFlow#Accuracy#0.960$Time Series Classification#NetFlow#Accuracy#0.793$Time Series Classification#PenDigits#Accuracy#0.954$Time Series Classification#PenDigits#Accuracy#0.953$Time Series Classification#DigitShapes#Accuracy#1$Time Series Classification#KickvsPunch#Accuracy#1$Time Series Classification#Wafer#Accuracy#0.989$Time Series Classification#Wafer#Accuracy#0.981$Time Series Classification#WalkvsRun#Accuracy#1$Time Series Classification#UWave#Accuracy#0.969$Time Series Classification#UWave#Accuracy#0.938$Time Series Classification#AUSLAN#Accuracy#0.993$Time Series Classification#AUSLAN#Accuracy#0.969$Time Series Classification#SHAPES#Accuracy#1$Time Series Classification#CharacterTrajectories#Accuracy#0.994$Time Series Classification#CharacterTrajectories#Accuracy#0.957$Time Series Classification#ECG#Accuracy#0.860$Time Series Classification#ECG#Accuracy#0.842$Time Series Classification#Libras#Accuracy#0.957$Time Series Classification#Libras#Accuracy#0.773$Time Series Classification#ArabicDigits#Accuracy#0.993$Time Series Classification#ArabicDigits#Accuracy#0.968$Time Series Classification#PEMS#Accuracy#0.857$Time Series Classification#PEMS#Accuracy#0.747$Time Series Classification#JapaneseVowels#Accuracy#0.980$Time Series Classification#JapaneseVowels#Accuracy#0.979$Time Series Classification#CMUsubject16#Accuracy#1
1806.02920v1.pdf	Multivariate Time Series Imputation#KDD CUP Challenge 2018#MSE (10% missing)#0.378
1901.10946v3.pdf	Multivariate Time Series Imputation#PEMS-SF#L2 Loss (10^-4)#3.54$Multivariate Time Series Imputation#Basketball Players Movement#Path Length#0.573$Multivariate Time Series Imputation#Basketball Players Movement#OOB Rate (10^−3)#1.733$Multivariate Time Series Imputation#Basketball Players Movement#Step Change (10^−3)#2.565$Multivariate Time Series Imputation#Basketball Players Movement#Path Difference#0.581$Multivariate Time Series Imputation#Basketball Players Movement#Player Distance#0.423
1805.10572v1.pdf	Multivariate Time Series Imputation#PEMS-SF#L2 Loss (10^-4)#4.51$Multivariate Time Series Imputation#UCI localization data#MAE (10% missing)#0.219$Multivariate Time Series Imputation#PhysioNet Challenge 2012#MAE (10% of data as GT)#0.281$Multivariate Time Series Imputation#Basketball Players Movement#Path Length#0.702$Multivariate Time Series Imputation#Basketball Players Movement#OOB Rate (10^−3)#3.874$Multivariate Time Series Imputation#Basketball Players Movement#Step Change (10^−3)#4.811$Multivariate Time Series Imputation#Basketball Players Movement#Path Difference#0.571$Multivariate Time Series Imputation#Basketball Players Movement#Player Distance#0.417$Multivariate Time Series Imputation#Beijing Multi-Site Air-Quality Dataset#MAE (PM2.5)#11.56$Multivariate Time Series Forecasting#USHCN-Daily#MSE#0.53$Multivariate Time Series Forecasting#MIMIC-III#MSE#0.79$Multivariate Time Series Forecasting#MIMIC-III#NegLL#1.16$Traffic Data Imputation#METR-LA Point Missing#MAE#2.34$Traffic Data Imputation#PEMS-BAY Point Missing#MAE#1.47
2202.08516v2.pdf	Multivariate Time Series Imputation#Electricity#MAE (100 steps, 10% data missing)#0.735$Multivariate Time Series Imputation#PhysioNet Challenge 2012#MAE (10% of data as GT)#0.186
1711.08742v1.pdf	Multivariate Time Series Imputation#UCI localization data#MAE (10% missing)#0.248$Multivariate Time Series Imputation#PhysioNet Challenge 2012#MAE (10% of data as GT)#0.451$Multivariate Time Series Imputation#Beijing Multi-Site Air-Quality Dataset#MAE (PM2.5)#14.24
1907.03907v1.pdf	Multivariate Time Series Imputation#PhysioNet Challenge 2012#mse (10^-3)#2.118$Multivariate Time Series Imputation#PhysioNet Challenge 2012#mse (10^-3)#2.789$Multivariate Time Series Imputation#MuJoCo#MSE (10^2, 50% missing)#0.285$Multivariate Time Series Imputation#MuJoCo#MSE (10^2, 50% missing)#0.665$Time Series Classification#PhysioNet Challenge 2012#AUC#83.3%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.9%$Time Series Classification#PhysioNet Challenge 2012#AUC#82.9%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.4%$Time Series Classification#PhysioNet Challenge 2012#AUC#82.6%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.7%$Multivariate Time Series Forecasting#MuJoCo#MSE (10^-2, 50% missing)#1.258$Multivariate Time Series Forecasting#MuJoCo#MSE (10^-2, 50% missing)#26.463$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#mse (10^-3)#2.208$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#MSE stdev#0.050$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#mse (10^-3)#2.231$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#MSE stdev#0.029
1806.07366v5.pdf	Multivariate Time Series Imputation#PhysioNet Challenge 2012#mse (10^-3)#3.907$Multivariate Time Series Imputation#PhysioNet Challenge 2012#mse (10^-3)#5.930$Multivariate Time Series Imputation#MuJoCo#MSE (10^2, 50% missing)#0.447$Multivariate Time Series Imputation#MuJoCo#MSE (10^2, 50% missing)#6.100$Multivariate Time Series Forecasting#MuJoCo#MSE (10^-2, 50% missing)#1.377$Multivariate Time Series Forecasting#MuJoCo#MSE (10^-2, 50% missing)#1.782$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#mse (10^-3)#3.055$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#MSE stdev#0.145$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#mse (10^-3)#3.162$Multivariate Time Series Forecasting#PhysioNet Challenge 2012#MSE stdev#0.052$Multivariate Time Series Forecasting#USHCN-Daily#MSE#0.83$Multivariate Time Series Forecasting#USHCN-Daily#MSE#0.96$Multivariate Time Series Forecasting#MIMIC-III#MSE#0.89$Multivariate Time Series Forecasting#MIMIC-III#NegLL#1.35$Multivariate Time Series Forecasting#MIMIC-III#NegLL#1.36
1801.07736v3.pdf	Multivariate Time Series Imputation#Basketball Players Movement#Path Length#0.793$Multivariate Time Series Imputation#Basketball Players Movement#OOB Rate (10^−3)#4.592$Multivariate Time Series Imputation#Basketball Players Movement#Step Change (10^−3)#9.622$Multivariate Time Series Imputation#Basketball Players Movement#Path Difference#0.680$Multivariate Time Series Imputation#Basketball Players Movement#Player Distance#0.427
2108.00298v3.pdf	Multivariate Time Series Imputation#Beijing Multi-Site Air-Quality Dataset#MAE (PM2.5)#10.51$Traffic Data Imputation#METR-LA Point Missing#MAE#1.91$Traffic Data Imputation#PEMS-BAY Point Missing#MAE#0.67
1606.01865v2.pdf	Multivariate Time Series Imputation#MuJoCo#MSE (10^2, 50% missing)#0.748$Time Series Classification#PhysioNet Challenge 2012#AUC#84.24%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.012%$Multivariate Time Series Forecasting#MuJoCo#MSE (10^-2, 50% missing)#5.833
2210.05357v1.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.859$Video Quality Assessment#LIVE-VQC#PLCC#0.858$Video Quality Assessment#LIVE-FB LSVQ#PLCC#0.874$Video Quality Assessment#KoNViD-1k#PLCC#0.898
2207.02595v1.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.852$Video Quality Assessment#YouTube-UGC#PLCC#0.748$Video Quality Assessment#LIVE-VQC#PLCC#0.862$Video Quality Assessment#LIVE-VQC#PLCC#0.844$Video Quality Assessment#LIVE-FB LSVQ#PLCC#0.877$Video Quality Assessment#KoNViD-1k#PLCC#0.892$Video Quality Assessment#KoNViD-1k#PLCC#0.855
2108.08505v2.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.8178$Video Quality Assessment#LIVE-VQC#PLCC#0.839$Video Quality Assessment#LIVE-FB LSVQ#PLCC#0.854$Video Quality Assessment#KoNViD-1k#PLCC#0.834
2208.14774v1.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.794$Video Quality Assessment#LIVE-VQC#PLCC#0.832$Video Quality Assessment#KoNViD-1k#PLCC#0.835
2005.14354v2.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.7733$Video Quality Assessment#LIVE-VQC#PLCC#0.7514$Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.7536$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.7697$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.5787$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR$Video Quality Assessment#LIVE-FB LSVQ#PLCC#0.783$Video Quality Assessment#KoNViD-1k#PLCC#0.7803
2101.10955v2.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.7684$Video Quality Assessment#LIVE-VQC#PLCC#0.7863$Video Quality Assessment#LIVE Livestream#SRCC#0.4899$Video Quality Assessment#KoNViD-1k#PLCC#0.8175
2109.08726v1.pdf	Video Quality Assessment#YouTube-UGC#PLCC#0.6911$Video Quality Assessment#LIVE-VQC#PLCC#0.7299$Video Quality Assessment#LIVE-ETRI#SRCC#0.6323$Video Quality Assessment#LIVE Livestream#SRCC#0.7808$Video Quality Assessment#KoNViD-1k#PLCC#0.7625
2011.13544v2.pdf	Video Quality Assessment#LIVE-VQC#PLCC#0.791$Video Quality Assessment#LIVE-FB LSVQ#PLCC#0.827$Video Quality Assessment#KoNViD-1k#PLCC#0.770
1908.00375v3.pdf	Video Quality Assessment#LIVE-VQC#PLCC#0.7426$Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.9139$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.9242$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.7826$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR$Video Quality Assessment#KoNViD-1k#PLCC#0.7754
2008.00031v3.pdf	Video Quality Assessment#LIVE-ETRI#SRCC#0.4028$Video Quality Assessment#LIVE Livestream#SRCC#0.7513
2011.04263v2.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.9358$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.9473$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.8199$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR
2008.03889v1.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.9205$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.9267$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.7976$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR
1912.10088v1.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.8902$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.8904$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.7526$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR
1910.06180v2.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.8644$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.8819$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.7164$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR
1709.05424v2.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.8534$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.8920$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.6943$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#NR$Aesthetics Quality Assessment#AVA#Accuracy#81.5%
2004.07728v3.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.8392$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.9028$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.6794$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#FR
2010.13715v2.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.7547$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.8116$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.5905$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#FR$Video Quality Assessment#LIVE-YT-HFR#SRCC#0.8822
1801.03924v2.pdf	Video Quality Assessment#MSU Video Quality Metrics Benchmark#SRCC#0.7538$Video Quality Assessment#MSU Video Quality Metrics Benchmark#PLCC#0.8128$Video Quality Assessment#MSU Video Quality Metrics Benchmark#KLCC#0.5846$Video Quality Assessment#MSU Video Quality Metrics Benchmark#Type#FR
2109.12785v1.pdf	Video Quality Assessment#LIVE-YT-HFR#SRCC#0.8658
2006.11424v2.pdf	Video Quality Assessment#LIVE-YT-HFR#SRCC#0.8064
1803.08489v1.pdf	Image Quality Assessment#KonIQ-10k#SRCC#0.921
1411.5014v1.pdf	No-Reference Image Quality Assessment#200k Short Texts for Humor Detection#14 gestures accuracy#kindness
2104.03133v2.pdf	Aesthetics Quality Assessment#CADB#MSE#0.3867$Aesthetics Quality Assessment#CADB#EMD#0.1798$Aesthetics Quality Assessment#CADB#SRCC#0.6564$Aesthetics Quality Assessment#CADB#LCCAll#0.6709
1704.00248v1.pdf	Aesthetics Quality Assessment#AVA#Accuracy#82.5%
1904.01382v1.pdf	Aesthetics Quality Assessment#AVA#Accuracy#81.7%
1604.04970v3.pdf	Aesthetics Quality Assessment#AVA#Accuracy#79.1%
1606.01621v2.pdf	Aesthetics Quality Assessment#AVA#Accuracy#77.3%
2205.14871v4.pdf	Image Enhancement#Exposure-Errors#PSNR#20.34$Image Enhancement#Exposure-Errors#SSIM#0.844$Low-Light Image Enhancement#LOL#Average PSNR#23.38$Low-Light Image Enhancement#LOL#SSIM#0.809
2003.11596v3.pdf	Image Enhancement#Exposure-Errors#PSNR#20.205$Image Enhancement#Exposure-Errors#SSIM#0.769
1911.13175v4.pdf	Image Enhancement#MIT-Adobe 5k#LPIPS#0.108$Image Enhancement#MIT-Adobe 5k#PSNR#24.2$Image Enhancement#MIT-Adobe 5k#SSIM#0.88
2207.09935v1.pdf	Image Enhancement#TIP 2018#PSNR#30.11$Image Enhancement#TIP 2018#SSIM#0.920$Image Enhancement#TIP 2018#PSNR#29.81$Image Enhancement#TIP 2018#SSIM#0.916$Image Restoration#UHDM#PSNR#22.422$Image Restoration#UHDM#PSNR#22.119
2004.00406v1.pdf	Image Enhancement#TIP 2018#PSNR#30.03$Image Enhancement#TIP 2018#SSIM#0.893
1805.02996v1.pdf	Image Enhancement#TIP 2018#PSNR#26.77$Image Enhancement#TIP 2018#SSIM#0.871$Image Enhancement#TIP 2018#FSIM#0.914
1908.00682v3.pdf	Low-Light Image Enhancement#3DMatch Benchmark#mAP (@0.1, Through-wall)#224
2001.06826v2.pdf	Low-Light Image Enhancement#VV#User Study Score#3.24$Low-Light Image Enhancement#LIME#User Study Score#3.8$Low-Light Image Enhancement#DICM#User Study Score#3.52$Low-Light Image Enhancement#MEF#User Study Score#4.13$Low-Light Image Enhancement#NPE#User Study Score#3.81
1906.06972v2.pdf	Low-Light Image Enhancement#VV#User Study Score#3.17$Low-Light Image Enhancement#AFLW (Zhang CVPR 2018 crops)#14 gestures accuracy#1$Low-Light Image Enhancement#DICM#User Study Score#3.50$Low-Light Image Enhancement#MEF#User Study Score#3.75
1808.04560v1.pdf	Low-Light Image Enhancement#VV#User Study Score#1.96$Low-Light Image Enhancement#DICM#User Study Score#2.88$Low-Light Image Enhancement#MEF#User Study Score#2.80
2111.15557v1.pdf	Low-Light Image Enhancement#VV#NIQE#3.671$Low-Light Image Enhancement#DICM#NIQE#3.0869$Low-Light Image Enhancement#LOL#Average PSNR#22.96$Low-Light Image Enhancement#LOL#SSIM#0.838$Low-Light Image Enhancement#LOL#NIQE#3.946$Low-Light Image Enhancement#LOL#DeltaE#11.19$Low-Light Image Enhancement#NPE#NIQE#3.4596
2112.01766v1.pdf	Low-Light Image Enhancement#DICM#NIQE#3.425$Low-Light Image Enhancement#LOL#Average PSNR#20.23$Low-Light Image Enhancement#MEF#NIQE#3.188
2109.05923v1.pdf	Low-Light Image Enhancement#LOL#Average PSNR#25.19$Low-Light Image Enhancement#LOL#SSIM#0.93$Low-Light Image Enhancement#LOL#LPIPS#0.11
2203.01296v1.pdf	Low-Light Image Enhancement#LOL#Average PSNR#24.24$Low-Light Image Enhancement#LOL#SSIM#0.852$Low-Light Image Enhancement#LOL#LPIPS#0.12
2207.10564v2.pdf	Low-Light Image Enhancement#LOL#Average PSNR#21.52$Low-Light Image Enhancement#LOL#SSIM#0.763
1905.04161v1.pdf	Low-Light Image Enhancement#LOL#Average PSNR#20.8665
2105.02209v1.pdf	Image Relighting#VIDIT’20 validation set#PSNR#17.62$Image Relighting#VIDIT’20 validation set#SSIM#0.6645$Image Relighting#VIDIT’20 validation set#LPIPS#0.2733$Image Relighting#VIDIT’20 validation set#MPS#0.6956$Image Relighting#VIDIT’20 validation set#Runtime(s)#0.53
2008.08298v2.pdf	Image Relighting#VIDIT’20 validation set#PSNR#17.59$Image Relighting#VIDIT’20 validation set#SSIM#0.596$Image Relighting#VIDIT’20 validation set#LPIPS#0.440$Image Relighting#VIDIT’20 validation set#MPS#0.578$Image Relighting#VIDIT’20 validation set#Runtime(s)#0.5
2009.06678v1.pdf	Image Relighting#VIDIT’20 validation set#PSNR#17.45$Image Relighting#VIDIT’20 validation set#SSIM#0.6642$Image Relighting#VIDIT’20 validation set#LPIPS#0.2771$Image Relighting#VIDIT’20 validation set#MPS#0.6935$Image Relighting#VIDIT’20 validation set#Runtime(s)#0.05
2102.09242v2.pdf	Image Relighting#VIDIT’20 validation set#PSNR#17.20$Image Relighting#VIDIT’20 validation set#SSIM#0.5696$Image Relighting#VIDIT’20 validation set#LPIPS#0.3712$Image Relighting#VIDIT’20 validation set#MPS#0.5992$Image Relighting#VIDIT’20 validation set#Runtime(s)#0.0058
2108.12818v1.pdf	Local Color Enhancement#University of Waterloo skin cancer database#Dice (Average)#0.40 ± 0.27
2109.00886v1.pdf	Local Color Enhancement#University of Waterloo skin cancer database#Dice (Average)#0.30 ± 0.20
1811.08747v2.pdf	Rain Removal#DID-MDN#PSNR#31.68$Image Dehazing#SOTS Indoor#PSNR#30.23$Image Dehazing#SOTS Indoor#SSIM#0.98$Image Dehazing#RS-Haze#PSNR#34.41$Image Dehazing#RS-Haze#SSIM#0.949
1901.09221v3.pdf	Single Image Deraining#Rain1400#PSNR#32.44$Single Image Deraining#Rain1400#SSIM#0.9440000000000001$Single Image Deraining#Test100#PSNR#24.81$Single Image Deraining#Rain100H#PSNR#29.46$Single Image Deraining#Rain100H#SSIM#0.899$Single Image Deraining#Test2800#SSIM#0.916$Single Image Deraining#Test1200#PSNR#31.36$Single Image Deraining#Rain100L#PSNR#37.48$Single Image Deraining#Rain100L#SSIM#0.979$Single Image Deraining#Rain12#PSNR#36.66
2009.13990v4.pdf	Single Image Deraining#RainCityscapes#PSNR#35.82$Single Image Deraining#RainCityscapes#SSIM#0.987$Single Image Deraining#Rain100H#PSNR#30.70$Single Image Deraining#Rain100H#SSIM#0.922$Single Image Deraining#Rain100L#PSNR#39.73$Single Image Deraining#Rain100L#SSIM#0.988
1904.01538v2.pdf	Single Image Deraining#RainCityscapes#PSNR#31.48$Single Image Deraining#RainCityscapes#SSIM#0.9656
1802.07412v1.pdf	Single Image Deraining#RainCityscapes#PSNR#28.43$Single Image Deraining#RainCityscapes#SSIM#0.9349$Single Image Deraining#Test100#PSNR#22.56$Single Image Deraining#Test100#SSIM#0.818$Single Image Deraining#Rain100H#PSNR#17.35$Single Image Deraining#Rain100H#SSIM#0.524$Single Image Deraining#Test2800#PSNR#28.13$Single Image Deraining#Test2800#SSIM#0.867$Single Image Deraining#Test1200#PSNR#29.65$Single Image Deraining#Test1200#SSIM#0.901$Single Image Deraining#Rain100L#PSNR#25.23$Single Image Deraining#Rain100L#SSIM#0.741
2003.10985v2.pdf	Single Image Deraining#Test100#PSNR#27.50$Single Image Deraining#Test100#SSIM#0.876$Single Image Deraining#Rain100H#PSNR#28.66$Single Image Deraining#Rain100H#SSIM#0.86$Single Image Deraining#Test2800#PSNR#32.82$Single Image Deraining#Test2800#SSIM#0.930$Single Image Deraining#Test1200#PSNR#32.39$Single Image Deraining#Test1200#SSIM#0.916$Single Image Deraining#Rain100L#PSNR#32.40$Single Image Deraining#Rain100L#SSIM#0.933
1807.05698v2.pdf	Single Image Deraining#Test100#PSNR#25.00$Single Image Deraining#Test100#SSIM#0.835$Single Image Deraining#Rain100H#PSNR#26.36$Single Image Deraining#Rain100H#SSIM#0.786$Single Image Deraining#Test2800#PSNR#31.29$Single Image Deraining#Test2800#SSIM#0.904$Single Image Deraining#Test1200#PSNR#30.51$Single Image Deraining#Test1200#SSIM#0.882$Single Image Deraining#Rain100L#PSNR#29.80$Single Image Deraining#Rain100L#SSIM#0.881
1906.11129v1.pdf	Single Image Deraining#Test100#PSNR#24.41$Single Image Deraining#Test100#SSIM#0.829$Single Image Deraining#Rain100H#PSNR#26.01$Single Image Deraining#Rain100H#SSIM#0.832$Single Image Deraining#Test2800#PSNR#29.97$Single Image Deraining#Test2800#SSIM#0.905$Single Image Deraining#Test1200#PSNR#30.55$Single Image Deraining#Test1200#SSIM#0.910$Single Image Deraining#Rain100L#PSNR#29.18$Single Image Deraining#Rain100L#SSIM#0.923
1609.02087v2.pdf	Single Image Deraining#Test100#PSNR#22.77$Single Image Deraining#Test100#SSIM#0.810$Single Image Deraining#Rain100H#PSNR#14.92$Single Image Deraining#Rain100H#SSIM#0.592$Single Image Deraining#Test2800#PSNR#24.31$Single Image Deraining#Test2800#SSIM#0.861$Single Image Deraining#Test1200#PSNR#23.38$Single Image Deraining#Test1200#SSIM#0.835$Single Image Deraining#Rain100L#PSNR#27.03$Single Image Deraining#Rain100L#SSIM#0.884
1807.11078v2.pdf	Single Image Deraining#Test100#PSNR#22.35$Single Image Deraining#Test100#SSIM#0.788$Single Image Deraining#Rain100H#PSNR#16.56$Single Image Deraining#Rain100H#SSIM#0.486$Single Image Deraining#Test2800#PSNR#24.43$Single Image Deraining#Test2800#SSIM#0.782$Single Image Deraining#Test1200#PSNR#26.05$Single Image Deraining#Test1200#SSIM#0.822$Single Image Deraining#Rain100L#PSNR#25.03$Single Image Deraining#Rain100L#SSIM#0.842
2111.14813v2.pdf	Single Image Deraining#Raindrop#PSNR#34.55
2109.07100v3.pdf	Image Dehazing#NH-HAZE#PSNR#24.26$Image Dehazing#NH-HAZE#PSNR#22.13
2008.06713v1.pdf	Image Dehazing#O-Haze#PSNR#24.27$Image Dehazing#O-Haze#SSIM#0.8919$Image Dehazing#I-Haze#SSIM#0.8994$Image Dehazing#I-Haze#PSNR#22.56$Image Dehazing#Dense-Haze#SSIM#0.613$Image Dehazing#Dense-Haze#PSNR#17.01
2202.04757v1.pdf	Image Dehazing#O-Haze#PSNR#23.46$Image Dehazing#O-Haze#SSIM#0.8198$Image Dehazing#I-Haze#SSIM#0.8270$Image Dehazing#I-Haze#PSNR#22.90$Image Dehazing#Dense-Haze#SSIM#0.5200$Image Dehazing#Dense-Haze#PSNR#15.43
1805.05308v1.pdf	Image Dehazing#O-Haze#PSNR#19.62$Image Dehazing#O-Haze#SSIM#0.67
1911.07559v2.pdf	Image Dehazing#KITTI#PSNR#27.45$Image Dehazing#SOTS Indoor#PSNR#36.39$Image Dehazing#SOTS Indoor#SSIM#0.989$Image Dehazing#RESIDE-6K#PSNR#29.96$Image Dehazing#RESIDE-6K#SSIM#0.973$Image Dehazing#RS-Haze#PSNR#39.39$Image Dehazing#RS-Haze#SSIM#0.969$Image Dehazing#SOTS Outdoor#PSNR#33.57$Image Dehazing#SOTS Outdoor#SSIM#0.9804$Image Dehazing#Haze4k#PSNR#26.96$Image Dehazing#Haze4k#SSIM#0.95
1911.08415v2.pdf	Image Dehazing#KITTI#PSNR#24.64$Traffic Prediction#PEMS-BAY#MAE @ 12 step#1.86$Traffic Prediction#PEMS-BAY#RMSE#4.32
2008.10325v1.pdf	Image Dehazing#KITTI#PSNR#18.32$Image Dehazing#RESIDE#PSNR#17.07
2204.03883v1.pdf	Image Dehazing#SOTS Indoor#PSNR#40.05$Image Dehazing#SOTS Indoor#SSIM#0.996$Image Dehazing#RESIDE-6K#PSNR#31.45$Image Dehazing#RESIDE-6K#SSIM#0.98$Image Dehazing#RS-Haze#PSNR#39.87$Image Dehazing#RS-Haze#SSIM#0.971$Image Dehazing#SOTS Outdoor#PSNR#34.95$Image Dehazing#SOTS Outdoor#SSIM#0.984
2111.09733v1.pdf	Image Dehazing#SOTS Indoor#PSNR#38.41$Image Dehazing#SOTS Indoor#SSIM#0.99$Image Dehazing#Haze4k#PSNR#33.49$Image Dehazing#Haze4k#SSIM#0.98
2104.09367v1.pdf	Image Dehazing#SOTS Indoor#PSNR#37.17$Image Dehazing#SOTS Indoor#SSIM#0.990$Image Dehazing#RS-Haze#PSNR#35.69
2112.02279v2.pdf	Image Dehazing#SOTS Indoor#PSNR#36.42$Image Dehazing#SOTS Indoor#SSIM#0.988$Image Dehazing#SOTS Outdoor#PSNR#31.10$Image Dehazing#SOTS Outdoor#SSIM#0.976
1908.03245v1.pdf	Image Dehazing#SOTS Indoor#PSNR#32.16$Image Dehazing#SOTS Indoor#SSIM#0.984$Image Dehazing#RS-Haze#PSNR#36.4$Image Dehazing#RS-Haze#SSIM#0.96$Image Dehazing#SOTS Outdoor#PSNR#30.86$Image Dehazing#SOTS Outdoor#SSIM#0.982$Image Dehazing#Haze4k#PSNR#23.29$Image Dehazing#Haze4k#SSIM#0.93
1804.00213v1.pdf	Image Dehazing#SOTS Indoor#PSNR#22.30$Image Dehazing#SOTS Indoor#SSIM#0.880$Image Dehazing#SOTS Outdoor#PSNR#22.30$Image Dehazing#SOTS Outdoor#SSIM#0.880
1810.02862v2.pdf	Image Dehazing#SOTS Indoor#PSNR#20.53$Image Dehazing#SOTS Indoor#SSIM#0.8081$Image Dehazing#SOTS Outdoor#PSNR#28.19$Image Dehazing#SOTS Outdoor#SSIM#0.9638
1812.07051v2.pdf	Image Dehazing#SOTS Indoor#PSNR#19.25$Image Dehazing#SOTS Indoor#SSIM#0.832$Image Dehazing#SOTS Outdoor#PSNR#24.08$Image Dehazing#SOTS Outdoor#SSIM#0.933
2005.04668v1.pdf	Image Dehazing#RESIDE-6K#PSNR#27.76$Image Dehazing#RESIDE-6K#SSIM#0.93
1601.07661v2.pdf	Image Dehazing#RS-Haze#PSNR#23.16$Image Dehazing#RS-Haze#SSIM#0.816
1805.12355v2.pdf	Image Dehazing#SOTS Outdoor#PSNR#24.07$Image Dehazing#SOTS Outdoor#SSIM#0.933
2209.11448v1.pdf	Image Dehazing#Haze4k#PSNR#33.52$Image Dehazing#Haze4k#SSIM#0.988
2108.02934v1.pdf	Image Dehazing#Haze4k#PSNR#28.53$Image Dehazing#Haze4k#SSIM#0.96
1506.02640v5.pdf	Real-Time Object Detection#PASCAL VOC 2007#MAP#63.4%$Real-Time Object Detection#PASCAL VOC 2007#FPS#46.0$Object Counting#CARPK#MAE#156.00$Object Counting#CARPK#RMSE#57.55$Object Detection#PASCAL VOC 2007#MAP#63.4%$Object Detection#PASCAL VOC 2012#MAP#57.9
1708.02813v1.pdf	Real-Time Object Detection#PASCAL VOC 2007#MAP#79.1%$Real-Time Object Detection#PASCAL VOC 2007#FPS#24$Real-Time Object Detection#PASCAL VOC 2007#MAP#81.5%$Real-Time Object Detection#PASCAL VOC 2007#FPS#19.5$Object Detection#PASCAL VOC 2007#MAP#81.5%
1605.06409v2.pdf	Real-Time Object Detection#PASCAL VOC 2007#MAP#80.5%$Real-Time Object Detection#PASCAL VOC 2007#FPS#9$Object Detection#UA-DETRAC#mAP#69.87
1506.01497v3.pdf	Real-Time Object Detection#PASCAL VOC 2007#MAP#73.2%$Real-Time Object Detection#PASCAL VOC 2007#FPS#7.0$Object Counting#CARPK#MAE#39.88$Object Counting#CARPK#RMSE#47.67$Object Detection#PASCAL VOC 2007#MAP#73.2%$Object Detection#UA-DETRAC#mAP#58.45
2203.03605v4.pdf	Real-Time Object Detection#COCO 2017 val#FPS (V100, b=1)#10$Real-Time Object Detection#COCO 2017 val#FPS#10$Object Detection#COCO test-dev#box AP#63.3$Object Detection#COCO 2017 val#AP50#66.9$Object Detection#COCO 2017 val#AP75#53.8$Object Detection#COCO 2017 val#box AP#49.4$Object Detection#COCO 2017 val#box AP#63.2$Object Detection#COCO minival#box AP#63.2
2107.08430v2.pdf	Real-Time Object Detection#Argoverse-HD (Detection-Only, Test)#AP#41.1$Real-Time Object Detection#COCO#FPS (V100, b=1)#62.5$Real-Time Object Detection#COCO#box AP#50.4$Real-Time Object Detection#COCO#FPS (V100, b=1)#69$Real-Time Object Detection#COCO#box AP#50$Real-Time Object Detection#COCO#FPS (V100, b=1)#81.3$Real-Time Object Detection#COCO#box AP#46.4$Real-Time Object Detection#COCO#FPS (V100, b=1)#90.1$Real-Time Object Detection#COCO#box AP#44.5$Real-Time Object Detection#Argoverse-HD (Detection-Only, Val)#AP#47.42$Real-Time Object Detection#Argoverse-HD (Full-Stack, Test)#AP#41.1$Object Detection#COCO test-dev#box AP#51.5$Object Detection#COCO test-dev#box AP#51.2$Object Detection#COCO test-dev#AP#51.2$Object Detection#COCO test-dev#AP50#69.6$Object Detection#COCO test-dev#AP75#55.7$Object Detection#COCO test-dev#APS#31.2$Object Detection#COCO test-dev#APM#56.1$Object Detection#COCO test-dev#APL#66.1$Object Detection#COCO test-dev#Params (M)#99.1$Object Detection#COCO test-dev#box AP#48.0$Object Detection#COCO test-dev#box AP#32.8$Object Detection#COCO test-dev#Params (M)#5.06$Object Detection#COCO test-dev#box AP#25.8$Object Detection#COCO test-dev#Params (M)#0.91
2106.05665v1.pdf	Real-Time Object Detection#Argoverse-HD (Detection-Only, Test)#AP#17.98$Real-Time Object Detection#Argoverse-HD (Full-Stack, Val)#AP#26.01$Real-Time Object Detection#Argoverse-HD (Full-Stack, Test)#AP#26.99
2005.10420v2.pdf	Real-Time Object Detection#Argoverse-HD (Detection-Only, Test)#AP#13.61$Real-Time Object Detection#Argoverse-HD (Full-Stack, Val)#AP#21.06$Real-Time Object Detection#Argoverse-HD (Detection-Only, Val)#AP#14.91$Real-Time Object Detection#Argoverse-HD (Full-Stack, Test)#AP#21.06
2207.02696v1.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#36$Real-Time Object Detection#COCO#box AP#56.8$Real-Time Object Detection#COCO#FPS#36$Real-Time Object Detection#COCO#FPS (V100, b=1)#44$Real-Time Object Detection#COCO#box AP#56.6$Real-Time Object Detection#COCO#FPS#44$Real-Time Object Detection#COCO#FPS (V100, b=1)#56$Real-Time Object Detection#COCO#box AP#56$Real-Time Object Detection#COCO#FPS#56$Real-Time Object Detection#COCO#FPS (V100, b=1)#84$Real-Time Object Detection#COCO#box AP#54.9$Real-Time Object Detection#COCO#FPS#84$Real-Time Object Detection#COCO#FPS (V100, b=1)#114$Real-Time Object Detection#COCO#box AP#53.1$Real-Time Object Detection#COCO#FPS#114$Real-Time Object Detection#COCO#FPS (V100, b=1)#161$Real-Time Object Detection#COCO#box AP#51.4$Real-Time Object Detection#COCO#FPS#161$Real-Time Object Detection#COCO#FPS (V100, b=1)#286$Real-Time Object Detection#COCO#box AP#38.7$Real-Time Object Detection#COCO#FPS#286$Object Detection#COCO test-dev#box AP#56.8$Object Detection#COCO test-dev#AP50#74.4$Object Detection#COCO test-dev#AP75#62.1$Object Detection#COCO test-dev#box AP#56.6$Object Detection#COCO test-dev#box AP#56$Object Detection#COCO test-dev#box AP#54.9$Object Detection#COCO test-dev#box AP#53.1$Object Detection#COCO test-dev#box AP#51.4$Object Detection#COCO test-dev#box AP#38.7$Object Detection#COCO minival#box AP#56.8
2203.16250v2.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#45.0$Real-Time Object Detection#COCO#box AP#54.7$Real-Time Object Detection#COCO#FPS (V100, b=1)#78.1$Real-Time Object Detection#COCO#box AP#52.9$Real-Time Object Detection#COCO#box AP#52.4$Real-Time Object Detection#COCO#box AP#51.6$Real-Time Object Detection#COCO#FPS (V100, b=1)#123.4$Real-Time Object Detection#COCO#box AP#49.1$Real-Time Object Detection#COCO#FPS (V100, b=1)#208.3$Real-Time Object Detection#COCO#box AP#43.6$Multi-Object Tracking#MOT16#MOTA#77.7$Multiple Object Tracking#CroHD#MOTA#72.6$Online Multi-Object Tracking#MOT16#MOTA#77.7$Object Detection#COCO test-dev#box AP#52.2$Object Detection#COCO test-dev#AP50#69.9$Object Detection#COCO test-dev#AP75#56.5$Object Detection#COCO test-dev#APS#33.3$Object Detection#COCO test-dev#APM#56.3$Object Detection#COCO test-dev#APL#66.4$Object Detection#COCO test-dev#box AP#51.4$Object Detection#COCO test-dev#AP50#68.9$Object Detection#COCO test-dev#AP75#55.6$Object Detection#COCO test-dev#APS#31.4$Object Detection#COCO test-dev#APM#55.3$Object Detection#COCO test-dev#APL#66.1$Object Detection#COCO test-dev#box AP#48.9$Object Detection#COCO test-dev#AP50#66.5$Object Detection#COCO test-dev#AP75#53.0$Object Detection#COCO test-dev#APS#28.6$Object Detection#COCO test-dev#APM#52.9$Object Detection#COCO test-dev#APL#63.8$Object Detection#COCO test-dev#box AP#43.1$Object Detection#COCO test-dev#AP50#60.5$Object Detection#COCO test-dev#AP75#46.6$Object Detection#COCO test-dev#APS#23.2$Object Detection#COCO test-dev#APM#46.4$Object Detection#COCO test-dev#APL#56.9$Object Detection#BDD100K#mAP@0.5#59.7$Object Detection#VisDrone-DET2019#AP50#66.7$2D object detection#BDD100K#mAP#35.6
2107.00420v7.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#6.5$Real-Time Object Detection#COCO#box AP#53.6$Object Detection#COCO test-dev#box AP#60.1$Object Detection#COCO test-dev#box AP#59.4$Object Detection#COCO minival#box AP#59.6$Object Detection#COCO minival#box AP#59.1$Instance Segmentation#COCO test-dev#mask AP#52.3$Instance Segmentation#COCO test-dev#mask AP#51.6$Instance Segmentation#COCO minival#mask AP#51.8$Instance Segmentation#COCO minival#mask AP#51
2103.14030v2.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#11.6$Real-Time Object Detection#COCO#box AP#51.9$Semantic Segmentation#FoodSeg103#mIoU#41.6$Semantic Segmentation#ADE20K#Validation mIoU#53.50$Semantic Segmentation#ADE20K#Test Score#62.8$Semantic Segmentation#ADE20K#Validation mIoU#49.7$Semantic Segmentation#ADE20K val#mIoU#53.5$Semantic Segmentation#ADE20K val#mIoU#49.7$Thermal Image Segmentation#MFN Dataset#mIOU#49.0$Object Detection#COCO test-dev#box AP#58.7$Object Detection#COCO test-dev#box AP#57.7$Object Detection#COCO minival#box AP#58$Object Detection#COCO minival#box AP#57.1$Image Classification#ImageNet#Top 1 Accuracy#87.3%$Image Classification#ImageNet#Number of params#197M$Image Classification#ImageNet#GFLOPs#103.9$Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#GFLOPs#47$Image Classification#ImageNet#Top 1 Accuracy#81.3%$Image Classification#ImageNet#Number of params#29M$Image Classification#ImageNet#GFLOPs#4.5$Image Classification#OmniBenchmark#Average Top-1 Accuracy#46.4$Instance Segmentation#COCO test-dev#mask AP#51.1$Instance Segmentation#COCO test-dev#mask AP#50.2$Instance Segmentation#Occluded COCO#Mean Recall#62.90$Instance Segmentation#Occluded COCO#Mean Recall#61.14$Instance Segmentation#Occluded COCO#Mean Recall#58.81$Instance Segmentation#Separated COCO#Mean Recall#36.31$Instance Segmentation#Separated COCO#Mean Recall#33.67$Instance Segmentation#Separated COCO#Mean Recall#31.94$Instance Segmentation#COCO minival#mask AP#50.4$Instance Segmentation#COCO minival#mask AP#49.5
2205.08534v3.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#4.4$Real-Time Object Detection#COCO#box AP#50.8$Semantic Segmentation#Cityscapes val#mIoU#85.8$Semantic Segmentation#ADE20K#Validation mIoU#60.5$Semantic Segmentation#ADE20K#Params (M)#571$Semantic Segmentation#ADE20K#Validation mIoU#58.4$Semantic Segmentation#ADE20K#Params (M)#451$Semantic Segmentation#ADE20K val#mIoU#60.5$Semantic Segmentation#ADE20K val#mIoU#58.4$Semantic Segmentation#COCO-Stuff test#mIoU#54.2%$Semantic Segmentation#COCO-Stuff test#mIoU#51.4%$Semantic Segmentation#PASCAL Context#mIoU#68.2$Semantic Segmentation#PASCAL Context#mIoU#67.5$Semantic Segmentation#Cityscapes test#Mean IoU (class)#85.2%$Object Detection#COCO test-dev#box AP#60.1$Object Detection#COCO minival#box AP#59.8$Instance Segmentation#COCO test-dev#mask AP#52.1$Instance Segmentation#COCO minival#mask AP#51.7
2104.10419v1.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#50.3$Real-Time Object Detection#COCO#box AP#50.3
2010.04159v4.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#19$Real-Time Object Detection#COCO#box AP#46.2$Object Detection#COCO test-dev#box AP#52.3$Object Detection#COCO test-dev#AP50#71.9$Object Detection#COCO test-dev#AP75#58.1$Object Detection#COCO test-dev#APS#34.4$Object Detection#COCO test-dev#APM#54.4$Object Detection#COCO test-dev#APL#65.6$Object Detection#COCO test-dev#Hardware Burden#17G$Object Detection#COCO test-dev#Operations per network pass#17.3G
2005.12872v3.pdf	Real-Time Object Detection#COCO#FPS (V100, b=1)#20$Real-Time Object Detection#COCO#box AP#43.5$Real-Time Object Detection#COCO#FPS (V100, b=1)#26$Real-Time Object Detection#COCO#box AP#42$Panoptic Segmentation#COCO minival#PQ#45.1$Panoptic Segmentation#COCO minival#SQ#79.9$Panoptic Segmentation#COCO minival#RQ#55.5$Panoptic Segmentation#COCO minival#PQth#50.5$Panoptic Segmentation#COCO minival#SQth#80.9$Panoptic Segmentation#COCO minival#RQth#61.7$Panoptic Segmentation#COCO minival#PQst#37$Panoptic Segmentation#COCO minival#SQst#78.5$Panoptic Segmentation#COCO minival#RQst#46$Panoptic Segmentation#COCO minival#AP#33$Panoptic Segmentation#COCO minival#PQ#44.1$Panoptic Segmentation#COCO minival#SQ#79.5$Panoptic Segmentation#COCO minival#RQ#53.3$Panoptic Segmentation#COCO minival#PQth#51.0$Panoptic Segmentation#COCO minival#SQth#83.2$Panoptic Segmentation#COCO minival#RQth#60.6$Panoptic Segmentation#COCO minival#PQst#33.6$Panoptic Segmentation#COCO minival#SQst#74.0$Panoptic Segmentation#COCO minival#RQst#42.1$Panoptic Segmentation#COCO minival#AP#39.7$Object Detection#COCO minival#box AP#44.9$Object Detection#COCO minival#AP50#64.7$Object Detection#COCO minival#AP75#47.7$Object Detection#COCO minival#APS#23.7$Object Detection#COCO minival#APM#49.5$Object Detection#COCO minival#APL#62.3$Object Detection#COCO minival#box AP#44$Object Detection#COCO minival#AP50#63.9$Object Detection#COCO minival#AP75#47.8$Object Detection#COCO minival#APS#27.2$Object Detection#COCO minival#APM#48.1$Object Detection#COCO minival#APL#56
2203.12338v2.pdf	Real-Time Object Detection#Argoverse-HD (Full-Stack, Val)#sAP#42.3
1703.06870v3.pdf	Real-Time Object Detection#COCO minival#APbb75#45.2$Real-Time Object Detection#COCO minival#MAP#37.6$Nuclear Segmentation#Cell17#F1-score#0.8004$Nuclear Segmentation#Cell17#Dice#0.707$Nuclear Segmentation#Cell17#Hausdorff#12.6723$Panoptic Segmentation#Cityscapes val#PQth#54.0$Object Localization#GRIT#Localization (ablation)#44.7$Object Localization#GRIT#Localization (test)#45.1$Pose Estimation#COCO test-dev#AP#63.1$Pose Estimation#COCO test-dev#AP50#87.3$Pose Estimation#COCO test-dev#AP75#68.7$Pose Estimation#COCO test-dev#APL#71.4$Keypoint Detection#COCO#Validation AP#69.2$Keypoint Detection#COCO#Test AP#63.1$Keypoint Detection#COCO test-dev#APL#71.4$Keypoint Detection#COCO test-dev#APM#57.8$Keypoint Detection#COCO test-dev#AP50#87.3$Keypoint Detection#COCO test-dev#AP75#68.7$Keypoint Detection#COCO test-challenge#AR#75.4$Keypoint Detection#COCO test-challenge#ARM#70.2$Keypoint Detection#COCO test-challenge#AP#68.9$Keypoint Detection#COCO test-challenge#AP50#89.2$Keypoint Detection#COCO test-challenge#AP75#75.2$Keypoint Detection#COCO test-challenge#APL#82.6$Keypoint Detection#COCO test-challenge#AR50#93.2$Keypoint Detection#COCO test-challenge#AR75#81.2$Keypoint Detection#COCO test-challenge#ARL#76.8$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#57.2$Multi-Person Pose Estimation#CrowdPose#AP Easy#69.4$Multi-Person Pose Estimation#CrowdPose#AP Medium#57.9$Multi-Person Pose Estimation#CrowdPose#AP Hard#45.8$Multi-Person Pose Estimation#OCHuman#Validation AP#20.2$Multi-Person Pose Estimation#OCHuman#AP50#33.2$Multi-Person Pose Estimation#OCHuman#AP75#24.5$Object Detection#COCO test-dev#box AP#39.8$Object Detection#COCO test-dev#AP50#62.3$Object Detection#COCO test-dev#AP75#43.4$Object Detection#COCO test-dev#APS#22.1$Object Detection#COCO test-dev#APM#43.2$Object Detection#COCO test-dev#APL#51.2$Object Detection#COCO test-dev#Hardware Burden#9G$Object Detection#COCO test-dev#box AP#38.2$Object Detection#COCO test-dev#AP50#60.3$Object Detection#COCO test-dev#AP75#41.7$Object Detection#COCO test-dev#APS#20.1$Object Detection#COCO test-dev#APM#41.1$Object Detection#COCO test-dev#APL#50.2$Object Detection#COCO minival#box AP#40.0$Object Detection#COCO minival#box AP#37.7$Object Detection#COCO minival#box AP#36.7$Object Detection#COCO minival#AP50#59.5$Object Detection#COCO minival#AP75#38.9$Object Detection#iSAID#Average Precision#37.18$Object Detection#iSAID#Average Precision#36.50$Instance Segmentation#BDD100K#AP#20.5$Instance Segmentation#COCO test-dev#mask AP#37.1$Instance Segmentation#COCO test-dev#AP50#60.0$Instance Segmentation#COCO test-dev#AP75#39.4$Instance Segmentation#COCO test-dev#APS#16.9$Instance Segmentation#COCO test-dev#APM#39.9$Instance Segmentation#COCO test-dev#APL#53.5$Instance Segmentation#iSAID#Average Precision#37.18$Instance Segmentation#iSAID#Average Precision#36.50$Instance Segmentation#BDD100K val#AP#20.5$Multi-Human Parsing#MHP v2.0#AP 0.5#14.9%$Multi-Human Parsing#MHP v1.0#AP 0.5#52.68%$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.760$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#50.9$Object Segmentation#GRIT#Segmentation (ablation)#26.2$Object Segmentation#GRIT#Segmentation (test)#26.2
2105.04206v1.pdf	Real-Time Object Detection#COCO test-dev#FPS (V100, b=1)#49$Object Detection#COCO test-dev#box AP#58.2$Object Detection#COCO test-dev#AP50#75.8$Object Detection#COCO test-dev#AP75#63.8$Object Detection#COCO test-dev#box AP#55.4$Object Detection#COCO test-dev#AP50#73.3$Object Detection#COCO test-dev#AP75#60.6$Object Detection#COCO minival#box AP#55.4$Object Detection#COCO minival#AP50#73.5$Object Detection#COCO minival#AP75#60.6$Object Detection#COCO minival#APS#40.4$Object Detection#COCO minival#APM#60.1$Object Detection#COCO minival#APL#68.7$Object Detection#COCO minival#AP50#70.6$Object Detection#COCO minival#AP75#57.4$Object Detection#COCO minival#APS#37.4$Object Detection#COCO minival#APM#57.3$Object Detection#COCO minival#APL#65.2
2008.00623v2.pdf	Machine Translation#WMT2016 English-French#BLEU score#40.5$Machine Translation#IWSLT2014 German-English#BLEU score#35.3$Machine Translation#WMT2016 English-Romanian#BLEU score#34.7$Machine Translation#WMT2016 English-German#BLEU score#28.0$Language Modelling#WikiText-103#Test perplexity#24.14$Language Modelling#WikiText-103#Number of params#99M
1907.00494v1.pdf	Machine Translation#WMT 2018 Finnish-English#BLEU#26.5$Machine Translation#WMT2019 Finnish-English#BLEU#34.1$Machine Translation#WMT2017 Finnish-English#BLEU#35.5$Machine Translation#WMT2016 Finnish-English#BLEU#32.4
1810.08392v1.pdf	Machine Translation#WMT 2018 Finnish-English#BLEU#24.00$Machine Translation#WMT 2018 English-Finnish#BLEU#17.40$Machine Translation#WMT 2017 Latvian-English#BLEU#24.37$Machine Translation#WMT 2017 English-Latvian#BLEU#22.89
2103.01075v1.pdf	Machine Translation#WMT2017 English-French#BLEU#43.1$Machine Translation#WMT2014 English-French#BLEU score#42.6$Machine Translation#WMT2017 Russian-English#BLEU#36.2$Machine Translation#WMT2014 English-German#BLEU score#29.8$Machine Translation#WMT2017 Chinese-English#BLEU#23.0$Machine Translation#WMT2017 English-German#BLEU#29.0$Machine Translation#WMT2017 English-Finnish#BLEU#20.9$Language Modelling#One Billion Word#PPL#21.5$Language Modelling#One Billion Word#Number of params#100M$Language Modelling#One Billion Word#PPL#21.6$Language Modelling#One Billion Word#PPL#22
1709.07809v1.pdf	Machine Translation#20NEWS#1-of-100 Accuracy#5
1508.04025v5.pdf	Machine Translation#20NEWS#Accuracy#1.0$Machine Translation#WMT2014 English-German#BLEU score#20.9$Machine Translation#WMT2014 English-German#BLEU score#14.0$Machine Translation#WMT2014 English-German#BLEU score#11.3
2008.07772v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#46.4$Machine Translation#WMT2014 English-French#SacreBLEU#44.4$Machine Translation#WMT2014 English-French#BLEU score#43.8$Machine Translation#WMT2014 English-French#SacreBLEU#41.8$Machine Translation#WMT2014 English-German#BLEU score#30.1$Machine Translation#WMT2014 English-German#SacreBLEU#29.5$Machine Translation#WMT2014 English-German#Number of Params#256M
1808.09381v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#45.6$Machine Translation#WMT2014 English-French#SacreBLEU#43.8$Machine Translation#WMT2014 English-French#Hardware Burden#180G$Machine Translation#WMT2014 English-German#BLEU score#35.0$Machine Translation#WMT2014 English-German#SacreBLEU#33.8$Machine Translation#WMT2014 English-German#Hardware Burden#146G
2010.03142v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#44.3$Machine Translation#WMT2014 English-French#SacreBLEU#41.7
2106.14448v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.95$Machine Translation#IWSLT2014 German-English#BLEU score#37.90$Machine Translation#IWSLT2014 German-English#BLEU score#37.25$Machine Translation#WMT2014 English-German#BLEU score#30.91$Machine Translation#WMT2014 English-German#Hardware Burden#49G$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.51$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.58$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.24
2004.08249v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.8
2002.06823v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.78$Machine Translation#WMT2014 English-German#BLEU score#30.75$Unsupervised Machine Translation#WMT2014 English-French#BLEU#38.27$Unsupervised Machine Translation#WMT2016 English--Romanian#BLEU#36.02
1911.09483v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.5$Machine Translation#IWSLT2014 German-English#BLEU score#36.3$Machine Translation#WMT2014 English-German#BLEU score#29.9
1910.10683v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.4$Machine Translation#WMT2014 English-German#BLEU score#32.1$Machine Translation#WMT2014 English-German#Number of Params#11110M$Question Answering#BoolQ#Accuracy#91.2$Question Answering#WebQuestions#Accuracy#42.8$Question Answering#MultiRC#F1#88.1$Question Answering#MultiRC#EM#63.3$Question Answering#COPA#Accuracy#94.8$Question Answering#Quora Question Pairs#Accuracy#90.4%$Question Answering#Quora Question Pairs#Accuracy#89.9%$Question Answering#Quora Question Pairs#Accuracy#89.7%$Question Answering#Quora Question Pairs#Accuracy#89.4%$Question Answering#Quora Question Pairs#Accuracy#88.0%$Question Answering#SQuAD1.1 dev#EM#90.06$Question Answering#SQuAD1.1 dev#F1#95.64$Question Answering#SQuAD1.1 dev#EM#88.53$Question Answering#SQuAD1.1 dev#F1#94.95$Question Answering#SQuAD1.1 dev#EM#86.66$Question Answering#SQuAD1.1 dev#F1#93.79$Question Answering#SQuAD1.1 dev#EM#85.44$Question Answering#SQuAD1.1 dev#F1#92.08$Question Answering#SQuAD1.1 dev#EM#79.1$Question Answering#SQuAD1.1 dev#F1#87.24$Common Sense Reasoning#ReCoRD#F1#94.1$Common Sense Reasoning#ReCoRD#EM#93.4$Word Sense Disambiguation#Words in Context#Accuracy#76.9$Natural Language Inference#CommitmentBank#F1#93.9$Natural Language Inference#CommitmentBank#Accuracy#96.8$Natural Language Inference#QNLI#Accuracy#96.7%$Natural Language Inference#QNLI#Accuracy#96.3%$Natural Language Inference#QNLI#Accuracy#94.8%$Natural Language Inference#QNLI#Accuracy#93.7%$Natural Language Inference#QNLI#Accuracy#90.3%$Natural Language Inference#WNLI#Accuracy#93.2%$Natural Language Inference#WNLI#Accuracy#89.7%$Natural Language Inference#WNLI#Accuracy#85.6%$Natural Language Inference#WNLI#Accuracy#78.8%$Natural Language Inference#WNLI#Accuracy#69.2%$Natural Language Inference#RTE#Accuracy#92.5%$Natural Language Inference#RTE#Accuracy#91.1%$Natural Language Inference#RTE#Accuracy#87.2%$Natural Language Inference#RTE#Accuracy#80.1%$Natural Language Inference#RTE#Accuracy#69.9%$Natural Language Inference#MultiNLI#Matched#92.0$Natural Language Inference#MultiNLI#Mismatched#91.7$Natural Language Inference#MultiNLI#Matched#91.4$Natural Language Inference#MultiNLI#Mismatched#91.2$Natural Language Inference#MultiNLI#Matched#89.9$Natural Language Inference#MultiNLI#Mismatched#89.6$Natural Language Inference#MultiNLI#Matched#87.1$Natural Language Inference#MultiNLI#Mismatched#86.2$Natural Language Inference#MultiNLI#Matched#82.4$Natural Language Inference#MultiNLI#Mismatched#82.3$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.925$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.921$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.906$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.898$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.899$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.886$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.894$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.856$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.85$Semantic Textual Similarity#MRPC#Accuracy#90.0%$Semantic Textual Similarity#MRPC#F1#91.9%$Semantic Textual Similarity#MRPC#Number of Params#11000M$Semantic Textual Similarity#MRPC#Accuracy#89.9%$Semantic Textual Similarity#MRPC#F1#92.4%$Semantic Textual Similarity#MRPC#Accuracy#89.2%$Semantic Textual Similarity#MRPC#F1#92.5%$Semantic Textual Similarity#MRPC#Number of Params#3000M$Semantic Textual Similarity#MRPC#Accuracy#87.5%$Semantic Textual Similarity#MRPC#F1#90.7%$Semantic Textual Similarity#MRPC#Accuracy#86.6%$Semantic Textual Similarity#MRPC#F1#89.7%$Semantic Parsing#WebQuestionsSP#Accuracy#56.5$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.4$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.1$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.3$Sentiment Analysis#SST-2 Binary classification#Accuracy#95.2$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.8$Coreference Resolution#Winograd Schema Challenge#Accuracy#93.8$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#43.52$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.55$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#40.69$Document Summarization#CNN / Daily Mail#ROUGE-1#43.52$Document Summarization#CNN / Daily Mail#ROUGE-2#21.55$Document Summarization#CNN / Daily Mail#ROUGE-L#40.69$Linguistic Acceptability#CoLA#Accuracy#70.8%$Linguistic Acceptability#CoLA#Accuracy#67.1%$Linguistic Acceptability#CoLA#Accuracy#61.2%$Linguistic Acceptability#CoLA#Accuracy#51.1%$Linguistic Acceptability#CoLA#Accuracy#41.0%
1905.06596v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.3$Machine Translation#IWSLT2014 German-English#BLEU score#35.7$Machine Translation#WMT2014 English-German#BLEU score#29.7
1907.01968v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.27$Machine Translation#WMT2014 English-French#Hardware Burden#24G$Machine Translation#WMT2014 English-German#BLEU score#30.07$Machine Translation#WMT2014 English-German#Hardware Burden#24G
1806.00187v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.2$Machine Translation#WMT2014 English-French#Hardware Burden#55G$Machine Translation#WMT2014 English-German#BLEU score#29.3$Machine Translation#WMT2014 English-German#Number of Params#210M$Machine Translation#WMT2014 English-German#Hardware Burden#9G
1901.10430v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.2$Machine Translation#WMT2014 English-French#BLEU score#43.1$Machine Translation#IWSLT2014 German-English#BLEU score#35.2$Machine Translation#IWSLT2014 German-English#BLEU score#34.8$Machine Translation#WMT2014 English-German#BLEU score#29.7$Machine Translation#WMT2014 English-German#Number of Params#213M$Machine Translation#WMT2014 English-German#BLEU score#28.9$Machine Translation#WMT2014 English-German#Number of Params#202M$Machine Translation#WMT 2017 English-Chinese#BLEU score#24.4$Machine Translation#WMT 2017 English-Chinese#BLEU score#24.3$Language Modelling#One Billion Word#PPL#26.67$Language Modelling#One Billion Word#Number of params#0.34B$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#39.84$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#16.25$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.73$Document Summarization#CNN / Daily Mail#ROUGE-1#39.84$Document Summarization#CNN / Daily Mail#ROUGE-2#16.25$Document Summarization#CNN / Daily Mail#ROUGE-L#36.73$Document Summarization#CNN / Daily Mail#ROUGE-1#39.52$Document Summarization#CNN / Daily Mail#ROUGE-2#15.97$Document Summarization#CNN / Daily Mail#ROUGE-L#36.51
2002.03184v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#43.2$Machine Translation#IWSLT2014 German-English#BLEU score#35.5$Machine Translation#WMT2014 English-German#BLEU score#29.6$Machine Translation#WMT2014 English-German#Number of Params#209M$Language Modelling#WikiText-103#Test perplexity#23.3$Language Modelling#WikiText-103#Number of params#240M$Document Summarization#CNN / Daily Mail#ROUGE-1#40.59$Document Summarization#CNN / Daily Mail#ROUGE-2#18.97$Document Summarization#CNN / Daily Mail#ROUGE-L#36.81$Document Summarization#CNN / Daily Mail#ROUGE-1#40.03$Document Summarization#CNN / Daily Mail#ROUGE-2#18.45$Document Summarization#CNN / Daily Mail#ROUGE-L#36.13
2003.09229v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#42.7$Machine Translation#WMT2014 English-German#BLEU score#29.2$Semantic Textual Similarity#MRPC#Accuracy#91.4%$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.7$Linguistic Acceptability#CoLA#Accuracy#69%
1809.09296v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#42.1$Machine Translation#WMT2014 English-German#BLEU score#29.6
2103.13076v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#42.1$Machine Translation#WMT2014 English-German#BLEU score#28.7$Machine Translation#WMT2017 Chinese-English#BLEU#23.8$Language Modelling#WikiText-103#Validation perplexity#19$Language Modelling#WikiText-103#Test perplexity#19.6
2005.14187v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.8$Machine Translation#WMT2014 English-German#BLEU score#28.4$Machine Translation#WMT2014 English-German#Number of Params#48M
1803.02155v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.5$Machine Translation#WMT2014 English-German#BLEU score#29.2
1711.02132v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.4$Machine Translation#WMT2014 English-German#BLEU score#28.9
1705.03122v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.3$Machine Translation#WMT2014 English-French#BLEU score#40.46$Machine Translation#WMT2014 English-French#Hardware Burden#143G$Machine Translation#IWSLT2015 German-English#BLEU score#32.31$Machine Translation#IWSLT2015 English-German#BLEU score#26.73$Machine Translation#WMT2014 English-German#BLEU score#26.4$Machine Translation#WMT2014 English-German#Hardware Burden#54G$Machine Translation#WMT2014 English-German#BLEU score#25.16$Machine Translation#WMT2014 English-German#Hardware Burden#72G$Machine Translation#WMT2016 English-Romanian#BLEU score#29.9$Image Classification#MNIST#Percentage error#1.41$Image Classification#MNIST#Accuracy#98.59
1901.11117v4.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.3$Machine Translation#WMT2014 English-French#BLEU score#40.6$Machine Translation#WMT2014 English-Czech#BLEU score#28.2$Machine Translation#WMT2014 English-Czech#BLEU score#27.6$Machine Translation#WMT2014 English-German#BLEU score#29.8$Machine Translation#WMT2014 English-German#SacreBLEU#29.2$Machine Translation#WMT2014 English-German#Number of Params#218M$Machine Translation#WMT2014 English-German#BLEU score#29.3$Machine Translation#WMT2014 English-German#Number of Params#222M$Machine Translation#WMT2014 English-German#BLEU score#28.4$Machine Translation#WMT2014 English-German#Hardware Burden#2488G$Language Modelling#One Billion Word#PPL#28.6
1804.09849v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.0$Machine Translation#WMT2014 English-French#Hardware Burden#132G$Machine Translation#WMT2014 English-French#Operations per network pass#2.81G$Machine Translation#WMT2014 English-German#BLEU score#28.5$Machine Translation#WMT2014 English-German#Hardware Burden#44G$Machine Translation#WMT2014 English-German#Operations per network pass#2.81G
1706.03762v5.pdf	Machine Translation#WMT2014 English-French#BLEU score#41.0$Machine Translation#WMT2014 English-French#Hardware Burden#23G$Machine Translation#WMT2014 English-French#Operations per network pass#2300000000.0G$Machine Translation#WMT2014 English-French#BLEU score#38.1$Machine Translation#WMT2014 English-French#Operations per network pass#330000000.0G$Machine Translation#IWSLT2014 German-English#BLEU score#34.44$Machine Translation#IWSLT2015 English-German#BLEU score#28.50$Machine Translation#WMT2014 English-German#BLEU score#28.4$Machine Translation#WMT2014 English-German#Hardware Burden#871G$Machine Translation#WMT2014 English-German#Operations per network pass#2300000000.0G$Machine Translation#WMT2014 English-German#BLEU score#27.3$Machine Translation#WMT2014 English-German#Operations per network pass#330000000.0G$Multimodal Machine Translation#Multi30K#BLUE (DE-EN)#29.0$Constituency Parsing#Penn Treebank#F1 score#92.7$Text Summarization#GigaWord#ROUGE-1#37.57$Text Summarization#GigaWord#ROUGE-2#18.90$Text Summarization#GigaWord#ROUGE-L#34.69$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#39.50$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#16.06$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.63
2105.03404v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#40.6$Machine Translation#WMT2014 English-French#BLEU score#40.3$Machine Translation#WMT2014 English-German#BLEU score#26.8$Machine Translation#WMT2014 English-German#BLEU score#26.4$Image Classification#CIFAR-100#Percentage correct#89.5$Image Classification#CIFAR-100#Percentage correct#87.0$Image Classification#iNaturalist 2018#Top-1 Accuracy#64.3%$Image Classification#iNaturalist 2018#Top-1 Accuracy#60.2%$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Number of params#116M$Image Classification#ImageNet#Top 1 Accuracy#80.8%$Image Classification#ImageNet#Number of params#30M$Image Classification#ImageNet#GFLOPs#6$Image Classification#ImageNet#Top 1 Accuracy#79.7%$Image Classification#ImageNet#Number of params#45M$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Top 1 Accuracy#78.6%$Image Classification#ImageNet#Number of params#17.7M$Image Classification#ImageNet#GFLOPs#3$Image Classification#ImageNet#Top 1 Accuracy#77.8%$Image Classification#ImageNet#Number of params#15.4M$Image Classification#iNaturalist 2019#Top-1 Accuracy#72.5$Image Classification#iNaturalist 2019#Top-1 Accuracy#71.0$Image Classification#ImageNet ReaL#Accuracy#85.6%$Image Classification#ImageNet ReaL#Params#45M$Image Classification#ImageNet ReaL#Accuracy#85.3%$Image Classification#ImageNet ReaL#Params#30M$Image Classification#ImageNet ReaL#Accuracy#84.6%$Image Classification#ImageNet ReaL#Params#15M$Image Classification#ImageNet ReaL#Top 1 Accuracy#84.4%$Image Classification#Stanford Cars#Accuracy#89.5$Image Classification#Stanford Cars#Accuracy#84.6$Image Classification#ImageNet V2#Top 1 Accuracy#74.2$Image Classification#ImageNet V2#Top 1 Accuracy#73.4$Image Classification#ImageNet V2#Top 1 Accuracy#69.8$Image Classification#ImageNet V2#Top 1 Accuracy#66.0$Image Classification#Flowers-102#Accuracy#97.9$Image Classification#Flowers-102#Accuracy#97.4$Image Classification#CIFAR-10#Percentage correct#98.7$Image Classification#CIFAR-10#Top-1 Accuracy#98.7$Image Classification#CIFAR-10#Percentage correct#98.1$Image Classification#CIFAR-10#Top-1 Accuracy#98.1$Fine-Grained Image Classification#Stanford Cars#Accuracy#89.5%$Fine-Grained Image Classification#Stanford Cars#Accuracy#84.6%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#97.9%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#97.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#72.8%$Self-Supervised Image Classification#ImageNet#Number of Params#30M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#69.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#67.5%$Self-Supervised Image Classification#ImageNet#Number of Params#15M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#62.6%
1701.06538v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#40.56$Machine Translation#WMT2014 English-French#Hardware Burden#142G$Machine Translation#WMT2014 English-German#BLEU score#26.03$Machine Translation#WMT2014 English-German#Hardware Burden#24G$Language Modelling#One Billion Word#PPL#28.0$Language Modelling#One Billion Word#Number of params#5B$Language Modelling#One Billion Word#PPL#34.1
1901.11150v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#40.5
2101.01761v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#40$Machine Translation#IWSLT2014 German-English#BLEU score#35.8$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#58.1$Language Modelling#Penn Treebank (Word Level)#Test perplexity#54.9$Image Classification#ImageNet#Top 1 Accuracy#80.3%$Image Classification#ImageNet#Top 1 Accuracy#78.7%$Image Classification#ImageNet#Top 1 Accuracy#77.5%$Image Classification#ImageNet-10#Top 1 Accuracy#72.9$Image Classification#cifar-10,4000#Percentage error#4.2$Image Classification#CIFAR-10#Percentage correct#97.9$Image Classification#CIFAR-10#PARAMS#36.5M$Image Classification#CIFAR-10#Percentage correct#96.8
1609.08144v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#39.9$Machine Translation#WMT2014 English-French#Hardware Burden#279G$Machine Translation#WMT2014 English-German#BLEU score#26.3
2004.11886v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#39.6$Machine Translation#WMT2014 English-German#BLEU score#26.5$Machine Translation#WMT2014 English-German#Number of Params#17.3M
1606.04199v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#39.2$Machine Translation#WMT2014 English-French#Hardware Burden#119G$Machine Translation#WMT2014 English-French#BLEU score#35.9$Machine Translation#WMT2014 English-German#BLEU score#20.7$Machine Translation#WMT2014 English-German#Hardware Burden#119G
2103.02143v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#39.2$Machine Translation#IWSLT2014 German-English#BLEU score#34.4$Machine Translation#WMT2014 English-German#BLEU score#28.2$Language Modelling#WikiText-103#Validation perplexity#22$Language Modelling#WikiText-103#Test perplexity#23.5$Language Modelling#WikiText-103#Validation perplexity#29.4$Language Modelling#WikiText-103#Test perplexity#30.5
1410.8206v4.pdf	Machine Translation#WMT2014 English-French#BLEU score#37.5
1409.3215v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#36.5$Machine Translation#WMT2014 English-French#BLEU score#34.8$Time Series Forecasting#PeMSD7#9 steps MAE#4.16$Traffic Prediction#PeMS-M#MAE (60 min)#4.16
1611.02344v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#35.7$Machine Translation#IWSLT2015 German-English#BLEU score#30.4$Machine Translation#WMT2016 English-Romanian#BLEU score#27.8$Machine Translation#WMT2016 English-Romanian#BLEU score#27.5
1406.1078v3.pdf	Machine Translation#WMT2014 English-French#BLEU score#34.54
2109.01652v5.pdf	Machine Translation#WMT2014 English-French#BLEU score#34$Machine Translation#WMT2014 French-English#BLEU score#36.5$Machine Translation#WMT2016 Romanian-English#BLEU score#36.7$Machine Translation#WMT2016 German-English#BLEU score#39.8$Machine Translation#WMT2016 English-Romanian#BLEU score#18.4$Machine Translation#WMT2016 English-German#BLEU score#27.0$Question Answering#BoolQ#Accuracy#82.9$Question Answering#ARC-c#Accuracy#63.1$Question Answering#ARC-e#Accuracy#79.6$Question Answering#StoryCloze#Accuracy#93.4$Question Answering#MultiRC#F1#77.5$Question Answering#COPA#Accuracy#91.0$Question Answering#NaturalQA#EM#20.7$Question Answering#TriviaQA#EM#56.7$Question Answering#OBQA#Accuracy#78.4$Question Answering#PIQA#Accuracy#80.5$Common Sense Reasoning#Winograd Schema Challenge#Score#71.2$Common Sense Reasoning#WSC273#Accuracy#80.8$Common Sense Reasoning#ReCoRD#Accuracy#72.5$Natural Language Inference#RTE#Accuracy#84.1%$Sentence Completion#HellaSwag#Accuracy#56.7
1409.2329v5.pdf	Machine Translation#WMT2014 English-French#BLEU score#29.03$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#82.2$Language Modelling#Penn Treebank (Word Level)#Test perplexity#78.4$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#86.2$Language Modelling#Penn Treebank (Word Level)#Test perplexity#82.7
1804.07755v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#28.11$Machine Translation#WMT2014 English-French#BLEU score#27.6$Machine Translation#WMT2014 English-French#BLEU score#25.14$Machine Translation#WMT2014 English-German#BLEU score#20.23$Machine Translation#WMT2014 English-German#BLEU score#17.94$Machine Translation#WMT2014 English-German#BLEU score#17.16$Machine Translation#WMT2016 English-Romanian#BLEU score#25.13$Machine Translation#WMT2016 English-Romanian#BLEU score#21.33$Machine Translation#WMT2016 English-Romanian#BLEU score#21.18$Machine Translation#WMT2016 English-Russian#BLEU score#13.76$Machine Translation#WMT2016 English-Russian#BLEU score#13.37$Machine Translation#WMT2016 English-Russian#BLEU score#7.98$Unsupervised Machine Translation#WMT2014 English-French#BLEU#27.6$Unsupervised Machine Translation#WMT2016 German-English#BLEU#25.2$Unsupervised Machine Translation#WMT2014 French-English#BLEU#27.7$Unsupervised Machine Translation#WMT2016 English-German#BLEU#20.2
1610.08613v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#26.4
1809.01272v1.pdf	Machine Translation#WMT2014 English-French#BLEU score#26.22$Machine Translation#WMT2014 French-English#BLEU score#25.87$Machine Translation#WMT2014 English-German#BLEU score#14.08$Machine Translation#WMT2014 German-English#BLEU score#17.43$Machine Translation#WMT2016 German-English#BLEU score#23.05$Machine Translation#WMT2016 English-German#BLEU score#18.23$Unsupervised Machine Translation#WMT2014 French-English#BLEU#25.9
1710.11041v2.pdf	Machine Translation#WMT2014 English-French#BLEU score#14.36$Machine Translation#WMT2015 English-German#BLEU score#6.89
2102.06320v1.pdf	Machine Translation#V_C (trained on T_H)#Median Relative Edit Distance#0.27$Machine Translation#V_A (trained on T_H)#Median Relative Edit Distance#0.28$Machine Translation#V_B (trained on T_H)#Median Relative Edit Distance#0.25
2109.04588v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#38.61$Machine Translation#WMT2014 English-German#BLEU score#31.26$Machine Translation#WMT2014 German-English#BLEU score#34.94
2206.02368v2.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#38.37$Machine Translation#IWSLT2014 German-English#BLEU score#37.81$Machine Translation#WMT2014 English-German#BLEU score#30.78$Machine Translation#WMT2014 English-German#BLEU score#30.56$Machine Translation#WMT2014 German-English#BLEU score#35.15$Machine Translation#WMT2014 German-English#BLEU score#34.86$Machine Translation#IWSLT2014 English-German#BLEU score#31.16$Machine Translation#IWSLT2014 English-German#BLEU score#30.98
2209.09735v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#37.96$Lipreading#LRS3-TED#Word Error Rate (WER)#25.51
2003.03977v5.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#37.78$Machine Translation#WMT2014 German-English#BLEU score#31.9
2009.13818v2.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#37.6
1911.01986v4.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#37.2$Machine Translation#WMT2014 English-German#BLEU score#30.7
2104.04946v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#36.88$Machine Translation#IWSLT2014 English-German#BLEU score#29.99
2103.13597v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#36.3$Machine Translation#IWSLT2014 German-English#Number of Params#37M$Machine Translation#WMT2014 English-German#BLEU score#30.4$Machine Translation#WMT2014 English-German#Number of Params#215M$Machine Translation#WMT2014 English-German#BLEU score#29.1$Machine Translation#WMT2014 English-German#Number of Params#63M$Text Summarization#GigaWord#ROUGE-1#38.28$Text Summarization#GigaWord#ROUGE-2#19.46$Text Summarization#GigaWord#ROUGE-L#35.46$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.98$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.29$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.88
2104.01853v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#36.22$Machine Translation#IWSLT2014 German-English#Number of Params#37M$Machine Translation#WMT2014 English-German#BLEU score#33.89$Machine Translation#WMT2014 English-German#SacreBLEU#32.35$Text Summarization#GigaWord#ROUGE-1#39.81$Text Summarization#GigaWord#ROUGE-2#20.40$Text Summarization#GigaWord#ROUGE-L#36.93$Text Summarization#GigaWord#ROUGE-1#39.66$Text Summarization#GigaWord#ROUGE-2#20.45$Text Summarization#GigaWord#ROUGE-L#36.59$Text Summarization#DUC 2004 Task 1#ROUGE-1#33.06$Text Summarization#DUC 2004 Task 1#ROUGE-2#11.45$Text Summarization#DUC 2004 Task 1#ROUGE-L#28.51
2006.10270v2.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#36.22$Machine Translation#WMT2014 English-German#SacreBLEU#29.9
2009.07253v2.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#35.4
2205.07260v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#35.1385$Text Classification#GLUE SST2#Accuracy#92.0872
1807.03756v2.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#33.1
1711.04956v5.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#32.84$Machine Translation#IWSLT2015 German-English#BLEU score#32.93
2103.11405v1.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#31.15$Machine Translation#WMT2014 English-German#BLEU score#26.6$Machine Translation#WMT2014 German-English#BLEU score#30.75
1706.05565v8.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#30.08$Machine Translation#IWSLT2015 German-English#BLEU score#30.08$Machine Translation#IWSLT2015 English-German#BLEU score#25.36
1912.10514v3.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#28.83
1607.07086v3.pdf	Machine Translation#IWSLT2014 German-English#BLEU score#28.53$Machine Translation#IWSLT2015 German-English#BLEU score#29.98$Machine Translation#IWSLT2015 English-German#BLEU score#25.04
2006.12000v3.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#36.20$Machine Translation#IWSLT2015 English-German#BLEU score#30.00$Multimodal Machine Translation#Multi30K#BLUE (DE-EN)#32.3$Object Detection#PASCAL VOC 2007#MAP#79.7%$Image Classification#CIFAR-100#Percentage correct#86.41$Image Classification#ImageNet#Top 1 Accuracy#79.24%$Image Classification#ImageNet#Top 5 Accuracy#94.66%
1808.03867v3.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#34.18$Machine Translation#IWSLT2015 English-German#BLEU score#27.99
1809.06858v2.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#33.97$Machine Translation#WMT2014 English-German#BLEU score#29.11$Language Modelling#WikiText-2#Validation perplexity#40.85$Language Modelling#WikiText-2#Test perplexity#39.14$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#47.38$Language Modelling#Penn Treebank (Word Level)#Test perplexity#46.54$Language Modelling#Penn Treebank (Word Level)#Params#22M
1802.06901v3.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#32.43$Machine Translation#WMT2016 Romanian-English#BLEU score#30.30$Machine Translation#IWSLT2015 English-German#BLEU score#27.01$Machine Translation#WMT2014 English-German#BLEU score#21.54$Machine Translation#WMT2014 German-English#BLEU score#25.43$Machine Translation#WMT2016 English-Romanian#BLEU score#29.66
1711.01068v2.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#29.56
1909.02480v3.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#24.75$Machine Translation#WMT2016 Romanian-English#BLEU score#32.91$Machine Translation#WMT2016 Romanian-English#BLEU score#32.46$Machine Translation#WMT2016 Romanian-English#BLEU score#32.03$Machine Translation#WMT2016 Romanian-English#BLEU score#30.69$Machine Translation#WMT2016 Romanian-English#BLEU score#30.16$Machine Translation#WMT2014 English-German#BLEU score#23.64$Machine Translation#WMT2014 English-German#BLEU score#23.14$Machine Translation#WMT2014 English-German#BLEU score#22.94$Machine Translation#WMT2014 English-German#BLEU score#20.85$Machine Translation#WMT2014 English-German#BLEU score#18.55$Machine Translation#WMT2014 German-English#BLEU score#28.29$Machine Translation#WMT2014 German-English#BLEU score#27.71$Machine Translation#WMT2014 German-English#BLEU score#27.16$Machine Translation#WMT2014 German-English#BLEU score#25.4$Machine Translation#WMT2014 German-English#BLEU score#23.36$Machine Translation#WMT2016 English-Romanian#BLEU score#32.35$Machine Translation#WMT2016 English-Romanian#BLEU score#31.97$Machine Translation#WMT2016 English-Romanian#BLEU score#31.08$Machine Translation#WMT2016 English-Romanian#BLEU score#29.86$Machine Translation#WMT2016 English-Romanian#BLEU score#29.26
1606.02960v2.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#24.0
1511.06732v7.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#20.2
1611.01576v2.pdf	Machine Translation#IWSLT2015 German-English#BLEU score#19.41
2011.07164v1.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#40.3
1901.07291v1.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#35.3$Unsupervised Machine Translation#WMT2014 English-French#BLEU#33.4$Unsupervised Machine Translation#WMT2016 English-Romanian#BLEU#33.3$Unsupervised Machine Translation#WMT2016 English--Romanian#BLEU#33.3$Unsupervised Machine Translation#WMT2016 German-English#BLEU#34.3$Unsupervised Machine Translation#WMT2016 Romanian-English#BLEU#31.8$Unsupervised Machine Translation#WMT2014 French-English#BLEU#33.3$Unsupervised Machine Translation#WMT2016 English-German#BLEU#26.4$Natural Language Inference#XNLI French#Accuracy#80.2
1606.02891v2.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#33.3$Machine Translation#WMT2016 German-English#BLEU score#38.6$Machine Translation#WMT2016 English-Romanian#BLEU score#28.1$Machine Translation#WMT2016 Russian-English#BLEU score#28.0$Machine Translation#WMT2016 English-Russian#BLEU score#26.0$Machine Translation#WMT2016 English-German#BLEU score#34.2$Machine Translation#WMT2016 English-Czech#BLEU score#25.8$Machine Translation#WMT2016 Czech-English#BLEU score#31.4
1905.11006v2.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#33.26
2011.06132v1.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#33.26$Machine Translation#WMT2016 Romanian-English#BLEU score#31.24$Machine Translation#WMT2014 English-German#BLEU score#27.35$Machine Translation#WMT2014 English-German#BLEU score#25.20$Machine Translation#WMT2014 German-English#BLEU score#32.04$Machine Translation#WMT2014 German-English#BLEU score#29.91$Machine Translation#WMT2016 English-Romanian#BLEU score#32.87$Machine Translation#WMT2016 English-Romanian#BLEU score#30.74
1711.02281v2.pdf	Machine Translation#WMT2016 Romanian-English#BLEU score#31.44$Machine Translation#IWSLT2015 English-German#BLEU score#28.16$Machine Translation#WMT2014 English-German#BLEU score#19.17$Machine Translation#WMT2014 German-English#BLEU score#23.20$Machine Translation#WMT2016 English-Romanian#BLEU score#29.79
1910.13267v2.pdf	Machine Translation#IWSLT2017 English-Arabic#Cased sacreBLEU#15.2$Machine Translation#IWSLT2017 Arabic-English#Cased sacreBLEU#33.0$Machine Translation#IWSLT2017 English-French#Cased sacreBLEU#39.83$Machine Translation#IWSLT2015 English-Vietnamese#BLEU#33.27$Machine Translation#IWSLT2017 French-English#Cased sacreBLEU#38.6
2207.04672v3.pdf	Machine Translation#IWSLT2017 English-Arabic#SacreBLEU#25.2$Machine Translation#IWSLT2017 Arabic-English#SacreBLEU#44.7$Machine Translation#IWSLT2017 English-French#SacreBLEU#43$Machine Translation#IWSLT2015 English-Vietnamese#SacreBLEU#34.8$Machine Translation#IWSLT2017 French-English#SacreBLEU#45.8
2003.07845v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#30.1
1906.03805v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#29.52$Language Modelling#WikiText-2#Validation perplexity#40.27$Language Modelling#WikiText-2#Test perplexity#38.65$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#46.63$Language Modelling#Penn Treebank (Word Level)#Test perplexity#46.01$Language Modelling#Penn Treebank (Word Level)#Params#22M$Language Modelling#WikiText-103#Validation perplexity#27.2$Language Modelling#WikiText-103#Test perplexity#28.0
1905.04847v1.pdf	Machine Translation#WMT2014 English-German#BLEU score#29.21
1810.10182v1.pdf	Machine Translation#WMT2014 English-German#BLEU score#29.2
2209.10655v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#29.01$Machine Translation#WMT2014 English-German#SacreBLEU#27.96$Machine Translation#WMT2014 English-German#Number of Params#67M$Machine Translation#WMT2014 German-English#BLEU score#33.12$Long-range modeling#LRA#ListOps#63.14$Long-range modeling#LRA#Text#90.43$Long-range modeling#LRA#Retrieval#91.25$Long-range modeling#LRA#Image#90.43$Long-range modeling#LRA#Pathfinder#96.01$Long-range modeling#LRA#Avg#88.21$Long-range modeling#LRA#Pathfinder-X#97.98$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Number of params#90M
1811.08541v1.pdf	Machine Translation#WMT2014 English-German#BLEU score#28.99
1807.03819v3.pdf	Machine Translation#WMT2014 English-German#BLEU score#28.9$Language Modelling#LAMBADA#Accuracy#56.25
1906.01604v1.pdf	Machine Translation#WMT2014 English-German#BLEU score#28.7
1709.02755v5.pdf	Machine Translation#WMT2014 English-German#BLEU score#28.4$Machine Translation#WMT2014 English-German#Hardware Burden#34G$Question Answering#SQuAD1.1#EM#71.4$Question Answering#SQuAD1.1#F1#80.2$Question Answering#SQuAD1.1#Hardware Burden#4G$Question Answering#SQuAD1.1 dev#EM#71.4$Question Answering#SQuAD1.1 dev#F1#80.2
1905.05513v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#28.1$Language Modelling#WikiText-2#Validation perplexity#43.9$Language Modelling#WikiText-2#Test perplexity#42.0$Language Modelling#WikiText-2#Number of params#34M$Language Modelling#WikiText-2#Validation perplexity#64.9$Language Modelling#WikiText-2#Test perplexity#61.9$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#49.5$Language Modelling#Penn Treebank (Word Level)#Test perplexity#49.4$Language Modelling#Penn Treebank (Word Level)#Params#24M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#58.2$Language Modelling#Penn Treebank (Word Level)#Test perplexity#55.7
1706.03059v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#26.1
1806.00722v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#25.52
2008.07905v3.pdf	Machine Translation#WMT2014 English-German#BLEU score#25.21
1610.10099v2.pdf	Machine Translation#WMT2014 English-German#BLEU score#23.75$Machine Translation#WMT2015 English-German#BLEU score#26.3$Language Modelling#enwik8#Bit per Character (BPC)#1.31
1606.07947v4.pdf	Machine Translation#WMT2014 English-German#BLEU score#18.5$Machine Translation#IWSLT2015 Thai-English#BLEU score#14.2
1607.04315v3.pdf	Machine Translation#WMT2014 English-German#BLEU score#17.9$Question Answering#WikiQA#MAP#0.6811$Question Answering#WikiQA#MRR#0.6993$Natural Language Inference#SNLI#% Test Accuracy#85.4$Natural Language Inference#SNLI#% Train Accuracy#86.9$Natural Language Inference#SNLI#Parameters#3.2m$Natural Language Inference#SNLI#% Test Accuracy#84.6$Natural Language Inference#SNLI#% Train Accuracy#86.2$Natural Language Inference#SNLI#Parameters#3.0m$Sentiment Analysis#SST-2 Binary classification#Accuracy#89.7
2008.01940v1.pdf	Machine Translation#Business Scene Dialogue EN-JA#BLEU#13.53$Machine Translation#Business Scene Dialogue JA-EN#BLEU#12.88
1710.03743v1.pdf	Machine Translation#WMT 2017 Latvian-English#BLEU#14.83
1808.02733v1.pdf	Machine Translation#WMT 2017 Latvian-English#BLEU#-
1606.02892v2.pdf	Machine Translation#WMT2016 German-English#BLEU score#32.9$Machine Translation#WMT2016 English-German#BLEU score#28.4
1804.09057v1.pdf	Machine Translation#WMT2016 German-English#BLEU score#14.62$Machine Translation#WMT2016 English-German#BLEU score#10.86
1711.00043v2.pdf	Machine Translation#WMT2016 German-English#BLEU score#13.33$Machine Translation#WMT2016 English-German#BLEU score#9.64
1907.06616v1.pdf	Machine Translation#WMT2019 English-German#BLEU score#43.1$Machine Translation#WMT2019 English-German#SacreBLEU#42.7
2104.06022v3.pdf	Machine Translation#newstest2014-deen eng-deu#SacreBLEU#33.54
2103.15075v1.pdf	Machine Translation#Tatoeba (EN-to-EL)#BLEU#76.9$Machine Translation#Tatoeba (EL-to-EN)#BLEU#79.3$Open Information Extraction#CaRB OIE benchmark (Greek Use-case)#F1#0.255
1911.04070v1.pdf	Machine Translation#IWSLT2015 Chinese-English#BLEU#19.84$Language Modelling#enwik8#Bit per Character (BPC)#1.02$Language Modelling#enwik8#Number of params#38M$Language Modelling#Text8#Bit per Character (BPC)#1.11$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#52.71$Sentiment Analysis#IMDb#Accuracy#92.12
2209.09368v1.pdf	Machine Translation#slone/myv_ru_2022 ru-myv#ChrF++#41.16$Machine Translation#slone/myv_ru_2022 myv-ru#ChrF++#38.63
1910.05895v2.pdf	Machine Translation#IWSLT2015 English-Vietnamese#BLEU#32.8
1911.07013v1.pdf	Machine Translation#IWSLT2015 English-Vietnamese#BLEU#31.4
1808.07374v2.pdf	Machine Translation#IWSLT2015 English-Vietnamese#BLEU#29.12
1905.02878v1.pdf	Machine Translation#IWSLT2015 English-Vietnamese#BLEU#29.09
1806.03692v1.pdf	Machine Translation#IWSLT2015 English-Vietnamese#BLEU#28.47
1910.04209v3.pdf	Machine Translation#WMT2016 English-German#BLEU score#26.7$Language Modelling#WikiText-103#Validation perplexity#19.5$Image Classification#ImageNet#Top 1 Accuracy#72.1%
1804.08313v2.pdf	Machine Translation#WMT2016 English-German#BLEU score#24.9
2210.15615v1.pdf	Machine Translation#ACES#Score#19.97$Machine Translation#ACES#Score#19.89$Machine Translation#ACES#Score#19.76$Machine Translation#ACES#Score#17.28$Machine Translation#ACES#Score#17.17$Machine Translation#ACES#Score#16.8$Machine Translation#ACES#Score#16.31$Machine Translation#ACES#Score#15.68$Machine Translation#ACES#Score#15.38$Machine Translation#ACES#Score#15.24$Machine Translation#ACES#Score#14.76$Machine Translation#ACES#Score#14.07$Machine Translation#ACES#Score#13.57$Machine Translation#ACES#Score#13.08$Machine Translation#ACES#Score#12.06$Machine Translation#ACES#Score#11.9$Machine Translation#ACES#Score#11.38$Machine Translation#ACES#Score#10.47$Machine Translation#ACES#Score#-3.13$Machine Translation#ACES#Score#-0.33$Machine Translation#ACES#Score#-0.18
2106.03269v3.pdf	Machine Translation#Itihasa#SacreBLEU#7.59$Machine Translation#Itihasa#SacreBLEU#7.49
1603.06147v4.pdf	Machine Translation#WMT2015 English-German#BLEU score#23.5$Machine Translation#WMT2015 English-German#BLEU score#21.7
1508.07909v5.pdf	Machine Translation#WMT2015 English-German#BLEU score#22.8$Machine Translation#WMT2015 English-Russian#BLEU score#20.9
1803.05567v2.pdf	Machine Translation#WMT 2017 English-Chinese#BLEU score#24.2
2005.06166v1.pdf	Machine Translation#WMT2019 English-Japanese#BLEU#527424878
2110.01938v1.pdf	Machine Translation#Arba Sicula#BLEU (En-Scn)#35.0$Machine Translation#Arba Sicula#BLEU (Scn-En)#36.8$Machine Translation#Arba Sicula#BLEU (It-Scn)#36.5$Machine Translation#Arba Sicula#BLEU (Scn-It)#30.9
1905.02450v5.pdf	Unsupervised Machine Translation#WMT2014 English-French#BLEU#37.5$Unsupervised Machine Translation#WMT2016 English-Romanian#BLEU#35.2$Unsupervised Machine Translation#WMT2016 German-English#BLEU#35.2$Unsupervised Machine Translation#WMT2016 Romanian-English#BLEU#33.1$Unsupervised Machine Translation#WMT2014 French-English#BLEU#34.9$Unsupervised Machine Translation#WMT2016 English-German#BLEU#28.3$Text Summarization#GigaWord#ROUGE-1#38.73$Text Summarization#GigaWord#ROUGE-2#19.71$Text Summarization#GigaWord#ROUGE-L#35.96
1902.01313v2.pdf	Unsupervised Machine Translation#WMT2014 English-French#BLEU#36.2$Unsupervised Machine Translation#WMT2014 German-English#BLEU#27.0$Unsupervised Machine Translation#WMT2016 German-English#BLEU#34.4$Unsupervised Machine Translation#WMT2014 English-German#BLEU#22.5$Unsupervised Machine Translation#WMT2014 French-English#BLEU#33.5$Unsupervised Machine Translation#WMT2016 English-German#BLEU#26.9
2005.14165v4.pdf	Unsupervised Machine Translation#WMT2014 English-French#BLEU#32.6$Unsupervised Machine Translation#WMT2016 English-Romanian#BLEU#21$Unsupervised Machine Translation#WMT2016 German-English#BLEU#40.6$Unsupervised Machine Translation#WMT2016 Romanian-English#BLEU#39.5$Unsupervised Machine Translation#WMT2014 French-English#BLEU#39.2$Unsupervised Machine Translation#WMT2016 English-German#BLEU#29.7$Zero-Shot Learning#Winogrande#Accuracy#57.4$Zero-Shot Learning#COPA#Accuracy#73.0$Zero-Shot Learning#ReCoRD#Accuracy#82.1$Zero-Shot Learning#PIQA#Accuracy#72.9$Zero-Shot Learning#HellaSwag#Accuracy#51.0$Zero-Shot Learning#StoryCloze#Accuracy#72.4$Multi-task Language Understanding#MMLU#Humanities#52.5$Multi-task Language Understanding#MMLU#Average (%)#53.9$Multi-task Language Understanding#MMLU#Parameters (Billions)#175$Multi-task Language Understanding#MMLU#STEM#41.4$Multi-task Language Understanding#MMLU#Social Sciences#63.9$Multi-task Language Understanding#MMLU#Other#57.9$Multi-task Language Understanding#MMLU#Tokens (Billions)#300$Multi-task Language Understanding#MMLU#Humanities#40.8$Multi-task Language Understanding#MMLU#Average (%)#43.9$Multi-task Language Understanding#MMLU#STEM#36.7$Multi-task Language Understanding#MMLU#Social Sciences#50.4$Multi-task Language Understanding#MMLU#Other#48.8$Multi-task Language Understanding#MMLU#Humanities#42.1$Multi-task Language Understanding#MMLU#Average (%)#43.2$Multi-task Language Understanding#MMLU#Parameters (Billions)#6.7$Multi-task Language Understanding#MMLU#STEM#35.1$Multi-task Language Understanding#MMLU#Social Sciences#49.2$Multi-task Language Understanding#MMLU#Other#46.9$Multi-task Language Understanding#MMLU#Humanities#27.1$Multi-task Language Understanding#MMLU#Average (%)#26$Multi-task Language Understanding#MMLU#Parameters (Billions)#13$Multi-task Language Understanding#MMLU#STEM#24.3$Multi-task Language Understanding#MMLU#Social Sciences#25.6$Multi-task Language Understanding#MMLU#Other#26.5$Multi-task Language Understanding#MMLU#Humanities#24.4$Multi-task Language Understanding#MMLU#Average (%)#25.9$Multi-task Language Understanding#MMLU#Parameters (Billions)#2.7$Multi-task Language Understanding#MMLU#STEM#26.0$Multi-task Language Understanding#MMLU#Social Sciences#30.9$Multi-task Language Understanding#MMLU#Other#24.1$Multi-task Language Understanding#MMLU#Humanities#26.1$Multi-task Language Understanding#MMLU#Average (%)#24.9$Multi-task Language Understanding#MMLU#STEM#25.6$Multi-task Language Understanding#MMLU#Social Sciences#21.6$Multi-task Language Understanding#MMLU#Other#25.5$Question Answering#BoolQ#Accuracy#76.4$Question Answering#BoolQ#Accuracy#60.5$Question Answering#WebQuestions#EM#41.5$Question Answering#WebQuestions#EM#25.3$Question Answering#WebQuestions#EM#14.4$Question Answering#QuAC#F1#44.3$Question Answering#CoQA#Overall#85$Question Answering#RACE#RACE-m#58.1$Question Answering#RACE#RACE-h#46.8$Question Answering#Story Cloze Test#Accuracy#87.7$Question Answering#MultiRC#F1#75.4$Question Answering#COPA#Accuracy#92$Question Answering#Natural Questions#EM#29.9$Question Answering#TriviaQA#EM#71.2$Question Answering#OpenBookQA#Accuracy#65.4$Question Answering#DROP Test#F1#36.5$Question Answering#PIQA#Accuracy#81.0$Common Sense Reasoning#ARC (Easy)#Accuracy#71.2$Common Sense Reasoning#ARC (Easy)#Accuracy#68.8$Common Sense Reasoning#ARC (Challenge)#Accuracy#53.2$Common Sense Reasoning#ARC (Challenge)#Accuracy#51.4$Word Sense Disambiguation#Words in Context#Accuracy#49.4$Natural Language Inference#ANLI test#A1#36.8$Natural Language Inference#ANLI test#A2#34$Natural Language Inference#ANLI test#A3#40.2$Natural Language Inference#CommitmentBank#F1#52$Natural Language Inference#CommitmentBank#Accuracy#75.6$Natural Language Inference#RTE#Accuracy#69%$Language Modelling#LAMBADA#Accuracy#86.4$Language Modelling#LAMBADA#Perplexity#1.92$Language Modelling#LAMBADA#Accuracy#76.2$Language Modelling#LAMBADA#Perplexity#3.00$Language Modelling#LAMBADA#Accuracy#72.5$Language Modelling#LAMBADA#Perplexity#3.56$Language Modelling#LAMBADA#Accuracy#70.3$Language Modelling#LAMBADA#Perplexity#4.00$Language Modelling#LAMBADA#Accuracy#67.1$Language Modelling#LAMBADA#Perplexity#4.60$Language Modelling#The Pile#Bits per byte#0.7177$Language Modelling#Penn Treebank (Word Level)#Test perplexity#20.5$Language Modelling#Penn Treebank (Word Level)#Params#175000M$Coreference Resolution#Winograd Schema Challenge#Accuracy#80.1$Coreference Resolution#WSC#Accuracy#80.1$Sentence Completion#HellaSwag#Accuracy#79.3$Sentence Completion#HellaSwag#Accuracy#78.9
1901.04112v1.pdf	Unsupervised Machine Translation#WMT2014 English-French#BLEU#29.5$Unsupervised Machine Translation#WMT2014 German-English#BLEU#20.4$Unsupervised Machine Translation#WMT2016 German-English#BLEU#26.3$Unsupervised Machine Translation#WMT2014 English-German#BLEU#17.0$Unsupervised Machine Translation#WMT2014 French-English#BLEU#28.9$Unsupervised Machine Translation#WMT2016 English-German#BLEU#21.7
1810.12703v1.pdf	Unsupervised Machine Translation#WMT2016 German-English#BLEU#26.7$Unsupervised Machine Translation#WMT2016 English-German#BLEU#20.0
2009.02016v1.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#39.7$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#56.8$Multimodal Machine Translation#Multi30K#Meteor (EN-FR)#76.4
1911.12798v1.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#39.4$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#58.7
2103.08862v2.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#39.2$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#57.8
2009.09654v2.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#38.4$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#55.7
1906.07701v1.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#38$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#55.6$Multimodal Machine Translation#Multi30K#Meteor (EN-FR)#74.6
1811.00357v2.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#37.6$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#56.0
1701.06521v1.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#37.3$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#55.1
1702.01287v1.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#37.1$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#54.5
1808.08266v2.pdf	Multimodal Machine Translation#Multi30K#BLEU (EN-DE)#31.6$Multimodal Machine Translation#Multi30K#Meteor (EN-DE)#52.2$Multimodal Machine Translation#Multi30K#Meteor (EN-FR)#70.3
2106.00250v3.pdf	Multimodal Machine Translation#Hindi Visual Genome (Challenge Set)#BLEU (EN-HI)#51.6$Multimodal Machine Translation#Hindi Visual Genome (Test Set)#BLEU (EN-HI)#44.6
2103.01910v3.pdf	Multimodal Lexical Translation#MultiSubs English-Portuguese#ALI#0.80$Multimodal Lexical Translation#MultiSubs English-German#ALI#0.94$Multimodal Lexical Translation#MultiSubs English-Spanish#ALI#0.81$Multimodal Lexical Translation#MultiSubs English-French#ALI#0.81$Multimodal Text Prediction#MultiSubs#Accuracy#30.35$Multimodal Text Prediction#MultiSubs#Word similarity#0.44
2205.08621v1.pdf	Low-Resource Neural Machine Translation#Umsuka#BLEU#13.73
1911.07067v1.pdf	Medical Image Segmentation#ASU-Mayo Clinic dataset#DSC#0.8743$Medical Image Segmentation#ASU-Mayo Clinic dataset#mIoU#0.8569$Medical Image Segmentation#ASU-Mayo Clinic dataset#Recall#0.6534$Medical Image Segmentation#ASU-Mayo Clinic dataset#Precision#0.4896$Medical Image Segmentation#CVC-VideoClinicDB#Dice#0.8798$Medical Image Segmentation#CVC-VideoClinicDB#mIoU#0.8730$Medical Image Segmentation#CVC-VideoClinicDB#Recall#0.7749$Medical Image Segmentation#CVC-VideoClinicDB#precision#0.6702$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8133$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.7955$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.7534$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.6364$Medical Image Segmentation#KvasirCapsule-SEG#DSC#0.9499$Medical Image Segmentation#KvasirCapsule-SEG#mIoU#0.9087$Polyp Segmentation#Kvasir-SEG#DSC#0.8133$Polyp Segmentation#Kvasir-SEG#mIoU#0.7927
2107.12435v1.pdf	Medical Image Segmentation#CVC-VideoClinicDB#Dice#0.8125$Medical Image Segmentation#CVC-VideoClinicDB#mIoU#0.8467$Medical Image Segmentation#CVC-VideoClinicDB#Recall#0.6896$Medical Image Segmentation#CVC-VideoClinicDB#precision#0.6421$Medical Image Segmentation#CVC-VideoClinicDB#Dice#0.8130$Medical Image Segmentation#CVC-VideoClinicDB#mIoU#0.8477$Medical Image Segmentation#CVC-VideoClinicDB#Recall#0.6875$Medical Image Segmentation#CVC-VideoClinicDB#precision#0.6276$Medical Image Segmentation#CVC-VideoClinicDB#Dice#0.8811$Medical Image Segmentation#CVC-VideoClinicDB#mIoU#0.8739$Medical Image Segmentation#CVC-VideoClinicDB#Recall#0.7743$Medical Image Segmentation#CVC-VideoClinicDB#precision#0.6706$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8508$Medical Image Segmentation#Kvasir-SEG#mIoU#0.7800$Medical Image Segmentation#Kvasir-SEG#FPS#69.59$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9020$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9017$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.8474$Medical Image Segmentation#CVC-ColonDB#mIoU#0.8466$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.7458$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.6136
2109.03201v6.pdf	Medical Image Segmentation#Synapse#Dice score#0.874$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#92.06
2011.08065v1.pdf	Medical Image Segmentation#Kvasir-Instrument#DSC#0.9158
2006.04868v2.pdf	Medical Image Segmentation#Kvasir-Instrument#DSC#0.9038$Medical Image Segmentation#2015 MICCAI Polyp Detection#Dice#0.7649$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9239$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.9133$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.8407$Medical Image Segmentation#2018 Data Science Bowl#Recall#0.6407$Medical Image Segmentation#2018 Data Science Bowl#Precision#0.9596$Lesion Segmentation#ISIC 2018#Dice Score#0.8962$Semantic Segmentation#Kvasir-Instrument#DSC#0.9038$Semantic Segmentation#Kvasir-Instrument#mIoU#0.8430
2208.08352v1.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.9385$Medical Image Segmentation#Kvasir-SEG#mIoU#0.8903$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9469$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.9020
2207.07759v2.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.936$Medical Image Segmentation#Kvasir-SEG#mIoU#0.891$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.950$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.909$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.803$Medical Image Segmentation#CVC-ColonDB#mIoU#0.719$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.772$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.801
2203.03635v3.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.9357$Medical Image Segmentation#Kvasir-SEG#mIoU#0.8905$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9447$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.8995$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.9230$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.8614$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.802$Medical Image Segmentation#CVC-ColonDB#mIoU#0.721$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.720$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.796
2205.08473v3.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.927$Medical Image Segmentation#Kvasir-SEG#mIoU#0.877$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.947$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.903
2111.10614v1.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.9263$Medical Image Segmentation#Kvasir-SEG#mIoU#0.8843
2209.07313v1.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.022$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.924$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.925$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.962$Medical Image Segmentation#Kvasir-SEG#mIoU#0.871$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.939$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.774$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.730
2105.07451v2.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.9217$Medical Image Segmentation#Kvasir-SEG#mIoU#0.8914$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9420$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.9224$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.8534$Medical Image Segmentation#2018 Data Science Bowl#Recall#0.9402$Medical Image Segmentation#2018 Data Science Bowl#Precision#0.9022$Lesion Segmentation#ISIC 2018#Dice Score#0.8813
2108.07368v3.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.023$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.918$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.929$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.968$Medical Image Segmentation#Kvasir-SEG#mIoU#0.865$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.936$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.887$Medical Image Segmentation#CVC-ClinicDB#Average MAE#0.007$Medical Image Segmentation#CVC-ClinicDB#S-Measure#0.954$Medical Image Segmentation#CVC-ClinicDB#max E-Measure#0.991$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.773$Medical Image Segmentation#CVC-ColonDB#mIoU#0.689$Medical Image Segmentation#CVC-ColonDB#Average MAE#0.042$Medical Image Segmentation#CVC-ColonDB#S-Measure#0.853$Medical Image Segmentation#CVC-ColonDB#max E-Measure#0.902$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.672$Medical Image Segmentation#ETIS-LARIBPOLYPDB#Average MAE#0.017$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.747$Medical Image Segmentation#ETIS-LARIBPOLYPDB#S-Measure#0.868$Medical Image Segmentation#ETIS-LARIBPOLYPDB#max E-Measure#0.894
2102.08005v2.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.918$Medical Image Segmentation#Kvasir-SEG#mIoU#0.868$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.934$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.918$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.773$Medical Image Segmentation#CVC-ColonDB#mIoU#0.696$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.744$Medical Image Segmentation#CVC-ColonDB#mIoU#0.676$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.661$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.737$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.659$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.733
2201.00767v2.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.021$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.915$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.923$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.972$Medical Image Segmentation#Kvasir-SEG#mIoU#0.865
2101.07172v2.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.025$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.912$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.923$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.958$Medical Image Segmentation#Kvasir-SEG#mIoU#0.857$Medical Image Segmentation#Kvasir-SEG#FPS#116$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9320$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.731$Medical Image Segmentation#CVC-ColonDB#mIoU#0.660$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.613$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.677
2107.02368v3.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.025$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.912$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.917$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.958$Medical Image Segmentation#Kvasir-SEG#mIoU#0.862$Medical Image Segmentation#Kvasir-SEG#Average MAE#0.026$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.905$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.914$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.951$Medical Image Segmentation#Kvasir-SEG#mIoU#0.852$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.926$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.916$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.783$Medical Image Segmentation#CVC-ColonDB#mIoU#0.704$Medical Image Segmentation#CVC-ColonDB#Average MAE#0.034$Medical Image Segmentation#CVC-ColonDB#S-Measure#0.848$Medical Image Segmentation#CVC-ColonDB#max E-Measure#0.897$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.751$Medical Image Segmentation#CVC-ColonDB#mIoU#0.678$Medical Image Segmentation#CVC-ColonDB#Average MAE#0.039$Medical Image Segmentation#CVC-ColonDB#S-Measure#0.835$Medical Image Segmentation#CVC-ColonDB#max E-Measure#0.878$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.689$Medical Image Segmentation#ETIS-LARIBPOLYPDB#Average MAE#0.012$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.766$Medical Image Segmentation#ETIS-LARIBPOLYPDB#S-Measure#0.859$Medical Image Segmentation#ETIS-LARIBPOLYPDB#max E-Measure#0.905$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.615$Medical Image Segmentation#ETIS-LARIBPOLYPDB#Average MAE#0.023$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.694$Medical Image Segmentation#ETIS-LARIBPOLYPDB#S-Measure#0.815$Medical Image Segmentation#ETIS-LARIBPOLYPDB#max E-Measure#0.851
2105.00402v3.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.902$Medical Image Segmentation#Kvasir-SEG#mIoU#0.845$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9170
2205.04280v1.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8982$Medical Image Segmentation#Kvasir-SEG#mIoU#0.8330$Medical Image Segmentation#BKAI-IGH NeoPolyp-Small#Average Dice#0.9023$Medical Image Segmentation#BKAI-IGH NeoPolyp-Small#mIoU#0.8409$Polyp Segmentation#Kvasir-SEG#DSC#0.8982$Polyp Segmentation#Kvasir-SEG#mIoU#0.8330
2006.11392v4.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.030$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.898$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.915$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.948$Medical Image Segmentation#Kvasir-SEG#mIoU#0.849$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.8990$Medical Image Segmentation#CVC-ColonDB#mean Dice#0.709$Medical Image Segmentation#CVC-ColonDB#mIoU#0.649$Medical Image Segmentation#CVC-ColonDB#Average MAE#0.045$Medical Image Segmentation#CVC-ColonDB#S-Measure#0.819$Medical Image Segmentation#CVC-ColonDB#max E-Measure#0.869$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mIoU#0.5670$Medical Image Segmentation#ETIS-LARIBPOLYPDB#Average MAE#0.031$Medical Image Segmentation#ETIS-LARIBPOLYPDB#mean Dice#0.6280$Medical Image Segmentation#ETIS-LARIBPOLYPDB#S-Measure#0.794$Medical Image Segmentation#ETIS-LARIBPOLYPDB#max E-Measure#0.841$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.733$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.753$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.572$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.632$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.621$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.524$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.717$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.735$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.544$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.607$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.598$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.512$Camouflaged Object Segmentation#CAMO#MAE#0.094$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#66.3$Camouflaged Object Segmentation#CAMO#S-Measure#76.9$Camouflaged Object Segmentation#CAMO#E-Measure#82.4
2103.17235v3.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.8153$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8803$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9355$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.9176$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.8569$Medical Image Segmentation#2018 Data Science Bowl#Recall#0.9222$Medical Image Segmentation#2018 Data Science Bowl#Precision#0.9194$Medical Image Segmentation#EM#IoU#0.9134$Medical Image Segmentation#EM#DSC#0.9547$Medical Image Segmentation#EM#Recall#0.9568$Medical Image Segmentation#EM#Specificity#0.8096$Medical Image Segmentation#EM#Precision#0.9529$Medical Image Segmentation#ISIC 2018#DSC#87.31$Medical Image Segmentation#CHASE_DB1#DSC#0.8108
2012.15245v1.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8576$Medical Image Segmentation#Kvasir-SEG#mIoU#0.7800$Medical Image Segmentation#Kvasir-SEG#FPS#69.59$Medical Image Segmentation#Endotect Polyp Segmentation Challenge Dataset#DSC#0.7870$Medical Image Segmentation#Endotect Polyp Segmentation Challenge Dataset#mIoU#0.701$Medical Image Segmentation#Endotect Polyp Segmentation Challenge Dataset#FPS#70.23
1807.10165v1.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.048$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8210$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.862$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.910$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.7940$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.8974$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.9255$Medical Image Segmentation#2018 Data Science Bowl#Recall#-$Medical Image Segmentation#2018 Data Science Bowl#Precision#-$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.457$Video Polyp Segmentation#SUN-SEG-Hard#S-Measure#0.685$Video Polyp Segmentation#SUN-SEG-Hard#mean E-measure#0.697$Video Polyp Segmentation#SUN-SEG-Hard#weighted F-measure#0.480$Video Polyp Segmentation#SUN-SEG-Hard#mean F-measure#0.544$Video Polyp Segmentation#SUN-SEG-Hard#Dice#0.554$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.467$Video Polyp Segmentation#SUN-SEG-Easy#S measure#0.684$Video Polyp Segmentation#SUN-SEG-Easy#mean E-measure#0.687$Video Polyp Segmentation#SUN-SEG-Easy#weighted F-measure#0.491$Video Polyp Segmentation#SUN-SEG-Easy#mean F-measure#0.553$Video Polyp Segmentation#SUN-SEG-Easy#Dice#0.559$Semantic Segmentation#Cityscapes val#mIoU#75.5
2011.07631v2.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8206$Medical Image Segmentation#Kvasir-SEG#mIoU#0.7239$Medical Image Segmentation#Kvasir-SEG#FPS#182.38$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9203$Medical Image Segmentation#BKAI-IGH NeoPolyp-Small#Average Dice#0.6881
1505.04597v1.pdf	Medical Image Segmentation#Kvasir-SEG#Average MAE#0.055$Medical Image Segmentation#Kvasir-SEG#mean Dice#0.8180$Medical Image Segmentation#Kvasir-SEG#S-Measure#0.858$Medical Image Segmentation#Kvasir-SEG#max E-Measure#0.893$Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.8230$Medical Image Segmentation#RITE#Dice#55.24$Medical Image Segmentation#RITE#Jaccard Index#31.11$Medical Image Segmentation#ISBI 2012 EM Segmentation#Warping Error#0.000353$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.4606$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.3447$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.5994$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.4449$Lesion Segmentation#University of Waterloo skin cancer database#Dice score#0.836 ±0.132$Cell Segmentation#DIC-C2DH-HeLa#SEG (~Mean IoU)#0.7756$Cell Segmentation#PhC-C2DH-U373#SEG (~Mean IoU)#0.9203$Retinal Vessel Segmentation#STARE#F1 score#0.8373$Retinal Vessel Segmentation#STARE#AUC#0.9898$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.7783$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9772$Retinal Vessel Segmentation#DRIVE#F1 score#0.8142$Retinal Vessel Segmentation#DRIVE#AUC#0.9755$Pancreas Segmentation#CT-150#Dice Score#0.814$Pancreas Segmentation#CT-150#Precision#0.848$Pancreas Segmentation#CT-150#Recall#0.806$Pancreas Segmentation#TCIA Pancreas-CT Dataset#Dice Score#0.82$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.420$Video Polyp Segmentation#SUN-SEG-Hard#S-Measure#0.670$Video Polyp Segmentation#SUN-SEG-Hard#mean E-measure#0.679$Video Polyp Segmentation#SUN-SEG-Hard#weighted F-measure#0.457$Video Polyp Segmentation#SUN-SEG-Hard#mean F-measure#0.527$Video Polyp Segmentation#SUN-SEG-Hard#Dice#0.542$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.429$Video Polyp Segmentation#SUN-SEG-Easy#S measure#0.669$Video Polyp Segmentation#SUN-SEG-Easy#mean E-measure#0.677$Video Polyp Segmentation#SUN-SEG-Easy#weighted F-measure#0.459$Video Polyp Segmentation#SUN-SEG-Easy#mean F-measure#0.528$Video Polyp Segmentation#SUN-SEG-Easy#Dice#0.530$Lung Nodule Segmentation#LUNA#F1 score#0.9658$Lung Nodule Segmentation#LUNA#AUC#0.9784$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#F1 score#0.8682$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#AUC#0.9371$Electron Microscopy Image Segmentation#SNEMI3D#AUC#0.8676$Semantic Segmentation#Kvasir-Instrument#DSC#0.9158$Semantic Segmentation#Kvasir-Instrument#mIoU#0.8578$Semantic Segmentation#Trans10K#mIoU#29.23%$Semantic Segmentation#Trans10K#GFLOPs#124.55$Semantic Segmentation#SkyScapes-Dense#Mean IoU#14.15$Semantic Segmentation#Stanford2D3D Panoramic#mIoU#35.9%$Thermal Image Segmentation#MFN Dataset#mIOU#45.1$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.625$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.514$Dichotomous Image Segmentation#DIS-TE1#MAE#0.106$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.716$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.750$Dichotomous Image Segmentation#DIS-TE1#HCE#233$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.703$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.597$Dichotomous Image Segmentation#DIS-TE2#MAE#0.107$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.755$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.796$Dichotomous Image Segmentation#DIS-TE2#HCE#474$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.748$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.644$Dichotomous Image Segmentation#DIS-TE3#MAE#0.098$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.780$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.827$Dichotomous Image Segmentation#DIS-TE3#HCE#883$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.759$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.659$Dichotomous Image Segmentation#DIS-TE4#MAE#0.102$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.784$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.821$Dichotomous Image Segmentation#DIS-TE4#HCE#3218$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.692$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.586$Dichotomous Image Segmentation#DIS-VD#MAE#0.113$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.745$Dichotomous Image Segmentation#DIS-VD#E-measure#0.785$Dichotomous Image Segmentation#DIS-VD#HCE#1337$Colorectal Gland Segmentation:#CRAG#F1-score#0.827$Colorectal Gland Segmentation:#CRAG#Dice#0.844$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#196.9$Colorectal Gland Segmentation:#CRAG#F1-score#0.796$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#199.5$Colorectal Gland Segmentation:#CRAG#DiceOC#0.835$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.758$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#47.8
1911.07069v1.pdf	Medical Image Segmentation#Kvasir-SEG#mean Dice#0.7877$Polyp Segmentation#Kvasir-SEG#DSC#0.7877
1912.05074v2.pdf	Medical Image Segmentation#Cell#IoU#91.21$Medical Image Segmentation#EM#IoU#89.33$Brain Image Segmentation#Brain Tumor#IoU#91.21
1906.02849v3.pdf	Medical Image Segmentation#HSVM#Dice Score#83.2$Medical Image Segmentation#HSVM#MSD#1.19$Medical Image Segmentation#HSVM#VS#94.45$Medical Image Segmentation#CHAOS MRI Dataset#Dice Score#86.75$Medical Image Segmentation#CHAOS MRI Dataset#MSD#66$Medical Image Segmentation#CHAOS MRI Dataset#VS#93.85$Brain Tumor Segmentation#BRATS 2018#Dice Score#0.8037$Brain Tumor Segmentation#BRATS 2018#MSD#0.9$Brain Tumor Segmentation#BRATS 2018#VS#93.08
2202.00972v2.pdf	Medical Image Segmentation#CVC-ClinicDB#mean Dice#0.9164$Medical Image Segmentation#CVC-ClinicDB#mIoU#0.8610$Medical Image Segmentation#2018 Data Science Bowl#Dice#0.9141$Medical Image Segmentation#2018 Data Science Bowl#mIoU#0.8501$Medical Image Segmentation#2018 Data Science Bowl#Recall#0.9240$Medical Image Segmentation#2018 Data Science Bowl#Precision#0.9137$Medical Image Segmentation#ISIC 2018#DSC#90.35$Medical Image Segmentation#SegPC-2021#mIoU#0.8048$Lesion Segmentation#ISIC 2018 Task 1#mIoU#0.8301
1804.02967v2.pdf	Medical Image Segmentation#iSEG 2017 Challenge#Dice Score#0.9257
2111.14791v2.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#90.80$Medical Image Segmentation#Medical Segmentation Decathlon#Dice (Average)#78.68$Medical Image Segmentation#Medical Segmentation Decathlon#NSD#89.28
2103.10504v3.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#89.10
1809.10486v1.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#88.80$Medical Image Segmentation#Medical Segmentation Decathlon#Dice (Average)#77.89$Medical Image Segmentation#Medical Segmentation Decathlon#NSD#88.09
1904.06346v2.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#85.40
2210.04285v1.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#82.0$Medical Image Segmentation#Synapse multi-organ CT#Avg HD#0.67$Medical Image Segmentation#MICCAI 2015 Multi-Atlas Abdomen Labeling Challenge#Avg DSC#82
2109.07162v1.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#81.96$Medical Image Segmentation#Synapse multi-organ CT#Avg HD#18.20$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#87.9
2012.15840v3.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#79.60$Semantic Segmentation#DADA-seg#mIoU#31.8$Semantic Segmentation#DADA-seg#mIoU#30.4$Semantic Segmentation#Cityscapes val#mIoU#82.15%$Semantic Segmentation#FoodSeg103#mIoU#45.1$Semantic Segmentation#FoodSeg103#mIoU#41.3$Semantic Segmentation#DensePASS#mIoU#35.7%$Semantic Segmentation#DensePASS#mIoU#35.6%$Semantic Segmentation#PASCAL Context#mIoU#55.83$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.64%
2105.05537v1.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#79.13$Medical Image Segmentation#Synapse multi-organ CT#Avg HD#21.55$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#90.00
2109.04335v3.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#78.99$Medical Image Segmentation#Synapse multi-organ CT#Avg HD#30.29$Medical Image Segmentation#GlaS#IoU#82.96$Medical Image Segmentation#GlaS#Dice#90.18
2102.04306v1.pdf	Medical Image Segmentation#Synapse multi-organ CT#Avg DSC#77.48$Medical Image Segmentation#Synapse multi-organ CT#Avg HD#31.69$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#89.71$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#87.57$Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#Avg DSC#86.75
2108.06932v4.pdf	Medical Image Segmentation#CVC-ColonDB#mean Dice#0.808$Medical Image Segmentation#CVC-ColonDB#mIoU#0.727$Medical Image Segmentation#CVC-ColonDB#Average MAE#0.031$Medical Image Segmentation#CVC-ColonDB#S-Measure#0.865$Medical Image Segmentation#CVC-ColonDB#max E-Measure#0.913
2206.14718v2.pdf	Medical Image Segmentation#MoNuSeg#F1#81.01$Medical Image Segmentation#MoNuSeg#IoU#68.2$Medical Image Segmentation#MoNuSeg#F1#80.66$Medical Image Segmentation#MoNuSeg#IoU#67.71$Medical Image Segmentation#MoNuSeg#F1#79.87$Medical Image Segmentation#MoNuSeg#IoU#66.68$Medical Image Segmentation#MoNuSeg#F1#79.26$Medical Image Segmentation#MoNuSeg#IoU#65.94$Medical Image Segmentation#MoNuSeg#F1#77.01$Medical Image Segmentation#MoNuSeg#IoU#63.04
2102.10662v2.pdf	Medical Image Segmentation#MoNuSeg#F1#79.56$Medical Image Segmentation#MoNuSeg#IoU#66.17$Medical Image Segmentation#MoNuSeg#F1#79.55$Medical Image Segmentation#MoNuSeg#F1#76.83$Medical Image Segmentation#MoNuSeg#IoU#62.49$Medical Image Segmentation#GlaS#F1#81.02$Medical Image Segmentation#GlaS#IoU#69.61$Medical Image Segmentation#GlaS#F1#79.68$Medical Image Segmentation#GlaS#IoU#67.69$Medical Image Segmentation#GlaS#F1#76.26$Medical Image Segmentation#GlaS#IoU#63.03$Medical Image Segmentation#Brain US#F1#88.84$Medical Image Segmentation#Brain US#IoU#81.34$Medical Image Segmentation#Brain US#F1#88.54$Medical Image Segmentation#Brain US#IoU#80.84$Medical Image Segmentation#Brain US#F1#87.92$Medical Image Segmentation#Brain US#IoU#80.14
2209.00729v1.pdf	Medical Image Segmentation#MoNuSeg#F1#75.08$Medical Image Segmentation#MoNuSeg#IoU#71.06$Medical Image Segmentation#MoNuSeg#Dice Score#95.20$Medical Image Segmentation#GlaS#F1#98.07$Medical Image Segmentation#GlaS#IoU#76.73$Medical Image Segmentation#GlaS#Dice#99.09
2010.01663v2.pdf	Medical Image Segmentation#RITE#Dice#75.17$Medical Image Segmentation#RITE#Jaccard Index#60.37$Liver Segmentation#LiTS2017#IoU#89.46$Liver Segmentation#LiTS2017#Dice#94.23$Ultrasound#Brain Anatomy US#Dice#89.43
1511.00561v3.pdf	Medical Image Segmentation#RITE#Dice#52.23$Medical Image Segmentation#RITE#Jaccard Index#39.14$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.2767$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.1911$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.3938$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.2532$Lesion Segmentation#University of Waterloo skin cancer database#Dice score#0.854 ±0.088$Crowd Counting#UCF-QNRF#MAE#270$Semantic Segmentation#CamVid#Mean IoU#46.4%$Semantic Segmentation#ADE20K#Validation mIoU#21.64$Semantic Segmentation#RSMSS#mIoU#59.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#57.0%$Semantic Segmentation#SkyScapes-Dense#Mean IoU#23.14$Scene Segmentation#SUN-RGBD#Mean IoU#31.84$Thermal Image Segmentation#MFN Dataset#mIOU#42.3$Real-Time Semantic Segmentation#CamVid#mIoU#46.4%$Real-Time Semantic Segmentation#CamVid#Time (ms)#217$Real-Time Semantic Segmentation#CamVid#Frame (fps)#4.6
1909.00166v1.pdf	Medical Image Segmentation#DRIVE#F1 score#0.8222$Lesion Segmentation#ISIC 2018#Dice Score#0.847$Lesion Segmentation#ISIC 2018#F1-Score#0.851$Retinal Vessel Segmentation#DRIVE#F1 score#0.8224$Retinal Vessel Segmentation#DRIVE#AUC#0.9789$Lung Nodule Segmentation#Lung Nodule#Dice Score#0.994$Lung Nodule Segmentation#LUNA#F1 score#0.9904$Lung Nodule Segmentation#LUNA#AUC#0.9946
2006.00414v1.pdf	Medical Image Segmentation#ISBI 2012 EM Segmentation#Jaccard#0.9262
1903.02740v1.pdf	Medical Image Segmentation#ISBI 2012 EM Segmentation#VInfo#0.9878$Medical Image Segmentation#ISBI 2012 EM Segmentation#VRand#0.9743$Retinal Vessel Segmentation#DRIVE#AUC#0.9779$Retinal Vessel Segmentation#DRIVE#Accuracy#0.9545$Lung Nodule Segmentation#LUNA#Accuracy#0.99
2207.06489v5.pdf	Medical Image Segmentation#Autoimmune Dataset#IoU#0.4983$Classification#Autoimmune Dataset#F1 score#0.891$Classification#Autoimmune Dataset#F1 score#0.63
2107.02319v2.pdf	Medical Image Segmentation#ROBUST-MIS#DSC#0.8495$Medical Image Segmentation#ROBUST-MIS#mIoU#0.7943$Medical Image Segmentation#ROBUST-MIS#FPS#185.54$Medical Image Segmentation#ROBUST-MIS#DSC#0.8739$Medical Image Segmentation#ROBUST-MIS#mIoU#0.8183$Medical Image Segmentation#ROBUST-MIS#FPS#101.36
2203.04967v1.pdf	Medical Image Segmentation#ISIC 2018#DSC#89.70
2107.05023v1.pdf	Medical Image Segmentation#BKAI-IGH NeoPolyp-Small#Average Dice#0.80723
2203.00129v1.pdf	Medical Image Segmentation#BKAI-IGH NeoPolyp-Small#Average Dice#0.78802
2104.11138v1.pdf	Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#DSC#0.7364$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#mIoU#0.6319$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#Recall#0.8566$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#Precision#0.7310$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#FPS#28.07$Medical Image Segmentation#KvasirCapsule-SEG#DSC#0.9493$Medical Image Segmentation#KvasirCapsule-SEG#mIoU#0.9059
2012.15247v1.pdf	Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#DSC#0.8154$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#mIoU#0.7396$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#Recall#0.8533$Medical Image Segmentation#Medico automatic polyp segmentation challenge (dataset)#Precision#0.8533
2004.08790v1.pdf	Medical Image Segmentation#LiTS2017#Dice#0.9675$Medical Image Segmentation#LiTS2017#Dice#0.9580
2103.15954v1.pdf	Medical Image Segmentation#Medical Segmentation Decathlon#Dice (Average)#77.93$Medical Image Segmentation#Medical Segmentation Decathlon#NSD#88.68
1908.06912v1.pdf	Medical Image Segmentation#Medical Segmentation Decathlon#Dice (Average)#76.97$Medical Image Segmentation#Medical Segmentation Decathlon#NSD#87.19$Brain Tumor Segmentation#BRATS-2013#Dice Score#0.9258$Liver Segmentation#LiTS2017#IoU#79.52$Liver Segmentation#LiTS2017#Dice#91.13$Lung Nodule Segmentation#LIDC-IDRI#IoU#77.62$Lung Nodule Segmentation#LIDC-IDRI#Dice#75.86$Lung Nodule Detection#LUNA2016 FPRED#AUC#98.2$Pulmonary Embolism Detection#PE-CAD FPRED#AUC#88.04
2102.10680v1.pdf	Medical Image Segmentation#Medical Segmentation Decathlon#Dice (Average)#76.96$Medical Image Segmentation#Medical Segmentation Decathlon#NSD#87.64
1810.07842v1.pdf	Lesion Segmentation#BUS 2017 Dataset B#Dice Score#0.804$Lesion Segmentation#BUS 2017 Dataset B#Dice Score#0.669$Lesion Segmentation#BUS 2017 Dataset B#Dice Score#0.615$Lesion Segmentation#ISIC 2018#Dice Score#0.856$Lesion Segmentation#ISIC 2018#Dice Score#0.829$Lesion Segmentation#ISIC 2018#Dice Score#0.806
1910.08978v2.pdf	Lesion Segmentation#BUS 2017 Dataset B#Dice Score#0.7341$Tumor Segmentation#BUS 2017 Dataset B#Dice Score#0.7341
1802.02611v3.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.4609$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.3458$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.5831$Semantic Segmentation#DADA-seg#mIoU#26.8$Semantic Segmentation#Cityscapes val#mIoU#79.6$Semantic Segmentation#SynPASS#mIoU#29.66%$Semantic Segmentation#EventScape#mIoU#53.65$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#89.0%$Semantic Segmentation#DensePASS#mIoU#32.5%$Semantic Segmentation#Trans10K#mIoU#68.87%$Semantic Segmentation#Trans10K#GFLOPs#37.98$Semantic Segmentation#SkyScapes-Dense#Mean IoU#38.20
1612.01105v2.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.3571$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.254$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.4769$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.3335$Semantic Segmentation#DADA-seg#mIoU#20.1$Semantic Segmentation#Cityscapes val#mIoU#79.7$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#85.4%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.6%$Semantic Segmentation#DensePASS#mIoU#29.5%$Semantic Segmentation#ADE20K#Validation mIoU#44.94$Semantic Segmentation#ADE20K#Test Score#55.38$Semantic Segmentation#ADE20K#Validation mIoU#43.51$Semantic Segmentation#ADE20K#Validation mIoU#43.29$Semantic Segmentation#ADE20K val#mIoU#43.51%$Semantic Segmentation#ADE20K val#mIoU#43.29%$Semantic Segmentation#ScanNetV2#Mean IoU#47.5%$Semantic Segmentation#PASCAL Context#mIoU#47.8$Semantic Segmentation#Trans10K#mIoU#68.23%$Semantic Segmentation#Trans10K#GFLOPs#187.03$Semantic Segmentation#Cityscapes test#Mean IoU (class)#80.2%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#78.4%$Thermal Image Segmentation#MFN Dataset#mIOU#46.1$Real-Time Semantic Segmentation#CamVid#Time (ms)#185.0$Real-Time Semantic Segmentation#CamVid#Frame (fps)#5.4$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#43.2$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#72$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#41.8$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#47$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#35.9$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#19$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.645$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.557$Dichotomous Image Segmentation#DIS-TE1#MAE#0.089$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.725$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.791$Dichotomous Image Segmentation#DIS-TE1#HCE#267$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.724$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.636$Dichotomous Image Segmentation#DIS-TE2#MAE#0.092$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.763$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.828$Dichotomous Image Segmentation#DIS-TE2#HCE#586$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.747$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.657$Dichotomous Image Segmentation#DIS-TE3#MAE#0.092$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.774$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.843$Dichotomous Image Segmentation#DIS-TE3#HCE#1111$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.725$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.630$Dichotomous Image Segmentation#DIS-TE4#MAE#0.107$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.758$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.815$Dichotomous Image Segmentation#DIS-TE4#HCE#3806$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.691$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.603$Dichotomous Image Segmentation#DIS-VD#MAE#0.102$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.744$Dichotomous Image Segmentation#DIS-VD#E-measure#0.802$Dichotomous Image Segmentation#DIS-VD#HCE#1588$Video Semantic Segmentation#Cityscapes val#mIoU#79.7$Video Semantic Segmentation#Cityscapes val#mIoU#78.1
1908.05104v1.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.5349$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.6331$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.5243
1907.07000v2.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.4867$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.3723$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.6000$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.4752
1709.07330v3.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.4741$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.3559$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.5613$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.4875
1711.10684v1.pdf	Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Dice#0.4702$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#IoU#0.3549$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Precision#0.5941$Lesion Segmentation#Anatomical Tracings of Lesions After Stroke (ATLAS)#Recall#0.4537$Retinal Vessel Segmentation#STARE#F1 score#0.8388$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.7800$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9779$Retinal Vessel Segmentation#DRIVE#F1 score#0.8149$Retinal Vessel Segmentation#DRIVE#AUC#0.9779$Lung Nodule Segmentation#LUNA#F1 score#0.9690$Lung Nodule Segmentation#LUNA#AUC#0.9849$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#F1 score#0.8799$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#AUC#0.9396
2111.08708v3.pdf	Lesion Segmentation#ISIC 2018#Dice Score#0.9152
2110.03864v1.pdf	Lesion Segmentation#ISIC 2018#Dice Score#0.912$Lesion Segmentation#ISIC 2018#Mean IoU#0.843
2003.05056v1.pdf	Lesion Segmentation#ISIC 2018#Dice Score#0.895
1807.08891v1.pdf	Lesion Segmentation#University of Waterloo skin cancer database#Dice score#0.883 ±0.108
1503.02351v1.pdf	Lesion Segmentation#University of Waterloo skin cancer database#Dice score#0.870 ±0.063
1703.05165v2.pdf	Lesion Segmentation#ISIC 2017#Mean IoU#0.765
1603.05959v3.pdf	Lesion Segmentation#ISLES-2015#Dice Score#59.0%$Brain Tumor Segmentation#BRATS-2015#Dice Score#85.0%
1810.11654v3.pdf	Brain Tumor Segmentation#BRATS 2018#Dice Score#0.87049
2007.06959v1.pdf	Brain Tumor Segmentation#BRATS 2018#IoU#68.8$Brain Tumor Segmentation#BRATS-2013#Dice Score#92.76$Liver Segmentation#LiTS2017#IoU#85.6$Liver Segmentation#LiTS2017#Dice#92.27$Lung Nodule Segmentation#LIDC-IDRI#IoU#77.24$Lung Nodule Detection#LUNA2016 FPRED#AUC#98.47
2107.12046v1.pdf	Brain Tumor Segmentation#768 chest X-ray images#1:3 Accuracy#8
1505.03540v3.pdf	Brain Tumor Segmentation#BRATS-2013 leaderboard#Dice Score#0.84$Brain Tumor Segmentation#BRATS-2013#Dice Score#0.88
1706.01805v2.pdf	Brain Tumor Segmentation#BRATS-2013 leaderboard#Dice Score#0.84
1709.00382v2.pdf	Brain Tumor Segmentation#BRATS-2014#Dice Score#0.8739$Brain Tumor Segmentation#BRATS-2017 val#Dice Score#0.9050
1906.01796v2.pdf	Brain Tumor Segmentation#BRATS-2017 val#Dice Score#0.9071$Brain Tumor Segmentation#BRATS-2015#Dice Score#87%$Brain Tumor Segmentation#BRATS 2018 val#Dice Score#91.59
1701.03056v2.pdf	Brain Tumor Segmentation#BRATS-2015#Dice Score#85%
1802.10508v1.pdf	Brain Tumor Segmentation#BRATS-2015#Dice Score#85%
1805.08403v3.pdf	Brain Tumor Segmentation#BRATS-2015#Dice Score#84%
2105.09511v3.pdf	Brain Tumor Segmentation#BRATS 2019#TC#0.817$Brain Tumor Segmentation#BRATS 2019#Avg.#0.817$Brain Tumor Segmentation#BRATS 2019#ET#0.740$Brain Tumor Segmentation#BRATS 2019#WT#0.894$Brain Tumor Segmentation#BRATS 2019#TC#0.807$Brain Tumor Segmentation#BRATS 2019#Avg.#0.812$Brain Tumor Segmentation#BRATS 2019#ET#0.729$Brain Tumor Segmentation#BRATS 2019#WT#0.895$Brain Tumor Segmentation#BRATS 2019#TC#0.802$Optic Cup Segmentation#REFUGE Challenge#Dice#0.872
2003.01995v3.pdf	Brain Segmentation#Brain MRI segmentation#Dice Score#0.8690000000000001$Brain Segmentation#Brain MRI segmentation#Dice Scoe#0.861
1906.03720v1.pdf	Brain Segmentation#Brain MRI segmentation#Dice Score#0.82
1805.11247v2.pdf	Cell Segmentation#DIC-C2DH-HeLa#SEG (~Mean IoU)#0.793$Cell Segmentation#DIC-C2DH-HeLa#SEG (~Mean IoU)#0.511$Cell Segmentation#Fluo-N2DH-SIM+#SEG (~Mean IoU)#0.811$Cell Segmentation#Fluo-N2DH-SIM+#SEG (~Mean IoU)#0.802$Cell Segmentation#PhC-C2DH-U373#SEG (~Mean IoU)#0.842$Cell Segmentation#Fluo-N2DH-GOWT1#SEG (~Mean IoU)#0.854$Cell Segmentation#Fluo-N2DH-GOWT1#SEG (~Mean IoU)#0.85$Cell Segmentation#Fluo-N2DL-HeLa#SEG (~Mean IoU)#0.839$Cell Segmentation#Fluo-N2DL-HeLa#SEG (~Mean IoU)#0.811
2004.01486v4.pdf	Cell Segmentation#Fluo-C3DL-MDA231#SEG (~Mean IoU)#0.616$Cell Segmentation#Fluo-N2DL-HeLa#SEG (~Mean IoU)#0.895
2203.14341v2.pdf	Skin Lesion Segmentation#ISIC 2017#Mean IoU#97.4$Semantic Segmentation#PH2#Average Dice#95.4$Semantic Segmentation#PH2#Average IOU#0.914$Semantic Segmentation#HAM10000#Average Dice#90.6$Semantic Segmentation#HAM10000#Average IOU#90.2$Semantic Segmentation#ISIC 2017#Average Dice#98.7
1802.06955v5.pdf	Retinal Vessel Segmentation#STARE#F1 score#0.8475$Retinal Vessel Segmentation#STARE#AUC#0.9914$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.7928$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9815$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#F1 score#0.8920$Skin Cancer Segmentation#Kaggle Skin Lesion Segmentation#AUC#0.9419
2101.00535v2.pdf	Retinal Vessel Segmentation#STARE#F1 score#0.8323$Retinal Vessel Segmentation#STARE#AUC#0.9887$Retinal Vessel Segmentation#STARE#mIOU#0.9754$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8957$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9914$Retinal Vessel Segmentation#CHASE_DB1#mIOU#0.9705$Retinal Vessel Segmentation#DRIVE#F1 score#0.8690$Retinal Vessel Segmentation#DRIVE#AUC#0.9887$Retinal Vessel Segmentation#DRIVE#Accuracy#0.9790$Retinal Vessel Segmentation#DRIVE#mIoU#0.9762
1806.02279v1.pdf	Retinal Vessel Segmentation#STARE#F1 score#0.8429$Retinal Vessel Segmentation#STARE#AUC#0.9877$Retinal Vessel Segmentation#HRF#AUC#0.9838$Retinal Vessel Segmentation#HRF#F1 score#0.8151$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8034$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9830$Retinal Vessel Segmentation#DRIVE#F1 score#0.8263$Retinal Vessel Segmentation#DRIVE#AUC#0.9802
1811.01206v1.pdf	Retinal Vessel Segmentation#STARE#F1 score#0.8143$Retinal Vessel Segmentation#STARE#AUC#0.9832$Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.7883$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9804$Retinal Vessel Segmentation#DRIVE#F1 score#0.8237$Retinal Vessel Segmentation#DRIVE#AUC#0.9802
2103.03451v1.pdf	Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8271$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9920$Retinal Vessel Segmentation#DRIVE#F1 score#0.8316$Retinal Vessel Segmentation#DRIVE#AUC#0.9886
2004.03696v3.pdf	Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8153$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9905$Retinal Vessel Segmentation#DRIVE#F1 score#0.8263$Retinal Vessel Segmentation#DRIVE#AUC#0.9864$Retinal Vessel Segmentation#DRIVE#Accuracy#0.9698
1912.05763v1.pdf	Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8073$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9851$Retinal Vessel Segmentation#DRIVE#F1 score#0.8205$Retinal Vessel Segmentation#DRIVE#AUC#0.9816
1810.07810v4.pdf	Retinal Vessel Segmentation#CHASE_DB1#F1 score#0.8031$Retinal Vessel Segmentation#CHASE_DB1#AUC#0.9839$Retinal Vessel Segmentation#DRIVE#F1 score#0.8202$Retinal Vessel Segmentation#DRIVE#AUC#0.9793
2105.09365v2.pdf	Retinal Vessel Segmentation#DRIVE#AUC#0.9855$Retinal Vessel Segmentation#DRIVE#Accuracy#0.9712
1907.10936v1.pdf	Retinal Vessel Segmentation#DRIVE#Accuracy#0.956$Retinal Vessel Segmentation#DRIVE#mIoU#0.7744$Lung Nodule Segmentation#Montgomery County#Accuracy#0.9865$Lung Nodule Segmentation#Montgomery County#mIoU#0.942$Lung Nodule Segmentation#LUNA#Accuracy#0.9868$Lung Nodule Segmentation#LUNA#mIoU#0.9623
1702.00045v1.pdf	3D Medical Imaging Segmentation#TCIA Pancreas-CT#Dice Score#81.3
1803.05431v2.pdf	3D Medical Imaging Segmentation#TCIA Pancreas-CT#Dice Score#76.8
1804.03999v3.pdf	Pancreas Segmentation#CT-150#Precision#0.849$Pancreas Segmentation#CT-150#Recall#0.841$Pancreas Segmentation#TCIA Pancreas-CT Dataset#Dice Score#0.831
1709.04518v4.pdf	Pancreas Segmentation#TCIA Pancreas-CT Dataset#Dice Score#0.845
2202.00677v2.pdf	Semi-supervised Medical Image Segmentation#MM-WHS 2017#DSC#79.83$Semi-supervised Medical Image Segmentation#Automatic Cardiac Diagnosis Challenge (ACDC)#DSC#89.8
1709.02974v4.pdf	Brain Image Segmentation#SegEM#IED#4.839$Brain Image Segmentation#CREMI#VOI#0.606$Brain Image Segmentation#CREMI#CREMI Score#0.289$Brain Image Segmentation#FIB-25 Synaptic Sites#VOI#2.151$Brain Image Segmentation#FIB-25 Whole Test#VOI#1.071
1902.09383v2.pdf	Brain Image Segmentation#T1-weighted MRI#Dice Score#81.5
1606.04797v1.pdf	Volumetric Medical Image Segmentation#PROMISE 2012#Dice Score#0.869
1807.07464v1.pdf	Volumetric Medical Image Segmentation#PROMISE 2012#Dice Score#0.780
1901.11195v2.pdf	Iris Segmentation#UBIRIS#F1#91.82$Iris Segmentation#UBIRIS#mIoU#85.39$Iris Segmentation#CASIA#F1#94.30$Iris Segmentation#CASIA#mIoU#89.4$Iris Segmentation#MICHE#F1#91.5$Iris Segmentation#MICHE#mIoU#85.07
2203.14291v3.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.806$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.798$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.676$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.730$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.756$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.630$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.797$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.793$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.653$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.709$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.737$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.623
2105.08468v2.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.767$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.744$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.616$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.664$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.676$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.574$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.767$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.755$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.609$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.656$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.675$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.579
2108.03151v3.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.725$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.695$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.551$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.630$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.702$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.493$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.724$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.694$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.541$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.611$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.699$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.491$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.4$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#94.5$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#3.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#83.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#90.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#2.6$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#83.25
2108.00882v1.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.720$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.745$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.566$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.634$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.649$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.521$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.706$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.743$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.526$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.580$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.598$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.505
2001.06810v1.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.654$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.600$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.431$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.496$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.596$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.359$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.670$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.627$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.443$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.506$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.606$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.380$Unsupervised Video Object Segmentation#FBMS#Jaccard (Mean)#75.6$Unsupervised Video Object Segmentation#YouTube#mIoU#0.705$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#80.5$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#93.1$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#4.4$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#79.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#89.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.0$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#80
2111.06394v1.pdf	Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#S measure#0.474$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean E-measure#0.533$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#weighted F-measure#0.133$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#mean F-measure#0.146$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Dice#0.266$Video Polyp Segmentation#SUN-SEG-Easy (Unseen)#Sensitivity#0.222$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#S-Measure#0.472$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean E-measure#0.527$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#weighted F-measure#0.128$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#mean F-measure#0.141$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Dice#0.252$Video Polyp Segmentation#SUN-SEG-Hard (Unseen)#Sensitivity#0.213
1904.09229v1.pdf	Lung Nodule Segmentation#NIH#AVD#0.262$Lung Nodule Segmentation#NIH#Dice Score#0.962$Lung Nodule Segmentation#NIH#Precision#0.969$Lung Nodule Segmentation#NIH#Recall#0.956$Lung Nodule Segmentation#NIH#VS#0.985
1712.05319v2.pdf	Infant Brain Mri Segmentation#iSEG 2017 Challenge#Dice Score#0.9243
2104.03310v1.pdf	Image Generation#CAT 256x256#FID#10.16$Image Generation#CIFAR-10#FID#2.47$Image Generation#CIFAR-10#FID#8.46$Image Generation#CIFAR-100#FID#2.99$Image Generation#CIFAR-100#FID#11.2$Image Generation#ImageNet - 10% labeled data#FID#24.38$Image Generation#ImageNet - 10% labeled data#IS#42.3$Image Generation#FFHQ 256 x 256#FID#3.49$Image Generation#25% ImageNet 128x128#FID#11.16$Image Generation#25% ImageNet 128x128#IS#84.7$Image Generation#ImageNet 128x128#FID#6.54$Image Generation#ImageNet 128x128#IS#108
1807.00734v3.pdf	Image Generation#CAT 256x256#FID#32.11$Image Generation#CIFAR-10#FID#25.60
1907.13052v4.pdf	Image Generation#GQN#FID#80.5$Image Generation#Multi-dSprites#FID#24.9
2202.00273v2.pdf	Image Generation#FFHQ 1024 x 1024#FID#2.02$Image Generation#CIFAR-10#FID#1.85$Image Generation#Pokemon 256x256#FID#23.97$Image Generation#ImageNet 64x64#Inception Score#4.06$Image Generation#ImageNet 64x64#FID#1.51$Image Generation#Pokemon 1024x1024#FID#25.47$Image Generation#ImageNet 32x32#FID#1.10$Image Generation#FFHQ 512 x 512#FID#2.41$Image Generation#FFHQ 256 x 256#FID#2.19$Image Generation#ImageNet 256x256#FID#2.3$Image Generation#ImageNet 512x512#FID#2.40$Image Generation#ImageNet 128x128#FID#1.81
2203.01993v2.pdf	Image Generation#FFHQ 1024 x 1024#FID#2.57$Image Generation#LSUN Car 512 x 384#FID#2.27$Image Generation#LSUN Cat 256 x 256#FID#6.34$Image Generation#AFHQV2#FID#3.95$Image Generation#LSUN Churches 256 x 256#FID#3.92$Image Generation#CelebA-HQ 1024x1024#FID#7.28$Image Generation#ImageNet 256x256#FID#6.82
2110.08009v3.pdf	Image Generation#FFHQ 1024 x 1024#FID#2.66
2106.12423v4.pdf	Image Generation#FFHQ 1024 x 1024#FID#2.79$Image Generation#FFHQ 1024 x 1024#FID#3.07$Image Generation#MetFaces-U#FID#18.75$Image Generation#MetFaces-U#EQ-T#66.34$Image Generation#MetFaces-U#EQ-R#48.57$Image Generation#MetFaces-U#EQ-T#64.11$Image Generation#MetFaces-U#EQ-R#16.63$Image Generation#MetFaces-U#FID#18.98$Image Generation#MetFaces-U#EQ-T#18.77$Image Generation#MetFaces-U#EQ-R#13.19$Image Generation#FFHQ-U#FID#3.66$Image Generation#FFHQ-U#EQ-T#64.78$Image Generation#FFHQ-U#EQ-R#47.64$Image Generation#FFHQ-U#FID#3.67$Image Generation#FFHQ-U#EQ-T#61.69$Image Generation#FFHQ-U#EQ-R#13.95$Image Generation#FFHQ-U#FID#3.79$Image Generation#FFHQ-U#EQ-T#15.89$Image Generation#FFHQ-U#EQ-R#10.79$Image Generation#FFHQ-U#FID#4.50$Image Generation#FFHQ-U#EQ-T#66.65$Image Generation#FFHQ-U#EQ-R#40.48$Image Generation#FFHQ-U#FID#4.54$Image Generation#FFHQ-U#EQ-T#15.81$Image Generation#FFHQ-U#EQ-R#10.84$Image Generation#FFHQ-U#FID#4.62$Image Generation#FFHQ-U#EQ-T#63.01$Image Generation#FFHQ-U#EQ-R#13.12$Image Generation#FFHQ-U#FID#4.64$Image Generation#FFHQ-U#EQ-T#45.20$Image Generation#FFHQ-U#EQ-R#10.61$Image Generation#FFHQ-U#FID#4.78$Image Generation#FFHQ-U#EQ-T#43.90$Image Generation#FFHQ-U#FID#4.79$Image Generation#FFHQ-U#EQ-T#16.23$Image Generation#FFHQ-U#EQ-R#10.81$Image Generation#FFHQ-U#FID#5.14$Image Generation#FFHQ-U#FID#5.21$Image Generation#FFHQ-U#EQ-T#19.47$Image Generation#FFHQ-U#EQ-R#10.41$Image Generation#FFHQ-U#FID#6.02$Image Generation#FFHQ-U#EQ-T#24.62$Image Generation#FFHQ-U#EQ-R#10.97$Image Generation#FFHQ-U#FID#6.35$Image Generation#FFHQ-U#EQ-T#30.60$Image Generation#AFHQV2#FID#4.04$Image Generation#AFHQV2#EQ-T#60.15$Image Generation#AFHQV2#EQ-R#13.51$Image Generation#AFHQV2#FID#4.40$Image Generation#AFHQV2#EQ-T#64.89$Image Generation#AFHQV2#EQ-R#40.34$Image Generation#AFHQV2#FID#4.62$Image Generation#AFHQV2#EQ-T#13.83$Image Generation#AFHQV2#EQ-R#11.50
2206.02262v3.pdf	Image Generation#FFHQ 1024 x 1024#FID#2.83$Image Generation#CIFAR-10#FID#2.25$Image Generation#CIFAR-10#FID#2.67$Image Generation#CIFAR-10#FID#3.19$Image Generation#AFHQ Dog#FID#4.83$Image Generation#AFHQ Wild#FID#1.51$Image Generation#LSUN Bedroom 256 x 256#FID#1.43$Image Generation#LSUN Bedroom 256 x 256#FID#3.65$Image Generation#LSUN Churches 256 x 256#FID#1.85$Image Generation#LSUN Churches 256 x 256#FID#3.17$Image Generation#AFHQ Cat#FID#2.40$Image Generation#CelebA 64x64#FID#1.69$Image Generation#STL-10#FID#6.91$Image Generation#STL-10#FID#11.53
2102.06108v1.pdf	Image Generation#FFHQ 1024 x 1024#FID#4.06$Image Generation#FFHQ 256 x 256#FID#5.22$Image Generation#LSUN Churches 256 x 256#FID#4.97
1812.04948v3.pdf	Image Generation#FFHQ 1024 x 1024#FID#4.4$Image Generation#LSUN Horse 256 x 256#Clean-FID (trainfull)#4.78 ± 0.03$Image Generation#LSUN Cat 256 x 256#Clean-FID (trainfull)#8.72 ± 0.03$Image Generation#LSUN Churches 256 x 256#FID#4.21$Image Generation#LSUN Churches 256 x 256#Clean-FID (trainfull)#4.75 ± 0.01$Image Generation#CelebA-HQ 1024x1024#FID#5.06$Image Generation#LSUN Bedroom#FID-50k#2.65
2112.10762v2.pdf	Image Generation#FFHQ 1024 x 1024#FID#5.07$Image Generation#CelebA 256x256#FID#3.25$Image Generation#FFHQ 256 x 256#FID#2.81$Image Generation#LSUN Churches 256 x 256#FID#2.95$Image Generation#CelebA-HQ 256x256#FID#3.25$Image Generation#CelebA-HQ 1024x1024#FID#4.43
1903.06048v4.pdf	Image Generation#FFHQ 1024 x 1024#FID#5.8$Image Generation#CIFAR-10#Inception score#7.92$Image Generation#Indian Celebs 256 x 256#FID#28.44$Image Generation#Oxford 102 Flowers 256 x 256#FID#19.60$Image Generation#LSUN Churches 256 x 256#FID#5.2$Image Generation#LSUN Churches 256 x 256#Clean-FID (trainfull)#5.38 ± 0.03$Image Generation#CelebA-HQ 1024x1024#FID#6.37
2106.07631v3.pdf	Image Generation#FFHQ 1024 x 1024#FID#6.37$Image Generation#CelebA 256x256#FID#3.39$Image Generation#FFHQ 256 x 256#FID#2.58$Image Generation#FFHQ 256 x 256#FID#2.95$Image Generation#FFHQ 256 x 256#FID#3.06$Image Generation#CelebA-HQ 1024x1024#FID#8.83$Image Generation#ImageNet 128x128#FID#30.83
2011.13775v1.pdf	Image Generation#FFHQ 1024 x 1024#FID#10.07$Image Generation#Landscapes 256 x 256#FID#3.61$Image Generation#FFHQ 256 x 256#FID#4.38$Image Generation#Satellite-Buildings 256 x 256#FID#69.67$Image Generation#LSUN Churches 256 x 256#FID#2.92$Image Generation#Satellite-Landscapes 256 x 256#FID#48.47
2004.04467v1.pdf	Image Generation#FFHQ 1024 x 1024#FID#13.09$Image Generation#CelebA 256x256#FID#19.21
2203.13751v2.pdf	Image Generation#FFHQ 1024 x 1024#bits/dimension#2.30$Image Generation#CIFAR-10#bits/dimension#2.87$Image Generation#ImageNet 64x64#Bits per dim#3.30$Image Generation#CelebA 256x256#bpd#0.51$Image Generation#CelebA 256x256#bpd (8-bits)#1.35$Image Generation#ImageNet 32x32#bpd#3.58$Image Generation#FFHQ 256 x 256#bits/dimension#0.53$Image Generation#FFHQ 256 x 256#bits/dimension (8-bits)#2.17$Image Generation#CelebA 64x64#bits/dimension#1.83$Image Generation#CelebA-HQ 1024x1024#bits/dimension#1.01$Image Generation#Binarized MNIST#nats#79.09
2011.10650v2.pdf	Image Generation#FFHQ 1024 x 1024#bits/dimension#2.42$Image Generation#CIFAR-10#bits/dimension#2.87$Image Generation#ImageNet 64x64#Bits per dim#3.52$Image Generation#ImageNet 32x32#bpd#3.8$Image Generation#FFHQ 256 x 256#bits/dimension#0.61
1904.00284v4.pdf	Image Generation#CelebA-HQ 64x64#FID#4.0$Image Generation#CelebA-HQ 128x128#FID#5.74$Image Generation#CelebA 128 x 128#FID#5.74$Image Generation#CelebA-HQ 1024x1024#FID#9.49
2010.00654v3.pdf	Image Generation#CelebA-HQ 64x64#FID#5.31$Image Generation#CIFAR-10#Inception score#8.43$Image Generation#CIFAR-10#FID#12.19$Image Generation#CIFAR-10#Inception score#8.21$Image Generation#CIFAR-10#FID#12.26$Image Generation#Stacked MNIST#FID#12.96$Image Generation#Stacked MNIST#Inception score#8.15$Image Generation#CelebA-HQ 256x256#FID#20.38
1911.03149v1.pdf	Image Generation#CelebA-HQ 64x64#FID#6.42
2103.01209v4.pdf	Image Generation#Cityscapes#FID-10k-training-steps#5.7589$Image Generation#Cityscapes#FID-10k-training-steps#8.35$Image Generation#Cityscapes#FID-10k-training-steps#11.5652$Image Generation#Cityscapes#FID-10k-training-steps#12.8077$Image Generation#Cityscapes#FID-10k-training-steps#173.7971$Image Generation#CLEVR#FID-5k-training-steps#9.1679$Image Generation#CLEVR#FID-5k-training-steps#16.0534$Image Generation#CLEVR#FID-5k-training-steps#25.0244$Image Generation#CLEVR#FID-5k-training-steps#26.0433$Image Generation#CLEVR#FID-5k-training-steps#32.6031$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#6.5085$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#11.5255$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#12.1567$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#14.0595$Image Generation#LSUN Bedroom 256 x 256#FID-10k-training-steps#59.6333$Image Generation#FFHQ 256 x 256#FID#7.42
2106.05931v3.pdf	Image Generation#CIFAR-10#FID#2.10$Image Generation#CIFAR-10#bits/dimension#3.43$Image Generation#CIFAR-10#FID#2.17$Image Generation#CIFAR-10#bits/dimension#2.95$Image Generation#CIFAR-10#FID#6.89$Image Generation#CIFAR-10#bits/dimension#2.87$Image Generation#CelebA 256x256#bpd#0.70$Image Generation#CelebA 256x256#FID#7.22$Image Generation#CelebA-HQ 256x256#FID#7.22
2205.01490v1.pdf	Image Generation#CIFAR-10#Inception score#9.99$Image Generation#CIFAR-10#FID#2.17
2011.13456v2.pdf	Image Generation#CIFAR-10#Inception score#9.73$Image Generation#CIFAR-10#FID#2.20$Image Generation#CIFAR-10#Inception score#9.83$Image Generation#CIFAR-10#FID#2.41
2112.07068v4.pdf	Image Generation#CIFAR-10#FID#2.23$Image Generation#CIFAR-10#FID#2.25$Image Generation#CIFAR-10#bits/dimension#3.31
2205.13699v3.pdf	Image Generation#CIFAR-10#FID#2.28$Image Generation#CIFAR-10#bits/dimension#3.09$Image Generation#CIFAR-10#FID#3.25$Image Generation#CIFAR-10#bits/dimension#3.01$Image Generation#CIFAR-10#FID#4.79$Image Generation#CIFAR-10#bits/dimension#2.97$Image Generation#CelebA 64x64#FID#1.75$Image Generation#CelebA 64x64#FID#2.54
2106.05527v5.pdf	Image Generation#CIFAR-10#FID#2.33$Image Generation#CIFAR-10#bits/dimension#3.04$Image Generation#CIFAR-10#Inception score#9.78$Image Generation#CIFAR-10#FID#2.47$Image Generation#CIFAR-10#bits/dimension#2.91$Image Generation#CIFAR-10#Inception score#9.17$Image Generation#CIFAR-10#FID#3.45$Image Generation#CIFAR-10#bits/dimension#2.88$Image Generation#CIFAR-10#Inception score#10.11$Image Generation#LSUN Bedroom 256 x 256#FID#4.57$Image Generation#ImageNet 32x32#bpd#3.85$Image Generation#ImageNet 32x32#FID#8.42$Image Generation#ImageNet 32x32#Inception score#11.82$Image Generation#FFHQ 256 x 256#FID#5.54$Image Generation#CelebA 64x64#FID#1.9$Image Generation#CelebA 64x64#bits/dimension#2.1$Image Generation#CelebA 64x64#FID#2.9$Image Generation#CelebA 64x64#bits/dimension#1.96$Image Generation#CelebA 64x64#bits/dimension#1.97$Image Generation#CelebA-HQ 256x256#FID#7.16$Image Generation#STL-10#FID#7.71$Image Generation#STL-10#Inception score#13.43
2203.13508v1.pdf	Image Generation#CIFAR-10#FID#2.38$Speech Synthesis#LJSpeech#Mean Opinion Score#4.48
2108.03702v3.pdf	Image Generation#CIFAR-10#Inception score#10.07$Image Generation#CIFAR-10#FID#2.41$Image Generation#ImageNet 256x256#FID#3.63$Image Generation#ImageNet 256x256#Inception score#260.02$Image Generation#ImageNet 256x256#FID#3.69$Image Generation#ImageNet 256x256#Inception score#249.91$Image Generation#ImageNet 128x128#FID#2.53$Image Generation#ImageNet 128x128#IS#169.73$Image Generation#ImageNet 128x128#FID#2.77$Image Generation#ImageNet 128x128#IS#150.43
2209.11178v4.pdf	Image Generation#CIFAR-10#Inception score#9.68$Image Generation#CIFAR-10#FID#2.48
2106.07023v3.pdf	Image Generation#CIFAR-10#Inception score#9.94$Image Generation#CIFAR-10#FID#2.82$Image Generation#STL-10#FID#15.17$Image Generation#STL-10#Inception score#11.01
2110.11291v4.pdf	Image Generation#CIFAR-10#FID#3.01$Image Generation#CIFAR-10#bits/dimension#2.96
2006.11239v2.pdf	Image Generation#CIFAR-10#Inception score#9.46$Image Generation#CIFAR-10#FID#3.17$Image Generation#CIFAR-10#bits/dimension#3.75$Image Generation#CIFAR-10#FID#13.51$Image Generation#CIFAR-10#bits/dimension#3.7$Image Generation#LSUN Bedroom 256 x 256#FID#4.9$Image Generation#LSUN Bedroom 256 x 256#FID#6.36$Image Generation#LSUN Cat 256 x 256#FID#19.75$Image Generation#LSUN Churches 256 x 256#FID#7.89$Image Generation#LSUN Bedroom#FID-50k#4.9
2202.09778v2.pdf	Image Generation#CIFAR-10#FID#3.26$Image Generation#LSUN Bedroom 256 x 256#FID#5.68$Image Generation#LSUN Churches 256 x 256#FID#8.69$Image Generation#CelebA 64x64#FID#2.71
2210.05475v1.pdf	Image Generation#CIFAR-10#FID#3.64$Image Generation#CIFAR-10#FID#3.67$Image Generation#CIFAR-10#FID#3.94$Image Generation#CIFAR-10#FID#4.49$Image Generation#CIFAR-10#FID#5.28$Image Generation#CIFAR-10#FID#5.97$Image Generation#CIFAR-10#FID#11.2$Image Generation#CIFAR-10#FID#13.9$Image Generation#AFHQV2#FID#4.83$Image Generation#AFHQV2#FID#4.9$Image Generation#AFHQV2#FID#5.53
2009.05475v2.pdf	Image Generation#CIFAR-10#FID#3.65
2112.07804v2.pdf	Image Generation#CIFAR-10#Inception score#9.63$Image Generation#CIFAR-10#FID#3.75$Image Generation#LSUN Churches 256 x 256#FID#5.25$Image Generation#CelebA-HQ 256x256#FID#7.64
2201.00308v2.pdf	Image Generation#CIFAR-10#FID#3.77$Image Generation#CelebA 64x64#FID#3.97
2107.00630v4.pdf	Image Generation#CIFAR-10#FID#4.0$Image Generation#CIFAR-10#bits/dimension#2.49$Image Generation#ImageNet 64x64#Bits per dim#3.40$Image Generation#ImageNet 32x32#bpd#3.72
2006.10738v4.pdf	Image Generation#CIFAR-10#Inception score#9.17$Image Generation#CIFAR-10#FID#4.30$Image Generation#CIFAR-10#FID-10k-test#8.49$Image Generation#CIFAR-10#Inception score#9.16$Image Generation#CIFAR-10#FID#4.61$Image Generation#CIFAR-10#FID-10k-test#8.7$Image Generation#CIFAR-10#Inception score#9.40$Image Generation#CIFAR-10#FID#5.79$Image Generation#CIFAR-10#FID-10k-test#9.89$Image Generation#CIFAR-10#Inception score#9.18$Image Generation#CIFAR-10#FID#11.07$Image Generation#CIFAR-10#Clean-FID-10k#7.361$Image Generation#CIFAR-10 (10% data)#FID#14.5$Image Generation#CIFAR-10 (10% data)#FID#18.7$Image Generation#CIFAR-10 (10% data)#FID#22.4$Image Generation#CIFAR-10 (20% data)#FID#12.15$Image Generation#CIFAR-10 (20% data)#FID#12.84$Image Generation#CIFAR-10 (20% data)#FID#14.04$Image Generation#ImageNet 128x128#FID#6.8$Image Generation#ImageNet 128x128#IS#100.8
2107.04589v1.pdf	Image Generation#CIFAR-10#Inception score#9.89$Image Generation#CIFAR-10#FID#4.57$Image Generation#CIFAR-10#Inception score#9.3$Image Generation#CIFAR-10#FID#6.66
2104.00816v2.pdf	Image Generation#CIFAR-10#Inception score#8.81$Image Generation#CIFAR-10#FID#8.93$Image Generation#ImageNet 64x64#Bits per dim#23.31$Image Generation#ImageNet 64x64#FID#21.73$Image Generation#STL-10#FID#19.52$Image Generation#STL-10#Inception score#11.16$Image Generation#ImageNet 128x128#FID#21.73$Image Generation#ImageNet 128x128#IS#23.31
2102.07074v4.pdf	Image Generation#CIFAR-10#Inception score#9.02$Image Generation#CIFAR-10#FID#9.26$Image Generation#CelebA 64x64#FID#12.23$Image Generation#STL-10#FID#18.28$Image Generation#STL-10#Inception score#10.43
2101.02388v1.pdf	Image Generation#CIFAR-10#Inception score#8.36$Image Generation#CIFAR-10#FID#9.36
2012.08125v2.pdf	Image Generation#CIFAR-10#Inception score#8.58$Image Generation#CIFAR-10#FID#9.6$Image Generation#CIFAR-10#bits/dimension#3.18$Image Generation#CelebA 64x64#FID#5.98
2012.00780v4.pdf	Image Generation#CIFAR-10#Inception score#9.35$Image Generation#CIFAR-10#FID#9.62$Text Generation#One Billion Word#JS-4#0.186
2010.09893v1.pdf	Image Generation#CIFAR-10#FID#9.80$Image Generation#CelebA-HQ 128x128#FID#16.84
2111.15097v2.pdf	Image Generation#CIFAR-10#Inception score#8.81$Image Generation#CIFAR-10#FID#9.91$Image Generation#CIFAR-10#FID#10.14$Image Generation#STL-10#FID#22.18$Image Generation#STL-10#Inception score#10.44$Image Generation#STL-10#FID#23.34$Image Generation#STL-10#Inception score#10.02
2006.06900v4.pdf	Image Generation#CIFAR-10#Inception score#8.69$Image Generation#CIFAR-10#FID#10.7$Text Generation#EMNLP2017 WMT#BLEU-2#0.905$Text Generation#EMNLP2017 WMT#BLEU-3#0.692$Text Generation#EMNLP2017 WMT#BLEU-4#0.47$Text Generation#EMNLP2017 WMT#BLEU-5#0.322$Text Generation#EMNLP2017 WMT#NLLgen#2.265
2006.09011v2.pdf	Image Generation#CIFAR-10#Inception score#8.40$Image Generation#CIFAR-10#FID#10.87
2007.09180v1.pdf	Image Generation#CIFAR-10#Inception score#8.51$Image Generation#CIFAR-10#FID#11.26$Image Generation#STL-10#FID#25.35$Image Generation#STL-10#Inception score#9.51
1911.06997v2.pdf	Image Generation#CIFAR-10#FID#11.40$Image Generation#CIFAR-100#FID#19.74$Image Generation#ImageNet 32x32#FID#12.3
1912.00606v3.pdf	Image Generation#CIFAR-10#Inception score#8.37$Image Generation#CIFAR-10#FID#12.01$Image Generation#STL-10#FID#28.76$Image Generation#STL-10#Inception score#9.71
1908.03835v1.pdf	Image Generation#CIFAR-10#Inception score#8.55$Image Generation#CIFAR-10#FID#12.42$Image Generation#STL-10#FID#31.01$Image Generation#STL-10#Inception score#9.16
1907.05681v3.pdf	Image Generation#CIFAR-10#Inception score#8.34$Image Generation#CIFAR-10#FID#12.96
1910.08967v2.pdf	Image Generation#CIFAR-10#Inception score#8.51$Image Generation#CIFAR-10#FID#14.41
1811.11212v2.pdf	Image Generation#CIFAR-10#FID#15.65$Image Generation#CelebA-HQ 128x128#FID#24.36$Image Generation#LSUN Bedroom 256 x 256#FID#13.3$Image Generation#ImageNet 128x128#FID#43.87
1901.10422v3.pdf	Image Generation#CIFAR-10#FID#16.1$Image Generation#CelebA-HQ 128x128#FID#15.4
1812.09916v4.pdf	Image Generation#CIFAR-10#Inception score#8.29$Image Generation#CIFAR-10#FID#16.21$Image Generation#STL-10#FID#37.63$Image Generation#STL-10#Inception score#9.34
2004.01704v1.pdf	Image Generation#CIFAR-10#Inception score#9.11$Image Generation#CIFAR-10#FID#16.24$Image Generation#CIFAR-10#Inception score#8.54$Image Generation#CIFAR-10#FID#21.67$Image Generation#STL-10#FID#17.68$Image Generation#STL-10#Inception score#9.33$Image Generation#STL-10#FID#22.25$Image Generation#STL-10#Inception score#9.25
2003.03828v2.pdf	Image Generation#CIFAR-10#Inception score#8.49$Image Generation#CIFAR-10#FID#16.79$Graph Representation Learning#COMA#Error (mm)#0.474
1803.08887v3.pdf	Image Generation#CIFAR-10#FID#17.61$Image Generation#STL-10#FID#36.19
2011.10063v1.pdf	Image Generation#CIFAR-10#Inception score#8.2$Image Generation#CIFAR-10#FID#17.9$Image Generation#CelebA 128x128#FID#19.9$Image Generation#CelebA-HQ 256x256#FID#15.81$Image Generation#LSUN Bedroom 128 x 128#FID#14.3$Image Generation#STL-10#FID#41.9$Image Generation#STL-10#Inception score#8.1
2108.07387v1.pdf	Image Generation#CIFAR-10#Inception score#7.71$Image Generation#CIFAR-10#FID#19.66$Image Classification#ImageNet#Top 1 Accuracy#79.03%$Image Classification#ImageNet#Top 5 Accuracy#94.52%$Image Classification#ImageNet#Number of params#60M
1906.04659v3.pdf	Image Generation#CIFAR-10#Inception score#8.53$Image Generation#CIFAR-10#FID#19.83
2101.07524v3.pdf	Image Generation#CIFAR-10#Inception score#7.45$Image Generation#CIFAR-10#FID#21.55$Image Generation#MNIST#FID#7.87$Image Generation#CelebA 64x64#FID#13.95$Image Generation#Fashion-MNIST#FID#21.73$Image Generation#STL-10#FID#51.37
1802.05957v1.pdf	Image Generation#CIFAR-10#Inception score#8.22$Image Generation#CIFAR-10#FID#21.7$Image Generation#STL-10#FID#40.1$Image Generation#STL-10#Inception score#9.10
2010.02917v3.pdf	Image Generation#CIFAR-10#FID#24.08$Image Generation#CelebA 256x256#FID#24.79$Image Generation#CelebA 64x64#FID#5.25
1706.08500v6.pdf	Image Generation#CIFAR-10#FID#24.8$Image Generation#LSUN Bedroom 64 x 64#FID#9.5
1805.11565v5.pdf	Image Generation#CIFAR-10#Inception score#7.3$Image Generation#CIFAR-10#FID#25.0
1907.05600v3.pdf	Image Generation#CIFAR-10#Inception score#8.87$Image Generation#CIFAR-10#FID#25.32
1910.06922v2.pdf	Image Generation#CIFAR-10#FID#27.12
1802.04591v2.pdf	Image Generation#CIFAR-10#FID#27.4$Image Generation#LSUN Bedroom 64 x 64#FID#11.4
2104.09630v2.pdf	Image Generation#CIFAR-10#Inception score#4.7128$Image Generation#CIFAR-10#FID#31.966$Image Generation#Oxford 102 Flowers 128x128#FID#115.838$Image Generation#Oxford 102 Flowers 128x128#IS#3$Image Generation#CelebA-HQ 128x128#FID#29.417$Image Generation#CelebA-HQ 128x128#IS#2.249$Image Generation#STL-10#FID#59.611$Image Generation#STL-10#Inception score#4.987
2106.04627v3.pdf	Image Generation#CIFAR-10#FID#34.90$Image Generation#CIFAR-10#bits/dimension#2.98$Image Generation#ImageNet 64x64#Bits per dim#3.35$Image Generation#ImageNet 32x32#bpd#3.63$Image Generation#CelebA 64x64#bits/dimension#1.99
1905.10485v2.pdf	Image Generation#CIFAR-10#FID#44.6$Image Generation#CelebA 256x256#FID#41.8$Image Generation#MNIST#FID#5.8$Image Generation#Fashion-MNIST#FID#10.3
1906.02735v6.pdf	Image Generation#CIFAR-10#FID#46.37$Image Generation#CIFAR-10#bits/dimension#3.28$Image Generation#ImageNet 64x64#Bits per dim#3.757$Image Generation#CelebA 256x256#bpd#0.992$Image Generation#ImageNet 32x32#bpd#4.01$Image Generation#MNIST#bits/dimension#0.97
1910.04302v1.pdf	Image Generation#CIFAR-10#FID#52.202$Image Generation#Stacked MNIST#FID#23.965$Image Generation#MNIST#FID#42.019$Image Generation#CelebA 128 x 128#FID#29.115
2106.12562v1.pdf	Image Generation#CIFAR-10#FID#69.89$Image Generation#MNIST#FID#38.53$Image Generation#CelebA 64x64#FID#128.35
2105.14080v1.pdf	Image Generation#CIFAR-10#Inception score#9.87$Image Generation#FFHQ 256 x 256#FID#15.67$Image Generation#LSUN Churches 256 x 256#FID#26.46
1710.10196v3.pdf	Image Generation#CIFAR-10#Inception score#8.8$Image Generation#LSUN Horse 256 x 256#Clean-FID (trainfull)#14.09 ± 0.06$Image Generation#LSUN Bedroom 256 x 256#FID#8.34$Image Generation#LSUN Cat 256 x 256#FID#37.52$Image Generation#LSUN Cat 256 x 256#Clean-FID (trainfull)#38.35 ± 0.32$Image Generation#LSUN Churches 256 x 256#FID#6.42$Image Generation#LSUN Churches 256 x 256#Clean-FID (trainfull)#6.43 ± 0.05$Image Generation#CelebA-HQ 256x256#FID#8.03$Image Generation#CelebA-HQ 1024x1024#FID#7.3
1909.13188v4.pdf	Image Generation#CIFAR-10#Inception score#8.54
1906.09453v2.pdf	Image Generation#CIFAR-10#Inception score#7.5
1611.01673v3.pdf	Image Generation#CIFAR-10#Inception score#6.00
1703.10717v4.pdf	Image Generation#CIFAR-10#Inception score#5.62
2105.14859v2.pdf	Image Generation#CIFAR-10#bits/dimension#2.51$Image Generation#CelebA 64x64#bits/dimension#1.86$Image Generation#Binarized MNIST#nats#76.93
2110.02037v2.pdf	Image Generation#CIFAR-10#bits/dimension#2.64
2107.05768v2.pdf	Image Generation#CIFAR-10#bits/dimension#2.77$Image Generation#CIFAR-10#bits/dimension#2.885$Image Generation#ImageNet 64x64#Bits per dim#3.42$Image Generation#ImageNet 64x64#Bits per dim#3.504$Language Modelling#Wiki-40B#Perplexity#16.49$Language Modelling#Wiki-40B#Perplexity#16.60
1904.10509v1.pdf	Image Generation#CIFAR-10#bits/dimension#2.80$Image Generation#ImageNet 64x64#Bits per dim#3.44$Question Answering#Natural Questions (long)#F1#74.5$Question Answering#Quasart-T#EM#52.1$Open-Domain Question Answering#SearchQA#EM#64.7$Language Modelling#enwik8#Bit per Character (BPC)#0.99$Language Modelling#enwik8#Number of params#95M$Audio Generation#Classical music, 5 seconds at 12 kHz#Bits per byte#1.97
1901.03416v1.pdf	Image Generation#CIFAR-10#bits/dimension#2.83$Image Generation#ImageNet 32x32#bpd#3.77
1802.05751v3.pdf	Image Generation#CIFAR-10#bits/dimension#2.89$Image Generation#ImageNet 32x32#bpd#3.77
2006.12486v3.pdf	Image Generation#CIFAR-10#bits/dimension#2.89$Image Generation#CelebA 256x256#bpd#0.74$Image Generation#MNIST#bits/dimension#0.65$Image Generation#Binarized MNIST#bits/dimension#0.143$Image Generation#Binarized MNIST#nats#77.58
1908.09948v1.pdf	Image Generation#CIFAR-10#bits/dimension#2.90
2007.03898v3.pdf	Image Generation#CIFAR-10#bits/dimension#2.91$Image Generation#CelebA 256x256#bpd#0.70$Image Generation#ImageNet 32x32#bpd#3.92$Image Generation#FFHQ 256 x 256#bits/dimension#0.69
2102.09672v1.pdf	Image Generation#CIFAR-10#bits/dimension#2.94$Image Generation#ImageNet 64x64#Bits per dim#3.53$Image Generation#ImageNet 64x64#FID#2.92$Image Generation#ImageNet 256x256#FID#12.3
2003.05997v5.pdf	Image Generation#CIFAR-10#bits/dimension#2.950$Image Generation#ImageNet 64x64#Bits per dim#3.43$Language Modelling#enwik8#Bit per Character (BPC)#0.99$Language Modelling#WikiText-103#Test perplexity#15.8
2002.09741v2.pdf	Image Generation#CIFAR-10#bits/dimension#2.98
1601.06759v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.00$Image Generation#CIFAR-10#bits/dimension#3.14$Image Generation#CIFAR-10#bits/dimension#4.48$Image Generation#ImageNet 32x32#bpd#3.86$Image Generation#Binarized MNIST#nats#79.20$Image Generation#Binarized MNIST#nats#81.30
1606.05328v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.03$Image Generation#ImageNet 64x64#Bits per dim#3.57$Image Generation#ImageNet 32x32#bpd#3.83
2002.07101v1.pdf	Image Generation#CIFAR-10#bits/dimension#3.05$Image Generation#CelebA 256x256#bpd#0.72$Image Generation#ImageNet 32x32#bpd#3.92
1902.00275v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.08$Image Generation#ImageNet 64x64#Bits per dim#3.69$Image Generation#ImageNet 32x32#bpd#3.86
1902.02102v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.08$Image Generation#ImageNet 32x32#bpd#3.96
1902.04208v5.pdf	Image Generation#CIFAR-10#bits/dimension#3.16$Image Generation#ImageNet 64x64#Bits per dim#3.69$Image Generation#ImageNet 64x64#Bits per dim#3.75$Image Generation#CelebA 256x256#bpd#0.67$Image Generation#CelebA 256x256#bpd#0.95
2102.04668v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.27$Image Generation#ImageNet 64x64#Bits per dim#3.71
2110.15828v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.282
2009.14794v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.310$Image Generation#CIFAR-10#bits/dimension#3.335$Image Generation#ImageNet 64x64#Bits per dim#3.636$Image Generation#ImageNet 64x64#Bits per dim#3.719
1907.07945v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.32$Image Generation#ImageNet 32x32#bpd#4.06$Image Generation#MNIST#bits/dimension#0.98
1807.03039v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.35$Image Generation#ImageNet 64x64#Bits per dim#3.81$Image Generation#CelebA 256x256#bpd#1.03$Image Generation#ImageNet 32x32#bpd#4.09$Image Generation#CelebA-HQ 256x256#FID#68.93
1802.04920v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.38
2002.02798v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.38$Image Generation#MNIST#bits/dimension#0.97$Image Generation#ImageNet64x64#bits/dimension#3.83$Image Generation#CelebA-HQ 256x256#bits/dimension#1.04$Density Estimation#MNIST#NLL#0.97$Density Estimation#CelebA-HQ 256x256#Log-likelihood#1.04$Density Estimation#CIFAR-10#Log-likelihood#3.38$Density Estimation#ImageNet64x64#Log-likelihood#3.83
1810.01367v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.4$Density Estimation#MNIST#NLL#0.99$Density Estimation#MNIST#Negative ELBO#82.82$Density Estimation#UCI HEPMASS#Log-likelihood#-14.92$Density Estimation#UCI HEPMASS#NLL#14.92$Density Estimation#Freyfaces#Negative ELBO#4.39$Density Estimation#BSDS300#NLL#-157.4$Density Estimation#CIFAR-10#NLL#3.4$Density Estimation#Caltech-101#Negative ELBO#104.03$Density Estimation#UCI POWER#Log-likelihood#0.46$Density Estimation#UCI POWER#NLL#-0.46$Density Estimation#UCI MINIBOONE#Log-likelihood#-10.43$Density Estimation#UCI MINIBOONE#NLL#10.43$Density Estimation#UCI GAS#Log-likelihood#8.59$Density Estimation#OMNIGLOT#Negative ELBO#98.33
1811.00995v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.45$Image Generation#MNIST#bits/dimension#1.06
1506.03478v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.47
1605.08803v3.pdf	Image Generation#CIFAR-10#bits/dimension#3.49$Image Generation#CIFAR-10#bits/dimension#3.5$Image Generation#ImageNet 32x32#bpd#4.28
2006.05218v2.pdf	Image Generation#CIFAR-10#bits/dimension#3.51$Image Generation#CIFAR-10#bits/dimension#3.65
2106.08462v5.pdf	Image Generation#CIFAR-10#bits/dimension#3.54$Image Generation#ImageNet 64x64#Bits per dim#3.44$Image Generation#ImageNet 32x32#bpd#3.77$Image Generation#ImageNet 128x128#bpd#3.31$Density Estimation#CIFAR-10#Log-likelihood#3.54
1604.08772v1.pdf	Image Generation#CIFAR-10#bits/dimension#3.58
1912.12180v1.pdf	Image Generation#CIFAR-10#bits/dimension#3.666$Image Generation#ImageNet 64x64#Bits per dim#4.032
1502.04623v2.pdf	Image Generation#CIFAR-10#bits/dimension#4.1
1907.00235v3.pdf	Image Generation#CIFAR-10#bits/dimension#4.253$Image Generation#ImageNet 64x64#Bits per dim#4.351
1410.8516v6.pdf	Image Generation#CIFAR-10#bits/dimension#4.5
2101.04775v1.pdf	Image Generation#Pokemon 256x256#FID#81.86$Image Generation#Pokemon 1024x1024#FID#56.46$Image Generation#ADE-Indoor#FID#30.33
2203.03226v2.pdf	Image Generation#NASA Perseverance#RMSE Signature#11601$Image Generation#NASA Perseverance#RMSE log-signature#7397$Image Generation#NASA Perseverance#MAE Signature#9086$Image Generation#NASA Perseverance#MAE log-signature#5717$Image Generation#AFHQ Dog#RMSE Signature#38861$Image Generation#AFHQ Dog#RMSE log-signature#31686$Image Generation#AFHQ Dog#MAE Signature#30441$Image Generation#AFHQ Dog#MAE log-signature#24612$Image Generation#AFHQ Wild#RMSE Signature#33306$Image Generation#AFHQ Wild#RMSE log-signature#26622$Image Generation#AFHQ Wild#MAE Signature#25578$Image Generation#AFHQ Wild#MAE log-signature#20359$Image Generation#MetFaces#RMSE Signature#30894$Image Generation#MetFaces#RMSE log-signature#21560$Image Generation#MetFaces#MAE Signature#19872$Image Generation#MetFaces#MAE log-signature#13761$Image Generation#MetFaces#RMSE Signature#34977$Image Generation#MetFaces#RMSE log-signature#24707$Image Generation#MetFaces#MAE Signature#22799$Image Generation#MetFaces#MAE log-signature#16539$Image Generation#MetFaces#RMSE Signature#33247$Image Generation#MetFaces#RMSE log-signature#25685$Image Generation#MetFaces#MAE Signature#23428$Image Generation#MetFaces#MAE log-signature#18071$Image Generation#AFHQ Cat#RMSE Signature#61450$Image Generation#AFHQ Cat#RMSE log-signature#29201$Image Generation#AFHQ Cat#MAE Signature#45968$Image Generation#AFHQ Cat#MAE log-signature#22297
2106.15282v3.pdf	Image Generation#ImageNet 64x64#FID#1.48$Image Generation#ImageNet 256x256#FID#4.88$Image Generation#ImageNet 128x128#FID#3.52
2210.11522v1.pdf	Image Generation#ImageNet 64x64#Inception Score#34.952$Image Generation#ImageNet 64x64#FID#29.184$Image Generation#ImageNet 64x64#KID#3.766$Image Generation#ImageNet 64x64#Inception Score#25.926$Image Generation#ImageNet 64x64#FID#29.219$Image Generation#ImageNet 64x64#KID#5.325$Image Generation#ImageNet 64x64#Inception Score#25.017$Image Generation#ImageNet 64x64#FID#30.462$Image Generation#ImageNet 64x64#KID#6.174$Image Generation#ImageNet 64x64#Inception Score#22.077$Image Generation#ImageNet 64x64#FID#30.871$Image Generation#ImageNet 64x64#KID#7.952$Question Answering#GSM8K#BS=1#16.831$Question Answering#GSM8K#BS=5#20.773$Video Question Answering#ActivityNet-QA#Accuracy#61.168$Video Question Answering#ActivityNet-QA#Vocabulary Size#304$Video Question Answering#ActivityNet-QA#Accuracy#58.389$Video Question Answering#ActivityNet-QA#Vocabulary Size#267
2110.13711v2.pdf	Image Generation#ImageNet 64x64#Bits per dim#3.44$Image Generation#ImageNet 32x32#bpd#3.74$Language Modelling#enwik8#Bit per Character (BPC)#0.997
1812.01608v1.pdf	Image Generation#ImageNet 64x64#Bits per dim#3.52$Image Generation#CelebA 256x256#bpd#0.61$Image Generation#ImageNet 32x32#bpd#3.85
1612.08185v4.pdf	Image Generation#ImageNet 64x64#Bits per dim#3.57
1703.03664v1.pdf	Image Generation#ImageNet 64x64#Bits per dim#3.7$Image Compression#ImageNet32#bpsp#3.95
2001.04451v2.pdf	Image Generation#ImageNet 64x64#Bits per dim#3.710$Image Generation#ImageNet 64x64#Bits per dim#3.740$Question Answering#Natural Questions (long)#F1#75.5$Question Answering#Quasart-T#EM#53.2$Open-Domain Question Answering#SearchQA#EM#66.0
1711.06491v12.pdf	Image Generation#CelebA 128x128#MS-SSIM#0.1978$Image Generation#CelebA 64x64#FID#8.44
2104.09958v3.pdf	Image Generation#ShapeStacks#FID#112.7$Image Generation#ShapeStacks#FID#186.8$Image Generation#ShapeStacks#FID#197.8$Image Generation#ObjectsRoom#FID#52.6$Image Generation#ObjectsRoom#FID#62.8$Image Generation#ObjectsRoom#FID#205.7$Unsupervised Object Segmentation#ObjectsRoom#ARI-FG#0.84$Unsupervised Object Segmentation#ObjectsRoom#ARI-FG#0.79$Unsupervised Object Segmentation#ObjectsRoom#ARI-FG#0.63$Unsupervised Object Segmentation#ObjectsRoom#ARI-FG#0.54$Unsupervised Object Segmentation#ShapeStacks#ARI-FG#0.81$Unsupervised Object Segmentation#ShapeStacks#ARI-FG#0.76$Unsupervised Object Segmentation#ShapeStacks#ARI-FG#0.70$Unsupervised Object Segmentation#Shelf&Tote Training Dataset#ARI#0.55$Unsupervised Object Segmentation#Shelf&Tote Training Dataset#ARI#0.11$Unsupervised Object Segmentation#Shelf&Tote Training Dataset#ARI#0.04$Unsupervised Object Segmentation#Shelf&Tote Training Dataset#ARI#0.03
1811.11155v2.pdf	Image Generation#Stanford Cars#FID#16.03$Image Generation#Stanford Cars#Inception score#32.62$Image Generation#CUB 128 x 128#FID#11.25$Image Generation#CUB 128 x 128#Inception score#52.53$Image Generation#Stanford Dogs#FID#25.66$Image Generation#Stanford Dogs#Inception score#46.92$Image Clustering#Stanford Cars#Accuracy#0.078$Image Clustering#Stanford Cars#NMI#0.354$Image Clustering#Stanford Dogs#Accuracy#0.079$Image Clustering#Stanford Dogs#NMI#0.233$Image Clustering#CUB Birds#Accuracy#0.126$Image Clustering#CUB Birds#NMI#0.403
1606.03657v1.pdf	Image Generation#Stanford Cars#FID#17.63$Image Generation#Stanford Cars#Inception score#28.62$Image Generation#CUB 128 x 128#FID#13.20$Image Generation#CUB 128 x 128#Inception score#47.32$Image Generation#Stanford Dogs#FID#29.34$Image Generation#Stanford Dogs#Inception score#43.16$Unsupervised Image Classification#MNIST#Accuracy#95
1907.12385v3.pdf	Image Generation#CelebA 256x256#FID#35.0
2112.09130v3.pdf	Image Generation#AFHQ Dog#clean-KID#0.38 ± .01$Image Generation#AFHQ Dog#clean-FID#4.73 ± .02$Image Generation#AFHQ Dog#FID#4.60$Image Generation#AFHQ Wild#clean-KID#0.38 ± .02$Image Generation#AFHQ Wild#clean-FID#2.35 ± .02$Image Generation#AFHQ Wild#FID#2.25$Image Generation#LSUN Horse 256 x 256#FID#2.15$Image Generation#LSUN Horse 256 x 256#Clean-FID (trainfull)#2.11$Image Generation#LSUN Cat 256 x 256#FID#3.87$Image Generation#LSUN Cat 256 x 256#Clean-FID (trainfull)#3.98 ± 0.03$Image Generation#LSUN Churches 256 x 256#FID#1.72$Image Generation#LSUN Churches 256 x 256#Clean-FID (trainfull)#1.72 ± 0.01$Image Generation#AFHQ Cat#clean-KID#0.46 ± .03$Image Generation#AFHQ Cat#clean-FID#2.51 ± .02$Image Generation#AFHQ Cat#FID#2.44
2103.11166v5.pdf	Image Generation#RC-49#Intra-FID#0.334
2011.07466v7.pdf	Image Generation#RC-49#Intra-FID#0.389
2207.13751v1.pdf	Image Generation#VLN-CE#FID#18.52$Image Generation#VLN-CE#FID (SwAV)#3.63$Image Generation#VLN-CE#FID#43.32$Image Generation#VLN-CE#FID (SwAV)#6.19$Image Generation#VLN-CE#FID#90.43$Image Generation#VLN-CE#FID (SwAV)#8.65$Image Generation#VLN-CE#FID#151.26$Image Generation#VLN-CE#FID (SwAV)#14.07$Image Generation#ARKitScenes#FID#37.35$Image Generation#ARKitScenes#FID (SwAV)#4.14$Image Generation#ARKitScenes#FID#79.54$Image Generation#ARKitScenes#FID (SwAV)#10.21$Image Generation#ARKitScenes#FID#87.06$Image Generation#ARKitScenes#FID (SwAV)#13.44$Image Generation#ARKitScenes#FID#134.8$Image Generation#ARKitScenes#FID (SwAV)#15.58$Image Generation#VizDoom#FID#33.7$Image Generation#VizDoom#FID (SwAV)#3.24$Image Generation#VizDoom#FID#37.21$Image Generation#VizDoom#FID (SwAV)#4.56$Image Generation#VizDoom#FID#47.5$Image Generation#VizDoom#FID (SwAV)#5.44$Image Generation#VizDoom#FID#143.55$Image Generation#VizDoom#FID (SwAV)#15.26$Image Generation#Replica#FID#18.75$Image Generation#Replica#FID (SwAV)#1.76$Image Generation#Replica#FID#41.75$Image Generation#Replica#FID (SwAV)#4.14$Image Generation#Replica#FID#65.37$Image Generation#Replica#FID (SwAV)#5.76$Image Generation#Replica#FID#166.55$Image Generation#Replica#FID (SwAV)#13.17
2111.12701v1.pdf	Image Generation#LSUN Bedroom 256 x 256#FID#3.64$Image Generation#FFHQ 256 x 256#FID#6.11$Image Generation#LSUN Churches 256 x 256#FID#4.07
1904.05408v2.pdf	Image Generation#LSUN Bedroom 256 x 256#FID#8.0$Image Generation#CelebA-HQ 1024x1024#FID#5.5$Video Generation#TrailerFaces#FID#404.1
2101.09258v4.pdf	Image Generation#ImageNet 32x32#bpd#3.76
2103.03243v1.pdf	Image Generation#FFHQ 512 x 512#FID#3.08$Image Generation#FFHQ 256 x 256#FID#3.35$Image Generation#FFHQ 128 x 128#FID#3.98
2106.04566v1.pdf	Image Generation#FFHQ 256 x 256#FID#3.31
2011.12026v2.pdf	Image Generation#FFHQ 256 x 256#FID#4.95$Image Generation#LSUN Churches 256 x 256#FID#4.04
2007.00674v3.pdf	Image Generation#MNIST#bits/dimension#1.34$Image Generation#MNIST#FID#4.5$Image Generation#Fashion-MNIST#FID#13.7
2102.05567v1.pdf	Image Generation#MNIST#FID#12.884
2111.01713v2.pdf	Image Generation#SDSS Galaxies#FID#19
2209.05442v2.pdf	Image Generation#CelebA 64x64#FID#1.85
1912.00589v2.pdf	Image Generation#CelebA 64x64#FID#12.21$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.13$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#95.53
1808.07258v1.pdf	Image Generation#CelebA 64x64#FID#34.136
2006.05479v4.pdf	Image Generation#CelebA 64x64#FID#49.2$Image Generation#Fashion-MNIST#FID#28.0$Outlier Detection#Fashion-MNIST#AUROC#0.997$Out-of-Distribution Detection#Fashion-MNIST#AUROC#0.997
2202.00708v2.pdf	Image Generation#1,078 People 3D Faces Collection Data#10%#15
1709.03831v1.pdf	Image Generation#STL-10#Inception score#7.98
1406.1485v3.pdf	Image Generation#Binarized MNIST#nats#84.68
1502.03509v2.pdf	Image Generation#Binarized MNIST#nats#86.64$Density Estimation#UCI GAS#Log-likelihood#8.47
1310.1757v2.pdf	Image Generation#Binarized MNIST#nats#88.33
2203.01941v2.pdf	Image Generation#ImageNet 256x256#FID#3.83$Image Generation#ImageNet 256x256#Inception score#317.1
2112.10752v2.pdf	Image Generation#ImageNet 512x512#FID#3.60$Image Generation#ImageNet 512x512#Inception score#247.67
2203.15270v3.pdf	Image Inpainting#Places2#FID#1.96$Image Inpainting#Places2#P-IDS#23.42$Image Inpainting#Places2#U-IDS#38.34$Image Inpainting#CelebA-HQ#FID#4.86$Image Inpainting#CelebA-HQ#P-IDS#13.83$Image Inpainting#CelebA-HQ#U-IDS#25.33
2103.10428v1.pdf	Image Inpainting#Places2#FID#2.92$Image Inpainting#Places2#P-IDS#19.64$Image Inpainting#Places2#U-IDS#35.78$Image Inpainting#CelebA-HQ#FID#5.65$Image Inpainting#CelebA-HQ#P-IDS#11.23$Image Inpainting#CelebA-HQ#U-IDS#22.54$Image Inpainting#FFHQ 512 x 512#P-IDS#16.6%$Image Inpainting#FFHQ 512 x 512#U-IDS#29.4%$Image Inpainting#FFHQ 512 x 512#FID#3.7
2109.07161v2.pdf	Image Inpainting#Places2#FID#2.97$Image Inpainting#Places2#P-IDS#13.09$Image Inpainting#Places2#U-IDS#32.29$Image Inpainting#CelebA-HQ#FID#8.15$Image Inpainting#CelebA-HQ#P-IDS#2.07$Image Inpainting#CelebA-HQ#U-IDS#7.58
2104.13743v1.pdf	Image Inpainting#Places2#FID#7.53$Image Inpainting#Places2#P-IDS#6.00$Image Inpainting#Places2#U-IDS#23.78$Image Inpainting#CelebA-HQ#FID#6.83$Image Inpainting#CelebA-HQ#P-IDS#3.41$Image Inpainting#CelebA-HQ#U-IDS#11.26
2104.01431v1.pdf	Image Inpainting#Places2#FID#10.64$Image Inpainting#Places2#P-IDS#3.07$Image Inpainting#Places2#U-IDS#19.92
2005.09704v1.pdf	Image Inpainting#Places2#FID#28.92$Image Inpainting#Places2#P-IDS#1.24$Image Inpainting#Places2#U-IDS#11.24$Image Inpainting#Places2 val#FID#15.7$Image Inpainting#Places2 val#PD#92.8$Image Inpainting#Places2 val#FID#16.9$Image Inpainting#Places2 val#PD#115.4
2111.05826v2.pdf	Image Inpainting#Places2 val#FID#11.7$Image Inpainting#Places2 val#PD#35.0$Image Inpainting#Places2 val#FID#11.9$Image Inpainting#Places2 val#PD#57.3$Colorization#ImageNet val#FID-5K#15.78$Colorization#ImageNet ctest10k#FID#3.4$Uncropping#Places2 val#FID#3.53$Uncropping#Places2 val#PD#103.3$Uncropping#Places2 val#Fool rate#39.9$JPEG Decompression#ImageNet#FID-5K#4.3$JPEG Decompression#ImageNet#IS#208.7$JPEG Decompression#ImageNet#CA#73.5$JPEG Decompression#ImageNet#PD#37.1$JPEG Decompression#ImageNet#FID-5K#5.4$JPEG Decompression#ImageNet#IS#180.5$JPEG Decompression#ImageNet#CA#70.7$JPEG Decompression#ImageNet#PD#58.3$JPEG Decompression#ImageNet#FID-5K#8.3$JPEG Decompression#ImageNet#IS#133.6$JPEG Decompression#ImageNet#CA#64.2$JPEG Decompression#ImageNet#PD#95.5$JPEG Decompression#ImageNet#FID-5K#11.5$JPEG Decompression#ImageNet#IS#158.7$JPEG Decompression#ImageNet#CA#69.7$JPEG Decompression#ImageNet#PD#65.4$JPEG Decompression#ImageNet#FID-5K#18.0$JPEG Decompression#ImageNet#IS#117.2$JPEG Decompression#ImageNet#CA#63.5$JPEG Decompression#ImageNet#PD#102.2$JPEG Decompression#ImageNet#FID-5K#29.0$JPEG Decompression#ImageNet#IS#73.9$JPEG Decompression#ImageNet#CA#52.8$JPEG Decompression#ImageNet#PD#155.4
1806.03589v2.pdf	Image Inpainting#Places2 val#FID#13.5$Image Inpainting#Places2 val#PD#63.0$Image Inpainting#Places2 val#FID#15.3$Image Inpainting#Places2 val#PD#96.3
2103.14031v1.pdf	Image Inpainting#CelebA-HQ#FID#12.84$Image Inpainting#CelebA-HQ#P-IDS#0.13$Image Inpainting#CelebA-HQ#U-IDS#0.58
2007.08854v1.pdf	Image Inpainting#Apolloscape Inpainting#RMSE#9.633$Image Inpainting#ApolloScape#MAE#6.135$Image Inpainting#ApolloScape#RMSE#9.633$Image Inpainting#ApolloScape#PSNR#21.631$Image Inpainting#ApolloScape#SSIM#0.895
1905.12384v3.pdf	Image Inpainting#Paris StreetView#40-50% Mask PSNR#23.10$Image Inpainting#Paris StreetView#10-20% Mask PSNR#32.67$Image Inpainting#Paris StreetView#20-30% Mask PSNR#30.32$Image Inpainting#Paris StreetView#30-40% Mask PSNR#24.85
1909.00968v3.pdf	Image Inpainting#Paris StreetView#40-50% Mask PSNR#22.62$Image Inpainting#Paris StreetView#10-20% Mask PSNR#28.73$Image Inpainting#Paris StreetView#20-30% Mask PSNR#26.16$Image Inpainting#Paris StreetView#30-40% Mask PSNR#24.26
2206.02850v3.pdf	Cloud Removal#SEN12MS-CR#MAE#0.0277$Cloud Removal#SEN12MS-CR#PSNR#28.6393$Cloud Removal#SEN12MS-CR#SAM#4.4907$Cloud Removal#SEN12MS-CR#SSIM#0.8845
2009.13015v2.pdf	Cloud Removal#SEN12MS-CR#MAE#0.0448$Cloud Removal#SEN12MS-CR#PSNR#24.7838$Cloud Removal#SEN12MS-CR#SAM#9.0423$Cloud Removal#SEN12MS-CR#SSIM#0.7544
1710.04835v1.pdf	Cloud Removal#SEN12MS-CR#MAE#0.0475$Cloud Removal#SEN12MS-CR#PSNR#25.1439$Cloud Removal#SEN12MS-CR#SAM#7.8380$Cloud Removal#SEN12MS-CR#SSIM#0.7436
2104.07021v3.pdf	Pose Transfer#Deep-Fashion#SSIM#0.806
2007.09278v1.pdf	Pose Transfer#Deep-Fashion#SSIM#0.778$Pose Transfer#Deep-Fashion#IS#3.476$Pose Transfer#Deep-Fashion#PCKh#0.95$Pose Transfer#Market-1501#IS#3.506$Pose Transfer#Market-1501#PCKh#0.93$Pose Transfer#Market-1501#SSIM#0.313$Pose Transfer#Market-1501#mask-IS#3.872$Pose Transfer#Market-1501#mask-SSIM#0.816
2008.04381v2.pdf	Pose Transfer#Deep-Fashion#SSIM#0.778$Pose Transfer#Deep-Fashion#IS#3.430$Pose Transfer#Deep-Fashion#PCKh#0.97$Pose Transfer#Market-1501#IS#3.329$Pose Transfer#Market-1501#PCKh#0.94$Pose Transfer#Market-1501#SSIM#0.325$Pose Transfer#Market-1501#mask-IS#3.695$Pose Transfer#Market-1501#mask-SSIM#0.818
2005.12486v1.pdf	Pose Transfer#Deep-Fashion#SSIM#0.774$Pose Transfer#Deep-Fashion#IS#3.125$Pose Transfer#Deep-Fashion#FID#14.611$Pose Transfer#Deep-Fashion#LPIPS#0.218$Pose Transfer#Deep-Fashion#Retrieval Top10 Recall#30.89
1904.03349v3.pdf	Pose Transfer#Deep-Fashion#SSIM#0.773$Pose Transfer#Deep-Fashion#IS#3.209$Pose Transfer#Deep-Fashion#DS#0.976$Pose Transfer#Deep-Fashion#PCKh#0.96$Pose Transfer#Deep-Fashion#Retrieval Top10 Recall#17.84$Pose Transfer#Market-1501#DS#0.74$Pose Transfer#Market-1501#IS#3.323$Pose Transfer#Market-1501#PCKh#0.94$Pose Transfer#Market-1501#SSIM#0.311$Pose Transfer#Market-1501#mask-IS#3.773$Pose Transfer#Market-1501#mask-SSIM#0.811
2003.12267v4.pdf	Pose Transfer#Deep-Fashion#SSIM#0.772$Pose Transfer#Deep-Fashion#IS#3.364
1910.11328v1.pdf	Pose Transfer#Deep-Fashion#SSIM#0.767$Pose Transfer#Deep-Fashion#IS#3.22$Pose Transfer#Deep-Fashion#FID#12.266$Image Reconstruction#Edge-to-Handbags#FID#74.9$Image Reconstruction#Edge-to-Handbags#LPIPS#0.2$Image Reconstruction#Edge-to-Clothes#FID#58.4$Image Reconstruction#Edge-to-Clothes#LPIPS#0.1$Image Reconstruction#Edge-to-Shoes#FID#121.2$Image Reconstruction#Edge-to-Shoes#LPIPS#0.1
1705.09368v6.pdf	Pose Transfer#Deep-Fashion#SSIM#0.762$Pose Transfer#Deep-Fashion#IS#3.090$Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#28.2403$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.4152$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#3.5$Gesture-to-Gesture Translation#Senz3D#PSNR#26.5138$Gesture-to-Gesture Translation#Senz3D#IS#3.3699$Gesture-to-Gesture Translation#Senz3D#AMT#2.8
1801.00055v2.pdf	Pose Transfer#Deep-Fashion#SSIM#0.756$Pose Transfer#Deep-Fashion#IS#3.439$Pose Transfer#Deep-Fashion#LPIPS#0.233$Pose Transfer#Deep-Fashion#Retrieval Top10 Recall#30.07$Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#29.5471$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.4017$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#9.3$Gesture-to-Gesture Translation#Senz3D#PSNR#27.3014$Gesture-to-Gesture Translation#Senz3D#IS#3.2147$Gesture-to-Gesture Translation#Senz3D#AMT#8.6
1712.02621v4.pdf	Pose Transfer#Deep-Fashion#SSIM#0.614$Pose Transfer#Deep-Fashion#IS#3.228$Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#30.6487$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.4547$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#7.1$Gesture-to-Gesture Translation#Senz3D#PSNR#26.9451$Gesture-to-Gesture Translation#Senz3D#IS#3.3874$Gesture-to-Gesture Translation#Senz3D#AMT#6.9
2110.09788v1.pdf	3D-Aware Image Synthesis#FFHQ 256 x 256#FID#6.97$3D-Aware Image Synthesis#FFHQ 256 x 256#KID#2.87$3D-Aware Image Synthesis#FFHQ 256 x 256#FID#8.00$3D-Aware Image Synthesis#FFHQ 256 x 256#KID#3.70$3D-Aware Image Synthesis#FFHQ 256 x 256#FID#34.56$3D-Aware Image Synthesis#FFHQ 256 x 256#KID#26.58$3D-Aware Image Synthesis#FFHQ 256 x 256#FID#63.33$3D-Aware Image Synthesis#FFHQ 256 x 256#KID#50.94
2203.10821v2.pdf	3D-Aware Image Synthesis#CelebAMask-HQ#FID#41.52$3D-Aware Image Synthesis#CelebAMask-HQ#IS#2.03$3D-Aware Image Synthesis#CelebAMask-HQ#FID#55.56$3D-Aware Image Synthesis#CelebAMask-HQ#IS#1.74$3D-Aware Image Synthesis#CelebAMask-HQ#FID#67.32$3D-Aware Image Synthesis#CelebAMask-HQ#IS#1.72
2205.15517v1.pdf	3D-Aware Image Synthesis#FFHQ 512 x 512#FID#4.6
2103.11897v1.pdf	Layout-to-Image Generation#Visual Genome 128x128#FID#21.78$Layout-to-Image Generation#Visual Genome 128x128#Inception Score#12.65$Layout-to-Image Generation#COCO-Stuff 128x128#FID#22.32$Layout-to-Image Generation#COCO-Stuff 128x128#Inception Score#15.62
2003.07449v2.pdf	Layout-to-Image Generation#Visual Genome 128x128#FID#28.26$Layout-to-Image Generation#Visual Genome 128x128#Inception Score#12.3$Layout-to-Image Generation#Visual Genome 128x128#SceneFID#9.63$Layout-to-Image Generation#Visual Genome 64x64#FID#20.27$Layout-to-Image Generation#Visual Genome 64x64#Inception Score#9.3$Layout-to-Image Generation#COCO-Stuff 64x64#FID#29.57$Layout-to-Image Generation#COCO-Stuff 64x64#Inception Score#10.8$Layout-to-Image Generation#Visual Genome 256x256#Inception Score#14.7$Layout-to-Image Generation#Visual Genome 256x256#FID#40.85$Layout-to-Image Generation#COCO-Stuff 256x256#Inception Score#17.8$Layout-to-Image Generation#COCO-Stuff 256x256#FID#41.65$Layout-to-Image Generation#COCO-Stuff 128x128#FID#36.31$Layout-to-Image Generation#COCO-Stuff 128x128#Inception Score#14.6$Layout-to-Image Generation#COCO-Stuff 128x128#SceneFID#16.76
2003.11571v2.pdf	Layout-to-Image Generation#Visual Genome 128x128#FID#29.00$Layout-to-Image Generation#Visual Genome 128x128#Inception Score#10.71$Layout-to-Image Generation#COCO-Stuff 128x128#FID#24.76$Layout-to-Image Generation#COCO-Stuff 128x128#Inception Score#14.21
1908.07500v1.pdf	Layout-to-Image Generation#Visual Genome 128x128#FID#29.36$Layout-to-Image Generation#Visual Genome 128x128#Inception Score#11.1$Layout-to-Image Generation#Visual Genome 128x128#SceneFID#13.17$Layout-to-Image Generation#Visual Genome 64x64#FID#34.75$Layout-to-Image Generation#Visual Genome 64x64#Inception Score#8.7$Layout-to-Image Generation#COCO-Stuff 64x64#FID#34.31$Layout-to-Image Generation#COCO-Stuff 64x64#Inception Score#9.8$Layout-to-Image Generation#COCO-Stuff 128x128#FID#29.65$Layout-to-Image Generation#COCO-Stuff 128x128#Inception Score#13.8$Layout-to-Image Generation#COCO-Stuff 128x128#SceneFID#20.03
1811.11389v3.pdf	Layout-to-Image Generation#Visual Genome 64x64#FID#31.25$Layout-to-Image Generation#Visual Genome 64x64#Inception Score#8.1$Layout-to-Image Generation#COCO-Stuff 64x64#FID#38.14$Layout-to-Image Generation#COCO-Stuff 64x64#Inception Score#9.1
1804.01622v1.pdf	Layout-to-Image Generation#Visual Genome 64x64#FID#74.61$Layout-to-Image Generation#Visual Genome 64x64#Inception Score#6.3$Layout-to-Image Generation#COCO-Stuff 64x64#FID#67.96$Layout-to-Image Generation#COCO-Stuff 64x64#Inception Score#7.3
1909.05379v2.pdf	Layout-to-Image Generation#COCO-Stuff 64x64#FID#48.7$Layout-to-Image Generation#COCO-Stuff 64x64#Inception Score#10.3$Layout-to-Image Generation#COCO-Stuff 128x128#FID#59.5$Layout-to-Image Generation#COCO-Stuff 128x128#Inception Score#12.5$Layout-to-Image Generation#COCO-Stuff 128x128#SceneFID#33.46
1912.07414v5.pdf	Layout-to-Image Generation#Visual Genome 256x256#Inception Score#11$Layout-to-Image Generation#Visual Genome 256x256#FID#36.4$Layout-to-Image Generation#Visual Genome 256x256#LPIPS#0.51$Layout-to-Image Generation#COCO-Stuff 256x256#Inception Score#15.6$Layout-to-Image Generation#COCO-Stuff 256x256#FID#54.7$Layout-to-Image Generation#COCO-Stuff 256x256#LPIPS#0.44
2110.11918v1.pdf	Image Generation from Scene Graphs#Home Action Genome#FID#98.1$Image Generation from Scene Graphs#Home Action Genome#FID#141.3$Image Generation from Scene Graphs#Visual Genome 64x64#FID#54.24$Image Generation from Scene Graphs#Visual Genome 64x64#FID#55.2$Image Generation from Scene Graphs#BDD100K-Subsets#FID#49.5$Image Generation from Scene Graphs#BDD100K-Subsets#FID#66.1
2104.00670v1.pdf	Scene Generation#Replica#FID#41.75$Scene Generation#Replica#SwAV-FID#4.14$Scene Generation#VizDoom#FID#37.21$Scene Generation#VizDoom#SwAV-FID#4.56$Scene Generation#AVD#FID#51.11$Scene Generation#AVD#SwAV-FID#6.59
2007.02442v4.pdf	Scene Generation#Replica#FID#65.37$Scene Generation#Replica#SwAV-FID#5.76$Scene Generation#VizDoom#FID#47.50$Scene Generation#VizDoom#SwAV-FID#5.44$Scene Generation#AVD#FID#62.59$Scene Generation#AVD#SwAV-FID#6.95
2012.00926v2.pdf	Scene Generation#Replica#FID#166.55$Scene Generation#Replica#SwAV-FID#13.17$Scene Generation#VizDoom#FID#143.55$Scene Generation#VizDoom#SwAV-FID#15.26$Scene Generation#AVD#FID#98.76$Scene Generation#AVD#SwAV-FID#9.54
1910.05672v1.pdf	Retinal OCT Disease Classification#OCT2017#Acc#99.8$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.8$Retinal OCT Disease Classification#OCT2017#Acc#99.7$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.7$Retinal OCT Disease Classification#OCT2017#Acc#99.4$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.4$Retinal OCT Disease Classification#OCT2017#Acc#99.3$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.3$Retinal OCT Disease Classification#OCT2017#Acc#96.6$Retinal OCT Disease Classification#OCT2017#Sensitivity#97.8$Retinal OCT Disease Classification#OCT2017#Acc#93.4$Retinal OCT Disease Classification#OCT2017#Sensitivity#96.6$Retinal OCT Disease Classification#Srinivasan2014#Acc#100$Retinal OCT Disease Classification#Srinivasan2014#Acc#99.36$Retinal OCT Disease Classification#Srinivasan2014#Acc#97.46$Retinal OCT Disease Classification#Srinivasan2014#Acc#96$Retinal OCT Disease Classification#Srinivasan2014#Acc#94.92$Retinal OCT Disease Classification#Srinivasan2014#Acc#93$Retinal OCT Disease Classification#Srinivasan2014#Acc#87.63
2010.12316v1.pdf	Retinal OCT Disease Classification#OCT2017#Acc#99.69
1801.04381v4.pdf	Retinal OCT Disease Classification#OCT2017#Acc#98.5$Retinal OCT Disease Classification#OCT2017#Sensitivity#99.4$Retinal OCT Disease Classification#Srinivasan2014#Acc#97.46$Semantic Segmentation#DADA-seg#mIoU#16.05$Image Classification#ImageNet#Top 1 Accuracy#74.7%$Image Classification#ImageNet#Number of params#6.9M$Image Classification#ImageNet#GFLOPs#1.170$Image Classification#ImageNet#Top 1 Accuracy#72%$Image Classification#ImageNet#Number of params#3.4M$Image Classification#ImageNet#GFLOPs#0.600
1512.00567v3.pdf	Retinal OCT Disease Classification#OCT2017#Acc#96.6$Retinal OCT Disease Classification#OCT2017#Sensitivity#97.8$Retinal OCT Disease Classification#OCT2017#Acc#93.4$Retinal OCT Disease Classification#OCT2017#Sensitivity#96.6$Image Classification#ImageNet#Top 1 Accuracy#78.8%$Image Classification#ImageNet#Top 5 Accuracy#94.4%$Image Classification#ImageNet#GFLOPs#4.8
2005.08094v2.pdf	Retinal OCT Disease Classification#OCT2017#Acc#95.6$Retinal OCT Disease Classification#OCT2017#Acc#92.4$Retinal OCT Disease Classification#OCT2017#Acc#77.4$Retinal OCT Disease Classification#Srinivasan2014#Acc#100$Retinal OCT Disease Classification#Srinivasan2014#Acc#99.68$Retinal OCT Disease Classification#Srinivasan2014#Acc#99.36
1612.04891v1.pdf	Retinal OCT Disease Classification#Srinivasan2014#Acc#87.63
1810.10489v1.pdf	Disease Trajectory Forecasting#UK CF trust#AUC (ABPA)#0.687$Disease Trajectory Forecasting#UK CF trust#AUC (Diabetes)#0.771$Disease Trajectory Forecasting#UK CF trust#I. Obstruction#0.577$Disease Trajectory Forecasting#UK CF trust#AUC (I. Obstruction)#0.577$Disease Trajectory Forecasting#UK CF trust#AUC (K. Pneumonia)#0.718$Disease Trajectory Forecasting#UK CF trust#AUC (E. Coli)#0.701$Disease Trajectory Forecasting#UK CF trust#AUC (Aspergillus)#0.640
1608.05745v4.pdf	Disease Trajectory Forecasting#UK CF trust#AUC (ABPA)#0.685$Disease Trajectory Forecasting#UK CF trust#AUC (Diabetes)#0.764$Disease Trajectory Forecasting#UK CF trust#I. Obstruction#0.578$Disease Trajectory Forecasting#UK CF trust#AUC (I. Obstruction)#0.578$Disease Trajectory Forecasting#UK CF trust#AUC (K. Pneumonia)#0.715$Disease Trajectory Forecasting#UK CF trust#AUC (E. Coli)#0.697$Disease Trajectory Forecasting#UK CF trust#AUC (Aspergillus)#0.641
2207.01909v1.pdf	Style Transfer#WikiArt#SSIM#0.45
2103.17185v1.pdf	Style Transfer#10-Monty-Hall#10 Hops#90
2103.09013v3.pdf	Person Re-Identification#DukeMTMC-reID#mAP#97.1$Person Re-Identification#MARS#mAP#87
2104.13643v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#95.6$Person Re-Identification#DukeMTMC-reID#Rank-5#96.2$Person Re-Identification#DukeMTMC-reID#Rank-10#97.9$Person Re-Identification#DukeMTMC-reID#mAP#96.1$Person Re-Identification#Market-1501#Rank-1#98.0$Person Re-Identification#Market-1501#Rank-5#98.6$Person Re-Identification#Market-1501#Rank-10#99.5$Person Re-Identification#Market-1501#mAP#98.3$Image Retrieval#Exact Street2Shop#mAP#59.8$Image Retrieval#Exact Street2Shop#Rank-1#53.7$Image Retrieval#Exact Street2Shop#Rank-10#70.9$Image Retrieval#Exact Street2Shop#Rank-20#75.0$Image Retrieval#Exact Street2Shop#Rank-50#79.2$Image Retrieval#Exact Street2Shop#mAP#49.8$Image Retrieval#Exact Street2Shop#Rank-1#43.2$Image Retrieval#Exact Street2Shop#Rank-10#61.9$Image Retrieval#Exact Street2Shop#Rank-20#66.0$Image Retrieval#Exact Street2Shop#Rank-50#72.1$Image Retrieval#DeepFashion - Consumer-to-shop#mAP#49.2$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-1#37.3$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-10#71.2$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-20#77.7$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-50#85.0$Image Retrieval#DeepFashion - Consumer-to-shop#mAP#40.4$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-1#29.4$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-10#61.3$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-20#68.9$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-50#77.4
2012.03753v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#93.99$Person Re-Identification#DukeMTMC-reID#mAP#92.77$Person Re-Identification#DukeMTMC-reID#Rank-1#91.9$Person Re-Identification#DukeMTMC-reID#mAP#84.1$Person Re-Identification#CUHK03#MAP#79.6$Person Re-Identification#CUHK03#Rank-1#81.9$Person Re-Identification#MSMT17#Rank-1#86.6$Person Re-Identification#MSMT17#mAP#68.8$Person Re-Identification#Market-1501#mAP#96.21$Person Re-Identification#Market-1501#Rank-1#97$Person Re-Identification#Market-1501#mAP#92$Person Re-Identification#Market-1501-C#Rank-1#32.22$Person Re-Identification#Market-1501-C#mAP#10.37$Person Re-Identification#Market-1501-C#mINP#0.29
1812.03282v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#94.5$Person Re-Identification#DukeMTMC-reID#mAP#92.7$Person Re-Identification#Market-1501#Rank-1#98.0$Person Re-Identification#Market-1501#Rank-5#98.9$Person Re-Identification#Market-1501#Rank-10#99.1$Person Re-Identification#Market-1501#mAP#95.5
2101.08533v5.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#94.3$Person Re-Identification#DukeMTMC-reID#mAP#92.7$Person Re-Identification#MSMT17#Rank-1#86.2$Person Re-Identification#MSMT17#mAP#65.9$Person Re-Identification#Market-1501#Rank-1#96.9$Person Re-Identification#Market-1501#mAP#95.6
1912.01300v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#93.9$Person Re-Identification#DukeMTMC-reID#Rank-5#96.5$Person Re-Identification#DukeMTMC-reID#mAP#91.8$Person Re-Identification#Market-1501#Rank-1#96.79$Person Re-Identification#Market-1501#Rank-5#98.31$Person Re-Identification#Market-1501#mAP#95.43
2111.05476v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#92.91$Person Re-Identification#DukeMTMC-reID#mAP#91.0$Person Re-Identification#MSMT17#Rank-1#88.35$Person Re-Identification#MSMT17#mAP#79.09$Person Re-Identification#P-DukeMTMC-reID#Rank-1#91.96$Person Re-Identification#P-DukeMTMC-reID#Rank-5#95.28$Person Re-Identification#P-DukeMTMC-reID#Rank-10#96.39$Person Re-Identification#P-DukeMTMC-reID#mAP#82.93$Person Re-Identification#Occluded-DukeMTMC#Rank-1#64.39$Person Re-Identification#Occluded-DukeMTMC#Rank-5#77.10$Person Re-Identification#Occluded-DukeMTMC#Rank-10#82.26$Person Re-Identification#Occluded-DukeMTMC#mAP#55.75$Person Re-Identification#Market-1501#Rank-1#96.17$Person Re-Identification#Market-1501#mAP#94.89
2105.05639v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#93.0$Person Re-Identification#DukeMTMC-reID#mAP#90.7$Person Re-Identification#DukeMTMC-reID#Rank-1#90.9$Person Re-Identification#DukeMTMC-reID#mAP#81.5$Person Re-Identification#MSMT17#Rank-1#87.5$Person Re-Identification#MSMT17#mAP#81.3$Person Re-Identification#MSMT17#Rank-1#85.6$Person Re-Identification#MSMT17#mAP#68.0$Person Re-Identification#Market-1501#Rank-1#95.8$Person Re-Identification#Market-1501#mAP#94.7$Person Re-Identification#Market-1501#Rank-1#95.5$Person Re-Identification#Market-1501#mAP#89.6
2007.07875v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#92.2$Person Re-Identification#DukeMTMC-reID#mAP#90.7$Person Re-Identification#DukeMTMC-reID#Rank-1#90.2$Person Re-Identification#DukeMTMC-reID#mAP#81.0$Person Re-Identification#MSMT17#Rank-1#84.9$Person Re-Identification#MSMT17#mAP#76.7$Person Re-Identification#MSMT17#Rank-1#81.7$Person Re-Identification#MSMT17#mAP#62.2$Person Re-Identification#Market-1501#Rank-1#96.0$Person Re-Identification#Market-1501#mAP#94.4$Person Re-Identification#Market-1501#Rank-1#95.6$Person Re-Identification#Market-1501#mAP#88.9
2003.00517v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.7$Person Re-Identification#DukeMTMC-reID#mAP#89.6$Person Re-Identification#DukeMTMC-reID#Rank-1#87.9$Person Re-Identification#DukeMTMC-reID#mAP#77.9$Person Re-Identification#Market-1501#Rank-1#96.4$Person Re-Identification#Market-1501#mAP#95$Person Re-Identification#Market-1501#Rank-1#95.1$Person Re-Identification#Market-1501#mAP#87.9
1903.09776v4.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.4$Person Re-Identification#DukeMTMC-reID#mAP#89.2$Person Re-Identification#CUHK03 labeled#MAP#73.0$Person Re-Identification#CUHK03 labeled#Rank-1#77.9$Person Re-Identification#CUHK03 detected#MAP#69.3$Person Re-Identification#CUHK03 detected#Rank-1#73.3$Person Re-Identification#Market-1501#Rank-1#95.4$Person Re-Identification#Market-1501#mAP#94.2
1903.07071v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.2$Person Re-Identification#DukeMTMC-reID#mAP#89.1$Person Re-Identification#MSMT17-C#Rank-1#20.20$Person Re-Identification#MSMT17-C#mAP#5.28$Person Re-Identification#MSMT17-C#mINP#0.07$Person Re-Identification#Market-1501#Rank-1#95.43$Person Re-Identification#Market-1501#mAP#94.24$Person Re-Identification#UAV-Human#mAP#63.41$Person Re-Identification#UAV-Human#Rank-1#62.48$Person Re-Identification#UAV-Human#Rank-5#84.38$Person Re-Identification#Market-1501-C#Rank-1#27.05$Person Re-Identification#Market-1501-C#mAP#8.42$Person Re-Identification#Market-1501-C#mINP#0.20
2108.00171v1.pdf	Person Re-Identification#DukeMTMC-reID#mAP#89.1$Person Re-Identification#Market-1501#mAP#90.8
2010.05435v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.9$Person Re-Identification#DukeMTMC-reID#mAP#88.6$Person Re-Identification#DukeMTMC-reID#Rank-1#87.5$Person Re-Identification#DukeMTMC-reID#mAP#73.5$Person Re-Identification#CUHK03 labeled#MAP#88.5$Person Re-Identification#CUHK03 labeled#Rank-1#86.7$Person Re-Identification#CUHK03 labeled#MAP#75.4$Person Re-Identification#CUHK03 labeled#Rank-1#79.4$Person Re-Identification#CUHK03 detected#MAP#86.9$Person Re-Identification#CUHK03 detected#Rank-1#85.7$Person Re-Identification#CUHK03 detected#MAP#74.2$Person Re-Identification#CUHK03 detected#Rank-1#77.3$Person Re-Identification#Market-1501#Rank-1#95.5$Person Re-Identification#Market-1501#mAP#94.1$Person Re-Identification#Market-1501#Rank-1#94.9$Person Re-Identification#Market-1501#mAP#85.8$Person Re-Identification#Market-1501-C#Rank-1#28.56$Person Re-Identification#Market-1501-C#mAP#8.90$Person Re-Identification#Market-1501-C#mINP#0.20
1904.11397v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#88.5$Person Re-Identification#DukeMTMC-reID#mAP#86.1$Person Re-Identification#CUHK03#Rank-1#95.8$Person Re-Identification#CUHK03#Rank-5#99.1$Person Re-Identification#Market-1501#Rank-1#95.4$Person Re-Identification#Market-1501#Rank-5#98.3$Person Re-Identification#Market-1501#mAP#93.3
1811.12150v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#89.0$Person Re-Identification#DukeMTMC-reID#mAP#85.9$Person Re-Identification#Market-1501#Rank-1#94.7$Person Re-Identification#Market-1501#mAP#91.7
2203.16533v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#92.0$Person Re-Identification#DukeMTMC-reID#mAP#84.3$Person Re-Identification#CUHK03#MAP#82.3$Person Re-Identification#CUHK03#Rank-1#84.7$Person Re-Identification#MSMT17#Rank-1#86.0$Person Re-Identification#MSMT17#mAP#68.0$Person Re-Identification#Market-1501#Rank-1#96.6$Person Re-Identification#Market-1501#mAP#91.9
1807.05618v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#86.4$Person Re-Identification#DukeMTMC-reID#mAP#83.7$Person Re-Identification#DukeMTMC-reID#Rank-1#81.8$Person Re-Identification#DukeMTMC-reID#mAP#68.6$Person Re-Identification#Market-1501#Rank-1#93.7$Person Re-Identification#Market-1501#mAP#90.8$Person Re-Identification#Market-1501#Rank-1#92.5$Person Re-Identification#Market-1501#mAP#80.1
2108.01901v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.2$Person Re-Identification#DukeMTMC-reID#mAP#82.9$Person Re-Identification#CUHK03 labeled#MAP#83.8$Person Re-Identification#CUHK03 labeled#Rank-1#85.9$Person Re-Identification#Market-1501#Rank-1#96.1$Person Re-Identification#Market-1501#mAP#90.6
2102.04378v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.1$Person Re-Identification#DukeMTMC-reID#mAP#82.1$Person Re-Identification#MSMT17#Rank-1#86.20$Person Re-Identification#MSMT17#mAP#69.40$Person Re-Identification#Market-1501#Rank-1#95.2$Person Re-Identification#Market-1501#mAP#89.5$Person Re-Identification#Market-1501-C#Rank-1#53.19$Person Re-Identification#Market-1501-C#mAP#27.38$Person Re-Identification#Market-1501-C#mINP#1.98$Vehicle Re-Identification#VeRi-776#mAP#82.3$Vehicle Re-Identification#VeRi-776#Rank-1#97.1
2003.08069v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.5$Person Re-Identification#DukeMTMC-reID#mAP#82$Person Re-Identification#CUHK03 labeled#MAP#81.1$Person Re-Identification#CUHK03 labeled#Rank-1#85$Person Re-Identification#CUHK03 detected#MAP#79.1$Person Re-Identification#CUHK03 detected#Rank-1#83.4$Person Re-Identification#MSMT17#Rank-1#83.5$Person Re-Identification#MSMT17#mAP#62.7$Person Re-Identification#Market-1501#Rank-1#96.4$Person Re-Identification#Market-1501#mAP#90.1
2008.06810v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.11$Person Re-Identification#DukeMTMC-reID#mAP#81.84$Person Re-Identification#Market-1501#Rank-1#95.7$Person Re-Identification#Market-1501#mAP#89.5
2102.09321v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.20$Person Re-Identification#DukeMTMC-reID#mAP#81.80$Person Re-Identification#CUHK03 labeled#MAP#84.7$Person Re-Identification#CUHK03 labeled#Rank-1#86.6$Person Re-Identification#CUHK03 detected#MAP#81.4$Person Re-Identification#CUHK03 detected#Rank-1#83.5$Person Re-Identification#MSMT17#Rank-1#85.60$Person Re-Identification#MSMT17#mAP#67.30$Person Re-Identification#Market-1501#Rank-1#95.7$Person Re-Identification#Market-1501#mAP#90.40
2108.05340v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.4$Person Re-Identification#DukeMTMC-reID#mAP#81.5$Person Re-Identification#MSMT17#Rank-1#83.7$Person Re-Identification#MSMT17#mAP#63.5$Person Re-Identification#Market-1501#Rank-1#96.2$Person Re-Identification#Market-1501#mAP#90.5
2009.05250v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.89$Person Re-Identification#DukeMTMC-reID#mAP#81.29$Person Re-Identification#MSMT17#Rank-1#83.54$Person Re-Identification#MSMT17#mAP#62.00$Person Re-Identification#Market-1501#Rank-1#95.96$Person Re-Identification#Market-1501#mAP#90.30$Person Re-Identification#CUHK03-C#Rank-1#17.04$Person Re-Identification#CUHK03-C#mAP#10.62$Person Re-Identification#CUHK03-C#mINP#2.09
2001.07442v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#91.6$Person Re-Identification#DukeMTMC-reID#mAP#81.2$Person Re-Identification#CUHK03 labeled#MAP#80.5$Person Re-Identification#CUHK03 labeled#Rank-1#84.6$Person Re-Identification#CUHK03 detected#MAP#77.2$Person Re-Identification#CUHK03 detected#Rank-1#80.4$Person Re-Identification#Market-1501#Rank-1#95.6$Person Re-Identification#Market-1501#mAP#88.9$Person Re-Identification#CUHK03-C#Rank-1#5.44$Person Re-Identification#CUHK03-C#mAP#4.20$Person Re-Identification#CUHK03-C#mINP#0.46$Person Re-Identification#Market-1501-C#Rank-1#37.56$Person Re-Identification#Market-1501-C#mAP#14.23$Person Re-Identification#Market-1501-C#mINP#0.48
2108.08728v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90$Person Re-Identification#DukeMTMC-reID#mAP#80.5$Person Re-Identification#MSMT17#Rank-1#84.2$Person Re-Identification#MSMT17#mAP#64$Person Re-Identification#Market-1501#Rank-1#95.5$Person Re-Identification#Market-1501#mAP#89.5$Fine-Grained Image Classification#CUB-200-2011#Accuracy#90.6$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.5%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#94.2%$Vehicle Re-Identification#VeRi-776#mAP#74.3$Vehicle Re-Identification#VeRi-776#Rank-1#95.4$Vehicle Re-Identification#VeRi-776#Rank5#97.9$Vehicle Re-Identification#VehicleID Medium#mAP#83.8$Vehicle Re-Identification#VehicleID Medium#Rank-1#78.2$Vehicle Re-Identification#VehicleID Small#mAP#87.8$Vehicle Re-Identification#VehicleID Small#Rank-1#82.5$Vehicle Re-Identification#VehicleID Large#mAP#80.9$Vehicle Re-Identification#VehicleID Large#Rank-1#75.1
1910.07038v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#89.8$Person Re-Identification#DukeMTMC-reID#mAP#80.3$Person Re-Identification#DukeMTMC-reID#Rank-1#88.8$Person Re-Identification#DukeMTMC-reID#mAP#78.9$Person Re-Identification#Market-1501#Rank-1#96.2$Person Re-Identification#Market-1501#mAP#89.7$Person Re-Identification#Market-1501#Rank-1#95.8$Person Re-Identification#Market-1501#mAP#88.7
2007.13467v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#89.6$Person Re-Identification#DukeMTMC-reID#Rank-5#95.5$Person Re-Identification#DukeMTMC-reID#mAP#80$Person Re-Identification#Market-1501#Rank-1#95.3$Person Re-Identification#Market-1501#mAP#88.6
1805.08805v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#84.4$Person Re-Identification#DukeMTMC-reID#mAP#80.0$Person Re-Identification#CUHK03 labeled#MAP#61.6$Person Re-Identification#CUHK03 labeled#Rank-1#66.1$Person Re-Identification#CUHK03 detected#MAP#59.0$Person Re-Identification#CUHK03 detected#Rank-1#63.3$Person Re-Identification#Market-1501#Rank-1#90.9$Person Re-Identification#Market-1501#mAP#86.7
1711.10378v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#85.2$Person Re-Identification#DukeMTMC-reID#mAP#79.8$Person Re-Identification#MARS#mAP#71.8$Person Re-Identification#MARS#Rank-1#76.7$Person Re-Identification#Market-1501#Rank-1#90.3$Person Re-Identification#Market-1501#mAP#84
1910.12003v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.0$Person Re-Identification#DukeMTMC-reID#mAP#79.5$Person Re-Identification#Market-1501#Rank-1#95.2$Person Re-Identification#Market-1501#mAP#87.1
2103.01451v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.2$Person Re-Identification#DukeMTMC-reID#mAP#79.1$Person Re-Identification#Market-1501#Rank-1#96.1$Person Re-Identification#Market-1501#mAP#88.8
1906.08332v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#90.1$Person Re-Identification#DukeMTMC-reID#mAP#79.1$Person Re-Identification#Market-1501#mAP#88.2
1810.12193v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#89.0$Person Re-Identification#DukeMTMC-reID#mAP#79.0$Person Re-Identification#CUHK03 labeled#MAP#76.9$Person Re-Identification#CUHK03 labeled#Rank-1#78.9$Person Re-Identification#CUHK03 detected#MAP#74.8$Person Re-Identification#CUHK03 detected#Rank-1#78.9$Person Re-Identification#Market-1501#Rank-1#95.7$Person Re-Identification#Market-1501#mAP#88.2$Person Re-Identification#CUHK03-C#Rank-1#10.42$Person Re-Identification#CUHK03-C#mAP#8.03$Person Re-Identification#CUHK03-C#mINP#1.10$Person Re-Identification#Market-1501-C#Rank-1#35.72$Person Re-Identification#Market-1501-C#mAP#12.75$Person Re-Identification#Market-1501-C#mINP#0.36
2104.06770v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#88.2$Person Re-Identification#DukeMTMC-reID#Rank-5#95.2$Person Re-Identification#DukeMTMC-reID#Rank-10#96.7$Person Re-Identification#DukeMTMC-reID#mAP#78.7$Person Re-Identification#Market-1501#Rank-1#95.2$Person Re-Identification#Market-1501#Rank-5#98.4$Person Re-Identification#Market-1501#Rank-10#99.1$Person Re-Identification#Market-1501#mAP#87.8
1908.01114v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#89.0$Person Re-Identification#DukeMTMC-reID#mAP#78.59$Person Re-Identification#MSMT17#Rank-1#82.3$Person Re-Identification#MSMT17#mAP#60.8$Person Re-Identification#Market-1501#Rank-1#95.6$Person Re-Identification#Market-1501#mAP#88.28$Person Re-Identification#Market-1501-C#Rank-1#29.65$Person Re-Identification#Market-1501-C#mAP#9.81$Person Re-Identification#Market-1501-C#mINP#0.26
1804.01438v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#88.7$Person Re-Identification#DukeMTMC-reID#mAP#78.4$Person Re-Identification#CUHK03 labeled#MAP#67.4$Person Re-Identification#CUHK03 labeled#Rank-1#68.0$Person Re-Identification#CUHK03 detected#MAP#66.0$Person Re-Identification#CUHK03 detected#Rank-1#68.0$Person Re-Identification#Market-1501#Rank-1#95.7$Person Re-Identification#Market-1501#mAP#86.9$Person Re-Identification#SYSU-30k#Rank-1#23.6$Person Re-Identification#Market-1501-C#Rank-1#29.56$Person Re-Identification#Market-1501-C#mAP#9.72$Person Re-Identification#Market-1501-C#mINP#0.29
2012.10674v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#87.7$Person Re-Identification#DukeMTMC-reID#Rank-5#93.7$Person Re-Identification#DukeMTMC-reID#Rank-10#95.4$Person Re-Identification#DukeMTMC-reID#mAP#76$Person Re-Identification#Market-1501#Rank-1#93.3$Person Re-Identification#Market-1501#Rank-5#97.5$Person Re-Identification#Market-1501#Rank-10#98.4$Person Re-Identification#Market-1501#mAP#85.1$Unsupervised Person Re-Identification#Market-1501#Rank-1#91.4$Unsupervised Person Re-Identification#Market-1501#MAP#79.2$Unsupervised Person Re-Identification#Market-1501#Rank-10#97.7$Unsupervised Person Re-Identification#Market-1501#Rank-5#96.3$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#81.1$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#91.8$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#89.3$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#67.3
1904.00244v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#85.2$Person Re-Identification#DukeMTMC-reID#mAP#74.8$Person Re-Identification#Market-1501#Rank-1#93.1$Person Re-Identification#Market-1501#mAP#89.3
1804.05275v4.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#86.6$Person Re-Identification#DukeMTMC-reID#mAP#74.3$Person Re-Identification#Market-1501#Rank-1#94.2$Person Re-Identification#Market-1501#mAP#82.7
1905.00953v6.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#88.6$Person Re-Identification#DukeMTMC-reID#mAP#73.5$Person Re-Identification#CUHK03 detected#MAP#67.8$Person Re-Identification#CUHK03 detected#Rank-1#72.3$Person Re-Identification#CUHK03#MAP#67.8$Person Re-Identification#MSMT17#Rank-1#78.7$Person Re-Identification#MSMT17#mAP#52.9$Person Re-Identification#MSMT17-C#Rank-1#28.51$Person Re-Identification#MSMT17-C#mAP#7.86$Person Re-Identification#MSMT17-C#mINP#0.08$Person Re-Identification#Market-1501#Rank-1#94.8$Person Re-Identification#Market-1501#mAP#84.9$Person Re-Identification#Market-1501-C#Rank-1#30.94$Person Re-Identification#Market-1501-C#mAP#10.37$Person Re-Identification#Market-1501-C#mINP#0.23
1910.10111v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#86.5$Person Re-Identification#DukeMTMC-reID#Rank-5#93.1$Person Re-Identification#DukeMTMC-reID#Rank-10#95$Person Re-Identification#DukeMTMC-reID#mAP#73.1$Person Re-Identification#Market-1501#Rank-1#95.2$Person Re-Identification#Market-1501#Rank-5#98.2$Person Re-Identification#Market-1501#Rank-10#99.1$Person Re-Identification#Market-1501#mAP#85.6
1711.09349v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#83.3$Person Re-Identification#DukeMTMC-reID#mAP#69.2$Person Re-Identification#DukeMTMC-reID#Rank-1#81.8$Person Re-Identification#DukeMTMC-reID#mAP#66.1$Person Re-Identification#Market-1501#Rank-1#93.8$Person Re-Identification#Market-1501#mAP#81.6$Person Re-Identification#Market-1501#Rank-1#92.3$Person Re-Identification#Market-1501#mAP#77.4$Person Re-Identification#UAV-Human#mAP#61.05$Person Re-Identification#UAV-Human#Rank-1#62.19$Person Re-Identification#UAV-Human#Rank-5#83.90$Person Re-Identification#Market-1501-C#Rank-1#34.93$Person Re-Identification#Market-1501-C#mAP#12.72$Person Re-Identification#Market-1501-C#mINP#0.41
1807.09975v1.pdf	Person Re-Identification#DukeMTMC-reID#mAP#68.2$Person Re-Identification#CUHK03#MAP#94.3$Person Re-Identification#Market-1501#mAP#82.8
1707.00408v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#75.94$Person Re-Identification#DukeMTMC-reID#mAP#66.74$Person Re-Identification#DukeMTMC-reID#Rank-1#71.59$Person Re-Identification#DukeMTMC-reID#mAP#51.51$Person Re-Identification#CUHK03 labeled#MAP#45.8$Person Re-Identification#CUHK03 labeled#Rank-1#43.9$Person Re-Identification#CUHK03 labeled#MAP#35.0$Person Re-Identification#CUHK03 labeled#Rank-1#36.9$Person Re-Identification#CUHK03 (detected)#Rank-1#41.9$Person Re-Identification#CUHK03 (detected)#MAP#43.8$Person Re-Identification#CUHK03 (detected)#Rank-1#36.3$Person Re-Identification#CUHK03 (detected)#MAP#34$Person Re-Identification#Market-1501#Rank-1#88.57$Person Re-Identification#Market-1501#mAP#81.53
1810.02936v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#80.0$Person Re-Identification#DukeMTMC-reID#mAP#64.5$Person Re-Identification#CUHK03#MAP#91.3$Person Re-Identification#CUHK03#Rank-1#92.6$Person Re-Identification#Market-1501#Rank-1#90.5$Person Re-Identification#Market-1501#mAP#77.7
1708.04896v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#79.3$Person Re-Identification#DukeMTMC-reID#mAP#62.4$Person Re-Identification#DukeMTMC-reID#Rank-1#73.0$Person Re-Identification#DukeMTMC-reID#mAP#56.6$Object Detection#PASCAL VOC 2007#MAP#76.2%$Image Classification#Fashion-MNIST#Percentage error#3.65
1808.06281v5.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#80.0$Person Re-Identification#DukeMTMC-reID#mAP#60.2$Person Re-Identification#Market-1501#Rank-1#89.3$Person Re-Identification#Market-1501#mAP#71.8
1711.10295v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#78.32$Person Re-Identification#DukeMTMC-reID#mAP#57.61$Person Re-Identification#DukeMTMC-reID#Rank-1#72.31$Person Re-Identification#DukeMTMC-reID#mAP#51.83$Person Re-Identification#Market-1501#Rank-1#89.49$Person Re-Identification#Market-1501#mAP#71.55$Person Re-Identification#Market-1501#Rank-1#85.66$Person Re-Identification#Market-1501#mAP#65.87
1703.05693v4.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#76.7$Person Re-Identification#DukeMTMC-reID#mAP#56.8$Person Re-Identification#CUHK03 detected#MAP#37.3$Person Re-Identification#CUHK03 detected#Rank-1#41.5$Person Re-Identification#CUHK03 detected#MAP#24.9$Person Re-Identification#CUHK03 detected#Rank-1#27.7$Person Re-Identification#Market-1501#Rank-1#82.3$Person Re-Identification#Market-1501#mAP#62.1
1703.07737v4.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#72.44$Person Re-Identification#DukeMTMC-reID#mAP#53.50$Person Re-Identification#CUHK03#Rank-1#89.63$Person Re-Identification#CUHK03#Rank-5#99.01$Person Re-Identification#MARS#mAP#77.43$Person Re-Identification#MARS#Rank-1#81.21$Person Re-Identification#MARS#Rank-5#90.76$Person Re-Identification#MARS#mAP#73.68$Person Re-Identification#MARS#Rank-1#78.48$Person Re-Identification#MARS#Rank-5#88.74$Person Re-Identification#MARS#mAP#67.70$Person Re-Identification#MARS#Rank-1#79.80$Person Re-Identification#MARS#Rank-5#91.36$Person Re-Identification#MARS#mAP#60.48$Person Re-Identification#MARS#Rank-1#75.56$Person Re-Identification#MARS#Rank-5#89.70$Person Re-Identification#Market-1501#Rank-1#86.67$Person Re-Identification#Market-1501#Rank-5#93.38$Person Re-Identification#Market-1501#mAP#81.07$Person Re-Identification#Market-1501#Rank-1#84.59$Person Re-Identification#Market-1501#Rank-5#91.89$Person Re-Identification#Market-1501#mAP#75.62$Person Re-Identification#Market-1501#Rank-1#84.92$Person Re-Identification#Market-1501#Rank-5#94.21$Person Re-Identification#Market-1501#mAP#69.14$Person Re-Identification#Market-1501#Rank-1#81.38$Person Re-Identification#Market-1501#Rank-5#92.34$Person Re-Identification#Market-1501#mAP#60.71
1703.07220v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#70.69$Person Re-Identification#DukeMTMC-reID#mAP#51.88
1611.05666v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#68.9$Person Re-Identification#DukeMTMC-reID#mAP#49.3$Person Re-Identification#MSMT17#Rank-1#60.48$Person Re-Identification#MSMT17#mAP#31.58$Person Re-Identification#Market-1501#Rank-1#79.5$Person Re-Identification#Market-1501#mAP#59.9$Image Retrieval#Oxford5k#mAP#76.4
1707.01083v2.pdf	Person Re-Identification#DukeMTMC-reID#mAP#48.09$Image Classification#ImageNet#Top 1 Accuracy#70.9%$Image Classification#ImageNet#Top 5 Accuracy#89.8%
1903.06325v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#79.8$Person Re-Identification#DukeMTMC-reID#mAP#48$Person Re-Identification#Market-1501#Rank-1#67.7$Person Re-Identification#Market-1501#Rank-5#81.9$Person Re-Identification#Market-1501#mAP#40
1604.01850v3.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#68.1$Person Re-Identification#DukeMTMC-reID#mAP#47.4$Person Re-Identification#CUHK03#MAP#72.5$Person Re-Identification#CUHK03#Rank-1#77.5
1701.07717v5.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#67.68$Person Re-Identification#DukeMTMC-reID#mAP#47.13$Person Re-Identification#CUHK03#MAP#87.4$Person Re-Identification#CUHK03#Rank-1#84.6$Person Re-Identification#Market-1501#Rank-1#83.97$Person Re-Identification#Market-1501#mAP#66.07
1610.02984v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#65.22$Person Re-Identification#DukeMTMC-reID#mAP#44.99$Person Re-Identification#Market-1501#Rank-1#72.54$Person Re-Identification#Market-1501#mAP#46.00
1903.00535v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#62.3$Person Re-Identification#DukeMTMC-reID#mAP#44.6$Person Re-Identification#DukeTracklet#Rank-1#43.8$Person Re-Identification#DukeTracklet#Rank-20#76.5$Person Re-Identification#DukeTracklet#Rank-5#62.8$Person Re-Identification#DukeTracklet#mAP#36.6$Person Re-Identification#CUHK03#MAP#42.3$Person Re-Identification#CUHK03#Rank-1#56.3$Person Re-Identification#MSMT17#Rank-1#31.4$Person Re-Identification#MSMT17#mAP#13.1$Person Re-Identification#MARS#mAP#35.2$Person Re-Identification#MARS#Rank-1#49.9$Person Re-Identification#MARS#Rank-10#66.4$Person Re-Identification#MARS#Rank-20#77.8$Person Re-Identification#PRID2011#Rank-1#54.7$Person Re-Identification#PRID2011#Rank-20#96.2$Person Re-Identification#PRID2011#Rank-5#83.1$Person Re-Identification#Market-1501#Rank-1#69.2$Person Re-Identification#Market-1501#mAP#46.2$Person Re-Identification#iLIDS-VID#Rank-1#35.1$Person Re-Identification#iLIDS-VID#Rank-20#83.8$Person Re-Identification#iLIDS-VID#Rank-5#59
1706.02413v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#60.23$Person Re-Identification#DukeMTMC-reID#mAP#39.36$3D Semantic Segmentation#KITTI-360#miou Class#35.66$3D Semantic Segmentation#KITTI-360#mIoU Category#58.28$3D Semantic Segmentation#SemanticKITTI#mIoU#20.1%$3D Semantic Segmentation#STPLS3D#mIOU#15.92$Semantic Segmentation#ShapeNet#Mean IoU#84.6%$Semantic Segmentation#ScanNet#3DIoU#0.339$3D Part Segmentation#IntrA#IoU (V)#93.42$3D Part Segmentation#IntrA#DSC (V)#96.48$3D Part Segmentation#IntrA#IoU (A)#76.38$3D Part Segmentation#IntrA#DSC (A)#84.64$3D Part Segmentation#ShapeNet-Part#Class Average IoU#81.9$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.1$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.903$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.236$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#77.9$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#75.4$3D Point Cloud Classification#ModelNet40#Overall Accuracy#90.7$3D Point Cloud Classification#ModelNet40#Number of params#1.74M$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.112
1906.01308v1.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#51.5$Person Re-Identification#DukeMTMC-reID#Rank-5#64.6$Person Re-Identification#DukeMTMC-reID#Rank-10#70.1$Person Re-Identification#DukeMTMC-reID#mAP#30$Person Re-Identification#Market-1501#Rank-5#83$Person Re-Identification#Market-1501#Rank-10#87.8$Person Re-Identification#Market-1501#mAP#41.3$Unsupervised Person Re-Identification#Market-1501#Rank-1#69.2$Unsupervised Person Re-Identification#Market-1501#MAP#41.3$Unsupervised Person Re-Identification#Market-1501#Rank-10#87.8$Unsupervised Person Re-Identification#Market-1501#Rank-5#83
1406.4216v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#30.75$Person Re-Identification#DukeMTMC-reID#mAP#17.04$Person Re-Identification#Market-1501#Rank-1#43.79$Person Re-Identification#Market-1501#mAP#22.22
1705.10444v2.pdf	Person Re-Identification#DukeMTMC-reID#Rank-1#30.4$Person Re-Identification#DukeMTMC-reID#mAP#16.4$Person Re-Identification#Market-1501#Rank-1#44.7$Person Re-Identification#Market-1501#mAP#20.1$Unsupervised Person Re-Identification#Market-1501#Rank-1#45.5$Unsupervised Person Re-Identification#Market-1501#MAP#20.5$Unsupervised Person Re-Identification#Market-1501#Rank-10#66.7$Unsupervised Person Re-Identification#Market-1501#Rank-5#60.7$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#30.0$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#48.5$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#43.4$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#16.4
2101.10774v1.pdf	Person Re-Identification#CUHK03 labeled#MAP#85.1$Person Re-Identification#CUHK03 labeled#Rank-1#87.2$Person Re-Identification#CUHK03 detected#MAP#82.4$Person Re-Identification#CUHK03 detected#Rank-1#84.9$Person Re-Identification#Market-1501#Rank-1#96.3$Person Re-Identification#Market-1501#mAP#91.5$Person Re-Identification#Market-1501-C#Rank-1#38.68$Person Re-Identification#Market-1501-C#mAP#14.84$Person Re-Identification#Market-1501-C#mINP#0.50
1811.07130v2.pdf	Person Re-Identification#CUHK03 labeled#MAP#76.7$Person Re-Identification#CUHK03 labeled#Rank-1#79.4$Person Re-Identification#Market-1501-C#Rank-1#33.79$Person Re-Identification#Market-1501-C#mAP#10.95$Person Re-Identification#Market-1501-C#mINP#0.32
1802.08122v1.pdf	Person Re-Identification#CUHK03 labeled#MAP#41.0$Person Re-Identification#CUHK03 labeled#Rank-1#44.4$Person Re-Identification#CUHK03 detected#MAP#38.6$Person Re-Identification#CUHK03 detected#Rank-1#41.7$Person Re-Identification#CUHK03#MAP#38.6$Person Re-Identification#CUHK03#Rank-1#41.7
1701.08398v4.pdf	Person Re-Identification#CUHK03 labeled#MAP#29.6$Person Re-Identification#CUHK03 labeled#Rank-1#32.0$Person Re-Identification#CUHK03 labeled#MAP#21.0$Person Re-Identification#CUHK03 labeled#Rank-1#22.2$Person Re-Identification#CUHK03 labeled#MAP#20.0$Person Re-Identification#CUHK03 labeled#Rank-1#21.9$Person Re-Identification#CUHK03 labeled#MAP#14.9$Person Re-Identification#CUHK03 labeled#Rank-1#15.6$Person Re-Identification#CUHK03 detected#MAP#28.2$Person Re-Identification#CUHK03 detected#Rank-1#31.1$Person Re-Identification#CUHK03 detected#MAP#19.7$Person Re-Identification#CUHK03 detected#Rank-1#21.3$Person Re-Identification#CUHK03 detected#MAP#19.0$Person Re-Identification#CUHK03 detected#Rank-1#21.1$Person Re-Identification#CUHK03 detected#MAP#14.2$Person Re-Identification#CUHK03 detected#Rank-1#15.1$Person Re-Identification#CUHK03#MAP#67.6$Person Re-Identification#CUHK03#Rank-1#61.6$Person Re-Identification#Market-1501#Rank-1#77.11$Person Re-Identification#Market-1501#mAP#63.63
1809.02874v1.pdf	Person Re-Identification#DukeTracklet#Rank-1#26.1$Person Re-Identification#DukeTracklet#Rank-20#57.2$Person Re-Identification#DukeTracklet#Rank-5#42.0$Person Re-Identification#DukeTracklet#mAP#20.8$Person Re-Identification#MSMT17#Rank-1#28.4$Person Re-Identification#MSMT17#mAP#12.5$Person Re-Identification#PRID2011#Rank-1#49.4$Person Re-Identification#PRID2011#Rank-20#98.9$Person Re-Identification#PRID2011#Rank-5#78.7
2106.03720v2.pdf	Person Re-Identification#CUHK03#MAP#96.4$Person Re-Identification#CUHK03#Rank-1#98.7$Person Re-Identification#Market-1501#Rank-1#98.27$Person Re-Identification#Market-1501#mAP#94.46
1711.08184v2.pdf	Person Re-Identification#CUHK03#Rank-1#97.8$Person Re-Identification#CUHK03#Rank-5#99.6$Person Re-Identification#CUHK03#Rank-10#99.8$Person Re-Identification#CUHK-SYSU#MAP#94.4$Person Re-Identification#CUHK-SYSU#Rank-1#95.7$Person Re-Identification#Market-1501#Rank-1#94.4$Person Re-Identification#Market-1501#mAP#90.7$Person Re-Identification#CUHK03-C#Rank-1#7.99$Person Re-Identification#CUHK03-C#mAP#4.87$Person Re-Identification#CUHK03-C#mINP#0.56$Person Re-Identification#Market-1501-C#Rank-1#31.00$Person Re-Identification#Market-1501-C#mAP#10.95$Person Re-Identification#Market-1501-C#mINP#0.32
1904.03579v1.pdf	Person Re-Identification#CUHK03#Rank-1#64.8$Object Detection#COCO minival#box AP#39.5$Document Classification#Cora#Accuracy#83.5%$Image Classification#ImageNet#Top 1 Accuracy#77.5%$Image Classification#ImageNet#Number of params#29.38M$Image Classification#CIFAR-10#Percentage correct#94$Instance Segmentation#COCO minival#mask AP#35.2
2112.04761v1.pdf	Person Re-Identification#MSMT17#Rank-1#89.9$Person Re-Identification#MSMT17#mAP#84.4
2111.12084v1.pdf	Person Re-Identification#MSMT17#Rank-1#89.6$Person Re-Identification#MSMT17#mAP#75.0$Person Re-Identification#Market-1501#Rank-1#96.7$Person Re-Identification#Market-1501#mAP#93.2$Unsupervised Person Re-Identification#Market-1501#Rank-1#95.3$Unsupervised Person Re-Identification#Market-1501#MAP#89.6
2003.07618v2.pdf	Person Re-Identification#MSMT17#Rank-1#77.97$Person Re-Identification#MSMT17#mAP#48.66
1712.02225v6.pdf	Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#15.8$Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#29.9
1707.06777v1.pdf	Person Re-Identification#CUHK-SYSU#MAP#77.9$Person Re-Identification#CUHK-SYSU#Rank-1#81.2
1610.05047v2.pdf	Person Re-Identification#CUHK-SYSU#MAP#74.0$Person Re-Identification#CUHK-SYSU#Rank-1#76.7
1912.05295v1.pdf	Person Re-Identification#MARS#mAP#88.5$Person Re-Identification#MARS#mAP#82.9$Person Re-Identification#MARS#Rank-1#88.6$Person Re-Identification#PRID2011#Rank-1#96.6
2202.06014.pdf	Person Re-Identification#MARS#mAP#86.8$Person Re-Identification#MARS#Rank-1#90.22$Person Re-Identification#MARS#Rank-10#98.04$Person Re-Identification#MARS#Rank-5#97.23$Person Re-Identification#iLIDS-VID#Rank-1#92.07$Person Re-Identification#iLIDS-VID#Rank-20#100$Person Re-Identification#iLIDS-VID#Rank-5#98.93$Person Re-Identification#iLIDS-VID#Rank-10#99.80
2107.11878v2.pdf	Person Re-Identification#MARS#mAP#86.10$Person Re-Identification#DukeMTMC-VideoReID#mAP#96.40$Person Re-Identification#iLIDS-VID#Rank-1#89.3
2104.14913v1.pdf	Person Re-Identification#MARS#mAP#85.8$Person Re-Identification#MARS#Rank-1#90.0$Person Re-Identification#MARS#Rank-20#98.5$Person Re-Identification#MARS#Rank-5#96.7
2108.09039v1.pdf	Person Re-Identification#MARS#mAP#84.5$Person Re-Identification#MARS#Rank-1#90.5
2007.04174v1.pdf	Person Re-Identification#MARS#mAP#83.1$Person Re-Identification#MARS#Rank-1#89.4$Person Re-Identification#MARS#Rank-5#96.8$Vehicle Re-Identification#VeRi#mAP#82.2
1908.01683v1.pdf	Person Re-Identification#MARS#mAP#82.8$Person Re-Identification#MARS#Rank-1#90
1909.02240v2.pdf	Person Re-Identification#MARS#mAP#81.1$Person Re-Identification#MARS#Rank-1#89.8$Person Re-Identification#MARS#Rank-10#96.1$Person Re-Identification#MARS#Rank-20#97.6$Person Re-Identification#PRID2011#Rank-1#93.1$Person Re-Identification#PRID2011#Rank-20#99.8$Person Re-Identification#PRID2011#Rank-10#98.7$Person Re-Identification#iLIDS-VID#Rank-1#83.7$Person Re-Identification#iLIDS-VID#Rank-20#99.5$Person Re-Identification#iLIDS-VID#Rank-10#95.4
2103.15537v4.pdf	Person Re-Identification#MARS#mAP#80.41$Person Re-Identification#MARS#Rank-1#88.32
1908.03885v3.pdf	Person Re-Identification#MARS#mAP#73.3$Person Re-Identification#MARS#Rank-1#84$Person Re-Identification#MARS#Rank-10#95.7$Person Re-Identification#MARS#Rank-5#93.7$Person Re-Identification#iLIDS-VID#Rank-1#54.6$Person Re-Identification#iLIDS-VID#Rank-20#93.5$Person Re-Identification#iLIDS-VID#Rank-5#79.4$Person Re-Identification#iLIDS-VID#Rank-10#86.9
2112.08740v2.pdf	Person Re-Identification#Occluded REID#rank1#87.0$Person Re-Identification#Occluded-DukeMTMC#rank1#68.1
2206.04401v1.pdf	Person Re-Identification#RegDB#Rank-1#94.13$Person Re-Identification#SYSU-MM01#rank1#82.31
2006.02631v4.pdf	Person Re-Identification#MSMT17-C#Rank-1#28.77$Person Re-Identification#MSMT17-C#mAP#7.89$Person Re-Identification#MSMT17-C#mINP#0.05$Person Re-Identification#Market-1501-C#Rank-1#34.13$Person Re-Identification#Market-1501-C#mAP#11.54$Person Re-Identification#Market-1501-C#mINP#0.29
2001.04193v2.pdf	Person Re-Identification#MSMT17-C#Rank-1#22.77$Person Re-Identification#MSMT17-C#mAP#6.53$Person Re-Identification#MSMT17-C#mINP#0.08$Person Re-Identification#SYSU-MM01-C#Rank-1 (All Search)#34.42$Person Re-Identification#SYSU-MM01-C#mAP (All Search)#29.99$Person Re-Identification#SYSU-MM01-C#mINP (All Search)#14.73$Person Re-Identification#SYSU-MM01-C#Rank-1 (Indoor Search)#33.80$Person Re-Identification#SYSU-MM01-C#mAP (Indoor Search)#40.98$Person Re-Identification#SYSU-MM01-C#mINP (Indoor Search)#35.39$Person Re-Identification#CUHK03-C#Rank-1#5.90$Person Re-Identification#CUHK03-C#mAP#3.45$Person Re-Identification#CUHK03-C#mINP#0.46$Person Re-Identification#Market-1501-C#Rank-1#31.90$Person Re-Identification#Market-1501-C#mAP#12.13$Person Re-Identification#Market-1501-C#mINP#0.35
2111.00880v2.pdf	Person Re-Identification#MSMT17-C#mINP#0.32$Person Re-Identification#MSMT17-C#mAP#15.33$Person Re-Identification#MSMT17-C#Rank-1#39.79$Person Re-Identification#SYSU-MM01-C#mINP (All Search)#22.48$Person Re-Identification#SYSU-MM01-C#mAP (All Search)#35.92$Person Re-Identification#SYSU-MM01-C#Rank-1 (All Search)#36.95$Person Re-Identification#SYSU-MM01-C#mINP (Indoor Search)#43.11$Person Re-Identification#SYSU-MM01-C#mAP (Indoor Search)#48.65$Person Re-Identification#SYSU-MM01-C#Rank-1 (Indoor Search)#40.73$Person Re-Identification#CUHK03-C#mAP#16.33$Person Re-Identification#CUHK03-C#mINP#22.96$Person Re-Identification#CUHK03-C#Rank-1#22.96$Person Re-Identification#Market-1501-C#mINP#1.76$Person Re-Identification#Market-1501-C#mAP#28.03$Person Re-Identification#Market-1501-C#Rank-1#55.57
2111.05170v3.pdf	Person Re-Identification#PRID2011#Rank-1#92.0$Person Re-Identification#PRID2011#Rank-20#100.0$Person Re-Identification#PRID2011#Rank-5#97.7$Person Re-Identification#iLIDS-VID#Rank-1#63.1$Person Re-Identification#iLIDS-VID#Rank-20#92.5$Person Re-Identification#iLIDS-VID#Rank-5#81.9$Unsupervised Person Re-Identification#DukeMTMC-VideoReID#mAP#76.9$Unsupervised Person Re-Identification#DukeMTMC-VideoReID#Rank-1#83.6$Unsupervised Person Re-Identification#DukeMTMC-VideoReID#Rank-5#93.1$Unsupervised Person Re-Identification#DukeMTMC-VideoReID#Rank-20#97.2$Unsupervised Person Re-Identification#PRID2011#Rank-1#92.00$Unsupervised Person Re-Identification#PRID2011#Rank-5#97.7$Unsupervised Person Re-Identification#PRID2011#Rank-20#100.0$Unsupervised Person Re-Identification#iLIDS-VID#Rank-1#63.1$Unsupervised Person Re-Identification#iLIDS-VID#Rank-5#81.9$Unsupervised Person Re-Identification#iLIDS-VID#Rank-20#92.5
1808.07301v1.pdf	Person Re-Identification#PRID2011#Rank-1#85.3$Person Re-Identification#PRID2011#Rank-20#99.6$Person Re-Identification#PRID2011#Rank-5#97.0
1709.09297v1.pdf	Person Re-Identification#PRID2011#Rank-1#73.1$Person Re-Identification#PRID2011#Rank-20#99.0$Person Re-Identification#PRID2011#Rank-5#92.5$Person Re-Identification#PRID2011#Rank-1#56.4$Person Re-Identification#PRID2011#Rank-20#96.4$Person Re-Identification#PRID2011#Rank-5#81.3
1804.10094v1.pdf	Person Re-Identification#PRID2011#Rank-1#43.0
2012.07620v2.pdf	Person Re-Identification#Market-1501#Rank-1#96.11$Person Re-Identification#Market-1501#mAP#94.65$Image Retrieval#Paris6k#mAP#96.21$Image Retrieval#Oxford5k#mAP#92.95$Drone-view target localization#University-1652#AP#74.11$Drone-view target localization#University-1652#Recall@1#70.3$Vehicle Re-Identification#VeRi-776#mAP#96.42
2112.04662v3.pdf	Person Re-Identification#Market-1501#Rank-1#95.4$Person Re-Identification#Market-1501#Rank-5#98.5$Person Re-Identification#Market-1501#Rank-10#99.2$Person Re-Identification#Market-1501#mAP#89.2
1804.00216v1.pdf	Person Re-Identification#Market-1501#Rank-1#93.6$Person Re-Identification#Market-1501#mAP#83.3
1803.10859v1.pdf	Person Re-Identification#Market-1501#Rank-1#89.4$Person Re-Identification#Market-1501#mAP#75.6
1709.04329v1.pdf	Person Re-Identification#Market-1501#Rank-1#89.9$Person Re-Identification#Market-1501#mAP#73.9
1707.00798v2.pdf	Person Re-Identification#Market-1501#Rank-1#88.2$Person Re-Identification#Market-1501#mAP#69.3
1901.00392v2.pdf	Person Re-Identification#Market-1501#Rank-1#86.54$Person Re-Identification#Market-1501#mAP#68.97$Fine-Grained Image Classification#CompCars#Accuracy#95.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#86.2%
1703.08359v1.pdf	Person Re-Identification#Market-1501#Rank-1#82.21$Person Re-Identification#Market-1501#mAP#68.80
1705.04724v2.pdf	Person Re-Identification#Market-1501#Rank-1#85.1$Person Re-Identification#Market-1501#mAP#65.5
1709.08325v1.pdf	Person Re-Identification#Market-1501#Rank-1#84.14$Person Re-Identification#Market-1501#mAP#63.41
1707.07256v1.pdf	Person Re-Identification#Market-1501#Rank-1#81.0$Person Re-Identification#Market-1501#mAP#63.4
1710.06555v1.pdf	Person Re-Identification#Market-1501#Rank-1#80.31$Person Re-Identification#Market-1501#mAP#57.53
1607.08378v2.pdf	Person Re-Identification#Market-1501#Rank-1#65.88$Person Re-Identification#Market-1501#mAP#39.55
1603.02139v1.pdf	Person Re-Identification#Market-1501#Rank-1#61.02$Person Re-Identification#Market-1501#mAP#35.68
1708.08062v2.pdf	Person Re-Identification#Market-1501#Rank-1#54.5$Person Re-Identification#Market-1501#mAP#26.3
1603.00370v2.pdf	Person Re-Identification#Market-1501#Rank-1#45.16
1911.05030v1.pdf	Person Re-Identification#Market-1501#Average-mAP#92.7
1804.07094v1.pdf	Person Re-Identification#UAV-Human#mAP#60.86$Person Re-Identification#UAV-Human#Rank-1#60.86$Person Re-Identification#UAV-Human#Rank-5#81.71
2103.11658v1.pdf	Person Re-Identification#SYSU-30k#Rank-1#36.0$Unsupervised Person Re-Identification#Market-1501#Rank-1#89.5$Unsupervised Person Re-Identification#Market-1501#MAP#72.9$Unsupervised Person Re-Identification#Market-1501#Rank-10#97.0$Unsupervised Person Re-Identification#Market-1501#Rank-5#95.2$Unsupervised Person Re-Identification#DukeMTMCreID#Rank-1#80.0
1904.03845v3.pdf	Person Re-Identification#SYSU-30k#Rank-1#26.9
2104.08760v3.pdf	Person Re-Identification#SYSU-30k#Rank-1#14.8$Self-Supervised Person Re-Identification#SYSU-30k#Rank-1#14.8$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.9%$Self-Supervised Image Classification#ImageNet#Number of Params#23.56M
2006.07733v3.pdf	Person Re-Identification#SYSU-30k#Rank-1#12.7$Self-Supervised Person Re-Identification#SYSU-30k#Rank-1#12.7$Image Classification#Places205#Top 1 Accuracy#54.0$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#89.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#71.2%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#87.9%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#69.1%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#84.1%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#62.2%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#78.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#53.2%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#94.8%$Self-Supervised Image Classification#ImageNet#Number of Params#250M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#94.2%$Self-Supervised Image Classification#ImageNet#Number of Params#375M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#77.4%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#93.6%$Self-Supervised Image Classification#ImageNet#Number of Params#94M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.3%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#91.6%
2003.04297v1.pdf	Person Re-Identification#SYSU-30k#Rank-1#11.6$Self-Supervised Person Re-Identification#SYSU-30k#Rank-1#11.6$Image Classification#Places205#Top 1 Accuracy#52.9$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#71.1%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#90.1%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#71.1
1604.04377v1.pdf	Person Re-Identification#SYSU-30k#Rank-1#11.2
2002.05709v3.pdf	Person Re-Identification#SYSU-30k#Rank-1#10.9$Self-Supervised Person Re-Identification#SYSU-30k#Rank-1#10.9$Image Classification#Places205#Top 1 Accuracy#53.3$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#92.6%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.2%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#87.8%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#85.8%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#63.0%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#83.0%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#58.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#75.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#48.3%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.5%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#93.2%$Self-Supervised Image Classification#ImageNet#Number of Params#375M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.2%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.0%$Self-Supervised Image Classification#ImageNet#Number of Params#94M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#69.3%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#89.0%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#77.2%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#69.3
1512.03622v1.pdf	Person Re-Identification#SYSU-30k#Rank-1#10.3
2011.00958v2.pdf	Person Re-Identification#eSports Sensors Dataset#LogLoss#0.01617$Person Re-Identification#eSports Sensors Dataset#Accuracy#52.1$Person Re-Identification#eSports Sensors Dataset#ROC AUC#0.919$Person Re-Identification#eSports Sensors Dataset#LogLoss#0.01615$Person Re-Identification#eSports Sensors Dataset#Accuracy#48.8$Person Re-Identification#eSports Sensors Dataset#ROC AUC#0.884$Person Re-Identification#eSports Sensors Dataset#LogLoss#0.01588$Person Re-Identification#eSports Sensors Dataset#Accuracy#45$Person Re-Identification#eSports Sensors Dataset#ROC AUC#0.89$Person Re-Identification#eSports Sensors Dataset#LogLoss#0.05735$Person Re-Identification#eSports Sensors Dataset#Accuracy#41.5$Person Re-Identification#eSports Sensors Dataset#ROC AUC#0.84$Person Re-Identification#eSports Sensors Dataset#LogLoss#0.02303$Person Re-Identification#eSports Sensors Dataset#Accuracy#10$Person Re-Identification#eSports Sensors Dataset#ROC AUC#0.5$Skills Evaluation#eSports Sensors Dataset#Accuracy#85.6$Skills Evaluation#eSports Sensors Dataset#ROC AUC#0.945$Skills Evaluation#eSports Sensors Dataset#LogLoss#0.311$Skills Evaluation#eSports Sensors Dataset#Accuracy#83.8$Skills Evaluation#eSports Sensors Dataset#ROC AUC#0.886$Skills Evaluation#eSports Sensors Dataset#LogLoss#0.596$Skills Evaluation#eSports Sensors Dataset#Accuracy#80$Skills Evaluation#eSports Sensors Dataset#ROC AUC#0.885$Skills Evaluation#eSports Sensors Dataset#LogLoss#0.456$Skills Evaluation#eSports Sensors Dataset#Accuracy#74.1$Skills Evaluation#eSports Sensors Dataset#ROC AUC#0.899$Skills Evaluation#eSports Sensors Dataset#LogLoss#0.442$Skills Evaluation#eSports Sensors Dataset#Accuracy#50$Skills Evaluation#eSports Sensors Dataset#ROC AUC#0.5$Skills Evaluation#eSports Sensors Dataset#LogLoss#0.693
1911.09318v2.pdf	Person Re-Identification#CUHK03-C#Rank-1#9.66$Person Re-Identification#CUHK03-C#mAP#7.30$Person Re-Identification#CUHK03-C#mINP#1.00$Person Re-Identification#Market-1501-C#Rank-1#36.57$Person Re-Identification#Market-1501-C#mAP#14.23$Person Re-Identification#Market-1501-C#mINP#0.48
1908.05819v1.pdf	Person Re-Identification#CUHK03-C#Rank-1#8.27$Person Re-Identification#CUHK03-C#mAP#3.97$Person Re-Identification#CUHK03-C#mINP#0.46$Person Re-Identification#Market-1501-C#Rank-1#33.29$Person Re-Identification#Market-1501-C#mAP#10.69$Person Re-Identification#Market-1501-C#mINP#0.38
1809.05996v3.pdf	Person Re-Identification#Market-1501-C#Rank-1#42.92$Person Re-Identification#Market-1501-C#mAP#18.24$Person Re-Identification#Market-1501-C#mINP#0.67$Semantic Segmentation#LIP val#mIoU#53.10%
1904.00537v1.pdf	Person Re-Identification#Market-1501-C#Rank-1#31.17$Person Re-Identification#Market-1501-C#mAP#10.15$Person Re-Identification#Market-1501-C#mINP#0.31
2101.08783v3.pdf	Person Re-Identification#Market-1501-C#Rank-1#29.35$Person Re-Identification#Market-1501-C#mAP#9.08$Person Re-Identification#Market-1501-C#mINP#0.23$Person Re-Identification#Market-1501-C#Rank-1#27.72$Person Re-Identification#Market-1501-C#mAP#8.26$Person Re-Identification#Market-1501-C#mINP#0.24
2109.12333v2.pdf	Unsupervised Person Re-Identification#Market-1501#Rank-1#93.4$Unsupervised Person Re-Identification#Market-1501#MAP#84.2$Unsupervised Person Re-Identification#Market-1501#Rank-10#98.5$Unsupervised Person Re-Identification#Market-1501#Rank-5#97.7$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#85.1$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#94.6$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#92.4$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#73.3
2103.16364v2.pdf	Unsupervised Person Re-Identification#Market-1501#Rank-1#93.8$Unsupervised Person Re-Identification#Market-1501#MAP#82.3$Unsupervised Person Re-Identification#Market-1501#Rank-10#98.4$Unsupervised Person Re-Identification#Market-1501#Rank-5#97.6$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#83.3$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#94.1$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#91.5$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#69.9
2107.03024v2.pdf	Unsupervised Person Re-Identification#Market-1501#Rank-1#92.3$Unsupervised Person Re-Identification#Market-1501#MAP#79.2$Unsupervised Person Re-Identification#Market-1501#Rank-10#97.8$Unsupervised Person Re-Identification#Market-1501#Rank-5#96.6$Unsupervised Person Re-Identification#MSMT17#mAP#24.6$Unsupervised Person Re-Identification#MSMT17#Rank-1#56.2$Unsupervised Person Re-Identification#MSMT17#Rank-5#67.3$Unsupervised Person Re-Identification#MSMT17#Rank-10#71.5$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-1#82.7$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-10#93.5$Unsupervised Person Re-Identification#DukeMTMC-reID#Rank-5#91.1$Unsupervised Person Re-Identification#DukeMTMC-reID#MAP#69.1
2011.03363v1.pdf	Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#58.3$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#76.2$Unsupervised Person Re-Identification#Market-1501->MSMT17#mAP#20.7$Unsupervised Person Re-Identification#Market-1501->MSMT17#Rank-1#49.7$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#65.1$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-1#88.3$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#mAP#24.4$Unsupervised Person Re-Identification#DukeMTMC-reID->MSMT17#Rank-1#56.5
2106.07204v1.pdf	Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#mAP#58.1$Unsupervised Person Re-Identification#Market-1501->DukeMTMC-reID#Rank-1#76.1$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#65.2$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-1#85.3
1910.06827v5.pdf	Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-1#71.1$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-10#86.4$Unsupervised Person Re-Identification#MSMT17->Market-1501#Rank-5#83.3$Unsupervised Person Re-Identification#MSMT17->Market-1501#mAP#52.7$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#mAP#30.6$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-1#61$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-10#82.5$Unsupervised Person Re-Identification#DukeMTMC-reID->Market-1501#Rank-5#77$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-1#70.1$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-10#88.6$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#Rank-5#84.1$Unsupervised Person Re-Identification#MSMT17->DukeMTMC-reID#mAP#43.3
2205.03124v1.pdf	Unsupervised Person Re-Identification#DukeMTMC-VideoReID#mAP#89.9$Unsupervised Person Re-Identification#DukeMTMC-VideoReID#Rank-1#91.9$Unsupervised Person Re-Identification#MARS#mAP#72.4$Unsupervised Person Re-Identification#MARS#rank-1#80.9
2105.14432v2.pdf	Generalizable Person Re-identification#MSMT->Market-1501#Rank-1#80.1$Generalizable Person Re-identification#MSMT->Market-1501#mAP#52.0$Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#Rank-1#31.9$Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#mAP#30.7$Generalizable Person Re-identification#Market-1501->MSMT17#Rank-1#47.3$Generalizable Person Re-identification#Market-1501->MSMT17#mAP#18.4$Generalizable Person Re-identification#RandPerson->Market-1501#Rank-1#77.3$Generalizable Person Re-identification#RandPerson->Market-1501#mAP#49.1$Generalizable Person Re-identification#MSMT17(all)->Market-1501#Rank-1#82.6$Generalizable Person Re-identification#MSMT17(all)->Market-1501#mAP#58.4$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#Rank-1#22.2$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#mAP#21.4$Generalizable Person Re-identification#RandPerson->CUHK03-NP (detected)#Rank-1#17.1$Generalizable Person Re-identification#RandPerson->CUHK03-NP (detected)#mAP#16.0$Generalizable Person Re-identification#RandPerson->MSMT17#Rank-1#48.3$Generalizable Person Re-identification#RandPerson->MSMT17#mAP#17.7$Generalizable Person Re-identification#MSMT->CUHK03-NP (detected)#Rank-1#23.7$Generalizable Person Re-identification#MSMT->CUHK03-NP (detected)#mAP#22.5
2104.01546v4.pdf	Generalizable Person Re-identification#MSMT->Market-1501#Rank-1#79.1$Generalizable Person Re-identification#MSMT->Market-1501#mAP#49.5$Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#Rank-1#27.6$Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#mAP#28.0$Generalizable Person Re-identification#Market-1501->MSMT17#Rank-1#45.9$Generalizable Person Re-identification#Market-1501->MSMT17#mAP#17.2$Generalizable Person Re-identification#RandPerson->Market-1501#Rank-1#76.7$Generalizable Person Re-identification#RandPerson->Market-1501#mAP#46.7$Generalizable Person Re-identification#MSMT17(all)->Market-1501#Rank-1#82.4$Generalizable Person Re-identification#MSMT17(all)->Market-1501#mAP#56.9$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#Rank-1#19.1$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#mAP#18.1$Generalizable Person Re-identification#RandPerson->CUHK03-NP (detected)#Rank-1#18.4$Generalizable Person Re-identification#RandPerson->CUHK03-NP (detected)#mAP#16.1$Generalizable Person Re-identification#RandPerson->MSMT17#Rank-1#45.1$Generalizable Person Re-identification#RandPerson->MSMT17#mAP#15.5$Generalizable Person Re-identification#MSMT->CUHK03-NP (detected)#Rank-1#20.9$Generalizable Person Re-identification#MSMT->CUHK03-NP (detected)#mAP#20.6
2204.02611v2.pdf	Generalizable Person Re-identification#ClonedPerson->Market-1501#Rank-1#84.8$Generalizable Person Re-identification#ClonedPerson->Market-1501#mAP#62.3$Generalizable Person Re-identification#ClonedPerson->Market-1501#Rank-1#84.5$Generalizable Person Re-identification#ClonedPerson->Market-1501#mAP#59.9$Generalizable Person Re-identification#ClonedPerson->MSMT17#Rank-1#51.6$Generalizable Person Re-identification#ClonedPerson->MSMT17#mAP#20.8$Generalizable Person Re-identification#ClonedPerson->MSMT17#Rank-1#49.1$Generalizable Person Re-identification#ClonedPerson->MSMT17#mAP#18.5$Generalizable Person Re-identification#ClonedPerson->CUHK03-NP (detected)#Rank-1#25.4$Generalizable Person Re-identification#ClonedPerson->CUHK03-NP (detected)#mAP#24.4$Generalizable Person Re-identification#ClonedPerson->CUHK03-NP (detected)#Rank-1#22.6$Generalizable Person Re-identification#ClonedPerson->CUHK03-NP (detected)#mAP#21.8
1904.10424v4.pdf	Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#Rank-1#25.3$Generalizable Person Re-identification#MSMT17(all)->CUHK03-NP (detected)#mAP#22.6$Generalizable Person Re-identification#Market-1501->MSMT17#Rank-1#22.6$Generalizable Person Re-identification#Market-1501->MSMT17#mAP#7.0$Generalizable Person Re-identification#MSMT17(all)->Market-1501#Rank-1#72.6$Generalizable Person Re-identification#MSMT17(all)->Market-1501#mAP#43.1$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#Rank-1#9.9$Generalizable Person Re-identification#Market-1501->CUHK03-NP (detected)#mAP#8.6
2008.06223v2.pdf	Cross-Modal  Person Re-Identification#SYSU-MM01#mAP (All-search & Single-shot)#57.51$Cross-Modal  Person Re-Identification#SYSU-MM01#rank1#61.68$Cross-Modal  Person Re-Identification#RegDB#rank1(V2T)#91.05$Cross-Modal  Person Re-Identification#RegDB#mAP(V2T)#83.28
2012.05010v2.pdf	Cross-Modal  Person Re-Identification#SYSU-MM01#mAP (All-search & Single-shot)#55.13$Cross-Modal  Person Re-Identification#SYSU-MM01#rank1#57.34$Cross-Modal  Person Re-Identification#RegDB#rank1(V2T)#83.92$Cross-Modal  Person Re-Identification#RegDB#mAP(V2T)#73.78
1601.03333v1.pdf	Person Identification#BioEye#R1#98.69
2111.14600v1.pdf	3D Reconstruction#DTU#Acc#0.321$3D Reconstruction#DTU#Overall#0.305$3D Reconstruction#DTU#Comp#0.289
2112.05999v3.pdf	3D Reconstruction#DTU#Acc#0.351$3D Reconstruction#DTU#Overall#0.315$3D Reconstruction#DTU#Comp#0.278
2201.01501v3.pdf	3D Reconstruction#DTU#Acc#0.352$3D Reconstruction#DTU#Overall#0.315$3D Reconstruction#DTU#Comp#0.278
2111.14420v1.pdf	3D Reconstruction#DTU#Acc#0.334$3D Reconstruction#DTU#Overall#0.321$3D Reconstruction#DTU#Comp#0.309
2207.12032v1.pdf	3D Reconstruction#DTU#Acc#0.379$3D Reconstruction#DTU#Overall#0.328$3D Reconstruction#DTU#Comp#0.278
1911.12012v2.pdf	3D Reconstruction#DTU#Acc#0.338$3D Reconstruction#DTU#Overall#0.344$3D Reconstruction#DTU#Comp#0.349
1912.08329v3.pdf	3D Reconstruction#DTU#Acc#0.296$3D Reconstruction#DTU#Overall#0.351$3D Reconstruction#DTU#Comp#0.406
2012.01411v1.pdf	3D Reconstruction#DTU#Acc#0.427$3D Reconstruction#DTU#Overall#0.352$3D Reconstruction#DTU#Comp#0.277
1912.06378v3.pdf	3D Reconstruction#DTU#Acc#0.325$3D Reconstruction#DTU#Overall#0.355$3D Reconstruction#DTU#Comp#0.385
2108.03824v1.pdf	3D Reconstruction#DTU#Acc#0.376$3D Reconstruction#DTU#Overall#0.357$3D Reconstruction#DTU#Comp#0.339
2008.07928v2.pdf	3D Reconstruction#DTU#Acc#0.369$3D Reconstruction#DTU#Overall#0.365$3D Reconstruction#DTU#Comp#0.361
1804.02505v2.pdf	3D Reconstruction#DTU#Acc#0.396$3D Reconstruction#DTU#Overall#0.462$3D Reconstruction#DTU#Comp#0.527
2205.04087v1.pdf	3D Reconstruction#3DPeople#IoU#61$3D Reconstruction#3DPeople#Chamfer#10$3D Reconstruction#3DPeople#Normal Consistency#82.1$3D Reconstruction#3DPeople#P2S#16.2
2201.01831v2.pdf	3D Reconstruction#ShapeNet#IoU#92.6$3D Reconstruction#ShapeNet#Chamfer Distance#0.3
2011.05813v1.pdf	3D Reconstruction#ShapeNet#IoU#89.5$3D Reconstruction#ShapeNet#Chamfer Distance#0.42$3D Reconstruction#ShapeNet#IoU#88.4$3D Reconstruction#ShapeNet#Chamfer Distance#0.45$3D Reconstruction#ShapeNet#IoU#76.1$3D Reconstruction#ShapeNet#Chamfer Distance#0.87
2103.12957v1.pdf	3D Reconstruction#ShapeNet#IoU#73.8$3D Reconstruction#ShapeNet#F-Score@1%#0.497
1905.03678v1.pdf	3D Reconstruction#300W#1-of-100 Accuracy#cosine loss
1811.11187v1.pdf	3D Reconstruction#Scan2CAD#Average Accuracy#31.68%
1603.08182v3.pdf	3D Reconstruction#Scan2CAD#Average Accuracy#10.29%$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#66.8$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.169
1808.00758v2.pdf	3D Reconstruction#Data3D−R2N2#3DIoU#0.642
1612.00603v2.pdf	3D Reconstruction#Data3D−R2N2#3DIoU#0.640$3D Object Reconstruction#Data3D−R2N2#3DIoU#0.64$3D Object Reconstruction#Data3D−R2N2#Avg F1#48.58
1703.09438v3.pdf	3D Reconstruction#Data3D−R2N2#3DIoU#0.596
1604.00449v1.pdf	3D Reconstruction#Data3D−R2N2#3DIoU#0.560$3D Object Reconstruction#Data3D−R2N2#3DIoU#0.56$3D Object Reconstruction#Data3D−R2N2#Avg F1#39.01
2104.03640v2.pdf	3D Semantic Scene Completion#NYUv2#mIoU#52.4
2111.13309v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#49.9$3D Semantic Scene Completion#NYUv2#mIoU#48
2112.12925v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#46
1908.00382v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#41.3
1909.01106v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#37.1
2103.07466v3.pdf	3D Semantic Scene Completion#NYUv2#mIoU#34.4$3D Semantic Scene Completion#NYUv2#mIoU#33.7$3D Semantic Scene Completion#NYUv2#mIoU#31.8$3D Semantic Scene Completion#NYUv2#mIoU#31.7$3D Semantic Scene Completion#NYUv2#mIoU#22.7
1804.03550v4.pdf	3D Semantic Scene Completion#NYUv2#mIoU#34.1$3D Semantic Scene Completion#SemanticKITTI#mIoU#17.7$3D Semantic Scene Completion#SemanticKITTI#mIoU#10.2$3D Semantic Scene Completion#SemanticKITTI#mIoU#9.5
2003.13910v2.pdf	3D Semantic Scene Completion#NYUv2#mIoU#33
2002.07269v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#32.9
1611.08974v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#30.5$3D Semantic Scene Completion#NYUv2#mIoU#24.7$3D Semantic Scene Completion#SemanticKITTI#mIoU#16.1
1903.00620v2.pdf	3D Semantic Scene Completion#NYUv2#mIoU#30.4
1806.05361v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#29.3
1908.02893v2.pdf	3D Semantic Scene Completion#NYUv2#mIoU#27.8
1802.04735v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#27.5
1907.05091v1.pdf	3D Semantic Scene Completion#NYUv2#mIoU#26.7$3D Semantic Scene Completion#SemanticKITTI#mIoU#17.5
2012.09242v1.pdf	3D Semantic Scene Completion#SemanticKITTI#mIoU#29.5
2109.11453v1.pdf	3D Semantic Scene Completion#SemanticKITTI#mIoU#23.5
2011.09141v3.pdf	3D Semantic Scene Completion#SemanticKITTI#mIoU#22.7
1901.03861v2.pdf	3D Room Layouts From A Single RGB Panorama#Stanford 2D-3D#3DIoU#79.79%$3D Room Layouts From A Single RGB Panorama#PanoContext#3DIoU#82.17%
1811.11977v2.pdf	3D Room Layouts From A Single RGB Panorama#Stanford 2D-3D#3DIoU#79.36%$3D Room Layouts From A Single RGB Panorama#Realtor360#3DIoU#77.20%$3D Room Layouts From A Single RGB Panorama#PanoContext#3DIoU#77.42%
1803.08999v1.pdf	3D Room Layouts From A Single RGB Panorama#Stanford 2D-3D#3DIoU#76.33%$3D Room Layouts From A Single RGB Panorama#Realtor360#3DIoU#62.77%$3D Room Layouts From A Single RGB Panorama#PanoContext#3DIoU#74.48%
1903.08094v2.pdf	3D Room Layouts From A Single RGB Panorama#PanoContext#3DIoU#78.79%
2006.14107v1.pdf	Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#79.2$Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#AUC#43.4$Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#MPJPE#99.2$Unsupervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#89.4
2012.09398v1.pdf	Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#68.2$Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#AUC#35.2$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#85.3$Unsupervised 3D Human Pose Estimation#Human3.6M#P-MPJPE#59.8
2106.05616v4.pdf	Unsupervised 3D Human Pose Estimation#MPI-INF-3DHP#PCK#66.5$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#98.3
2112.07088v1.pdf	Unsupervised 3D Human Pose Estimation#Human3.6M#PA-MPJPE#36.7$Unsupervised 3D Human Pose Estimation#Human3.6M#MPJPE#64.0
2110.05313v4.pdf	Music Source Separation#Slakh2100#SDR (drums)#5.83$Music Source Separation#Slakh2100#SDR (bass)#7.42
2111.03600v3.pdf	Music Source Separation#MUSDB18#SDR (vocals)#8.13$Music Source Separation#MUSDB18#SDR (drums)#8.24$Music Source Separation#MUSDB18#SDR (other)#5.59$Music Source Separation#MUSDB18#SDR (bass)#8.76$Music Source Separation#MUSDB18#SDR (avg)#7.68
2111.12203v1.pdf	Music Source Separation#MUSDB18#SDR (vocals)#9.00$Music Source Separation#MUSDB18#SDR (drums)#7.33$Music Source Separation#MUSDB18#SDR (other)#5.95$Music Source Separation#MUSDB18#SDR (bass)#7.86$Music Source Separation#MUSDB18#SDR (avg)#7.54
1911.13254v2.pdf	Music Source Separation#MUSDB18#SDR (vocals)#7.29$Music Source Separation#MUSDB18#SDR (drums)#7.58$Music Source Separation#MUSDB18#SDR (other)#4.69$Music Source Separation#MUSDB18#SDR (bass)#7.60$Music Source Separation#MUSDB18#SDR (avg)#6.79$Music Source Separation#MUSDB18#SDR (vocals)#6.84$Music Source Separation#MUSDB18#SDR (drums)#6.86$Music Source Separation#MUSDB18#SDR (other)#4.42$Music Source Separation#MUSDB18#SDR (bass)#7.01$Music Source Separation#MUSDB18#SDR (avg)#6.28
2112.04685v1.pdf	Music Source Separation#MUSDB18#SDR (vocals)#8.92$Music Source Separation#MUSDB18#SDR (drums)#6.38$Music Source Separation#MUSDB18#SDR (other)#5.84$Music Source Separation#MUSDB18#SDR (bass)#5.93$Music Source Separation#MUSDB18#SDR (avg)#6.77
2010.01733v4.pdf	Music Source Separation#MUSDB18#SDR (vocals)#7.80$Music Source Separation#MUSDB18#SDR (drums)#7.36$Music Source Separation#MUSDB18#SDR (other)#5.37$Music Source Separation#MUSDB18#SDR (bass)#6.20$Music Source Separation#MUSDB18#SDR (avg)#6.68$Music Source Separation#MUSDB18#SDR (vocals)#7.24$Music Source Separation#MUSDB18#SDR (drums)#7.01$Music Source Separation#MUSDB18#SDR (other)#4.53$Music Source Separation#MUSDB18#SDR (bass)#5.25$Music Source Separation#MUSDB18#SDR (avg)#6.01
1809.07454v3.pdf	Music Source Separation#MUSDB18#SDR (vocals)#6.74$Music Source Separation#MUSDB18#SDR (drums)#7.11$Music Source Separation#MUSDB18#SDR (other)#4.44$Music Source Separation#MUSDB18#SDR (bass)#7.00$Music Source Separation#MUSDB18#SDR (avg)#6.32$Music Source Separation#MUSDB18#SDR (vocals)#6.81$Music Source Separation#MUSDB18#SDR (drums)#6.08$Music Source Separation#MUSDB18#SDR (other)#4.37$Music Source Separation#MUSDB18#SDR (bass)#5.66$Music Source Separation#MUSDB18#SDR (avg)#5.73$Speech Separation#WSJ0-2mix#SI-SDRi#15.3
1805.02410v2.pdf	Music Source Separation#MUSDB18#SDR (vocals)#7.16$Music Source Separation#MUSDB18#SDR (drums)#6.81$Music Source Separation#MUSDB18#SDR (other)#4.80$Music Source Separation#MUSDB18#SDR (bass)#5.40$Music Source Separation#MUSDB18#SDR (avg)#6.04
2010.11631v2.pdf	Music Source Separation#MUSDB18#SDR (vocals)#7.33$Music Source Separation#MUSDB18#SDR (drums)#5.68$Music Source Separation#MUSDB18#SDR (other)#4.87$Music Source Separation#MUSDB18#SDR (bass)#5.63$Music Source Separation#MUSDB18#SDR (avg)#5.88
2010.04228v4.pdf	Music Source Separation#MUSDB18#SDR (vocals)#6.61$Music Source Separation#MUSDB18#SDR (drums)#6.47$Music Source Separation#MUSDB18#SDR (other)#4.64$Music Source Separation#MUSDB18#SDR (bass)#5.43$Music Source Separation#MUSDB18#SDR (avg)#5.79
1909.05746v4.pdf	Music Source Separation#MUSDB18#SDR (vocals)#6.61$Music Source Separation#MUSDB18#SDR (drums)#6.63$Music Source Separation#MUSDB18#SDR (other)#4.09$Music Source Separation#MUSDB18#SDR (bass)#5.25$Music Source Separation#MUSDB18#SDR (avg)#5.65
2002.07016v1.pdf	Music Source Separation#MUSDB18#SDR (vocals)#6.40$Music Source Separation#MUSDB18#SDR (drums)#5.91$Music Source Separation#MUSDB18#SDR (other)#4.19$Music Source Separation#MUSDB18#SDR (bass)#5.58$Music Source Separation#MUSDB18#SDR (avg)#5.52
1810.12187v2.pdf	Music Source Separation#MUSDB18#SDR (vocals)#3.46$Music Source Separation#MUSDB18#SDR (drums)#4.60$Music Source Separation#MUSDB18#SDR (other)#0.54$Music Source Separation#MUSDB18#SDR (bass)#2.49$Music Source Separation#MUSDB18#SDR (avg)#3.5
1806.03185v1.pdf	Music Source Separation#MUSDB18#SDR (vocals)#3.25$Music Source Separation#MUSDB18#SDR (drums)#4.22$Music Source Separation#MUSDB18#SDR (other)#2.25$Music Source Separation#MUSDB18#SDR (bass)#3.21$Music Source Separation#MUSDB18#SDR (avg)#3.23
2111.14200v3.pdf	Music Source Separation#MUSDB18-HQ#SDR (drums)#4.925$Music Source Separation#MUSDB18-HQ#SDR (bass)#4.073$Music Source Separation#MUSDB18-HQ#SDR (others)#2.695$Music Source Separation#MUSDB18-HQ#SDR (vocals)#5.06$Music Source Separation#MUSDB18-HQ#SDR (avg)#4.188
2109.09052v1.pdf	Object Tracking#FE108#Success Rate#92.4
2105.01922v2.pdf	Object Tracking#SeaDronesSee#Success Rate#67.33400$Object Tracking#SeaDronesSee#Precision Score#86.84020$Object Tracking#SeaDronesSee#Success Rate#67.00010$Object Tracking#SeaDronesSee#Precision Score#84.93010$Object Tracking#SeaDronesSee#Success Rate#65.90210$Object Tracking#SeaDronesSee#Precision Score#83.51010$Object Tracking#SeaDronesSee#Success Rate#64.60100$Object Tracking#SeaDronesSee#Precision Score#82.70010$Object Tracking#SeaDronesSee#Success Rate#63.80000$Object Tracking#SeaDronesSee#Precision Score#82.32100$Multi-Object Tracking#SeaDronesSee#MOTA#0.7190$Multi-Object Tracking#SeaDronesSee#MOTA#0.3650$Multi-Object Tracking#SeaDronesSee#MOTA#0.3050$Object Detection#SeaDronesSee#mAP@0.5#54.66$Object Detection#SeaDronesSee#mAP@0.5#50.32$Object Detection#SeaDronesSee#mAP@0.5#37.11$Object Detection#SeaDronesSee#mAP@0.5#36.42$Object Detection#SeaDronesSee#mAP@0.5#30.09$Object Detection#SeaDronesSee#mAP@0.5#21.84
2203.01730v1.pdf	Object Tracking#KITTI#mean success#62.9$Object Tracking#KITTI#mean precision#83.4
2108.04728v2.pdf	Object Tracking#KITTI#mean success#55.0$Object Tracking#KITTI#mean precision#75.2
2108.05015v3.pdf	Object Tracking#VisEvent#Precision Plot#0.627
2206.14651v2.pdf	Multi-Object Tracking#MOT20#MOTA#77.8$Multi-Object Tracking#MOT20#IDF1#77.5$Multi-Object Tracking#MOT20#HOTA#63.3$Multi-Object Tracking#MOT17#MOTA#80.5$Multi-Object Tracking#MOT17#IDF1#80.2$Multi-Object Tracking#MOT17#HOTA#65.0
2110.06864v3.pdf	Multi-Object Tracking#MOT20#MOTA#77.8$Multi-Object Tracking#MOT20#IDF1#75.2$Multi-Object Tracking#MOT20#HOTA#61.3$Multi-Object Tracking#DanceTrack#HOTA#47.1$Multi-Object Tracking#DanceTrack#DetA#70.5$Multi-Object Tracking#DanceTrack#AssA#31.5$Multi-Object Tracking#DanceTrack#MOTA#88.2$Multi-Object Tracking#DanceTrack#IDF1#51.9$Multi-Object Tracking#MOT17#MOTA#80.3$Multi-Object Tracking#MOT17#IDF1#77.3
2104.00194v2.pdf	Multi-Object Tracking#MOT20#MOTA#77.5$Multi-Object Tracking#MOT20#IDF1#75.2$Multi-Object Tracking#2DMOT15#MOTA#57$Multi-Object Tracking#2DMOT15#IDF1#66$Multi-Object Tracking#MOT17#MOTA#76.7$Multi-Object Tracking#MOT17#IDF1#75.1$Multi-Object Tracking#MOT16#MOTA#76.7$Multi-Object Tracking#MOT16#IDF1#76.8
2203.14360v1.pdf	Multi-Object Tracking#MOT20#MOTA#75.9$Multi-Object Tracking#MOT20#IDF1#76.4$Multi-Object Tracking#MOT20#HOTA#62.4$Multi-Object Tracking#DanceTrack#HOTA#55.1$Multi-Object Tracking#DanceTrack#AssA#38.0$Multi-Object Tracking#DanceTrack#MOTA#89.4$Multi-Object Tracking#DanceTrack#IDF1#54.2$Multi-Object Tracking#MOT17#MOTA#78.0$Multi-Object Tracking#MOT17#IDF1#77.5$Multi-Object Tracking#MOT17#HOTA#63.2$Multiple Object Tracking#CroHD#MOTA#67.9$Multiple Object Tracking#CroHD#IDF1#62.9$Multiple Object Tracking#CroHD#HOTA#44.1$Multiple Object Tracking#KITTI Tracking test#MOTA#90.3$Multiple Object Tracking#KITTI Tracking test#HOTA#76.5
2202.13514v1.pdf	Multi-Object Tracking#MOT20#MOTA#73.8$Multi-Object Tracking#MOT20#IDF1#77.0$Multi-Object Tracking#MOT20#HOTA#62.6$Multi-Object Tracking#MOT17#MOTA#79.6$Multi-Object Tracking#MOT17#IDF1#79.5$Multi-Object Tracking#MOT17#HOTA#64.4
2205.00968v2.pdf	Multi-Object Tracking#MOT20#MOTA#72.8$Multi-Object Tracking#MOT20#IDF1#70.6$Multi-Object Tracking#MOT20#HOTA#57.0$Multi-Object Tracking#HiEve#MOTA#47.2$Multi-Object Tracking#HiEve#IDF1#53.7$Multi-Object Tracking#MOT17#MOTA#76.4$Multi-Object Tracking#MOT17#IDF1#72.8$Multi-Object Tracking#MOT17#HOTA#60.8$Multi-Object Tracking#MOT16#MOTA#76.8$Multi-Object Tracking#MOT16#IDF1#73.5
2203.03985v1.pdf	Multi-Object Tracking#MOT20#MOTA#72.6$Multi-Object Tracking#MOT20#IDF1#70.2$Multi-Object Tracking#MOT20#HOTA#57.6$Multi-Object Tracking#MOT17#MOTA#75.3$Multi-Object Tracking#MOT17#IDF1#76.3$Multi-Object Tracking#MOT17#HOTA#61.6
2201.01297v1.pdf	Multi-Object Tracking#MOT20#MOTA#68.5$Multi-Object Tracking#MOT20#IDF1#69.4$Multi-Object Tracking#MOT17#MOTA#73.5$Multi-Object Tracking#MOT17#IDF1#70.2$Multi-Object Tracking#MOT16#MOTA#74.2$Multi-Object Tracking#MOT16#IDF1#71.1$Multi-Object Tracking#MOT16#IDs#1324
2210.03355v1.pdf	Multi-Object Tracking#MOT20#MOTA#68.0$Multi-Object Tracking#MOT20#IDF1#69.7$Multi-Object Tracking#MOT20#HOTA#57.3$Multi-Object Tracking#DanceTrack#HOTA#48.7$Multi-Object Tracking#DanceTrack#DetA#79.8$Multi-Object Tracking#DanceTrack#AssA#29.9$Multi-Object Tracking#DanceTrack#MOTA#89.9$Multi-Object Tracking#DanceTrack#IDF1#46.5$Multi-Object Tracking#MOT17#MOTA#76.7$Multi-Object Tracking#MOT17#IDF1#77.7$Multi-Object Tracking#MOT17#HOTA#62.6
2006.13164v3.pdf	Multi-Object Tracking#MOT20#MOTA#67.1$Multi-Object Tracking#2D MOT 2015#MOTA#60.7$Multi-Object Tracking#MOT17#MOTA#66.2$Multi-Object Tracking#MOT16#MOTA#66.7
2004.01888v6.pdf	Multi-Object Tracking#MOT20#MOTA#61.8$Multi-Object Tracking#MOT20#IDF1#67.3$Multi-Object Tracking#DanceTrack#HOTA#39.7$Multi-Object Tracking#DanceTrack#DetA#66.7$Multi-Object Tracking#DanceTrack#AssA#23.8$Multi-Object Tracking#DanceTrack#MOTA#82.2$Multi-Object Tracking#DanceTrack#IDF1#40.8$Multi-Object Tracking#2DMOT15#MOTA#60.6$Multi-Object Tracking#HiEve#MOTA#35.0$Multi-Object Tracking#MOT17#MOTA#73.7$Multi-Object Tracking#MOT17#IDF1#72.3$Multi-Object Tracking#MOT16#MOTA#74.9
2006.14550v1.pdf	Multi-Object Tracking#2D MOT 2015#MOTA#52.5$Multi-Object Tracking#2D MOT 2015#IDF1#60.0$Multi-Object Tracking#MOT17#MOTA#60.5$Multi-Object Tracking#MOT17#IDF1#65.6$Multi-Object Tracking#MOT16#MOTA#61.3$Multi-Object Tracking#MOT16#IDF1#64.7
1906.06618v3.pdf	Multi-Object Tracking#2D MOT 2015#MOTA#44.1$Multi-Object Tracking#MOT17#MOTA#53.7$Multi-Object Tracking#MOT16#MOTA#54.8
2105.03247v4.pdf	Multi-Object Tracking#DanceTrack#HOTA#54.2$Multi-Object Tracking#DanceTrack#DetA#73.5$Multi-Object Tracking#DanceTrack#AssA#40.2$Multi-Object Tracking#DanceTrack#MOTA#79.7$Multi-Object Tracking#DanceTrack#IDF1#51.5$Multi-Object Tracking#MOT17#MOTA#67.4$Multi-Object Tracking#MOT17#IDF1#67.0$Multi-Object Tracking#MOT16#MOTA#66.8$Multi-Object Tracking#MOT16#IDF1#67.0
2006.06664v4.pdf	Multi-Object Tracking#DanceTrack#HOTA#45.7$Multi-Object Tracking#DanceTrack#DetA#72.1$Multi-Object Tracking#DanceTrack#AssA#29.2$Multi-Object Tracking#DanceTrack#MOTA#83.0$Multi-Object Tracking#DanceTrack#IDF1#44.8$Multi-Object Tracking#MOT17#MOTA#68.7$Multi-Object Tracking#MOT17#IDF1#66.3$Multi-Object Tracking#MOT16#MOTA#69.8$Multi-Object Tracking#MOT16#IDF1#67.1$Multiple Object Tracking#BDD100K#mMOTA#35.5$Multiple Object Tracking#BDD100K#mIDF1#52.3$Multiple Object Tracking#Waymo Open Dataset#MOTA#55.6$Multiple Object Tracking#Waymo Open Dataset#mAP#49.5$Multiple Object Tracking#Waymo Open Dataset#Category#Vehicle$Multiple Object Tracking#BDD100K val#mMOTA#36.6$Multiple Object Tracking#BDD100K val#mIDF1#50.8$One-Shot Object Detection#PASCAL VOC 2012 val#MAP#22.1
2012.15460v2.pdf	Multi-Object Tracking#DanceTrack#HOTA#45.7$Multi-Object Tracking#DanceTrack#DetA#72.1$Multi-Object Tracking#DanceTrack#AssA#27.5$Multi-Object Tracking#DanceTrack#MOTA#83.0$Multi-Object Tracking#DanceTrack#IDF1#44.8
2103.08808v1.pdf	Multi-Object Tracking#DanceTrack#HOTA#43.3$Multi-Object Tracking#DanceTrack#DetA#74.5$Multi-Object Tracking#DanceTrack#AssA#25.4$Multi-Object Tracking#DanceTrack#MOTA#86.2$Multi-Object Tracking#DanceTrack#IDF1#41.2$Multi-Object Tracking#MOT15#MOTA#66.5$Multi-Object Tracking#MOT17#MOTA#69.1$Multi-Object Tracking#MOT17#IDF1#63.9$Multi-Object Tracking#MOTS20#sMOTSA#50.8$Multi-Object Tracking#MOTS20#IDF1#58.7$Multi-Object Tracking#MOT16#MOTA#70.1$Multi-Object Tracking#MOT16#IDF1#64.7$Online Multi-Object Tracking#MOT16#MOTA#67.7$Instance Segmentation#Cityscapes test#Average Precision#20.2$Instance Segmentation#nuScenes#MOTA#68.2$Video Instance Segmentation#YouTube-VIS validation#mask AP#32.6$Video Instance Segmentation#YouTube-VIS validation#AP50#52.6$Video Instance Segmentation#YouTube-VIS validation#AP75#32.8
2004.01177v2.pdf	Multi-Object Tracking#DanceTrack#HOTA#41.8$Multi-Object Tracking#DanceTrack#DetA#78.1$Multi-Object Tracking#DanceTrack#AssA#22.6$Multi-Object Tracking#DanceTrack#MOTA#86.8$Multi-Object Tracking#DanceTrack#IDF1#35.7$Multiple Object Tracking#KITTI Tracking test#MOTA#89.44
2101.08040v2.pdf	Multi-Object Tracking#TAO#Track mAP#27.461
2208.14167v1.pdf	Multi-Object Tracking#Synthehicle#MOTA#59.05
2010.12138v3.pdf	Multi-Object Tracking#HiEve#MOTA#48.6$Multi-Object Tracking#HiEve#IDF1#51.4
1909.12605v2.pdf	Multi-Object Tracking#HiEve#MOTA#33.1$Multi-Object Tracking#HiEve#IDF1#36.0$Multi-Object Tracking#MOT16#MOTA#64.4
1602.00763v2.pdf	Multi-Object Tracking#MOT15#MOTA#33.4$Multi-Object Tracking#MOT15#MOTP#72.1
2207.07078v4.pdf	Multi-Object Tracking#MOT17#MOTA#77.2$Multi-Object Tracking#MOT17#IDF1#75.5$Multi-Object Tracking#MOT17#HOTA#61.7$Multi-Object Tracking#MOTS20#sMOTSA#65.3$Multi-Object Tracking#MOTS20#IDF1#65.9$Visual Object Tracking#LaSOT#AUC#68.5$Visual Object Tracking#LaSOT#Normalized Precision#76.6$Visual Object Tracking#LaSOT#Precision#74.1$Visual Object Tracking#TrackingNet#Precision#82.2$Visual Object Tracking#TrackingNet#Normalized Precision#86.4$Visual Object Tracking#TrackingNet#Accuracy#83$Multiple Object Tracking#BDD100K#mMOTA#41.2$Multiple Object Tracking#BDD100K#mIDF1#54.0$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#29.6
2203.13250v2.pdf	Multi-Object Tracking#MOT17#MOTA#75.3$Multi-Object Tracking#MOT17#IDF1#71.5$Multi-Object Tracking#MOT17#HOTA#59.1
2101.02702v3.pdf	Multi-Object Tracking#MOT17#MOTA#74.1$Multi-Object Tracking#MOT17#IDF1#68.0$Multi-Object Tracking#MOTS20#sMOTSA#54.9
2106.10950v2.pdf	Multi-Object Tracking#MOT17#MOTA#67.8$Multi-Object Tracking#MOT17#IDF1#61.4
2102.02267v2.pdf	Multi-Object Tracking#MOT17#MOTA#66.6$Multi-Object Tracking#MOT16#MOTA#68.03$3D Multi-Object Tracking#nuScenes#amota#0.18$Multiple Object Tracking#KITTI Tracking test#MOTA#88.95
1811.07258v1.pdf	Multi-Object Tracking#MOT17#MOTA#51.9$Multi-Object Tracking#MOT16#MOTA#49.2
1705.08314v4.pdf	Multi-Object Tracking#MOT17#MOTA#51.3$Multi-Object Tracking#MOT16#MOTA#47.8
1809.04427v1.pdf	Multi-Object Tracking#MOT17#MOTA#50.9$Multi-Object Tracking#MOT16#MOTA#50.9$Online Multi-Object Tracking#MOT16#MOTA#47.6
1911.10535v5.pdf	Multi-Object Tracking#MOT15_3D#MOTA#54.2
2007.03200v3.pdf	Multi-Object Tracking#MOTS20#sMOTSA#70.4$Multi-Object Tracking#MOT16#MOTA#76.9
2107.02156v2.pdf	Multi-Object Tracking#MOTS20#sMOTSA#68.9$Multi-Object Tracking#MOTS20#IDF1#67.2$Multi-Object Tracking#MOTS20#IDs#622$Multi-Object Tracking#MOT16#MOTA#74.7$Multi-Object Tracking#MOT16#IDF1#71.8$Multi-Object Tracking#MOT16#IDs#683$Visual Object Tracking#OTB-2015#AUC#0.618$Video Object Segmentation#DAVIS 2017#mIoU#58.4$Pose Estimation#J-HMDB#Mean PCK@0.2#80.5$Pose Estimation#J-HMDB#Mean PCK@0.1#58.3$Pose Tracking#PoseTrack2018#MOTA#63.5$Pose Tracking#PoseTrack2018#IDF1#73.2$Pose Tracking#PoseTrack2018#IDs#6760$Video Instance Segmentation#YouTube-VIS validation#mask AP#30.1
1902.03604v2.pdf	Multi-Object Tracking#MOTS20#sMOTSA#40.6$Multi-Object Tracking#MOTS20#IDF1#42.4$Multiple Object Tracking#KITTI Tracking test#MOTA#84.83
1804.04555v1.pdf	Multi-Object Tracking#MOT16#MOTA#48.2
1504.02340v1.pdf	Multi-Object Tracking#MOT16#MOTA#46.4$Multiple Object Tracking#KITTI Tracking test#MOTA#78.15$Multiple Object Tracking#KITTI Tracking test#MOTA#75.20
1902.00749v1.pdf	Multi-Object Tracking#MOT16#MOTA#46.1$Online Multi-Object Tracking#MOT16#MOTA#46.1
2111.09621v1.pdf	3D Multi-Object Tracking#Waymo Open Dataset#3DMOTA#0.6030$3D Multi-Object Tracking#nuScenes#amota#0.67
2205.13542v2.pdf	3D Multi-Object Tracking#nuScenes#amota#0.74$3D Object Detection#nuScenes#NDS#0.76$3D Object Detection#nuScenes#mAP#0.75$3D Object Detection#nuScenes#mATE#0.24$3D Object Detection#nuScenes#mASE#0.23$3D Object Detection#nuScenes#mAOE#0.32$3D Object Detection#nuScenes#mAVE#0.22$3D Object Detection#nuScenes#mAAE#0.13
2104.14682v1.pdf	3D Multi-Object Tracking#nuScenes#amota#0.66$3D Multi-Object Tracking#KITTI#MOTA#96.61%$3D Multi-Object Tracking#KITTI#MOTP#80%$3D Multi-Object Tracking#KITTI#sAMOTA#94.94$Multiple Object Tracking#KITTI Tracking test#MOTA#87.82$Multiple Object Tracking#KITTI Tracking test#HOTA#74.39$Multi-Object Tracking and Segmentation#KITTI MOTS#HOTA#74.66$Multi-Object Tracking and Segmentation#KITTI MOTS#DetA#76.11$Multi-Object Tracking and Segmentation#KITTI MOTS#AssA#73.75
2006.11275v2.pdf	3D Multi-Object Tracking#nuScenes#amota#0.64$3D Object Detection#waymo all_ns#APH/L2#71.93$3D Object Detection#waymo cyclist#APH/L2#71.28$3D Object Detection#nuScenes#NDS#0.71$3D Object Detection#nuScenes#mAP#0.67$3D Object Detection#nuScenes#mATE#0.25$3D Object Detection#nuScenes#mASE#0.24$3D Object Detection#nuScenes#mAOE#0.35$3D Object Detection#nuScenes#mAVE#0.25$3D Object Detection#nuScenes#mAAE#0.14$3D Object Detection#waymo pedestrian#APH/L2#71.52
1802.09298v2.pdf	3D Multi-Object Tracking#KITTI#MOTA#84.24%$3D Multi-Object Tracking#KITTI#MOTP#85.73%$Multiple Object Tracking#KITTI Tracking test#MOTA#84.24
1907.03961v5.pdf	3D Multi-Object Tracking#KITTI#MOTA#83.34%$3D Multi-Object Tracking#KITTI#MOTP#85.23%$Multiple Object Tracking#KITTI Tracking test#MOTA#83.84
1905.02843v1.pdf	3D Multi-Object Tracking#KITTI#MOTA#77.72%$3D Multi-Object Tracking#KITTI#MOTP#82.32%
1806.11534v1.pdf	3D Multi-Object Tracking#KITTI#MOTA#76.15%$3D Multi-Object Tracking#KITTI#MOTP#83.42%$Multiple Object Tracking#KITTI Tracking test#MOTA#76.15
1904.07537v1.pdf	3D Multi-Object Tracking#KITTI#MOTA#75.70%$3D Multi-Object Tracking#KITTI#MOTP#78.46%
2203.11991v3.pdf	Visual Object Tracking#UAV123#AUC#0.707$Visual Object Tracking#LaSOT#AUC#71.1$Visual Object Tracking#LaSOT#Normalized Precision#81.1$Visual Object Tracking#LaSOT#Precision#77.6$Visual Object Tracking#GOT-10k#Average Overlap#73.7$Visual Object Tracking#GOT-10k#Success Rate 0.5#83.2$Visual Object Tracking#GOT-10k#Success Rate 0.75#70.8$Visual Object Tracking#TrackingNet#Precision#83.2$Visual Object Tracking#TrackingNet#Normalized Precision#88.5$Visual Object Tracking#TrackingNet#Accuracy#83.9
2207.09603v2.pdf	Visual Object Tracking#UAV123#AUC#0.706$Visual Object Tracking#LaSOT#AUC#69.0$Visual Object Tracking#LaSOT#Normalized Precision#79.4$Visual Object Tracking#LaSOT#Precision#73.8$Visual Object Tracking#NeedForSpeed#AUC#0.679$Visual Object Tracking#OTB-100#AUC#0.696$Visual Object Tracking#GOT-10k#Average Overlap#69.6$Visual Object Tracking#GOT-10k#Success Rate 0.5#80.0$Visual Object Tracking#GOT-10k#Success Rate 0.75#63.2$Visual Object Tracking#TrackingNet#Precision#80.4$Visual Object Tracking#TrackingNet#Normalized Precision#87.8$Visual Object Tracking#TrackingNet#Accuracy#82.7
2203.11082v2.pdf	Visual Object Tracking#UAV123#AUC#0.704$Visual Object Tracking#UAV123#Precision#0.918$Visual Object Tracking#LaSOT#AUC#70.1$Visual Object Tracking#LaSOT#Normalized Precision#79.9$Visual Object Tracking#LaSOT#Precision#76.3$Visual Object Tracking#GOT-10k#Average Overlap#71.2$Visual Object Tracking#GOT-10k#Success Rate 0.5#79.9$Visual Object Tracking#GOT-10k#Success Rate 0.75#65.8$Visual Object Tracking#GOT-10k#Average Overlap#70.7$Visual Object Tracking#GOT-10k#Success Rate 0.5#80.0$Visual Object Tracking#GOT-10k#Success Rate 0.75#67.8$Visual Object Tracking#TrackingNet#Precision#83.1$Visual Object Tracking#TrackingNet#Normalized Precision#88.9$Visual Object Tracking#TrackingNet#Accuracy#83.9
2103.16556v2.pdf	Visual Object Tracking#UAV123#AUC#0.697$Visual Object Tracking#LaSOT#AUC#67.1$Visual Object Tracking#LaSOT#Normalized Precision#77.2$Visual Object Tracking#LaSOT#Precision#70.2$Visual Object Tracking#OTB-2015#AUC#0.709
2007.04108v2.pdf	Visual Object Tracking#UAV123#AUC#0.679$Visual Object Tracking#UAV123#Precision#0.873$Visual Object Tracking#LaSOT#AUC#57.6$Visual Object Tracking#GOT-10k#Average Overlap#61.7$Visual Object Tracking#GOT-10k#Success Rate 0.5#72.9$Visual Object Tracking#OTB-2015#Precision#0.931$Visual Object Tracking#OTB-2015#AUC#0.701
1909.12297v4.pdf	Visual Object Tracking#UAV123#AUC#0.672$Visual Object Tracking#TrackingNet#Precision#69.7$Visual Object Tracking#TrackingNet#Normalized Precision#80.1$Visual Object Tracking#TrackingNet#Success Rate#74.5$Object Detection#COCO test-dev#AP50#58.5$Object Detection#COCO test-dev#AP75#41.8
2005.01698v2.pdf	Visual Object Tracking#UAV123#AUC#0.672$Visual Object Tracking#LaSOT#AUC#63.7$Visual Object Tracking#NeedForSpeed#AUC#0.65$Visual Object Tracking#OTB-100#AUC#0.707$Visual Object Tracking#TrackingNet#Precision#73.7$Visual Object Tracking#TrackingNet#Normalized Precision#83.7$Visual Object Tracking#TrackingNet#Success Rate#0.787$Visual Object Tracking#TrackingNet#AUC#0.787
2104.00403v1.pdf	Visual Object Tracking#UAV123#AUC#0.669$Visual Object Tracking#UAV123#Precision#0.884$Visual Object Tracking#VOT2019#Expected Average Overlap (EAO)#0.391$Visual Object Tracking#VOT2019#Accuracy#60.3$Visual Object Tracking#GOT-10k#Average Overlap#66.8$Visual Object Tracking#GOT-10k#Success Rate 0.5#77.8$Visual Object Tracking#GOT-10k#Success Rate 0.75#57.2$Visual Object Tracking#VOT2018#Expected Average Overlap (EAO)#0.496$Visual Object Tracking#VOT2018#Accuracy#61.2$Visual Object Tracking#TrackingNet#Precision#75$Visual Object Tracking#TrackingNet#Normalized Precision#83.8$Visual Object Tracking#TrackingNet#Accuracy#78.5
2007.09115v2.pdf	Visual Object Tracking#OTB-2013#AUC#0.68$Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.36$Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.27$Visual Object Tracking#OTB-2015#AUC#0.66
1802.08817v1.pdf	Visual Object Tracking#OTB-2013#AUC#0.677$Visual Object Tracking#OTB-50#AUC#0.610$Visual Object Tracking#OTB-2015#AUC#0.657
1902.02804v4.pdf	Visual Object Tracking#OTB-2013#AUC#0.665$Visual Object Tracking#OTB-50#AUC#0.61$Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.351$Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.286$Visual Object Tracking#OTB-2015#AUC#0.654
1704.06036v1.pdf	Visual Object Tracking#OTB-2013#AUC#0.611$Visual Object Tracking#OTB-50#AUC#0.530$Visual Object Tracking#OTB-2015#AUC#0.568
1606.09549v3.pdf	Visual Object Tracking#OTB-2013#AUC#0.607$Visual Object Tracking#OTB-50#AUC#0.516
1907.03892v5.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.446$Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.466$Visual Object Tracking#VOT2019#Expected Average Overlap (EAO)#0.309
1911.06188v4.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.428$Visual Object Tracking#GOT-10k#Average Overlap#61.0$Visual Object Tracking#GOT-10k#Success Rate 0.5#74.2$Visual Object Tracking#TrackingNet#Precision#68.5$Visual Object Tracking#TrackingNet#Normalized Precision#79.8$Visual Object Tracking#TrackingNet#Accuracy#74.5
1907.12920v2.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.4160$Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.4104
1812.11703v1.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.414$Visual Object Tracking#TrackingNet#Precision#69.38$Visual Object Tracking#TrackingNet#Normalized Precision#79.98$Visual Object Tracking#TrackingNet#Accuracy#70
1812.05050v2.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.380$Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Seen)#54.3$Visual Object Tracking#YouTube-VOS 2018 val#O (Average of Measures)#52.8$Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Unseen)#45.1$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Seen)#58.2$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Unseen)#47.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#54.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#62.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#19.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#58.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#67.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#20.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#56.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#71.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#86.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#3.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#67.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#79.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#2.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#69.75$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#43.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#40.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#44.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#21.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#45.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#45.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#22.4
1803.08679v1.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.345
1809.01368v1.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.337
1808.06048v1.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.326
1706.07457v2.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.323
1611.09224v2.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.280$Visual Object Tracking#TrackingNet#Precision#48.86$Visual Object Tracking#TrackingNet#Normalized Precision#62.14$Visual Object Tracking#TrackingNet#Accuracy#56.13
1611.08461v3.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.263
1803.10537v1.pdf	Visual Object Tracking#VOT2017/18#Expected Average Overlap (EAO)#0.137
2103.16746v1.pdf	Visual Object Tracking#TNL2K#precision#0.42|0.50|0.42$Visual Tracking#TNL2K#precision#0.42|0.50|0.42
2112.00995v3.pdf	Visual Object Tracking#LaSOT#AUC#70.2$Visual Object Tracking#LaSOT#Normalized Precision#78.4$Visual Object Tracking#LaSOT#Precision#75.3$Visual Object Tracking#GOT-10k#Average Overlap#69.4$Visual Object Tracking#GOT-10k#Success Rate 0.5#78$Visual Object Tracking#GOT-10k#Success Rate 0.75#64.3$Visual Object Tracking#TrackingNet#Precision#83.2$Visual Object Tracking#TrackingNet#Normalized Precision#88.2$Visual Object Tracking#TrackingNet#Accuracy#84
2103.17154v1.pdf	Visual Object Tracking#LaSOT#AUC#67.1$Visual Object Tracking#LaSOT#Normalized Precision#77.0$Visual Object Tracking#GOT-10k#Average Overlap#68.8$Visual Object Tracking#GOT-10k#Success Rate 0.5#78.1$Visual Object Tracking#TrackingNet#Precision#79.1$Visual Object Tracking#TrackingNet#Normalized Precision#86.9$Visual Object Tracking#TrackingNet#Accuracy#82.0
2208.05810v3.pdf	Visual Object Tracking#LaSOT#AUC#66.8$Visual Object Tracking#LaSOT#Normalized Precision#75.5$Visual Object Tracking#GOT-10k#Average Overlap#67.5$Visual Object Tracking#GOT-10k#Success Rate 0.5#76.8$Visual Object Tracking#GOT-10k#Success Rate 0.75#60.3$Visual Object Tracking#TrackingNet#Precision#81.4$Visual Object Tracking#TrackingNet#Normalized Precision#87.5$Visual Object Tracking#TrackingNet#Accuracy#82.8
2103.15436v1.pdf	Visual Object Tracking#LaSOT#AUC#64.9$Visual Object Tracking#LaSOT#Normalized Precision#73.8$Visual Object Tracking#LaSOT#Precision#69.0
1911.12836v2.pdf	Visual Object Tracking#LaSOT#AUC#64.8$Visual Object Tracking#LaSOT#Normalized Precision#72.2$Visual Object Tracking#GOT-10k#Average Overlap#64.9$Visual Object Tracking#GOT-10k#Success Rate 0.5#72.8$Visual Object Tracking#TrackingNet#Precision#80.0$Visual Object Tracking#TrackingNet#Normalized Precision#85.4$Visual Object Tracking#TrackingNet#Accuracy#81.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#66.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#74.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#15.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#75.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#82.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#16.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#70.55$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#76.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#86.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#2.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#80.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#78.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#53.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#48.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#53.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#21.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#58.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#62.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#20.2
2103.11681v2.pdf	Visual Object Tracking#LaSOT#AUC#63.7$Visual Object Tracking#LaSOT#Precision#61.4
2012.02776v2.pdf	Visual Object Tracking#LaSOT#AUC#57.2$Visual Object Tracking#LaSOT#Normalized Precision#65.3$Visual Object Tracking#LaSOT#Precision#58.7$Visual Object Tracking#TrackingNet#Precision#71.2$Visual Object Tracking#TrackingNet#Normalized Precision#81.0$Visual Object Tracking#TrackingNet#Accuracy#75.3
1904.07220v2.pdf	Visual Object Tracking#LaSOT#AUC#56.8$Visual Object Tracking#LaSOT#Normalized Precision#65.0$Visual Object Tracking#LaSOT#Precision#56.7$Visual Object Tracking#GOT-10k#Average Overlap#61.1$Visual Object Tracking#GOT-10k#Success Rate 0.5#71.7$Visual Object Tracking#TrackingNet#Precision#68.7$Visual Object Tracking#TrackingNet#Normalized Precision#80.1$Visual Object Tracking#TrackingNet#Accuracy#74.0
1811.07628v2.pdf	Visual Object Tracking#LaSOT#AUC#51.4$Visual Object Tracking#LaSOT#Normalized Precision#57.6$Visual Object Tracking#LaSOT#Precision#50.5$Visual Object Tracking#GOT-10k#Average Overlap#55.6$Visual Object Tracking#GOT-10k#Success Rate 0.5#63.4$Visual Object Tracking#TrackingNet#Precision#64.84$Visual Object Tracking#TrackingNet#Normalized Precision#77.11$Visual Object Tracking#TrackingNet#Accuracy#70.34
2203.11192v1.pdf	Visual Object Tracking#LaSOT#Precision#67.1$Visual Object Tracking#LaSOT#IS#66$Visual Object Tracking#TOTB#Precision#67.6
1704.06326v2.pdf	Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.3903
1901.01660v3.pdf	Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.37$Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.30
1806.07078v3.pdf	Visual Object Tracking#VOT2016#Expected Average Overlap (EAO)#0.295$Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.263$Visual Tracking#OTB-2013#AUC#0.657$Visual Tracking#OTB-100#AUC#0.318
2006.10721v2.pdf	Visual Object Tracking#VOT2019#Expected Average Overlap (EAO)#0.327$Visual Object Tracking#GOT-10k#Average Overlap#61.1$Visual Object Tracking#GOT-10k#Success Rate 0.5#72.1$Visual Object Tracking#VOT2018#Expected Average Overlap (EAO)#0.467
1907.13242v2.pdf	Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.397$Visual Object Tracking#TrackingNet#Precision#56.57$Visual Object Tracking#TrackingNet#Normalized Precision#71.79$Visual Object Tracking#TrackingNet#Accuracy#60.9
1909.06800v1.pdf	Visual Object Tracking#VOT2017#Expected Average Overlap (EAO)#0.247$Visual Object Tracking#OTB-2015#Precision#0.861
2104.00324v2.pdf	Visual Object Tracking#GOT-10k#Average Overlap#64.2$Visual Object Tracking#GOT-10k#Success Rate 0.5#73.7$Visual Object Tracking#GOT-10k#Success Rate 0.75#57.5$Visual Object Tracking#OTB-2015#AUC#0.719
2112.07957v2.pdf	Visual Object Tracking#GOT-10k#Average Overlap#0.645$Visual Object Tracking#GOT-10k#Average Overlap#0.623$Visual Object Tracking#GOT-10k#Average Overlap#0.619
1611.05198v4.pdf	Visual Object Tracking#YouTube-VOS 2018 val#O (Average of Measures)#58.8$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Seen)#60.5$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Unseen)#60.7$Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.783$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#60.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#60.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#58.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#0.10$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#59.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#54.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#56.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#63.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#26.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#63.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#73.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#27.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#60.25$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#79.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#93.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#14.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#80.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#92.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#15.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#80.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#50.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#47.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#52.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#19.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#54.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#59.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#19.8$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#60.5$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#60.7$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#59.8$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#54.2
1706.09364v2.pdf	Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Seen)#60.1$Visual Object Tracking#YouTube-VOS 2018 val#O (Average of Measures)#55.2$Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Unseen)#46.6$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Seen)#62.7$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Unseen)#51.4$Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.774$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#61.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#67.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#27.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#69.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#75.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#26.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#65.35$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#96.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#84.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#89.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#85.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#52.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#49.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#54.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#23.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#55.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#60.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#23.4
1802.01218v1.pdf	Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Seen)#60.0$Visual Object Tracking#YouTube-VOS 2018 val#O (Average of Measures)#51.2$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Seen)#60.1$Visual Object Tracking#YouTube-VOS 2018 val#F-Measure (Unseen)#44.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#60.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#44.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#51.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#7.14$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#60.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#40.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#52.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#60.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#21.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#57.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#66.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#24.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#54.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#74.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#9.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#72.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#84.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#10.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#73.45$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J&F score#41.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J score#37.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#F score#44.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#41.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#37.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#38.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#19.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#44.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#47.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#17.4$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#60.1$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#44.0$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#60.0$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#40.6$Video Instance Segmentation#YouTube-VIS validation#mask AP#29.1$Video Instance Segmentation#YouTube-VIS validation#AP50#28.6$Video Instance Segmentation#YouTube-VIS validation#AP75#33.1
1907.01203v2.pdf	Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Seen)#73.5$Visual Object Tracking#YouTube-VOS 2018 val#Jaccard (Unseen)#64.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#71.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#77.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#74.65
2009.09237v2.pdf	Visual Object Tracking#OTB-2015#Precision#0.91$Visual Object Tracking#OTB-2015#AUC#0.70$Visual Object Tracking#TempleColor128#AUC#0.62$Visual Object Tracking#TempleColor128#Precision#0.84
1512.01355v2.pdf	Visual Object Tracking#TrackingNet#Precision#46.72$Visual Object Tracking#TrackingNet#Normalized Precision#60.84$Visual Object Tracking#TrackingNet#Accuracy#53.59
2208.01159v4.pdf	Visual Object Tracking#YouTube-VOS 2018 validation#F-Measure (Unseen)#83.4$Visual Object Tracking#YouTube-VOS 2018 validation#F-Measure (Seen)#86.7$Visual Object Tracking#YouTube-VOS 2018 validation#Jaccard (Unseen)#75.7$Visual Object Tracking#YouTube-VOS 2018 validation#Jaccard (Unseen)#75.3$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#84.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#79.2$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#85.3$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#89.8$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#87.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#83.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#78.1$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#84.1$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#88.5$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#86.1$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#83.1$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#78.5$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#84$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#87.7$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#86.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#81.9$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#77.9$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#83$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#86.5$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#85.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#81.8$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#77.1$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#82.8$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#86.6$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#85.6$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#82.2$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#82$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#82$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#75$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#81.8$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#86.7$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#83.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#81.2$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#76$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#81.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#80.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#76.4$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#81.5$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#84.9$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#84.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#81.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#75.3$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#81.4$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#85.6$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#83.3$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#78.8$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#74.1$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#79.6$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#83.1$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#82.6$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#79.7$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#72.8$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#79.4$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#84.2$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#80.9$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#82.1$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#75.7$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#85.7$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#82.4$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#81.1$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#85.8$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#86.2$Video Object Segmentation#DAVIS-2017 validation#F-measure#89.3$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#85.4$Video Object Segmentation#DAVIS-2017 validation#Jaccard#82.2$Video Object Segmentation#DAVIS-2017 validation#F-measure#88.6$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#84.9$Video Object Segmentation#DAVIS-2017 validation#Jaccard#82.3$Video Object Segmentation#DAVIS-2017 validation#F-measure#87.5$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#83.9$Video Object Segmentation#DAVIS-2017 validation#Jaccard#81.4$Video Object Segmentation#DAVIS-2017 validation#F-measure#86.4$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#83.7$Video Object Segmentation#DAVIS-2017 validation#Jaccard#81.3$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#83.5$Video Object Segmentation#DAVIS-2017 validation#Jaccard#81$Video Object Segmentation#DAVIS-2017 validation#F-measure#86$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#82.9$Video Object Segmentation#DAVIS-2017 validation#Jaccard#80.1$Video Object Segmentation#DAVIS-2017 validation#F-measure#85.7$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#82.8$Video Object Segmentation#DAVIS-2017 validation#Jaccard#80$Video Object Segmentation#DAVIS-2017 validation#F-measure#85.6$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#82.5$Video Object Segmentation#DAVIS-2017 validation#Jaccard#79.9$Video Object Segmentation#DAVIS-2017 validation#F-measure#85.1$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#81.9$Video Object Segmentation#DAVIS-2017 validation#Jaccard#79.3$Video Object Segmentation#DAVIS-2017 validation#F-measure#84.5$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#81.6$Video Object Segmentation#DAVIS-2017 validation#Jaccard#79.1$Video Object Segmentation#DAVIS-2017 validation#F-measure#84.1$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#74.6$Video Object Segmentation#DAVIS-2017 validation#Jaccard#73$Video Object Segmentation#DAVIS-2017 validation#F-measure#76.1$Video Object Segmentation#DAVIS-2017 validation#Jaccard#80.5$Video Object Segmentation#DAVIS-2017 validation#F-measure#86.5$Video Object Segmentation#DAVIS-2017 validation#Jaccard#79.2$Video Object Segmentation#DAVIS-2017 validation#F-measure#84.3$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#92.5$Video Object Segmentation#DAVIS 2016 val#Jaccard#90.7$Video Object Segmentation#DAVIS 2016 val#F-measure#94.2$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#91.6$Video Object Segmentation#DAVIS 2016 val#Jaccard#90.8$Video Object Segmentation#DAVIS 2016 val#F-measure#92.5$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#91.1$Video Object Segmentation#DAVIS 2016 val#Jaccard#90.1$Video Object Segmentation#DAVIS 2016 val#F-measure#92.1$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#90.7$Video Object Segmentation#DAVIS 2016 val#Jaccard#89.9$Video Object Segmentation#DAVIS 2016 val#F-measure#91.4$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#90.6$Video Object Segmentation#DAVIS 2016 val#Jaccard#87.1$Video Object Segmentation#DAVIS 2016 val#F-measure#94$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#90.5$Video Object Segmentation#DAVIS 2016 val#Jaccard#89.5$Video Object Segmentation#DAVIS 2016 val#F-measure#91.5$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#89.9$Video Object Segmentation#DAVIS 2016 val#F-measure#91.1$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#89.4$Video Object Segmentation#DAVIS 2016 val#Jaccard#88.3$Video Object Segmentation#DAVIS 2016 val#F-measure#90.5$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#88.8$Video Object Segmentation#DAVIS 2016 val#Jaccard#88.9$Video Object Segmentation#DAVIS 2016 val#F-measure#88.7$Video Object Segmentation#DAVIS 2016 val#Jaccard#89.8$Video Object Segmentation#DAVIS 2016 val#F-measure#91.2$Video Object Segmentation#DAVIS 2016 val#Jaccard#88.7$Video Object Segmentation#DAVIS 2016 val#F-measure#89.9$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#85$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.5$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#89.3$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.2$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#84.1$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#83.5$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#78.4$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.1$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#86.3$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#83.9$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#82.6$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79.1$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#86.9$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.1$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#82.7$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#81.1$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#78.2$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#85.4$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#85.9$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#82.6$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#81.7$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#77.1$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#86.2$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#85.2$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#81.8$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#80.9$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#76.6$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#81$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#80.6$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#75.2$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#85.1$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#83$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#82.2$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#78.4$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#79.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#75.9$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#83.3$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#79.2$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#75.8$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#82.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#78.1$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#74.4$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#81.8$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#77.2$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#74.1$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#80.3$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#76.9$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#73$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#80.9$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#76.1$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#72.7$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#79.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#75.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#71.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#75$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#71.4$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#78.7$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#71.9$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#78.1$Video Object Segmentation#DAVIS-2017#F-measure#86.1
2103.13516v1.pdf	Multiple Object Tracking#CroHD#MOTA#63.6$Multiple Object Tracking#CroHD#IDEucl#60.3$Multiple Object Tracking#CroHD#MT#146$Multiple Object Tracking#CroHD#ML#93$Multiple Object Tracking#CroHD#IDs#892$Multiple Object Tracking#CroHD#IDF1#57.1$Multiple Object Tracking#CroHD#MOTA#58.9$Multiple Object Tracking#CroHD#IDEucl#31.8$Multiple Object Tracking#CroHD#MT#125$Multiple Object Tracking#CroHD#ML#117$Multiple Object Tracking#CroHD#IDs#3474$Multiple Object Tracking#CroHD#IDF1#38.5$Multiple Object Tracking#CroHD#MOTA#46.4$Multiple Object Tracking#CroHD#IDEucl#58$Multiple Object Tracking#CroHD#MT#49$Multiple Object Tracking#CroHD#ML#216$Multiple Object Tracking#CroHD#IDs#649$Multiple Object Tracking#CroHD#IDF1#48.4
2003.13870v1.pdf	Multiple Object Tracking#Waymo Open Dataset#MOTA#44.92$Multiple Object Tracking#Waymo Open Dataset#mAP#45.70$Multiple Object Tracking#Waymo Open Dataset#Category#Vehicle
2103.07351v1.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#86.41
2002.08397v4.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#85.70
1909.03850v1.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#84.77
1811.10742v3.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#84.52
1802.09975v1.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#80.39
1608.08434v1.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#78.90
1809.07357v1.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#75.39
1407.6251v2.pdf	Multiple Object Tracking#KITTI Tracking test#MOTA#72.69
2210.13570v1.pdf	Multiple Object Tracking with Transformer#MOT20#HOTA#56.1$Multiple Object Tracking with Transformer#MOT20#MOTA#73.0$Multiple Object Tracking with Transformer#MOT20#IDF1#67.6
2106.11958v2.pdf	Multiple Object Track and Segmentation#BDD100K#mMOTSA#27.4$Video Instance Segmentation#BDD100K#mMOTSA#27.4$Video Instance Segmentation#BDD100K#mMOTSA#23.5$Video Instance Segmentation#BDD100K#mMOTSA#22.5$Video Instance Segmentation#BDD100K#mMOTSA#12.3$Video Instance Segmentation#BDD100K#mMOTSA#12.2$Video Instance Segmentation#BDD100K#mMOTSA#10.3$Video Instance Segmentation#YouTube-VIS validation#mask AP#36.1$Video Instance Segmentation#YouTube-VIS validation#AP50#54.9$Video Instance Segmentation#YouTube-VIS validation#AP75#39.4$Video Instance Segmentation#YouTube-VIS validation#AR1#36.3$Video Instance Segmentation#YouTube-VIS validation#AR10#41.6$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#27.4$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#23.5$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#22.5$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#12.3$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#12.2$Multi-Object Tracking and Segmentation#BDD100K#mMOTSA#10.3
1903.05625v3.pdf	Online Multi-Object Tracking#MOT16#MOTA#54.4$Online Multi-Object Tracking#MOT17#MOTA#53.5$Online Multi-Object Tracking#2D MOT 2015#MOTA#44.1
1907.13347v1.pdf	Online Multi-Object Tracking#MOT17#MOTA#49.9$Online Multi-Object Tracking#MOT15#MOTA#30.7
2205.13349v2.pdf	Video Object Tracking#CATER#Top 1 Accuracy#90.7$Video Object Tracking#CATER#Top 5 Accuracy#98.5$Video Object Tracking#CATER#L1#0.14
2203.05928v1.pdf	Video Object Tracking#CATER#Top 1 Accuracy#79.7$Video Object Tracking#CATER#Top 5 Accuracy#95.5$Video Object Tracking#CATER#L1#0.47$Action Recognition#Diving-48#Accuracy#88.3
2003.10469v4.pdf	Video Object Tracking#CATER#Top 1 Accuracy#74.8$Video Object Tracking#CATER#L1#0.54
2012.08508v3.pdf	Video Object Tracking#CATER#Top 1 Accuracy#74.0$Video Object Tracking#CATER#Top 5 Accuracy#94.0$Video Object Tracking#CATER#L1#0.44
2103.10574v2.pdf	Video Object Tracking#CATER#Top 1 Accuracy#73.2$Video Object Tracking#CATER#Top 5 Accuracy#93.8$Video Object Tracking#CATER#L1#0.85
2106.10271v4.pdf	Temporal Action Localization#HACS#Average-mAP#32.09$Temporal Action Localization#HACS#mAP@0.5#47.14$Temporal Action Localization#HACS#mAP@0.75#32.11$Temporal Action Localization#HACS#mAP@0.95#10.94$Temporal Action Localization#THUMOS’14#mAP IOU@0.5#60.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#74.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#69.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#46.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#32.8$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#56.7$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#53.62$Temporal Action Localization#ActivityNet-1.3#mAP#36.75$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#37.52$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#10.56
1712.09374v3.pdf	Temporal Action Localization#HACS#Average-mAP#18.97$Temporal Action Localization#HACS#mAP@0.5#28.82$Temporal Action Localization#HACS#mAP@0.75#18.80$Temporal Action Localization#HACS#mAP@0.95#5.32
1911.06644v5.pdf	Temporal Action Localization#UCF101-24#Frame-mAP#87.2$Temporal Action Localization#UCF101-24#Video-mAP 0.5#48.8$Temporal Action Localization#J-HMDB-21#Frame-mAP#74.4$Temporal Action Localization#J-HMDB-21#Video-mAP 0.2#87.8$Temporal Action Localization#J-HMDB-21#Video-mAP 0.5#85.7$Temporal Action Localization#J-HMDB-21#Video-mAP 0.75#58.1
2210.12686v1.pdf	Temporal Action Localization#UCF101-24#Frame-mAP#84.8$Temporal Action Localization#UCF101-24#Video-mAP 0.5#74.3$Temporal Action Localization#UCF101-24#Video-mAP 0.2#88.8$Temporal Action Localization#J-HMDB-21#Frame-mAP#83.8$Temporal Action Localization#J-HMDB-21#Video-mAP 0.2#89.7$Temporal Action Localization#J-HMDB-21#Video-mAP 0.5#88.1$Action Recognition#AVA v2.2#mAP#32.6$Action Detection#MultiSports#Frame-mAP#33.3$Action Detection#MultiSports#Video-mAP 0.2#27.8$Action Detection#MultiSports#Video-mAP 0.5#8.8
1705.08421v4.pdf	Temporal Action Localization#UCF101-24#Frame-mAP#76.3$Temporal Action Localization#UCF101-24#Video-mAP 0.5#59.9$Temporal Action Localization#J-HMDB-21#Frame-mAP#73.3$Temporal Action Localization#J-HMDB-21#Video-mAP 0.5#78.6$Action Recognition#AVA v2.1#mAP (Val)#22.0
1705.01861v3.pdf	Temporal Action Localization#UCF101-24#Frame-mAP#69.5$Temporal Action Localization#J-HMDB-21#Frame-mAP#65.7
2202.07925v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#71.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#82.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#77.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#59.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#43.9$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#66.8$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#54.7$Temporal Action Localization#ActivityNet-1.3#mAP#36.6$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#37.8$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.4
2207.07097v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#57.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#69.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#65.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#47.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#35.6$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#55.0
2205.02717v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#58.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#68.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#65.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#49.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#33.5$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#54.9
2204.02932v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#56.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#69.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#64.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#46.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#34.9$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#54.2$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.47$Temporal Action Localization#ActivityNet-1.3#mAP#35.10$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.99$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#10.83
2012.09434v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#56.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#68.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#64.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#46.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#31.0$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#53.4$Temporal Action Localization#MUSES#mAP@0.3#25.9$Temporal Action Localization#MUSES#mAP@0.4#22.6$Temporal Action Localization#MUSES#mAP@0.5#18.9$Temporal Action Localization#MUSES#mAP@0.6#15.0$Temporal Action Localization#MUSES#mAP@0.7#10.6$Temporal Action Localization#MUSES#mAP#18.6
2106.14118v4.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#57.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#70.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#64.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#45.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#28.8$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#53.3$Temporal Action Localization#THUMOS'14#mAP IOU@0.5#57.18$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#54.34$Temporal Action Localization#ActivityNet-1.3#mAP#36.82$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#37.66$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.93
2207.06580v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#57.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#68.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#63.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#46.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#31.8$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#52.8$Temporal Action Localization#ActivityNet-1.3#mAP#36.5
2112.03612v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#54.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#68.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#62.7$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#43.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#32.6$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#52.3$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#51.78$Temporal Action Localization#ActivityNet-1.3#mAP#35.39$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.98$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#9.45
2011.11479v3.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#53.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#74.02$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#72.29$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#69.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#63.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#40.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#26$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#50.46$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#51.26$Temporal Action Localization#ActivityNet-1.3#mAP#35.81$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#37.12$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#9.29$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#69.04$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#76.63$Dense Video Captioning#ActivityNet Captions#METEOR#8.75$Dense Video Captioning#ActivityNet Captions#BLEU-3#4.16$Dense Video Captioning#ActivityNet Captions#BLEU-4#2.02
2011.14598v3.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#52.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#66.7$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#60.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#41.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#30.4$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#50.2$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#53.26$Temporal Action Localization#ActivityNet-1.3#mAP#35.94$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#36.76$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.12
2107.04362v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#53.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#62.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#59.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#43.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#30.1$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#50.0
1904.07442v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#44.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#60.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#54.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#32.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#19.1$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#42.0
1804.07667v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#42.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#59.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#57.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#53.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#48.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#33.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#20.8$Temporal Action Localization#THUMOS’14#Avg mAP (0.3:0.7)#39.8
2112.00302v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#51.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#72.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#70.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#66.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#60.8$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#51.03$Temporal Action Localization#ActivityNet-1.3#mAP#34.24$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.17$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#7.44
2101.08540v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#50.2$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#72.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#69.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#65$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#58.1
1909.03252v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#49.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#69.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#67.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#63.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#57.8$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#48.26$Temporal Action Localization#ActivityNet-1.3#mAP#31.11$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#33.16$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#3.27
2001.07793v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#29.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#62.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#46.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#9.7$Temporal Action Localization#ActivityNet-1.2#mAP IOU@0.5#35.2$Temporal Action Localization#ActivityNet-1.2#mAP IOU@0.1#60.5$Temporal Action Localization#ActivityNet-1.2#mAP IOU@0.3#48.4$Temporal Action Localization#ActivityNet-1.2#mAP IOU@0.7#16.3
1705.01180v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#31$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#60.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#56.7$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#50.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#41.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#19.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#9.9
1703.07814v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#28.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#54.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#51.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#44.8$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#35.6$Action Detection#Charades#mAP#12.4
1703.06189v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#25.6$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#54$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#50.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#44.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#34.9$Action Recognition#THUMOS’14#mAP@0.3#46.3$Action Recognition#THUMOS’14#mAP@0.4#35.3$Action Recognition#THUMOS’14#mAP@0.5#24.5
1511.06984v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#17.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#48.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#44.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#36.0$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#26.4$Action Recognition#THUMOS’14#mAP@0.1#48.9$Action Recognition#THUMOS’14#mAP@0.2#44.0$Action Recognition#THUMOS’14#mAP@0.3#36.0$Action Recognition#THUMOS’14#mAP@0.4#26.4$Action Recognition#THUMOS’14#mAP@0.5#17.1
1601.02129v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#19$Temporal Action Localization#THUMOS’14#mAP IOU@0.1#47.7$Temporal Action Localization#THUMOS’14#mAP IOU@0.2#43.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#36.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#28.7$Temporal Action Localization#MEXaction2#mAP#7.4$Action Recognition#THUMOS’14#mAP@0.1#47.7$Action Recognition#THUMOS’14#mAP@0.2#43.5$Action Recognition#THUMOS’14#mAP@0.3#36.3$Action Recognition#THUMOS’14#mAP@0.4#28.7$Action Recognition#THUMOS’14#mAP@0.5#19.0
1806.02964v3.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#36.9$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#53.5$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#45$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#28.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#20$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#46.45$Temporal Action Localization#ActivityNet-1.3#mAP#30.03$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#29.96$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.02$Action Recognition#THUMOS’14#mAP@0.3#53.5$Action Recognition#THUMOS’14#mAP@0.4#45.0$Action Recognition#THUMOS’14#mAP@0.5#36.9$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#66.17$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#74.16$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (test)#66.26$Temporal Action Proposal Generation#THUMOS' 14#AR@100#46.06$Temporal Action Proposal Generation#THUMOS' 14#AR@1000#64.52$Temporal Action Proposal Generation#THUMOS' 14#AR@200#53.21$Temporal Action Proposal Generation#THUMOS' 14#AR@50#37.46$Temporal Action Proposal Generation#THUMOS' 14#AR@500#60.64
1703.01515v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#23.3$Temporal Action Localization#THUMOS’14#mAP IOU@0.3#40.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.4#29.4$Temporal Action Localization#THUMOS’14#mAP IOU@0.6#13.1$Temporal Action Localization#THUMOS’14#mAP IOU@0.7#7.9
1911.11462v2.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#40.2$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.36$Temporal Action Localization#ActivityNet-1.3#mAP#34.09$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#34.60$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#9.02
1907.09702v1.pdf	Temporal Action Localization#THUMOS’14#mAP IOU@0.5#32.2$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.07$Temporal Action Localization#ActivityNet-1.3#mAP#33.85$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#34.78$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.29$Action Recognition#THUMOS’14#mAP@0.3#56.0$Action Recognition#THUMOS’14#mAP@0.4#47.4$Action Recognition#THUMOS’14#mAP@0.5#38.8$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#67.1$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#75.01
1604.07279v1.pdf	Temporal Action Localization#J-HMDB-21#Frame-mAP#39.9
2109.14084v2.pdf	Temporal Action Localization#CrossTask#Recall#47.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#30.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#55.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#66.8$Video Retrieval#YouCook2#text-to-video R@1#32.2$Video Retrieval#YouCook2#text-to-video R@10#75.0$Video Retrieval#YouCook2#text-to-video R@5#62.6$Video Retrieval#YouCook2#text-to-video R@1#22.7$Video Retrieval#YouCook2#text-to-video R@10#63.1$Video Retrieval#YouCook2#text-to-video R@5#50.4$Action Segmentation#COIN#Frame accuracy#68.7
2105.09996v3.pdf	Temporal Action Localization#CrossTask#Recall#46.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#28.10$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#55.50$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#67.40$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#4$Video Retrieval#YouCook2#text-to-video Median Rank#4$Video Retrieval#YouCook2#text-to-video R@1#27.05$Video Retrieval#YouCook2#text-to-video R@10#69.38$Video Retrieval#YouCook2#text-to-video R@5#56.88$Action Segmentation#COIN#Frame accuracy#68.4$Video Captioning#YouCook2#BLEU-3#17.78$Video Captioning#YouCook2#BLEU-4#12.27$Video Captioning#YouCook2#METEOR#18.22$Video Captioning#YouCook2#ROUGE-L#41.51$Video Captioning#YouCook2#CIDEr#1.3869
2108.09980v1.pdf	Temporal Action Localization#CrossTask#Recall#42.5$Video Retrieval#ActivityNet#text-to-video R@1#30.4$Video Retrieval#ActivityNet#text-to-video R@5#61.2$Video Retrieval#ActivityNet#text-to-video R@50#93.4$Video Retrieval#ActivityNet#text-to-video Median Rank#3.0$Video Retrieval#MSR-VTT#text-to-video R@1#24.8$Video Retrieval#MSR-VTT#text-to-video R@5#52.1$Video Retrieval#MSR-VTT#text-to-video R@10#64.0$Video Retrieval#MSR-VTT#text-to-video Median Rank#5$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#28.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#57.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#71.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#4$Video Retrieval#YouCook2#text-to-video Median Rank#4$Video Retrieval#YouCook2#text-to-video R@1#29.6$Video Retrieval#YouCook2#text-to-video R@10#72.7$Video Retrieval#YouCook2#text-to-video R@5#59.7$Action Segmentation#COIN#Frame accuracy#68.4
1906.03327v2.pdf	Temporal Action Localization#CrossTask#Recall#33.6$Video Retrieval#MSR-VTT#text-to-video R@1#14.9$Video Retrieval#MSR-VTT#text-to-video R@10#52.8$Video Retrieval#MSR-VTT#text-to-video Median Rank#9$Video Retrieval#MSR-VTT#video-to-text R@5#40.2$Video Retrieval#LSMDC#text-to-video R@1#7.2$Video Retrieval#LSMDC#text-to-video R@5#19.6$Video Retrieval#LSMDC#text-to-video R@10#27.9$Video Retrieval#LSMDC#text-to-video Median Rank#40$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#14.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#40.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#52.8$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#9$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#12.1$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#35.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#48.0$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#12$Video Retrieval#YouCook2#text-to-video Median Rank#24$Video Retrieval#YouCook2#text-to-video R@1#8.2$Video Retrieval#YouCook2#text-to-video R@10#35.3$Video Retrieval#YouCook2#text-to-video R@5#24.5
1903.08225v2.pdf	Temporal Action Localization#CrossTask#Recall#31.6$Temporal Action Localization#CrossTask#Recall#22.4
1506.09215v4.pdf	Temporal Action Localization#CrossTask#Recall#13.3
2106.11812v1.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#59.7$Temporal Action Localization#ActivityNet-1.3#mAP#42.0$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#57.9$Temporal Action Localization#ActivityNet-1.3#mAP#39.4$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#55.5$Temporal Action Localization#ActivityNet-1.3#mAP#37.5
2103.13141v1.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#54.33$Temporal Action Localization#ActivityNet-1.3#mAP#37.56$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#39.13$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.41
2009.07641v5.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#51.27$Temporal Action Localization#ActivityNet-1.3#mAP#34.88$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.70$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#8.33$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#68.26$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#76.52
2011.10830v3.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.94$Temporal Action Localization#ActivityNet-1.3#mAP#34.75$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.61$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#7.98
2104.03214v1.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.72$Temporal Action Localization#ActivityNet-1.3#mAP#34.48$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#35.28$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#7.87
2008.01432v1.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#50.56$Temporal Action Localization#ActivityNet-1.3#mAP#34.26$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.75#34.75$Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.95#9.37
1703.02716v1.pdf	Temporal Action Localization#ActivityNet-1.3#mAP IOU@0.5#39.12$Temporal Action Localization#ActivityNet-1.3#mAP#32.26
2006.08247v2.pdf	Action Recognition#HACS#Top 1 Accuracy#84.33$Action Recognition#HACS#Top 5 Accuracy#96.85$Action Recognition#HACS#Top 1 Accuracy#83.77$Action Recognition#HACS#Top 5 Accuracy#96.56$Action Recognition#HACS#Top 1 Accuracy#81.66$Action Recognition#HACS#Top 5 Accuracy#96.33$Action Recognition#HACS#Top 1 Accuracy#80.39$Action Recognition#HACS#Top 5 Accuracy#94.27$Action Recognition#HACS#Top 1 Accuracy#80.36$Action Recognition#HACS#Top 5 Accuracy#95.55$Action Recognition#HACS#Top 1 Accuracy#78.60$Action Recognition#HACS#Top 5 Accuracy#93.57$Action Classification#Moments in Time#Top 1 Accuracy#33.56$Action Classification#Moments in Time#Top 5 Accuracy#58.49$Action Classification#Moments in Time#Top 1 Accuracy#31.60$Action Classification#Moments in Time#Top 5 Accuracy#56.80$Action Classification#Moments in Time#Top 1 Accuracy#30.72$Action Classification#Moments in Time#Top 5 Accuracy#55.65$Action Classification#Moments in Time#Top 1 Accuracy#28.97$Action Classification#Moments in Time#Top 5 Accuracy#54.18$Action Classification#Moments in Time#Top 1 Accuracy#28.55$Action Classification#Moments in Time#Top 5 Accuracy#52.35$Action Classification#Kinetics-700#Top-1 Accuracy#56.46$Action Classification#Kinetics-700#Top-5 Accuracy#76.82$Action Classification#Kinetics-700#Top-1 Accuracy#54.17$Action Classification#Kinetics-700#Top-5 Accuracy#74.62$Action Classification#Kinetics-700#Top-1 Accuracy#53.52$Action Classification#Kinetics-700#Top-5 Accuracy#74.17$Action Classification#Kinetics-700#Top-1 Accuracy#49.43$Action Classification#Kinetics-700#Top-5 Accuracy#73.23$Action Classification#Kinetics-700#Top-1 Accuracy#49.15$Action Classification#Kinetics-700#Top-5 Accuracy#72.68
2107.10771v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#57.2$Action Recognition#Something-Something V1#Top 5 Accuracy#83.9
2103.15584v4.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#57.1$Action Recognition#Something-Something V1#Top 5 Accuracy#84.2$Action Recognition#UCF101#3-fold Accuracy#97.6$Action Recognition#HMDB-51#Average accuracy of 3 splits#77.6$Action Classification#Kinetics-400#Acc@1#77.3$Action Classification#Kinetics-400#Acc@5#93.2
2012.10071v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#56.8$Action Recognition#Something-Something V1#Top 5 Accuracy#84.1$Action Recognition#Something-Something V2#Top-1 Accuracy#69.6$Action Recognition#Something-Something V2#Top-5 Accuracy#92.2$Action Recognition#Something-Something V2#GFLOPs#198x3$Action Recognition#Something-Something V2#Top-1 Accuracy#68.2$Action Recognition#Something-Something V2#Top-5 Accuracy#91.6$Action Recognition#Something-Something V2#GFLOPs#198x1$Action Classification#Kinetics-400#Acc@1#79.4$Action Classification#Kinetics-400#Acc@5#94.4
2102.07092v3.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#56.6$Action Recognition#Something-Something V1#Top 5 Accuracy#84.4$Action Recognition#Something-Something V1#Top 1 Accuracy#55.8$Action Recognition#Something-Something V1#Top 5 Accuracy#83.9$Action Recognition#Something-Something V1#Top 1 Accuracy#54.3$Action Recognition#Something-Something V1#Top 5 Accuracy#82.9$Action Recognition#Something-Something V2#Top-1 Accuracy#67.7$Action Recognition#Something-Something V2#Top-5 Accuracy#91.1$Action Recognition#Something-Something V2#Top-1 Accuracy#67.4$Action Recognition#Something-Something V2#Top-5 Accuracy#91$Action Recognition#Something-Something V2#Top-1 Accuracy#65.7$Action Recognition#Something-Something V2#Top-5 Accuracy#89.8
2106.01603v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#56.6$Action Recognition#Something-Something V2#Top-1 Accuracy#67.8$Action Recognition#Something-Something V2#Top-5 Accuracy#91.1$Action Recognition#Something-Something V2#Parameters#83.8$Action Recognition#Something-Something V2#GFLOPs#280$Action Classification#Kinetics-400#Acc@1#79.8
2111.01673v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#56.1$Action Recognition#Something-Something V1#Top 5 Accuracy#82.8$Action Recognition#Something-Something V1#Top 1 Accuracy#55.5$Action Recognition#Something-Something V1#Top 5 Accuracy#82.6$Action Recognition#Something-Something V1#Top 1 Accuracy#54.0$Action Recognition#Something-Something V1#Top 5 Accuracy#81.1$Action Recognition#Something-Something V1#Top 1 Accuracy#51.9$Action Recognition#Something-Something V1#Top 5 Accuracy#79.6$Action Recognition#Something-Something V2#Top-1 Accuracy#67.7$Action Recognition#Something-Something V2#Top-5 Accuracy#91.1$Action Recognition#Something-Something V2#Top-1 Accuracy#67.3$Action Recognition#Something-Something V2#Top-5 Accuracy#90.8$Action Recognition#Something-Something V2#Top-1 Accuracy#66$Action Recognition#Something-Something V2#Top-5 Accuracy#89.8$Action Recognition#Something-Something V2#Top-1 Accuracy#64.8$Action Recognition#Something-Something V2#Top-5 Accuracy#89.1$Action Recognition#Diving-48#Accuracy#84.2
2008.03462v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#55.3$Action Recognition#Something-Something V1#Top 5 Accuracy#82.8$Action Recognition#Jester#Val#97.4$Action Recognition#Something-Something V2#Top-1 Accuracy#66.5$Action Recognition#Something-Something V2#Top-5 Accuracy#90.6
1912.00381v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#55.16$Action Recognition#Something-Something V1#Top 1 Accuracy#51.68
2007.09933v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#55.1$Action Recognition#Something-Something V1#Top 1 Accuracy#54.4$Action Recognition#Something-Something V1#Top 5 Accuracy#83.8$Action Recognition#Something-Something V1#Top 1 Accuracy#52.1$Action Recognition#Something-Something V1#Top 5 Accuracy#82.3$Action Recognition#Something-Something V1#Top 1 Accuracy#50.9$Action Recognition#Something-Something V1#Top 5 Accuracy#80.3$Action Recognition#Something-Something V2#Top-1 Accuracy#66.6$Action Recognition#Something-Something V2#Top-5 Accuracy#90.6$Action Recognition#Something-Something V2#Top-1 Accuracy#64.7$Action Recognition#Something-Something V2#Top-5 Accuracy#89.4$Action Recognition#Something-Something V2#Top-1 Accuracy#63$Action Recognition#Something-Something V2#Top-5 Accuracy#88.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#77.4$Action Classification#Kinetics-400#Acc@1#76.4$Video Classification#Something-Something V2#Top-5 Accuracy#91$Video Classification#Something-Something V1#Top-5 Accuracy#84
2012.00317v3.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#54.59$Action Recognition#Something-Something V1#Top 5 Accuracy#82.30$Action Recognition#Something-Something V1#Param.#5.8M$Action Recognition#Something-Something V1#GFLOPs#20.9x6$Action Recognition#Something-Something V1#Top 1 Accuracy#52.68$Action Recognition#Something-Something V1#Top 5 Accuracy#80.43$Action Recognition#Something-Something V1#Param.#3.3M$Action Recognition#Something-Something V1#GFLOPs#11.5x6$Action Recognition#Something-Something V1#Top 1 Accuracy#50.6$Action Recognition#Something-Something V1#Top 5 Accuracy#78.7$Action Recognition#Something-Something V1#Top 1 Accuracy#49.8$Action Recognition#Something-Something V1#Top 5 Accuracy#78.0$Action Recognition#Something-Something V1#Top 1 Accuracy#49.5$Action Recognition#Something-Something V1#GFLOPs#9.3x6$Action Recognition#Something-Something V1#Top 1 Accuracy#48.1$Action Recognition#Something-Something V1#Top 5 Accuracy#76.9$Action Recognition#Something-Something V1#GFLOPs#5.7x6$Action Recognition#Something-Something V2#Top-1 Accuracy#67.35$Action Recognition#Something-Something V2#Top-5 Accuracy#90.50$Action Recognition#Something-Something V2#Parameters#5.8M$Action Recognition#Something-Something V2#GFLOPs#20.9x6$Action Recognition#Something-Something V2#Top-1 Accuracy#65.8$Action Recognition#Something-Something V2#Top-5 Accuracy#89.5$Action Recognition#Something-Something V2#Top-1 Accuracy#65.24$Action Recognition#Something-Something V2#Top-5 Accuracy#89.48$Action Recognition#Something-Something V2#Parameters#3.3M$Action Recognition#Something-Something V2#GFLOPs#11.5x6$Action Recognition#Something-Something V2#Top-1 Accuracy#64.2$Action Recognition#Something-Something V2#Top-5 Accuracy#88.8$Action Recognition#Something-Something V2#Top-1 Accuracy#64.1$Action Recognition#Something-Something V2#Top-5 Accuracy#88.6$Action Recognition#Something-Something V2#GFLOPs#9.3x6$Action Recognition#Something-Something V2#Top-1 Accuracy#63.2$Action Recognition#Something-Something V2#Top-5 Accuracy#88.2$Action Recognition#Something-Something V2#GFLOPs#5.7x6
2007.09033v5.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#54.1$Action Recognition#Something-Something V1#Top 5 Accuracy#82.2$Action Recognition#Something-Something V1#Top 1 Accuracy#52.7$Action Recognition#Something-Something V1#Top 5 Accuracy#81.5$Action Classification#Kinetics-400#Acc@1#77.4
2012.06977v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#54.0$Action Recognition#Something-Something V2#Top-1 Accuracy#66.3$Action Classification#Kinetics-400#Acc@1#79.1$Action Classification#Kinetics-400#Acc@5#93.8
1908.07625v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#53.4$Action Classification#Kinetics-400#Acc@1#78.8
1904.02811v4.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#53.3$Action Recognition#Something-Something V1#Top 1 Accuracy#52.1$Action Recognition#Something-Something V1#Top 1 Accuracy#51.6$Action Recognition#Something-Something V1#Top 1 Accuracy#49.3$Action Recognition#Something-Something V1#Top 1 Accuracy#48.4$Action Recognition#Sports-1M#Video hit@1#75.5$Action Recognition#Sports-1M#Video hit@5#92.8$Action Recognition#Sports-1M#Video hit@1#74.9$Action Recognition#Sports-1M#Video hit@5#92.6$Action Classification#Kinetics-400#Acc@1#82.6$Action Classification#Kinetics-400#Acc@1#82.5$Action Classification#Kinetics-400#Acc@5#95.3$Action Classification#Kinetics-400#Acc@1#81.3$Action Classification#Kinetics-400#Acc@5#95.1$Action Classification#Kinetics-400#Acc@1#79.2$Action Classification#Kinetics-400#Acc@5#93.8$Action Classification#Kinetics-400#Acc@1#77.8$Action Classification#Kinetics-400#Acc@5#92.8
2004.01278v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#52.6$Action Recognition#Something-Something V1#Top 5 Accuracy#81.3$Action Recognition#Something-Something V2#Top-1 Accuracy#66.5$Action Recognition#Something-Something V2#Top-5 Accuracy#90.4$Action Recognition#EPIC-KITCHENS-55#Top-1 Accuracy#34.2$Action Recognition#EgoGesture#Top-1 Accuracy#94.3$Action Recognition#EgoGesture#Top-5 Accuracy#99.2
1908.02486v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#50.7$Action Recognition#Jester#Val#96.7$Action Recognition#Something-Something V2#Top-1 Accuracy#64.2$Action Recognition#Something-Something V2#Top-5 Accuracy#89.8$Action Recognition#UCF101#3-fold Accuracy#96.2$Action Recognition#HMDB-51#Average accuracy of 3 splits#72.2$Action Classification#Kinetics-400#Acc@1#73.7
1811.08383v3.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#50.7$Action Recognition#Something-Something V1#Top 1 Accuracy#49.7$Action Recognition#Something-Something V1#Top 5 Accuracy#78.5$Action Recognition#Something-Something V1#Top 1 Accuracy#47.2$Action Recognition#Something-Something V1#Top 5 Accuracy#77.1$Action Recognition#Something-Something V2#Top-1 Accuracy#66.6$Action Recognition#Something-Something V2#Top-5 Accuracy#91.3$Action Classification#Kinetics-400#Acc@1#74.7$Video Object Detection#ImageNet VID#MAP#76.3
1801.03150v3.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#50$Action Recognition#Something-Something V1#Top 1 Accuracy#48.6$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#31.16$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#57.67$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#29.51$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#56.06$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#28.27$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#53.87$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#15.71$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#34.65$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#7.60$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#18.00
1908.09995v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#49.7$Action Recognition#Something-Something V1#Top 1 Accuracy#49.5$Action Recognition#Something-Something V1#Top 5 Accuracy#86.1$Action Recognition#Something-Something V2#Top-1 Accuracy#62.2$Action Recognition#Something-Something V2#Top-5 Accuracy#90.3$Action Recognition#Something-Something V2#Top-1 Accuracy#61.3$Action Recognition#Something-Something V2#Top-5 Accuracy#91.4
1904.05582v4.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#49.2
1712.04851v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#48.2$Action Recognition#Something-Something V1#Top 5 Accuracy#78.7$Action Recognition#Something-Something V1#Top 1 Accuracy#47.3$Action Recognition#Something-Something V1#Top 5 Accuracy#78.1$Action Recognition#UCF101#3-fold Accuracy#96.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#75.9$Action Classification#Kinetics-600#Top-1 Accuracy#78.6$Action Classification#Kinetics-600#Top-1 Accuracy#76.6$Action Classification#Kinetics-600#Top-1 Accuracy#69.7$Action Classification#Kinetics-400#Acc@1#77.2$Action Classification#Kinetics-400#Acc@5#93$Action Classification#Kinetics-400#Acc@1#74.7$Action Classification#Kinetics-400#Acc@5#93.4$Action Classification#Kinetics-400#Acc@1#68$Action Classification#Kinetics-400#Acc@5#87.6
1804.09066v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#46.4
1806.01810v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#46.1$Action Classification#Charades#MAP#39.7
1711.07971v3.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#44.4$Action Classification#Toyota Smarthome dataset#CS#53.6$Action Classification#Toyota Smarthome dataset#CV1#34.3$Action Classification#Toyota Smarthome dataset#CV2#43.9$Action Classification#Kinetics-400#Acc@1#77.7$Action Classification#Kinetics-400#Acc@5#93.3$Keypoint Detection#COCO#Validation AP#66.5$Object Detection#COCO minival#box AP#45.0$Object Detection#COCO minival#AP50#67.8$Object Detection#COCO minival#AP75#48.9$Object Detection#COCO minival#box AP#40.8$Object Detection#COCO minival#AP50#63.1$Object Detection#COCO minival#AP75#44.5$Object Detection#COCO minival#box AP#39.0$Object Detection#COCO minival#AP50#61.1$Object Detection#COCO minival#AP75#41.9$Instance Segmentation#COCO minival#mask AP#40.3$Instance Segmentation#COCO minival#mask AP#37.1$Instance Segmentation#COCO minival#mask AP#35.5
1807.10037v2.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#43.9$Action Recognition#Jester#Val#96.68
1905.12462v1.pdf	Action Recognition#Something-Something V1#Top 1 Accuracy#41.97$Action Recognition#HMDB-51#Average accuracy of 3 splits#71.13
1905.12681v5.pdf	Action Recognition#Sports-1M#Video hit@1#74.8$Action Recognition#Sports-1M#Video hit@5#92.4$Action Recognition#miniSports#Video hit@1#62.8$Action Recognition#miniSports#Video hit@5#85.5$Action Recognition#miniSports#Clip Hit@1#49.7$Action Classification#Kinetics-400#Acc@1#78.9$Action Classification#Kinetics-400#Acc@1#77.7
1711.11248v3.pdf	Action Recognition#Sports-1M#Video hit@1#73.3$Action Recognition#Sports-1M#Video hit@5#91.9$Action Recognition#Sports-1M#Clip Hit@1#57$Action Recognition#Sports-1M#Video hit@1#73$Action Recognition#Sports-1M#Video hit@5#91.5$Action Recognition#Sports-1M#Clip Hit@1#46.4$Action Recognition#Sports-1M#Video hit@1#68.4$Action Recognition#Sports-1M#Video hit@5#88.7$Action Recognition#UCF101#3-fold Accuracy#97.3$Action Recognition#UCF101#3-fold Accuracy#96.8$Action Recognition#UCF101#3-fold Accuracy#95.5$Action Recognition#UCF101#3-fold Accuracy#95$Action Recognition#UCF101#3-fold Accuracy#93.6$Action Recognition#UCF101#3-fold Accuracy#93.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#78.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#76.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#74.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#72.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#70.1$Action Recognition#HMDB-51#Average accuracy of 3 splits#66.6$Action Classification#Kinetics-400#Acc@1#75.4$Action Classification#Kinetics-400#Acc@5#91.9$Action Classification#Kinetics-400#Acc@1#74.3$Action Classification#Kinetics-400#Acc@5#91.4$Action Classification#Kinetics-400#Acc@1#73.9$Action Classification#Kinetics-400#Acc@5#90.9$Action Classification#Kinetics-400#Acc@1#72$Action Classification#Kinetics-400#Acc@5#90$Action Classification#Kinetics-400#Acc@1#67.5$Action Classification#Kinetics-400#Acc@5#87.2
1503.08909v2.pdf	Action Recognition#Sports-1M#Video hit@1#71.7$Action Recognition#Sports-1M#Video hit@5#90.4$Action Recognition#UCF101#3-fold Accuracy#88.6
1711.10305v1.pdf	Action Recognition#Sports-1M#Clip Hit@1#47.9$Action Recognition#Sports-1M#Video hit@1#66.4$Action Recognition#Sports-1M#Video hit@5#87.4$Action Recognition#UCF101#3-fold Accuracy#88.6$Action Recognition#ActivityNet#mAP#78.9
1412.0767v4.pdf	Action Recognition#Sports-1M#Clip Hit@1#46.1$Action Recognition#Sports-1M#Video hit@1#61.1$Action Recognition#Sports-1M#Video hit@5#85.5$Action Recognition#UCF101#3-fold Accuracy#82.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#51.6
2008.01232v3.pdf	Action Recognition#UCF 101#3-fold Accuracy#98.69$Action Recognition#HMDB-51#Average accuracy of 3 splits#85.10
2203.10233v1.pdf	Action Recognition#Jester#Val#98.15$Action Recognition#Something-Something V2#Top-1 Accuracy#64.94$Action Recognition#Something-Something V2#Top-5 Accuracy#87.9$Action Classification#Kinetics-400#Acc@1#82.75$Action Classification#Kinetics-400#Acc@5#94.86
1905.07853v1.pdf	Action Recognition#Jester#Val#96.70$Action Recognition#Something-Something V2#Top-1 Accuracy#57.65$Action Recognition#Something-Something V2#Top-5 Accuracy#83.95
2108.13153v1.pdf	Action Recognition#Jester#Val#95.56$Action Recognition#UCF101#3-fold Accuracy#94.85
1805.07550v1.pdf	Action Recognition#Jester#Val#95.31$Action Recognition#Something-Something V2#Top-1 Accuracy#34.11
1911.11033v4.pdf	Action Recognition#Jester#Val#92.7$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.30$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.4%
1904.02422v5.pdf	Action Recognition#Jester#Val#90.77$Action Recognition#Jester#Val#86.91$Action Recognition#Jester#Val#86.43$Action Recognition#UCF101#3-fold Accuracy#74.94$Action Recognition#UCF101#3-fold Accuracy#56.52$Action Recognition#UCF101#3-fold Accuracy#55.56
2012.07175v2.pdf	Action Recognition#NTU RGB+D#Accuracy (CS)#92.24
2210.07503v1.pdf	Action Recognition#NTU RGB+D#Accuracy (CS)#92.0$Action Recognition#NTU RGB+D#Accuracy (CV)#96.5$Action Recognition#Penn Action#1:1 Accuracy#98.7$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#90.3$Action Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#92.7
2002.12886v1.pdf	Action Recognition#NTU RGB+D#Accuracy (CS)#91.8$Action Recognition#NTU RGB+D#Accuracy (CV)#94.9
1603.07120v2.pdf	Action Recognition#NTU RGB+D#Accuracy (CS)#74.9$Multimodal Activity Recognition#MSR Daily Activity3D dataset#Accuracy#97.5
2102.07355v1.pdf	Action Recognition#Win-Fail Action Understanding#2-Class Accuracy#75.74%$Action Understanding#Win-Fail Action Understanding#2-Class Accuracy#75.74 %
2007.02561v2.pdf	Action Recognition#BAR#Accuracy#62.98
2204.02426v4.pdf	Action Recognition#BAR#Accuracy#52.6
2009.05224v2.pdf	Action Recognition#HAA500#Top-1 (%)#64.4$Action Recognition#HAA500#Top-1 (%)#50.53$Action Recognition#HAA500#Top-1 (%)#49.87$Action Recognition#HAA500#Top-1 (%)#39.93
2006.07976v3.pdf	Action Recognition#AVA v2.1#mAP (Val)#30.0$Action Recognition#AVA v2.2#mAP#31.72$Spatio-Temporal Action Localization#AVA-Kinetics#val mAP#40.49$Spatio-Temporal Action Localization#AVA-Kinetics#test mAP#39.62$Spatio-Temporal Action Localization#AVA-Kinetics#val mAP#36.36
1812.03982v3.pdf	Action Recognition#AVA v2.1#mAP (Val)#28.3$Action Recognition#AVA v2.1#mAP (Val)#27.3$Action Recognition#AVA v2.1#mAP (Val)#26.8$Action Recognition#AVA v2.1#mAP (Val)#26.3$Action Recognition#Something-Something V2#Top-1 Accuracy#61.7$Action Recognition#AVA v2.2#mAP#27.5$Action Recognition#AVA v2.2#mAP#27.1$Action Recognition#AVA v2.2#mAP#23.8$Action Recognition#AVA v2.2#mAP#21.9$Action Recognition#Diving-48#Accuracy#77.6$Action Classification#Charades#MAP#45.2$Action Classification#Charades#MAP#42.5$Action Classification#Charades#MAP#42.1$Action Classification#Kinetics-600#Top-1 Accuracy#81.8$Action Classification#Kinetics-600#Top-5 Accuracy#95.1$Action Classification#Kinetics-600#Top-1 Accuracy#81.1$Action Classification#Kinetics-600#Top-1 Accuracy#80.4$Action Classification#Kinetics-600#Top-5 Accuracy#94.8$Action Classification#Kinetics-600#Top-1 Accuracy#79.9$Action Classification#Kinetics-600#Top-5 Accuracy#94.5$Action Classification#Kinetics-600#Top-1 Accuracy#78.8$Action Classification#Kinetics-600#Top-5 Accuracy#94$Action Classification#Kinetics-400#Acc@1#79.8$Action Classification#Kinetics-400#Acc@1#78.9$Action Classification#Kinetics-400#Acc@5#93.5$Action Classification#Kinetics-400#Acc@1#77.9$Action Classification#Kinetics-400#Acc@5#93.2$Action Classification#Kinetics-400#Acc@1#77$Action Classification#Kinetics-400#Acc@5#92.6$Action Classification#Kinetics-400#Acc@1#75.6$Action Classification#Kinetics-400#Acc@5#92.1$Action Classification#Kinetics-400#Acc@5#93.9
1812.05038v2.pdf	Action Recognition#AVA v2.1#mAP (Val)#27.7$Action Classification#Charades#MAP#42.5$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#21.2$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S1)#32.70
1812.02707v2.pdf	Action Recognition#AVA v2.1#mAP (Val)#27.6$Action Recognition#AVA v2.1#GFlops#39.6$Action Recognition#AVA v2.1#Params (M)#19.3$Action Recognition#AVA v2.1#mAP (Val)#23.4$Action Recognition#AVA v2.1#GFlops#6.5$Action Recognition#AVA v2.1#Params (M)#16.2
1812.08249v2.pdf	Action Recognition#AVA v2.1#mAP (Val)#23$Action Recognition#UCF101#3-fold Accuracy#97.6$Action Recognition#UCF101#3-fold Accuracy#97.1$Action Recognition#UCF101#3-fold Accuracy#97$Action Recognition#HMDB-51#Average accuracy of 3 splits#80.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#79.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#78.7$Action Classification#Kinetics-600#Top-1 Accuracy#79.1$Action Classification#Kinetics-600#Top-1 Accuracy#77.9$Action Classification#Kinetics-400#Acc@1#76.5$Action Classification#Kinetics-400#Acc@1#75.9
1807.10066v1.pdf	Action Recognition#AVA v2.1#mAP (Val)#22.8$Action Recognition#AVA v2.1#mAP (Val)#21.9
1807.10982v1.pdf	Action Recognition#AVA v2.1#mAP (Val)#17.4
2203.12602v3.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#75.4$Action Recognition#Something-Something V2#Top-5 Accuracy#95.2$Action Recognition#Something-Something V2#Parameters#305$Action Recognition#Something-Something V2#GFLOPs#1436x3$Action Recognition#Something-Something V2#Top-1 Accuracy#74.3$Action Recognition#Something-Something V2#Top-5 Accuracy#94.6$Action Recognition#Something-Something V2#GFLOPs#597x6$Action Recognition#Something-Something V2#Top-1 Accuracy#70.8$Action Recognition#Something-Something V2#Top-5 Accuracy#92.4$Action Recognition#Something-Something V2#Parameters#87$Action Recognition#Something-Something V2#GFLOPs#180x6$Action Recognition#AVA v2.2#mAP#39.5$Action Recognition#AVA v2.2#mAP#39.3$Action Recognition#AVA v2.2#mAP#37.8$Action Recognition#AVA v2.2#mAP#36.5$Action Recognition#AVA v2.2#mAP#36.1$Action Recognition#AVA v2.2#mAP#34.3$Action Recognition#AVA v2.2#mAP#31.8$Action Recognition#AVA v2.2#mAP#26.7$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#73.3$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#62.6$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#no extra data$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#96.1$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#91.3$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#no extra data$Action Classification#Kinetics-400#Acc@1#87.4$Action Classification#Kinetics-400#Acc@5#97.6$Action Classification#Kinetics-400#Acc@1#86.6$Action Classification#Kinetics-400#Acc@5#97.1$Action Classification#Kinetics-400#Acc@1#86.1$Action Classification#Kinetics-400#Acc@5#97.3$Action Classification#Kinetics-400#Acc@1#85.2$Action Classification#Kinetics-400#Acc@5#96.8$Action Classification#Kinetics-400#Acc@1#81.5$Action Classification#Kinetics-400#Acc@5#95.1
2112.09133v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#75.0$Action Recognition#Something-Something V2#Top-5 Accuracy#95.0$Action Recognition#Something-Something V2#Parameters#218$Action Recognition#Something-Something V2#GFLOPs#2828*3$Action Recognition#AVA v2.2#mAP#38.8$Action Classification#Kinetics-600#Top-1 Accuracy#88.3$Action Classification#Kinetics-600#Top-5 Accuracy#98.0$Action Classification#Kinetics-400#Acc@1#87.0$Action Classification#Kinetics-400#Acc@5#97.4$Action Classification#Kinetics-400#Acc@1#86.7$Action Classification#Kinetics-400#Acc@5#97.3$Action Classification#Kinetics-700#Top-1 Accuracy#80.4$Action Classification#Kinetics-700#Top-5 Accuracy#95.7$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#85.7%
2207.11660v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#74.7$Action Recognition#Something-Something V2#Top-5 Accuracy#94.9$Action Recognition#Something-Something V2#Parameters#311$Action Recognition#Something-Something V2#GFLOPs#276x6$Action Recognition#Something-Something V2#Top-1 Accuracy#73.8$Action Recognition#Something-Something V2#Top-5 Accuracy#94.4$Action Recognition#Something-Something V2#GFLOPs#131x6$Action Recognition#Something-Something V2#Top-1 Accuracy#71.0$Action Recognition#Something-Something V2#Top-5 Accuracy#92.8$Action Recognition#Something-Something V2#Parameters#94$Action Recognition#Something-Something V2#GFLOPs#86x6$Action Recognition#Something-Something V2#Top-1 Accuracy#69.5$Action Recognition#Something-Something V2#Top-5 Accuracy#91.9$Action Recognition#Something-Something V2#GFLOPs#41x6$Action Classification#Kinetics-400#Acc@1#85.3$Action Classification#Kinetics-400#Acc@5#96.3$Action Classification#Kinetics-400#Acc@1#83.9$Action Classification#Kinetics-400#Acc@5#96.0$Action Classification#Kinetics-400#Acc@1#81.0$Action Classification#Kinetics-400#Acc@5#94.4$Action Classification#Kinetics-400#Acc@1#79.4$Action Classification#Kinetics-400#Acc@5#93.7
2112.01526v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#73.3$Action Recognition#Something-Something V2#Top-5 Accuracy#94.1$Action Recognition#Something-Something V2#Parameters#213.1$Action Recognition#Something-Something V2#Top-1 Accuracy#72.1$Action Recognition#Something-Something V2#GFLOPs#225x3$Action Recognition#Something-Something V2#Top-5 Accuracy#93.4$Action Recognition#Something-Something V2#Parameters#51.1$Action Recognition#Something-Something V2#GFLOPs#2828x3$Action Recognition#AVA v2.2#mAP#34.4$Action Classification#Kinetics-600#Top-1 Accuracy#87.9$Action Classification#Kinetics-600#Top-5 Accuracy#97.9$Action Classification#Kinetics-600#Top-1 Accuracy#85.5$Action Classification#Kinetics-600#Top-5 Accuracy#97.2$Action Classification#Kinetics-600#GFLOPs#206x5$Action Classification#Kinetics-400#Acc@1#86.1$Action Classification#Kinetics-400#Acc@5#97.0$Action Classification#Kinetics-400#FLOPs (G) x views#225x5$Action Classification#Kinetics-700#Top-1 Accuracy#79.4$Action Classification#Kinetics-700#Top-5 Accuracy#94.9$Action Classification#Kinetics-700#Top-1 Accuracy#76.6$Action Classification#Kinetics-700#Top-5 Accuracy#93.2$Object Detection#COCO minival#box AP#58.7$Object Detection#COCO minival#box AP#56.1$Object Detection#COCO minival#box AP#54.3$Object Detection#COCO minival#box AP#52.7$Image Classification#ImageNet#Top 1 Accuracy#88.8%$Image Classification#ImageNet#Number of params#667M$Image Classification#ImageNet#GFLOPs#763.5$Image Classification#ImageNet#Top 1 Accuracy#88.4%$Image Classification#ImageNet#Number of params#218M$Image Classification#ImageNet#GFLOPs#140.7$Image Classification#ImageNet#Top 1 Accuracy#88%$Image Classification#ImageNet#GFLOPs#120.6$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#GFLOPs#140.2$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#Number of params#24M$Image Classification#ImageNet#GFLOPs#4.7$Instance Segmentation#COCO minival#mask AP#50.5$Instance Segmentation#COCO minival#mask AP#48.5$Instance Segmentation#COCO minival#mask AP#47.1$Instance Segmentation#COCO minival#mask AP#46.2
2206.13559v3.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#72.3$Action Recognition#Something-Something V2#Top-5 Accuracy#93.9$Action Recognition#Something-Something V2#GFLOPs#8248$Action Classification#Kinetics-400#Acc@1#87.2$Action Classification#Kinetics-400#Acc@5#97.6
2201.08377v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#71.4$Action Recognition#Something-Something V2#Top-5 Accuracy#93.5$Action Recognition#EPIC-KITCHENS-100#Action@1#49.9$Action Recognition#EPIC-KITCHENS-100#Verb@1#69.5$Action Recognition#EPIC-KITCHENS-100#Noun@1#61.7$Action Classification#Kinetics-400#Acc@1#84.1$Action Classification#Kinetics-400#Acc@5#96.1$Action Classification#Kinetics-400#Acc@1#84.0$Action Classification#Kinetics-400#Acc@5#96.2$Scene Recognition#SUN-RGBD#Accuracy (%)#67.2$Semantic Segmentation#NYU Depth v2#Mean IoU#56.8%$Semantic Segmentation#NYU Depth v2#Mean IoU#55.1%$Image Classification#iNaturalist 2018#Top-1 Accuracy#84.1%$Image Classification#ImageNet#Top 1 Accuracy#86.0%$Image Classification#ImageNet#Top 5 Accuracy#97.7%$Image Classification#ImageNet#Top 1 Accuracy#85.3%$Image Classification#ImageNet#Top 5 Accuracy#97.5%
2112.01529v3.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#71.4$Action Recognition#Something-Something V2#Top-5 Accuracy#-$Action Recognition#Something-Something V2#Parameters#89$Action Recognition#Something-Something V2#GFLOPs#321x3$Action Recognition#Diving-48#Accuracy#86.7
2112.07175v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#70.9$Action Recognition#Something-Something V2#Top-5 Accuracy#92.5$Action Recognition#Something-Something V2#Top-1 Accuracy#69.8$Action Recognition#Something-Something V2#Top-5 Accuracy#91.9$Action Classification#Moments in Time#Top 1 Accuracy#46.1$Action Classification#Moments in Time#Top 5 Accuracy#75.4$Action Classification#Moments in Time#Top 1 Accuracy#45.0$Action Classification#Moments in Time#Top 5 Accuracy#73.9$Action Classification#Kinetics-600#Top-1 Accuracy#87.9$Action Classification#Kinetics-600#Top-5 Accuracy#97.8$Action Classification#Kinetics-600#Top-1 Accuracy#86.8$Action Classification#Kinetics-600#Top-5 Accuracy#97.3$Action Classification#Kinetics-400#Acc@1#87.2$Action Classification#Kinetics-400#Acc@5#97.5$Action Classification#Kinetics-400#Acc@1#86.3$Action Classification#Kinetics-400#Acc@5#97.2$Action Classification#Kinetics-700#Top-1 Accuracy#79.8$Action Classification#Kinetics-700#Top-5 Accuracy#94.9$Action Classification#Kinetics-700#Top-1 Accuracy#78.5$Action Classification#Kinetics-700#Top-5 Accuracy#94.2
2111.12527v3.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#70.1$Action Recognition#Something-Something V2#Top-5 Accuracy#92.8$Action Recognition#Something-Something V2#Parameters#68.5$Action Recognition#Something-Something V2#GFLOPs#197x3
2106.13230v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#69.6$Action Recognition#Something-Something V2#Top-5 Accuracy#92.7$Action Recognition#Something-Something V2#Parameters#89$Action Recognition#Something-Something V2#GFLOPs#321x3$Action Classification#Kinetics-600#Top-1 Accuracy#86.1$Action Classification#Kinetics-600#Top-5 Accuracy#97.3$Action Classification#Kinetics-600#Top-1 Accuracy#84.0$Action Classification#Kinetics-600#Top-5 Accuracy#96.5$Action Classification#Kinetics-400#Acc@1#84.9$Action Classification#Kinetics-400#Acc@5#96.7$Action Classification#Kinetics-400#Acc@1#83.1$Action Classification#Kinetics-400#Acc@5#95.9$Action Classification#Kinetics-400#Acc@1#82.7$Action Classification#Kinetics-400#Acc@5#95.5$Action Classification#Kinetics-400#Acc@1#80.6$Action Classification#Kinetics-400#Acc@5#94.6$Action Classification#Kinetics-400#Acc@5#94.5$Action Classification#Kinetics-400#Acc@1#78.8$Action Classification#Kinetics-400#Acc@5#93.6
2110.06915v3.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#69.5$Action Recognition#Something-Something V2#Top-5 Accuracy#91.5$Action Recognition#Something-Something V2#Parameters#N/A$Action Recognition#Something-Something V2#GFLOPs#N/A$Action Recognition#Something-Something V2#Top-1 Accuracy#67.9$Action Recognition#Something-Something V2#Top-5 Accuracy#90.5$Action Recognition#AVA v2.2#mAP#26.6$Action Recognition#Diving-48#Accuracy#88.0$Action Recognition#EPIC-KITCHENS-100#Action@1#45.7$Action Recognition#EPIC-KITCHENS-100#Verb@1#68.4$Action Recognition#EPIC-KITCHENS-100#Noun@1#58.7
2011.02543v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#69.02$Action Recognition#Something-Something V2#Top-5 Accuracy#92.70$Action Recognition#Something-Something V2#Top-1 Accuracy#66.83$Action Recognition#Something-Something V2#Top-5 Accuracy#91.30
2104.11227v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#68.7$Action Recognition#Something-Something V2#Top-5 Accuracy#91.5$Action Recognition#Something-Something V2#Parameters#53.2M$Action Recognition#Something-Something V2#GFLOPs#236x3$Action Recognition#Something-Something V2#Top-1 Accuracy#67.8$Action Recognition#Something-Something V2#Top-5 Accuracy#91.3$Action Recognition#Something-Something V2#Parameters#36.6$Action Recognition#Something-Something V2#GFLOPs#170x3$Action Recognition#Something-Something V2#Top-1 Accuracy#66.2$Action Recognition#Something-Something V2#Top-5 Accuracy#90.2$Action Recognition#AVA v2.2#mAP#28.7$Action Recognition#AVA v2.2#mAP#27.5$Action Recognition#AVA v2.2#mAP#27.3$Action Recognition#AVA v2.2#mAP#26.8$Action Recognition#AVA v2.2#mAP#26.1$Action Recognition#AVA v2.2#mAP#24.5$Action Classification#Charades#MAP#47.7$Action Classification#Charades#MAP#47.1$Action Classification#Charades#MAP#46.3$Action Classification#Charades#MAP#44.3$Action Classification#Charades#MAP#43.9$Action Classification#Charades#MAP#40$Action Classification#Kinetics-600#Top-1 Accuracy#83.8$Action Classification#Kinetics-600#Top-5 Accuracy#96.3$Action Classification#Kinetics-600#Top-1 Accuracy#83.4$Action Classification#Kinetics-600#Top-1 Accuracy#82.1$Action Classification#Kinetics-600#Top-5 Accuracy#95.7$Action Classification#Kinetics-400#Acc@1#81.2$Action Classification#Kinetics-400#Acc@5#95.1$Action Classification#Kinetics-400#Acc@1#80.2$Action Classification#Kinetics-400#Acc@5#94.4$Action Classification#Kinetics-400#Acc@1#78.4$Action Classification#Kinetics-400#Acc@5#93.5$Action Classification#Kinetics-400#Acc@1#76$Action Classification#Kinetics-400#Acc@5#92.1$Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Number of params#72.9M$Image Classification#ImageNet#Top 1 Accuracy#83.0%$Image Classification#ImageNet#Number of params#37.0M
2201.04288v4.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#68.5$Action Recognition#Something-Something V2#Top-5 Accuracy#90.4$Action Recognition#EPIC-KITCHENS-100#Action@1#50.5$Action Recognition#EPIC-KITCHENS-100#Verb@1#69.9$Action Recognition#EPIC-KITCHENS-100#Noun@1#63.9$Action Classification#Moments in Time#Top 1 Accuracy#47.2$Action Classification#Moments in Time#Top 5 Accuracy#75.7$Action Classification#Kinetics-600#Top-1 Accuracy#90.3$Action Classification#Kinetics-600#Top-5 Accuracy#98.5$Action Classification#Kinetics-400#Acc@1#89.9$Action Classification#Kinetics-400#Acc@5#98.3$Action Classification#Kinetics-700#Top-1 Accuracy#83.4$Action Classification#Kinetics-700#Top-5 Accuracy#96.2
2106.05392v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#68.1$Action Recognition#Something-Something V2#Top-5 Accuracy#91.2$Action Recognition#Something-Something V2#Parameters#N/A$Action Recognition#Something-Something V2#GFLOPs#1181x3$Action Recognition#Something-Something V2#Top-1 Accuracy#67.1$Action Recognition#Something-Something V2#Top-5 Accuracy#90.6$Action Recognition#Something-Something V2#GFLOPs#958.8x3$Action Recognition#Something-Something V2#Top-1 Accuracy#66.5$Action Recognition#Something-Something V2#Top-5 Accuracy#90.1$Action Recognition#EPIC-KITCHENS-100#Action@1#44.5$Action Recognition#EPIC-KITCHENS-100#Verb@1#67.0$Action Recognition#EPIC-KITCHENS-100#Noun@1#58.5$Action Recognition#EPIC-KITCHENS-100#Action@1#44.1$Action Recognition#EPIC-KITCHENS-100#Verb@1#67.1$Action Recognition#EPIC-KITCHENS-100#Noun@1#57.6$Action Recognition#EPIC-KITCHENS-100#Action@1#43.1$Action Recognition#EPIC-KITCHENS-100#Verb@1#66.7$Action Recognition#EPIC-KITCHENS-100#Noun@1#56.5$Action Classification#Kinetics-400#Acc@1#81.1$Action Classification#Kinetics-400#Acc@5#95.2
2106.11250v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#68.1$Action Recognition#UCF101#3-fold Accuracy#92.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#65.9$Action Recognition#Diving-48#Accuracy#85.5$Action Classification#Kinetics-400#Acc@1#77.4
2106.05968v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#67.2$Action Recognition#Something-Something V2#Top-5 Accuracy#90.8$Action Recognition#Something-Something V2#Parameters#N/A$Action Recognition#Something-Something V2#GFLOPs#850x1$Action Classification#Kinetics-600#Top-1 Accuracy#84.5$Action Classification#Kinetics-600#Top-5 Accuracy#96.3
2110.06178v4.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#67.2$Action Recognition#Something-Something V2#Top-5 Accuracy#89.8$Action Recognition#Something-Something V2#Top-1 Accuracy#67.1$Action Recognition#Something-Something V2#Top-5 Accuracy#90.4$Action Recognition#Something-Something V2#Top-1 Accuracy#65.6$Action Recognition#Something-Something V2#Top-5 Accuracy#89.2$Action Recognition#Something-Something V2#Top-1 Accuracy#64.0$Action Recognition#Something-Something V2#Top-5 Accuracy#88.0$Action Classification#Kinetics-400#Acc@1#79.1$Action Classification#Kinetics-400#Acc@5#93.7$Action Classification#Kinetics-400#Acc@1#78.2$Action Classification#Kinetics-400#Acc@5#93.5$Action Classification#Kinetics-400#Acc@1#77.4$Action Classification#Kinetics-400#Acc@5#93.1$Action Classification#Kinetics-400#Acc@1#76.7$Action Classification#Kinetics-400#Acc@5#92.6
2103.15691v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#65.4$Action Recognition#Something-Something V2#Top-5 Accuracy#89.8$Action Recognition#EPIC-KITCHENS-100#Action@1#44.0$Action Recognition#EPIC-KITCHENS-100#Verb@1#66.4$Action Recognition#EPIC-KITCHENS-100#Noun@1#56.8$Action Classification#Moments in Time#Top 5 Accuracy#64.9$Action Classification#Kinetics-600#Top-1 Accuracy#85.8$Action Classification#Kinetics-600#Top-5 Accuracy#96.5$Action Classification#Kinetics-600#Top-1 Accuracy#84.3$Action Classification#Kinetics-600#Top-5 Accuracy#95.6$Action Classification#Kinetics-600#Top-1 Accuracy#83.0$Action Classification#Kinetics-600#Top-5 Accuracy#95.7$Action Classification#Kinetics-400#Acc@5#95.8$Action Classification#Kinetics-400#Acc@5#94.7
1912.00869v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#65.2$Action Classification#Kinetics-400#Acc@1#73.5$Action Classification#Kinetics-400#Acc@5#91.2
2103.11511v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#63.5$Action Recognition#Something-Something V2#Top-5 Accuracy#89.0$Action Recognition#Something-Something V2#Parameters#4.8M$Action Recognition#Something-Something V2#GFLOPs#10.3x1$Action Recognition#Something-Something V2#Top-1 Accuracy#62.7$Action Recognition#Something-Something V2#Parameters#4.6M$Action Recognition#Something-Something V2#GFLOPs#6.0x1$Action Recognition#Something-Something V2#Top-1 Accuracy#61.3$Action Recognition#Something-Something V2#Top-5 Accuracy#88.2$Action Recognition#Something-Something V2#Parameters#3.1M$Action Recognition#Something-Something V2#GFLOPs#2.7x1$Action Recognition#Something-Something V2#Parameters#5.3M$Action Recognition#Something-Something V2#GFLOPs#23.7x1$Action Recognition#EPIC-KITCHENS-100#Action@1#47.7$Action Recognition#EPIC-KITCHENS-100#Verb@1#72.2$Action Recognition#EPIC-KITCHENS-100#Noun@1#57.3$Action Recognition#EPIC-KITCHENS-100#GFLOPs#117x1$Action Recognition#EPIC-KITCHENS-100#Action@1#44.5$Action Recognition#EPIC-KITCHENS-100#Verb@1#69.1$Action Recognition#EPIC-KITCHENS-100#Noun@1#55.1$Action Recognition#EPIC-KITCHENS-100#GFLOPs#74.9x1$Action Recognition#EPIC-KITCHENS-100#Action@1#44.4$Action Recognition#EPIC-KITCHENS-100#Verb@1#68.8$Action Recognition#EPIC-KITCHENS-100#Noun@1#56.2$Action Recognition#EPIC-KITCHENS-100#GFLOPs#42.2x1$Action Recognition#EPIC-KITCHENS-100#Action@1#41.2$Action Recognition#EPIC-KITCHENS-100#Verb@1#67.1$Action Recognition#EPIC-KITCHENS-100#Noun@1#52.3$Action Recognition#EPIC-KITCHENS-100#GFLOPs#7.59x1$Action Recognition#EPIC-KITCHENS-100#Action@1#36.8$Action Recognition#EPIC-KITCHENS-100#Verb@1#64.8$Action Recognition#EPIC-KITCHENS-100#Noun@1#47.4$Action Recognition#EPIC-KITCHENS-100#GFLOPs#1.74x1$Action Classification#Moments in Time#Top 1 Accuracy#40.2$Action Classification#Moments in Time#Top 1 Accuracy#39.1$Action Classification#Moments in Time#Top 1 Accuracy#37.9$Action Classification#Moments in Time#Top 1 Accuracy#35.6$Action Classification#Moments in Time#Top 1 Accuracy#34.3$Action Classification#Moments in Time#Top 1 Accuracy#32.0$Action Classification#Moments in Time#Top 1 Accuracy#27.5$Action Classification#Charades#MAP#63.2$Action Classification#Charades#MAP#48.5$Action Classification#Charades#MAP#32.5$Action Classification#Kinetics-600#Top-1 Accuracy#84.3$Action Classification#Kinetics-600#Top-5 Accuracy#96.4$Action Classification#Kinetics-600#GFLOPs#281x1$Action Classification#Kinetics-600#Top-1 Accuracy#83.5$Action Classification#Kinetics-600#Top-5 Accuracy#96.5$Action Classification#Kinetics-600#GFLOPs#386x1$Action Classification#Kinetics-600#Top-1 Accuracy#82.7$Action Classification#Kinetics-600#Top-5 Accuracy#95.7$Action Classification#Kinetics-600#Top-1 Accuracy#81.2$Action Classification#Kinetics-600#Top-5 Accuracy#94.9$Action Classification#Kinetics-600#GFLOPs#105x1$Action Classification#Kinetics-600#Top-1 Accuracy#80.8$Action Classification#Kinetics-600#Top-5 Accuracy#80.8$Action Classification#Kinetics-600#GFLOPs#56.9x1$Action Classification#Kinetics-600#Top-1 Accuracy#77.5$Action Classification#Kinetics-600#Top-5 Accuracy#93.4$Action Classification#Kinetics-600#GFLOPs#10.3x1$Action Classification#Kinetics-600#Top-1 Accuracy#76.0$Action Classification#Kinetics-600#Top-5 Accuracy#92.6$Action Classification#Kinetics-600#GFLOPs#6.0x1$Action Classification#Kinetics-600#Top-1 Accuracy#71.5$Action Classification#Kinetics-600#Top-5 Accuracy#90.4$Action Classification#Kinetics-600#GFLOPs#2.7x1$Action Classification#Kinetics-400#Acc@1#81.5$Action Classification#Kinetics-400#FLOPs (G) x views#386x1$Action Classification#Kinetics-400#Acc@1#80.9$Action Classification#Kinetics-400#Acc@5#94.9$Action Classification#Kinetics-400#FLOPs (G) x views#281x1$Action Classification#Kinetics-400#Acc@1#80.5$Action Classification#Kinetics-400#Acc@5#94.5$Action Classification#Kinetics-400#FLOPs (G) x views#105x1$Action Classification#Kinetics-400#Acc@1#78.2$Action Classification#Kinetics-400#Acc@5#93.8$Action Classification#Kinetics-400#FLOPs (G) x views#56.9x1$Action Classification#Kinetics-400#Acc@1#75.0$Action Classification#Kinetics-400#Acc@5#92.3$Action Classification#Kinetics-400#FLOPs (G) x views#10.3x1$Action Classification#Kinetics-400#Acc@1#72.7$Action Classification#Kinetics-400#Acc@5#91.2$Action Classification#Kinetics-400#FLOPs (G) x views#6.0x1$Action Classification#Kinetics-400#Acc@1#65.8$Action Classification#Kinetics-400#Acc@5#87.4$Action Classification#Kinetics-400#FLOPs (G) x views#2.7x1$Action Classification#Kinetics-700#Top-1 Accuracy#72.3$Action Classification#Kinetics-700#Top-1 Accuracy#71.7$Action Classification#Kinetics-700#Top-1 Accuracy#70.7$Action Classification#Kinetics-700#Top-1 Accuracy#68.0$Action Classification#Kinetics-700#Top-1 Accuracy#66.7$Action Classification#Kinetics-700#Top-1 Accuracy#63.5$Action Classification#Kinetics-700#Top-1 Accuracy#58.5
2209.07526v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#62.5$Action Recognition#Something-Something V2#Top-5 Accuracy#86.2$Action Classification#Kinetics-400#Acc@1#79.1$Action Classification#Kinetics-400#Acc@5#94.5$Video Retrieval#MSR-VTT#text-to-video R@1#47.8$Video Retrieval#MSR-VTT#text-to-video R@5#74.2$Video Retrieval#MSR-VTT#text-to-video R@10#83.8$Video Retrieval#DiDeMo#text-to-video R@1#52.4$Video Retrieval#DiDeMo#text-to-video R@5#79.5$Video Retrieval#DiDeMo#text-to-video R@10#85.4$Visual Question Answering#MSVD-QA#Accuracy#0.510$Visual Question Answering#MSRVTT-QA#Accuracy#0.441$Image Captioning#nocaps-val-out-domain#CIDEr#106.3$Image Captioning#nocaps-val-out-domain#SPICE#14.2$Image Captioning#nocaps-val-out-domain#Pretrain (#images)#14M$Image Captioning#nocaps-val-overall#CIDEr#107.5$Image Captioning#nocaps-val-overall#SPICE#14.7$Image Captioning#nocaps-val-overall#Pretrain (#images)#14M$Image Captioning#nocaps-val-in-domain#CIDEr#104.6$Image Captioning#nocaps-val-in-domain#SPICE#15$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#14M$Image Captioning#nocaps-val-near-domain#CIDEr#108.3$Image Captioning#nocaps-val-near-domain#SPICE#14.9$Image Captioning#nocaps-val-near-domain#Pre-train (#images)#14M$Video Captioning#YouCook2#BLEU-3#12.87$Video Captioning#YouCook2#BLEU-4#8.72$Video Captioning#YouCook2#METEOR#14.83$Video Captioning#YouCook2#ROUGE-L#36.09$Video Captioning#YouCook2#CIDEr#1.16$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#82.1$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#98.1$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#95.9$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#64.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#91.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#86.1$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#97.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#100$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#99.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#87.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#99.1$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#97.8
2102.05095v4.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#62.5$Action Recognition#Something-Something V2#Top-1 Accuracy#62.3$Action Recognition#Something-Something V2#Top-1 Accuracy#59.5$Action Recognition#Diving-48#Accuracy#81$Action Recognition#Diving-48#Accuracy#78$Action Recognition#Diving-48#Accuracy#75$Action Classification#Kinetics-400#Acc@1#80.7$Action Classification#Kinetics-400#Acc@5#94.7$Action Classification#Kinetics-400#Acc@1#79.7$Action Classification#Kinetics-400#Acc@5#94.4$Action Classification#Kinetics-400#Acc@1#78$Action Classification#Kinetics-400#Acc@5#93.7$Anomaly Detection#UBnormal#AUC#68.5%$Anomaly Detection#UBnormal#RBDC#0.04$Anomaly Detection#UBnormal#TBDC#0.05$Video Question Answering#Howto100M-QA#Accuracy#62.1
2004.03548v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#62.0
1912.00998v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#61.7$Video Classification#Charades#mAP#38.2$Video Classification#Kinetics#Top-1#77.6
1908.10136v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#61.2$Action Recognition#Something-Something V2#Top-5 Accuracy#89.3$Action Recognition#UCF101#3-fold Accuracy#97.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#81.9
2104.11746v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#60.2$Action Recognition#UCF101#3-fold Accuracy#96.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#74.4$Action Classification#Charades#MAP#47.3$Action Classification#Charades#MAP#43.5$Action Classification#Kinetics-400#Acc@1#80.5$Action Classification#Kinetics-400#Acc@5#94.6$Action Classification#Kinetics-400#Acc@1#79.7$Action Classification#Kinetics-400#Acc@5#94.2$Action Classification#Kinetics-400#Acc@1#79.4$Action Classification#Kinetics-400#Acc@5#94$Action Classification#Kinetics-700#Top-1 Accuracy#70.8$Action Classification#Kinetics-700#Top-5 Accuracy#89.4$Action Classification#Kinetics-700#Top-1 Accuracy#70.2$Action Classification#Kinetics-700#Top-5 Accuracy#89$Action Classification#Kinetics-700#Top-1 Accuracy#69.5$Action Classification#Kinetics-700#Top-5 Accuracy#88.3$Action Classification#Kinetics-700#Top-1 Accuracy#67.3$Action Classification#Kinetics-700#Top-5 Accuracy#87.7
1906.11415v1.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#52.3$Few Shot Action Recognition#Something-Something-100#1:1 Accuracy#52.3$Few Shot Action Recognition#Kinetics-100#Accuracy#85.8
1706.04261v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#51.33$Action Recognition#Something-Something V2#Top-5 Accuracy#80.46
1904.03249v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#49.9$Action Recognition#Something-Something V2#Top-5 Accuracy#79.1$Action Recognition#UCF101#3-fold Accuracy#95.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#72.0
1909.05165v2.pdf	Action Recognition#Something-Something V2#Top-1 Accuracy#47.73
1611.09078v1.pdf	Action Recognition#Volleyball#Accuracy#82.6$Action Recognition#Volleyball#Accuracy#81.8
1811.11524v2.pdf	Action Recognition#THUMOS’14#mAP@0.3#53.9$Action Recognition#THUMOS’14#mAP@0.4#46.8$Action Recognition#THUMOS’14#mAP@0.5#37.4$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#66.43$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#74.54
1906.02182v1.pdf	Action Recognition#THUMOS’14#mAP@0.1#56.9$Action Recognition#THUMOS’14#mAP@0.2#54.7$Action Recognition#THUMOS’14#mAP@0.3#51.2$Action Recognition#THUMOS’14#mAP@0.4#43.0$Action Recognition#THUMOS’14#mAP@0.5#36.1$Action Recognition#THUMOS’14#mAP@0.1#57.4$Action Recognition#THUMOS’14#mAP@0.2#54.9$Action Recognition#THUMOS’14#mAP@0.3#51.1$Action Recognition#THUMOS’14#mAP@0.4#43.1$Action Recognition#THUMOS’14#mAP@0.5#35.8
1704.06228v2.pdf	Action Recognition#THUMOS’14#mAP@0.1#66.0$Action Recognition#THUMOS’14#mAP@0.2#59.4$Action Recognition#THUMOS’14#mAP@0.3#51.9$Action Recognition#THUMOS’14#mAP@0.4#41.0$Action Recognition#THUMOS’14#mAP@0.5#29.8
1708.02349v1.pdf	Action Recognition#THUMOS’14#mAP@0.4#33.3$Action Recognition#THUMOS’14#mAP@0.5#25.6
2201.08383v1.pdf	Action Recognition#AVA v2.2#mAP#35.4$Action Recognition#EPIC-KITCHENS-100#Action@1#48.4$Action Recognition#EPIC-KITCHENS-100#Verb@1#71.4$Action Recognition#EPIC-KITCHENS-100#Noun@1#60.3$Action Anticipation#EPIC-KITCHENS-100#Recall@5#17.7
2106.11310v1.pdf	Action Recognition#AVA v2.2#mAP#31.0
1901.06882v1.pdf	Action Recognition#ICVL-4#Accuracy#91.86%$Action Recognition#IRD#Accuracy#80.11%
1901.03460v3.pdf	Action Recognition#UCF-101#3-fold Accuracy#90.9$Action Recognition#UCF101#3-fold Accuracy#96.5$Action Recognition#UCF101#3-fold Accuracy#92.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#77.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#71.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#62.8
2012.10671v1.pdf	Action Recognition#UCF101#3-fold Accuracy#98.64$Action Recognition#HMDB-51#Average accuracy of 3 splits#84.36$Action Recognition#ActivityNet#mAP#84.4
2003.13042v2.pdf	Action Recognition#UCF101#3-fold Accuracy#98.6$Action Recognition#HMDB-51#Average accuracy of 3 splits#83.8$Action Classification#Kinetics-400#Acc@1#83.6$Action Classification#Kinetics-400#Acc@1#80.5$Action Classification#Kinetics-400#Acc@5#94.4$Action Classification#Kinetics-400#Acc@1#80.4
2009.13087v2.pdf	Action Recognition#UCF101#3-fold Accuracy#98.6$Action Recognition#HMDB-51#Average accuracy of 3 splits#83.2$Action Classification#Kinetics-600#Top-1 Accuracy#82.0$Action Classification#Kinetics-600#Top-5 Accuracy#95.7
1906.05571v1.pdf	Action Recognition#UCF101#3-fold Accuracy#98.2$Action Recognition#UCF101#3-fold Accuracy#97$Action Recognition#UCF101#3-fold Accuracy#96.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#80.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#78.9$Action Recognition#HMDB-51#Average accuracy of 3 splits#75.7$Action Classification#Kinetics-600#Top-1 Accuracy#83.1$Action Classification#Kinetics-600#Top-5 Accuracy#96.2$Action Classification#Kinetics-600#Top-1 Accuracy#81.5$Action Classification#Kinetics-600#Top-5 Accuracy#95.6$Action Classification#Kinetics-600#Top-1 Accuracy#75$Action Classification#Kinetics-600#Top-5 Accuracy#92.4$Action Classification#Kinetics-400#Acc@1#81.2$Action Classification#Kinetics-400#Acc@5#95.2$Action Classification#Kinetics-400#Acc@1#79.4$Action Classification#Kinetics-400#Acc@5#94.4$Action Classification#Kinetics-400#Acc@1#72.3$Action Classification#Kinetics-400#Acc@5#90.9
1904.11451v3.pdf	Action Recognition#UCF101#3-fold Accuracy#97.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#76.5$Action Classification#Kinetics-400#Acc@1#77.6
1704.00389v4.pdf	Action Recognition#UCF101#3-fold Accuracy#97.1$Action Recognition#HMDB-51#Average accuracy of 3 splits#78.7
2103.13915v2.pdf	Action Recognition#UCF101#3-fold Accuracy#97$Action Classification#Kinetics-400#Acc@1#80.5$Action Classification#Kinetics-400#FLOPs (G) x views#1040x1$Action Classification#Kinetics-400#Acc@1#79.3$Action Classification#Kinetics-400#FLOPs (G) x views#270x1
1906.04226v2.pdf	Action Recognition#UCF101#3-fold Accuracy#96.9$Action Recognition#HMDB-51#Average accuracy of 3 splits#75.7$Action Classification#Kinetics-400#Acc@1#75.1$Action Classification#Kinetics-400#Acc@1#71.7
1908.00497v1.pdf	Action Recognition#UCF101#3-fold Accuracy#96.5$Action Classification#Kinetics-400#Acc@1#75.98
1810.11579v1.pdf	Action Recognition#UCF101#3-fold Accuracy#96.4$Action Classification#Kinetics-400#Acc@1#74.6$Action Classification#Kinetics-400#Acc@5#91.5
1807.11195v3.pdf	Action Recognition#UCF101#3-fold Accuracy#96.0$Action Classification#Kinetics-400#Acc@1#72.8$Action Classification#Kinetics-400#Acc@5#90.4
1711.11152v2.pdf	Action Recognition#UCF101#3-fold Accuracy#96$Action Recognition#HMDB-51#Average accuracy of 3 splits#74.2
1804.00413v1.pdf	Action Recognition#UCF101#3-fold Accuracy#95.4$Action Recognition#HMDB-51#Average accuracy of 3 splits#72.6
2002.04685v2.pdf	Action Recognition#UCF101#3-fold Accuracy#95.2$Action Recognition#HMDB-51#Average accuracy of 3 splits#71.5
1611.02155v1.pdf	Action Recognition#UCF101#3-fold Accuracy#94.6$Action Recognition#HMDB-51#Average accuracy of 3 splits#70.3
1711.09577v2.pdf	Action Recognition#UCF101#3-fold Accuracy#94.5
1809.03669v1.pdf	Action Recognition#UCF101#3-fold Accuracy#94.3
1711.09125v2.pdf	Action Recognition#UCF101#3-fold Accuracy#94.3$Action Recognition#HMDB-51#Average accuracy of 3 splits#70.9$Action Classification#Kinetics-400#Acc@1#72.4$Action Classification#Kinetics-400#Acc@5#90.4
1608.00859v1.pdf	Action Recognition#UCF101#3-fold Accuracy#94.2$Action Recognition#HMDB-51#Average accuracy of 3 splits#69.4$Action Classification#Kinetics-400#Acc@1#73.9$Action Classification#Kinetics-400#Acc@5#91.1$Multimodal Activity Recognition#EV-Action#Accuracy#73.6
1703.10667v1.pdf	Action Recognition#UCF101#3-fold Accuracy#94.1$Action Recognition#HMDB-51#Average accuracy of 3 splits#69
1604.06573v2.pdf	Action Recognition#UCF101#3-fold Accuracy#92.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#65.4
1904.00696v3.pdf	Action Recognition#UCF101#3-fold Accuracy#92$Action Detection#UCF101-24#mAP#22.02
1604.04494v2.pdf	Action Recognition#UCF101#3-fold Accuracy#91.7$Action Recognition#HMDB-51#Average accuracy of 3 splits#64.8
1505.04868v1.pdf	Action Recognition#UCF101#3-fold Accuracy#91.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#65.9$Activity Recognition In Videos#DogCentric#Accuracy#76.6
1507.02159v1.pdf	Action Recognition#UCF101#3-fold Accuracy#91.4
2109.02137v2.pdf	Action Recognition#UCF101#3-fold Accuracy#91.2
1604.07669v1.pdf	Action Recognition#UCF101#3-fold Accuracy#86.4
1901.09244v2.pdf	Action Recognition#UCF101#3-fold Accuracy#85.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#54.8
1708.05038v1.pdf	Action Recognition#UCF101#3-fold Accuracy#85.8$Action Recognition#HMDB-51#Average accuracy of 3 splits#54.9$Action Classification#Kinetics-400#Acc@1#73.9
1612.03052v3.pdf	Action Recognition#UCF101#3-fold Accuracy#83.9$Action Recognition#HMDB-51#Average accuracy of 3 splits#56.4
1912.04430v3.pdf	Action Recognition#UCF101#3-fold Accuracy#79.83$Scene Recognition#YUP++#Accuracy (%)#84.44
2103.05905v2.pdf	Action Recognition#UCF101#3-fold Accuracy#78.7$Action Recognition#UCF101#3-fold Accuracy#74.1$Action Recognition#HMDB-51#Average accuracy of 3 splits#49.2$Action Recognition#HMDB-51#Average accuracy of 3 splits#43.6
1803.08460v1.pdf	Action Recognition#UCF101#3-fold Accuracy#42.5$Action Recognition#HMDB-51#Average accuracy of 3 splits#51.8$Action Recognition#ActivityNet#mAP#53.8$Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#24.4$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#17.5
2001.04627v2.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#87.56$Action Classification#Charades#MAP#62.29$Action Classification#Charades#MAP#50.16$Scene Recognition#YUP++#Accuracy (%)#94.4$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#27.3$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S1)#35.8
2110.05216v1.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#87.21$Action Recognition#HMDB-51#Average accuracy of 3 splits#85.70$Scene Recognition#YUP++#Accuracy (%)#93.1$Scene Recognition#YUP++#Accuracy (%)#92.5
1906.05910v2.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#82.48$Action Classification#Charades#MAP#43.1$Scene Recognition#YUP++#Accuracy (%)#92.6
1810.01455v3.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#81.1$Action Classification#Kinetics-400#Acc@1#77.9
1807.09380v3.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#74.3
1812.00722v2.pdf	Action Recognition#HMDB-51#Average accuracy of 3 splits#62.7
2204.14198v1.pdf	Action Recognition#RareAct#mWAP#60.8$Zero-Shot Learning#iVQA#Accuracy#0.407$Temporal/Casual QA#NExT-QA#WUPS#33.5$Visual Question Answering#MSRVTT-QA#Accuracy#0.310$Visual Question Answering#MSRVTT-QA#Accuracy#0.174$Meme Classification#Hateful Memes#ROC-AUC#0.700
2103.00020v1.pdf	Action Recognition#RareAct#mWAP#40.7$Few-Shot Image Classification#ImageNet - 0-Shot#Accuracy#63.2%$Few-Shot Image Classification#ImageNet - 0-Shot#Accuracy#59.6%$Image Classification#OmniBenchmark#Average Top-1 Accuracy#42.1$Image Classification#ObjectNet#Top-1 Accuracy#72.3$Semi-Supervised Image Classification#ImageNet - 0.2% labeled data#ImageNet Top-1 Accuracy#40%$Meme Classification#Hateful Memes#ROC-AUC#0.661$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Private)#72.3$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#SUN#Accuracy#58.5$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#70.1$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#59.6$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Public)#31.3$Zero-Shot Transfer Image Classification#ImageNet#Accuracy#76.2$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#88.9$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#77.2$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#aYahoo#Accuracy#98.4$Object Categorization#GRIT#Categorization (ablation)#48.1$Prompt Engineering#ImageNet-R#Top-1 accuracy %#73.96$Prompt Engineering#UCF101#Harmonic mean#73.85$Prompt Engineering#ImageNet-A#Top-1 accuracy %#47.77$Prompt Engineering#ImageNet#Harmonic mean#70.22$Prompt Engineering#EuroSAT#Harmonic mean#60.03$Prompt Engineering#ImageNet-S#Top-1 accuracy %#46.15$Prompt Engineering#ImageNet V2#Top-1 accuracy %#60.83$Prompt Engineering#FGVC-Aircraft#Harmonic mean#31.09$Prompt Engineering#SUN397#Harmonic mean#72.23
1912.06430v4.pdf	Action Recognition#RareAct#mWAP#30.5$Action Segmentation#COIN#Frame accuracy#61.0$Action Segmentation#COIN#Frame accuracy#53.9
2206.01670v2.pdf	Action Recognition#Charades-Ego#mAP#32.1
1904.04346v2.pdf	Action Recognition#MTL-AQA#Position Accuracy#96.32 %$Action Recognition#MTL-AQA#Armstand Accuracy#99.72 %$Action Recognition#MTL-AQA#Rotation Type Accuracy#97.45 %$Action Recognition#MTL-AQA#No. of Somersaults Accuracy#96.88 %$Action Recognition#MTL-AQA#No. of Twists Accuracy#93.20 %$Action Quality Assessment#MTL-AQA#Spearman Correlation#90.44$Action Quality Assessment#MTL-AQA#Spearman Correlation#89.60$Action Quality Assessment#MTL-AQA#Spearman Correlation#86.12$Action Quality Assessment#MTL-AQA#Spearman Correlation#84.72
2010.05654v1.pdf	Action Recognition#MECCANO#Top-1 Accuracy#42.85$Human-Object Interaction Detection#MECCANO#mAP@0.5 role#25.93$Object Recognition#MECCANO#mAP#30.39
2207.10388v1.pdf	Action Recognition#ActivityNet#mAP#94.3
2207.10379v1.pdf	Action Recognition#ActivityNet#mAP#93.7
2105.12085v3.pdf	Action Recognition#ActivityNet#mAP#90.5
1907.13369v2.pdf	Action Recognition#ActivityNet#mAP#90.05
1912.04487v3.pdf	Action Recognition#ActivityNet#mAP#89.9
2006.15560v1.pdf	Action Recognition#ActivityNet#mAP#87.9
2012.14950v2.pdf	Action Recognition#ActivityNet#mAP#84.0
1810.11189v1.pdf	Action Recognition#ActivityNet#mAP#83.4
1512.07155v1.pdf	Action Recognition#ActivityNet#mAP#53.8$Action Recognition#ActivityNet#mAP#52.3
1904.04289v2.pdf	Action Recognition#miniSports#Accuracy#74.9$Action Recognition#miniSports#Accuracy#69.9
2206.09852v1.pdf	Action Recognition#EPIC-KITCHENS-100#Action@1#53.6$Action Recognition#EPIC-KITCHENS-100#Verb@1#72.0$Action Recognition#EPIC-KITCHENS-100#Noun@1#66.3
2106.03152v2.pdf	Action Recognition#EPIC-KITCHENS-100#Action@1#45.26$Action Recognition#EPIC-KITCHENS-100#Verb@1#66$Action Recognition#EPIC-KITCHENS-100#Noun@1#53.35$Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#12.6$Action Anticipation#EPIC-KITCHENS-100#Recall@5#14.73
2203.08897v1.pdf	Action Recognition#EPIC-KITCHENS-100#Action@1#44.48$Action Recognition#EPIC-KITCHENS-100#Verb@1#69.06$Action Recognition#EPIC-KITCHENS-100#Noun@1#53.18
2107.00135v2.pdf	Action Recognition#EPIC-KITCHENS-100#Action@1#43.4$Action Recognition#EPIC-KITCHENS-100#Verb@1#64.8$Action Recognition#EPIC-KITCHENS-100#Noun@1#58$Action Classification#Moments in Time#Top 1 Accuracy#37.3$Action Classification#Moments in Time#Top 5 Accuracy#61.2$Action Classification#Kinetics-Sounds#Top 1 Accuracy#85$Action Classification#Kinetics-Sounds#Top 5 Accuracy#96.8$Action Classification#Kinetics-400#Acc@1#80.8$Action Classification#Kinetics-400#Acc@5#94.6$Audio Classification#VGGSound#Top 1 Accuracy#64.1$Audio Classification#VGGSound#Top 1 Accuracy#52.3$Audio Classification#VGGSound#Top 5 Accuracy#78.1$Audio Classification#VGGSound#Top 1 Accuracy#51.2$Audio Classification#VGGSound#Top 5 Accuracy#72.6$Audio Classification#VGGSound#Top 5 Accuracy#85.6$Audio Classification#AudioSet#Test mAP#0.521
2006.13256v4.pdf	Action Recognition#EPIC-KITCHENS-100#Action@1#37.39$Action Recognition#EPIC-KITCHENS-100#Action@1#36.81$Action Recognition#EPIC-KITCHENS-100#Action@1#35.55$Action Recognition#EPIC-KITCHENS-100#Action@1#35.28$Action Recognition#EPIC-KITCHENS-100#Action@1#33.57$Action Anticipation#EPIC-KITCHENS-100#Recall@5#13.94
2001.01215v2.pdf	3D Action Recognition#100 sleep nights of 8 caregivers#10%#4
2102.04530v1.pdf	3D Semantic Segmentation#nuScenes#mIoU#78.3%$3D Semantic Segmentation#SemanticKITTI#mIoU#70.8%
1907.03739v2.pdf	3D Semantic Segmentation#S3DIS#mAcc#87.12$3D Semantic Segmentation#S3DIS#mIoU#58.98$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.2$3D Object Detection#KITTI Cars Hard val#AP#63.81$3D Object Detection#KITTI Pedestrian Moderate val#AP#64.71$3D Object Detection#KITTI Cyclist Easy val#AP#81.4$3D Object Detection#KITTI Cyclist Moderate val#AP#59.97$3D Object Detection#KITTI Cars Easy val#AP#84.02$3D Object Detection#KITTI Cars Moderate val#AP#71.54$3D Object Detection#KITTI Pedestrian Easy val#AP#73.2$3D Object Detection#KITTI Cyclist Hard val#AP#56.24$3D Object Detection#KITTI Pedestrian Hard val#AP#56.78
2203.08537v2.pdf	3D Semantic Segmentation#ScribbleKITTI#mIoU#61.3
2204.07548v2.pdf	3D Semantic Segmentation#KITTI-360#miou Class#58.3$3D Semantic Segmentation#KITTI-360#mIoU Category#73.66$3D Semantic Segmentation#KITTI-360#miou Class#53.92$3D Semantic Segmentation#KITTI-360#mIoU Category#74.08$Semantic Segmentation#S3DIS#Mean IoU#74.7$Semantic Segmentation#S3DIS#mAcc#83.8$Semantic Segmentation#S3DIS#oAcc#90.1
2109.09074v1.pdf	3D Semantic Segmentation#SensatUrban#mIoU#61.7
1904.08889v2.pdf	3D Semantic Segmentation#SensatUrban#mIoU#57.58$3D Semantic Segmentation#SemanticKITTI#mIoU#58.8%$3D Semantic Segmentation#STPLS3D#mIOU#53.73$Semantic Segmentation#S3DIS Area5#mIoU#67.1$Semantic Segmentation#S3DIS Area5#mAcc#72.8$Semantic Segmentation#Semantic3D#mIoU#74.6%$Semantic Segmentation#S3DIS#Mean IoU#70.6$Semantic Segmentation#S3DIS#mAcc#79.1$Semantic Segmentation#ScanNet#3DIoU#0.680$Scene Segmentation#ScanNet#3DIoU#68.6$3D Part Segmentation#ShapeNet-Part#Class Average IoU#85.1$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.4$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.9$LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.759
1711.10275v1.pdf	3D Semantic Segmentation#SensatUrban#mIoU#42.66$Semantic Segmentation#ScanNet#3DIoU#0.725
1711.09869v2.pdf	3D Semantic Segmentation#SensatUrban#mIoU#37.29$3D Semantic Segmentation#SemanticKITTI#mIoU#17.4%$Semantic Segmentation#S3DIS Area5#mIoU#58.04$Semantic Segmentation#S3DIS Area5#oAcc#86.38$Semantic Segmentation#S3DIS Area5#mAcc#66.5$Semantic Segmentation#Semantic3D#mIoU#76.2%$Semantic Segmentation#Semantic3D#oAcc#92.9%$Semantic Segmentation#Semantic3D#mIoU#73.2%$Semantic Segmentation#S3DIS#Mean IoU#62.1$Semantic Segmentation#S3DIS#mAcc#73$Semantic Segmentation#S3DIS#oAcc#85.5
1807.02443v1.pdf	3D Semantic Segmentation#SensatUrban#mIoU#33.30$3D Semantic Segmentation#SemanticKITTI#mIoU#35.9%$Semantic Segmentation#S3DIS Area5#mAcc#62.2$Semantic Segmentation#ScanNet#3DIoU#0.438
2207.04397v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#72.9%$LIDAR Semantic Segmentation#nuScenes#mIOU#0.81
2011.10033v1.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#68.9%$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#50.9$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#65.9$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#66.6$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#71.2$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#39.2$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#48.0$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#52.1$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#53.8
2007.16100v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#66.4%
2207.02605v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#65.4%$LIDAR Semantic Segmentation#nuScenes#mIOU#0.76
2007.12668v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#63.1%
2008.10544v1.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#63.1%
2202.13377v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#61.0%
2103.07074v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#59.9%$Semantic Segmentation#S3DIS Area5#mIoU#65.4$Semantic Segmentation#S3DIS Area5#oAcc#88.9$Semantic Segmentation#S3DIS Area5#mAcc#73.1$Semantic Segmentation#Semantic3D#mIoU#75.4%$Semantic Segmentation#Semantic3D#oAcc#94.9%$Semantic Segmentation#S3DIS#Mean IoU#72.2$Semantic Segmentation#S3DIS#mAcc#83.1$Semantic Segmentation#S3DIS#oAcc#88.9
2003.03653v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#59.5%
2003.14032v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#57.2%
2103.00738v1.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#57.1%
2004.01803v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#55.9%
2002.10893v5.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#55.8%$Real-Time 3D Semantic Segmentation#SemanticKITTI#Speed  (FPS)#98$Real-Time 3D Semantic Segmentation#SemanticKITTI#mIoU#46.9$Real-Time 3D Semantic Segmentation#SemanticKITTI#Parameters (M)#0.44$Real-Time 3D Semantic Segmentation#SemanticKITTI#Speed  (FPS)#28$Real-Time 3D Semantic Segmentation#SemanticKITTI#mIoU#55.8$Real-Time 3D Semantic Segmentation#SemanticKITTI#Parameters (M)#3.97
2011.01974v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#55.5%$Real-Time 3D Semantic Segmentation#SemanticKITTI#Speed  (FPS)#20.6$LIDAR Semantic Segmentation#SemanticKITTI#mIOU#55.5%
2008.09162v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#55.2%$Real-Time 3D Semantic Segmentation#SemanticKITTI#Speed  (FPS)#47$Real-Time 3D Semantic Segmentation#SemanticKITTI#mIoU#55.2$Real-Time 3D Semantic Segmentation#SemanticKITTI#Parameters (M)#1.0
1911.11236v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#53.9%$Semantic Segmentation#Semantic3D#mIoU#77.4%$Semantic Segmentation#Semantic3D#oAcc#94.8$Semantic Segmentation#S3DIS#Mean IoU#70.0$Semantic Segmentation#S3DIS#mAcc#82.0$Semantic Segmentation#S3DIS#oAcc#88.0$Semantic Segmentation#S3DIS#Mean IoU#68.5
2012.09439v2.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#53.8%$3D Semantic Segmentation#PartNet#mIOU#58.2$Semantic Segmentation#Semantic3D#mIoU#78.2%$Semantic Segmentation#Semantic3D#oAcc#93.6$Semantic Segmentation#S3DIS#Mean IoU#70.8$Semantic Segmentation#S3DIS#mAcc#82.9$Semantic Segmentation#S3DIS#oAcc#88.2$Semantic Segmentation#ScanNet#3DIoU#0.690$3D Part Segmentation#ShapeNet-Part#Class Average IoU#87.7$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.6$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.1$LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.819
1912.05905v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#52.9%
1904.01416v3.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#49.9%
1809.08495v1.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#39.7%
1710.07368v1.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#29.5%
1802.08275v4.pdf	3D Semantic Segmentation#SemanticKITTI#mIoU#18.4%$Semantic Segmentation#ScanNet#3DIoU#0.393$3D Part Segmentation#ShapeNet-Part#Class Average IoU#82.0$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#84.6
2008.01068v2.pdf	3D Semantic Segmentation#PartNet#mIOU#60.8$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.3
2007.01294v1.pdf	3D Semantic Segmentation#PartNet#mIOU#53.8
1910.06849v3.pdf	3D Semantic Segmentation#PartNet#mIOU#45.1$Semantic Segmentation#S3DIS Area5#mIoU#52.49$Semantic Segmentation#S3DIS#Mean IoU#60.0$Semantic Segmentation#S3DIS#oAcc#85.9$Node Classification#PPI#F1#99.43$Node Classification#PPI#F1#99.41$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.6$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.9$3D Point Cloud Classification#ModelNet40#Number of params#2.2M
1812.02713v1.pdf	3D Semantic Segmentation#PartNet#mIOU#43.2
1904.08755v4.pdf	3D Semantic Segmentation#STPLS3D#mIOU#51.35$Semantic Segmentation#S3DIS Area5#mIoU#65.4$Semantic Segmentation#S3DIS Area5#mAcc#71.7$Semantic Segmentation#S3DIS#Mean IoU#65.4$Semantic Segmentation#ScanNet#3DIoU#0.734
2012.09164v2.pdf	3D Semantic Segmentation#STPLS3D#mIOU#47.64$Semantic Segmentation#S3DIS Area5#mIoU#70.4$Semantic Segmentation#S3DIS Area5#oAcc#90.8$Semantic Segmentation#S3DIS Area5#mAcc#76.5$Semantic Segmentation#S3DIS Area5#mIoU#57.3$Semantic Segmentation#S3DIS Area5#mIoU#41.1$Semantic Segmentation#S3DIS#Mean IoU#73.5$Semantic Segmentation#S3DIS#mAcc#81.9$Semantic Segmentation#S3DIS#oAcc#90.2$Semantic Segmentation#S3DIS#Mean IoU#70.6$Semantic Segmentation#S3DIS#Mean IoU#65.4$Semantic Segmentation#S3DIS#Mean IoU#62.1$Semantic Segmentation#S3DIS#Mean IoU#47.6$3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.7$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.6$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.7$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.6$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.049
2011.12954v4.pdf	3D Semantic Segmentation#RELLIS-3D Dataset#Mean IoU (class)#40.2$3D Semantic Segmentation#RELLIS-3D Dataset#Mean IoU (class)#18.64$Semantic Segmentation#RELLIS-3D Dataset#Mean IoU (class)#50.13$Semantic Segmentation#RELLIS-3D Dataset#Mean IoU (class)#48.83
2101.11530v2.pdf	Zero Shot Skeletal Action Recognition#NTU RGB+D#Accuracy (5 unseen classes)#75.81$Zero Shot Skeletal Action Recognition#NTU RGB+D#Accuracy (12 unseen classes)#33.30$Zero Shot Skeletal Action Recognition#NTU RGB+D 120#Accuracy (10 unseen classes)#62.69$Zero Shot Skeletal Action Recognition#NTU RGB+D 120#Accuracy (24 unseen classes)#38.70$Generalized Zero Shot skeletal action recognition#NTU RGB+D 120#Harmonic Mean (10 unseen classes)#54.94$Generalized Zero Shot skeletal action recognition#NTU RGB+D 120#Harmonic Mean (24 unseen classes)#41.04$Generalized Zero Shot skeletal action recognition#NTU RGB+D#Harmonic Mean (5 unseen classes)#59.02$Generalized Zero Shot skeletal action recognition#NTU RGB+D#Harmonic Mean (12 unseen classes)#36.33
2008.03800v4.pdf	Self-Supervised Action Recognition#Kinetics-600#Top-1 Accuracy#72.9$Self-Supervised Action Recognition#Kinetics-600#Top-1 Accuracy#71.6$Self-Supervised Action Recognition#Kinetics-600#Top-1 Accuracy#70.4$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#69.9$Self-Supervised Action Recognition#HMDB51 (finetuned)#Pretraining Dataset#K600$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#68.0$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#66.7$Self-Supervised Action Recognition#HMDB51 (finetuned)#Pretraining Dataset#K400$Self-Supervised Action Recognition#Kinetics-400#Top-1 accuracy %#71.6$Self-Supervised Action Recognition#Kinetics-400#Top-1 accuracy %#67.6$Self-Supervised Action Recognition#Kinetics-400#Top-1 accuracy %#66.1$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#93.9$Self-Supervised Action Recognition#UCF101 (finetuned)#Pretrain#K600$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#93.4$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#92.2$Self-Supervised Action Recognition#UCF101 (finetuned)#Pretrain#K400$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#69.9$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics600$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#68.0$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#66.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#93.9$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics600$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#93.4$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#92.2$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400
2103.16559v3.pdf	Self-Supervised Action Recognition#Kinetics-600#Top-1 Accuracy#71.4$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#77.8$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#95.7$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#70.5$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#93.1$Self-Supervised Action Recognition#UCF101#Frozen#false
2006.16228v2.pdf	Self-Supervised Action Recognition#Kinetics-600#Top-1 Accuracy#55.5$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#70.1$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#91.5$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#95.2$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Audioset + Howto100M$Self-Supervised Action Recognition#UCF101#Frozen#false$Audio Classification#AudioSet#Test mAP#0.309
1911.12667v3.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#68.9$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#95.5$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#68.9$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#IG-Kinetics$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#66.5$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#IG-Random$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#63.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#AudioSet$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#52.6$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Audio Classification#DCASE#Top-1 Accuracy#95$Audio Classification#DCASE#PRE-TRAINING DATASET#IG-Random$Audio Classification#DCASE#PRE-TRAINING DATASET#AudioSet$Audio Classification#ESC-50#Top-1 Accuracy#85.4$Audio Classification#ESC-50#PRE-TRAINING DATASET#IG-Random$Audio Classification#ESC-50#Top-1 Accuracy#84.8$Audio Classification#ESC-50#PRE-TRAINING DATASET#AudioSet
2002.12177v1.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#67.4$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#93.8$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#64.5$Self-Supervised Action Recognition#HMDB51#Frozen#false
2004.12943v3.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#64.7$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#91.5$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#64.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Audioset (Video+Audio)$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#64.1$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#60.8$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400 (Video+Audio)$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#59.9$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#91.5$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Audioset (Audio+Video)$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#91.0$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#87.5$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400 (Audio+Video)$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#86.9$Audio Classification#ESC-50#Top-1 Accuracy#89.2
2106.10137v3.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#62.2$Self-Supervised Action Recognition#HMDB51 (finetuned)#Pretraining Dataset#UCF101$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#52.4$Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#47.9$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#90.5$Self-Supervised Action Recognition#UCF101 (finetuned)#Pretrain#UCF101$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#88.8$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#84.3$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#82.8$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#62.2$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#61.5$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#52.4$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#38.5$Self-Supervised Action Recognition#HMDB51#Frozen#true$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#90.5$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#88.8$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#82.8$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#72.2$Self-Supervised Action Recognition#UCF101#Frozen#true
1807.00230v2.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#61.6$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#89.0$Audio Classification#ESC-50#Top-1 Accuracy#82.3
2010.09709v2.pdf	Self-Supervised Action Recognition#HMDB51 (finetuned)#Top-1 Accuracy#54.6$Self-Supervised Action Recognition#UCF101 (finetuned)#3-fold Accuracy#87.9$Self-Supervised Action Recognition#UCF101 (finetuned)#Pretrain#K400$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#46.1$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#74.5$Self-Supervised Action Recognition#UCF101#Frozen#false
2104.14558v1.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#75.0$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#96.3$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false
2111.05329v3.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#66.8$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#AudioSet$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#64.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#60.5$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics-Sound$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#92.4$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#AudioSet$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#91.5$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#88.3$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics-Sound$Audio Classification#DCASE#Top-1 Accuracy#97$Audio Classification#DCASE#PRE-TRAINING DATASET#AudioSet$Audio Classification#DCASE#Top-1 Accuracy#96$Audio Classification#DCASE#PRE-TRAINING DATASET#Kinetics-400$Audio Classification#DCASE#Top-1 Accuracy#93$Audio Classification#DCASE#PRE-TRAINING DATASET#Kinetics-Sound
2011.07949v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#64.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#93.7$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false
2108.08426v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#54.8$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#54.5$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#85.4$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#84.8
2101.07974v4.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#52.9$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#82.4$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
2010.15464v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#43.2$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#82.3$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
2008.02531v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#38.3$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#74.4$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
2004.02753v5.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#36.6$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#34.2$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#71.2$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#68.8$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#68.2$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101
1909.04656v3.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#35.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#34.5$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#75.7$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#68.2$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#60.6$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101
1811.11387v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#33.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#62.9$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false
1811.09795v1.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#33.7$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#65.8$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#Kinetics400$Self-Supervised Action Recognition#UCF101#Frozen#false
2001.00294v1.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#31.5$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#66$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
1708.01246v1.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#23.8$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false
1904.03597v1.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#20.3$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#58.8$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
1603.08561v2.pdf	Self-Supervised Action Recognition#HMDB51#Top-1 Accuracy#19.8$Self-Supervised Action Recognition#HMDB51#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#HMDB51#Frozen#false$Self-Supervised Action Recognition#UCF101#3-fold Accuracy#50.9$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
1910.12770v1.pdf	Self-Supervised Action Recognition#UCF101#3-fold Accuracy#64.4$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
1611.06646v4.pdf	Self-Supervised Action Recognition#UCF101#3-fold Accuracy#60.3$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false
1906.05849v5.pdf	Self-Supervised Action Recognition#UCF101#3-fold Accuracy#59.1$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#70.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#89.7%$Self-Supervised Image Classification#ImageNet#Number of Params#188M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#66.2%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#87.0%$Self-Supervised Image Classification#ImageNet#Number of Params#47M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#65.0%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#86.0%
1609.02612v3.pdf	Self-Supervised Action Recognition#UCF101#3-fold Accuracy#52.1$Self-Supervised Action Recognition#UCF101#Pre-Training Dataset#UCF101$Self-Supervised Action Recognition#UCF101#Frozen#false$Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#8.18$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#8.18
2112.05132v2.pdf	Few Shot Action Recognition#Something-Something-100#1:1 Accuracy#68.1$Few Shot Action Recognition#Kinetics-100#Accuracy#86.7$Few Shot Action Recognition#HMDB51#1:1 Accuracy#77.3$Few Shot Action Recognition#UCF101#1:1 Accuracy#96.8
2101.06184v3.pdf	Few Shot Action Recognition#Something-Something-100#1:1 Accuracy#64.6$Few Shot Action Recognition#Kinetics-100#Accuracy#85.9$Few Shot Action Recognition#HMDB51#1:1 Accuracy#75.6$Few Shot Action Recognition#UCF101#1:1 Accuracy#96.1
2010.09982v1.pdf	Few Shot Action Recognition#Kinetics-100#Accuracy#86.8$Few Shot Action Recognition#HMDB51#1:1 Accuracy#75.5$Few Shot Action Recognition#UCF101#1:1 Accuracy#95.5
2001.03905v3.pdf	Few Shot Action Recognition#Kinetics-100#Accuracy#82.4$Few Shot Action Recognition#HMDB51#1:1 Accuracy#60.6$Few Shot Action Recognition#UCF101#1:1 Accuracy#83.1
1907.09021v1.pdf	Few Shot Action Recognition#Kinetics-100#Accuracy#78.5
2206.04790v2.pdf	Few Shot Action Recognition#HMDB51#1:1 Accuracy#76.4$Few Shot Action Recognition#UCF101#1:1 Accuracy#96.5
2109.03223v2.pdf	Action Triplet Recognition#CholecT50#Mean AP#29.9$Action Triplet Recognition#CholecT50#Mean AP#23.4
2204.05235v1.pdf	Action Triplet Recognition#CholecT50#Mean AP#29.5$Action Triplet Recognition#CholecT50#Mean AP#23.3$Action Triplet Recognition#CholecT50#Mean AP#21.6$Action Triplet Recognition#CholecT50 (cross-val)#mAP#29.4±2.5$Action Triplet Recognition#CholecT50 (cross-val)#mAP#27.2±2.9$Action Triplet Recognition#CholecT50 (cross-val)#mAP#25.3±2.4$Action Triplet Recognition#CholecT45 (cross-val)#mAP#29.4±2.8$Action Triplet Recognition#CholecT45 (cross-val)#mAP#27.2±2.7$Action Triplet Recognition#CholecT45 (cross-val)#mAP#24.4±4.7$Action Triplet Recognition#CholecT45#mAP#29.4±2.8$Action Triplet Recognition#CholecT45#mAP#27.2±2.7$Action Triplet Recognition#CholecT45#mAP#24.4±4.7$Action Triplet Recognition#CholecT50 (Challenge)#mAP#32.8$Action Triplet Recognition#CholecT50 (Challenge)#mAP#27.7$Action Triplet Recognition#CholecT50 (Challenge)#mAP#27.4
2007.05405v1.pdf	Action Triplet Recognition#CholecT50#Mean AP#20.0$Action Triplet Recognition#CholecT50 (Challenge)#mAP#23.4$Action Triplet Recognition#CholecT40#mAP#18.95
2204.04746v1.pdf	Action Triplet Recognition#CholecT50 (Challenge)#mAP#38.1$Action Triplet Recognition#CholecT50 (Challenge)#mAP#36.9$Action Triplet Recognition#CholecT50 (Challenge)#mAP#35.8$Action Triplet Recognition#CholecT50 (Challenge)#mAP#32.9$Action Triplet Recognition#CholecT50 (Challenge)#mAP#32.7$Action Triplet Recognition#CholecT50 (Challenge)#mAP#32.0$Action Triplet Recognition#CholecT50 (Challenge)#mAP#31.9$Action Triplet Recognition#CholecT50 (Challenge)#mAP#31.7$Action Triplet Recognition#CholecT50 (Challenge)#mAP#26.7$Action Triplet Recognition#CholecT50 (Challenge)#mAP#26.3$Action Triplet Recognition#CholecT50 (Challenge)#mAP#25.6$Action Triplet Recognition#CholecT50 (Challenge)#mAP#25.5$Action Triplet Recognition#CholecT50 (Challenge)#mAP#25.2$Action Triplet Recognition#CholecT50 (Challenge)#mAP#24.8$Action Triplet Recognition#CholecT50 (Challenge)#mAP#18.4$Action Triplet Recognition#CholecT50 (Challenge)#mAP#18.1$Action Triplet Recognition#CholecT50 (Challenge)#mAP#16.0$Action Triplet Recognition#CholecT50 (Challenge)#mAP#10.4$Action Triplet Recognition#CholecT50 (Challenge)#mAP#9.8$Action Triplet Recognition#CholecT50 (Challenge)#mAP#9.3$Action Triplet Recognition#CholecT50 (Challenge)#mAP#4.2
2203.15187v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#41$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#25.1$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#36.6$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#45.1
2108.05029v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#40.4$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#25.1$Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#45.3$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#44$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#26.8$Weakly Supervised Action Localization#GTEA#mAP@0.1:0.7#43.5$Weakly Supervised Action Localization#GTEA#mAP@0.5#33.9$Weakly Supervised Action Localization#BEOID#mAP@0.1:0.7#51.8$Weakly Supervised Action Localization#BEOID#mAP@0.5#42.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#45.3$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#52.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#62.7$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#62.7$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#44.5$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#52.8
2104.02967v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#40.1$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#24.6$Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#34.6$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#34.6$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#42.6$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#53.2$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#53.2$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#33.4$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#42.6
2006.07006v3.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#37$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#23.7$Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#33.7$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#41.2$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#25.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#33.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#41.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#51.6$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#51.6$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#32.9$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#41.9
2007.06643v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#36.8$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#22.5$Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#30.1$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#30.1$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#37.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#46.9$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#46.9$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#30.6$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#37.8$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.1#61.2$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.2#56.1$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.3#48.1$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.4#39.0$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.5#30.1$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.6#19.2$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.7#10.6$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.8#4.8$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.9#1.0$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP@AVG(0.1:0.9)#30.0
1911.09963v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#34.5$Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5:0.95#22.2$Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#27.0$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#38.5$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#27$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#35.3$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#43.6
1905.08586v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#33.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#20.3$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#31.6
1712.05080v2.pdf	Weakly Supervised Action Localization#ActivityNet-1.3#mAP@0.5#29.3$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#16.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#27.0
2012.06440v2.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#35.9$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#42.3$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#26$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#35.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#-$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#51.4
2012.08236v1.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#35.9$Weakly Supervised Action Localization#GTEA#mAP@0.1:0.7#33.7$Weakly Supervised Action Localization#GTEA#mAP@0.5#21.9$Weakly Supervised Action Localization#BEOID#mAP@0.1:0.7#34.9$Weakly Supervised Action Localization#BEOID#mAP@0.5#20.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#35.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#44.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#55.6$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#55.6$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#35.4$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#44.8
2103.15088v1.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#32.4
2103.16392v2.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#32.2$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#42.7$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#26.1$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#32.2$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#40.9$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#50.3$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#50.3$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#32.1$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#40.9
2004.00163v2.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#30.5$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#44.9$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#30.4$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#37.7
1908.08216v2.pdf	Weakly Supervised Action Localization#THUMOS’14#mAP@0.5#26.6$Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#37.2$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#21.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#26.6$Action Classification#THUMOS’14#mAP#86.9$Action Classification#ActivityNet-1.2#mAP#92.4$Action Classification#THUMOS'14#mAP#86.9
2003.12424v2.pdf	Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#41.0$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#24.4$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#28.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#37.0$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#45.6
2105.02439v1.pdf	Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#40.2$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#25.8
2003.06845v6.pdf	Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#37.8$Weakly Supervised Action Localization#ActivityNet-1.2#Mean mAP#22.8$Weakly Supervised Action Localization#GTEA#mAP@0.1:0.7#31.0$Weakly Supervised Action Localization#GTEA#mAP@0.5#19.3$Weakly Supervised Action Localization#BEOID#mAP@0.1:0.7#30.1$Weakly Supervised Action Localization#BEOID#mAP@0.5#16.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#30.5$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#41.2$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#51.2
1807.10418v3.pdf	Weakly Supervised Action Localization#ActivityNet-1.2#mAP@0.5#37.0$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#22.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#-$Action Classification#THUMOS’14#mAP#85.6$Action Classification#ActivityNet-1.2#mAP#93.2
2103.06669v3.pdf	Weakly Supervised Action Localization#GTEA#mAP@0.1:0.7#36.4$Weakly Supervised Action Localization#GTEA#mAP@0.5#28.8$Weakly Supervised Action Localization#BEOID#mAP@0.1:0.7#34.4$Weakly Supervised Action Localization#BEOID#mAP@0.5#20.3
2107.12589v1.pdf	Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#38.3$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#44.6$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.5#54.4$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.1#70.1$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.2#63.6$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.3#54.5$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.4#45.7$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.5#38.3$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.6#26.4$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.7#13.4$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.8#6.9$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP IOU@0.9#2.0$Weakly-supervised Temporal Action Localization#THUMOS’14#mAP@AVG(0.1:0.9)#35.7
1703.03329v2.pdf	Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#13.7$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#-$Action Classification#THUMOS’14#mAP#82.2$Action Classification#ActivityNet-1.2#mAP#87.7
1704.04232v2.pdf	Weakly Supervised Action Localization#THUMOS 2014#mAP@0.5#6.8$Weakly Supervised Action Localization#THUMOS 2014#mAP@0.1:0.7#-
2104.02357v1.pdf	Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#52.0$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#32.4$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#42.3
2104.14135v1.pdf	Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#52.1$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#32.4$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#41.5
2010.11594v1.pdf	Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1-0.5)#47.0$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.3-0.7)#28.8$Weakly Supervised Action Localization#THUMOS14#avg-mAP (0.1:0.7)#37.8
2005.08271v2.pdf	Temporal Action Proposal Generation#ActivityNet Captions#Average Precision#48.23$Temporal Action Proposal Generation#ActivityNet Captions#Average Recall#80.31$Temporal Action Proposal Generation#ActivityNet Captions#Average F1#60.27$Dense Video Captioning#ActivityNet Captions#METEOR#8.44$Dense Video Captioning#ActivityNet Captions#BLEU-3#3.84$Dense Video Captioning#ActivityNet Captions#BLEU-4#1.88
2210.02578v1.pdf	Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#69.71$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#77.67$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (test)#70.10$Temporal Action Proposal Generation#THUMOS' 14#AR@100#50.26$Temporal Action Proposal Generation#THUMOS' 14#AR@1000#68.19$Temporal Action Proposal Generation#THUMOS' 14#AR@200#57.30$Temporal Action Proposal Generation#THUMOS' 14#AR@50#44.56$Temporal Action Proposal Generation#THUMOS' 14#AR@500#64.32
2110.11474v2.pdf	Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#69.47$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#77.24$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (test)#70.09
2203.08942v1.pdf	Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#69.16$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#76.72$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (test)#69.26
1807.04821v2.pdf	Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#65.72$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#73.17
1707.06750v3.pdf	Temporal Action Proposal Generation#ActivityNet-1.3#AUC (val)#64.40$Temporal Action Proposal Generation#ActivityNet-1.3#AR@100#73.01$Temporal Action Proposal Generation#ActivityNet-1.3#AUC (test)#64.80
1605.08140v3.pdf	Activity Recognition In Videos#DogCentric#Accuracy#81.4
1412.6505v2.pdf	Activity Recognition In Videos#DogCentric#Accuracy#73.0
2106.09696v2.pdf	Action Classification#BABEL#CE Top-1#44.87$Action Classification#BABEL#CE Top-1-norm#17.16$Action Classification#BABEL#CE Top-5#71.78
2008.08072v1.pdf	Action Classification#Toyota Smarthome dataset#CS#63.6$Action Classification#Charades#MAP#59.8$Action Classification#Charades#MAP#54.98
2104.07135v1.pdf	Action Classification#Toyota Smarthome dataset#CS#62.11
1604.08826v1.pdf	Action Classification#Toyota Smarthome dataset#CS#41.9$Action Classification#Toyota Smarthome dataset#CV1#20.9$Action Classification#Toyota Smarthome dataset#CV2#23.7
2103.16516v1.pdf	Action Classification#Toyota Smarthome dataset#CV1#39.6$Action Classification#Toyota Smarthome dataset#CV2#54.6
2202.11423v2.pdf	Action Classification#Toyota Smarthome dataset#Accuracy#70.22
2205.01917v2.pdf	Action Classification#Moments in Time#Top 1 Accuracy#49.0$Action Classification#Moments in Time#Top 1 Accuracy#47.4$Action Classification#Kinetics-600#Top-1 Accuracy#89.4$Action Classification#Kinetics-600#Top-1 Accuracy#88.5$Action Classification#Kinetics-400#Acc@1#88.9$Action Classification#Kinetics-400#Acc@1#88.0$Action Classification#Kinetics-700#Top-1 Accuracy#82.7$Action Classification#Kinetics-700#Top-1 Accuracy#81.1$Video Retrieval#MSR-VTT#text-to-video R@1#30.0$Video Retrieval#MSR-VTT#text-to-video R@5#52.4$Video Retrieval#MSR-VTT#text-to-video R@10#61.6$Video Retrieval#MSR-VTT#video-to-text R@1#49.9$Video Retrieval#MSR-VTT#video-to-text R@5#73.4$Video Retrieval#MSR-VTT#video-to-text R@10#81.4$Visual Question Answering#VQA v2 test-dev#Accuracy#82.3$Visual Reasoning#NLVR2 Dev#Accuracy#86.1$Visual Reasoning#NLVR2 Test#Accuracy#87.0$Visual Entailment#SNLI-VE test#Accuracy#87.1$Visual Entailment#SNLI-VE val#Accuracy#87.0$Image Captioning#COCO Captions#BLEU-4#40.9$Image Captioning#COCO Captions#METEOR#33.9$Image Captioning#COCO Captions#CIDER#143.6$Image Captioning#COCO Captions#SPICE#24.7$Image Classification#ImageNet#Top 1 Accuracy#91.0%$Image Classification#ImageNet#Number of params#2100M$Image Classification#ImageNet#Top 1 Accuracy#90.60%$Image Classification#ObjectNet#Top-1 Accuracy#82.7$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Private)#82.7$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#80.7$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#86.3$Zero-Shot Transfer Image Classification#ImageNet-Sketch#Accuracy (Private)#77.6$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#96.5$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#90.2$Classification#ImageNet#Params(M)#2100
2104.11178v3.pdf	Action Classification#Moments in Time#Top 1 Accuracy#41.1$Action Classification#Moments in Time#Top 5 Accuracy#67.7$Action Classification#Kinetics-600#Top-1 Accuracy#83.6$Action Classification#Kinetics-600#Top-5 Accuracy#96.6$Action Classification#Kinetics-400#Acc@1#82.1$Action Classification#Kinetics-400#Acc@5#95.5$Audio Classification#AudioSet#Test mAP#0.394$Audio Classification#AudioSet#AUC#0.971$Audio Classification#AudioSet#d-prime#2.895
2102.00719v3.pdf	Action Classification#Moments in Time#Top 1 Accuracy#37.4$Action Classification#Moments in Time#Top 5 Accuracy#65.4$Action Classification#Kinetics-400#Acc@1#79.8$Action Classification#Kinetics-400#Acc@1#78.6$Action Classification#Kinetics-400#Acc@5#93.7$Action Classification#Kinetics-400#Acc@5#94.2$Action Classification#Kinetics-400#Acc@5#93.4
1905.13209v4.pdf	Action Classification#Moments in Time#Top 1 Accuracy#34.27%$Action Classification#Moments in Time#Top 5 Accuracy#62.71%$Action Classification#Charades#MAP#58.6$Multimodal Activity Recognition#Moments in Time Dataset#Top-1 (%)#34.27$Multimodal Activity Recognition#Moments in Time Dataset#Top-5 (%)#62.71
1811.10636v2.pdf	Action Classification#Moments in Time#Top 1 Accuracy#31.8%$Action Classification#Charades#MAP#38.1$Action Classification#Kinetics-400#Acc@1#77.4
1705.02953v1.pdf	Action Classification#Moments in Time#Top 5 Accuracy#50.10%
2106.11297v4.pdf	Action Classification#AViD#Accuracy#53.8$Action Classification#Charades#MAP#66.3$Action Classification#Kinetics-600#Top-1 Accuracy#86.3$Action Classification#Kinetics-600#Top-5 Accuracy#97.0$Action Classification#Kinetics-400#Acc@1#85.4$Image Classification#ImageNet#Top 1 Accuracy#88.87%$Image Classification#ImageNet#Number of params#460M$Image Classification#ImageNet#Top 1 Accuracy#87.07%$Image Classification#ImageNet ReaL#Accuracy#91.05%$Image Classification#ImageNet ReaL#Params#460M
2007.05515v3.pdf	Action Classification#AViD#Accuracy#50.9$Action Classification#AViD#Accuracy#50.5$Action Classification#AViD#Accuracy#50.4$Action Classification#AViD#Accuracy#50.1$Action Classification#AViD#Accuracy#48.8$Action Classification#AViD#Accuracy#48.5$Action Classification#AViD#Accuracy#48.2$Action Classification#AViD#Accuracy#46.8$Action Classification#AViD#Accuracy#36.2$Action Detection#Charades#mAP#25.2$Action Detection#Charades#mAP#23.2
1904.01766v2.pdf	Action Classification#YouCook2#Object Top 5 Accuracy#33.7$Action Classification#YouCook2#Object Top-1 Accuracy#13.1$Action Classification#YouCook2#Verb Top-1 Accuracy#3.2$Action Classification#YouCook2#Verb Top-5 Accuracy#43.3$Video Captioning#YouCook2#BLEU-3#7.59$Video Captioning#YouCook2#BLEU-4#4.33$Video Captioning#YouCook2#METEOR#11.94$Video Captioning#YouCook2#ROUGE-L#28.80$Video Captioning#YouCook2#CIDEr#0.55
2109.08472v1.pdf	Action Classification#Charades#MAP#44.3$Action Classification#Kinetics-400#Acc@1#83.8$Action Classification#Kinetics-400#Acc@5#97.1
2111.01936v1.pdf	Action Classification#Charades#MAP#38.5
2106.00050v3.pdf	Action Classification#Charades#MAP#25.2$Action Classification#Charades#FLOPs (G) x views#6.9x1$Action Classification#Charades#MAP#24.1$Action Classification#Charades#FLOPs (G) x views#54.9x1$Action Classification#Charades#MAP#21.5$Action Classification#Kinetics-400#Acc@1#73.05$Action Classification#Kinetics-400#FLOPs (G) x views#6.90x1$Action Classification#Kinetics-400#Parameters (M)#32.45$Action Classification#Kinetics-400#Acc@1#71.61$Action Classification#Kinetics-400#FLOPs (G) x views#1.25x1$Action Classification#Kinetics-400#Parameters (M)#6.15$Action Classification#Kinetics-400#Acc@1#71.03$Action Classification#Kinetics-400#FLOPs (G) x views#0.33x1$Action Classification#Kinetics-400#Parameters (M)#3.79$Action Classification#Kinetics-400#Acc@1#69.29$Action Classification#Kinetics-400#FLOPs (G) x views#19.17x1$Action Classification#Kinetics-400#Acc@1#68.45$Action Classification#Kinetics-400#FLOPs (G) x views#66.25x1$Action Classification#Kinetics-400#Parameters (M)#66.25$Action Classification#Kinetics-400#Acc@1#67.42$Action Classification#Kinetics-400#FLOPs (G) x views#54.87x1$Action Classification#Kinetics-400#Acc@1#67.33$Action Classification#Kinetics-400#FLOPs (G) x views#0.17x1$Action Classification#Kinetics-400#Acc@1#67.24$Action Classification#Kinetics-400#FLOPs (G) x views#4.97x1$Action Classification#Kinetics-400#Acc@1#67.06$Action Classification#Kinetics-400#FLOPs (G) x views#36.46x1$Action Classification#Kinetics-400#Parameters (M)#34.48$Action Classification#Kinetics-400#Acc@1#65.90$Action Classification#Kinetics-400#Acc@1#64.71$Action Classification#Kinetics-400#FLOPs (G) x views#2.06x1$Action Classification#Kinetics-400#Acc@1#63.98$Action Classification#Kinetics-400#FLOPs (G) x views#28.61x1$Action Classification#Kinetics-400#Parameters (M)#28.04$Action Classification#Kinetics-400#Acc@1#63.03$Action Classification#Kinetics-400#Acc@1#62.80$Action Classification#Kinetics-400#Acc@1#60.18$Action Classification#Kinetics-400#Acc@1#59.58$Action Classification#Kinetics-400#FLOPs (G) x views#5.68x1$Action Classification#Kinetics-400#Acc@1#59.52$Action Classification#Kinetics-400#FLOPs (G) x views#40.71x1$Action Classification#Kinetics-400#Parameters (M)#31.51$Action Classification#Kinetics-400#Acc@1#59.37$Action Classification#Kinetics-400#FLOPs (G) x views#0.64x1$Action Classification#Kinetics-400#Acc@1#56.86$Action Classification#Kinetics-400#Acc@1#53.52$Action Classification#Kinetics-400#FLOPs (G) x views#20.35x1$Action Classification#Kinetics-400#Acc@1#53.40$Action Classification#Kinetics-400#FLOPs (G) x views#4.71x1$Action Classification#Kinetics-400#Parameters (M)#12.80
1612.06371v2.pdf	Action Classification#Charades#MAP#22.4$Action Detection#Charades#mAP#9.6
1712.00636v2.pdf	Action Classification#Charades#MAP#21.9
2201.02639v4.pdf	Action Classification#Kinetics-600#Top-1 Accuracy#91.1$Action Classification#Kinetics-600#Top-5 Accuracy#97.1$Action Classification#Kinetics-600#Top-1 Accuracy#89.7$Action Classification#Kinetics-600#Top-5 Accuracy#96.6$Action Classification#Kinetics-600#Top-1 Accuracy#89.4$Action Classification#Kinetics-600#Top-5 Accuracy#96.3$Action Classification#Kinetics-600#Top-1 Accuracy#88.1$Action Classification#Kinetics-600#Top-5 Accuracy#95.8
2208.02816v1.pdf	Action Classification#Kinetics-600#Top-1 Accuracy#88.3$Action Classification#Kinetics-600#Top-5 Accuracy#97.7$Action Classification#Kinetics-400#Acc@1#87.7$Action Classification#Kinetics-400#Acc@5#97.4$Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#44.6$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#72.0$Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#65.2$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#86.1
2109.01696v1.pdf	Action Classification#Kinetics-600#Top-1 Accuracy#83.1$Action Classification#Kinetics-400#Acc@1#80.4$Action Classification#Kinetics-400#Acc@5#94.4
1808.01340v1.pdf	Action Classification#Kinetics-600#Top-1 Accuracy#73.6
2111.11432v1.pdf	Action Classification#Kinetics-600#Top-5 Accuracy#97.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#37.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#63.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#72.6$Visual Question Answering#VQA v2 test-dev#Accuracy#80.16$Visual Question Answering#VQA v2 test-std#overall#80.36$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#81.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#95.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#63.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#85.7$Object Detection#COCO test-dev#box AP#62.4$Object Detection#COCO minival#box AP#62$Image Classification#ImageNet#Top 1 Accuracy#90.05%$Image Classification#ImageNet#Top 5 Accuracy#99.02%$Image Classification#ImageNet#Number of params#893M$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#83.7
2207.01297v2.pdf	Action Classification#Kinetics-400#Acc@1#87.8$Action Classification#Kinetics-400#Acc@5#97.6
2208.03550v1.pdf	Action Classification#Kinetics-400#Acc@1#87.7$Action Classification#Kinetics-400#Acc@5#97.8
2111.09883v2.pdf	Action Classification#Kinetics-400#Acc@1#86.8$Semantic Segmentation#ADE20K#Validation mIoU#59.9$Semantic Segmentation#ADE20K#Validation mIoU#53.7$Object Detection#COCO test-dev#box AP#63.1$Object Detection#COCO minival#box AP#62.5$Image Classification#ImageNet#Top 1 Accuracy#90.17%$Image Classification#ImageNet#Number of params#3000M$Image Classification#ImageNet#Top 1 Accuracy#87.1%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet V2#Top 1 Accuracy#84.00%$Image Classification#ImageNet V2#Top 1 Accuracy#78.08$Instance Segmentation#COCO test-dev#mask AP#54.4$Instance Segmentation#COCO minival#mask AP#53.7
1905.00561v1.pdf	Action Classification#Kinetics-400#Acc@1#82.8$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#25.6$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#16.8
2004.04730v1.pdf	Action Classification#Kinetics-400#Acc@1#80.4$Action Classification#Kinetics-400#Acc@5#94.6$Action Classification#Kinetics-400#Acc@1#79.1$Action Classification#Kinetics-400#Acc@5#93.9$Action Classification#Kinetics-400#Acc@1#77.5$Action Classification#Kinetics-400#Acc@5#92.9$Action Classification#Kinetics-400#Acc@1#76$Action Classification#Kinetics-400#Acc@5#92.3
1906.03349v2.pdf	Action Classification#Kinetics-400#Acc@1#79.2
1906.00550v1.pdf	Action Classification#Kinetics-400#Acc@1#76.1
1904.05049v3.pdf	Action Classification#Kinetics-400#Acc@1#75.7$Image Classification#ImageNet#Top 1 Accuracy#82.9%$Image Classification#ImageNet#Top 5 Accuracy#96.3$Image Classification#ImageNet#Number of params#66.8M$Image Classification#ImageNet#Hardware Burden#20771G$Image Classification#ImageNet#Operations per network pass#2.22G$Image Classification#ImageNet#GFLOPs#22.2
1708.03805v1.pdf	Action Classification#Kinetics-400#Acc@1#73.0$Action Classification#Kinetics-400#Acc@5#90.9
2203.15205v1.pdf	Action Classification#UCF101#Top-1#62.03
2207.07115v2.pdf	Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#85.6$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#81.7$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#86.9$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#90.3$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#90.2$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#84.6$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#80.2$Video Object Segmentation#YouTube-VOS 2018 validation#Mean Jaccard & F-Measure#85.7$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Seen)#89.3$Video Object Segmentation#YouTube-VOS 2018 validation#F-Measure (Unseen)#88.7$Video Object Segmentation#YouTube-VOS 2018 validation#FPS#22.6$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#89.5$Video Object Segmentation#DAVIS-2017 validation#Jaccard#86.3$Video Object Segmentation#DAVIS-2017 validation#F-measure#92.6$Video Object Segmentation#DAVIS-2017 validation#Mean Jaccard & F-Measure#86.2$Video Object Segmentation#DAVIS-2017 validation#Jaccard#82.9$Video Object Segmentation#DAVIS-2017 validation#F-measure#89.5$Video Object Segmentation#DAVIS-2017 validation#FPS#22.6$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#93.3$Video Object Segmentation#DAVIS 2016 val#Jaccard#92.2$Video Object Segmentation#DAVIS 2016 val#F-measure#94.4$Video Object Segmentation#DAVIS 2016 val#Mean Jaccard & F-Measure#91.5$Video Object Segmentation#DAVIS 2016 val#Jaccard#90.4$Video Object Segmentation#DAVIS 2016 val#F-measure#92.7$Video Object Segmentation#DAVIS 2016 val#FPS#29.7$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#86.8$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#85.5$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#81.8$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#89.8$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#89.9$Video Object Segmentation#YouTube-VOS 2019 validation#Mean Jaccard & F-Measure#85.5$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.3$Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#80.3$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.6$Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#88.6$Video Object Segmentation#YouTube-VOS 2019 validation#FPS#22.6$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#83.7$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#80.5$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#87.0$Video Object Segmentation#DAVIS-2017 (test-dev)#Mean Jaccard & F-Measure#81.0$Video Object Segmentation#DAVIS-2017 (test-dev)#Jaccard#77.4$Video Object Segmentation#DAVIS-2017 (test-dev)#F-measure#84.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#90.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#90.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#86.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#81.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#89.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#89.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#86.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#89.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#89.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#86.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#22.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#80.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#89.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#88.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#84.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#80.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#88.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#84.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#83.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#78.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#88.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#87.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#FPS#22.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#86.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#92.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#89.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#85.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#91.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#88.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#84.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#91.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#87.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#22.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#89.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#86.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#84.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#74.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#79.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#76.7$Semi-Supervised Video Object Segmentation#Long Video Dataset#J&F#89.8±0.2$Semi-Supervised Video Object Segmentation#Long Video Dataset#J#88.0±0.2$Semi-Supervised Video Object Segmentation#Long Video Dataset#F#91.6±0.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#86.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#85.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#81.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#89.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#89.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#86.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#89.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#89.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#85.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#80.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#88.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#FPS#22.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#85.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#88.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#83.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#78.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#92.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#93.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#29.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#92.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#91.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#91.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#88.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#87.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#76.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#74.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#79.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#FPS#22.6$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#J&F#90.0±0.4$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#J#88.2±0.3$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#F#91.8±0.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J&F score#64.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J score#61.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#F score#68.1$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J score#86.7$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J&F score#87.8$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#F score#88.9$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#FPS#29.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#83.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#80.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#87.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#83.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#79.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#86.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#82.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#79.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#85.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#81.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#77.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#84.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#81.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#77.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#84.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#79.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#76.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#83.4
2101.08833v2.pdf	Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Seen)#80.9$Video Object Segmentation#YouTube-VOS 2018 validation#Jaccard (Unseen)#76.6
2008.01270v1.pdf	Video Object Segmentation#FBMS#F-Score#82.3$Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.4$Video Object Segmentation#DAVIS 2016#F-Score#81.8
2104.14294v2.pdf	Video Object Segmentation#DAVIS 2017#J&F#71.4$Image Classification#OmniBenchmark#Average Top-1 Accuracy#38.9$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#80.3%$Self-Supervised Image Classification#ImageNet#Number of Params#84M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#77.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#80.1%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#77.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.7%$Self-Supervised Image Classification#ImageNet#Number of Params#21M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#78.3%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.2%$Self-Supervised Image Classification#ImageNet#Number of Params#85M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#76.1%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#77.0%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#74.5%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.3%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#67.5%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#85M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#82.8%$Single-object discovery#COCO_20k#CorLoc#42.1
1803.08006v3.pdf	Video Object Segmentation#DAVIS 2017#J&F#62.2$Video Object Segmentation#DAVIS 2016#mIoU#84.5$Video Object Segmentation#DAVIS 2016#mIoU#82.8$Video Object Segmentation#DAVIS-2017#mIoU#59$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#58.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#60.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#66.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#22.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#63.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#70.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#24.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#95.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#6.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#84.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#93.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#8.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#83.65$Referring Expression Segmentation#DAVIS 2017 (val)#J&F 1st frame#39.3$Referring Expression Segmentation#DAVIS 2017 (val)#J&F Full video#37.1
2106.03348v4.pdf	Video Object Segmentation#DAVIS 2017#AUC-J&F#82.5$Object Detection#DAVIS 2016#AUC-J&F#89.8$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Number of params#48.5M$Image Classification#ImageNet#GFLOPs#27.6$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#19.2M$Image Classification#ImageNet#GFLOPs#12.0$Image Classification#ImageNet#Top 1 Accuracy#81%$Image Classification#ImageNet#Number of params#13.2M$Image Classification#ImageNet#GFLOPs#6.8$Image Classification#ImageNet#Top 1 Accuracy#77.9%$Image Classification#ImageNet#Number of params#6.5M$Image Classification#ImageNet#GFLOPs#4$Image Classification#ImageNet#Top 1 Accuracy#76.8%$Image Classification#ImageNet#Top 5 Accuracy#93.5$Image Classification#ImageNet#Number of params#4.8M$Image Classification#ImageNet#GFLOPs#4.6$Image Classification#ImageNet#Top 1 Accuracy#75.3%$Image Classification#ImageNet#GFLOPs#3.0
2008.11516v1.pdf	Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#84.3$Video Object Segmentation#DAVIS 2016#F-Score#84.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#84.3$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#95.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#0.074$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#84.7$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#92.6$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#0.052$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#84.5
2112.02853v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS#Overall#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS#Jaccard (Seen)#83.3$Semi-Supervised Video Object Segmentation#YouTube-VOS#Jaccard (Unseen)#78.9$Semi-Supervised Video Object Segmentation#YouTube-VOS#F-Measure (Seen)#87.9$Semi-Supervised Video Object Segmentation#YouTube-VOS#F-Measure (Unseen)#86.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#84$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#83.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#78.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#87.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#86.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#86$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#83.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#83.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#86.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#87.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#81$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#77.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#84.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#79.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#75.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#82.6
1902.09513v2.pdf	Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.821$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#69.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#79.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#17.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#74.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#20.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#71.55$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#81.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#90.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#13.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#82.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#86.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#14.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#81.65$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#57.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#55.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#62.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#29.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#60.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#68.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#33.5
1904.02363v1.pdf	Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.796$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#58.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#64.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#61.65$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#83.8
1803.09453v1.pdf	Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.784$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#67.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#74.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#24.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#74.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#81.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#26.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#70.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#94.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#12.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#85.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#92.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#14.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#84.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#67.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#64.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#73.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#20.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#70.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#79.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#20.0
1612.02646v1.pdf	Semi-Supervised Video Object Segmentation#YouTube#mIoU#0.726$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#79.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#93.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#8.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#75.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#87.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#9.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#77.55
2203.11442v5.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#90.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#88.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#86.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#0.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#80.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#65.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#90.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#88.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#5.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#79.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#90.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#6.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#15.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#88.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#14.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#79.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#15.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#88.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#20.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#13.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#86.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#83.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#81.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#30.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#81.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#75.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#12.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#84.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#89.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#87.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#1.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#65.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#89.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#86.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#83.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#89.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#86.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#12.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#88.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#85.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#17.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#15.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#88.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#85.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#24.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#13.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#86.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#83.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#37.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#12.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#86.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#85.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#81.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#90.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#89.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#85.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#84.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#88.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#84.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#83.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#83.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#78.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#88.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#81.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#81.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#754.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#85.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#91.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#93.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#1.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#91.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#12.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#94.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#17.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#24.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#90.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#37.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#84.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#80.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#88.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#1.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#84.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#81.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#87.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#82.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#78.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#86.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#12.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#79.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#76.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#83.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#17.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#78.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#74.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#81.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#24.3
2106.02638v3.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#89.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#88.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#6.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#84.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#79.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#14.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#90.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#85.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#5.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#85.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#65.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#89.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#9.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#77.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#88.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#6.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#8.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#88.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#14.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#20.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#83.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#16.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#77.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#83.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#85.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#83.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#27.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#77.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#7.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#86.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#85.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#76.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#84.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#83.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#80.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#41.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#80.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#75.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#5.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#84.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#82.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#80.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#80.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#74.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#88.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#85.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#12.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#65.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#87.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#84.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#18.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#14.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#86.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#83.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#18.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#8.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#79.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#85.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#82.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#29.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#78.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#83.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#81.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#40.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#7.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#77.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#82.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#79.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#51.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Params(M)#5.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#12.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#92.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#91.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#18.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#91.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#18.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#89.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#29.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#90.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#89.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#40.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#87.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#86.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#51.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#81.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#77.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#85.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#12.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#79.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#75.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#83.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#18.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#78.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#74.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#82.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#18.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#75.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#71.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#79.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#29.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#73.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#70.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#77.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#40.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#72.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#68.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#75.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#FPS#51.4
2207.10258v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#23$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#79.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#89.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#86.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#42 (on 3090)$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#92.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#91.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#58
2106.05210v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#87.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#84.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#13.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#83.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#79.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#91.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#6.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#88.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#94.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#85.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#85.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#20.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#85.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#83.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#80.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#87.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#88.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Overall#84.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Seen)#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#Jaccard (Unseen)#79.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Seen)#87.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2019 validation#F-Measure (Unseen)#87.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#98.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#4.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#97.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#91.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#26.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#79.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#76.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#85.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#10.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#83.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#89.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#10.3
2207.07922v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#86.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#83.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#78.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#82.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#88.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#85.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#90.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#93.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#81.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#78.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#85.4
2010.06349v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#86.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#85.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#82.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#4.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#81.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#77.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#80.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#85.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#82.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#91.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#89.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#78.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#74.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#81.6
2109.11404v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#87.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#84.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#76.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#87.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#84.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#92.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#78.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#74.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#82.5
2103.07941v3.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#84.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#85.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#82.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#80.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#77.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#90.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#7.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#87.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#93.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#8.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#84.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Speed (FPS)#11.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#6.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#92.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#96.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#91.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Speed (FPS)#16.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#76.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#72.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#81.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#14.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#80.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#14.5$Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.849$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.854$Interactive Video Object Segmentation#DAVIS 2017#AUC-J&F#0.879$Interactive Video Object Segmentation#DAVIS 2017#J&F@60s#0.885
2103.12934v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#85.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#82.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#81.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#82.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#75.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#81.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#86.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#83.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#88.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#88.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#75.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#71.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#78.1
2007.08270v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#85.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#83.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#81.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#81.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#75.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#80$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#85.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#82.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#89.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#91.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#90.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#77.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#74.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#80.3
2003.08333v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#85.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#83.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#81.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#3.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#81.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#75.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Params(M)#66.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#79.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#84.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#81.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#90.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#89.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#74.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#71.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#78.5
2010.07958v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#83.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#82.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#79.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#78.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#74.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#73.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#85.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#13.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#76.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#87.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#15.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#74.6$Semi-Supervised Video Object Segmentation#Long Video Dataset#J&F#83.7$Semi-Supervised Video Object Segmentation#Long Video Dataset#J#82.9$Semi-Supervised Video Object Segmentation#Long Video Dataset#F#84.5$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#J&F#83.8$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#J#82.9$Semi-Supervised Video Object Segmentation#Long Video Dataset (3X)#F#84.6
2012.01866v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#66.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#73.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#71.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#71.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#74.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#74.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#13.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#80.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#77.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#4.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#87.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#86.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#64.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#60.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#22.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#68.6
2107.12569v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#68.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#73.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#68.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#67.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#64.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#68.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#71.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#69.7
1910.00132v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#68.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#59.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#62.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#13.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#67.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#53.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#62.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#67.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#53.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#68.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#59.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#51.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#47.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#54.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#55.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#64.6
1809.00461v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#65.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#50.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Overall#57.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Speed  (FPS)#6.25$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#66.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#48.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#64.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#71.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#55.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#70.0$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#61.2
2003.00908v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#72.1$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#72.3$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#65.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#76.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#74.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#68.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#66.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#71.2$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J&F score#81.7
2010.12176v1.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#69.9$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#71.7$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#61.4$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#75.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#70.4
1904.00607v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#68.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#79.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#88.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#8.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#84.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#91.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#10.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#81.75$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#88.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#90.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#95.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#89.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#43.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#38.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#47.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#72.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#69.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#78.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#16.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#75.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#83.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#17.5$Interactive Video Object Segmentation#DAVIS 2017#AUC-J&F#0.803$Interactive Video Object Segmentation#DAVIS 2017#J&F@60s#0.848
1903.05612v2.pdf	Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J&F score#56.8$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (seen)#63.6$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#J score (unseen)#45.5$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (seen)#67.2$Semi-Supervised Video Object Segmentation#YouTube-VOS 2018 val (no extra training data)#F score (unseen)#51.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#57.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#65.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#24.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#63.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#73.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#28.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#60.55$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#50.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#47.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#54.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#35.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#52.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#61.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#36.7$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Seen)#67.2$One-shot visual object segmentation#YouTube-VOS 2018 val#F-Measure (Unseen)#51$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Seen)#63.6$One-shot visual object segmentation#YouTube-VOS 2018 val#Jaccard (Unseen)#45.5$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#22.5$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#17.7$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#16.2$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#1.6$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#27.3$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#24.8$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#1.8$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#41.2$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#36.8$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#40.2$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#45.7$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#46.4
1807.09190v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#73.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#83.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#16.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#81.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#88.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#19.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#77.85$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#84.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#96.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#8.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#88.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#94.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#9.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#86.75$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#71.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#67.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#76.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#21.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#75.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#84.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#20.6
2009.00771v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#73.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#83.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#12.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#80.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#91.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#15.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#77.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#85.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#87.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#96.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#86.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#67.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#63.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#72.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#16.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#71.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#81.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#16.5
1904.08141v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#73.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#83.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#17.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#78.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#87.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#19.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#76.15$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#6.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#89.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#95.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#9.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#88.55$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#69.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#66.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#76.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#18.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#72.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#82.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#19.1
2004.07193v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#69.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#74.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#72.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#72.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#69.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#74.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J&F score#63.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J score#58.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#F score#67.4
1811.11611v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#68.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#78.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#14.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#73.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#83.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#15.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#71.05$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#81.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#93.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#9.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#82.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#90.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#9.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#81.85$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#52.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#49.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#53.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#28.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#55.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#61.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#27.6
2111.06265v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#67.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#80.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#71.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#84.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#69.4
1709.06031v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#64.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#74.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#15.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#71.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#80.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#18.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#68$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#85.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#96.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#87.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#95.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#8.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#86.55$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#57.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#52.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#60.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#24.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#62.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#70.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#21.9
1908.06647v4.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#63.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#73.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#18.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#68.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#78.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#19.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#65.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#7.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#87.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#96.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#8.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#87.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#85.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#97.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#6.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#85.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#94.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#85.45$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J score#73.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#55.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#53.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#61.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#21.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#57.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#67.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#22.1
2002.07793v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#63.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#73.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#67.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#77.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#65.5$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#65.5$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#63.3$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#73.2$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#67.6$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#77.7
1909.11895v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#57.7$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#68.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#61.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#69.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#59.5
1806.02323v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#54.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#61.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#14.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#61.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#72.3$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#18.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#58.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#82.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#96.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#4.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#79.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#89.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#80.95$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#58.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#54.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#61.8$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J&F score#43.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#J score#42.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 test-dev (no extra training data)#F score#44.2$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J score#82.4$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#J&F score#81.0$Semi-Supervised Video Object Segmentation#DAVIS 2016 val (no extra training data)#F score#79.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#43.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#42.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#48.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#18.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#44.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#51.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#19.8
2003.05020v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#54.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#60.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Decay)#32.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#58.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#62.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Decay)#37.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#56.05$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#65.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#77.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#26.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#63.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#67.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#27.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#64.65$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#41.7$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#38.9$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#44.3$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#-2.7$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#44.5$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#46.6$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#-1.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#62.0$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#74.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#-3.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#56.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#62.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#-3.6$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#59.05
1905.00875v5.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#48.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#53.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#52.2$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#56.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#50.3
1903.07593v2.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#46.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#50.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#50.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#48.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (val)#J&F#48.7
2012.01851v2.pdf	Semi-Supervised Video Object Segmentation#100DOH#10 fold Cross validation#omer$Video Generation#100DOH#10-20% Mask PSNR#07
1703.09554v5.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#83.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#95.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#9.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#82.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#88.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#9.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#82.95$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#66.6$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#63.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#74.0$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#19.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#69.9$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#80.1$Semi-Supervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#19.5
2002.03651v4.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#82.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#93.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#10.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#81.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#90.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#8.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#81.6
1907.08895v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#78.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#91.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#2.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#77.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#84.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.9$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#77.75
1804.03131v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#75.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#89.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#8.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#79.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#93.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#7.8$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#77.4
1709.06750v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#76.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#90.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#12.1$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#76.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#85.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#10.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#76.05$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#67.4$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#81.4$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#6.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#66.7$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#77.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#5.1$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#67.05
1612.05478v3.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#70.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#82.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#12.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#65.6$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#69.0$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#14.4$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#67.9
1708.05137v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#70.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#86.3$Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#11.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#62.5$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#73.2$Semi-Supervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#14.7$Semi-Supervised Video Object Segmentation#DAVIS 2016#J&F#66.35
1907.02731v5.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#86.3$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#78.8
1809.01123v1.pdf	Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J&F score#62.4$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#J score#56.5$Semi-Supervised Video Object Segmentation#DAVIS 2017 val (no extra training data)#F score#68.2
1909.13258v2.pdf	Unsupervised Video Object Segmentation#SegTrack v2#Mean IoU#70.9$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#80.6$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#95.2$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#2.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#75.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#87.9$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#2.4$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#78.05
1704.05737v2.pdf	Unsupervised Video Object Segmentation#SegTrack v2#Mean IoU#57.3$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#75.9$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#89.1$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#0$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#72.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#83.4$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#1.3$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#74
2209.09341v2.pdf	Unsupervised Video Object Segmentation#SegTrack v2#Jaccard (Mean)#74.9$Unsupervised Video Object Segmentation#FBMS#Jaccard (Mean)#70$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#80.2
2005.13039v2.pdf	Unsupervised Video Object Segmentation#FBMS#Jaccard (Mean)#77.6$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#58.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#56.6$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#63.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#60.2$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#63.1
2001.05425v1.pdf	Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#J&F#58.0$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Mean)#54.0$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Recall)#62.9$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#Jaccard (Decay)#3.5$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Mean)#62.0$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Recall)#66.6$Unsupervised Video Object Segmentation#DAVIS 2017 (test-dev)#F-measure (Decay)#6.6$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#67.9$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#66.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#76.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#69.3$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#76.9
2111.07774v1.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#85.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#86.5$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#86.0
2003.04253v3.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#82.4$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#94.5$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#80.7$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#90.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#4.5$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#81.55
1910.10895v1.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#81.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#90.9$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#2.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#80.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#85.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#0.6$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#81.1
2003.08429v3.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#J&F#80.6$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#64.7$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#61.5$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Recall)#70.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#67.8$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Recall)#75.5$Video Instance Segmentation#YouTube-VIS validation#mask AP#34.6$Video Instance Segmentation#YouTube-VIS validation#AP50#55.8$Video Instance Segmentation#YouTube-VIS validation#AP75#37.9$Video Instance Segmentation#YouTube-VIS validation#AR1#34.4$Video Instance Segmentation#YouTube-VIS validation#AR10#41.6$Video Instance Segmentation#YouTube-VIS validation#mask AP#30.6$Video Instance Segmentation#YouTube-VIS validation#AP50#50.7
2008.07012v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#J&F#80.0
1810.07733v4.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#77.2$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#87.8$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#77.4$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#84.4$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#3.3$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#77.3
1712.01127v1.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#78.2$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#89.1$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#4.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#75.9$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#84.7$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#3.5$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#77.05
1901.03360v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#J&F#71.5
1810.03783v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#73.9$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#88.5$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#0.6$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#68.0$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#80.6$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#0.7$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#70.95
1701.05384v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#70.7$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#83.5$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#1.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#65.3$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#73.8$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#1.8$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#68
1612.07217v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#70.0$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#85.0$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#1.3$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#65.9$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#79.2$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#2.5$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#67.95
1811.07958v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Mean)#62.6$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Recall)#80.3$Unsupervised Video Object Segmentation#DAVIS 2016#Jaccard (Decay)#7.1$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Mean)#59.6$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Recall)#74.5$Unsupervised Video Object Segmentation#DAVIS 2016#F-measure (Decay)#6.4$Unsupervised Video Object Segmentation#DAVIS 2016#J&F#61.1
2103.13746v2.pdf	Unsupervised Video Object Segmentation#DAVIS 2017 (val)#J&F#70.4$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#Jaccard (Mean)#67.0$Unsupervised Video Object Segmentation#DAVIS 2017 (val)#F-measure (Mean)#73.8
1907.11315v1.pdf	Video Salient Object Detection#MCL#S-Measure#0.642$Video Salient Object Detection#MCL#MAX E-MEASURE#0.760$Video Salient Object Detection#MCL#AVERAGE MAE#0.113$Video Salient Object Detection#SegTrack v2#S-Measure#0.644$Video Salient Object Detection#SegTrack v2#AVERAGE MAE#0.116$Video Salient Object Detection#SegTrack v2#max E-measure#0.768
1809.01125v1.pdf	Video Salient Object Detection#DAVSOD-Difficult20#S-Measure#0.561$Video Salient Object Detection#DAVSOD-Difficult20#max E-measure#0.635$Video Salient Object Detection#DAVSOD-Difficult20#Average MAE#0.140
2203.04708v2.pdf	Video Salient Object Detection#FBMS-59#S-Measure#0.894$Video Salient Object Detection#FBMS-59#AVERAGE MAE#0.028$Video Salient Object Detection#FBMS-59#MAX F-MEASURE#0.890$Video Salient Object Detection#ViSal#S-Measure#0.953$Video Salient Object Detection#ViSal#max E-measure#0.987$Video Salient Object Detection#ViSal#Average MAE#0.011$Video Salient Object Detection#DAVIS-2016#S-Measure#0.918$Video Salient Object Detection#DAVIS-2016#MAX F-MEASURE#0.906$Video Salient Object Detection#DAVIS-2016#AVERAGE MAE#0.015$Video Salient Object Detection#SegTrack v2#S-Measure#0.892$Video Salient Object Detection#SegTrack v2#MAX F-MEASURE#0.863$Video Salient Object Detection#SegTrack v2#AVERAGE MAE#0.022$Co-Salient Object Detection#CoSal2015#MAE#0.064$Co-Salient Object Detection#CoSal2015#S-measure#0.860$Co-Salient Object Detection#CoSal2015#max F-measure#0.865$Co-Salient Object Detection#CoSal2015#max E-measure#0.906$Co-Salient Object Detection#CoSal2015#mean E-measure#0.889$Co-Salient Object Detection#CoSal2015#mean F-measure#0.848$Co-Salient Object Detection#CoCA#S-measure#0.697$Co-Salient Object Detection#CoCA#max F-measure#0.571$Co-Salient Object Detection#CoCA#mean E-measure#0.762$Co-Salient Object Detection#CoCA#Mean F-measure#0.555$Co-Salient Object Detection#CoCA#max E-measure#0.782$Co-Salient Object Detection#CoCA#MAE#0.095$Co-Salient Object Detection#iCoSeg#S-measure#0.924$Co-Salient Object Detection#iCoSeg#MAE#0.029$Co-Salient Object Detection#iCoSeg#max E-measure#0.969$Co-Salient Object Detection#iCoSeg#max F-measure#0.953$Co-Salient Object Detection#CoSOD3k#S-measure#0.819$Co-Salient Object Detection#CoSOD3k#max E-measure#0.874$Co-Salient Object Detection#CoSOD3k#max F-measure#0.797$Co-Salient Object Detection#CoSOD3k#MAE#0.073$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.855$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.783
1908.04051v2.pdf	Video Salient Object Detection#FBMS-59#S-Measure#0.870$Video Salient Object Detection#FBMS-59#AVERAGE MAE#0.054$Video Salient Object Detection#FBMS-59#MAX F-MEASURE#0.861$Video Salient Object Detection#VOS-T#S-Measure#0.872$Video Salient Object Detection#VOS-T#max E-measure#0.856$Video Salient Object Detection#VOS-T#Average MAE#0.049$Video Salient Object Detection#DAVIS-2016#S-Measure#0.884$Video Salient Object Detection#DAVIS-2016#MAX F-MEASURE#0.859$Video Salient Object Detection#DAVIS-2016#AVERAGE MAE#0.028
2104.10386v1.pdf	Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.820$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.829$Interactive Video Object Segmentation#DAVIS 2017#AUC-J&F#0.856$Interactive Video Object Segmentation#DAVIS 2017#J&F@60s#0.866
2007.08139v1.pdf	Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.778$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.790$Interactive Video Object Segmentation#DAVIS 2017#AUC-J&F#0.809$Interactive Video Object Segmentation#DAVIS 2017#J&F@60s#0.827
2103.03821v2.pdf	Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.759$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.767$Interactive Video Object Segmentation#DAVIS 2017#AUC-J&F#0.782$Interactive Video Object Segmentation#DAVIS 2017#J&F@60s#0.790
2003.13246v1.pdf	Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.749$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.761
1904.09791v2.pdf	Interactive Video Object Segmentation#DAVIS 2017#AUC-J#0.691$Interactive Video Object Segmentation#DAVIS 2017#J@60s#0.734
2209.06430v2.pdf	Video Retrieval#ActivityNet#text-to-video R@1#61.4$Video Retrieval#ActivityNet#text-to-video R@5#85.7$Video Retrieval#ActivityNet#text-to-video R@10#92.6$Video Retrieval#ActivityNet#text-to-video Median Rank#1$Video Retrieval#LSMDC#text-to-video R@1#30.7$Video Retrieval#LSMDC#text-to-video R@5#51.4$Video Retrieval#LSMDC#text-to-video R@10#60.6$Video Retrieval#LSMDC#text-to-video Median Rank#5$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#57.7$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#80.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#88.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#1.0$Video Retrieval#DiDeMo#text-to-video R@1#55.3$Video Retrieval#DiDeMo#text-to-video R@5#82$Video Retrieval#DiDeMo#text-to-video R@10#89.3$Video Retrieval#DiDeMo#text-to-video Median Rank#1
2204.03382v6.pdf	Video Retrieval#ActivityNet#text-to-video R@1#59.2$Video Retrieval#ActivityNet#text-to-video R@1#57.3$Video Retrieval#ActivityNet#text-to-video R@5#84.8$Video Retrieval#ActivityNet#text-to-video R@10#93.1$Video Retrieval#ActivityNet#text-to-video Median Rank#1$Video Retrieval#ActivityNet#text-to-video Mean Rank#4.0$Video Retrieval#ActivityNet#video-to-text R@1#57.7$Video Retrieval#ActivityNet#video-to-text R@5#85.7$Video Retrieval#ActivityNet#video-to-text R@10#93.9$Video Retrieval#ActivityNet#video-to-text Median Rank#1$Video Retrieval#ActivityNet#video-to-text Mean Rank#3.4$Video Retrieval#LSMDC#text-to-video R@1#40.4$Video Retrieval#LSMDC#text-to-video R@1#29.7$Video Retrieval#LSMDC#text-to-video R@5#46.4$Video Retrieval#LSMDC#text-to-video R@10#55.4$Video Retrieval#LSMDC#text-to-video Median Rank#7$Video Retrieval#LSMDC#video-to-text R@1#30.1$Video Retrieval#LSMDC#video-to-text R@5#47.5$Video Retrieval#LSMDC#video-to-text R@10#55.7$Video Retrieval#LSMDC#video-to-text Median Rank#7$Video Retrieval#LSMDC#text-to-video Mean Rank#56.4$Video Retrieval#LSMDC#video-to-text Mean Rank#48.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#62.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#55.0$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#55.5$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#78.4$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#85.8$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#1.0$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#7.7$Video Retrieval#DiDeMo#text-to-video R@1#52.7$Video Retrieval#DiDeMo#text-to-video R@1#52.1$Video Retrieval#DiDeMo#text-to-video R@5#78.2$Video Retrieval#DiDeMo#text-to-video R@10#85.7$Video Retrieval#DiDeMo#text-to-video Median Rank#1$Video Retrieval#DiDeMo#text-to-video Mean Rank#11.1$Video Retrieval#DiDeMo#video-to-text R@1#54.8$Video Retrieval#DiDeMo#video-to-text R@10#87.2$Video Retrieval#DiDeMo#video-to-text Median Rank#1$Video Retrieval#DiDeMo#video-to-text Mean Rank#7.1$Video Retrieval#DiDeMo#video-to-text R@5#79.9$Video Retrieval#MSVD#text-to-video R@1#59.0$Video Retrieval#MSVD#text-to-video R@1#58.2$Video Retrieval#MSVD#text-to-video R@5#83.5$Video Retrieval#MSVD#text-to-video R@10#90.1$Video Retrieval#MSVD#text-to-video Median Rank#1$Video Retrieval#MSVD#text-to-video Mean Rank#7.8$Video Retrieval#MSVD#video-to-text R@1#69.1$Video Retrieval#MSVD#video-to-text R@5#91.5$Video Retrieval#MSVD#video-to-text R@10#95.0$Video Retrieval#MSVD#video-to-text Median Rank#1.0$Video Retrieval#MSVD#video-to-text Mean Rank#3.8
2109.04290v3.pdf	Video Retrieval#ActivityNet#text-to-video R@1#51.0$Video Retrieval#ActivityNet#text-to-video R@5#77.7$Video Retrieval#ActivityNet#text-to-video R@10#87.6$Video Retrieval#ActivityNet#text-to-video Median Rank#1$Video Retrieval#ActivityNet#text-to-video Mean Rank#6.3$Video Retrieval#MSR-VTT#text-to-video R@1#32.9$Video Retrieval#MSR-VTT#text-to-video R@5#58.3$Video Retrieval#MSR-VTT#text-to-video R@10#68.4$Video Retrieval#MSR-VTT#text-to-video Mean Rank#42.6$Video Retrieval#MSR-VTT#text-to-video Median Rank#3$Video Retrieval#MSR-VTT#video-to-text R@1#59.8$Video Retrieval#MSR-VTT#video-to-text R@5#86.2$Video Retrieval#MSR-VTT#video-to-text R@10#92.8$Video Retrieval#MSR-VTT#video-to-text Median Rank#1$Video Retrieval#MSR-VTT#video-to-text Mean Rank#3.8$Video Retrieval#LSMDC#text-to-video R@1#25.9$Video Retrieval#LSMDC#text-to-video R@5#46.1$Video Retrieval#LSMDC#text-to-video R@10#53.7$Video Retrieval#LSMDC#text-to-video Mean Rank#54.4$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#12.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#48.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#75.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#85.3$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#50.3$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#74.6$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#83.8$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#9.9$Video Retrieval#DiDeMo#text-to-video R@1#43.8$Video Retrieval#DiDeMo#text-to-video R@5#71.4$Video Retrieval#DiDeMo#text-to-video R@10#79.9$Video Retrieval#DiDeMo#text-to-video Median Rank#2.0$Video Retrieval#DiDeMo#text-to-video Mean Rank#16.3$Video Retrieval#DiDeMo#video-to-text R@1#45.5$Video Retrieval#DiDeMo#video-to-text R@10#80.5$Video Retrieval#DiDeMo#video-to-text Median Rank#2$Video Retrieval#DiDeMo#video-to-text Mean Rank#10.2$Video Retrieval#MSVD#text-to-video R@1#51.8$Video Retrieval#MSVD#text-to-video R@5#87.6$Video Retrieval#MSVD#text-to-video R@10#87.6$Video Retrieval#MSVD#text-to-video Median Rank#1$Video Retrieval#MSVD#text-to-video Mean Rank#8.9$Video Retrieval#MSVD#video-to-text R@1#69.3$Video Retrieval#MSVD#video-to-text R@5#90.6$Video Retrieval#MSVD#video-to-text R@10#94.6$Video Retrieval#MSVD#video-to-text Median Rank#1$Video Retrieval#MSVD#video-to-text Mean Rank#3.1
2206.03428v1.pdf	Video Retrieval#ActivityNet#text-to-video R@1#47.1$Video Retrieval#ActivityNet#text-to-video R@5#75.5$Video Retrieval#ActivityNet#text-to-video R@10#85.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#41.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#68.7$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#77$Video Retrieval#DiDeMo#text-to-video R@1#53.9$Video Retrieval#DiDeMo#text-to-video R@5#79.4$Video Retrieval#DiDeMo#text-to-video R@10#86.9$Video Retrieval#SSv2-template retrieval#text-to-video R@1#77.6$Video Retrieval#SSv2-template retrieval#text-to-video R@5#96$Video Retrieval#SSv2-template retrieval#text-to-video R@10#98.9$Video Retrieval#SSv2-label retrieval#text-to-video R@1#47.4$Video Retrieval#SSv2-label retrieval#text-to-video R@5#75.9$Video Retrieval#SSv2-label retrieval#text-to-video R@10#84$Video Question Answering#MSRVTT-MC#Accuracy#93.7$Video Question Answering#MSRVTT-MC#Accuracy#92.1$Video Question Answering#ActivityNet-QA#Accuracy#0.441$Video Question Answering#ActivityNet-QA#Accuracy#0.431$Video Question Answering#MSRVTT-QA#Accuracy#43.9$Video Question Answering#MSRVTT-QA#Accuracy#43.5
2205.00823v1.pdf	Video Retrieval#ActivityNet#text-to-video R@1#46.2$Video Retrieval#ActivityNet#text-to-video R@5#77.0$Video Retrieval#ActivityNet#text-to-video R@10#87.6$Video Retrieval#ActivityNet#text-to-video Median Rank#2$Video Retrieval#ActivityNet#text-to-video Mean Rank#5.7$Video Retrieval#ActivityNet#video-to-text R@1#46.7$Video Retrieval#ActivityNet#video-to-text R@5#77.1$Video Retrieval#ActivityNet#video-to-text R@10#88.0$Video Retrieval#ActivityNet#video-to-text Median Rank#2$Video Retrieval#ActivityNet#video-to-text Mean Rank#5.5$Video Retrieval#LSMDC#text-to-video R@1#24.2$Video Retrieval#LSMDC#text-to-video R@5#46.2$Video Retrieval#LSMDC#text-to-video R@10#55.9$Video Retrieval#LSMDC#text-to-video Median Rank#8$Video Retrieval#LSMDC#video-to-text R@1#24.5$Video Retrieval#LSMDC#video-to-text R@5#46.4$Video Retrieval#LSMDC#video-to-text R@10#55.8$Video Retrieval#LSMDC#video-to-text Median Rank#7$Video Retrieval#LSMDC#text-to-video Mean Rank#47.3$Video Retrieval#LSMDC#video-to-text Mean Rank#41.3$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#13.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#48.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#73.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#82.0$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#47.7$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#75.0$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#83.3$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#10.2$Video Retrieval#MSVD#text-to-video R@1#50.6$Video Retrieval#MSVD#text-to-video R@5#80.3$Video Retrieval#MSVD#text-to-video R@10#88.4$Video Retrieval#MSVD#text-to-video Median Rank#1$Video Retrieval#MSVD#text-to-video Mean Rank#8.4$Video Retrieval#MSVD#video-to-text R@1#68.4$Video Retrieval#MSVD#video-to-text R@5#90.1$Video Retrieval#MSVD#video-to-text R@10#95.0$Video Retrieval#MSVD#video-to-text Median Rank#1$Video Retrieval#MSVD#video-to-text Mean Rank#3.0
2207.07285v2.pdf	Video Retrieval#ActivityNet#text-to-video R@1#46.2$Video Retrieval#ActivityNet#text-to-video R@5#75.5$Video Retrieval#ActivityNet#text-to-video Mean Rank#6.8$Video Retrieval#ActivityNet#video-to-text R@1#46.4$Video Retrieval#ActivityNet#video-to-text R@5#75.9$Video Retrieval#ActivityNet#video-to-text Mean Rank#6.4$Video Retrieval#LSMDC#text-to-video R@1#26.1$Video Retrieval#LSMDC#text-to-video Median Rank#48.4$Video Retrieval#LSMDC#video-to-text R@1#46.2$Video Retrieval#LSMDC#video-to-text Median Rank#26.9$Video Retrieval#LSMDC#text-to-video Mean Rank#46.7$Video Retrieval#LSMDC#video-to-text Mean Rank#41.9$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#12.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#49.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#75.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#84.8$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2.0$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#48.9$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#76.8$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#84.5$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2.0$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#8.1$Video Retrieval#DiDeMo#text-to-video R@1#47.8$Video Retrieval#DiDeMo#text-to-video R@5#79.3$Video Retrieval#DiDeMo#text-to-video Mean Rank#12.6$Video Retrieval#DiDeMo#video-to-text R@1#47.8$Video Retrieval#DiDeMo#video-to-text R@10#76.8$Video Retrieval#DiDeMo#video-to-text Mean Rank#10.5$Video Retrieval#MSVD#text-to-video R@1#50.4$Video Retrieval#MSVD#text-to-video R@5#80.6$Video Retrieval#MSVD#text-to-video Mean Rank#8.4$Video Retrieval#MSVD#video-to-text R@1#66.8$Video Retrieval#MSVD#video-to-text R@10#90.4$Video Retrieval#MSVD#video-to-text Mean Rank#4.2
2104.08860v2.pdf	Video Retrieval#ActivityNet#text-to-video R@1#40.5$Video Retrieval#ActivityNet#text-to-video R@5#73.4$Video Retrieval#ActivityNet#text-to-video R@50#98.2$Video Retrieval#ActivityNet#text-to-video Median Rank#2$Video Retrieval#ActivityNet#text-to-video Mean Rank#7.5$Video Retrieval#LSMDC#text-to-video R@1#21.6$Video Retrieval#LSMDC#text-to-video R@5#41.8$Video Retrieval#LSMDC#text-to-video R@10#49.8$Video Retrieval#LSMDC#text-to-video Mean Rank#58.0$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#15.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#44.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#71.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#81.6$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#42.7$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#70.9$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#80.6$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2$Video Retrieval#DiDeMo#text-to-video R@1#43.4$Video Retrieval#DiDeMo#text-to-video R@5#70.2$Video Retrieval#DiDeMo#text-to-video R@10#80.6$Video Retrieval#DiDeMo#text-to-video Median Rank#2$Video Retrieval#DiDeMo#text-to-video Mean Rank#17.5$Video Retrieval#MSVD#text-to-video R@1#46.2$Video Retrieval#MSVD#text-to-video R@5#76.1$Video Retrieval#MSVD#text-to-video R@10#84.6$Video Retrieval#MSVD#text-to-video Median Rank#2$Video Retrieval#MSVD#text-to-video Mean Rank#10.0$Video Retrieval#MSVD#video-to-text R@1#62.0$Video Retrieval#MSVD#video-to-text R@5#87.3$Video Retrieval#MSVD#video-to-text R@10#92.6$Video Retrieval#MSVD#video-to-text Median Rank#1
2007.10639v1.pdf	Video Retrieval#ActivityNet#text-to-video R@1#28.7$Video Retrieval#ActivityNet#text-to-video R@5#61.4$Video Retrieval#ActivityNet#text-to-video R@50#94.5$Video Retrieval#ActivityNet#text-to-video Median Rank#3.3$Video Retrieval#ActivityNet#text-to-video Mean Rank#16$Video Retrieval#ActivityNet#text-to-video R@1#22.7$Video Retrieval#ActivityNet#text-to-video R@5#54.2$Video Retrieval#ActivityNet#text-to-video R@50#93.2$Video Retrieval#ActivityNet#text-to-video Median Rank#5$Video Retrieval#ActivityNet#text-to-video Mean Rank#20.8$Video Retrieval#LSMDC#text-to-video R@1#13.5$Video Retrieval#LSMDC#text-to-video R@5#29.9$Video Retrieval#LSMDC#text-to-video R@10#40.1$Video Retrieval#LSMDC#text-to-video Median Rank#19.3$Video Retrieval#LSMDC#text-to-video R@1#13.2$Video Retrieval#LSMDC#text-to-video R@5#29.2$Video Retrieval#LSMDC#text-to-video R@10#38.8$Video Retrieval#LSMDC#text-to-video Median Rank#21$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#24.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#26.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#57.1$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#69.6$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#4$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#26.7$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#24.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#54.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#67.1
2110.11298v1.pdf	Video Retrieval#ActivityNet#text-to-video R@1#25.4$Video Retrieval#ActivityNet#text-to-video R@5#59.1$Video Retrieval#ActivityNet#video-to-text R@1#26.1$Video Retrieval#ActivityNet#video-to-text R@5#60$Video Retrieval#MSR-VTT#text-to-video R@1#26$Video Retrieval#MSR-VTT#text-to-video R@5#56.7$Video Retrieval#MSR-VTT#text-to-video Median Rank#3$Video Retrieval#MSR-VTT#video-to-text R@1#26.7$Video Retrieval#MSR-VTT#video-to-text R@5#56.5$Video Retrieval#MSR-VTT#video-to-text Median Rank#3$Video Retrieval#LSMDC#text-to-video R@1#14.9$Video Retrieval#LSMDC#text-to-video R@5#33.2$Video Retrieval#LSMDC#video-to-text R@1#15.3$Video Retrieval#LSMDC#video-to-text R@5#34.1
1907.13487v2.pdf	Video Retrieval#ActivityNet#text-to-video R@1#20.5$Video Retrieval#ActivityNet#text-to-video R@5#47.7$Video Retrieval#ActivityNet#text-to-video R@10#63.9$Video Retrieval#ActivityNet#text-to-video R@50#91.4$Video Retrieval#ActivityNet#text-to-video Median Rank#6$Video Retrieval#ActivityNet#text-to-video Mean Rank#23.1$Video Retrieval#MSR-VTT#text-to-video R@1#10.0$Video Retrieval#MSR-VTT#text-to-video R@5#29.0$Video Retrieval#MSR-VTT#text-to-video R@10#41.2$Video Retrieval#MSR-VTT#text-to-video Mean Rank#86.8$Video Retrieval#MSR-VTT#text-to-video Median Rank#16$Video Retrieval#MSR-VTT#video-to-text R@1#15.6$Video Retrieval#MSR-VTT#video-to-text R@5#40.9$Video Retrieval#MSR-VTT#video-to-text R@10#55.2$Video Retrieval#MSR-VTT#video-to-text Median Rank#8.3$Video Retrieval#MSR-VTT#video-to-text Mean Rank#38.1$Video Retrieval#LSMDC#text-to-video R@1#11.2$Video Retrieval#LSMDC#text-to-video R@5#26.9$Video Retrieval#LSMDC#text-to-video R@10#34.8$Video Retrieval#LSMDC#text-to-video Median Rank#25$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#28.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#20.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#48.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#62.4$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#6$Video Retrieval#DiDeMo#text-to-video R@1#16.1$Video Retrieval#DiDeMo#text-to-video R@5#41.1$Video Retrieval#DiDeMo#text-to-video R@50#82.7$Video Retrieval#DiDeMo#text-to-video R@10#54.4$Video Retrieval#DiDeMo#text-to-video Median Rank#8.3$Video Retrieval#DiDeMo#text-to-video Mean Rank#43.7$Video Retrieval#MSVD#text-to-video R@1#19.8$Video Retrieval#MSVD#text-to-video R@5#49.0$Video Retrieval#MSVD#text-to-video R@10#63.8$Video Retrieval#MSVD#text-to-video Median Rank#6.0$Video Retrieval#MSVD#text-to-video R@50#89.0$Video Retrieval#MSVD#text-to-video Mean Rank#23.1
2112.12777v3.pdf	Video Retrieval#QuerYD#text-to-video R@1#15.1$Video Retrieval#LSMDC#text-to-video R@1#22.4$Video Retrieval#LSMDC#text-to-video R@5#40.1$Video Retrieval#LSMDC#text-to-video R@10#49.5$Video Retrieval#LSMDC#text-to-video Median Rank#11.0$Video Retrieval#VATEX#text-to-video R@1#58.8$Video Retrieval#VATEX#text-to-video R@10#93.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#47.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#73.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#83.0$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#DiDeMo#text-to-video R@1#43.5$Video Retrieval#DiDeMo#text-to-video R@5#71.4$Video Retrieval#DiDeMo#text-to-video R@10#80.9$Video Retrieval#DiDeMo#text-to-video Median Rank#2.0$Video Retrieval#MSVD#text-to-video R@1#48.0$Video Retrieval#MSVD#text-to-video R@5#77.9$Video Retrieval#MSVD#text-to-video R@10#86.2$Video Retrieval#MSVD#text-to-video Median Rank#2.0$Metric Learning#Stanford Online Products#R@1#78.1
2203.07086v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#33.7$Video Retrieval#MSR-VTT#text-to-video R@5#60.5$Video Retrieval#MSR-VTT#text-to-video R@10#70.8$Video Retrieval#MSR-VTT#text-to-video Mean Rank#37.8$Video Retrieval#MSR-VTT#text-to-video Median Rank#3.0$Video Retrieval#LSMDC#text-to-video R@1#26.9$Video Retrieval#LSMDC#text-to-video R@5#46.7$Video Retrieval#LSMDC#text-to-video R@10#55.9$Video Retrieval#LSMDC#text-to-video Median Rank#6.7$Video Retrieval#LSMDC#text-to-video Mean Rank#48.0$Video Retrieval#MSVD#text-to-video R@1#56.8$Video Retrieval#MSVD#text-to-video R@5#83.1$Video Retrieval#MSVD#text-to-video R@10#89.2$Video Retrieval#MSVD#text-to-video Median Rank#1.0$Video Retrieval#MSVD#text-to-video Mean Rank#8.8$Video Retrieval#YouCook2#text-to-video Median Rank#3.0$Video Retrieval#YouCook2#text-to-video R@1#32.0$Video Retrieval#YouCook2#text-to-video R@10#74.8$Video Retrieval#YouCook2#text-to-video R@5#64.0$Video Retrieval#YouCook2#text-to-video Mean Rank#12.7$Video Retrieval#TGIF#text-to-video R@1#25.5$Video Retrieval#TGIF#text-to-video R@5#46.1$Video Retrieval#TGIF#text-to-video R@10#55.7$Video Retrieval#TGIF#text-to-video Mean Rank#94.1$Video Retrieval#TGIF#text-to-video Median Rank#7.0
2111.05610v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#33.1$Video Retrieval#MSR-VTT#text-to-video R@5#58.9$Video Retrieval#MSR-VTT#text-to-video R@10#68.9$Video Retrieval#MSR-VTT#text-to-video Mean Rank#44.7$Video Retrieval#MSR-VTT#text-to-video Median Rank#3$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#12.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#52.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#78.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#86.5$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#1$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#54.1$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#77.4$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#85.7$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#1$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#9.0
2104.00650v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#32.5$Video Retrieval#MSR-VTT#text-to-video R@5#61.5$Video Retrieval#MSR-VTT#text-to-video R@10#71.2$Video Retrieval#LSMDC#text-to-video R@1#15.0$Video Retrieval#LSMDC#text-to-video R@5#30.8$Video Retrieval#LSMDC#text-to-video R@10#39.8$Video Retrieval#LSMDC#text-to-video Median Rank#20.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#31.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#59.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#70.5$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#3$Video Retrieval#DiDeMo#text-to-video R@1#31.0$Video Retrieval#DiDeMo#text-to-video R@5#59.8$Video Retrieval#DiDeMo#text-to-video R@10#72.4$Video Retrieval#DiDeMo#text-to-video Median Rank#3$Video Retrieval#MSVD#text-to-video R@1#33.7$Video Retrieval#MSVD#text-to-video R@5#64.7$Video Retrieval#MSVD#text-to-video R@10#76.3$Video Retrieval#MSVD#text-to-video Median Rank#3
2204.07441v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#32.1$Video Retrieval#MSR-VTT#text-to-video R@5#60.8$Video Retrieval#MSR-VTT#text-to-video R@10#70.2$Video Retrieval#MSR-VTT#text-to-video Median Rank#3$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#36.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#63.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#73.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2
2106.11097v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#29.8$Video Retrieval#MSR-VTT#text-to-video R@5#55.5$Video Retrieval#MSR-VTT#text-to-video R@10#66.2$Video Retrieval#MSR-VTT#text-to-video Mean Rank#45.4$Video Retrieval#MSR-VTT#text-to-video Median Rank#4$Video Retrieval#MSR-VTT#video-to-text R@1#54.6$Video Retrieval#MSR-VTT#video-to-text R@5#82.1$Video Retrieval#MSR-VTT#video-to-text R@10#90.8$Video Retrieval#MSR-VTT#video-to-text Median Rank#1$Video Retrieval#MSR-VTT#video-to-text Mean Rank#5.3$Video Retrieval#VATEX#text-to-video R@1#57.3$Video Retrieval#VATEX#text-to-video R@50#95.5$Video Retrieval#VATEX#text-to-video R@10#90$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#14.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#45.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#72.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#81.7$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#43.3$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#72.3$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#82.1$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#10.2
2104.08271v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#29.6$Video Retrieval#MSR-VTT#text-to-video R@5#61.6$Video Retrieval#MSR-VTT#text-to-video R@10#74.2$Video Retrieval#DiDeMo#text-to-video R@1#21.6$Video Retrieval#DiDeMo#text-to-video R@5#48.6$Video Retrieval#DiDeMo#text-to-video R@10#62.9
2112.01832v3.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#29.1$Video Retrieval#MSR-VTT#text-to-video R@5#54.9$Video Retrieval#MSR-VTT#text-to-video R@10#65.8$Video Retrieval#VATEX#text-to-video R@1#59.1$Video Retrieval#VATEX#text-to-video R@50#96.3$Video Retrieval#VATEX#text-to-video R@10#91.7$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#45.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#71.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#82$Video Retrieval#MSVD#text-to-video R@1#45.4$Video Retrieval#MSVD#text-to-video R@5#76.0$Video Retrieval#MSVD#text-to-video R@10#84.6$Video Retrieval#TGIF#text-to-video R@1#24.5$Video Retrieval#TGIF#text-to-video R@5#45.0$Video Retrieval#TGIF#text-to-video R@10#54.5$Ad-hoc video search#TRECVID-AVS19 (V3C1)#infAP#0.192$Ad-hoc video search#TRECVID-AVS17 (IACC.3)#infAP#0.290$Ad-hoc video search#TRECVID-AVS20 (V3C1)#infAP#0.265$Ad-hoc video search#TRECVID-AVS18 (IACC.3)#infAP#0.147$Ad-hoc video search#TRECVID-AVS16 (IACC.3)#infAP#0.222
2103.10699v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#23.1$Video Retrieval#MSR-VTT#text-to-video R@5#49.8$Video Retrieval#MSR-VTT#text-to-video R@10#61.8$Video Retrieval#MSR-VTT#text-to-video Mean Rank#52.8$Video Retrieval#MSR-VTT#text-to-video Median Rank#6$Video Retrieval#LSMDC#text-to-video R@1#18.8$Video Retrieval#LSMDC#text-to-video R@5#38.5$Video Retrieval#LSMDC#text-to-video R@10#47.9$Video Retrieval#LSMDC#text-to-video Median Rank#12.3$Video Retrieval#LSMDC#text-to-video Mean Rank#58.0$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#16.5$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#38.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#69.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#79.7$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2
2102.12443v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#21.4$Video Retrieval#MSR-VTT#text-to-video R@5#41.1$Video Retrieval#MSR-VTT#text-to-video R@10#50.4$Video Retrieval#MSR-VTT#text-to-video Median Rank#10$Video Retrieval#MSR-VTT#video-to-text R@1#40.3$Video Retrieval#MSR-VTT#video-to-text R@5#69.7$Video Retrieval#MSR-VTT#video-to-text R@10#79.2$Video Retrieval#MSR-VTT#video-to-text Median Rank#2$Video Retrieval#LSMDC#text-to-video R@1#11.3$Video Retrieval#LSMDC#text-to-video R@5#22.7$Video Retrieval#LSMDC#text-to-video R@10#29.2$Video Retrieval#LSMDC#text-to-video Median Rank#56.5$Video Retrieval#LSMDC#video-to-text R@1#6.8$Video Retrieval#LSMDC#video-to-text R@5#16.4$Video Retrieval#LSMDC#video-to-text R@10#22.1$Video Retrieval#LSMDC#video-to-text Median Rank#73$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#31.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#53.7$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#64.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#4$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#27.2$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#51.7$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#62.6$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#5$Video Retrieval#MSVD#text-to-video R@1#37$Video Retrieval#MSVD#text-to-video R@5#64.1$Video Retrieval#MSVD#text-to-video R@10#73.8$Video Retrieval#MSVD#text-to-video Median Rank#3.0$Video Retrieval#MSVD#video-to-text R@1#59.9$Video Retrieval#MSVD#video-to-text R@5#85.2$Video Retrieval#MSVD#video-to-text R@10#90.7$Video Retrieval#MSVD#video-to-text Median Rank#1
2002.06353v3.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#21.2$Video Retrieval#MSR-VTT#text-to-video R@5#49.6$Video Retrieval#MSR-VTT#text-to-video R@10#63.1$Video Retrieval#MSR-VTT#text-to-video Median Rank#6$Video Retrieval#YouCook2#text-to-video Median Rank#4$Video Retrieval#YouCook2#text-to-video R@1#28.9$Video Retrieval#YouCook2#text-to-video R@10#70.0$Video Retrieval#YouCook2#text-to-video R@5#57.6$Action Segmentation#COIN#Frame accuracy#70.0$Video Captioning#YouCook2#BLEU-3#23.87$Video Captioning#YouCook2#BLEU-4#17.35$Video Captioning#YouCook2#METEOR#22.35$Video Captioning#YouCook2#ROUGE-L#46.52$Video Captioning#YouCook2#CIDEr#1.81
2206.12845v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#10.7$Video Retrieval#MSR-VTT#text-to-video R@5#29.6$Video Retrieval#MSR-VTT#text-to-video R@10#41.2$Video Retrieval#MSR-VTT#text-to-video Median Rank#17$Video Retrieval#YouCook2#text-to-video Median Rank#53$Video Retrieval#YouCook2#text-to-video R@1#6.3$Video Retrieval#YouCook2#text-to-video R@10#25.2$Video Retrieval#YouCook2#text-to-video R@5#16.9
1808.02559v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#10.2$Video Retrieval#MSR-VTT#text-to-video R@10#43.2$Video Retrieval#MSR-VTT#text-to-video Median Rank#13$Video Retrieval#MSR-VTT#video-to-text R@5#31.2$Video Retrieval#LSMDC#text-to-video R@1#9.1$Video Retrieval#LSMDC#text-to-video R@5#21.2$Video Retrieval#LSMDC#text-to-video R@10#34.1$Video Retrieval#LSMDC#text-to-video Median Rank#36$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#10.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#31.2$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#43.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#13
1612.06950v2.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#4.7$Video Retrieval#MSR-VTT#text-to-video R@10#24.1$Video Retrieval#MSR-VTT#text-to-video Median Rank#41$Video Retrieval#MSR-VTT#video-to-text R@5#16.6
1609.08124v1.pdf	Video Retrieval#MSR-VTT#text-to-video R@1#4.2$Video Retrieval#MSR-VTT#text-to-video R@10#19.9$Video Retrieval#MSR-VTT#text-to-video Median Rank#55$Video Retrieval#MSR-VTT#video-to-text R@5#12.9
2203.15086v1.pdf	Video Retrieval#LSMDC#text-to-video R@1#25.2$Video Retrieval#LSMDC#text-to-video R@5#43.7$Video Retrieval#LSMDC#text-to-video R@10#53.5$Video Retrieval#LSMDC#text-to-video Median Rank#8.0$Video Retrieval#LSMDC#video-to-text R@1#22.7$Video Retrieval#LSMDC#video-to-text R@5#42.6$Video Retrieval#LSMDC#video-to-text R@10#51.2$Video Retrieval#LSMDC#video-to-text Median Rank#10.0$Video Retrieval#LSMDC#text-to-video Mean Rank#53.2$Video Retrieval#LSMDC#video-to-text Mean Rank#47.4$Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#14.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#46.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#72.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#82.2$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#2$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#44.4$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#73.3$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#84.0$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#2.0$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#9.0$Video Retrieval#MSVD#text-to-video R@1#47.2$Video Retrieval#MSVD#text-to-video R@5#77.4$Video Retrieval#MSVD#text-to-video R@10#86.0$Video Retrieval#MSVD#text-to-video Median Rank#2.0$Video Retrieval#MSVD#text-to-video Mean Rank#9.3$Video Retrieval#MSVD#video-to-text R@1#66.4$Video Retrieval#MSVD#video-to-text R@5#90.0$Video Retrieval#MSVD#video-to-text R@10#94.2$Video Retrieval#MSVD#video-to-text Median Rank#1.0$Video Retrieval#MSVD#video-to-text Mean Rank#3.3
1804.02516v2.pdf	Video Retrieval#LSMDC#text-to-video R@1#10.1$Video Retrieval#LSMDC#text-to-video R@5#25.6$Video Retrieval#LSMDC#text-to-video R@10#34.6$Video Retrieval#LSMDC#text-to-video Median Rank#27
1707.09074v1.pdf	Video Retrieval#LSMDC#text-to-video R@1#7.3$Video Retrieval#LSMDC#text-to-video R@5#19.2$Video Retrieval#LSMDC#text-to-video R@10#27.1$Video Retrieval#LSMDC#text-to-video Median Rank#52
1610.02947v3.pdf	Video Retrieval#LSMDC#text-to-video R@1#5.1$Video Retrieval#LSMDC#text-to-video R@5#16.3$Video Retrieval#LSMDC#text-to-video R@10#25.2$Video Retrieval#LSMDC#text-to-video Median Rank#46
2207.07852v1.pdf	Video Retrieval#VATEX#text-to-video R@1#59.1$Video Retrieval#VATEX#text-to-video R@10#95.2$Video Retrieval#VATEX#text-to-video R@5#90.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#54.0$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#79.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#87.4
2203.07111v1.pdf	Video Retrieval#MSR-VTT-1kA#text-to-video Mean Rank#11.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#53.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#80.3$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#87.6$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#1$Video Retrieval#MSR-VTT-1kA#video-to-text R@1#56.2$Video Retrieval#MSR-VTT-1kA#video-to-text R@5#79.9$Video Retrieval#MSR-VTT-1kA#video-to-text R@10#87.4$Video Retrieval#MSR-VTT-1kA#video-to-text Median Rank#1.0$Video Retrieval#MSR-VTT-1kA#video-to-text Mean Rank#7.6$Video Retrieval#DiDeMo#text-to-video R@1#49.0$Video Retrieval#DiDeMo#text-to-video R@5#76.5$Video Retrieval#DiDeMo#text-to-video R@10#84.5$Video Retrieval#DiDeMo#text-to-video Median Rank#2.0$Video Retrieval#DiDeMo#text-to-video Mean Rank#11.5$Video Retrieval#DiDeMo#video-to-text R@1#49.9$Video Retrieval#DiDeMo#video-to-text R@10#83.3$Video Retrieval#DiDeMo#video-to-text Median Rank#2$Video Retrieval#DiDeMo#video-to-text Mean Rank#7.9
2203.07303v1.pdf	Video Retrieval#MSR-VTT-1kA#text-to-video R@1#37.9$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#68.1$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#77.1$Visual Question Answering#MSVD-QA#Accuracy#0.483$Visual Question Answering#MSRVTT-QA#Accuracy#0.443
2201.04850v2.pdf	Video Retrieval#MSR-VTT-1kA#text-to-video R@1#37.6$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#64.8$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#75.1$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#3$Video Retrieval#MSR-VTT-1kA#text-to-video R@1#26$Video Retrieval#MSR-VTT-1kA#text-to-video R@5#46.4$Video Retrieval#MSR-VTT-1kA#text-to-video R@10#56.4$Video Retrieval#MSR-VTT-1kA#text-to-video Median Rank#7
2204.00598v2.pdf	Video Retrieval#MSR-VTT-1kA#video-to-text R@1#42.8
2112.09583v2.pdf	Video Retrieval#DiDeMo#text-to-video R@1#35.9$Video Retrieval#DiDeMo#text-to-video R@5#67.5$Video Retrieval#DiDeMo#text-to-video R@10#78.8$Video Retrieval#DiDeMo#text-to-video Median Rank#3$Visual Question Answering#MSVD-QA#Accuracy#0.459$Visual Question Answering#MSRVTT-QA#Accuracy#0.421
2103.05457v1.pdf	Video Retrieval#DiDeMo#text-to-video R@1#16.3$Video Retrieval#DiDeMo#text-to-video R@10#56.5$Video Retrieval#DiDeMo#text-to-video Median Rank#8$Video Retrieval#DiDeMo#text-to-video Mean Rank#40.2$Video Retrieval#DiDeMo#video-to-text R@1#15$Video Retrieval#DiDeMo#video-to-text R@10#54.9$Video Retrieval#DiDeMo#video-to-text Median Rank#8$Video Retrieval#DiDeMo#video-to-text Mean Rank#39.6$Video Retrieval#Charades-STA#text-to-video R@1#3.6$Video Retrieval#Charades-STA#text-to-video R@10#15.9$Video Retrieval#Charades-STA#text-to-video Median Rank#77$Video Retrieval#Charades-STA#text-to-video Mean Rank#162.3$Video Retrieval#Charades-STA#video-to-text R@1#3.2$Video Retrieval#Charades-STA#video-to-text R@10#14.9$Video Retrieval#Charades-STA#video-to-text Median Rank#83$Video Retrieval#Charades-STA#video-to-text Mean Rank#164.6$Video Retrieval#RUDDER#text-to-video R@1#4.48$Video Retrieval#RUDDER#text-to-video R@5#13.47$Video Retrieval#RUDDER#text-to-video R@10#20.02$Video Retrieval#RUDDER#text-to-video R@50#42.49$Video Retrieval#RUDDER#text-to-video Mean Rank#66$Video Retrieval#RUDDER#text-to-video Median Rank#153.14$Video Retrieval#RUDDER#video-to-text R@1#3.87$Video Retrieval#RUDDER#video-to-text R@5#12.13$Video Retrieval#RUDDER#video-to-text R@10#19.09$Video Retrieval#RUDDER#video-to-text Mean Rank#73$Video Retrieval#RUDDER#video-to-text Median Rank#151.63
2005.00200v2.pdf	Video Retrieval#TVR#R@1#4.34$Video Retrieval#TVR#R@10#13.97$Video Retrieval#TVR#R@100#21.78$Video Question Answering#TVQA#Accuracy#74.24$Video Question Answering#Howto100M-QA#Accuracy#77.75
2001.09099v2.pdf	Video Retrieval#TVR#R@1#2.70$Video Retrieval#TVR#R@10#8.93$Video Retrieval#TVR#R@100#15.34
2003.03186v3.pdf	Video Retrieval#MSVD#text-to-video R@1#20.3$Video Retrieval#MSVD#text-to-video R@5#49.0$Video Retrieval#MSVD#text-to-video R@10#63.3$Video Retrieval#MSVD#text-to-video Median Rank#6.0$Video Retrieval#MSVD#text-to-video R@50#--$Video Retrieval#MSVD#text-to-video Mean Rank#--$Visual Question Answering#MSVD-QA#Accuracy#0.351$Visual Question Answering#MSRVTT-QA#Accuracy#0.35
2011.00597v1.pdf	Video Retrieval#YouCook2#text-to-video Median Rank#9$Video Retrieval#YouCook2#text-to-video R@1#16.7$Video Retrieval#YouCook2#text-to-video R@10#52.3$Video Captioning#YouCook2#BLEU-3#17.97$Video Captioning#YouCook2#BLEU-4#11.30$Video Captioning#YouCook2#METEOR#19.85$Video Captioning#YouCook2#ROUGE-L#37.94$Video Captioning#YouCook2#CIDEr#0.57$Video Captioning#ActivityNet Captions#BLEU-3#17.43$Video Captioning#ActivityNet Captions#ROUGE-L#31.45$Video Captioning#ActivityNet Captions#METEOR#15.99$Video Captioning#ActivityNet Captions#BLEU4#10.85$Video Captioning#ActivityNet Captions#CIDEr#28.19
2206.12849v1.pdf	Video Retrieval#YouCook2#text-to-video Median Rank#77$Video Retrieval#YouCook2#text-to-video R@1#5.3$Video Retrieval#YouCook2#text-to-video R@10#20.8$Video Retrieval#YouCook2#text-to-video R@5#14.5
2204.00486v4.pdf	Boundary Grounding#Kinetics-GEB+#F1@0.1s#4.28$Boundary Grounding#Kinetics-GEB+#F1@0.2s#8.54$Boundary Grounding#Kinetics-GEB+#F1@0.5s#18.33$Boundary Grounding#Kinetics-GEB+#F1@1.0s#31.04$Boundary Grounding#Kinetics-GEB+#F1@1.5s#40.48$Boundary Grounding#Kinetics-GEB+#F1@2.0s#47.86$Boundary Grounding#Kinetics-GEB+#F1@2.5s#54.81$Boundary Grounding#Kinetics-GEB+#F1@3.0s#61.45$Boundary Grounding#Kinetics-GEB+#F1@Avg#33.35$Boundary Captioning#Kinetics-GEB+#CIDEr#74.71$Boundary Captioning#Kinetics-GEB+#SPICE#19.52$Boundary Captioning#Kinetics-GEB+#ROUGE-L#28.15$Text to Video Retrieval#Kinetics-GEB+#mAP#23.39$Text to Video Retrieval#Kinetics-GEB+#text-to-video R@1#12.8$Text to Video Retrieval#Kinetics-GEB+#text-to-video R@5#34.81$Text to Video Retrieval#Kinetics-GEB+#text-to-video R@10#45.66$Text to Video Retrieval#Kinetics-GEB+#text-to-video R@50#68.1
2011.13367v3.pdf	Replay Grounding#SoccerNet-v2#Average-AP#41.8$Replay Grounding#SoccerNet-v2#Average-AP#24.3$Action Spotting#SoccerNet-v2#Average-mAP#39.9$Action Spotting#SoccerNet-v2#Average-mAP#31.4$Camera shot segmentation#SoccerNet-v2#mIoU#47.3$Camera shot segmentation#SoccerNet-v2#mIoU#35.8$Camera shot boundary detection#SoccerNet-v2#mAP#78.5$Camera shot boundary detection#SoccerNet-v2#mAP#64.0$Camera shot boundary detection#SoccerNet-v2#mAP#62.2$Camera shot boundary detection#SoccerNet-v2#mAP#59.6
1906.00377v1.pdf	Video Classification#YouTube-8M#Hit@1#87.7
1902.10640v1.pdf	Video Classification#YouTube-8M#Hit@1#86.8$Video Classification#YouTube-8M#Global Average Precision#81.1$Video Classification#YouTube-8M#mAP#41.4
1609.08675v1.pdf	Video Classification#YouTube-8M#Hit@1#70.1$Video Classification#YouTube-8M#PERR#29.1$Video Classification#YouTube-8M#Hit@5#84.8
2105.05226v1.pdf	Video Classification#Home Action Genome#Accuracy (%)#24.7
2101.04884v2.pdf	Video Classification#Multimodal PISA#Accuracy (%)#73.95$Audio Classification#Multimodal PISA#Accuracy (%)#64.50$Skills Assessment#Multimodal PISA#Accuracy (%)#74.60
2001.02408v3.pdf	Video Prediction#Colored dSprites#MSE#4.5$Video Prediction#Sprites#MSE#61.6
2206.12126v1.pdf	Video Prediction#Moving MNIST#MSE#19.8$Video Prediction#Moving MNIST#MAE#60.3$Video Prediction#Moving MNIST#SSIM#0.957
2206.05099v1.pdf	Video Prediction#Moving MNIST#MSE#23.8$Video Prediction#Moving MNIST#SSIM#0.948$Video Prediction#Human3.6M#SSIM#0.904
2003.01460v2.pdf	Video Prediction#Moving MNIST#MSE#24.4$Video Prediction#Moving MNIST#MAE#70.3$Video Prediction#Moving MNIST#SSIM#0.947$Video Prediction#Human3.6M#SSIM#0.901$Video Prediction#Human3.6M#MSE#369$Video Prediction#Human3.6M#MAE#1620$Video Prediction#SynpickVP#MSE#57.31$Video Prediction#SynpickVP#PSNR#26.84$Video Prediction#SynpickVP#SSIM#0.877$Video Prediction#SynpickVP#LPIPS#0.053$Weather Forecasting#SEVIR#MSE#4.8165$Weather Forecasting#SEVIR#mCSI#0.3940
2203.09303v3.pdf	Video Prediction#Moving MNIST#MSE#34.44$Video Prediction#Moving MNIST#SSIM#0.975$Video Prediction#Moving MNIST#LPIPS#0.024$Video Prediction#Moving MNIST#PSNR#26.82$Video Prediction#KTH#LPIPS#0.029$Video Prediction#KTH#PSNR#27.81$Video Prediction#KTH#SSIM#0.951$Video Prediction#KTH#MSE#23.18$Video Prediction#SynpickVP#MSE#53.09$Video Prediction#SynpickVP#PSNR#27.89$Video Prediction#SynpickVP#SSIM#0.881$Video Prediction#SynpickVP#LPIPS#0.033
2104.00924v1.pdf	Video Prediction#Moving MNIST#MSE#41.5$Video Prediction#Moving MNIST#SSIM#0.924$Video Prediction#Moving MNIST#LPIPS#0.047$Video Prediction#KTH#LPIPS#159.8$Video Prediction#KTH#PSNR#27.5$Video Prediction#KTH#SSIM#0.879$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40
1811.07490v3.pdf	Video Prediction#Moving MNIST#MSE#44.2$Video Prediction#Moving MNIST#MAE#101.1$Video Prediction#Moving MNIST#SSIM#0.910$Video Prediction#Moving MNIST#MSE#52.0$Video Prediction#Moving MNIST#MAE#116.5$Video Prediction#Moving MNIST#SSIM#0.874$Video Prediction#Human3.6M#SSIM#0.790$Video Prediction#Human3.6M#MSE#429.9$Video Prediction#Human3.6M#MAE#1782.8
1804.06300v2.pdf	Video Prediction#Moving MNIST#MSE#46.5$Video Prediction#Moving MNIST#MAE#106.8$Video Prediction#Moving MNIST#SSIM#0.898$Video Prediction#KTH#PSNR#28.47$Video Prediction#KTH#SSIM#0.865$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20$Video Prediction#SynpickVP#MSE#51.73$Video Prediction#SynpickVP#PSNR#27.50$Video Prediction#SynpickVP#SSIM#0.894$Video Prediction#SynpickVP#LPIPS#0.053
2103.09504v4.pdf	Video Prediction#Moving MNIST#MSE#48.4$Video Prediction#Moving MNIST#SSIM#0.891$Video Prediction#Moving MNIST#LPIPS#0.071$Video Prediction#KTH#LPIPS#0.139$Video Prediction#KTH#PSNR#28.37$Video Prediction#KTH#SSIM#0.839$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20$Weather Forecasting#SEVIR#MSE#3.9014$Weather Forecasting#SEVIR#mCSI#0.4080
1506.04214v2.pdf	Video Prediction#Moving MNIST#MSE#103.3$Video Prediction#Moving MNIST#MAE#182.9$Video Prediction#Moving MNIST#SSIM#0.707$Video Prediction#KTH#LPIPS#0.231$Video Prediction#KTH#PSNR#23.58$Video Prediction#KTH#SSIM#0.712$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
2107.13170v1.pdf	Video Prediction#KTH#LPIPS#0.092$Video Prediction#KTH#PSNR#27.11$Video Prediction#KTH#FVD#144.2$Video Prediction#KTH#SSIM#0.837$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40$Video Prediction#KTH#Params (M)#2.0$Video Prediction#KTH#Train#10
1804.01523v1.pdf	Video Prediction#KTH#LPIPS#0.116$Video Prediction#KTH#PSNR#26.00$Video Prediction#KTH#FVD#145.7$Video Prediction#KTH#SSIM#0.806$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40$Video Prediction#KTH#Params (M)#7.3$Video Prediction#KTH#Train#10$Video Prediction#KTH#LPIPS#0.126$Video Prediction#KTH#PSNR#23.79$Video Prediction#KTH#FVD#183.7$Video Prediction#KTH#SSIM#0.699$Video Prediction#KTH#Params (M)#17.6$Video Prediction#KTH#LPIPS#0.1120±0.0039$Video Prediction#KTH#PSNR#26.51±0.29$Video Prediction#KTH#FVD#374 ± 3$Video Prediction#KTH#SSIM#0.7564±0.0062$Video Prediction#KTH#Pred#30$Video Prediction#KTH#PSNR#27.77$Video Prediction#KTH#SSIM#0.852$Video Prediction#KTH#Pred#20$Video Generation#BAIR Robot Pushing#FVD score#116.4$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#Pred#14$Video Generation#BAIR Robot Pushing#Train#14$Video Generation#BAIR Robot Pushing#FVD score#143.43$Video Generation#BAIR Robot Pushing#SSIM#0.795±0.07$Video Generation#BAIR Robot Pushing#LPIPS#0.062±0.03$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#10$Video Generation#BAIR Robot Pushing#FVD score#152±9$Video Generation#BAIR Robot Pushing#SSIM#0.7887±0.0092$Video Generation#BAIR Robot Pushing#PSNR#18.44±0.25$Video Generation#BAIR Robot Pushing#LPIPS#0.0634±0.0026$Video Generation#BAIR Robot Pushing#Train#12$Video Generation#BAIR Robot Pushing#SSIM#0.815$Video Generation#BAIR Robot Pushing#PSNR#19.09
1802.07687v2.pdf	Video Prediction#KTH#LPIPS#0.129$Video Prediction#KTH#PSNR#23.91$Video Prediction#KTH#FVD#157.9$Video Prediction#KTH#SSIM#0.800$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40$Video Prediction#KTH#Params (M)#22.8$Video Prediction#KTH#Train#10$Video Prediction#KTH#LPIPS#0.0923±0.0038$Video Prediction#KTH#PSNR#28.06±0.29$Video Prediction#KTH#FVD#377 ± 6$Video Prediction#KTH#SSIM#0.8438±0.0054$Video Prediction#KTH#Pred#30$Video Prediction#SynpickVP#MSE#51.82$Video Prediction#SynpickVP#PSNR#27..38$Video Prediction#SynpickVP#SSIM#0.886$Video Prediction#SynpickVP#LPIPS#0.066$Video Prediction#SynpickVP#MSE#60.60$Video Prediction#SynpickVP#PSNR#26.92$Video Prediction#SynpickVP#SSIM#0.879$Video Prediction#SynpickVP#LPIPS#0.068$Video Prediction#Cityscapes 128x128#FVD#1300.26$Video Prediction#Cityscapes 128x128#SSIM#0.574±0.08$Video Prediction#Cityscapes 128x128#LPIPS#0.549 ± 0.06$Video Prediction#Cityscapes 128x128#Cond.#2$Video Prediction#Cityscapes 128x128#Pred#28$Video Prediction#Cityscapes 128x128#Train#10$Video Generation#BAIR Robot Pushing#FVD score#255±4$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.8058±0.0088$Video Generation#BAIR Robot Pushing#PSNR#18.95±0.26$Video Generation#BAIR Robot Pushing#LPIPS#0.0609±0.0034$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#12$Video Generation#BAIR Robot Pushing#FVD score#256.62$Video Generation#BAIR Robot Pushing#SSIM#0.816±0.07$Video Generation#BAIR Robot Pushing#LPIPS#0.061±0.03$Video Generation#BAIR Robot Pushing#Train#10$Video Generation#BAIR Robot Pushing#FVD score#315.5$Video Generation#BAIR Robot Pushing#Pred#14$Video Generation#BAIR Robot Pushing#Train#14
1710.11252v2.pdf	Video Prediction#KTH#LPIPS#0.232$Video Prediction#KTH#PSNR#25.87$Video Prediction#KTH#FVD#209.5$Video Prediction#KTH#SSIM#0.782$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40$Video Prediction#KTH#Params (M)#8.3$Video Prediction#KTH#Train#10$Video Prediction#KTH#LPIPS#0.260$Video Prediction#KTH#PSNR#25.70$Video Prediction#KTH#FVD#253.5$Video Prediction#KTH#SSIM#0.772$Video Prediction#KTH#LPIPS#0.2049±0.0053$Video Prediction#KTH#PSNR#28.19±0.31$Video Prediction#KTH#FVD#636 ± 1$Video Prediction#KTH#SSIM#0.838$Video Prediction#KTH#Pred#30$Video Generation#BAIR Robot Pushing#FVD score#262.5$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#Pred#14$Video Generation#BAIR Robot Pushing#Train#14$Video Generation#BAIR Robot Pushing#FVD score#965±17$Video Generation#BAIR Robot Pushing#SSIM#0.8169±0.0086$Video Generation#BAIR Robot Pushing#PSNR#20.39±0.27$Video Generation#BAIR Robot Pushing#LPIPS#0.0912±0.0053$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#12
2002.09219v4.pdf	Video Prediction#KTH#LPIPS#0.0736±0.0029$Video Prediction#KTH#PSNR#29.69±032$Video Prediction#KTH#FVD#222 ± 3$Video Prediction#KTH#SSIM#0.8697±0.0046$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#30$Video Prediction#KTH#Train#10$Video Prediction#KTH 64x64 cond10 pred30#FVD#222$Video Prediction#Cityscapes 128x128#SSIM#0.603±0.016$Video Prediction#Cityscapes 128x128#LPIPS#0.447±0.014$Video Prediction#Cityscapes 128x128#Cond.#10$Video Prediction#Cityscapes 128x128#PSNR#20.97±0.43$Video Prediction#Cityscapes 128x128#Pred#20$Video Generation#BAIR Robot Pushing#FVD score#162 ± 4$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.8196±0.0084$Video Generation#BAIR Robot Pushing#PSNR#19.59±0.27$Video Generation#BAIR Robot Pushing#LPIPS#0.0574±0.0032$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#12
2108.02760v1.pdf	Video Prediction#KTH#LPIPS#0.0795±0.0034$Video Prediction#KTH#PSNR#29.39±0.30$Video Prediction#KTH#FVD#228 ± 5$Video Prediction#KTH#SSIM#0.8646±0.0050$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#30$Video Prediction#KTH#Train#10$Video Prediction#Cityscapes 128x128#SSIM#0.649±0.025$Video Prediction#Cityscapes 128x128#LPIPS#0.2941±0.022$Video Prediction#Cityscapes 128x128#Cond.#10$Video Prediction#Cityscapes 128x128#PSNR#21.73±0.76$Video Prediction#Cityscapes 128x128#Pred#20$Video Generation#BAIR Robot Pushing#FVD score#245 ± 5$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.8175±0.084$Video Generation#BAIR Robot Pushing#PSNR#19.67±0.26$Video Generation#BAIR Robot Pushing#LPIPS#0.0596±0.0032$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#10
1906.07889v3.pdf	Video Prediction#KTH#LPIPS#0.124$Video Prediction#KTH#PSNR#24.29$Video Prediction#KTH#FVD#395.0$Video Prediction#KTH#SSIM#0.766$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#40$Video Prediction#KTH#Params (M)#2.3$Video Prediction#KTH#Train#10
2002.09905v2.pdf	Video Prediction#KTH#PSNR#29.85$Video Prediction#KTH#SSIM#0.893$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20$Video Generation#BAIR Robot Pushing#FVD score#159.6$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.844$Video Generation#BAIR Robot Pushing#PSNR#21.02$Video Generation#BAIR Robot Pushing#LPIPS#0.0936$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#14
1804.04810v2.pdf	Video Prediction#KTH#PSNR#27.08$Video Prediction#KTH#SSIM#0.876$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
2002.09131v5.pdf	Video Prediction#KTH#LPIPS#0.196$Video Prediction#KTH#PSNR#27.62$Video Prediction#KTH#SSIM#0.815$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
1706.08033v2.pdf	Video Prediction#KTH#PSNR#26.29$Video Prediction#KTH#SSIM#0.806$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20$Video Prediction#KTH#PSNR#25.95$Video Prediction#KTH#SSIM#0.804
1605.09673v2.pdf	Video Prediction#KTH#PSNR#27.26$Video Prediction#KTH#SSIM#0.794$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
1706.03458v2.pdf	Video Prediction#KTH#PSNR#26.97$Video Prediction#KTH#SSIM#0.790$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
1712.00311v2.pdf	Video Prediction#KTH#PSNR#26.12$Video Prediction#KTH#SSIM#0.771$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20$Video Prediction#Human3.6M#SSIM#0.771$Video Prediction#Human3.6M#MSE#497.7$Video Prediction#Human3.6M#MAE#1901.1
1610.00527v1.pdf	Video Prediction#KTH#PSNR#23.76$Video Prediction#KTH#SSIM#0.746$Video Prediction#KTH#Cond#10$Video Prediction#KTH#Pred#20
2206.07696v2.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#16.46$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Generation#BAIR Robot Pushing#FVD score#84.20$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#20
2003.04035v3.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#25.74±0.66$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Prediction#Kinetics-600 12 frames, 64x64#IS#12.54±0.06$Video Generation#BAIR Robot Pushing#FVD score#103.3$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15
2107.08037v2.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#55±1$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Generation#BAIR Robot Pushing#FVD score#99 ± 2$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15
2103.01950v1.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#64.30±2.04$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#4$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#12
1907.06571v2.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#69.15±0.78$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Prediction#BAIR Robot Pushing#FVD#109.8$Video Generation#Kinetics-600 12 frames, 128x128#FID#2.16$Video Generation#BAIR Robot Pushing#FVD score#109.8$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15$Video Generation#Kinetics-600 12 frames, 64x64#FID#0.91$Video Generation#Kinetics-600 12 frames, 64x64#Inception Score#129.9$Video Generation#Kinetics-600 48 frames, 64x64#FID#12.92$Video Generation#Kinetics-600 48 frames, 64x64#Inception Score#219.05
1906.02634v3.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#170±5$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Generation#BAIR Robot Pushing#FVD score#94± 2$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15$Video Generation#BAIR Robot Pushing#Notes#FVD on only leftmost samples is 94, FVD on unrolled (all subsequences) is 96
2006.10704v1.pdf	Video Prediction#Kinetics-600 12 frames, 64x64#FVD#224.73$Video Prediction#Kinetics-600 12 frames, 64x64#Cond#5$Video Prediction#Kinetics-600 12 frames, 64x64#Pred#11$Video Generation#BAIR Robot Pushing#FVD score#125.76±2.90$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15$Video Generation#BAIR Robot Pushing#FVD score#320.9
2107.04619v1.pdf	Video Prediction#BAIR Robot Pushing#FVD#120.03$Video Generation#KTH#Diversity#0.483
2001.01328v6.pdf	Video Prediction#CMU Mocap-2#Test Error#4.03$Video Prediction#CMU Mocap-2#Test Error#5.98
1905.10994v2.pdf	Video Prediction#CMU Mocap-2#Test Error#8.09$Video Prediction#CMU Mocap-2#Test Error#10.06$Video Prediction#CMU Mocap-1#Test Error#15.99$Video Prediction#CMU Mocap-1#Test Error#93.07
2103.04174v3.pdf	Video Prediction#Cityscapes 128x128#FVD#418.00 ± 5.0$Video Prediction#Cityscapes 128x128#SSIM#0.740±0.4$Video Prediction#Cityscapes 128x128#LPIPS#0.193 ± 0.014$Video Prediction#Cityscapes 128x128#Cond.#2$Video Prediction#Cityscapes 128x128#Pred#28$Video Prediction#Cityscapes 128x128#Train#10
1904.12165v1.pdf	Video Prediction#Cityscapes 128x128#FVD#567.51$Video Prediction#Cityscapes 128x128#SSIM#0.628±0.1$Video Prediction#Cityscapes 128x128#LPIPS#0.264 ± .07$Video Prediction#Cityscapes 128x128#Cond.#2$Video Prediction#Cityscapes 128x128#Pred#28$Video Prediction#Cityscapes 128x128#Train#10$Video Generation#BAIR Robot Pushing#FVD score#143.4$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.822±0.06$Video Generation#BAIR Robot Pushing#LPIPS#0.055±0.03$Video Generation#BAIR Robot Pushing#Pred#28$Video Generation#BAIR Robot Pushing#Train#10$Video Generation#BAIR Robot Pushing#FVD score#149.22$Video Generation#BAIR Robot Pushing#SSIM#0.829±0.06$Video Generation#BAIR Robot Pushing#LPIPS#0.058±0.03
2011.03864v3.pdf	Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#15.20$Video Generation#UCF-101 16 frames, 64x64, Unconditional#FID#26512$Video Generation#UCF-101 16 frames, 128x128, Unconditional#Inception Score#21.02$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#21.02
1912.08860v1.pdf	Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#13.62$Video Generation#UCF-101 16 frames, 64x64, Unconditional#FID#8943$Video Generation#UCF-101 16 frames, 128x128, Unconditional#Inception Score#22.91$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#22.91
1707.04993v2.pdf	Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#12.42$Video Generation#BAIR Robot Pushing#FVD score#503$Video Generation#BAIR Robot Pushing#Cond#4$Video Generation#BAIR Robot Pushing#Pred#12$Video Generation#BAIR Robot Pushing#Train#12$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#12.42
1909.12400v1.pdf	Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#11.86$Video Generation#UCF-101 16 frames, 64x64, Unconditional#FVD#1277$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#11.86
1611.06624v3.pdf	Video Generation#UCF-101 16 frames, 64x64, Unconditional#Inception Score#11.85$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#11.85
2209.14792v1.pdf	Video Generation#UCF-101#Inception Score#82.55$Video Generation#UCF-101#FVD#81.25$Video Generation#UCF-101#Inception Score#33$Video Generation#UCF-101#FVD#367.23$Text-to-Video Generation#MSR-VTT#FID#13.17$Text-to-Video Generation#MSR-VTT#CLIPSIM#0.3049
1811.09245v2.pdf	Video Generation#UCF-101 16 frames, 128x128, Unconditional#Inception Score#28.87$Video Generation#UCF-101 16 frames, 128x128, Unconditional#Inception Score#24.34$Video Generation#UCF-101 16 frames, Unconditional, Single GPU#Inception Score#21.45
2104.10157v2.pdf	Video Generation#UCF-101 16 frames, 128x128, Unconditional#Inception Score#24.69$Video Generation#BAIR Robot Pushing#FVD score#103.3$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15
2205.09853v4.pdf	Video Generation#BAIR Robot Pushing#FVD score#87.9$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#SSIM#0.838$Video Generation#BAIR Robot Pushing#PSNR#19.1$Video Generation#BAIR Robot Pushing#Pred#14$Video Generation#BAIR Robot Pushing#Train#5$Video Generation#BAIR Robot Pushing#FVD score#89.5$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#SSIM#0.78$Video Generation#BAIR Robot Pushing#PSNR#16.9$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#FVD score#118.4$Video Generation#BAIR Robot Pushing#SSIM#0.745$Video Generation#BAIR Robot Pushing#PSNR#16.2$Video Generation#BAIR Robot Pushing#Pred#28
2106.13195v1.pdf	Video Generation#BAIR Robot Pushing#FVD score#93.6$Video Generation#BAIR Robot Pushing#Cond#1$Video Generation#BAIR Robot Pushing#Pred#15$Video Generation#BAIR Robot Pushing#Train#15$Video Generation#BAIR Robot Pushing#Notes#Uses 100 times more fake than real samples (atypical)
1903.01434v3.pdf	Video Generation#BAIR Robot Pushing#FVD score#131±5$Video Generation#BAIR Robot Pushing#Cond#3$Video Generation#BAIR Robot Pushing#Pred#14 (total 16)$Video Generation#BAIR Robot Pushing#Train#10
1605.07157v4.pdf	Video Generation#BAIR Robot Pushing#FVD score#296.5$Video Generation#BAIR Robot Pushing#Cond#2$Video Generation#BAIR Robot Pushing#Pred#14$Video Generation#BAIR Robot Pushing#Train#14
2210.02303v1.pdf	Video Generation#LAION-400M#CLIP#25.19$Video Generation#LAION-400M#CLIP R-Precision#92.12$Video Generation#LAION-400M#CLIP R-Precision#90.97$Video Generation#LAION-400M#CLIP#25.29$Video Generation#LAION-400M#CLIP R-Precision#90.88$Video Generation#LAION-400M#CLIP#25.03$Video Generation#LAION-400M#CLIP R-Precision#89.91$Video Generation#LAION-400M#CLIP R-Precision#89.68$Video Generation#LAION-400M#CLIP#25.12$Video Generation#LAION-400M#CLIP R-Precision#88.78
2207.12393v1.pdf	Unconditional Video Generation#CelebV-HQ#FVD#69.17$Unconditional Video Generation#CelebV-HQ#FID#17.95$Unconditional Video Generation#CelebV-HQ#FVD#72.98$Unconditional Video Generation#CelebV-HQ#FID#19.39$Unconditional Video Generation#CelebV-HQ#FVD#177.89$Unconditional Video Generation#CelebV-HQ#FID#52.95$Unconditional Video Generation#CelebV-HQ#FVD#212.41$Unconditional Video Generation#CelebV-HQ#FID#21.55
2103.16206v2.pdf	Video Frame Interpolation#MSU Video Frame Interpolation#SSIM#0.913$Video Frame Interpolation#MSU Video Frame Interpolation#LPIPS#0.061$Video Frame Interpolation#X4K1000FPS#PSNR#30.12$Video Frame Interpolation#X4K1000FPS#SSIM#0.870$Video Frame Interpolation#X4K1000FPS#tOF#2.15$Video Frame Interpolation#X4K1000FPS#PSNR#28.86$Video Frame Interpolation#X4K1000FPS#SSIM#0.858$Video Frame Interpolation#X4K1000FPS#tOF#2.67
2111.15483v2.pdf	Video Frame Interpolation#SNU-FILM (hard)#PSNR#31.698$Video Frame Interpolation#DAVIS#PSNR#28.287$Video Frame Interpolation#SNU-FILM (extreme)#PSNR#25.81$Video Frame Interpolation#UCF101#PSNR#33.384$Video Frame Interpolation#VFITex#PSNR#29.175$Video Frame Interpolation#SNU-FILM (medium)#PSNR#37.111$Video Frame Interpolation#SNU-FILM (easy)#PSNR#40.775
2203.00137v1.pdf	Video Frame Interpolation#SNU-FILM (hard)#PSNR#30.66$Video Frame Interpolation#SNU-FILM (hard)#SSIM#0.9373$Video Frame Interpolation#X4K1000FPS-2K#PSNR#30.05$Video Frame Interpolation#X4K1000FPS-2K#SSIM#0.8998$Video Frame Interpolation#SNU-FILM (extreme)#PSNR#25.44$Video Frame Interpolation#SNU-FILM (extreme)#SSIM#0.8638$Video Frame Interpolation#UCF101#PSNR#35.36$Video Frame Interpolation#UCF101#SSIM#0.9705$Video Frame Interpolation#Nvidia Dynamic Scene#PSNR#36.24$Video Frame Interpolation#Nvidia Dynamic Scene#SSIM#0.9839$Video Frame Interpolation#Vimeo90K#PSNR#35.73$Video Frame Interpolation#Vimeo90K#SSIM#0.9789$Video Frame Interpolation#Xiph 4k#PSNR#30.94$Video Frame Interpolation#Xiph 4k#SSIM#0.9389$Video Frame Interpolation#SNU-FILM (medium)#PSNR#35.94$Video Frame Interpolation#SNU-FILM (medium)#SSIM#0.9797$Video Frame Interpolation#SNU-FILM (easy)#PSNR#39.9$Video Frame Interpolation#SNU-FILM (easy)#SSIM#0.9910
2204.03513v1.pdf	Video Frame Interpolation#X4K1000FPS-2K#PSNR#32.07$Video Frame Interpolation#X4K1000FPS-2K#SSIM#0.923$Video Frame Interpolation#ATD-12K#PSNR#29.03$Video Frame Interpolation#ATD-12K#SSIM#0.959$Video Frame Interpolation#Xiph-2K#PSNR#36.45$Video Frame Interpolation#Xiph-2K#SSIM#0.967$Video Frame Interpolation#UCF101#PSNR#35.17$Video Frame Interpolation#UCF101#SSIM#0.97$Video Frame Interpolation#Vimeo90K#PSNR#35.4$Video Frame Interpolation#Vimeo90K#SSIM#0.978$Video Frame Interpolation#Vimeo90K#Speed (ms/f)#32 (Titan X)$Video Frame Interpolation#X4K1000FPS#PSNR#30.81$Video Frame Interpolation#X4K1000FPS#SSIM#0.912$Video Frame Interpolation#X4K1000FPS#Speed (ms/f)#200 (Titan X)$Video Frame Interpolation#Xiph-4K (Crop)#PSNR#33.93$Video Frame Interpolation#Xiph-4K (Crop)#SSIM#0.945
2205.14620v1.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#4.216$Video Frame Interpolation#UCF101#PSNR#35.42$Video Frame Interpolation#UCF101#SSIM#0.9698$Video Frame Interpolation#Vimeo90K#PSNR#36.20$Video Frame Interpolation#Vimeo90K#SSIM#0.9808$Video Frame Interpolation#Vimeo90K#Speed (ms/f)#16 (Tesla V100)
2003.05534v1.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#4.223$Video Frame Interpolation#Middlebury#SSIM#0.971$Video Frame Interpolation#Middlebury#PSNR#38.42$Video Frame Interpolation#UCF101#PSNR#35.39$Video Frame Interpolation#UCF101#SSIM#0.952$Video Frame Interpolation#Vimeo90K#PSNR#36.10$Video Frame Interpolation#Vimeo90K#SSIM#0.970
2007.12622v1.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#4.479$Video Frame Interpolation#UCF101#PSNR#35.15$Video Frame Interpolation#UCF101#SSIM#0.9689$Video Frame Interpolation#Vimeo90K#PSNR#35.01$Video Frame Interpolation#Vimeo90K#SSIM#0.9764
1904.00830v1.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#4.86$Video Frame Interpolation#UCF101#PSNR#34.99$Video Frame Interpolation#UCF101#SSIM#0.9683$Video Frame Interpolation#Vimeo90K#PSNR#34.71$Video Frame Interpolation#Vimeo90K#SSIM#0.9756$Video Frame Interpolation#X4K1000FPS#PSNR#27.52$Video Frame Interpolation#X4K1000FPS#SSIM#0.821$Video Frame Interpolation#X4K1000FPS#tOF#3.47$Video Frame Interpolation#X4K1000FPS#PSNR#26.78$Video Frame Interpolation#X4K1000FPS#SSIM#0.807$Video Frame Interpolation#X4K1000FPS#tOF#3.83
1810.08768.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#5.24
1711.09078v3.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#5.49$Video Frame Interpolation#Vimeo90K#PSNR#33.73
1708.01692v1.pdf	Video Frame Interpolation#Middlebury#Interpolation Error#5.61$Video Frame Interpolation#Vimeo90K#PSNR#33.80
2203.10291v1.pdf	Video Frame Interpolation#Middlebury#PSNR#38.83$Video Frame Interpolation#UCF101#PSNR#35.43$Video Frame Interpolation#UCF101#SSIM#0.979$Video Frame Interpolation#Vimeo90K#PSNR#36.76$Video Frame Interpolation#Vimeo90K#SSIM#0.9800
2103.10559v2.pdf	Video Frame Interpolation#Middlebury#SSIM#0.966$Video Frame Interpolation#Middlebury#PSNR#37.14$Video Frame Interpolation#Middlebury#LPIPS#0.007$Video Frame Interpolation#UCF101#PSNR#35.21$Video Frame Interpolation#UCF101#LPIPS#0.015$Video Frame Interpolation#Vimeo90K#PSNR#35.17$Video Frame Interpolation#Vimeo90K#LPIPS#0.010
2108.06815v1.pdf	Video Frame Interpolation#UCF101#PSNR#35.38$Video Frame Interpolation#UCF101#SSIM#0.9698$Video Frame Interpolation#Vimeo90K#PSNR#36.18$Video Frame Interpolation#Vimeo90K#SSIM#0.9805$Video Frame Interpolation#X4K1000FPS#PSNR#30.16$Video Frame Interpolation#X4K1000FPS#SSIM#0.8793
2207.06763v1.pdf	Video Frame Interpolation#UCF101#PSNR#35.36$Video Frame Interpolation#UCF101#SSIM#0.9695$Video Frame Interpolation#Vimeo90K#PSNR#35.88$Video Frame Interpolation#Vimeo90K#SSIM#0.9795$Video Frame Interpolation#X4K1000FPS#PSNR#31.63$Video Frame Interpolation#X4K1000FPS#SSIM#0.9185
1906.05928v3.pdf	Video Frame Interpolation#UCF101#PSNR (sRGB)#34.55
2203.14186v1.pdf	Video Frame Interpolation#Vid4 - 4x upscaling#PSNR#26.43$Video Frame Interpolation#Vid4 - 4x upscaling#SSIM#0.7994$Video Frame Interpolation#Vid4 - 4x upscaling#Parameters#7670000$Video Frame Interpolation#Vid4 - 4x upscaling#PSNR#26.37$Video Frame Interpolation#Vid4 - 4x upscaling#SSIM#0.7978$Video Frame Interpolation#Vid4 - 4x upscaling#Parameters#6080000$Video Frame Interpolation#Vid4 - 4x upscaling#PSNR#26.29$Video Frame Interpolation#Vid4 - 4x upscaling#SSIM#0.7941$Video Frame Interpolation#Vid4 - 4x upscaling#Parameters#4490000$Space-time Video Super-resolution#Vimeo90K-Medium#PSNR#35.66$Space-time Video Super-resolution#Vimeo90K-Medium#SSIM#0.9381$Space-time Video Super-resolution#Vimeo90K-Medium#PSNR#35.62$Space-time Video Super-resolution#Vimeo90K-Medium#SSIM#0.9377$Space-time Video Super-resolution#Vimeo90K-Medium#PSNR#35.43$Space-time Video Super-resolution#Vimeo90K-Medium#SSIM#0.9358$Space-time Video Super-resolution#Vimeo90K-Fast#PSNR#36.80$Space-time Video Super-resolution#Vimeo90K-Fast#SSIM#0.9403$Space-time Video Super-resolution#Vimeo90K-Fast#PSNR#36.78$Space-time Video Super-resolution#Vimeo90K-Fast#SSIM#0.9401$Space-time Video Super-resolution#Vimeo90K-Fast#PSNR#36.58$Space-time Video Super-resolution#Vimeo90K-Fast#SSIM#0.9381
2002.11616v1.pdf	Video Frame Interpolation#Vid4 - 4x upscaling#PSNR#26.31$Video Frame Interpolation#Vid4 - 4x upscaling#SSIM#0.7976$Video Frame Interpolation#Vid4 - 4x upscaling#Parameters#11100000$Video Frame Interpolation#Vid4 - 4x upscaling#runtime (s)#0.0606
2111.08869v1.pdf	Video Frame Interpolation#Vimeo90K#PSNR#34.95$Video Frame Interpolation#Vimeo90K#SSIM#0.9749$Video Frame Interpolation#X4K1000FPS#PSNR#30.51$Video Frame Interpolation#X4K1000FPS#SSIM#0.8719
1810.08768v2.pdf	Video Frame Interpolation#Vimeo90K#PSNR#34.40
1907.10244v3.pdf	Video Frame Interpolation#X4K1000FPS#PSNR#25.81$Video Frame Interpolation#X4K1000FPS#SSIM#0.772$Video Frame Interpolation#X4K1000FPS#tOF#6.42$Video Frame Interpolation#X4K1000FPS#PSNR#23.90$Video Frame Interpolation#X4K1000FPS#SSIM#0.727$Video Frame Interpolation#X4K1000FPS#tOF#6.89
1812.01969v2.pdf	Video Summarization#TvSum#F1-score (Canonical)#61.42$Video Summarization#TvSum#F1-score (Augmented)#62.37$Video Summarization#SumMe#F1-score (Canonical)#49.71$Video Summarization#SumMe#F1-score (Augmented)#51.09
1708.09545v2.pdf	Video Summarization#TvSum#F1-score (Canonical)#61.0$Video Summarization#TvSum#F1-score (Augmented)#61.8$Video Summarization#SumMe#F1-score (Canonical)#44.4$Video Summarization#SumMe#F1-score (Augmented)#46.1
1811.09791v1.pdf	Unsupervised Video Summarization#SumMe#F1-score#51.3$Unsupervised Video Summarization#SumMe#training time (s)#568.6$Unsupervised Video Summarization#SumMe#Parameters (M)#100.76$Unsupervised Video Summarization#TvSum#F1-score#58.8$Unsupervised Video Summarization#TvSum#Spearman's Rho#0.034$Unsupervised Video Summarization#TvSum#Kendall's Tau#0.025$Unsupervised Video Summarization#TvSum#training time (s)#1797$Unsupervised Video Summarization#TvSum#Parameters (M)#100.76$Supervised Video Summarization#SumMe#F1-score (Canonical)#48.6$Supervised Video Summarization#SumMe#F1-score (Augmented)#48.7$Supervised Video Summarization#TvSum#F1-score (Canonical)#58.5$Supervised Video Summarization#TvSum#F1-score (Augmented)#57.1
1904.08265v1.pdf	Unsupervised Video Summarization#SumMe#F1-score#41.9$Unsupervised Video Summarization#TvSum#F1-score#57.6
1801.00054v3.pdf	Unsupervised Video Summarization#SumMe#F1-score#41.4$Unsupervised Video Summarization#SumMe#training time (s)#19.8$Unsupervised Video Summarization#SumMe#Parameters (M)#2.63$Unsupervised Video Summarization#TvSum#F1-score#57.6$Unsupervised Video Summarization#TvSum#Spearman's Rho#0.026$Unsupervised Video Summarization#TvSum#Kendall's Tau#0.020$Unsupervised Video Summarization#TvSum#training time (s)#58.8$Unsupervised Video Summarization#TvSum#Parameters (M)#2.63$Supervised Video Summarization#SumMe#F1-score (Canonical)#42.1$Supervised Video Summarization#SumMe#F1-score (Augmented)#43.9$Supervised Video Summarization#TvSum#F1-score (Canonical)#58.1$Supervised Video Summarization#TvSum#F1-score (Augmented)#59.8
2104.11530v2.pdf	Supervised Video Summarization#SumMe#F1-score (Canonical)#53.4$Supervised Video Summarization#SumMe#Kendall's Tau#0.2$Supervised Video Summarization#SumMe#Spearman's Rho#0.23$Supervised Video Summarization#SumMe#F1-score (Canonical)#51.6$Supervised Video Summarization#SumMe#F1-score (Canonical)#48$Supervised Video Summarization#SumMe#Kendall's Tau#0.16$Supervised Video Summarization#SumMe#Spearman's Rho#0.17$Supervised Video Summarization#SumMe#F1-score (Canonical)#44.9$Supervised Video Summarization#SumMe#F1-score (Canonical)#44.4$Supervised Video Summarization#SumMe#F1-score (Canonical)#43.1$Supervised Video Summarization#TvSum#F1-score (Canonical)#67.5$Supervised Video Summarization#TvSum#F1-score (Canonical)#63.9$Supervised Video Summarization#TvSum#F1-score (Canonical)#63.7$Supervised Video Summarization#TvSum#F1-score (Canonical)#61.5$Supervised Video Summarization#TvSum#F1-score (Canonical)#61$Supervised Video Summarization#TvSum#F1-score (Canonical)#59.8
2101.10030v3.pdf	Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#97.21$Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#84.03$Anomaly Detection In Surveillance Videos#UCF-Crime#Decidability#-$Anomaly Detection In Surveillance Videos#UCF-Crime#EER#-$Anomaly Detection In Surveillance Videos#XD-Violence#AP#77.81$Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#98.6
2104.01633v1.pdf	Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#94.83$Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#82.30
2104.07268v1.pdf	Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#91.24
2007.01548v2.pdf	Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#89.14$Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#80.10$Anomaly Detection In Surveillance Videos#UCF-Crime#Decidability#-$Anomaly Detection In Surveillance Videos#UCF-Crime#EER#-
1903.07256v1.pdf	Anomaly Detection In Surveillance Videos#ShanghaiTech Weakly Supervised#AUC-ROC#84.44$Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#93.2
2008.08944v3.pdf	Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#85.38
2002.01132v1.pdf	Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#76.67$Anomaly Detection In Surveillance Videos#UCF-Crime#Decidability#-$Anomaly Detection In Surveillance Videos#UCF-Crime#EER#-
1801.04264v3.pdf	Anomaly Detection In Surveillance Videos#UCF-Crime#ROC AUC#75.41$Anomaly Detection In Surveillance Videos#UCF-Crime#Decidability#0.613$Anomaly Detection In Surveillance Videos#UCF-Crime#EER#0.353$Anomaly Detection#UBnormal#AUC#50.3%$Anomaly Detection#UBnormal#RBDC#0.002$Anomaly Detection#UBnormal#TBDC#0.001$Abnormal Event Detection In Video#UBI-Fights#AUC#0.892$Abnormal Event Detection In Video#UBI-Fights#Decidability#0.804$Abnormal Event Detection In Video#UBI-Fights#EER#0.186$Semi-supervised Anomaly Detection#UBI-Fights#AUC#0.787$Semi-supervised Anomaly Detection#UBI-Fights#Decidability#0.738$Semi-supervised Anomaly Detection#UBI-Fights#EER#0.294
2207.05500v1.pdf	Anomaly Detection In Surveillance Videos#XD-Violence#AP#83.4
2007.04687v2.pdf	Anomaly Detection In Surveillance Videos#XD-Violence#AP#78.64
2208.05251v1.pdf	Anomaly Detection In Surveillance Videos#XD-Violence#AP#71.68
2008.12328v4.pdf	Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#98.7$Anomaly Detection#UCSD Peds2#AUC#98.7$Anomaly Detection#CUHK Avenue#AUC#92.3%$Anomaly Detection#CUHK Avenue#RBDC#65.05$Anomaly Detection#CUHK Avenue#TBDC#66.95$Anomaly Detection#ShanghaiTech#AUC#82.7%$Anomaly Detection#ShanghaiTech#RBDC#41.34$Anomaly Detection#ShanghaiTech#TBDC#78.79$Anomaly Detection#UBnormal#AUC#61.3%$Anomaly Detection#UBnormal#RBDC#25.43$Anomaly Detection#UBnormal#TBDC#56.27$Abnormal Event Detection In Video#UCSD Ped2#AUC#98.7%
2004.07941v1.pdf	Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#97.8
2011.07491v3.pdf	Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#97.5$Anomaly Detection#UCSD Peds2#AUC#97.5$Anomaly Detection#CUHK Avenue#AUC#91.5%$Anomaly Detection#CUHK Avenue#RBDC#57.00$Anomaly Detection#CUHK Avenue#TBDC#58.30$Anomaly Detection#ShanghaiTech#AUC#82.4%$Anomaly Detection#ShanghaiTech#RBDC#42.80$Anomaly Detection#ShanghaiTech#TBDC#83.90$Abnormal Event Detection In Video#UCSD Ped2#AUC#97.5%
2106.08613v4.pdf	Anomaly Detection In Surveillance Videos#UCSD Peds2#AUC#96.3
2207.06937v1.pdf	Video Denoising#Set8 sigma50#PSNR#30.06$Video Denoising#Set8 sigma40#PSNR#30.97$Video Denoising#CRVD#PSNR (Raw)#44.39$Video Denoising#CRVD#SSIM (Raw)#0.9894$Video Denoising#CRVD#PSNR (sRBG)#40.48$Video Denoising#CRVD#SSIM (sRGB)#0.9820$Video Denoising#DAVIS sigma40#PSNR#33.86$Video Denoising#DAVIS sigma50#PSNR#32.91
2011.15045v3.pdf	Video Denoising#Set8 sigma50#PSNR#29.89$Video Denoising#Set8 sigma20#PSNR#33.36$Video Denoising#Set8 sigma40#PSNR#30.82$Video Denoising#DAVIS sigma20#PSNR#35.16$Video Denoising#Set8 sigma30#PSNR#32.01$Video Denoising#DAVIS sigma40#PSNR#32.68$Video Denoising#DAVIS sigma50#PSNR#31.70$Video Denoising#DAVIS sigma30#PSNR#33.92
2103.13767v2.pdf	Video Denoising#Set8 sigma50#PSNR#29.66$Video Denoising#Set8 sigma20#PSNR#33.94$Video Denoising#Set8 sigma40#PSNR#30.7$Video Denoising#DAVIS sigma20#PSNR#36.82$Video Denoising#Set8 sigma10#PSNR#37.06$Video Denoising#DAVIS sigma10#PSNR#39.97$Video Denoising#Set8 sigma30#PSNR#32.05$Video Denoising#DAVIS sigma40#PSNR#33.34$Video Denoising#DAVIS sigma50#PSNR#32.2$Video Denoising#DAVIS sigma30#PSNR#34.79$Color Image Denoising#CBSD68 sigma25#PSNR#31.22$Color Image Denoising#CBSD68 sigma50#PSNR#27.93$Color Image Denoising#CBSD68 sigma15#PSNR#33.95
1906.11890v1.pdf	Video Denoising#Set8 sigma50#PSNR#29.56$Video Denoising#Set8 sigma20#PSNR#33.49$Video Denoising#Set8 sigma40#PSNR#30.55$Video Denoising#DAVIS sigma20#PSNR#35.7$Video Denoising#Set8 sigma10#PSNR#36.08$Video Denoising#DAVIS sigma10#PSNR#38.13$Video Denoising#Set8 sigma30#PSNR#31.79$Video Denoising#DAVIS sigma40#PSNR#32.86$Video Denoising#DAVIS sigma50#PSNR#31.85$Video Denoising#DAVIS sigma30#PSNR#34.08
1907.01361v2.pdf	Video Denoising#Set8 sigma50#PSNR#29.42$Video Denoising#Set8 sigma20#PSNR#33.37$Video Denoising#Set8 sigma40#PSNR#30.37$Video Denoising#DAVIS sigma20#PSNR#35.86$Video Denoising#Set8 sigma10#PSNR#36.43$Video Denoising#DAVIS sigma10#PSNR#38.97$Video Denoising#Set8 sigma30#PSNR#31.6$Video Denoising#DAVIS sigma40#PSNR#32.8$Video Denoising#DAVIS sigma50#PSNR#31.83$Video Denoising#DAVIS sigma30#PSNR#34.06
2103.02861v3.pdf	Video Denoising#CRVD#PSNR (Raw)#43.96$Video Denoising#CRVD#SSIM (Raw)#0.988$Video Denoising#CRVD#PSNR (sRBG)#40.40$Video Denoising#CRVD#SSIM (sRGB)#0.981$Video Denoising#CRVD#LPIPS (sRGB)#0.0357
2103.05407v1.pdf	Video Denoising#CRVD#PSNR (Raw)#42.63$Video Denoising#CRVD#SSIM (Raw)#0.9851
1910.12713v1.pdf	Video-to-Video Synthesis#Street Scene#FID#144.24$Video-to-Video Synthesis#YouTube Dancing#FID#80.44
2102.07624v1.pdf	Action Spotting#SoccerNet#Average-mAP#75.1
1912.01326v3.pdf	Action Spotting#SoccerNet#Average-mAP#62.5$Action Spotting#SoccerNet-v2#Average-mAP#40.7
2004.06172v1.pdf	Action Spotting#SoccerNet#Average-mAP#60.1
2011.04258v1.pdf	Action Spotting#SoccerNet#Average-mAP#56.0
1804.04527v2.pdf	Action Spotting#SoccerNet#Average-mAP#49.7
2104.06779v1.pdf	Action Spotting#SoccerNet-v2#Average-mAP#53.4
2209.07923v1.pdf	Video Background Subtraction#DAVIS 2017 (zoomInZoomOut)#AUC#0.994$Video Background Subtraction#DAVIS 2017 (stroller)#AUC#0.877$Video Background Subtraction#DAVIS 2017 (tennis)#AUC#0.963$Video Background Subtraction#DAVIS 2017 (swing)#AUC#0.897$Video Background Subtraction#DAVIS 2017 (sidewalk)#AUC#0.932$Video Background Subtraction#DAVIS 2017 (flamingo)#AUC#0.98$Video Background Subtraction#DAVIS 2017 (boxing-fisheye)#AUC#0.927$Video Background Subtraction#DAVIS 2017 (horsejump-high)#AUC#0.943$Video Background Subtraction#DAVIS 2017 (bmx-trees)#AUC#0.916$Video Background Subtraction#DAVIS 2017 (dog-gooses)#AUC#0.984$Video Background Subtraction#DAVIS 2017 (stunt)#AUC#0.979$Video Background Subtraction#DAVIS 2017 (breakdance-flare)#AUC#0.963$Video Background Subtraction#DAVIS 2017 (continuousPan)#AUC#0.94
2112.00431v2.pdf	Natural Language Moment Retrieval#MAD#R@1,IoU=0.1#6.57$Natural Language Moment Retrieval#MAD#R@5,IoU=0.1#15.05$Natural Language Moment Retrieval#MAD#R@10,IoU=0.1#20.26$Natural Language Moment Retrieval#MAD#R@50,IoU=0.1#37.92$Natural Language Moment Retrieval#MAD#R@100,IoU=0.1#47.73$Natural Language Moment Retrieval#MAD#R@1,IoU=0.3#3.13$Natural Language Moment Retrieval#MAD#R@5,IoU=0.3#9.85$Natural Language Moment Retrieval#MAD#R@10,IoU=0.3#14.13$Natural Language Moment Retrieval#MAD#R@50,IoU=0.3#28.71$Natural Language Moment Retrieval#MAD#R@100,IoU=0.3#36.98$Natural Language Moment Retrieval#MAD#R@1,IoU=0.5#1.39$Natural Language Moment Retrieval#MAD#R@5,IoU=0.5#5.44$Natural Language Moment Retrieval#MAD#R@10,IoU=0.5#8.38$Natural Language Moment Retrieval#MAD#R@50,IoU=0.5#18.80$Natural Language Moment Retrieval#MAD#R@100,IoU=0.5#24.99$Natural Language Moment Retrieval#MAD#R@1,IoU=0.1#3.50$Natural Language Moment Retrieval#MAD#R@5,IoU=0.1#11.74$Natural Language Moment Retrieval#MAD#R@10,IoU=0.1#18.32$Natural Language Moment Retrieval#MAD#R@50,IoU=0.1#38.41$Natural Language Moment Retrieval#MAD#R@100,IoU=0.1#49.65$Natural Language Moment Retrieval#MAD#R@1,IoU=0.3#2.63$Natural Language Moment Retrieval#MAD#R@5,IoU=0.3#9.49$Natural Language Moment Retrieval#MAD#R@10,IoU=0.3#15.2$Natural Language Moment Retrieval#MAD#R@50,IoU=0.3#33.68$Natural Language Moment Retrieval#MAD#R@100,IoU=0.3#43.95$Natural Language Moment Retrieval#MAD#R@1,IoU=0.5#1.61$Natural Language Moment Retrieval#MAD#R@5,IoU=0.5#6.23$Natural Language Moment Retrieval#MAD#R@10,IoU=0.5#10.18$Natural Language Moment Retrieval#MAD#R@50,IoU=0.5#25.33$Natural Language Moment Retrieval#MAD#R@100,IoU=0.5#34.18$Natural Language Moment Retrieval#MAD#R@1,IoU=0.1#0.09$Natural Language Moment Retrieval#MAD#R@5,IoU=0.1#0.44$Natural Language Moment Retrieval#MAD#R@10,IoU=0.1#0.88$Natural Language Moment Retrieval#MAD#R@50,IoU=0.1#4.33$Natural Language Moment Retrieval#MAD#R@100,IoU=0.1#8.47$Natural Language Moment Retrieval#MAD#R@1,IoU=0.3#0.04$Natural Language Moment Retrieval#MAD#R@5,IoU=0.3#0.19$Natural Language Moment Retrieval#MAD#R@10,IoU=0.3#0.39$Natural Language Moment Retrieval#MAD#R@50,IoU=0.3#1.92$Natural Language Moment Retrieval#MAD#R@100,IoU=0.3#3.80$Natural Language Moment Retrieval#MAD#R@1,IoU=0.5#0.01$Natural Language Moment Retrieval#MAD#R@5,IoU=0.5#0.07$Natural Language Moment Retrieval#MAD#R@10,IoU=0.5#0.14$Natural Language Moment Retrieval#MAD#R@50,IoU=0.5#0.71$Natural Language Moment Retrieval#MAD#R@100,IoU=0.5#1.40
2011.10132v2.pdf	Natural Language Moment Retrieval#TACoS#R@1,IoU=0.1#57.21$Natural Language Moment Retrieval#TACoS#R@1,IoU=0.3#45.46$Natural Language Moment Retrieval#TACoS#R@1,IoU=0.5#34.19$Natural Language Moment Retrieval#TACoS#R@5,IoU=0.1#81.80$Natural Language Moment Retrieval#TACoS#R@5,IoU=0.5#56.56$Natural Language Moment Retrieval#TACoS#R@5,IoU=0.3#70.38$Natural Language Moment Retrieval#ActivityNet Captions#R@1,IoU=0.5#46.32$Natural Language Moment Retrieval#ActivityNet Captions#R@1,IoU=0.7#29.82$Natural Language Moment Retrieval#ActivityNet Captions#R@5,IoU=0.5#77.15$Natural Language Moment Retrieval#ActivityNet Captions#R@5,IoU=0.7#63.33$Natural Language Moment Retrieval#DiDeMo#R@1,IoU=0.5#33.35$Natural Language Moment Retrieval#DiDeMo#R@1,IoU=0.7#25.57$Natural Language Moment Retrieval#DiDeMo#R@1,IoU=1.0#25.57$Natural Language Moment Retrieval#DiDeMo#R@5,IoU=0.5#88.86$Natural Language Moment Retrieval#DiDeMo#R@5,IoU=0.7#71.72$Natural Language Moment Retrieval#DiDeMo#R@5,IoU=1.0#71.65
2004.03545v1.pdf	Natural Language Moment Retrieval#ActivityNet Captions#R@1,IoU=0.5#45.45$Natural Language Moment Retrieval#ActivityNet Captions#R@1,IoU=0.7#24.36$Natural Language Moment Retrieval#ActivityNet Captions#R@5,IoU=0.5#77.97$Natural Language Moment Retrieval#ActivityNet Captions#R@5,IoU=0.7#50.30
2003.13137v2.pdf	Vehicle Speed Estimation#BrnoCompSpeed#Mean Speed Measurement Error (km/h)#0.75$Vehicle Speed Estimation#BrnoCompSpeed#Median Speed Measurement Error (km/h)#0.58$Vehicle Speed Estimation#BrnoCompSpeed#95-th Percentile Speed Measurement Error (km/h)#1.84
1702.06451v2.pdf	Vehicle Speed Estimation#BrnoCompSpeed#Mean Speed Measurement Error (km/h)#1.10$Vehicle Speed Estimation#BrnoCompSpeed#Median Speed Measurement Error (km/h)#0.97$Vehicle Speed Estimation#BrnoCompSpeed#99-th Percentile Speed Measurement Error (km/h)#3.05
1708.00187v1.pdf	Video Deinterlacing#MSU Deinterlacer Benchmark#PSNR#39.203$Video Deinterlacing#MSU Deinterlacer Benchmark#SSIM#0.976$Video Deinterlacing#MSU Deinterlacer Benchmark#FPS on CPU#0.3
1904.08607v1.pdf	Video Story QA#MovieQA#Accuracy#42.53
1709.09345v4.pdf	Video Story QA#MovieQA#Accuracy#36.25
2010.05903v3.pdf	Anomaly Detection#Fashion-MNIST#ROC AUC#95.6$Anomaly Detection#Fashion-MNIST#ROC AUC#92.8$Anomaly Detection#Fashion-MNIST#ROC AUC#91.8$Anomaly Detection#Fashion-MNIST#ROC AUC#84.8$Anomaly Detection#One-class CIFAR-100#AUROC#97.3$Anomaly Detection#One-class CIFAR-100#AUROC#94.1$Anomaly Detection#One-class CIFAR-100#AUROC#80.1$Anomaly Detection#One-class CIFAR-100#AUROC#67$Anomaly Detection#One-class CIFAR-100#AUROC#62.6$Anomaly Detection#Cats-and-Dogs#ROC AUC#97.3$Anomaly Detection#Cats-and-Dogs#ROC AUC#94.5$Anomaly Detection#Cats-and-Dogs#ROC AUC#51.7$Anomaly Detection#Cats-and-Dogs#ROC AUC#50.5$Anomaly Detection#DIOR#ROC AUC#95.9$Anomaly Detection#DIOR#ROC AUC#94.3$Anomaly Detection#DIOR#ROC AUC#70.7$Anomaly Detection#DIOR#ROC AUC#70$Anomaly Detection#One-class CIFAR-10#AUROC#98.9$Anomaly Detection#One-class CIFAR-10#AUROC#96.2$Anomaly Detection#One-class CIFAR-10#AUROC#64.8$Anomaly Detection#One-class CIFAR-10#AUROC#64.7
2201.10703v2.pdf	Anomaly Detection#Fashion-MNIST#ROC AUC#95.0$Anomaly Detection#MVTec AD#Detection AUROC#98.5$Anomaly Detection#MVTec AD#Segmentation AUROC#97.8$Anomaly Detection#MVTec AD#Segmentation AUPRO#93.9$Anomaly Detection#One-class CIFAR-10#AUROC#86.5
2101.10043v5.pdf	Anomaly Detection#Fashion-MNIST#ROC AUC#94.41$Anomaly Detection#Fashion-MNIST#ROC AUC#93.57$Anomaly Detection#Fashion-MNIST#ROC AUC#92.01$Anomaly Detection#MNIST#ROC AUC#99.27$Anomaly Detection#MNIST#ROC AUC#98.69$Anomaly Detection#MVTec AD#Detection AUROC#93.4$Anomaly Detection#MVTec AD#Segmentation AUROC#93.0$Anomaly Detection#MVTec AD#Detection AUROC#92.6$Anomaly Detection#MVTec AD#Segmentation AUROC#91$Anomaly Detection#One-class CIFAR-10#AUROC#91.25$Anomaly Detection#One-class CIFAR-10#AUROC#83.68$Anomaly Detection#One-class CIFAR-10#AUROC#74.33
2106.05410v2.pdf	Anomaly Detection#Fashion-MNIST#ROC AUC#92.6$Anomaly Detection#MNIST#ROC AUC#97.7$Anomaly Detection#One-class CIFAR-10#AUROC#66.5
2007.06963v2.pdf	Anomaly Detection#Fashion-MNIST#ROC AUC#0.9293$Anomaly Detection#MNIST#ROC AUC#97.25$Anomaly Detection#One-class CIFAR-10#AUROC#73.05
2203.03677v3.pdf	Anomaly Detection#UCSD Peds2#AUC#96.46
2112.07662v2.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#96.7$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ViT$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#93.3$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-152$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#90.8$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-18$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#90.2$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#99.1$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ViT$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#95.7$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-152$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#94.3$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-18$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#90.2$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#ROC-AUC#98.3$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#Network#ViT$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#ROC-AUC#99.4$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#Network#ViT
2106.03844v1.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#90.0$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-152$Anomaly Detection#One-class CIFAR-100#AUROC#96.5$Anomaly Detection#MVTec AD#Detection AUROC#87.2$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#92.6$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-152$Anomaly Detection#One-class CIFAR-10#AUROC#97.5
2103.12051v1.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#89.6$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-18$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#96.5$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-34$Anomaly Detection#One-class CIFAR-10#AUROC#90.0
2007.08176v2.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#89.3$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-18$Anomaly Detection#One-class CIFAR-100#AUROC#89.6$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#90.3$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-18$Anomaly Detection#One-class ImageNet-30#AUROC#91.6$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#ROC-AUC#94.7$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#Network#ResNet-18$Anomaly Detection#One-class CIFAR-10#AUROC#94.3$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#ROC-AUC#71.5$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#Network#ResNet-18
2005.02359v1.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#89.2$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#Network#ResNet-18$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#ROC-AUC#78.8$Anomaly Detection#Anomaly Detection on Unlabeled CIFAR-10 vs LSUN (Fix)#Network#ResNet-18$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#ROC-AUC#92.8$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#Network#ResNet-18$Anomaly Detection#One-class CIFAR-10#AUROC#88.2$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#ROC-AUC#90.5$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#Network#ResNet-18
2106.03899v2.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#82.92$Anomaly Detection#One-class CIFAR-100#AUROC#83.95
1909.11480v3.pdf	Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#73.6$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#58.2$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#53.5$Anomaly Detection#Unlabeled CIFAR-10 vs CIFAR-100#AUROC#52.6
2104.05591v1.pdf	Anomaly Detection#AG News#AUROC#90
2206.06602v2.pdf	Anomaly Detection#NB15-Analysis#AUC#0.931$Anomaly Detection#Forest CoverType#AUC#0.972$Anomaly Detection#Kaggle-Credit Card Fraud Dataset#AUC#0.953$Anomaly Detection#NB15-DoS#AUC#0.932$Anomaly Detection#NB15-Backdoor#AUC#0.918
1911.08623v1.pdf	Anomaly Detection#Thyroid#AUC#0.783$Anomaly Detection#Thyroid#Average Precision#0.274$Anomaly Detection#Census#AUC#0.828$Anomaly Detection#Census#Average Precision#0.321$Fraud Detection#Kaggle-Credit Card Fraud Dataset#AUC#0.98$Fraud Detection#Kaggle-Credit Card Fraud Dataset#Average Precision#0.69$Network Intrusion Detection#NB15-Backdoor#AUC#0.969$Network Intrusion Detection#NB15-Backdoor#Average Precision#0.883
2112.04185v2.pdf	Anomaly Detection#One-class CIFAR-100#AUROC#97.7$Anomaly Detection#One-class CIFAR-10#AUROC#98.3
2011.02578v2.pdf	Anomaly Detection#One-class CIFAR-100#AUROC#86.5$Anomaly Detection#One-class CIFAR-100#AUROC#84.1$Anomaly Detection#MVTec AD#Detection AUROC#86.5$Anomaly Detection#MVTec AD#Segmentation AUROC#90.4$Anomaly Detection#MVTec AD#Detection AUROC#86.3$Anomaly Detection#MVTec AD#Segmentation AUROC#93$Anomaly Detection#One-class CIFAR-10#AUROC#92.5
2012.04837v1.pdf	Anomaly Detection#One-class CIFAR-100#AUROC#86$Anomaly Detection#One-class CIFAR-10#AUROC#92.6
1805.10917v2.pdf	Anomaly Detection#One-class CIFAR-100#AUROC#78.7$Anomaly Detection#One-class CIFAR-10#AUROC#86
2110.13101v2.pdf	Anomaly Detection#MNIST#ROC AUC#97.68
2209.12148v1.pdf	Anomaly Detection#CUHK Avenue#AUC#93.2%$Anomaly Detection#CUHK Avenue#RBDC#66.04$Anomaly Detection#CUHK Avenue#TBDC#86.95$Anomaly Detection#MVTec AD#Detection AUROC#98.7$Anomaly Detection#MVTec AD#Segmentation AUROC#97.2$Anomaly Detection#MVTec AD#Detection AUROC#97.7$Anomaly Detection#MVTec AD#Segmentation AUROC#96.7$Anomaly Detection#ShanghaiTech#AUC#83.6%$Anomaly Detection#ShanghaiTech#RBDC#47.73$Anomaly Detection#ShanghaiTech#TBDC#85.65
2111.08644v2.pdf	Anomaly Detection#CUHK Avenue#AUC#93.0%$Anomaly Detection#CUHK Avenue#RBDC#61.10$Anomaly Detection#CUHK Avenue#TBDC#61.38$Anomaly Detection#ShanghaiTech#AUC#83.7%$Anomaly Detection#ShanghaiTech#RBDC#47.15$Anomaly Detection#ShanghaiTech#TBDC#86.15
2111.09099v6.pdf	Anomaly Detection#CUHK Avenue#AUC#92.9%$Anomaly Detection#CUHK Avenue#RBDC#65.99$Anomaly Detection#CUHK Avenue#TBDC#89.28$Anomaly Detection#MVTec AD#Detection AUROC#98.9$Anomaly Detection#MVTec AD#Segmentation AUROC#97.2$Anomaly Detection#MVTec AD#Detection AUROC#96.1$Anomaly Detection#ShanghaiTech#AUC#83.6%$Anomaly Detection#ShanghaiTech#RBDC#45.45$Anomaly Detection#ShanghaiTech#TBDC#84.50
2008.11988v1.pdf	Anomaly Detection#CUHK Avenue#AUC#89.6%$Anomaly Detection#ShanghaiTech#AUC#74.8%
1801.05030v4.pdf	Anomaly Detection#CUHK Avenue#AUC#88.9%
1908.04321v1.pdf	Anomaly Detection#CUHK Avenue#AUC#88.33%$Anomaly Detection#ShanghaiTech#AUC#76.03%$Anomaly Detection#Corridor#AUC#67.12$Anomaly Detection#HR-ShanghaiTech#AUC#77.04
1812.04960v2.pdf	Anomaly Detection#CUHK Avenue#AUC#87.4%$Anomaly Detection#CUHK Avenue#RBDC#15.77$Anomaly Detection#CUHK Avenue#TBDC#27.01$Anomaly Detection#ShanghaiTech#AUC#78.7%$Anomaly Detection#ShanghaiTech#RBDC#20.65$Anomaly Detection#ShanghaiTech#TBDC#44.54
2001.09189v1.pdf	Anomaly Detection#CUHK Avenue#AUC#87.2%$Anomaly Detection#CUHK Avenue#RBDC#41.20$Anomaly Detection#CUHK Avenue#TBDC#78.60
2110.09742v2.pdf	Anomaly Detection#CUHK Avenue#AUC#87.1%$Anomaly Detection#ShanghaiTech#AUC#75.9%
1908.06351v1.pdf	Anomaly Detection#CUHK Avenue#AUC#86.9%
2004.02072v1.pdf	Anomaly Detection#CUHK Avenue#AUC#86.4%$Anomaly Detection#ShanghaiTech#AUC#71.6%
1712.09867v3.pdf	Anomaly Detection#CUHK Avenue#AUC#85.1%$Anomaly Detection#CUHK Avenue#RBDC#19.59$Anomaly Detection#CUHK Avenue#TBDC#56.01$Anomaly Detection#ShanghaiTech#AUC#72.8%$Anomaly Detection#ShanghaiTech#RBDC#17.03$Anomaly Detection#ShanghaiTech#TBDC#54.23$Traffic Accident Detection#SA#AUC#50.4$Traffic Accident Detection#A3D#AUC#46.1
1705.08182v3.pdf	Anomaly Detection#CUHK Avenue#AUC#80.6%
2111.12264v6.pdf	Anomaly Detection#Road Anomaly#AP#62.37$Anomaly Detection#Road Anomaly#FPR#28.29$Anomaly Detection#Fishyscapes#AP#95.45$Anomaly Detection#Fishyscapes#FPR#0.77$Anomaly Detection#Fishyscapes L&F#AP#44.17$Anomaly Detection#Fishyscapes L&F#FPR95#7.58$Anomaly Detection#Lost and Found#AP#78.29$Anomaly Detection#Lost and Found#FPR#0.81
2103.05445v1.pdf	Anomaly Detection#Road Anomaly#AP#41.83$Anomaly Detection#Road Anomaly#FPR#59.72$Anomaly Detection#Fishyscapes#AP#72.59$Anomaly Detection#Fishyscapes#FPR#18.75$Anomaly Detection#Fishyscapes L&F#AP#43.22$Anomaly Detection#Fishyscapes L&F#FPR95#15.79$Anomaly Detection#Lost and Found#AP#70.43$Anomaly Detection#Lost and Found#FPR#4.89$Semantic Segmentation#Cityscapes val#mIoU#83.5
2107.11264v4.pdf	Anomaly Detection#Road Anomaly#AP#25.82$Anomaly Detection#Road Anomaly#FPR#49.74$Anomaly Detection#Fishyscapes#AP#53.11$Anomaly Detection#Fishyscapes#FPR#19.64$Anomaly Detection#Fishyscapes L&F#AP#36.55$Anomaly Detection#Fishyscapes L&F#FPR95#14.53$Anomaly Detection#Lost and Found#AP#25.89$Anomaly Detection#Lost and Found#FPR#44.48$Semantic Segmentation#Cityscapes val#mIoU#80.33
2003.08440v2.pdf	Anomaly Detection#Road Anomaly#AP#24.86$Anomaly Detection#Road Anomaly#FPR#64.69
1811.12709v2.pdf	Anomaly Detection#Fishyscapes#AP#48.7$Anomaly Detection#Fishyscapes#FPR#15.5
2106.08265v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.6$Anomaly Detection#MVTec AD#Segmentation AUROC#98.2$Anomaly Detection#MVTec AD#Segmentation AUPRO#94.9$Few Shot Anomaly Detection#MVTec AD#Detection AUROC#95.4
2205.00908v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.56$Anomaly Detection#MVTec AD#Segmentation AUROC#98.84
2111.07677v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.4$Anomaly Detection#MVTec AD#Segmentation AUROC#98.5$Anomaly Detection#One-class CIFAR-10#AUROC#66.7
2210.08768v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.37$Anomaly Detection#MVTec AD#Segmentation AUROC#98.75$Anomaly Detection#MVTec AD#Segmentation AUPRO#95.1
2206.04325v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.3$Anomaly Detection#MVTec AD#Segmentation AUROC#98.2
2210.07829v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#99.2$Anomaly Detection#MVTec AD#Segmentation AUROC#95.0$Anomaly Detection#MVTEC 3D-AD#Detection AUROC#93.7$Anomaly Detection#MVTEC 3D-AD#Segmentation AUROC#97.6
2210.07548v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.7$Anomaly Detection#MVTec AD#Segmentation AUROC#98.5$Anomaly Detection#MVTec AD#Segmentation AUPRO#95.1
2110.02855v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.7$Anomaly Detection#Surface Defect Saliency of Magnetic Tile#Detection AUROC#99.3
2210.14913v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.4$Anomaly Detection#MVTec AD#Segmentation AUROC#98.7$Anomaly Detection#MVTec AD#Segmentation AUROC#98.83
2203.00259v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.3
2107.12571v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.26$Anomaly Detection#MVTec AD#Segmentation AUROC#98.62$Anomaly Detection#MVTec AD#Segmentation AUPRO#94.6
2108.07610v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#98.0$Anomaly Detection#MVTec AD#Segmentation AUROC#97.3
2011.08785v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#97.9$Anomaly Detection#MVTec AD#Detection AUROC#95.3$Anomaly Detection#MVTec AD#Segmentation AUROC#97.5$Anomaly Detection#MVTec AD#Segmentation AUROC#96.7
2110.04538v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#97.7$Anomaly Detection#MVTec AD#Segmentation AUROC#98.2
2109.15222v3.pdf	Anomaly Detection#MVTec AD#Detection AUROC#97.2$Anomaly Detection#MVTec AD#Segmentation AUROC#96.3$Anomaly Detection#MVTec AD#Segmentation AUPRO#91.0
2104.04015v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#96.1$Anomaly Detection#MVTec AD#Detection AUROC#95.2$Anomaly Detection#MVTec AD#Segmentation AUROC#88.3$Anomaly Detection#MVTec AD#Segmentation AUROC#96.0
2110.03396v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#96$Anomaly Detection#MVTec AD#Segmentation AUROC#97
2005.14140v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#95.8
2103.04257v3.pdf	Anomaly Detection#MVTec AD#Detection AUROC#95.5$Anomaly Detection#MVTec AD#Segmentation AUROC#97.0
2108.12159v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#95.1$Few Shot Anomaly Detection#MVTec AD#Detection AUROC#89.02$Few Shot Anomaly Detection#MVTec AD#Detection AUROC#85.61
2104.13897v3.pdf	Anomaly Detection#MVTec AD#Detection AUROC#95.0$Anomaly Detection#MVTec AD#Segmentation AUROC#96.6
2008.12577v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#94.9$Anomaly Detection#Surface Defect Saliency of Magnetic Tile#Detection AUROC#97.7
2012.07122v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#93.8$Anomaly Detection#MVTec AD#Segmentation AUROC#95.5
2110.15525v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#92.8$Anomaly Detection#MVTec AD#Segmentation AUROC#95.9
2006.16067v2.pdf	Anomaly Detection#MVTec AD#Detection AUROC#92.1$Anomaly Detection#MVTec AD#Segmentation AUROC#95.7
2103.11671v1.pdf	Anomaly Detection#MVTec AD#Detection AUROC#90$Anomaly Detection#One-class CIFAR-10#AUROC#88.4
2012.12111v4.pdf	Anomaly Detection#MVTec AD#Detection AUROC#87.5
2005.02357v3.pdf	Anomaly Detection#MVTec AD#Detection AUROC#85.5$Anomaly Detection#MVTec AD#Segmentation AUROC#96.5
2105.14737v1.pdf	Anomaly Detection#MVTec AD#Segmentation AUROC#98.2$Unsupervised Anomaly Detection#KolektorSDD2#Segmentation AUROC#98.1$Unsupervised Anomaly Detection#KolektorSDD#Segmentation AUROC#96.0
2008.05369v1.pdf	Anomaly Detection#MVTec AD#Segmentation AUROC#95.3
2007.01760v3.pdf	Anomaly Detection#MVTec AD#Segmentation AUROC#94$Anomaly Detection#MVTec AD#Segmentation AUROC#88$Anomaly Detection#One-class ImageNet-30#AUROC#91$Anomaly Detection#One-class CIFAR-10#AUROC#92
1911.08616v4.pdf	Anomaly Detection#MVTec AD#Segmentation AUROC#93$Anomaly Detection#MVTec AD#Segmentation AUROC#92$Anomaly Detection#MVTec AD#Segmentation AUROC#89$Anomaly Detection#MVTec AD#Segmentation AUROC#85
2002.03734v1.pdf	Anomaly Detection#MVTec AD#Segmentation AUROC#89.2
1911.02357v2.pdf	Anomaly Detection#MVTec AD#Segmentation AUPRO#91.4$Anomaly Detection#MVTec AD#Segmentation AUPRO#90.0$Anomaly Detection#MVTec AD#Segmentation AUPRO#85.7
2207.08003v2.pdf	Anomaly Detection#ShanghaiTech#AUC#83.8%$Anomaly Detection#ShanghaiTech#RBDC#47.10$Anomaly Detection#ShanghaiTech#TBDC#85.60
1804.08381v1.pdf	Anomaly Detection#ShanghaiTech#AUC#76.2%
1903.03295v2.pdf	Anomaly Detection#ShanghaiTech#AUC#73.40%
2206.15476v3.pdf	Anomaly Detection#AnoShift#ROC-AUC IID#84.54$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#85.62$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#54.24$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#50.42$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#76.86$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#71.43$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#49.57$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#50.48$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#54.55$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#49.35$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#84.76$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#44.87$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#49.19$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#91.5$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#79.29$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#34.96$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#73.43$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#69.61$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#31.81$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#85.75$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#49.03$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#28.19$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#84.54$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#86.05$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#28.15$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#86.09$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#75.26$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#27.16$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#84.86$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#52.26$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#22.45$Unsupervised Anomaly Detection#AnoShift#ROC-AUC IID#81$Unsupervised Anomaly Detection#AnoShift#ROC-AUC NEAR#44.06$Unsupervised Anomaly Detection#AnoShift#ROC-AUC FAR#19.96
2004.07657v4.pdf	Anomaly Detection#MNIST-test#F1 score#96.7
2112.12833v2.pdf	Anomaly Detection#Fishyscapes L&F#AP#69.43$Anomaly Detection#Fishyscapes L&F#FPR95#2.00$Anomaly Detection#Fishyscapes L&F#AP#39.36
2207.02606v1.pdf	Anomaly Detection#Fishyscapes L&F#AP#43.9$Anomaly Detection#Fishyscapes L&F#FPR95#6.2
2111.15463v1.pdf	Anomaly Detection#Fishyscapes L&F#AP#41.95$Anomaly Detection#Fishyscapes L&F#FPR95#13.32
1904.03215v4.pdf	Anomaly Detection#Fishyscapes L&F#AP#34.28$Anomaly Detection#Fishyscapes L&F#FPR95#47.43$Anomaly Detection#Fishyscapes L&F#AP#10.29$Anomaly Detection#Fishyscapes L&F#FPR95#22.11$Anomaly Detection#Fishyscapes L&F#AP#9.8$Anomaly Detection#Fishyscapes L&F#FPR95#38.5$Anomaly Detection#Fishyscapes L&F#AP#4.7$Anomaly Detection#Fishyscapes L&F#FPR95#24.4$Anomaly Detection#Fishyscapes L&F#AP#2.9$Anomaly Detection#Fishyscapes L&F#FPR95#44.8
1908.01098v1.pdf	Anomaly Detection#Fishyscapes L&F#AP#31.31$Anomaly Detection#Fishyscapes L&F#FPR95#19.02
2210.14056v2.pdf	Anomaly Detection#Vehicle Claims#AUC#98.65$Anomaly Detection#Vehicle Claims#AUC#95.88$Unsupervised Anomaly Detection#Vehicle Claims#AUC#65.43$Unsupervised Anomaly Detection#Vehicle Claims#AUC#59.42$Unsupervised Anomaly Detection#Vehicle Claims#AUC#58.59$Unsupervised Anomaly Detection#Vehicle Claims#AUC#57.03$Unsupervised Anomaly Detection#Vehicle Claims#AUC#55.38$Unsupervised Anomaly Detection#Vehicle Claims#AUC#53.82$Unsupervised Anomaly Detection#Vehicle Claims#AUC#52.86$Unsupervised Anomaly Detection#Vehicle Claims#AUC#51.68$Unsupervised Anomaly Detection#Vehicle Claims#AUC#51.22
1906.12340v2.pdf	Anomaly Detection#One-class ImageNet-30#AUROC#85.7$Anomaly Detection#One-class ImageNet-30#AUROC#84.8$Anomaly Detection#One-class ImageNet-30#AUROC#81.6$Anomaly Detection#One-class ImageNet-30#AUROC#77.9$Anomaly Detection#One-class ImageNet-30#AUROC#65.3$Anomaly Detection#One-class ImageNet-30#AUROC#56.1$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#ROC-AUC#86.3$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#Network#ResNet-18$Anomaly Detection#One-class CIFAR-10#AUROC#90.1$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#ROC-AUC#74.5$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#Network#ResNet-18$Out-of-Distribution Detection#CIFAR-10#FPR95#16.0$Out-of-Distribution Detection#CIFAR-10#AUROC#96.2$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#67.7$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#90.9
2002.10445v1.pdf	Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#ROC-AUC#93.2$Anomaly Detection#Anomaly Detection on Anomaly Detection on Unlabeled ImageNet-30 vs Flowers-102#Network#ViT$Anomaly Detection#One-class CIFAR-10#AUROC#92.5$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#ROC-AUC#93.8$Anomaly Detection#Anomaly Detection on Unlabeled ImageNet-30 vs CUB-200#Network#ViT
1510.03336v4.pdf	Anomaly Detection#Numenta Anomaly Benchmark#NAB score#64.7$Anomaly Detection#Numenta Anomaly Benchmark#NAB score#47.1$Anomaly Detection#Numenta Anomaly Benchmark#NAB score#35.7$Anomaly Detection#Numenta Anomaly Benchmark#NAB score#16.8
1607.02480v1.pdf	Anomaly Detection#Numenta Anomaly Benchmark#NAB score#17.7$Anomaly Detection#Numenta Anomaly Benchmark#NAB score#15.0
2205.14297v1.pdf	Anomaly Detection#One-class CIFAR-10#AUROC#99.1
1911.10676v3.pdf	Anomaly Detection#One-class CIFAR-10#AUROC#86.6
2012.04905v3.pdf	Anomaly Detection#One-class CIFAR-10#AUROC#83.3
2103.14953v3.pdf	Anomaly Detection#One-class CIFAR-10#AUROC#67.1
1903.08550v1.pdf	Anomaly Detection#One-class CIFAR-10#AUROC#66.83
1904.00152v2.pdf	Unsupervised Anomaly Detection#20NEWS#AUC (outlier ratio = 0.5)#0.831$Unsupervised Anomaly Detection#Fashion-MNIST#AUC (outlier ratio = 0.5)#0.833$Unsupervised Anomaly Detection#Caltech-101#AUC (outlier ratio = 0.5)#0.772$Unsupervised Anomaly Detection#Reuters-21578#AUC (outlier ratio = 0.5)#0.849
1701.01546v1.pdf	Abnormal Event Detection In Video#UBI-Fights#AUC#0.541$Abnormal Event Detection In Video#UBI-Fights#Decidability#0.059$Abnormal Event Detection In Video#UBI-Fights#EER#0.480$Semi-supervised Anomaly Detection#UBI-Fights#AUC#0.541$Semi-supervised Anomaly Detection#UBI-Fights#Decidability#0.059$Semi-supervised Anomaly Detection#UBI-Fights#EER#0.480
1708.09644v1.pdf	Abnormal Event Detection In Video#UBI-Fights#AUC#0.533$Abnormal Event Detection In Video#UBI-Fights#Decidability#0.147$Abnormal Event Detection In Video#UBI-Fights#EER#0.484$Abnormal Event Detection In Video#UCSD Ped2#AUC#97.4%$Semi-supervised Anomaly Detection#UBI-Fights#AUC#0.533$Semi-supervised Anomaly Detection#UBI-Fights#Decidability#0.147$Semi-supervised Anomaly Detection#UBI-Fights#EER#0.484
1604.04574v1.pdf	Abnormal Event Detection In Video#UBI-Fights#AUC#0.528$Abnormal Event Detection In Video#UBI-Fights#Decidability#0.194$Abnormal Event Detection In Video#UBI-Fights#EER#0.466$Semi-supervised Anomaly Detection#UBI-Fights#AUC#0.528$Semi-supervised Anomaly Detection#UBI-Fights#Decidability#0.194$Semi-supervised Anomaly Detection#UBI-Fights#EER#0.466$Traffic Accident Detection#SA#AUC#50.4$Traffic Accident Detection#A3D#AUC#49.5
2112.07661v1.pdf	Physical Video Anomaly Detection#PHANTOM#Avg. ROC-AUC#0.78$Physical Video Anomaly Detection#PHANTOM#Architecture#ViT$Physical Video Anomaly Detection#PHANTOM#Avg. ROC-AUC#0.76$Physical Video Anomaly Detection#PHANTOM#Architecture#TimeSformer$General Action Video Anomaly Detection#Something-Something V2#Avg. ROC-AUC#0.58$General Action Video Anomaly Detection#Something-Something V2#Architecture#ViT$General Action Video Anomaly Detection#Something-Something V2#Avg. ROC-AUC#0.52$General Action Video Anomaly Detection#Something-Something V2#Architecture#TimeSformer
2003.13228v1.pdf	Physical Video Anomaly Detection#PHANTOM#Avg. ROC-AUC#0.55$General Action Video Anomaly Detection#Something-Something V2#Avg. ROC-AUC#0.52
2203.05550v2.pdf	3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.924$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.782$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUROC#0.978$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.910$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.727$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUROC#0.974$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.771$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.559$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUROC#0.930$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.755$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.675$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.5572$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.696$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUROC#0.817$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.442$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.573$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUROC#0.771$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.959$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUCROC#0.865$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUCROC#0.992
2202.11660v1.pdf	3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.833
2112.09045v1.pdf	3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.583$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.537$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.492$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.571$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.348$3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.699$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.374$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.546$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.203$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.143$Depth Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUROC#0.523$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.639$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUCROC#0.517$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.564$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUCROC#0.538$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Segmentation AUPRO#0.471$RGB+3D Anomaly Detection and Segmentation#MVTEC 3D-AD#Detection AUCROC#0.609
2102.12828v3.pdf	Reading Comprehension#ReCAM#Accuracy#87.9/92.8
2203.00357v1.pdf	Reading Comprehension#ReClor#Test#79.3
2105.03659v1.pdf	Reading Comprehension#ReClor#Test#76.1
2205.00731v2.pdf	Reading Comprehension#ReClor#Test#63.5
2105.10334v1.pdf	Reading Comprehension#ReClor#Test#58.9
2103.14349v2.pdf	Reading Comprehension#ReClor#Test#58.2
2002.04326v3.pdf	Reading Comprehension#ReClor#Test#56.0$Reading Comprehension#ReClor#Test#50.4$Reading Comprehension#ReClor#Test#48.5$Reading Comprehension#ReClor#Test#47.3$Machine Reading Comprehension#ReClor#Accuracy#56.0$Machine Reading Comprehension#ReClor#Accuracy (easy)#75.7$Machine Reading Comprehension#ReClor#Accuracy (hard)#40.5$Machine Reading Comprehension#ReClor#Accuracy#55.6$Machine Reading Comprehension#ReClor#Accuracy (easy)#75.5$Machine Reading Comprehension#ReClor#Accuracy (hard)#40.0$Machine Reading Comprehension#ReClor#Accuracy#49.8$Machine Reading Comprehension#ReClor#Accuracy (easy)#72.0$Machine Reading Comprehension#ReClor#Accuracy (hard)#32.3$Question Answering#ReClor#Accuracy#56.0$Question Answering#ReClor#Accuracy (easy)#75.7$Question Answering#ReClor#Accuracy (hard)#40.5$Question Answering#ReClor#Accuracy#55.6$Question Answering#ReClor#Accuracy (easy)#75.5$Question Answering#ReClor#Accuracy (hard)#40.0$Question Answering#ReClor#Accuracy#49.8$Question Answering#ReClor#Accuracy (easy)#72.0$Question Answering#ReClor#Accuracy (hard)#32.3$Logical Reasoning Question Answering#ReClor#Accuracy#56.0$Logical Reasoning Question Answering#ReClor#Accuracy (easy)#75.7$Logical Reasoning Question Answering#ReClor#Accuracy (hard)#40.5$Logical Reasoning Question Answering#ReClor#Accuracy#55.6$Logical Reasoning Question Answering#ReClor#Accuracy (easy)#75.5$Logical Reasoning Question Answering#ReClor#Accuracy (hard)#40.0$Logical Reasoning Question Answering#ReClor#Accuracy#49.8$Logical Reasoning Question Answering#ReClor#Accuracy (easy)#72.0$Logical Reasoning Question Answering#ReClor#Accuracy (hard)#32.3
2002.00293v2.pdf	Reading Comprehension#AdversarialQA#D(BiDAF): F1#74.1$Reading Comprehension#AdversarialQA#D(BERT): F1#65.5$Reading Comprehension#AdversarialQA#D(RoBERTa): F1#53.4$Reading Comprehension#AdversarialQA#Overall: F1#64.4$Reading Comprehension#AdversarialQA#D(BiDAF): F1#71.3$Reading Comprehension#AdversarialQA#D(BERT): F1#62.4$Reading Comprehension#AdversarialQA#D(RoBERTa): F1#54.4$Reading Comprehension#AdversarialQA#Overall: F1#62.7$Reading Comprehension#AdversarialQA#D(BiDAF): F1#28.6$Reading Comprehension#AdversarialQA#D(BERT): F1#30.2$Reading Comprehension#AdversarialQA#D(RoBERTa): F1#26.7$Reading Comprehension#AdversarialQA#Overall: F1#28.5
2002.10107v4.pdf	Reading Comprehension#CrowdSource QA#MSE#0.046$Community Question Answering#CrowdSource QA#MSE#0.046$Question Quality Assessment#CrowdSource QA#MSE#0.046$Common Sense Reasoning#CrowdSource QA#MSE#0.046
2011.03292v2.pdf	Reading Comprehension#RACE#Accuracy#91.4
1909.08053v4.pdf	Reading Comprehension#RACE#Accuracy#90.9$Reading Comprehension#RACE#Accuracy (High)#90.0$Reading Comprehension#RACE#Accuracy (Middle)#93.1$Reading Comprehension#RACE#Accuracy#89.5$Reading Comprehension#RACE#Accuracy (High)#88.6$Reading Comprehension#RACE#Accuracy (Middle)#91.8$Question Answering#PIQA#Accuracy#82.0$Language Modelling#WikiText-103#Test perplexity#10.81$Language Modelling#WikiText-103#Number of params#8300M
2001.09415v5.pdf	Reading Comprehension#RACE#Accuracy#89.8$Reading Comprehension#RACE#Accuracy (High)#92.6$Reading Comprehension#RACE#Accuracy (Middle)#88.7
2006.03654v6.pdf	Reading Comprehension#RACE#Accuracy#86.8$Question Answering#BoolQ#Accuracy#90.4$Question Answering#SQuAD2.0#EM#88.0$Question Answering#SQuAD2.0#F1#90.7$Question Answering#MultiRC#F1#88.2$Question Answering#MultiRC#EM#63.7$Question Answering#COPA#Accuracy#98.4$Question Answering#COPA#Accuracy#96.8$Question Answering#Quora Question Pairs#Accuracy#92.3%$Common Sense Reasoning#SWAG#Test#90.8$Common Sense Reasoning#ReCoRD#F1#94.5$Common Sense Reasoning#ReCoRD#EM#94.1$Word Sense Disambiguation#Words in Context#Accuracy#77.5$Word Sense Disambiguation#Words in Context#Accuracy#76.4$Natural Language Inference#CommitmentBank#F1#94.9$Natural Language Inference#CommitmentBank#Accuracy#97.2$Natural Language Inference#MRPC Dev#Accuracy#92.5$Natural Language Inference#QNLI#Accuracy#95.3%$Natural Language Inference#WNLI#Accuracy#94.5%$Natural Language Inference#RTE#Accuracy#93.2%$Natural Language Inference#MultiNLI#Matched#91.1$Natural Language Inference#MultiNLI#Mismatched#91.1$Semantic Textual Similarity#STS Benchmark#Accuracy#92.5$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.5$Coreference Resolution#Winograd Schema Challenge#Accuracy#95.9$Linguistic Acceptability#CoLA Dev#Accuracy#69.5
2006.03236v1.pdf	Reading Comprehension#RACE#Accuracy#85.7$Reading Comprehension#RACE#Accuracy (High)#84.4$Reading Comprehension#RACE#Accuracy (Middle)#88.8
1907.11692v1.pdf	Reading Comprehension#RACE#Accuracy#83.2$Reading Comprehension#RACE#Accuracy (High)#81.3$Reading Comprehension#RACE#Accuracy (Middle)#86.5$Multi-task Language Understanding#MMLU#Humanities#27.9$Multi-task Language Understanding#MMLU#Average (%)#27.9$Multi-task Language Understanding#MMLU#Parameters (Billions)#0.354$Multi-task Language Understanding#MMLU#STEM#27.0$Multi-task Language Understanding#MMLU#Social Sciences#28.8$Multi-task Language Understanding#MMLU#Other#27.7$Question Answering#SQuAD2.0 dev#F1#89.4$Question Answering#SQuAD2.0 dev#EM#86.5$Question Answering#SQuAD2.0#EM#86.820$Question Answering#SQuAD2.0#F1#89.795$Question Answering#Quora Question Pairs#Accuracy#90.2%$Common Sense Reasoning#CommonsenseQA#Accuracy#72.1$Common Sense Reasoning#SWAG#Test#89.9$Natural Language Inference#ANLI test#A1#72.4$Natural Language Inference#ANLI test#A2#49.8$Natural Language Inference#ANLI test#A3#44.4$Natural Language Inference#QNLI#Accuracy#98.9%$Natural Language Inference#WNLI#Accuracy#89%$Natural Language Inference#RTE#Accuracy#88.2%$Natural Language Inference#MultiNLI#Matched#90.8$Natural Language Inference#MultiNLI#Mismatched#90.2$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.922$Semantic Textual Similarity#MRPC#Accuracy#92.3%$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.7$Type prediction#ManyTypes4TypeScript#Average Accuracy#59.84$Type prediction#ManyTypes4TypeScript#Average Precision#57.45$Type prediction#ManyTypes4TypeScript#Average Recall#57.62$Type prediction#ManyTypes4TypeScript#Average F1#57.54$Document Image Classification#RVL-CDIP#Accuracy#90.06$Document Image Classification#RVL-CDIP#Parameters#125M$Linguistic Acceptability#CoLA#Accuracy#67.8%
2104.07545v2.pdf	Reading Comprehension#RACE#Accuracy#67.3$Text Summarization#arXiv#ROUGE-1#46.74$Text Summarization#arXiv#ROUGE-2#19.19$Text Summarization#arXiv#ROUGE-L#42.2$Text Summarization#AMI#ROUGE-1#52.27$Text Summarization#AMI#ROUGE-2#20.15$Text Summarization#AMI#ROUGE-L#50.57$Text Summarization#X-Sum#ROUGE-1#45.92$Text Summarization#X-Sum#ROUGE-2#22.79$Text Summarization#Pubmed#ROUGE-1#48.25$Text Summarization#Pubmed#ROUGE-2#21.35$Text Summarization#Pubmed#ROUGE-L#36.69$Text Summarization#SAMSum Corpus#ROUGE-1#53.01$Text Summarization#SAMSum Corpus#ROUGE-2#28.27$Text Summarization#SAMSum Corpus#ROUGE-L#48.84$Document Summarization#CNN / Daily Mail#ROUGE-1#44.48$Document Summarization#CNN / Daily Mail#ROUGE-2#21.31$Document Summarization#CNN / Daily Mail#ROUGE-L#41.52
1906.08237v2.pdf	Reading Comprehension#RACE#Accuracy (High)#84.0$Reading Comprehension#RACE#Accuracy (Middle)#88.6$Question Answering#SQuAD1.1#EM#89.898$Question Answering#SQuAD1.1#F1#95.080$Question Answering#SQuAD1.1#Hardware Burden#46449G$Question Answering#SQuAD2.0 dev#F1#90.6$Question Answering#SQuAD2.0 dev#EM#87.9$Question Answering#RACE#RACE-m#85.45$Question Answering#RACE#RACE#81.75$Question Answering#SQuAD2.0#EM#87.926$Question Answering#SQuAD2.0#F1#90.689$Question Answering#Quora Question Pairs#Accuracy#92.3%$Question Answering#SQuAD1.1 dev#EM#89.7$Question Answering#SQuAD1.1 dev#F1#95.1$Natural Language Inference#ANLI test#A1#70.3$Natural Language Inference#ANLI test#A2#50.9$Natural Language Inference#ANLI test#A3#49.4$Natural Language Inference#QNLI#Accuracy#94.9%$Natural Language Inference#WNLI#Accuracy#92.5%$Natural Language Inference#RTE#Accuracy#85.9%$Natural Language Inference#MultiNLI#Matched#90.8$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.925$Semantic Textual Similarity#SentEval#MRPC#93.0/90.7$Semantic Textual Similarity#SentEval#SICK-R#-$Semantic Textual Similarity#SentEval#SICK-E#-$Semantic Textual Similarity#SentEval#STS#91.6/91.1*$Semantic Textual Similarity#MRPC#Accuracy#90.8%$Paraphrase Identification#Quora Question Pairs#Accuracy#90.3$Paraphrase Identification#Quora Question Pairs#F1#74.2$Sentiment Analysis#SST-2 Binary classification#Accuracy#97$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.8$Sentiment Analysis#Yelp Fine-grained classification#Error#27.80$Sentiment Analysis#IMDb#Accuracy#96.21$Sentiment Analysis#Yelp Binary classification#Error#1.55$Document Ranking#ClueWeb09-B#nDCG@20#31.10$Document Ranking#ClueWeb09-B#ERR@20#20.28$Text Classification#Amazon-5#Error#31.67$Text Classification#Yelp-5#Accuracy#72.95%$Text Classification#Yelp-2#Accuracy#98.63%$Text Classification#DBpedia#Error#0.62$Text Classification#AG News#Error#4.45$Text Classification#Amazon-2#Error#2.11$Text Classification#IMDb#Accuracy (2 classes)#96.8$Text Classification#IMDb#Accuracy (10 classes)#-$Humor Detection#200k Short Texts for Humor Detection#F1-score#0.920$Linguistic Acceptability#CoLA#Accuracy#69%
2010.11934v3.pdf	Reading Comprehension#MuSeRC#Average F1#0.844$Reading Comprehension#MuSeRC#EM#0.543$Question Answering#DaNetQA#Accuracy#0.657$Common Sense Reasoning#RWSD#Accuracy#0.669$Common Sense Reasoning#PARus#Accuracy#0.504$Common Sense Reasoning#RuCoS#Average F1#0.57$Common Sense Reasoning#RuCoS#EM#0.562$Natural Language Inference#RCB#Average F1#0.366$Natural Language Inference#RCB#Accuracy#0.454$Natural Language Inference#TERRa#Accuracy#0.561$Natural Language Inference#LiDiRus#MCC#0.061$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#89.8$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#NA$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#73.6$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#NA$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#40.9
2010.15925v2.pdf	Reading Comprehension#MuSeRC#Average F1#0.806$Reading Comprehension#MuSeRC#EM#0.42$Reading Comprehension#MuSeRC#Average F1#0.587$Reading Comprehension#MuSeRC#EM#0.242$Question Answering#DaNetQA#Accuracy#0.915$Question Answering#DaNetQA#Accuracy#0.621$Common Sense Reasoning#RWSD#Accuracy#0.662$Common Sense Reasoning#RWSD#Accuracy#0.84$Common Sense Reasoning#PARus#Accuracy#0.982$Common Sense Reasoning#PARus#Accuracy#0.486$Common Sense Reasoning#RuCoS#Average F1#0.93$Common Sense Reasoning#RuCoS#EM#0.89$Common Sense Reasoning#RuCoS#Average F1#0.26$Common Sense Reasoning#RuCoS#EM#0.252$Word Sense Disambiguation#RUSSE#Accuracy#0.805$Word Sense Disambiguation#RUSSE#Accuracy#0.57$Natural Language Inference#RCB#Average F1#0.68$Natural Language Inference#RCB#Accuracy#0.702$Natural Language Inference#RCB#Average F1#0.301$Natural Language Inference#RCB#Accuracy#0.441$Natural Language Inference#TERRa#Accuracy#0.92$Natural Language Inference#TERRa#Accuracy#0.471$Natural Language Inference#LiDiRus#MCC#0.626$Natural Language Inference#LiDiRus#MCC#0.06
2105.01192v1.pdf	Reading Comprehension#MuSeRC#Average F1#0.671$Reading Comprehension#MuSeRC#EM#0.237$Reading Comprehension#MuSeRC#Average F1#0.45$Reading Comprehension#MuSeRC#EM#0.071$Reading Comprehension#MuSeRC#Average F1#0.0$Reading Comprehension#MuSeRC#EM#0.0$Question Answering#DaNetQA#Accuracy#0.642$Question Answering#DaNetQA#Accuracy#0.52$Question Answering#DaNetQA#Accuracy#0.503$Common Sense Reasoning#RWSD#Accuracy#0.597$Common Sense Reasoning#RWSD#Accuracy#0.669$Common Sense Reasoning#PARus#Accuracy#0.498$Common Sense Reasoning#PARus#Accuracy#0.48$Common Sense Reasoning#PARus#Accuracy#0.478$Common Sense Reasoning#RuCoS#Average F1#0.26$Common Sense Reasoning#RuCoS#EM#0.257$Common Sense Reasoning#RuCoS#Average F1#0.25$Common Sense Reasoning#RuCoS#EM#0.247$Word Sense Disambiguation#RUSSE#Accuracy#0.595$Word Sense Disambiguation#RUSSE#Accuracy#0.587$Word Sense Disambiguation#RUSSE#Accuracy#0.528$Natural Language Inference#RCB#Average F1#0.4$Natural Language Inference#RCB#Accuracy#0.438$Natural Language Inference#RCB#Average F1#0.319$Natural Language Inference#RCB#Accuracy#0.374$Natural Language Inference#RCB#Average F1#0.217$Natural Language Inference#RCB#Accuracy#0.484$Natural Language Inference#TERRa#Accuracy#0.549$Natural Language Inference#TERRa#Accuracy#0.513$Natural Language Inference#TERRa#Accuracy#0.483$Natural Language Inference#LiDiRus#MCC#0.147$Natural Language Inference#LiDiRus#MCC#0
2111.01543v1.pdf	Machine Reading Comprehension#UQuAD#Exact Match#66%$Machine Reading Comprehension#UQuAD#Exact Match#.36$Machine Reading Comprehension#UQuAD#F1#66%
2206.12866v1.pdf	Machine Reading Comprehension#BIOMRC#Acc#88.0
2203.15556v1.pdf	Implicit Relations#BIG-bench#Accuracy#49.4$LAMBADA#BIG-bench#Accuracy#77.4$Intent Recognition#BIG-bench#Accuracy#92.8$Question Selection#BIG-bench#Accuracy#52.6$Implicatures#BIG-bench#Accuracy#75$English Proverbs#BIG-bench#Accuracy#82.4$Fantasy Reasoning#BIG-bench#Accuracy#69$Figure Of Speech Detection#BIG-bench#Accuracy#63.3$Formal Fallacies Syllogisms Negation#BIG-bench#Accuracy#52.1$GRE Reading Comprehension#BIG-bench#Accuracy#53.1$Hyperbaton#BIG-bench#Accuracy#54.2$Movie Dialog Same Or Different#BIG-bench#Accuracy#54.5$Nonsense Words Grammar#BIG-bench#Accuracy#78$Phrase Relatedness#BIG-bench#Accuracy#94$Multi-task Language Understanding#MMLU#Humanities#73.1$Multi-task Language Understanding#MMLU#Average (%)#67.5$Multi-task Language Understanding#MMLU#Parameters (Billions)#70$Multi-task Language Understanding#MMLU#STEM#55$Multi-task Language Understanding#MMLU#Social Sciences#78.8$Multi-task Language Understanding#MMLU#Other#70.3$Multi-task Language Understanding#MMLU#Tokens (Billions)#1400$Question Answering#BoolQ#Accuracy#83.7$Question Answering#Natural Questions#EM#35.5$Question Answering#SIQA#Accuracy#51.3$Question Answering#PIQA#Accuracy#81.8$Riddle Sense#BIG-bench#Accuracy#85.7$Winowhy#BIG-bench#Accuracy#62.5$Discourse Marker Prediction#BIG-bench#Accuracy#13.1$Timedial#BIG-bench#Accuracy#68.8$Anachronisms#BIG-bench#Accuracy#69.1$Causal Judgment#BIG-bench#Accuracy#57.4$Crash Blossom#BIG-bench#Accuracy#47.6$Crass AI#BIG-bench#Accuracy#75.0$Disambiguation Q#BIG-bench#Accuracy#54.7$Empirical Judgments#BIG-bench#Accuracy#67.7$Irony Identification#BIG-bench#Accuracy#73.0$Understanding Fables#BIG-bench#Accuracy#60.3$Language Modelling#LAMBADA#Accuracy#77.7$Mathematical Induction#BIG-bench#Accuracy#47.3$Analogical Similarity#BIG-bench#Accuracy#38.1$Identify Odd Metapor#BIG-bench#Accuracy#68.8$Odd One Out#BIG-bench#Accuracy#70.9$Sentence Completion#HellaSwag#Accuracy#80.8$Dark Humor Detection#BIG-bench#Accuracy#66.2$Ruin Names#BIG-bench#Accuracy#47.1$SNARKS#BIG-bench#Accuracy#58.6$Moral Permissibility#BIG-bench#Accuracy#57.3$Misconceptions#BIG-bench#Accuracy#65.3$Known Unknowns#BIG-bench#Accuracy#65.2$Sentence Ambiguity#BIG-bench#Accuracy#71.7$General Knowledge#BIG-bench#Accuracy#94.3$Movie Recommendation#BIG-bench#Accuracy#75.6$Sports Understanding#BIG-bench#Accuracy#71$Similarities Abstraction#BIG-bench#Accuracy#87$Navigate#BIG-bench#Accuracy#52.6$Temporal Sequences#BIG-bench#Accuracy#32.0$Novel Concepts#BIG-bench#Accuracy#65.6$Physical Intuition#BIG-bench#Accuracy#79$Date Understanding#BIG-bench#Accuracy#52.3$StrategyQA#BIG-bench#Accuracy#68.3$Logic Grid Puzzle#BIG-bench#Accuracy#44$Logical Fallacy Detection#BIG-bench#Accuracy#72.1$Logical Sequence#BIG-bench#Accuracy#64.1$Analytic Entailment#BIG-bench#Accuracy#67.1$Entailed Polarity#BIG-bench#Accuracy#94$Epistemic Reasoning#BIG-bench#Accuracy#60.6$Evaluating Information Essentiality#BIG-bench#Accuracy#17.6$Logical Args#BIG-bench#Accuracy#56.2$Metaphor Boolean#BIG-bench#Accuracy#93.1$Penguins In A Table#BIG-bench#Accuracy#48.7$Presuppositions As NLI#BIG-bench#Accuracy#49.9$Reasoning About Colored Objects#BIG-bench#Accuracy#59.7$Human Organs Senses Multiple Choice#BIG-bench#Accuracy#85.7$Physics MC#BIG-bench#Accuracy#65.5
2112.11446v2.pdf	Implicit Relations#BIG-bench#Accuracy#36.4$LAMBADA#BIG-bench#Accuracy#74.5$Intent Recognition#BIG-bench#Accuracy#88.7$Question Selection#BIG-bench#Accuracy#41.4$Implicatures#BIG-bench#Accuracy#62.0$English Proverbs#BIG-bench#Accuracy#57.6$Fantasy Reasoning#BIG-bench#Accuracy#64.1$Figure Of Speech Detection#BIG-bench#Accuracy#52.7$Formal Fallacies Syllogisms Negation#BIG-bench#Accuracy#50.7$GRE Reading Comprehension#BIG-bench#Accuracy#27.3$Hyperbaton#BIG-bench#Accuracy#51.7$Movie Dialog Same Or Different#BIG-bench#Accuracy#50.7$Nonsense Words Grammar#BIG-bench#Accuracy#61.4$Phrase Relatedness#BIG-bench#Accuracy#81.8$RACE-h#BIG-bench#Accuracy#71.6$RACE-m#BIG-bench#Accuracy#75.1$Multi-task Language Understanding#MMLU#Humanities#65.8$Multi-task Language Understanding#MMLU#Average (%)#60.0$Multi-task Language Understanding#MMLU#Parameters (Billions)#280$Multi-task Language Understanding#MMLU#STEM#48.0$Multi-task Language Understanding#MMLU#Social Sciences#71.2$Multi-task Language Understanding#MMLU#Other#64.0$Multi-task Language Understanding#MMLU#Tokens (Billions)#300$Multi-task Language Understanding#MMLU#Humanities#28.0$Multi-task Language Understanding#MMLU#Average (%)#29.5$Multi-task Language Understanding#MMLU#Parameters (Billions)#7.1$Multi-task Language Understanding#MMLU#STEM#30.1$Multi-task Language Understanding#MMLU#Social Sciences#31.0$Multi-task Language Understanding#MMLU#Other#31.0$Multi-task Language Understanding#MMLU#Humanities#27.5$Multi-task Language Understanding#MMLU#Average (%)#27.3$Multi-task Language Understanding#MMLU#Parameters (Billions)#1.4$Multi-task Language Understanding#MMLU#STEM#26.6$Multi-task Language Understanding#MMLU#Social Sciences#30.0$Multi-task Language Understanding#MMLU#Other#24.7$Multi-task Language Understanding#MMLU#Humanities#26.6$Multi-task Language Understanding#MMLU#Average (%)#25.7$Multi-task Language Understanding#MMLU#Parameters (Billions)#0.4$Multi-task Language Understanding#MMLU#STEM#26.0$Multi-task Language Understanding#MMLU#Social Sciences#23.4$Multi-task Language Understanding#MMLU#Other#24.1$Question Answering#BoolQ#Accuracy#79.3$Question Answering#TruthfulQA#MC1#0.295$Question Answering#TruthfulQA#MC1#0.23$Question Answering#TruthfulQA#MC1#0.217$Question Answering#Natural Questions#EM#28.2$Question Answering#SIQA#Accuracy#50.6$Question Answering#PIQA#Accuracy#81.8$Winogrande#BIG-bench#Accuracy#70.1$HellaSwag#BIG-bench#Accuracy#79.2$PIQA#BIG-bench#Accuracy#81.8$SIQA#BIG-bench#Accuracy#50.6$Riddle Sense#BIG-bench#Accuracy#68.2$Winowhy#BIG-bench#Accuracy#56.7$Discourse Marker Prediction#BIG-bench#Accuracy#11.7$Timedial#BIG-bench#Accuracy#50.9$Anachronisms#BIG-bench#Accuracy#56.4$Causal Judgment#BIG-bench#Accuracy#50.8$Crash Blossom#BIG-bench#Accuracy#63.6$Crass AI#BIG-bench#Accuracy#56.8$Disambiguation Q#BIG-bench#Accuracy#45.5$Empirical Judgments#BIG-bench#Accuracy#52.5$Irony Identification#BIG-bench#Accuracy#69.7$Understanding Fables#BIG-bench#Accuracy#39.6$Language Modelling#arXiv#BPB#0.662$Language Modelling#Ubuntu IRC#BPB#1.09$Language Modelling#StackExchange#BPB#0.641$Language Modelling#Books3#BPB#0.712$Language Modelling#FreeLaw#BPB#0.513$Language Modelling#GitHub#BPB#0.377$Language Modelling#PubMed Central#BPB#0.525$Language Modelling#OpenSubtitles#BPB#0.899$Language Modelling#Pile CC#BPB#0.691$Language Modelling#Curation Corpus#BPB#0.475$Language Modelling#HackerNews#BPB#0.890$Language Modelling#NIH ExPorter#BPB#0.590$Language Modelling#PubMed Cognitive Control Abstracts#BPB#0.577$Language Modelling#USPTO Backgrounds#BPB#0.546$Language Modelling#OpenWebtext2#BPB#0.677$Language Modelling#PhilPapers#BPB#0.695$Language Modelling#Gutenberg PG-19#BPB#0.656$Language Modelling#DM Mathematics#BPB#1.14$Language Modelling#Bookcorpus2#BPB#0.741$Language Modelling#WikiText-103#BPB#0.566$Formal Logic#BIG-bench#Accuracy#35.7$Abstract Algebra#BIG-bench#Accuracy#25.0$High School Mathematics#BIG-bench#Accuracy#23.7$Mathematical Induction#BIG-bench#Accuracy#57.6$Professional Accounting#BIG-bench#Accuracy#44.3$Analogical Similarity#BIG-bench#Accuracy#17.2$Identify Odd Metapor#BIG-bench#Accuracy#38.6$Odd One Out#BIG-bench#Accuracy#32.5$Sentence Completion#HellaSwag#Accuracy#79.2$Dark Humor Detection#BIG-bench#Accuracy#83.1$Ruin Names#BIG-bench#Accuracy#38.6$SNARKS#BIG-bench#Accuracy#48.3$Business Ethics#BIG-bench#Accuracy#70.0$Moral Disputes#BIG-bench#Accuracy#66.8$Moral Permissibility#BIG-bench#Accuracy#55.1$Moral Scenarios#BIG-bench#Accuracy#40.2$Misconceptions#BIG-bench#Accuracy#61.7$Known Unknowns#BIG-bench#Accuracy#63.6$Sentence Ambiguity#BIG-bench#Accuracy#69.1$FEVER (2-way)#BIG-bench#Accuracy#77.5$FEVER (3-way)#BIG-bench#Accuracy#77.5$General Knowledge#BIG-bench#Accuracy#93.9$Natural Questions#BIG-bench#Accuracy#28.2$TriviaQA#BIG-bench#Accuracy#57.1$Movie Recommendation#BIG-bench#Accuracy#50.5$Miscellaneous#BIG-bench#Accuracy#75.7$Sports Understanding#BIG-bench#Accuracy#54.9$Global Facts#BIG-bench#Accuracy#38.0$Similarities Abstraction#BIG-bench#Accuracy#81.8$High School European History#BIG-bench#Accuracy#72.1$High School US History#BIG-bench#Accuracy#78.9$High School World History#BIG-bench#Accuracy#75.1$Hindu Knowledge#BIG-bench#Accuracy#80.0$International Law#BIG-bench#Accuracy#77.7$Jurisprudence#BIG-bench#Accuracy#71.3$Logical Fallacies#BIG-bench#Accuracy#72.4$Management#BIG-bench#Accuracy#77.7$Marketing#BIG-bench#Accuracy#83.3$Philosophy#BIG-bench#Accuracy#68.8$Prehistory#BIG-bench#Accuracy#67.6$Professional Law#BIG-bench#Accuracy#44.5$World Religions#BIG-bench#Accuracy#84.2$Navigate#BIG-bench#Accuracy#51.1$Temporal Sequences#BIG-bench#Accuracy#19.0$Novel Concepts#BIG-bench#Accuracy#59.1$Physical Intuition#BIG-bench#Accuracy#59.7$Date Understanding#BIG-bench#Accuracy#44.1$StrategyQA#BIG-bench#Accuracy#61.0$Logic Grid Puzzle#BIG-bench#Accuracy#35.1$Logical Fallacy Detection#BIG-bench#Accuracy#58.9$Logical Sequence#BIG-bench#Accuracy#36.4$Elementary Mathematics#BIG-bench#Accuracy#33.6$Analytic Entailment#BIG-bench#Accuracy#53.0$Entailed Polarity#BIG-bench#Accuracy#89.5$Epistemic Reasoning#BIG-bench#Accuracy#56.4$Evaluating Information Essentiality#BIG-bench#Accuracy#16.7$Logical Args#BIG-bench#Accuracy#59.1$Metaphor Boolean#BIG-bench#Accuracy#59.3$Penguins In A Table#BIG-bench#Accuracy#40.6$Presuppositions As NLI#BIG-bench#Accuracy#34.0$Reasoning About Colored Objects#BIG-bench#Accuracy#49.2$College Mathematics#BIG-bench#Accuracy#37.0$Anatomy#BIG-bench#Accuracy#56.3$Clinical Knowledge#BIG-bench#Accuracy#67.2$College Medicine#BIG-bench#Accuracy#60.1$Human Aging#BIG-bench#Accuracy#66.4$Human Organs Senses Multiple Choice#BIG-bench#Accuracy#84.8$Medical Genetics#BIG-bench#Accuracy#69.0$Nutrition#BIG-bench#Accuracy#69.9$Professional Medicine#BIG-bench#Accuracy#64.0$Virology#BIG-bench#Accuracy#47.0$BIG-bench Machine Learning#BIG-bench#Accuracy#41.1$Astronomy#BIG-bench#Accuracy#65.8$Computer Security#BIG-bench#Accuracy#65.0$College Biology#BIG-bench#Accuracy#70.8$College Chemistry#BIG-bench#Accuracy#45.0$College Computer Science#BIG-bench#Accuracy#49.0$College Physics#BIG-bench#Accuracy#34.3$Conceptual Physics#BIG-bench#Accuracy#49.4$Electrical Engineering#BIG-bench#Accuracy#60.0$High School Biology#BIG-bench#Accuracy#71.3$High School Chemistry#BIG-bench#Accuracy#47.8$High School Computer Science#BIG-bench#Accuracy#54.0$High School Physics#BIG-bench#Accuracy#33.8$High School Statistics#BIG-bench#Accuracy#50.0$Physics MC#BIG-bench#Accuracy#50.9$Econometrics#BIG-bench#Accuracy#43.0$High School Geography#BIG-bench#Accuracy#76.8$High School Government and Politics#BIG-bench#Accuracy#83.9$High School Macroeconomics#BIG-bench#Accuracy#65.1$High School Microeconomics#BIG-bench#Accuracy#66.4$High School Psychology#BIG-bench#Accuracy#81.8$Human Sexuality#BIG-bench#Accuracy#67.2$Professional Psychology#BIG-bench#Accuracy#68.1$Public Relations#BIG-bench#Accuracy#71.8$Security Studies#BIG-bench#Accuracy#64.9$Sociology#BIG-bench#Accuracy#84.1$US Foreign Policy#BIG-bench#Accuracy#81.0
2209.04355v1.pdf	Multimodal Intent Recognition#MIntRec#Accuracy (20 classes)#85.51$Multimodal Intent Recognition#MIntRec#Accuracy (Binary)#94.72$Multimodal Intent Recognition#MIntRec#Accuracy (20 classes)#72.65$Multimodal Intent Recognition#MIntRec#Accuracy (Binary)#89.24$Multimodal Intent Recognition#MIntRec#Accuracy (20 classes)#72.52$Multimodal Intent Recognition#MIntRec#Accuracy (Binary)#89.19$Multimodal Intent Recognition#MIntRec#Accuracy (20 classes)#72.29$Multimodal Intent Recognition#MIntRec#Accuracy (Binary)#89.21
2203.09064v1.pdf	Few-Shot Learning#Mini-ImageNet - 1-Shot Learning#Acc#74.74$Few-Shot Learning#Mini-Imagenet 5-way (1-shot)#5 way 1~2 shot#74.74$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#79.67$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#48.27$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.50$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#89.19$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#91.72$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#78.89$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#66.42$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#74.74
2003.14247v2.pdf	Few-Shot Learning#Mini-ImageNet - 1-Shot Learning#Acc#67.6
2108.13161v7.pdf	Few-Shot Learning#MRPC#F1-score#78.3(4.5)$Few-Shot Learning#CR#Acc#91.8(0.5)$Few-Shot Learning#GLUE QQP#F1-score#67.8(3.2)$Few-Shot Learning#SST-2 Binary classification#Acc#93.5(0.5)$Few-Shot Learning#MR#Acc#88.2(1.0)
2008.11297v3.pdf	Few-Shot Learning#Mini-ImageNet - 5-Shot Learning#Accuracy#87.4%$Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#59.5$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#82.1$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.8$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#72.8$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#90.8$Few-Shot Image Classification#Mini-ImageNet to CUB - 5 shot learning#Accuracy#71$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#56.1$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#82.2%$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#77.80$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#39.3
2201.09699v2.pdf	Few-Shot Learning#Mini-Imagenet 5-way (1-shot)#Accuracy#82.75$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#84.29$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#83.98$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#74.71$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#74.31$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#54.47$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#54.13$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#48.07$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#47.94$Few-Shot Image Classification#CUB 200 5-way#Accuracy#93.79$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.47$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.2$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#89.0$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.38$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#89.14$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#88.57$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#87.15$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#86.28$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.76$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.26$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#88.33$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#87.86$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#87.16$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#86.99$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#76.2$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#75.24$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#66.86$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#65.82$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#64.74$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#64.14$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#93.5$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#91.93$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#91.59$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#90.56$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#90.5$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#78.56$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#77.97$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#84.04$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#82.31$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#71.75$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#70.63
2203.11378v1.pdf	Few-Shot Learning#Mini-Imagenet 5-way (1-shot)#Accuracy#53.18$Few-Shot Image Classification#OMNIGLOT-EMNIST 5-way (1-shot)#Accuracy#80.65$Few-Shot Image Classification#OMNIGLOT-EMNIST 5-way (5-shot)#Accuracy#90.81$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#69.62%$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#53.18%$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#58.86$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#40.03$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#80.07$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#66.13
1603.00550v3.pdf	Few-Shot Image Classification#AWA - 0-Shot#Accuracy#72.9%$Few-Shot Image Classification#ImageNet - 0-Shot#Accuracy#1.5%$Few-Shot Image Classification#CUB-200-2011 - 0-Shot#Top-1 Accuracy#54.7%$Few-Shot Image Classification#SUN - 0-Shot#Accuracy#62.7%
2012.07176v3.pdf	Few-Shot Image Classification#CIFAR-FS - 5-Shot Learning#Accuracy#89.12$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#76.55$Few-Shot Image Classification#Fewshot-CIFAR100 - 1-Shot Learning#Accuracy#50.57%$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#50.57$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#89.12$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.51$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.82$Few-Shot Image Classification#CIFAR-FS - 1-Shot Learning#Accuracy#81.87%$Few-Shot Image Classification#Fewshot-CIFAR100 - 5-Shot Learning#Accuracy#61.58%$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#81.87$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#61.58$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#73.35
2103.11383v4.pdf	Few-Shot Image Classification#Stanford Dogs 5-way (1-shot)#Accuracy#59.05$Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#91.05$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#75.59$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#72.43
2011.14479v1.pdf	Few-Shot Image Classification#Stanford Dogs 5-way (1-shot)#Accuracy#55.63$Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#91.89$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#72.67$Few-Shot Image Classification#CUB-200-2011 5-way (5-shot)#Accuracy#83.92$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#70.29$Few-Shot Image Classification#CUB-200-2011 5-way (1-shot)#Accuracy#67.33$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#73.15$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#53.63
1903.12290v2.pdf	Few-Shot Image Classification#Stanford Dogs 5-way (1-shot)#Accuracy#45.73$Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#89.6$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#71.02$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#66.33$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#81.9$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#61.51$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#53.15$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#51.24
1910.05199v4.pdf	Few-Shot Image Classification#OMNIGLOT-EMNIST 5-way (1-shot)#Accuracy#75.40$Few-Shot Image Classification#OMNIGLOT-EMNIST 5-way (5-shot)#Accuracy#90.3$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#64.0$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#56.40$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#40.22$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#85.64$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#72.27$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#62.96
2106.05974v1.pdf	Few-Shot Image Classification#ImageNet - 5-shot#Top 1 Accuracy#82.78$Few-Shot Image Classification#ImageNet - 5-shot#Top 1 Accuracy#78.21$Few-Shot Image Classification#ImageNet - 5-shot#Top 1 Accuracy#78.08$Few-Shot Image Classification#ImageNet - 5-shot#Top 1 Accuracy#77.1$Few-Shot Image Classification#ImageNet - 5-shot#Top 1 Accuracy#76.95$Few-Shot Image Classification#ImageNet - 1-shot#Top 1 Accuracy#68.66$Few-Shot Image Classification#ImageNet - 1-shot#Top 1 Accuracy#63.38$Few-Shot Image Classification#ImageNet - 1-shot#Top 1 Accuracy#62.95$Few-Shot Image Classification#ImageNet - 1-shot#Top 1 Accuracy#62.41$Few-Shot Image Classification#ImageNet - 1-shot#Top 1 Accuracy#62.34$Few-Shot Image Classification#ImageNet - 10-shot#Top 1 Accuracy#84.29$Few-Shot Image Classification#ImageNet - 10-shot#Top 1 Accuracy#80.33$Few-Shot Image Classification#ImageNet - 10-shot#Top 1 Accuracy#80.1$Few-Shot Image Classification#ImageNet - 10-shot#Top 1 Accuracy#79.01$Image Classification#ImageNet#Top 1 Accuracy#88.36%$Image Classification#ImageNet#Number of params#7200M$Image Classification#ImageNet#Top 1 Accuracy#88.23%$Image Classification#ImageNet#Number of params#2700M$Image Classification#ImageNet#Top 1 Accuracy#88.08%$Image Classification#ImageNet#Number of params#656M$Image Classification#ImageNet#Top 1 Accuracy#87.41%$Image Classification#ImageNet#Number of params#3400M$Image Classification#JFT-300M#prec@1#60.62$Image Classification#JFT-300M#prec@1#60.12$Image Classification#JFT-300M#prec@1#57.65$Image Classification#JFT-300M#prec@1#56.68
1811.07100v3.pdf	Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#47.31$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#68.83$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#75.84$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#79.62$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#62.88$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#32.07
1707.09835v2.pdf	Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#28.92$Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#26.06$Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#22.69$Few-Shot Image Classification#Mini-Imagenet 20-way (5-shot)#Accuracy#19.29$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#17.56$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#17.31$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#16.70$Few-Shot Image Classification#Mini-Imagenet 20-way (1-shot)#Accuracy#16.49
1902.02527v1.pdf	Few-Shot Image Classification#OMNIGLOT - 5-Shot, 1000 way#Accuracy#78.9$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#97.9$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#97.6%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.9$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 423 way#Accuracy#88$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#97.2%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 1000 way#Accuracy#68.9$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 423 way#Accuracy#73.5
2205.13803v1.pdf	Few-Shot Image Classification#Bongard-HOI#Avg. Accuracy#91.42$Few-Shot Image Classification#Bongard-HOI#Avg. Accuracy#55.82$Few-Shot Image Classification#Bongard-HOI#Avg. Accuracy#54.30$Few-Shot Image Classification#Bongard-HOI#Avg. Accuracy#54.23$Few-Shot Image Classification#Bongard-HOI#Avg. Accuracy#49.74
2208.10559v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#86.97$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#95.95$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#96.57$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#80.74$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#84.61$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#86.11
2110.09446v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#86.07$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#91.86$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#91.53$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.67$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#91.09$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#88.44$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#79.15$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#63.90$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#96.43$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#94.78$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#85.54$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#68.43
2006.03806v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#85.41$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#64.1$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#60.6$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.68$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#88.82$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#90.44$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#71.3$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#87.69$Few-Shot Image Classification#Mini-Imagenet 5-way (10-shot)#Accuracy#90.03$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#70.0$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#67.1$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#82.92%$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#76.51$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#62.49$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#93.99$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#91.55%$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#82.92$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#65.1
2209.08527v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#85.20$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#76.6$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#57.27$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#71.0$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.63$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#91.65$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#90.41$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#90.7$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#87.35$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#86.5$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#83.6$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#70.60$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#93.50$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#90.42$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#84.80$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#82.0
2003.11853v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#84.01$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#74.6$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#58.7$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#84.32$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#80.11$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.00$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#76.51$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#85.1$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#73.5$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#92.48$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#89.58$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#69.66
2106.11486v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#81.77$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#80.13$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.36$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.32$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#87.61$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.34$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#88.65$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#82.68$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#76.84$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#73.98
2006.15486.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#80.30$Few-Shot Image Classification#miniImagenet → CUB (5-way 5-shot)#Accuracy#66.33$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.72$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#87.93$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#66.33$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#88.68$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#80.96$Few-Shot Image Classification#iNaturalist (227-way multi-shot)#Accuracy#74.97$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#75.57$Few-Shot Image Classification#miniImagenet → CUB (5-way 1-shot)#Accuracy#55.46
2003.04151v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#78.50$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#88.05$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.34$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#88.36$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#77.27%$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#77.27
1906.00562v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#77.7$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#78.7$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#85.2$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#70.1
2206.07267v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#76.32$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#47.68$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.90$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#86.38$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.96$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#77.76$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#63.81$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#72.40
2101.02833v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#74.33$Few-Shot Image Classification#Meta-Dataset#Accuracy#74.3$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.79$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.28$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#89.56$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#75.83$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.83
2006.12245v6.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#73.8$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#65.9$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#80.6$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#72.5$Few-Shot Image Classification#Meta-Dataset#Accuracy#70.32$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#65.1$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#54.6$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#91.5$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#73.1$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#87.7$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#81.8$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#85.9$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#59.6$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#3.05$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#68.5$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#42.8$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#79.9$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#55.6
1907.12087v4.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#73.71$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#87.47$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#83.18$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#88.59$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#74.81$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#90.85$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#80.68$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#64.93
2109.12932v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#72.52$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#43.72$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#86.61$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.75$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.61$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#74.5$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#58.92$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.25
2103.01315v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#72.21$Few-Shot Image Classification#Meta-Dataset#Accuracy#68.89$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#47.76$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#89.74$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.78$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#87.08$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#77.87$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#65.3$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.28
2006.09785v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#72.03$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#46.5$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.9$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#83.54$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.66$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#76.9$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#63.1$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.04
2108.09666v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#71.61$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#86.60$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.58$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#85.28$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#74.51$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#91.11$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#79.49$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.60
1912.03432v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#71.4$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#63.0$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#78.5$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#70.2$Few-Shot Image Classification#Meta-Dataset#Accuracy#69.86$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#57.1$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#48.1$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#90.3$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#70.8$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.0$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#80.0$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#83.1$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#56.7$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#3.45$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#63.5$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#37.1$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#77.4$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#53.2
2003.02455v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#70.82$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#63.87$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#81.84$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#52.11
1907.11864v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.87$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.43$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.52%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.56%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#93.2$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#64.31$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#82.7$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#51.54
2207.09176v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.60$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#83.40$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.51$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.55$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.55$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.51$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#83.40$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.60
2002.02050v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.14$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.07$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#85.82$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#68.33$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#49.44$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#71.88
1902.07104v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.08$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#78.10$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#82.58$Few-Shot Image Classification#Mini-Imagenet 5-way (10-shot)#Accuracy#81.57$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.30
1911.10807v3.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#68.77$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#41.6$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#89.3$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#80.75$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#86.75$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#73.1$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#66.9$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#62.21
1912.02738v4.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#67.72$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#80.82$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#83.28$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#64.13
2106.09017v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#67.11$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#42.4$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#84.1$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#77.72$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#83.69$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#69.5$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#57.7$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#59.84
1904.03758v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#65.81$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#47.2$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#85$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#80$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#81.75$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#72.8$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#62.5$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#64.09
1905.06549v2.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#63.08$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.49%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#98.07%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#76.36$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#80.26$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.65
2011.12527v1.pdf	Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#62.42$Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#61.27$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#82.93$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#80.16$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#71.93$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#70.22$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#80.05$Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#77.82$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#68.34$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#66.31$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#56.12$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#55.03
2204.11181v1.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#74.4$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#67.4$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#89.8$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#86.6$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#82.5$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#75.7
1911.10713v4.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#74.1$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#67.0$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#87.1$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#84.8$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#80.2$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#70.31%$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#74.5
2006.15486v3.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#72.3$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#65.4$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#87.7$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#85.7$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#81.6$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#73.7
1911.04623v2.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#69.6$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#63.0$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#81.5$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#87.5$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#84.7$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#80.1$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#64.29$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#70.6
1904.04232v2.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#68.0$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#60.4$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#87.5$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#84.2$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#79.7$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (5-shot)#Accuracy#62.04$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#33.04$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#69.4
1909.02729v5.pdf	Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 1-shot)#1:1 Accuracy#61.2$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#58.5$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 5-shot)#1:1 Accuracy#82.9$Few-Shot Image Classification#Dirichlet Tiered-Imagenet (5-way, 5-shot)#1:1 Accuracy#75.5$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#74.8$Few-Shot Image Classification#Dirichlet CUB-200 (5-way, 1-shot)#1:1 Accuracy#67.5
1805.10002v5.pdf	Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#59.4$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#57.9$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#44.8$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#39.4$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#52.8$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#51.2$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#38.4$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#35.2
1703.05175v2.pdf	Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#58.3$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#57.8$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.8$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.9%$Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#52.93$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.7$Few-Shot Image Classification#Meta-Dataset#Accuracy#60.573$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#38.6$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#37.3$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#53.6$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#96%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#68.20$Few-Shot Image Classification#CUB 200 50-way (0-shot)#Accuracy#54.6$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#50.1$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#49.3$Few-Shot Image Classification#Mini-Imagenet 5-way (10-shot)#Accuracy#74.3$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#74.2$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#8.5$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#48.19$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#45.31$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#34.6$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#32.9$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#40.90$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#49.42$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#69.57
1711.06025v2.pdf	Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#58.0$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.6$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.1%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.8$Few-Shot Image Classification#Meta-Dataset#Accuracy#53.315$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#36.3$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#69.3$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#97.6%$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#47.9$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#11.8$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#42.91$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#65.32$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#34.9$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#50.44$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#50.4$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#71.31
1703.03400v3.pdf	Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#54.7$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#53.3$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.7$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.9$Few-Shot Image Classification#Meta-Dataset#Accuracy#57.024$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#34.8$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#34.4$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#47.6$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#63.1$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#48.2$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#46.9$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#64.5$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#10.25$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#40.15$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#31.8$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#31.3$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#48.7$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#70.83$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#70.30
1803.02999v3.pdf	Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#52.0$Few-Shot Image Classification#Tiered ImageNet 10-way (5-shot)#Accuracy#48.0$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#97.68$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#97.12%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.48$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#35.3$Few-Shot Image Classification#Tiered ImageNet 10-way (1-shot)#Accuracy#33.7$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#89.43%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#65.99$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#47.6$Few-Shot Image Classification#Mini-Imagenet 10-way (5-shot)#Accuracy#44.7$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#32.0$Few-Shot Image Classification#Mini-Imagenet 10-way (1-shot)#Accuracy#31.1$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#49.97$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#71.03$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#66.47
1902.03356v3.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.97$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.65%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.89$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#88%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#70.33$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#55.73
1909.11446v2.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.92%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.8%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.63$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.5%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.92%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.89%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#99.11$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#98.8%
1801.05558v3.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.5$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#96.2%$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#51.7
1909.04630v1.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.50$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.14%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.74%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#96.18$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#49.30
1810.09502v3.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.47$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.33%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.85%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#97.65$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#67.15$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#52.40
1904.02239v2.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#99.0$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.15%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.4$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#95.9%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#66.27$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#72.22$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#60.52$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#51.57
1712.09926v3.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.42$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.43%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.37$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#96.12%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#71.94$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#56.88
1703.03129v1.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.4$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.6%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.6$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#95%
1606.04080v2.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.1$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.5%$Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#44.70$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#98.9$Few-Shot Image Classification#Meta-Dataset#Accuracy#56.247$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#93.8%$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#60$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#10.5$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#47.50$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#45.59$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#34.80$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#46.6
1606.02185v2.pdf	Few-Shot Image Classification#OMNIGLOT - 1-Shot, 5-way#Accuracy#98.1$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#98.1%$Few-Shot Image Classification#OMNIGLOT - 5-Shot, 5-way#Accuracy#99.5$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#93.2%
1908.05257v1.pdf	Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#99.32$Few-Shot Image Classification#mini-ImageNet - 100-Way#Accuracy#39.14$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#99.63$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#53.21
1912.03820v3.pdf	Few-Shot Image Classification#OMNIGLOT - 5-Shot, 20-way#Accuracy#94.1%$Few-Shot Image Classification#OMNIGLOT - 1-Shot, 20-way#Accuracy#83.3%
1711.04043v3.pdf	Few-Shot Image Classification#Stanford Cars 5-way (5-shot)#Accuracy#71.25$Few-Shot Image Classification#Stanford Dogs 5-way (5-shot)#Accuracy#62.27$Few-Shot Image Classification#Stanford Cars 5-way (1-shot)#Accuracy#55.85
1904.05967v1.pdf	Few-Shot Image Classification#aPY - 0-Shot#Accuracy#42.2$Few-Shot Image Classification#AWA2 - 0-Shot#Accuracy#69.3$Few-Shot Image Classification#AWA1 - 0-Shot#Accuracy#70.8$Few-Shot Image Classification#CUB-200 - 0-Shot Learning#Accuracy#56.9%$Few-Shot Image Classification#SUN - 0-Shot#Accuracy#60.9%
1805.01033v1.pdf	Few-Shot Image Classification#Caltech-256 5-way (1-shot)#Accuracy#74.7$Few-Shot Image Classification#CIFAR100 5-way (1-shot)#Accuracy#89.6$Image Classification#CIFAR-10#Percentage correct#83.1$Fine-Grained Image Classification#Caltech-101#Accuracy#91.00%$Semi-Supervised Image Classification#Caltech-256#Accuracy#77.40%$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#16.90$Semi-Supervised Image Classification#Caltech-101#Accuracy#91.00%$Semi-Supervised Image Classification#Caltech-256, 1024 Labels#Accuracy#77.40%$Semi-Supervised Image Classification#Caltech-101, 202 Labels#Accuracy#91.00%
1806.04734v3.pdf	Few-Shot Image Classification#Caltech-256 5-way (1-shot)#Accuracy#73.2$Few-Shot Image Classification#CIFAR100 5-way (1-shot)#Accuracy#66.7$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#69.8$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#59.9
1605.05395v1.pdf	Few-Shot Image Classification#Flowers-102 - 0-Shot#AP50#59.6$Few-Shot Image Classification#Flowers-102 - 0-Shot#Accuracy#65.6%$Few-Shot Image Classification#CUB 200 50-way (0-shot)#Accuracy#50.9$Few-Shot Image Classification#CUB 200 50-way (0-shot)#Accuracy#50.4$Few-Shot Image Classification#CUB-200-2011 - 0-Shot#Top-1 Accuracy#56.8%$Few-Shot Image Classification#CUB-200-2011 - 0-Shot#AP50#48.7
2201.01490v2.pdf	Few-Shot Image Classification#ImageNet - 0-Shot#Accuracy#68.3%$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#5.4$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.6$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#71.3%$Semi-Supervised Image Classification#ImageNet - 0.2% labeled data#ImageNet Top-1 Accuracy#69.6%
1312.5650v3.pdf	Few-Shot Image Classification#ImageNet - 0-Shot#Accuracy#1.4%$Multi-label zero-shot learning#Open Images V4#MAP#40.4
2204.07305v1.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#84.75$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#92.2$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#98.4$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#84.3$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#95.3
2107.00358v4.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#78.07
2206.09843v2.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#76.1$Few-Shot Image Classification#Meta-Dataset#Accuracy#74.9$Image Classification#VTAB-1k#Top-1 Accuracy#58.4$Image Classification#VTAB-1k#Top-1 Accuracy#56.6
2103.13841v1.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#75.75
2006.11702v4.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#72.15$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#2.85
2003.09338v2.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#70.72$Few-Shot Image Classification#Meta-Dataset#Accuracy#69.3$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#4.2$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#4.25
1906.07697v2.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#66.9$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#5.95
1903.03096v4.pdf	Few-Shot Image Classification#Meta-Dataset#Accuracy#63.428$Few-Shot Image Classification#Meta-Dataset#Accuracy#58.758$Few-Shot Image Classification#Meta-Dataset#Accuracy#54.319$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#6.65$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#8.7$Few-Shot Image Classification#Meta-Dataset Rank#Mean Rank#10.85
2003.00804v1.pdf	Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#51.35$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#49.77$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.38$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#88.33$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.13$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#81.96$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#77.66$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#76.75$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#65.95%$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#65.38%$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#67.66$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#67.17$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.95$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.38
1812.02391v3.pdf	Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#45.1$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#75.5$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#57.6$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.2$Few-Shot Image Classification#FC100 5-way (10-shot)#Accuracy#63.4
2007.10778v1.pdf	Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#41$Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#40.7$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#86.8$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#85.2$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#80.34$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#78.16$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#74.7$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#73.8$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#57.8$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#56.6$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#62.53$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.32
1805.10123v4.pdf	Few-Shot Image Classification#FC100 5-way (1-shot)#Accuracy#40.1$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#76.7$Few-Shot Image Classification#Mini-Imagenet 5-way (10-shot)#Accuracy#80.8$Few-Shot Image Classification#FC100 5-way (5-shot)#Accuracy#56.1$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#58.5
1805.09921v4.pdf	Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 1-shot)#1:1 Accuracy#47.8$Few-Shot Image Classification#Dirichlet Mini-Imagenet (5-way, 5-shot)#1:1 Accuracy#61.9
2104.12709v2.pdf	Few-Shot Image Classification#Oxford 102 Flower#ACCURACY#75.33$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#65.66$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#65.33
2204.03065v1.pdf	Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#92.83$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#91.34$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#89.94$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#97.12$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#95.80$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#85.59
2102.05176v2.pdf	Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#90.73$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#87.79$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#94.09$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#91.68
2004.12696v1.pdf	Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#85.3$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#79.2$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#80.0$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#70.0
2009.03558v1.pdf	Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#82.96$Few-Shot Image Classification#CIFAR-FS 5-way (5-shot)#Accuracy#77.63$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#75.19$Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#71.63$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#69.02$Few-Shot Image Classification#CIFAR-FS 5-way (1-shot)#Accuracy#61.61$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#57.40$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#53.57
1911.06045v3.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#90.98$Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#76.82%$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#89.18$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#77.09$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#76.82$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#46.13$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#70.14
2107.07746v3.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#85.16$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#69.28
2108.05010v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#84.18$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#79.01
2009.03665v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#82.2$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#71.5
2005.13826v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#79.54$Few-Shot Image Classification#ImageNet (1-shot)#Top-5 Accuracy#59.2$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.10
1812.03664v6.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#78.38$Few-Shot Image Classification#Mini-ImageNet-CUB 5-way (1-shot)#Accuracy#39.00$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#83.03$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#68.65$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.72
2108.08891v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#77.78
1905.10295v6.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#77.64$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#85.63$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#83.8$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#70.46$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#67.48$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#62.86
1905.01436v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#76.37$Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#80.15
1905.11641v2.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#74.63$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#59.14
1706.03466v3.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#73.74$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#59.60
1804.09458v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#72.81$Few-Shot Image Classification#ImageNet (1-shot)#Top-5 Accuracy#58.2$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#56.20
1409.8403v2.pdf	Few-Shot Image Classification#CUB 200 50-way (0-shot)#Accuracy#50.1$Few-Shot Image Classification#CUB-200-2011 - 0-Shot#Top-1 Accuracy#50.1%$Few-Shot Image Classification#CUB-200 - 0-Shot Learning#Accuracy#50.1%$Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#13.3$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#12.0$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#9.9$Zero-Shot Action Recognition#Olympics#Top-1 Accuracy#47.5$Zero-Shot Action Recognition#Olympics#Top-1 Accuracy#28.6$Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#22.3$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#48.2
1509.04767v2.pdf	Few-Shot Image Classification#CUB-200-2011 - 0-Shot#Top-1 Accuracy#30.4%
1706.00326v2.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (10-shot)#Accuracy#78.5
2002.12017v2.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#78.55%$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#78.55
2001.09849v4.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#76.47%$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#92.14$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#88.35%
1906.01905v2.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#67.2%
2003.12060v1.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#63.85$Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#89.40$Few-Shot Image Classification#Mini-ImageNet to CUB - 5 shot learning#Accuracy#69.30$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#72.66
1903.11341v2.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#63.73%
1806.02817v2.pdf	Few-Shot Image Classification#Mini-ImageNet - 1-Shot Learning#Accuracy#50.13%
2210.00174v1.pdf	Few-Shot Image Classification#ORBIT Clutter Video Evaluation#Frame accuracy#71.69
2107.01105v2.pdf	Few-Shot Image Classification#ORBIT Clutter Video Evaluation#Frame accuracy#66.3$Few-Shot Image Classification#ORBIT Clean Video Evaluation#Frame accuracy#82.70
2104.03841v5.pdf	Few-Shot Image Classification#ORBIT Clutter Video Evaluation#Frame accuracy#53.73$Few-Shot Image Classification#ORBIT Clean Video Evaluation#Frame accuracy#70.58
2207.01376v1.pdf	Few-Shot Image Classification#CUB 200 5-way 5-shot#Accuracy#93.37$Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#84.36
2209.06794v2.pdf	Few-Shot Image Classification#ImageNet#Top 1 Accuracy#85.8$Visual Question Answering#VQA v2 test-dev#Accuracy#84.3$Visual Question Answering#VizWiz 2020 VQA#overall#73.3$Visual Question Answering#TextVQA test-standard#overall#73.1$Image Captioning#nocaps entire#CIDEr#124.36$Image Captioning#nocaps entire#B1#88.1$Image Captioning#nocaps entire#B2#74.74$Image Captioning#nocaps entire#B3#57.91$Image Captioning#nocaps entire#B4#38.71$Image Captioning#nocaps entire#ROUGE-L#63.57$Image Captioning#nocaps entire#METEOR#33.12$Image Captioning#nocaps entire#SPICE#15.69$Image Captioning#nocaps near-domain#CIDEr#124.35$Image Captioning#nocaps near-domain#B1#88.57$Image Captioning#nocaps near-domain#B2#75.56$Image Captioning#nocaps near-domain#B3#58.99$Image Captioning#nocaps near-domain#B4#39.98$Image Captioning#nocaps near-domain#ROUGE-L#63.99$Image Captioning#nocaps near-domain#METEOR#33.47$Image Captioning#nocaps near-domain#SPICE#15.75$Image Captioning#nocaps in-domain#CIDEr#149.1$Image Captioning#nocaps in-domain#CIDEr#121.09$Image Captioning#nocaps in-domain#B1#88.02$Image Captioning#nocaps in-domain#B2#75.21$Image Captioning#nocaps in-domain#B3#59.38$Image Captioning#nocaps in-domain#B4#41.16$Image Captioning#nocaps in-domain#ROUGE-L#64.39$Image Captioning#nocaps in-domain#METEOR#34.22$Image Captioning#nocaps in-domain#SPICE#15.69$Image Captioning#nocaps out-of-domain#CIDEr#126.67$Image Captioning#nocaps out-of-domain#B1#86.28$Image Captioning#nocaps out-of-domain#B2#71.19$Image Captioning#nocaps out-of-domain#B3#52.63$Image Captioning#nocaps out-of-domain#B4#32.0$Image Captioning#nocaps out-of-domain#ROUGE-L#61.35$Image Captioning#nocaps out-of-domain#METEOR#30.99$Image Captioning#nocaps out-of-domain#SPICE#15.49$Image Classification#ImageNet#Top 1 Accuracy#90.9%$Image Classification#ImageNet#Number of params#3900M$Image Classification#ImageNet#Number of params#16900M$Image Classification#ObjectNet#Top 1 Accuracy#72.0$Image Classification#ImageNet V2#Top 1 Accuracy#84.3$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Private)#84.9$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Private)#42.62$Zero-Shot Transfer Image Classification#ObjectNet#Top 5 Accuracy#58.35$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#80.6$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#64.46$Zero-Shot Transfer Image Classification#ImageNet V2#Top 5 Accuracy#80.71$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#85.4$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#72.11$Zero-Shot Transfer Image Classification#ImageNet#Top 5 Accuracy#86.18$Zero-Shot Transfer Image Classification#ImageNet-S#Top 5 Accuracy#79.3$Zero-Shot Transfer Image Classification#ImageNet-S#Accuracy (Private)#63.83$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#96.1$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#81.97$Zero-Shot Transfer Image Classification#ImageNet-R#Top 5 Accuracy#91.51$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#88.0$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#44.7$Zero-Shot Transfer Image Classification#ImageNet-A#Top 5 Accuracy#62.72
2105.05348v2.pdf	Few-Shot Image Classification#CUB 200 5-way 1-shot#Accuracy#95.48$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#84.81
2111.04331v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#68.01
2204.04567v1.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.83$Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#67.34
2110.13188v3.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.94
1905.05301v2.pdf	Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#50.38
2105.11874v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#63.84$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#84.20$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#83.11$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#69.01
2210.06339v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#61.02$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#65.19$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#72.52$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#49.10
2210.03595v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#59.47$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#78.79
2106.10846v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#58.92$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#73.94
2011.14663v3.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#58.20$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#75.85$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#75.77$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#58.42
2010.02430v2.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#57.1$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#84.3$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#77.2$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#68.0
2008.09942v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#54.17$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#68.91
2209.13635v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#49.13$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#64.31$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#62.91$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#49.51
2202.08149v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#47.92$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#64.81
2006.11325v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#45.67$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#62.99
2201.05916v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#41.09$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#57.53$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#55.38$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#43.01
2001.03919v4.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#41.08$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#58.56$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#57.01$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#43.68
2004.05805v2.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#40.71$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (5-shot)#Accuracy#56.78$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#56.18$Unsupervised Few-Shot Image Classification#Tiered ImageNet 5-way (1-shot)#Accuracy#41.77
2006.10236v1.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#40.05$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#54.56
1811.11819v2.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#39.93$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#50.73
1810.02334v6.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#39.90$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#53.97
1902.09884v3.pdf	Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (1-shot)#Accuracy#37.67$Unsupervised Few-Shot Image Classification#Mini-Imagenet 5-way (5-shot)#Accuracy#49.18
2010.01824v1.pdf	Long-tail Learning#EGTEA#Average Precision#63.86$Long-tail Learning#EGTEA#Average Recall#66.24$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#57.43$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#38.5$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#41.26
1901.05555v1.pdf	Long-tail Learning#EGTEA#Average Precision#63.39$Long-tail Learning#EGTEA#Average Recall#63.26$Image Classification#iNaturalist 2018#Top-1 Accuracy#69.05%$Image Classification#iNaturalist 2018#Top-1 Accuracy#67.98%$Image Classification#iNaturalist 2018#Top-1 Accuracy#64.16%
2203.14197v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#42.29$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#46.45$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#53.9$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#31.33$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#70.2%
2209.02960v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#43.1$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#47.04$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.4$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#54.0$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#44.6$Long-tail Learning#Places-LT#Top-1 Accuracy#41.7$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#34.78
2203.15359v2.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#43.2$Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#15.3$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#46.7$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#58.4$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.4$Long-tail Learning#Places-LT#Top-1 Accuracy#41.5$Long-tail Learning#CIFAR-10-LT (ρ=50)#Error Rate#13.2$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#74.2%
2107.09249v4.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#46.1$Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#16.2$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#50.2$Long-tail Learning#CIFAR-10-LT (ρ=10)#Error Rate#9.2$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#61.4$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#58.8$Long-tail Learning#Places-LT#Top-1 Accuracy#41.3$Long-tail Learning#Places-LT#Top 1 Accuracy#40.9$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#36.4$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#77%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#72.9%$Image Classification#iNaturalist 2018#Top-1 Accuracy#72.9%
2104.00466v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#47.7$Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#17.9$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#53$Long-tail Learning#CIFAR-10-LT (ρ=10)#Error Rate#10$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#52.7$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#36.8$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#71.6%
2111.05956v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#49.1$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#53.41$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#38.87$Long-tail Learning#mini-ImageNet-LT#Error Rate#55.27
2103.14267v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#51.07$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#55.03$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#37.63$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#68.1%
2106.09859v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#51.5$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#55.5$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#51.8$Long-tail Learning#Places-LT#Top-1 Accuracy#39.3$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#70.3%
2006.07529v2.pdf	Long-tail Learning#CIFAR-100-LT (ρ=50)#Error Rate#52.89$Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#22.17$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#56.57$Long-tail Learning#CIFAR-10-LT (ρ=10)#Error Rate#11.47$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#51.3$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#41.09$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#68.1%
2207.09052v3.pdf	Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#15.68$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#46.1$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.1$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#71.8%
2004.02235v4.pdf	Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#20.37$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#56.50$Long-tail Learning#CIFAR-10-LT (ρ=10)#Error Rate#11.84$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#42.0$Long-tail Learning#Places-LT#Top-1 Accuracy#38.1$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#41.23$Long-tail learning with class descriptors#ImageNet-LT-d#Per-Class Accuracy#53.5$Long-tail learning with class descriptors#ImageNet-LT-d#Per-Class Accuracy#51.2$Long-tail learning with class descriptors#AWA-LT#Per-Class Accuracy#76.2$Long-tail learning with class descriptors#AWA-LT#Long-Tailed Accuracy#92.2$Long-tail learning with class descriptors#AWA-LT#Per-Class Accuracy#74.1$Long-tail learning with class descriptors#AWA-LT#Long-Tailed Accuracy#94.1$Long-tail learning with class descriptors#CUB-LT#Per-Class Accuracy#60.1$Long-tail learning with class descriptors#CUB-LT#Long-Tailed Accuracy#66.5$Long-tail learning with class descriptors#CUB-LT#Per-Class Accuracy#57.8$Long-tail learning with class descriptors#CUB-LT#Long-Tailed Accuracy#67.7$Long-tail learning with class descriptors#SUN-LT#Per-Class Accuracy#36.1$Long-tail learning with class descriptors#SUN-LT#Long-Tailed Accuracy#38.5$Long-tail learning with class descriptors#SUN-LT#Per-Class Accuracy#34.8$Long-tail learning with class descriptors#SUN-LT#Long-Tailed Accuracy#40.4$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (1-shot)#67.1$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (2-shots)#69.1$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (5-shots)#76.7$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (10-shots)#89.1$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (20-shots)#83.3$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (1-shot)#41.0$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (2-shots)#43.8$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (5-shots)#46.7$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (10-shots)#48.2$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (1-shot)#55.3$Generalized Few-Shot Learning#CUB#Per-Class Accuracy  (2-shots)#59.2$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (5-shots)#63.5$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (10-shots)#67.8$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (20-shots)#69.9
1906.07413v2.pdf	Long-tail Learning#CIFAR-10-LT (ρ=100)#Error Rate#22.97$Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#57.96$Long-tail Learning#CIFAR-10-LT (ρ=10)#Error Rate#11.84$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#41.29$Long-tail learning with class descriptors#AWA-LT#Per-Class Accuracy#69.1$Long-tail learning with class descriptors#AWA-LT#Long-Tailed Accuracy#93.5$Long-tail learning with class descriptors#CUB-LT#Per-Class Accuracy#50.1$Long-tail learning with class descriptors#CUB-LT#Long-Tailed Accuracy#64.1$Long-tail learning with class descriptors#SUN-LT#Per-Class Accuracy#29.8$Long-tail learning with class descriptors#SUN-LT#Long-Tailed Accuracy#36.4
2010.01809v4.pdf	Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#52$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#56.4$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#54.9$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#72.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#72.2%
2104.03066v2.pdf	Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#52.67$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#53.5$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#36.59
2012.00321v2.pdf	Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#54.6$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#53.0$Long-tail Learning#Places-LT#Top-1 Accuracy#38.8$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#38.3$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#70.0%$Image Classification#iNaturalist 2018#Top-1 Accuracy#70.0%
2010.11820v1.pdf	Long-tail Learning#CIFAR-100-LT (ρ=100)#Error Rate#56.9$Long-tail Learning#CIFAR-100-LT (ρ=10)#Error Rate#41.4$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#67.9%
2111.13579v4.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#77.2$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#70.1$Long-tail Learning#Places-LT#Top-1 Accuracy#50.1$Long-tail Learning#Places-LT#Top-1 Accuracy#48.0$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#81.0%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#74.6%$Image Classification#iNaturalist 2018#Top-1 Accuracy#81.0%$Image Classification#iNaturalist 2018#Top-1 Accuracy#74.6%
2111.14745v1.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#76.5$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#75.7$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#70.5$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#67.2$Long-tail Learning#Places-LT#Top-1 Accuracy#49.5$Long-tail Learning#Places-LT#Top-1 Accuracy#49.3$Long-tail Learning#Places-LT#Top-1 Accuracy#47.9$Long-tail Learning#Places-LT#Top-1 Accuracy#46.5
2107.12028v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#60.0$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#58.2$Long-tail Learning#Places-LT#Top-1 Accuracy#41.2$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#75.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#75.2%$Image Classification#ImageNet#Top 1 Accuracy#81.8%$Image Classification#ImageNet#Top 1 Accuracy#81.3%$Image Classification#ImageNet#Top 5 Accuracy#95.4$Image Classification#ImageNet#Top 1 Accuracy#80.9%$Image Classification#ImageNet#Top 5 Accuracy#95.2
2112.00412v3.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#58.0$Image Classification#iNaturalist 2018#Top-1 Accuracy#74.0%
2104.05279v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.7$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#55.6$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#75.3%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#73.6%$Image Classification#iNaturalist 2018#Top-1 Accuracy#75.3%$Image Classification#iNaturalist 2018#Top-1 Accuracy#73.6%
2101.10633v3.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.6$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#55.1$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#52.9$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#72.9%
2103.15042v3.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#57.12$Long-tail Learning#ImageNet-LT#Top-1 Accuracy#53.1$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#73.44%$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#71.71%
2103.16370v1.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#53.4$Long-tail Learning#Places-LT#Top-1 Accuracy#39.3$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#70.6%
2009.12991v4.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#51.8
2007.07314v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#51.3
2007.10740v3.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#41.8$Long-tail Learning#Places-LT#Top-1 Accuracy#38.7
1910.09217v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#41.4$Long-tail Learning#Places-LT#Top-1 Accuracy#37.6$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#69.5%$Long-tail learning with class descriptors#ImageNet-LT-d#Per-Class Accuracy#49.9$Long-tail learning with class descriptors#AWA-LT#Per-Class Accuracy#73.4$Long-tail learning with class descriptors#AWA-LT#Long-Tailed Accuracy#93.5$Long-tail learning with class descriptors#CUB-LT#Per-Class Accuracy#53.1$Long-tail learning with class descriptors#CUB-LT#Long-Tailed Accuracy#65.7$Long-tail learning with class descriptors#SUN-LT#Per-Class Accuracy#33.9$Long-tail learning with class descriptors#SUN-LT#Long-Tailed Accuracy#40.2
2004.03706v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#39.2$Long-tail Learning#Places-LT#Top-1 Accuracy#38.9
2001.01536v3.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#38.8$Long-tail Learning#Places-LT#Top-1 Accuracy#36.2
1904.05160v2.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#35.6$Long-tail Learning#Places-LT#Top-1 Accuracy#34.1$Long-tail learning with class descriptors#ImageNet-LT-d#Per-Class Accuracy#37.7
2008.03673v1.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#35.3$Long-tail Learning#Places-LT#Top-1 Accuracy#36.4$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#65.9%$Image Classification#iNaturalist 2018#Top-1 Accuracy#69.08%$Image Classification#iNaturalist 2018#Top-1 Accuracy#68.39%$Image Classification#iNaturalist 2018#Top-1 Accuracy#65.91%
2003.10780v1.pdf	Long-tail Learning#ImageNet-LT#Top-1 Accuracy#29.9$Long-tail Learning#Places-LT#Top-1 Accuracy#30.8$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#67.5%
2202.11233v1.pdf	Long-tail Learning#Places-LT#Top-1 Accuracy#47.17$Long-tail Learning#iNaturalist 2018#Top-1 Accuracy#80.24%
2012.06166v2.pdf	Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (5-shot)#Mean IoU#67.7$Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#41.6$Few-Shot Semantic Segmentation#PASCAL-5i (10-Shot)#Mean IoU#68.1$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#59.7$Few-Shot Semantic Segmentation#COCO-20i (10-shot)#Mean IoU#44.1$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#66.6$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#34.1$Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (1-shot)#Mean IoU#63.1
2008.01449v1.pdf	Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (5-shot)#Mean IoU#63.4$Few-Shot Semantic Segmentation#PASCAL-5i (10-Shot)#Mean IoU#62.1$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#60.8$Few-Shot Semantic Segmentation#COCO-20i (10-shot)#Mean IoU#39.7$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#61.9$Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (1-shot)#Mean IoU#61.1
2008.03898v2.pdf	Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (5-shot)#Mean IoU#53.8$Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#35.5$Few-Shot Semantic Segmentation#PASCAL-5i (10-Shot)#Mean IoU#57.6$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#56.3$Few-Shot Semantic Segmentation#COCO-20i (10-shot)#Mean IoU#33.1$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#57.3$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#30.6$Few-Shot Semantic Segmentation#COCO-20i -> Pascal VOC (1-shot)#Mean IoU#49.6
2206.09667v1.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#56.80$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#69.13$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#73.99$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#51.09
2206.06122v2.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#54.38$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#68.95$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#72.28$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#48.47
2203.07615v2.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#51.16$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#67.81$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#70.91$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#46.23
2207.11549v1.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#50.2$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#64.6$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#73.1$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#44.1$Few-Shot Semantic Segmentation#FSS-1000 (1-shot)#Mean IoU#87.3$Few-Shot Semantic Segmentation#FSS-1000 (5-shot)#Mean IoU#88.6
2203.15712v2.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#49.5$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#66.9$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#71.1$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#43.1
2112.11685v1.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#47.9$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#67.5$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#71.6$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#41.3$Few-Shot Semantic Segmentation#FSS-1000 (1-shot)#Mean IoU#90.0$Few-Shot Semantic Segmentation#FSS-1000 (5-shot)#Mean IoU#90.6$Semantic correspondence#SPair-71k#PCK#54.2$Semantic correspondence#PF-PASCAL#PCK#92.3$Semantic correspondence#PF-WILLOW#PCK#81.0
2207.10866v1.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#47.9$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#67.9$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#72$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#41.3$Few-Shot Semantic Segmentation#FSS-1000 (1-shot)#Mean IoU#90.3$Few-Shot Semantic Segmentation#FSS-1000 (5-shot)#Mean IoU#90.8$Semantic correspondence#SPair-71k#PCK#55.5$Semantic correspondence#PF-PASCAL#PCK#92.3$Semantic correspondence#PF-WILLOW#PCK#81.6
2104.01538v3.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#46.9$Few-Shot Semantic Segmentation#FSS-1000#Mean IoU#86.5$Few-Shot Semantic Segmentation#PASCAL-5i (10-Shot)#Mean IoU#70.6$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#66.2$Few-Shot Semantic Segmentation#COCO-20i (10-shot)#Mean IoU#48.7$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#70.4$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#41.2$Few-Shot Semantic Segmentation#FSS-1000 (1-shot)#Mean IoU#86.5$Few-Shot Semantic Segmentation#FSS-1000 (5-shot)#Mean IoU#88.5
2204.09903v2.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#46.48$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#62.80$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#67.80$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#41.39
2106.02320v4.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#45.6$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#64.3$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#66.6$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#40.3
2007.06309v2.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#38.5$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#51.5$Few-Shot Semantic Segmentation#Pascal5i#meanIOU#55.16$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#62.0$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#29.0
1909.13140v1.pdf	Few-Shot Semantic Segmentation#COCO-20i (5-shot)#Mean IoU#23.7$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#56.2$Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#51.9$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#59.9$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#55.1$Few-Shot Semantic Segmentation#COCO-20i (1-shot)#Mean IoU#21.2
2201.03546v2.pdf	Few-Shot Semantic Segmentation#FSS-1000#Mean IoU#87.8
2003.04052v3.pdf	Few-Shot Semantic Segmentation#FSS-1000#Mean IoU#83.36$Few-Shot Semantic Segmentation#Pascal5i#meanIOU#60.6
1912.06290v4.pdf	Few-Shot Semantic Segmentation#FSS-1000#Mean IoU#82.78
1907.12347v2.pdf	Few-Shot Semantic Segmentation#FSS-1000#Mean IoU#80.12
1910.05886v2.pdf	Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#57.0$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#60.6
1903.02351v1.pdf	Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#55.4$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#57.1
1908.06391v2.pdf	Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#48.1$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#55.7
1810.09091v4.pdf	Few-Shot Semantic Segmentation#PASCAL-5i (1-Shot)#Mean IoU#46.3$Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#47.1
2203.09550v5.pdf	Few-Shot Semantic Segmentation#PASCAL-5i (5-Shot)#Mean IoU#72.3
2106.03041v1.pdf	Cross-Domain Few-Shot#miniImagenet#Accuracy (%)#74.99%
2204.02121v2.pdf	Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#63.85 +- 0.44$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#60.89 +- 0.45$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#59.64 +- 0.44$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#55.54 +- 0.42$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#48.50 +- 0.42$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#28.79 +- 0.38$Few-Shot Audio Classification#VoxCeleb1#Top-1 Accuracy(5-Way-1-Shot)#28.09 +- 0.37$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#43.45 +- 0.46$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#43.18 +- 0.45$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#42.05 +- 0.42$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#40.27 +- 0.44$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#39.44 +- 0.44$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#38.78 +- 0.41$Few-Shot Audio Classification#FSDKaggle2018#Top-1 Accuracy(5-Way-1-Shot)#33.52 +- 0.39$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#61.34 +- 0.46$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#57.66 +- 0.43$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#57.28 +- 0.41$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#56.26 +- 0.45$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#56.11 +- 0.46$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#36.41 +- 0.42$Few-Shot Audio Classification#BirdClef 2020  (Pruned)#Top-1 Accuracy(5-Way-1-Shot)#33.04 +- 0.41$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#96.47 +-0.19$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#95.23 +- 0.19$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#93.85 +- 0.24$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#90.74 +- 0.25$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#90.04 +- 0.27$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#66.68 +- 0.41$Few-Shot Audio Classification#NSynth#Top-1 Accuracy(5-Way-1-Shot)#63.78 +- 0.42$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#76.17 +- 0.41$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#71.72 +- 0.38$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#68.83 +- 0.38$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#68.82 +-0.39$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#64.48 +- 0.41$Few-Shot Audio Classification#ESC-50#Top-1 Accuracy(5-Way-1-Shot)#60.41 +- 0.41
2105.10438v1.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#69.4
2003.07833v2.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#64.9$Zero-Shot Learning#Oxford 102 Flower#average top-1 classification accuracy#70.8$Zero-Shot Learning#AwA2#average top-1 classification accuracy#72.2$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#66$Generalized Zero-Shot Learning#AwA2#Harmonic mean#66.6$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#43$Generalized Zero-Shot Learning#CUB-200-2011#Harmonic mean#58.1$Generalized Zero-Shot Learning#Oxford 102 Flower#Harmonic mean#71.7
1903.10132v1.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#61.0$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#64.7$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#41.3
1908.05832v1.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#59.5$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#61.5$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#34.0
1904.04092v1.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#58.8$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#61.7$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#40.2
1808.00136v2.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#58.6$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#59.9$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#39.4
1712.00981v2.pdf	Zero-Shot Learning#CUB-200-2011#average top-1 classification accuracy#57.3$Zero-Shot Learning#SUN Attribute#average top-1 classification accuracy#60.8$Generalized Zero-Shot Learning#SUN Attribute#Harmonic mean#39.4
2206.08155v2.pdf	Zero-Shot Learning#TVQA#Accuracy#59.7$Zero-Shot Learning#ActivityNet-QA#Accuracy#25.9$Zero-Shot Learning#iVQA#Accuracy#0.268$Zero-Shot Learning#How2QA#Accuracy#58.4$Zero-Shot Learning#LSMDC#Accuracy#51.5$Zero-Shot Learning#MSRVTT-QA#Accuracy#16.7$Zero-Shot Learning#MSVD-QA#Accuracy#33.8$Zero-Shot Learning#TGIF-QA#Accuracy#41.9$Visual Question Answering#MSVD-QA#Accuracy#0.548$Visual Question Answering#MSRVTT-QA#Accuracy#0.470$Video Question Answering#ActivityNet-QA#Accuracy#0.432$Video Question Answering#iVQA#Accuracy#0.396$Video Question Answering#MSRVTT-QA#Accuracy#47.0$Video Question Answering#How2QA#Accuracy#86.7$Video Question Answering#TVQA#Accuracy#82
2203.06850v3.pdf	Zero-Shot Learning#Winogrande#Accuracy#54.31$Zero-Shot Learning#COPA#Accuracy#79.00$Zero-Shot Learning#COPA#Accuracy#76.00$Zero-Shot Learning#COPA#Accuracy#75.0$Zero-Shot Learning#COPA#Accuracy#64.00$Zero-Shot Learning#COPA#Accuracy#63.00$Zero-Shot Learning#ReCoRD#Accuracy#73.42$Zero-Shot Learning#PIQA#Accuracy#72.96$Zero-Shot Learning#HellaSwag#Accuracy#54.53$Zero-Shot Learning#StoryCloze#Accuracy#74.67
2012.00451v3.pdf	Zero-Shot Learning#ActivityNet-QA#Accuracy#12.2$Zero-Shot Learning#How2QA#Accuracy#51.1$Visual Question Answering#MSVD-QA#Accuracy#0.463$Visual Question Answering#MSRVTT-QA#Accuracy#0.415$Video Question Answering#ActivityNet-QA#Accuracy#0.389$Video Question Answering#iVQA#Accuracy#0.354$Video Question Answering#How2QA#Accuracy#84.4
2006.10713v4.pdf	Zero-Shot Learning#SNIPS#Accuracy#88.98$Zero-Shot Learning#AwA2#average top-1 classification accuracy#78.08$Zero-Shot Learning#ImageNet#Top-1#3.0$Zero-Shot Learning#aPY - 0-Shot#Top-1#60.54$Generalized Zero-Shot Learning#AwA2#Harmonic mean#74.58$Generalized Zero-Shot Learning#BBN Pronoun Coreference and Entity Type Corpus#F1#26.69$Generalized Zero-Shot Learning#ImageNet#Top-1#1.7$Generalized Zero-Shot Learning#aPY - 0-Shot#Harmonic mean#61.57$Generalized Zero-Shot Learning#OntoNotes#F1#45.21
2210.03780v1.pdf	Zero-Shot Learning#MIT-States#A-acc#36.0
1906.03038v3.pdf	Zero-Shot Learning#CUB-200 - 0-Shot Learning#Average Per-Class Accuracy#70.9
1906.00817v2.pdf	Zero-Shot Learning#PASCAL Context#k=10 mIOU#26.3
2204.11822v4.pdf	Generalized Zero-Shot Learning#AwA2#Accuracy Unseen#65.4$Generalized Zero-Shot Learning#AwA2#Accuracy Seen#82.2$Generalized Zero-Shot Learning#AwA2#H#72.8$Generalized Zero-Shot Learning#aPY#H#46$Generalized Zero-Shot Learning#SUN Attribute#H#43.2$Generalized Zero-Shot Learning#Caltech-UCSD Birds 200 - 2011#H#68.7
2004.00587v1.pdf	Compositional Zero-Shot Learning#UT-Zappos#Top-1 accuracy %#52.1$Compositional Zero-Shot Learning#UT-Zappos#Top-2 accuracy %#67.8$Compositional Zero-Shot Learning#UT-Zappos#Top-3 accuracy %#76.0$Compositional Zero-Shot Learning#MIT-States, generalized split#H-Mean#16.1$Compositional Zero-Shot Learning#MIT-States, generalized split#Seen accuracy#24.4$Compositional Zero-Shot Learning#MIT-States, generalized split#Test AUC top 1#3.0$Compositional Zero-Shot Learning#MIT-States, generalized split#Test AUC top 2#7.6$Compositional Zero-Shot Learning#MIT-States, generalized split#Test AUC top 3#12.3$Compositional Zero-Shot Learning#MIT-States, generalized split#Unseen accuracy#25.2$Compositional Zero-Shot Learning#MIT-States, generalized split#Val AUC top 1#4.3$Compositional Zero-Shot Learning#MIT-States, generalized split#Val AUC top 2#9.8$Compositional Zero-Shot Learning#MIT-States, generalized split#Val AUC top 3#14.8$Compositional Zero-Shot Learning#MIT-States#Top-1 accuracy %#19.9$Compositional Zero-Shot Learning#MIT-States#Top-2 accuracy %#28.2$Compositional Zero-Shot Learning#MIT-States#Top-3 accuracy %#33.8
2208.09562v1.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#39.01$Multi-label zero-shot learning#NUS-WIDE#mAP#36.56$Multi-label zero-shot learning#ImageNet-1k to MSCOCO#mAP#67.10$Multi-Label Classification#MS-COCO#mAP#93.54$Multi-Label Classification#MS-COCO#mAP#93.41$Multi-Label Classification#MS-COCO#mAP#91.76
2111.12933v2.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#31.1$Multi-Label Classification#OpenImages-v6#mAP#86.8$Multi-Label Classification#MS-COCO#mAP#91.4$Multi-Label Classification#MS-COCO#mAP#91.1$Image Classification#CIFAR-100#Percentage correct#95.1$Fine-Grained Image Classification#Stanford Cars#Accuracy#96.41%
2108.09301v1.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#26.3$Multi-label zero-shot learning#Open Images V4#MAP#73.6
2105.05926v1.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#25.9$Multi-label zero-shot learning#Open Images V4#MAP#62.9
2101.11606v2.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#25.7
1605.09759v1.pdf	Multi-label zero-shot learning#NUS-WIDE#mAP#15.1$Multi-label zero-shot learning#Open Images V4#MAP#41.2
1503.08677v2.pdf	Multi-label zero-shot learning#Open Images V4#MAP#40.5$Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#23.4$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#50.3
1708.00524v2.pdf	Transfer Learning#Amazon Review Polarity#Accuracy#12.8$Sentiment Analysis#1B Words#1 in 10 R@1#17$Sentiment Analysis#MR#Training Time#1500$Sarcasm Detection#SCv1#F1#0.69
2012.13255v1.pdf	Transfer Learning#Amazon Review Polarity#Structure Aware Intrinsic Dimension#1200$Semantic Textual Similarity#MRPC#Direct Intrinsic Dimension#1861$Semantic Textual Similarity#MRPC#Structure Aware Intrinsic Dimension#1608$Semantic Textual Similarity#MRPC#Structure Aware Intrinsic Dimension#1037$Paraphrase Identification#Quora Question Pairs#Direct Intrinsic Dimension#9295$Paraphrase Identification#Quora Question Pairs#Structure Aware Intrinsic Dimension#8030
2008.03464v1.pdf	Transfer Learning#ImageCLEF-DA#Accuracy#5.32$Transfer Learning#KITTI Object Tracking Evaluation 2012#EER#5.74
2003.05379v1.pdf	Transfer Learning#100 sleep nights of 8 caregivers#10-20% Mask PSNR#3.23
2103.14660v1.pdf	Transfer Learning#Retinal Fundus MultiDisease Image Dataset (RFMiD)#AUROC#0.95
2111.12853v4.pdf	Transfer Learning#Office-Home#Accuracy#84.2
1810.04650v2.pdf	Multi-Task Learning#CelebA#Error#8.25$Multi-Task Learning#Cityscapes test#mIoU#66.63
1910.04915v2.pdf	Multi-Task Learning#OMNIGLOT#Average Accuracy#93.52
2210.11416v2.pdf	Multi-task Language Understanding#MMLU#Average (%)#75.2$Multi-task Language Understanding#MMLU#Average (%)#74.1$Multi-task Language Understanding#MMLU#Parameters (Billions)#540$Multi-task Language Understanding#MMLU#Average (%)#73.5$Multi-task Language Understanding#MMLU#Average (%)#72.2$Multi-task Language Understanding#MMLU#Average (%)#70.9$Multi-task Language Understanding#MMLU#Average (%)#70.2$Multi-task Language Understanding#MMLU#Average (%)#69.8$Multi-task Language Understanding#MMLU#Average (%)#66.1$Multi-task Language Understanding#MMLU#Parameters (Billions)#62$Multi-task Language Understanding#MMLU#Average (%)#62$Multi-task Language Understanding#MMLU#Average (%)#59.6$Multi-task Language Understanding#MMLU#Average (%)#56.9$Multi-task Language Understanding#MMLU#Average (%)#55.1$Multi-task Language Understanding#MMLU#Parameters (Billions)#11$Multi-task Language Understanding#MMLU#Average (%)#52.4$Multi-task Language Understanding#MMLU#Parameters (Billions)#3$Multi-task Language Understanding#MMLU#Average (%)#49.3$Multi-task Language Understanding#MMLU#Parameters (Billions)#8$Multi-task Language Understanding#MMLU#Average (%)#48.6$Multi-task Language Understanding#MMLU#Average (%)#45.5$Multi-task Language Understanding#MMLU#Average (%)#45.1$Multi-task Language Understanding#MMLU#Average (%)#41.3$Multi-task Language Understanding#MMLU#Average (%)#40.5$Multi-task Language Understanding#MMLU#Average (%)#35.9$Multi-task Language Understanding#MMLU#Average (%)#33.7$Multi-task Language Understanding#MMLU#Average (%)#28.7$Multi-task Language Understanding#MMLU#Average (%)#12.1$Multi-task Language Understanding#MMLU#Parameters (Billions)#80$Multi-task Language Understanding#MMLU#Parameters (Billions)#250$Multi-task Language Understanding#MMLU#Parameters (Billions)#780$Multi-task Language Understanding#BBH-nlp#Average (%)#78.4$Multi-task Language Understanding#BBH-nlp#Average (%)#72.4$Multi-task Language Understanding#BBH-nlp#Average (%)#70$Multi-task Language Understanding#TyDi QA#Average (%)#67.8$Multi-task Language Understanding#BBH-alg#Average (%)#66.5$Multi-task Language Understanding#BBH-alg#Average (%)#61.3$Multi-task Language Understanding#BBH-alg#Average (%)#48.2$Multi-task Language Understanding#MGSM#Average (%)#72$Multi-task Language Understanding#MGSM#Average (%)#57$Multi-task Language Understanding#MGSM#Average (%)#21.2
2210.11399v1.pdf	Multi-task Language Understanding#MMLU#Average (%)#70.7$Multi-task Language Understanding#MMLU#Parameters (Billions)#540$Question Answering#StrategyQA#Accuracy#76.6$Question Answering#StrategyQA#Accuracy#76.4$Question Answering#StrategyQA#Accuracy#61.9$Cross-Lingual Question Answering#TyDiQA-GoldP#EM#78.4$Cross-Lingual Question Answering#TyDiQA-GoldP#F1#88.5$Arithmetic Reasoning#GSM8K#Accuracy#58.5$Arithmetic Reasoning#GSM8K#Parameters#540
2204.02311v5.pdf	Multi-task Language Understanding#MMLU#Humanities#77.0$Multi-task Language Understanding#MMLU#Average (%)#69.3$Multi-task Language Understanding#MMLU#Parameters (Billions)#540$Multi-task Language Understanding#MMLU#STEM#55.6$Multi-task Language Understanding#MMLU#Social Sciences#81.0$Multi-task Language Understanding#MMLU#Other#69.6$Multi-task Language Understanding#MMLU#Tokens (Billions)#780$Question Answering#BoolQ#Accuracy#92.2$Question Answering#WebQuestions#EM#43.5$Question Answering#WebQuestions#EM#22.6$Question Answering#WebQuestions#EM#10.6$Question Answering#MultiRC#F1#90.1$Question Answering#MultiRC#EM#69.2$Question Answering#COPA#Accuracy#100$Question Answering#Natural Questions#EM#39.6$Question Answering#Natural Questions#EM#29.3$Question Answering#Natural Questions#EM#21.2$Question Answering#TriviaQA#EM#81.4$Question Answering#TriviaQA#EM#76.9$Common Sense Reasoning#ReCoRD#F1#94.6$Common Sense Reasoning#ReCoRD#EM#94.0$Winowhy#BIG-bench#Accuracy#65.9$Winowhy#BIG-bench#Accuracy#61.0$Word Sense Disambiguation#Words in Context#Accuracy#78.8$Natural Language Inference#CommitmentBank#F1#100$Natural Language Inference#CommitmentBank#Accuracy#100$Natural Language Inference#RTE#Accuracy#95.7%$Language Modelling#LAMBADA#Accuracy#89.7$Language Modelling#LAMBADA#Accuracy#81.8$Language Modelling#LAMBADA#Accuracy#77.9$Coreference Resolution#WSC#Accuracy#89.5$Extreme Summarization#GEM-XSum#ROUGE-2#21.2$Extreme Summarization#GEM-XSum#Parameters#540 B$Extreme Summarization#GEM-XSum#ROUGE-2#21.0$Extreme Summarization#GEM-XSum#ROUGE-2#18.5$Extreme Summarization#GEM-XSum#Parameters#62 B$Sentence Completion#HellaSwag#Accuracy#83.8$Sentence Completion#HellaSwag#Accuracy#83.6$Sentence Completion#HellaSwag#Accuracy#83.4$Auto Debugging#Big-bench Lite#Accuracy#14.7$Known Unknowns#BIG-bench#Accuracy#73.9$Hindu Knowledge#BIG-bench#Accuracy#95.4$Hindu Knowledge#BIG-bench#Accuracy#77.7$Novel Concepts#BIG-bench#Accuracy#71.9$Novel Concepts#BIG-bench#Accuracy#59.4$StrategyQA#BIG-bench#Accuracy#73.9$StrategyQA#BIG-bench#Accuracy#65.4$Logic Grid Puzzle#BIG-bench#Accuracy#42.4$Logic Grid Puzzle#BIG-bench#Accuracy#36.5
2005.00700v3.pdf	Multi-task Language Understanding#MMLU#Humanities#45.6$Multi-task Language Understanding#MMLU#Average (%)#48.9$Multi-task Language Understanding#MMLU#Parameters (Billions)#11$Multi-task Language Understanding#MMLU#STEM#40.2$Multi-task Language Understanding#MMLU#Social Sciences#56.6$Multi-task Language Understanding#MMLU#Other#54.6$Question Answering#CommonsenseQA#Test Accuracy#79.1$Common Sense Reasoning#CommonsenseQA#Accuracy#79.1
2208.03299v2.pdf	Multi-task Language Understanding#MMLU#Humanities#46.1$Multi-task Language Understanding#MMLU#Average (%)#47.9$Multi-task Language Understanding#MMLU#Parameters (Billions)#11$Multi-task Language Understanding#MMLU#STEM#38.8$Multi-task Language Understanding#MMLU#Social Sciences#54.6$Multi-task Language Understanding#MMLU#Other#52.8$Question Answering#Natural Questions#EM#60.4$Question Answering#Natural Questions#EM#42.4
2204.06745v1.pdf	Multi-task Language Understanding#MMLU#Humanities#29.8$Multi-task Language Understanding#MMLU#Average (%)#33.6$Multi-task Language Understanding#MMLU#Parameters (Billions)#20$Multi-task Language Understanding#MMLU#STEM#34.9$Multi-task Language Understanding#MMLU#Social Sciences#33.7$Multi-task Language Understanding#MMLU#Other#37.7$Multi-task Language Understanding#MMLU#Tokens (Billions)#300$Multi-task Language Understanding#MMLU#Humanities#28.2$Multi-task Language Understanding#MMLU#Average (%)#28.6$Multi-task Language Understanding#MMLU#STEM#27.2$Multi-task Language Understanding#MMLU#Social Sciences#30.8$Multi-task Language Understanding#MMLU#Other#29.2$Multi-task Language Understanding#MMLU#Humanities#27.8$Multi-task Language Understanding#MMLU#Average (%)#27.3$Multi-task Language Understanding#MMLU#Parameters (Billions)#6$Multi-task Language Understanding#MMLU#STEM#25.7$Multi-task Language Understanding#MMLU#Social Sciences#28.7$Multi-task Language Understanding#MMLU#Other#28.0
1909.11942v6.pdf	Multi-task Language Understanding#MMLU#Humanities#27.2$Multi-task Language Understanding#MMLU#Average (%)#27.1$Multi-task Language Understanding#MMLU#Parameters (Billions)#0.031$Multi-task Language Understanding#MMLU#STEM#27.7$Multi-task Language Understanding#MMLU#Social Sciences#25.7$Multi-task Language Understanding#MMLU#Other#27.9$Question Answering#SQuAD2.0 dev#F1#88.1$Question Answering#SQuAD2.0 dev#EM#85.1$Question Answering#SQuAD2.0 dev#F1#85.9$Question Answering#SQuAD2.0 dev#EM#83.1$Question Answering#SQuAD2.0 dev#F1#82.1$Question Answering#SQuAD2.0 dev#EM#79$Question Answering#SQuAD2.0 dev#F1#79.1$Question Answering#SQuAD2.0 dev#EM#76.1$Question Answering#SQuAD2.0#EM#89.731$Question Answering#SQuAD2.0#F1#92.215$Question Answering#SQuAD2.0#EM#88.107$Question Answering#SQuAD2.0#F1#90.902$Question Answering#Quora Question Pairs#Accuracy#90.5%$Common Sense Reasoning#CommonsenseQA#Accuracy#76.5$Natural Language Inference#QNLI#Accuracy#99.2%$Natural Language Inference#WNLI#Accuracy#91.8%$Natural Language Inference#RTE#Accuracy#89.2%$Natural Language Inference#MultiNLI#Matched#91.3$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.925$Semantic Textual Similarity#MRPC#Accuracy#93.4%$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.1$Linguistic Acceptability#CoLA#Accuracy#69.1%
2009.03300v3.pdf	Multi-task Language Understanding#MMLU#Humanities#25.0$Multi-task Language Understanding#MMLU#Average (%)#25.0$Multi-task Language Understanding#MMLU#STEM#25.0$Multi-task Language Understanding#MMLU#Social Sciences#25.0$Multi-task Language Understanding#MMLU#Other#25.0
2206.14858v2.pdf	Multi-task Language Understanding#MMLU#STEM#75.0$Multi-task Language Understanding#MMLU#Tokens (Billions)#540$Multi-task Language Understanding#MMLU#STEM#63.9$Multi-task Language Understanding#MMLU#STEM#63.5$Multi-task Language Understanding#MMLU#Tokens (Billions)#62$Multi-task Language Understanding#MMLU#STEM#53.9$Multi-task Language Understanding#MMLU#STEM#43.4$Multi-task Language Understanding#MMLU#Tokens (Billions)#8$Multi-task Language Understanding#MMLU#STEM#39.1$Multi-task Language Understanding#MMLU#STEM#35.6$Multi-task Language Understanding#MMLU#STEM#22.0$Math Word Problem Solving#MATH#Accuracy#50.3$Math Word Problem Solving#MATH#Parameters (Billions)#540$Math Word Problem Solving#MATH#Accuracy#43.4$Math Word Problem Solving#MATH#Parameters (Billions)#62$Math Word Problem Solving#MATH#Accuracy#33.6$Math Word Problem Solving#MATH#Accuracy#27.6$Math Word Problem Solving#MATH#Accuracy#25.4$Math Word Problem Solving#MATH#Parameters (Billions)#8$Math Word Problem Solving#MATH#Accuracy#19.1$Math Word Problem Solving#MATH#Accuracy#14.1$Math Word Problem Solving#MATH#Accuracy#8.8$Math Word Problem Solving#MATH#Accuracy#4.4$Math Word Problem Solving#MATH#Accuracy#1.5$Arithmetic Reasoning#GSM8K#Accuracy#78.5$Arithmetic Reasoning#GSM8K#Parameters#540$Arithmetic Reasoning#GSM8K#Accuracy#68.5$Arithmetic Reasoning#GSM8K#Parameters#62$Arithmetic Reasoning#GSM8K#Accuracy#58.8$Arithmetic Reasoning#GSM8K#Accuracy#56.5$Arithmetic Reasoning#GSM8K#Accuracy#52.4$Arithmetic Reasoning#GSM8K#Accuracy#33.0$Arithmetic Reasoning#GSM8K#Accuracy#28.4$Arithmetic Reasoning#GSM8K#Parameters#8$Arithmetic Reasoning#GSM8K#Accuracy#16.2$Arithmetic Reasoning#GSM8K#Accuracy#4.1
2104.00233v1.pdf	Unsupervised Domain Expansion#UDE-Office-Home#1:1 Accuracy#72.67$Unsupervised Domain Expansion#UDE-DomainNet#1:1 Accuracy#60.91
2109.00122v3.pdf	Question Answering#FinQA#Execution Accuracy#65.05$Question Answering#FinQA#Program Accuracy#63.52$Question Answering#FinQA#Execution Accuracy#57.43$Question Answering#FinQA#Program Accuracy#55.52$Question Answering#FinQA#Execution Accuracy#53.71$Question Answering#FinQA#Program Accuracy#51.71
2101.00178v2.pdf	Question Answering#EfficientQA test#Accuracy#54$Question Answering#EfficientQA dev#Accuracy#54.1$Question Answering#TriviaQA#F1#70.3$Open-Domain Question Answering#Natural Questions#Exact Match#54.7$Open-Domain Question Answering#TriviaQA#Exact Match#70.5
2109.04066v1.pdf	Question Answering#FriendsQA#EM#58.7$Question Answering#FriendsQA#F1#75.4$Question Answering#Molweni#F1#72.2$Question Answering#Molweni#EM#58.6
2109.03772v2.pdf	Question Answering#FriendsQA#EM#55.8$Question Answering#FriendsQA#F1#72.3$Question Answering#FriendsQA#EM#46.9$Question Answering#FriendsQA#F1#63.9$Question Answering#Molweni#F1#72.9$Question Answering#Molweni#EM#58$Question Answering#Molweni#F1#64$Question Answering#Molweni#EM#49.2
2004.03561v2.pdf	Question Answering#FriendsQA#EM#53.5$Question Answering#FriendsQA#F1#69.6$Question Answering#FriendsQA#EM#46.8$Question Answering#FriendsQA#F1#63.1
1810.04805v2.pdf	Question Answering#SQuAD1.1#EM#87.433$Question Answering#SQuAD1.1#F1#93.160$Question Answering#SQuAD1.1#EM#85.083$Question Answering#SQuAD1.1#F1#91.835$Question Answering#SQuAD2.0 dev#F1#81.9$Question Answering#SQuAD2.0 dev#EM#78.7$Question Answering#CoQA#In-domain#82.5$Question Answering#CoQA#Out-of-domain#77.6$Question Answering#CoQA#Overall#81.1$Question Answering#CoQA#In-domain#79.8$Question Answering#CoQA#Out-of-domain#74.1$Question Answering#CoQA#Overall#78.1$Question Answering#SQuAD2.0#EM#80.005$Question Answering#SQuAD2.0#F1#83.061$Question Answering#MultiRC#F1#70.0$Question Answering#MultiRC#EM#24.1$Question Answering#MRQA#Average F1#78.5$Question Answering#Quora Question Pairs#Accuracy#72.1%$Question Answering#SQuAD1.1 dev#EM#84.2$Question Answering#SQuAD1.1 dev#F1#91.1$Question Answering#SQuAD1.1 dev#EM#84.1$Question Answering#SQuAD1.1 dev#F1#90.9$Question Answering#SQuAD1.1 dev#EM#80.8$Question Answering#SQuAD1.1 dev#F1#88.5$Common Sense Reasoning#Winograd Schema Challenge#Score#62.0$Common Sense Reasoning#SWAG#Dev#86.6$Common Sense Reasoning#SWAG#Test#86.3$Common Sense Reasoning#SWAG#Dev#81.6$Common Sense Reasoning#SWAG#Test#-$Common Sense Reasoning#ReCoRD#F1#56.065$Common Sense Reasoning#ReCoRD#EM#54.040$Natural Language Inference#SciTail#Accuracy#92.0$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-Spanish#Accuracy#74.3%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-German#Accuracy#70.5%$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#48.96$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#45.18$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.9$Named Entity Recognition#BC5CDR#F1#85.61$Named Entity Recognition#SciERC#F1#65.24$Named Entity Recognition#CoNLL 2003 (English)#F1#92.8$Named Entity Recognition#CoNLL 2003 (English)#F1#92.4$Named Entity Recognition#NCBI-disease#F1#86.37$Type prediction#ManyTypes4TypeScript#Average Accuracy#57.52$Type prediction#ManyTypes4TypeScript#Average Precision#54.18$Type prediction#ManyTypes4TypeScript#Average Recall#54.02$Type prediction#ManyTypes4TypeScript#Average F1#54.10$Text Classification#DBpedia#Error#0.64$Sentence Classification#SciCite#F1#84.4$Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#24.0%$Natural Language Understanding#PDP60#Accuracy#78.3$Natural Language Understanding#WNLI#Accuracy#65.1
1705.02798v6.pdf	Question Answering#SQuAD1.1#EM#82.283$Question Answering#SQuAD1.1#F1#88.533$Question Answering#SQuAD1.1#EM#79.545$Question Answering#SQuAD1.1#F1#86.654$Question Answering#SQuAD1.1#EM#74.268$Question Answering#SQuAD1.1#F1#82.371$Question Answering#SQuAD1.1#EM#70.995$Question Answering#SQuAD1.1#F1#80.146$Question Answering#TriviaQA#EM#46.94$Question Answering#TriviaQA#F1#52.85$Question Answering#SQuAD1.1 dev#EM#78.9$Question Answering#SQuAD1.1 dev#F1#86.3
2112.00459v3.pdf	Question Answering#SQuAD1.1#EM#81.5$Question Answering#SQuAD1.1#F1#88.5$Question Answering#SQuAD1.1#EM#77.7$Question Answering#SQuAD1.1#F1#85.8$Knowledge Distillation#ImageNet#Top-1 accuracy %#71.96
1802.05365v2.pdf	Question Answering#SQuAD1.1#EM#81.003$Question Answering#SQuAD1.1#F1#87.432$Question Answering#SQuAD1.1#EM#78.58$Question Answering#SQuAD1.1#F1#85.833$Question Answering#SQuAD2.0#EM#63.372$Question Answering#SQuAD2.0#F1#66.251$Question Answering#SQuAD1.1 dev#F1#85.6$Word Sense Disambiguation#Supervised:#Senseval 2#71.6$Word Sense Disambiguation#Supervised:#Senseval 3#69.6$Word Sense Disambiguation#Supervised:#SemEval 2007#62.2$Word Sense Disambiguation#Supervised:#SemEval 2013#66.2$Word Sense Disambiguation#Supervised:#SemEval 2015#71.3$Natural Language Inference#SNLI#% Test Accuracy#89.3$Natural Language Inference#SNLI#% Train Accuracy#92.1$Natural Language Inference#SNLI#Parameters#40m$Natural Language Inference#SNLI#% Test Accuracy#88.7$Natural Language Inference#SNLI#% Train Accuracy#91.6$Natural Language Inference#SNLI#Parameters#8.0m$Semantic Role Labeling#OntoNotes#F1#84.6$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#54.7$Named Entity Recognition#CoNLL++#F1#93.42$Named Entity Recognition#CoNLL 2003 (English)#F1#92.22$Coreference Resolution#OntoNotes#F1#70.4$Citation Intent Classification#ACL-ARC#F1#54.6$Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#19.3%
1712.03556v2.pdf	Question Answering#SQuAD1.1#EM#79.608$Question Answering#SQuAD1.1#F1#86.496$Question Answering#SQuAD1.1#EM#76.828$Question Answering#SQuAD1.1#F1#84.396$Question Answering#SQuAD2.0#EM#71.316$Question Answering#SQuAD2.0#F1#73.704$Question Answering#SQuAD2.0#EM#68.653$Question Answering#SQuAD2.0#F1#71.439$Question Answering#SQuAD1.1 dev#EM#76.235$Question Answering#SQuAD1.1 dev#F1#84.056
1711.07341v2.pdf	Question Answering#SQuAD1.1#EM#78.978$Question Answering#SQuAD1.1#F1#86.016$Question Answering#SQuAD1.1#EM#75.968$Question Answering#SQuAD1.1#F1#83.900$Question Answering#SQuAD2.0#EM#70.300$Question Answering#SQuAD2.0#F1#72.484$Question Answering#SQuAD1.1 dev#EM#75.3$Question Answering#SQuAD1.1 dev#F1#83.6
1711.00106v2.pdf	Question Answering#SQuAD1.1#EM#78.852$Question Answering#SQuAD1.1#F1#85.996$Question Answering#SQuAD1.1#EM#74.866$Question Answering#SQuAD1.1#F1#82.806$Question Answering#SQuAD1.1 dev#EM#74.5$Question Answering#SQuAD1.1 dev#F1#83.1
1707.09098v1.pdf	Question Answering#SQuAD1.1#EM#78.234$Question Answering#SQuAD1.1#F1#85.344$Question Answering#SQuAD1.1#EM#75.370$Question Answering#SQuAD1.1#F1#82.658$Question Answering#TriviaQA#EM#43.16$Question Answering#TriviaQA#F1#46.90
1712.03609v4.pdf	Question Answering#SQuAD1.1#EM#77.583$Question Answering#SQuAD1.1#F1#84.163$Question Answering#SQuAD1.1#EM#75.789$Question Answering#SQuAD1.1#F1#83.261
1710.10504v2.pdf	Question Answering#SQuAD1.1#EM#76.996$Question Answering#SQuAD1.1#F1#84.630$Question Answering#SQuAD1.1#EM#74.405$Question Answering#SQuAD1.1#F1#82.742$Question Answering#SQuAD1.1#EM#73.240$Question Answering#SQuAD1.1#F1#81.933$Question Answering#SQuAD1.1 dev#EM#72.1$Question Answering#SQuAD1.1 dev#F1#81.4
1804.09541v1.pdf	Question Answering#SQuAD1.1#EM#76.2$Question Answering#SQuAD1.1#F1#84.6$Question Answering#SQuAD1.1 dev#EM#75.1$Question Answering#SQuAD1.1 dev#F1#83.8$Question Answering#SQuAD1.1 dev#EM#74.5$Question Answering#SQuAD1.1 dev#F1#83.2$Question Answering#SQuAD1.1 dev#EM#73.6$Question Answering#SQuAD1.1 dev#F1#82.7
1809.03449v3.pdf	Question Answering#SQuAD1.1#EM#76.125$Question Answering#SQuAD1.1#F1#83.538$Question Answering#SQuAD1.1 dev#EM#76.7$Question Answering#SQuAD1.1 dev#F1#84.9
1609.05284v3.pdf	Question Answering#SQuAD1.1#EM#75.034$Question Answering#SQuAD1.1#F1#82.552$Question Answering#SQuAD1.1#EM#70.555$Question Answering#SQuAD1.1#F1#79.364$Question Answering#CNN / Daily Mail#CNN#74.7$Question Answering#CNN / Daily Mail#Daily Mail#76.6
1703.00572v3.pdf	Question Answering#SQuAD1.1#EM#74.090$Question Answering#SQuAD1.1#F1#81.761$Question Answering#SQuAD1.1#EM#73.723$Question Answering#SQuAD1.1#F1#81.530$Question Answering#SQuAD1.1#EM#68.478$Question Answering#SQuAD1.1#F1#77.971$Question Answering#SQuAD1.1#EM#68.163$Question Answering#SQuAD1.1#F1#77.527$Question Answering#SQuAD1.1 dev#EM#67.89$Question Answering#SQuAD1.1 dev#F1#77.42$Question Answering#SQuAD1.1 dev#EM#67.65$Question Answering#SQuAD1.1 dev#F1#77.19
1612.04211v1.pdf	Question Answering#SQuAD1.1#EM#73.765$Question Answering#SQuAD1.1#F1#81.257$Question Answering#SQuAD1.1#EM#70.387$Question Answering#SQuAD1.1#F1#78.784$Question Answering#SQuAD1.1 dev#EM#66.1$Question Answering#SQuAD1.1 dev#F1#75.8$Open-Domain Question Answering#SQuAD1.1#EM#65.5
1611.01603v6.pdf	Question Answering#SQuAD1.1#EM#73.744$Question Answering#SQuAD1.1#F1#81.525$Question Answering#SQuAD1.1#EM#67.974$Question Answering#SQuAD1.1#F1#77.323$Question Answering#MS MARCO#Rouge-L#23.96$Question Answering#MS MARCO#BLEU-1#10.64$Question Answering#CNN / Daily Mail#CNN#76.9$Question Answering#CNN / Daily Mail#Daily Mail#79.6$Question Answering#NarrativeQA#BLEU-1#33.45$Question Answering#NarrativeQA#BLEU-4#15.69$Question Answering#NarrativeQA#METEOR#15.68$Question Answering#NarrativeQA#Rouge-L#36.74$Question Answering#SQuAD1.1 dev#EM#67.7$Question Answering#SQuAD1.1 dev#F1#77.3$Open-Domain Question Answering#Quasar#EM (Quasar-T)#25.9$Open-Domain Question Answering#Quasar#F1 (Quasar-T)#28.5
1703.04617v2.pdf	Question Answering#SQuAD1.1#EM#73.010$Question Answering#SQuAD1.1#F1#81.517$Question Answering#SQuAD1.1#EM#70.607$Question Answering#SQuAD1.1#F1#79.821$Question Answering#SQuAD1.1 dev#EM#69.10$Question Answering#SQuAD1.1 dev#F1#78.38
1710.10723v2.pdf	Question Answering#SQuAD1.1#EM#72.139$Question Answering#SQuAD1.1#F1#81.048$Question Answering#TriviaQA#EM#66.37$Question Answering#TriviaQA#F1#71.32
1611.01604v4.pdf	Question Answering#SQuAD1.1#EM#71.625$Question Answering#SQuAD1.1#F1#80.383$Question Answering#SQuAD1.1#EM#66.233$Question Answering#SQuAD1.1#F1#75.896$Question Answering#SQuAD1.1 dev#EM#65.4$Question Answering#SQuAD1.1 dev#F1#75.6$Open-Domain Question Answering#SQuAD1.1#EM#66.2
1710.02772v1.pdf	Question Answering#SQuAD1.1#EM#71.415$Question Answering#SQuAD1.1#F1#80.160$Question Answering#SQuAD1.1 dev#EM#71.362$Question Answering#SQuAD1.1 dev#F1#80.183
1708.00107v2.pdf	Question Answering#SQuAD1.1#EM#71.3$Question Answering#SQuAD1.1#F1#79.9$Question Answering#SQuAD1.1 dev#EM#71.3$Question Answering#SQuAD1.1 dev#F1#79.9$Natural Language Inference#SNLI#% Test Accuracy#88.1$Natural Language Inference#SNLI#% Train Accuracy#88.5$Natural Language Inference#SNLI#Parameters#22m$Sentiment Analysis#SST-2 Binary classification#Accuracy#90.3$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#53.7$Sentiment Analysis#IMDb#Accuracy#91.8$Text Classification#TREC-6#Error#4.2
1703.04816v3.pdf	Question Answering#SQuAD1.1#EM#70.849$Question Answering#SQuAD1.1#F1#78.857$Question Answering#SQuAD1.1#EM#68.436$Question Answering#SQuAD1.1#F1#77.070$Question Answering#NewsQA#F1#56.1$Question Answering#NewsQA#EM#43.7$Question Answering#SQuAD1.1 dev#EM#70.3$Question Answering#SQuAD1.1 dev#F1#78.5
1611.01436v2.pdf	Question Answering#SQuAD1.1#EM#70.849$Question Answering#SQuAD1.1#F1#78.741$Question Answering#SQuAD1.1 dev#EM#66.4$Question Answering#SQuAD1.1 dev#F1#74.9
1704.00051v2.pdf	Question Answering#SQuAD1.1#EM#70.733$Question Answering#SQuAD1.1#F1#79.353$Question Answering#Natural Questions (long)#F1#46.1$Question Answering#Quasart-T#EM#37.7$Question Answering#SQuAD1.1 dev#EM#69.5$Question Answering#SQuAD1.1 dev#F1#78.8$Open-Domain Question Answering#SQuAD1.1#EM#70.0$Open-Domain Question Answering#SearchQA#EM#41.9
1704.07415v1.pdf	Question Answering#SQuAD1.1#EM#70.639$Question Answering#SQuAD1.1#F1#79.456$Question Answering#SQuAD1.1 dev#EM#70.6$Question Answering#SQuAD1.1 dev#F1#79.5
1608.07905v2.pdf	Question Answering#SQuAD1.1#EM#67.901$Question Answering#SQuAD1.1#F1#77.022$Question Answering#SQuAD1.1#EM#64.744$Question Answering#SQuAD1.1#F1#73.743$Question Answering#SQuAD1.1#EM#60.474$Question Answering#SQuAD1.1#F1#70.695$Question Answering#SQuAD1.1#EM#54.505$Question Answering#SQuAD1.1#F1#67.748$Question Answering#SQuAD1.1 dev#EM#64.1$Question Answering#SQuAD1.1 dev#F1#64.7
1810.09580v1.pdf	Question Answering#SQuAD1.1#EM#67.744$Question Answering#SQuAD1.1#F1#77.605$Question Answering#SQuAD1.1 dev#EM#65.1$Question Answering#SQuAD1.1 dev#F1#75.6
1706.00286v3.pdf	Question Answering#SQuAD1.1#EM#64.083$Question Answering#SQuAD1.1#F1#73.056$Question Answering#SQuAD1.1#EM#62.897$Question Answering#SQuAD1.1#F1#72.016$Question Answering#SQuAD1.1#EM#62.604$Question Answering#SQuAD1.1#F1#71.968$Question Answering#SQuAD1.1 dev#EM#63.06
1610.09996v2.pdf	Question Answering#SQuAD1.1#EM#62.499$Question Answering#SQuAD1.1#F1#70.956$Question Answering#SQuAD1.1 dev#EM#62.5$Question Answering#SQuAD1.1 dev#F1#71.2
1611.01724v2.pdf	Question Answering#SQuAD1.1#EM#62.446$Question Answering#SQuAD1.1#F1#73.327$Question Answering#SQuAD1.1 dev#EM#59.95$Question Answering#SQuAD1.1 dev#F1#71.25
2005.02925v1.pdf	Question Answering#SQuAD1.1#EM#61.145$Question Answering#SQuAD1.1#F1#71.389$Question Answering#SQuAD1.1#EM#55.827$Question Answering#SQuAD1.1#F1#65.467
2102.06356v3.pdf	Question Answering#SQuAD1.1#F1#91.58$Image Classification#ImageNet#Top 1 Accuracy#75.92%
1905.07213v1.pdf	Question Answering#SQuAD1.1#F1#84.6$Sentiment Analysis#RuSentiment#Weighted F1#72.63
2206.02873v4.pdf	Question Answering#NQ (BEIR)#nDCG@10#0.633$Question Answering#FiQA-2018 (BEIR)#nDCG@10#0.513$Question Answering#HotpotQA (BEIR)#nDCG@10#0.759$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.579$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.383$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.795$Fact Checking#CLIMATE-FEVER (BEIR)#nDCG@10#0.280$Fact Checking#FEVER (BEIR)#nDCG@10#0.849$Fact Checking#SciFact (BEIR)#nDCG@10#0.777
2104.08663v4.pdf	Question Answering#NQ (BEIR)#nDCG@10#0.533$Question Answering#NQ (BEIR)#nDCG@10#0.524$Question Answering#FiQA-2018 (BEIR)#nDCG@10#0.347$Question Answering#HotpotQA (BEIR)#nDCG@10#0.707$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.413$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.408$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.401$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.388$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.351$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.338$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.296$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.228$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.177$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.523$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.514$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.350$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.305$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.757$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.677$Fact Checking#CLIMATE-FEVER (BEIR)#nDCG@10#0.253$Fact Checking#FEVER (BEIR)#nDCG@10#0.819$Fact Checking#SciFact (BEIR)#nDCG@10#0.688$Fact Checking#SciFact (BEIR)#nDCG@10#0.671
2202.08904v5.pdf	Question Answering#NQ (BEIR)#nDCG@10#0.524$Question Answering#NQ (BEIR)#nDCG@10#0.401$Question Answering#FiQA-2018 (BEIR)#nDCG@10#0.401$Question Answering#FiQA-2018 (BEIR)#nDCG@10#0.372$Question Answering#HotpotQA (BEIR)#nDCG@10#0.699$Question Answering#HotpotQA (BEIR)#nDCG@10#0.593$Information Retrieval#CQADupStack#mAP@100#0.160$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.399$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.290$Passage Retrieval#MSMARCO (BEIR)#nDCG@10#0.278$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.547$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.546$Biomedical Information Retrieval#BioASQ (BEIR)#nDCG@10#0.413$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.362$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.347$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0.333$Biomedical Information Retrieval#NFCorpus (BEIR)#nDCG@10#0,358$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.873$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.791$Biomedical Information Retrieval#TREC-COVID (BEIR)#nDCG@10#0.762$Fact Checking#CLIMATE-FEVER (BEIR)#nDCG@10#0.305$Fact Checking#CLIMATE-FEVER (BEIR)#nDCG@10#0.161$Fact Checking#FEVER (BEIR)#nDCG@10#0.783$Fact Checking#FEVER (BEIR)#nDCG@10#0.725$Fact Checking#SciFact (BEIR)#nDCG@10#0.747$Fact Checking#SciFact (BEIR)#nDCG@10#0.682
1901.07696v2.pdf	Question Answering#JD Product Question Answer#BLEU#2.0189
1707.04412v1.pdf	Question Answering#COMPLEXQUESTIONS#F1#32.6
1809.02040v1.pdf	Question Answering#COMPLEXQUESTIONS#F1#30.1$Question Answering#WikiHop#Test#65.4
2202.08906v2.pdf	Question Answering#BoolQ#Accuracy#92.4$Common Sense Reasoning#ARC (Easy)#Accuracy#95.2$Common Sense Reasoning#ARC (Challenge)#Accuracy#86.5
2101.11038v1.pdf	Question Answering#BoolQ#Accuracy#87.5$Question Answering#BoolQ#Accuracy#83.8$Common Sense Reasoning#CommonsenseQA#Accuracy#79.2$Natural Language Inference#RTE#Accuracy#92.8%$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.4$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.7$Text Summarization#GigaWord#ROUGE-1#40.4$Text Summarization#GigaWord#ROUGE-2#20.54$Text Summarization#GigaWord#ROUGE-L#36.21$Text Summarization#Reddit TIFU#ROUGE-1#30.3$Text Summarization#Reddit TIFU#ROUGE-2#11.25$Text Summarization#Reddit TIFU#ROUGE-L#24.92$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.45$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.25$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.4$Sentence Completion#HellaSwag#Accuracy#86.4
2104.14690v1.pdf	Question Answering#BoolQ#Accuracy#86.0$Natural Language Inference#SNLI#% Test Accuracy#93.1$Natural Language Inference#QNLI#Accuracy#94.5%$Natural Language Inference#RTE#Accuracy#90.5%$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.918$Semantic Textual Similarity#MRPC#F1#91.0$Paraphrase Identification#Quora Question Pairs#F1#89.2$Sentiment Analysis#CR#Accuracy#92.5$Sentiment Analysis#MPQA#Accuracy#90.8$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.9$Sentiment Analysis#MR#Accuracy#92.5$Sentiment Analysis#IMDb#Accuracy#96.1$Subjectivity Analysis#SUBJ#Accuracy#97.1$Linguistic Acceptability#CoLA#Accuracy#86.4%
2210.02441v2.pdf	Question Answering#BoolQ#Accuracy#67.2$Question Answering#BoolQ#Accuracy#66.5$Question Answering#BoolQ#Accuracy#64.9$Question Answering#Story Cloze Test#Accuracy#87.8$Question Answering#Story Cloze Test#Accuracy#76.3$Question Answering#Story Cloze Test#Accuracy#51.0$Question Answering#MultiRC#F1#63.8$Question Answering#MultiRC#F1#60.8$Question Answering#MultiRC#F1#58.8$Question Answering#COPA#Accuracy#84.0$Question Answering#COPA#Accuracy#77.0$Question Answering#COPA#Accuracy#58.2$Question Answering#Natural Questions#EM#19.7$Question Answering#Natural Questions#EM#19.6$Question Answering#Natural Questions#EM#13.7$Natural Language Inference#RTE#Accuracy#74.7%$Natural Language Inference#RTE#Accuracy#61.7%$Natural Language Inference#RTE#Accuracy#58.8%$Coreference Resolution#WSC#Accuracy#77.9$Coreference Resolution#WSC#Accuracy#74.7$Coreference Resolution#WSC#Accuracy#36.5
2207.06366v1.pdf	Question Answering#BoolQ#Accuracy#64.98$Question Answering#MultiRC#F1#61.95$Question Answering#MultiRC#EM#11.33$Question Answering#COPA#Accuracy#60.0$Common Sense Reasoning#ReCoRD#F1#29.90$Common Sense Reasoning#ReCoRD#EM#28.91$Word Sense Disambiguation#Words in Context#Accuracy#56.11$Natural Language Inference#CommitmentBank#F1#59.69$Natural Language Inference#CommitmentBank#Accuracy#67.86$Natural Language Inference#RTE#Accuracy#59.21%$Language Modelling#C4#Perplexity#14.79$Coreference Resolution#WSC#Accuracy#68.27
2012.15283v3.pdf	Question Answering#Torque#F1#76.3$Question Answering#Torque#EM#52.0$Question Answering#Torque#C#37.0
2005.00242v2.pdf	Question Answering#Torque#F1#75.2$Question Answering#Torque#EM#51.1$Question Answering#Torque#C#34.5
1911.04118v2.pdf	Question Answering#WikiQA#MAP#0.920$Question Answering#WikiQA#MRR#0.933$Question Answering#TrecQA#MAP#0.943$Question Answering#TrecQA#MRR#0.974
2205.10455v2.pdf	Question Answering#WikiQA#MAP#0.887$Question Answering#WikiQA#MRR#0.899$Question Answering#TrecQA#MAP#0.903$Question Answering#TrecQA#MRR#0.951$Answer Selection#ASNQ#MAP#0.697$Answer Selection#ASNQ#MRR#0.757
2205.01228v2.pdf	Question Answering#WikiQA#MAP#0.885$Question Answering#WikiQA#MRR#0.890$Question Answering#TrecQA#MAP#0.911$Question Answering#TrecQA#MRR#0.952$Answer Selection#ASNQ#MAP#0.673$Answer Selection#ASNQ#MRR#0.737$Fact Verification#FEVER#Accuracy#74.4
1905.12897v2.pdf	Question Answering#WikiQA#MAP#0.764$Question Answering#WikiQA#MRR#0.784$Question Answering#TrecQA#MAP#0.868$Question Answering#TrecQA#MRR#0.928
1908.00300v1.pdf	Question Answering#WikiQA#MAP#0.7452$Question Answering#WikiQA#MRR#0.7618$Question Answering#Quora Question Pairs#Accuracy#89.2 %$Natural Language Inference#SNLI#% Test Accuracy#88.9$Natural Language Inference#SNLI#% Train Accuracy#94.0$Natural Language Inference#SNLI#Parameters#2.8m$Natural Language Inference#SciTail#Accuracy#86.0$Paraphrase Identification#Quora Question Pairs#Accuracy#89.2
1707.07847v3.pdf	Question Answering#WikiQA#MAP#0.712$Question Answering#WikiQA#MRR#0.727$Question Answering#SemEvalCQA#P@1#0.809$Question Answering#SemEvalCQA#MAP#0.795$Question Answering#TrecQA#MAP#0.770$Question Answering#TrecQA#MRR#0.825$Question Answering#YahooCQA#P@1#0.683$Question Answering#YahooCQA#MRR#0.801$Question Answering#YahooCQA#P@1#0.465$Question Answering#YahooCQA#MRR#0.669$Question Answering#YahooCQA#P@1#0.413$Question Answering#YahooCQA#MRR#0.632
1606.03126v2.pdf	Question Answering#WikiQA#MAP#0.7069$Question Answering#WikiQA#MRR#0.7265
1602.07019v2.pdf	Question Answering#WikiQA#MAP#0.7058$Question Answering#WikiQA#MRR#0.7226
1809.01812v1.pdf	Question Answering#WikiQA#MAP#0.7010$Question Answering#WikiQA#MRR#0.7180
1511.06038v4.pdf	Question Answering#WikiQA#MAP#0.6886$Question Answering#WikiQA#MRR#0.7069$Question Answering#WikiQA#MAP#0.682$Question Answering#WikiQA#MRR#0.6988$Question Answering#WikiQA#MAP#0.6552$Question Answering#WikiQA#MRR#0.6747$Question Answering#QASent#MAP#0.7339$Question Answering#QASent#MRR#0.8117$Question Answering#QASent#MAP#0.7228$Question Answering#QASent#MRR#0.7986$Question Answering#QASent#MAP#0.6436$Question Answering#QASent#MRR#0.7235$Topic Models#20 Newsgroups#Test perplexity#836
1602.03609v1.pdf	Question Answering#WikiQA#MAP#0.6886$Question Answering#WikiQA#MRR#0.6957$Question Answering#SemEvalCQA#P@1#0.755$Question Answering#SemEvalCQA#MAP#0.771$Question Answering#YahooCQA#P@1#0.568$Question Answering#YahooCQA#MRR#0.731$Question Answering#YahooCQA#P@1#0.560$Question Answering#YahooCQA#MRR#0.726
1805.09843v1.pdf	Question Answering#WikiQA#MAP#0.6788$Question Answering#WikiQA#MRR#0.6908$Question Answering#Quora Question Pairs#Accuracy#83.03%$Natural Language Inference#SNLI#% Test Accuracy#83.8$Natural Language Inference#MultiNLI#Matched#68.2$Natural Language Inference#MultiNLI#Mismatched#67.7$Paraphrase Identification#MSRP#Accuracy#71.5$Paraphrase Identification#MSRP#F1#81.3$Sentiment Analysis#SST-2 Binary classification#Accuracy#84.3$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#46.1$Sentiment Analysis#Yelp Fine-grained classification#Error#36.21$Sentiment Analysis#MR#Accuracy#78.2$Sentiment Analysis#Yelp Binary classification#Error#4.19$Named Entity Recognition#CoNLL 2003 (English)#F1#86.28$Named Entity Recognition#CoNLL 2000#F1#90.34$Subjectivity Analysis#SUBJ#Accuracy#93$Text Classification#TREC-6#Error#7.8$Text Classification#DBpedia#Error#1.43$Text Classification#AG News#Error#7.34$Text Classification#Yahoo! Answers#Accuracy#73.53
1412.1632v1.pdf	Question Answering#WikiQA#MAP#0.6520$Question Answering#WikiQA#MRR#0.6652$Question Answering#WikiQA#MAP#0.6190$Question Answering#WikiQA#MRR#0.6281$Question Answering#QASent#MAP#0.7113$Question Answering#QASent#MRR#0.7846$Question Answering#QASent#MAP#0.5693$Question Answering#QASent#MRR#0.6613$Question Answering#TrecQA#MAP#0.711$Question Answering#TrecQA#MRR#0.785
1405.4053v2.pdf	Question Answering#WikiQA#MAP#0.5976$Question Answering#WikiQA#MRR#0.6058$Question Answering#WikiQA#MAP#0.5110$Question Answering#WikiQA#MRR#0.5160$Question Answering#QASent#MAP#0.6762$Question Answering#QASent#MRR#0.7514$Question Answering#QASent#MAP#0.5213$Question Answering#QASent#MRR#0.6023$Text Classification#IMDb#Accuracy (2 classes)#92.58$Text Classification#IMDb#Accuracy (10 classes)#-
2010.10439v2.pdf	Question Answering#OTT-QA#ANS-EM#27.2
2201.05880v1.pdf	Question Answering#OTT-QA#ANS-EM#32.5
2005.11401v4.pdf	Question Answering#WebQuestions#EM#45.2$Question Answering#Natural Questions#EM#44.5$Question Answering#TriviaQA#EM#56.1$Fact Verification#FEVER#Accuracy#89.5
2004.04906v3.pdf	Question Answering#WebQuestions#EM#42.4$Question Answering#NaturalQA#EM#41.5$Question Answering#Natural Questions#EM#41.5$Question Answering#TriviaQA#EM#56.8$Question Answering#SQuAD#EM#24.1$Passage Retrieval#Natural Questions#Precision@20#79.4$Passage Retrieval#Natural Questions#Precision@100#86
2002.08909v1.pdf	Question Answering#WebQuestions#EM#40.7$Question Answering#Natural Questions#EM#40.4
1906.00300v3.pdf	Question Answering#WebQuestions#EM#36.4$Question Answering#TriviaQA#EM#45
2112.06905v2.pdf	Question Answering#WebQuestions#EM#15.5$Question Answering#Natural Questions#EM#32.5$Question Answering#Natural Questions#EM#26.3$Question Answering#Natural Questions#EM#24.7$Question Answering#TriviaQA#EM#75.8$Question Answering#TriviaQA#EM#71.3$Common Sense Reasoning#ARC (Easy)#Accuracy#74.8$Common Sense Reasoning#ARC (Easy)#Accuracy#68.0$Common Sense Reasoning#ARC (Challenge)#Accuracy#50.3$Common Sense Reasoning#ARC (Challenge)#Accuracy#48.2$Language Modelling#LAMBADA#Accuracy#80.9
1506.02075v1.pdf	Question Answering#WebQuestions#F1#42.2%$Question Answering#SimpleQuestions#F1#63.9%$Question Answering#Reverb#Accuracy#68%
1406.3676v3.pdf	Question Answering#WebQuestions#F1#39.2%
1404.4326v1.pdf	Question Answering#WebQuestions#F1#29.7%$Question Answering#Reverb#Accuracy#73%
2111.09543v2.pdf	Question Answering#SWAG#Accuracy#93.4$Natural Language Inference#MRPC#Acc#92.2$Natural Language Inference#QNLI#Accuracy#96%$Natural Language Inference#RTE#Accuracy#92.7%
2105.13626v3.pdf	Question Answering#TweetQA#BLEU-1#72.0$Question Answering#TweetQA#BLEU-1#70.8$Question Answering#TweetQA#ROUGE-L#74.3$Question Answering#TweetQA#ROUGE-L#75.7$Cross-Lingual Question Answering#XQuAD#EM#63.6$Cross-Lingual Question Answering#XQuAD#F1#79.7$Cross-Lingual Question Answering#TyDiQA-GoldP#EM#60.0$Cross-Lingual Question Answering#TyDiQA-GoldP#F1#75.3$Cross-Lingual Question Answering#MLQA#EM#54.9$Cross-Lingual Question Answering#MLQA#F1#71.6$Cross-Lingual Natural Language Inference#XNLI#Accuracy#83.7$Cross-Lingual Natural Language Inference#XNLI#Accuracy#69.1$Cross-Lingual NER#WikiAnn NER#F1#67.7$Extreme Summarization#GEM-XSum#BLEU score#15.3$Extreme Summarization#GEM-XSum#BLEU score#14.3
1901.02262v2.pdf	Question Answering#MS MARCO#Rouge-L#52.2$Question Answering#MS MARCO#BLEU-1#43.77$Question Answering#NarrativeQA#BLEU-1#54.11$Question Answering#NarrativeQA#BLEU-4#30.43$Question Answering#NarrativeQA#METEOR#26.13$Question Answering#NarrativeQA#Rouge-L#59.87$Question Answering#NarrativeQA#BLEU-1#48.7$Question Answering#NarrativeQA#BLEU-4#20.98$Question Answering#NarrativeQA#METEOR#21.95$Question Answering#NarrativeQA#Rouge-L#54.74
1811.11374v1.pdf	Question Answering#MS MARCO#Rouge-L#52.01$Question Answering#MS MARCO#BLEU-1#54.64
1805.02220v2.pdf	Question Answering#MS MARCO#Rouge-L#51.63$Question Answering#MS MARCO#BLEU-1#54.37
1810.06683v3.pdf	Question Answering#QuAC#F1#64.1$Question Answering#QuAC#HEQQ#59.6$Question Answering#QuAC#HEQD#5.8$Question Answering#CoQA#Out-of-domain#71.8$Question Answering#CoQA#Overall#75.0
1703.02620v1.pdf	Question Answering#CNN / Daily Mail#CNN#78.6
1606.01549v3.pdf	Question Answering#CNN / Daily Mail#CNN#77.9$Question Answering#CNN / Daily Mail#Daily Mail#80.9$Question Answering#Children's Book Test#Accuracy-CN#71.9%$Question Answering#Children's Book Test#Accuracy-NE#73.2%$Question Answering#Children's Book Test#Accuracy-CN#70.7%$Question Answering#Children's Book Test#Accuracy-NE#74.9%$Question Answering#Children's Book Test#Accuracy-CN#69.4%$Question Answering#Children's Book Test#Accuracy-NE#71.9%$Open-Domain Question Answering#Quasar#EM (Quasar-T)#26.4$Open-Domain Question Answering#Quasar#F1 (Quasar-T)#26.4
1606.02858v2.pdf	Question Answering#CNN / Daily Mail#CNN#77.6$Question Answering#CNN / Daily Mail#Daily Mail#79.2$Question Answering#CNN / Daily Mail#CNN#72.4$Question Answering#CNN / Daily Mail#Daily Mail#75.8$Question Answering#CNN / Daily Mail#CNN#67.9$Question Answering#CNN / Daily Mail#Daily Mail#68.3
1606.02245v4.pdf	Question Answering#CNN / Daily Mail#CNN#76.1$Question Answering#Children's Book Test#Accuracy-NE#72%
1603.01547v2.pdf	Question Answering#CNN / Daily Mail#CNN#75.4$Question Answering#CNN / Daily Mail#Daily Mail#77.7$Question Answering#CNN / Daily Mail#CNN#69.5$Question Answering#CNN / Daily Mail#Daily Mail#73.9$Question Answering#Children's Book Test#Accuracy-CN#68.9%$Question Answering#Children's Book Test#Accuracy-NE#70.6%$Question Answering#Children's Book Test#Accuracy-CN#67.5%$Question Answering#Children's Book Test#Accuracy-NE#71%$Open-Domain Question Answering#SearchQA#Unigram Acc#41.3$Open-Domain Question Answering#SearchQA#N-gram F1#22.8
1607.04423v4.pdf	Question Answering#CNN / Daily Mail#CNN#74.4$Question Answering#Children's Book Test#Accuracy-CN#69.4%$Question Answering#Children's Book Test#Accuracy-NE#72%
1606.02270v2.pdf	Question Answering#CNN / Daily Mail#CNN#74$Question Answering#Children's Book Test#Accuracy-CN#67.4%$Question Answering#Children's Book Test#Accuracy-NE#69.7%
1506.03340v3.pdf	Question Answering#CNN / Daily Mail#CNN#69.4$Question Answering#CNN / Daily Mail#CNN#63.8$Question Answering#CNN / Daily Mail#Daily Mail#68.0$Question Answering#CNN / Daily Mail#CNN#63$Question Answering#CNN / Daily Mail#Daily Mail#69
1911.02855v3.pdf	Question Answering#SQuAD2.0 dev#F1#89.51$Question Answering#SQuAD2.0 dev#EM#87.65$Question Answering#SQuAD1.1 dev#EM#89.79$Question Answering#SQuAD1.1 dev#F1#95.77$Named Entity Recognition#Ontonotes v5 (English)#F1#92.07$Named Entity Recognition#CoNLL 2003 (English)#F1#93.33$Chinese Named Entity Recognition#MSRA#F1#96.72$Chinese Named Entity Recognition#OntoNotes 4#F1#84.47
1908.05147v3.pdf	Question Answering#SQuAD2.0 dev#F1#87.9$Question Answering#SQuAD2.0 dev#EM#85.1$Question Answering#SQuAD2.0#EM#88.174$Question Answering#SQuAD2.0#F1#90.702$Question Answering#SQuAD2.0#EM#87.238$Question Answering#SQuAD2.0#F1#90.071$Question Answering#SQuAD2.0#EM#86.211$Question Answering#SQuAD2.0#F1#88.848$Question Answering#SQuAD2.0#EM#85.229$Question Answering#SQuAD2.0#F1#87.926
1909.02209v3.pdf	Question Answering#SQuAD2.0 dev#F1#83.6$Question Answering#SQuAD2.0 dev#EM#80.9$Question Answering#SQuAD2.0#EM#86.166$Question Answering#SQuAD2.0#F1#88.886$Question Answering#SQuAD2.0#EM#84.800$Question Answering#SQuAD2.0#F1#87.864$Natural Language Inference#SNLI#% Test Accuracy#91.9$Natural Language Inference#SNLI#% Train Accuracy#94.4$Natural Language Inference#SNLI#Parameters#339m
1808.05759v5.pdf	Question Answering#SQuAD2.0 dev#F1#74.8$Question Answering#SQuAD2.0 dev#EM#72.3$Question Answering#SQuAD2.0#EM#71.767$Question Answering#SQuAD2.0#F1#74.295
1810.06638v1.pdf	Question Answering#SQuAD2.0 dev#F1#74.0$Question Answering#SQuAD2.0 dev#EM#70.3$Question Answering#SQuAD2.0#EM#71.417$Question Answering#SQuAD2.0#F1#74.869
1909.10351v5.pdf	Question Answering#SQuAD2.0 dev#F1#73.4$Question Answering#SQuAD2.0 dev#EM#69.9$Question Answering#SQuAD1.1 dev#EM#79.7$Question Answering#SQuAD1.1 dev#F1#87.5$Natural Language Inference#QNLI#Accuracy#87.7%$Natural Language Inference#RTE#Accuracy#62.9%$Natural Language Inference#MultiNLI Dev#Matched#84.5$Natural Language Inference#MultiNLI Dev#Mismatched#84.5$Natural Language Inference#MultiNLI#Matched#82.5$Natural Language Inference#MultiNLI#Mismatched#81.8$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.799$Semantic Textual Similarity#MRPC#Accuracy#86.4%$Semantic Textual Similarity#MRPC Dev#Accuracy#86.3$Paraphrase Identification#Quora Question Pairs#F1#71.3$Sentiment Analysis#SST-2 Binary classification#Accuracy#92.6$Linguistic Acceptability#CoLA#Accuracy#43.3%$Linguistic Acceptability#CoLA Dev#Accuracy#54
2204.08292v1.pdf	Question Answering#StepGame#1-of-100 Accuracy#52.99
1503.03244v1.pdf	Question Answering#SemEvalCQA#P@1#0.753$Question Answering#SemEvalCQA#MAP#0.780
2104.08671v3.pdf	Question Answering#CaseHOLD#Macro F1 (10-fold)#69.5$Question Answering#CaseHOLD#Macro F1 (10-fold)#68.0$Question Answering#CaseHOLD#Macro F1 (10-fold)#61.3$Text Classification#Terms of Service#F1(10-fold)#78.7$Text Classification#Terms of Service#F1(10-fold)#75.0$Text Classification#Terms of Service#F1(10-fold)#72.2$Text Classification#Overruling#F1(10-fold)#97.4$Text Classification#Overruling#F1(10-fold)#96.3$Text Classification#Overruling#F1(10-fold)#95.8
1809.10735v2.pdf	Question Answering#CoQA#In-domain#69.4$Question Answering#CoQA#Out-of-domain#63.8$Question Answering#CoQA#Overall#67.8
1808.07042v2.pdf	Question Answering#CoQA#In-domain#67.0$Question Answering#CoQA#Out-of-domain#60.4$Question Answering#CoQA#Overall#65.1$Question Answering#CoQA#In-domain#54.5$Question Answering#CoQA#Out-of-domain#47.9$Question Answering#CoQA#Overall#52.6$Generative Question Answering#CoQA#F1-Score#45.4
1812.03593v5.pdf	Question Answering#CoQA#Overall#79.3$Question Answering#CoQA#Overall#76.6
2011.07831v2.pdf	Question Answering#catbAbI LM-mode#Accuracy (mean)#93.04%$Question Answering#catbAbI LM-mode#Accuracy (mean)#90.23%$Question Answering#catbAbI LM-mode#Accuracy (mean)#80.15%$Question Answering#catbAbI LM-mode#Accuracy (mean)#69.3%$Question Answering#catbAbI QA-mode#1:1 Accuracy#96.75%$Question Answering#catbAbI QA-mode#1:1 Accuracy#88.97%$Question Answering#catbAbI QA-mode#1:1 Accuracy#87.66%$Question Answering#catbAbI QA-mode#1:1 Accuracy#80.88%$Language Modelling#WikiText-2#Validation perplexity#54.48$Language Modelling#WikiText-2#Test perplexity#61.65$Language Modelling#WikiText-2#Number of params#37M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#56.76$Language Modelling#Penn Treebank (Word Level)#Test perplexity#54.48$Language Modelling#Penn Treebank (Word Level)#Params#24M
2002.03519v3.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#99.85%$Question Answering#bAbi#Mean Error Rate#0.39%
1606.04582v6.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#99.7%$Question Answering#bAbi#Accuracy (trained on 1k)#90.1%$Question Answering#bAbi#Mean Error Rate#0.3%
1612.03969v3.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#99.5%$Question Answering#bAbi#Accuracy (trained on 1k)#89.1%$Question Answering#bAbi#Mean Error Rate#9.7%
1607.00036v2.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#97.2%$Question Answering#bAbi#Accuracy (trained on 1k)#66.8%
1503.08895v5.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#93.4%$Question Answering#bAbi#Accuracy (trained on 1k)#86.1%$Question Answering#bAbi#Mean Error Rate#7.5%
2205.11276v1.pdf	Question Answering#bAbi#Accuracy (trained on 10k)#89.1%
1710.09537v1.pdf	Question Answering#bAbi#Accuracy (trained on 1k)#73.2%
1706.02761v3.pdf	Question Answering#bAbi#Accuracy (trained on 1k)#60%
1610.09027v1.pdf	Question Answering#bAbi#Accuracy (trained on 1k)#49%$Question Answering#bAbi#Mean Error Rate#28.7%$Question Answering#bAbi#Mean Error Rate#6.4%
1711.08028v4.pdf	Question Answering#bAbi#Mean Error Rate#0.46%
1801.08459v2.pdf	Question Answering#bAbi#Mean Error Rate#1.2%
1906.08862v2.pdf	Question Answering#bAbi#Mean Error Rate#5.6%
2012.12624v3.pdf	Question Answering#Natural Questions (long)#F1#79.6$Question Answering#Natural Questions (long)#EM#71.9$Question Answering#SQuAD1.1 dev#EM#78.3$Question Answering#SQuAD1.1 dev#F1#86.3$Slot Filling#KILT: Zero Shot RE#KILT-AC#41.34$Slot Filling#KILT: Zero Shot RE#R-Prec#57.43$Slot Filling#KILT: Zero Shot RE#Recall@5#60.47$Slot Filling#KILT: Zero Shot RE#Accuracy#47.42$Slot Filling#KILT: Zero Shot RE#F1#54.75$Slot Filling#KILT: Zero Shot RE#KILT-F1#46.79$Slot Filling#KILT: T-REx#KILT-AC#27.84$Slot Filling#KILT: T-REx#R-Prec#37.62$Slot Filling#KILT: T-REx#Recall@5#40.07$Slot Filling#KILT: T-REx#Accuracy#53.9$Slot Filling#KILT: T-REx#F1#61.74$Slot Filling#KILT: T-REx#KILT-F1#32.34
2009.06097v2.pdf	Question Answering#Natural Questions (long)#F1#76.5$Question Answering#Quasart-T#EM#54$Open-Domain Question Answering#SearchQA#EM#68.0$Language Modelling#enwik8#Bit per Character (BPC)#1.22
1909.05286v1.pdf	Question Answering#Natural Questions (long)#F1#68.2
1901.08634v3.pdf	Question Answering#Natural Questions (long)#F1#64.7
1603.08884v1.pdf	Question Answering#MCTest-500#Accuracy#71%$Question Answering#MCTest-500#Accuracy#69.94%$Question Answering#MCTest-160#Accuracy#75.27%
2202.07362v1.pdf	Question Answering#MuLD (HotpotQA)#BLEU-1#30.38$Question Answering#MuLD (HotpotQA)#BLEU-4#16.76$Question Answering#MuLD (HotpotQA)#Rouge-L#30.49$Question Answering#MuLD (HotpotQA)#METEOR#4.98$Question Answering#MuLD (HotpotQA)#BLEU-1#28.11$Question Answering#MuLD (HotpotQA)#BLEU-4#13.63$Question Answering#MuLD (HotpotQA)#Rouge-L#27.61$Question Answering#MuLD (HotpotQA)#METEOR#4.46$Question Answering#MuLD (NarrativeQA)#BLEU-1#19.84$Question Answering#MuLD (NarrativeQA)#BLEU-4#62$Question Answering#MuLD (NarrativeQA)#Rouge-L#22.09$Question Answering#MuLD (NarrativeQA)#METEOR#4.52$Question Answering#MuLD (NarrativeQA)#BLEU-1#17.67$Question Answering#MuLD (NarrativeQA)#BLEU-4#55$Question Answering#MuLD (NarrativeQA)#Rouge-L#19.03$Question Answering#MuLD (NarrativeQA)#METEOR#3.36$Summarization#MuLD (VLSP)#BLEU-1#46.74$Summarization#MuLD (VLSP)#BLEU-4#3.05$Summarization#MuLD (VLSP)#Rouge-L#19.52$Summarization#MuLD (VLSP)#METEOR#9.58$Summarization#MuLD (VLSP)#BLEU-1#28.85$Summarization#MuLD (VLSP)#BLEU-4#84$Summarization#MuLD (VLSP)#Rouge-L#16.55$Summarization#MuLD (VLSP)#METEOR#7.98$Text Classification#MuLD (Character Type)#F1#82.58$Text Classification#MuLD (Character Type)#F1#54.01
2101.04727v1.pdf	Question Answering#RecipeQA#Accuracy#0.475
2109.07958v2.pdf	Question Answering#TruthfulQA#% true#53.86$Question Answering#TruthfulQA#% info#64.50$Question Answering#TruthfulQA#% true (GPT-judge)#53.24$Question Answering#TruthfulQA#BLEURT#0.08$Question Answering#TruthfulQA#ROUGE#1.76$Question Answering#TruthfulQA#BLEU#-0.16$Question Answering#TruthfulQA#MC1#0.19$Question Answering#TruthfulQA#MC2#0.35$Question Answering#TruthfulQA#% true#29.50$Question Answering#TruthfulQA#% info#89.84$Question Answering#TruthfulQA#% true (GPT-judge)#29.87$Question Answering#TruthfulQA#BLEURT#-0.25$Question Answering#TruthfulQA#ROUGE#-9.41$Question Answering#TruthfulQA#BLEU#-4.91$Question Answering#TruthfulQA#MC1#0.22$Question Answering#TruthfulQA#MC2#0.39$Question Answering#TruthfulQA#% true#26.68$Question Answering#TruthfulQA#% info#89.96$Question Answering#TruthfulQA#% true (GPT-judge)#27.17$Question Answering#TruthfulQA#BLEURT#-0.31$Question Answering#TruthfulQA#ROUGE#-11.35$Question Answering#TruthfulQA#BLEU#-7.58$Question Answering#TruthfulQA#MC1#0.20$Question Answering#TruthfulQA#MC2#0.36$Question Answering#TruthfulQA#% true#20.44$Question Answering#TruthfulQA#% info#97.55$Question Answering#TruthfulQA#% true (GPT-judge)#20.56$Question Answering#TruthfulQA#BLEURT#-0.56$Question Answering#TruthfulQA#ROUGE#-17.75$Question Answering#TruthfulQA#BLEU#-17.38$Question Answering#TruthfulQA#MC1#0.21$Question Answering#TruthfulQA#MC2#0.33
2204.05814v1.pdf	Question Answering#ChAII - Hindi and Tamil Question Answering#Jaccard#0.53
2007.14062v2.pdf	Question Answering#HotpotQA#ANS-F1#0.812$Question Answering#HotpotQA#SUP-F1#0.891$Question Answering#HotpotQA#JOINT-F1#0.736$Question Answering#TriviaQA#F1#80.9$Question Answering#WikiHop#Test#82.3$Question Answering#Quora Question Pairs#Accuracy#88.6%$Natural Language Inference#QNLI#Accuracy#92.2%$Natural Language Inference#RTE#Accuracy#75.0%$Natural Language Inference#MultiNLI#Matched#87.5$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#.878$Semantic Textual Similarity#MRPC#F1#91.5%$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.6$Text Summarization#BigPatent#ROUGE-1#60.64$Text Summarization#BigPatent#ROUGE-2#42.46$Text Summarization#BigPatent#ROUGE-L#50.01$Text Summarization#arXiv#ROUGE-1#46.63$Text Summarization#arXiv#ROUGE-2#19.02$Text Summarization#arXiv#ROUGE-L#41.77$Text Summarization#Pubmed#ROUGE-1#46.32$Text Summarization#Pubmed#ROUGE-2#20.65$Text Summarization#Pubmed#ROUGE-L#42.33$Document Summarization#BBC XSum#ROUGE-1#47.12$Document Summarization#BBC XSum#ROUGE-2#24.05$Document Summarization#BBC XSum#ROUGE-L#38.8$Document Summarization#CNN / Daily Mail#ROUGE-1#43.84$Document Summarization#CNN / Daily Mail#ROUGE-2#21.11$Document Summarization#CNN / Daily Mail#ROUGE-L#40.74$Text Classification#Hyperpartisan#Accuracy#92.2$Text Classification#Yelp-5#Accuracy#72.16%$Text Classification#Patents#Accuracy#69.3$Text Classification#arXiv#Accuracy#92.31$Text Classification#IMDb#Accuracy (2 classes)#95.2$Text Classification#IMDb#Accuracy (10 classes)#-$Linguistic Acceptability#CoLA#Accuracy#58.5%
2109.06747v1.pdf	Question Answering#HotpotQA#ANS-EM#0.675$Question Answering#HotpotQA#ANS-F1#0.805$Question Answering#HotpotQA#SUP-EM#0.612$Question Answering#HotpotQA#SUP-F1#0.860$Question Answering#HotpotQA#JOINT-EM#0.449$Question Answering#HotpotQA#JOINT-F1#0.720
2012.15534v1.pdf	Question Answering#HotpotQA#ANS-EM#0.671$Question Answering#HotpotQA#ANS-F1#0.799$Question Answering#HotpotQA#SUP-EM#0.574$Question Answering#HotpotQA#SUP-F1#0.835$Question Answering#HotpotQA#JOINT-EM#0.432$Question Answering#HotpotQA#JOINT-F1#0.706
2010.12527v4.pdf	Question Answering#HotpotQA#ANS-EM#0.663$Question Answering#HotpotQA#ANS-F1#0.791$Question Answering#HotpotQA#SUP-EM#0.569$Question Answering#HotpotQA#SUP-F1#0.832$Question Answering#HotpotQA#JOINT-EM#0.428$Question Answering#HotpotQA#JOINT-F1#0.696$Question Answering#HotpotQA#ANS-EM#0.657$Question Answering#HotpotQA#ANS-F1#0.782$Question Answering#HotpotQA#SUP-EM#0.559$Question Answering#HotpotQA#SUP-F1#0.821$Question Answering#HotpotQA#JOINT-EM#0.421$Question Answering#HotpotQA#JOINT-F1#0.686
2009.12756v2.pdf	Question Answering#HotpotQA#ANS-EM#0.623$Question Answering#HotpotQA#ANS-F1#0.753$Question Answering#HotpotQA#SUP-EM#0.575$Question Answering#HotpotQA#SUP-F1#0.809$Question Answering#HotpotQA#JOINT-EM#0.418$Question Answering#HotpotQA#JOINT-F1#0.666
2009.07465v5.pdf	Question Answering#HotpotQA#ANS-EM#0.625$Question Answering#HotpotQA#ANS-F1#0.759$Question Answering#HotpotQA#SUP-EM#0.510$Question Answering#HotpotQA#SUP-F1#0.789$Question Answering#HotpotQA#JOINT-EM#0.360$Question Answering#HotpotQA#JOINT-F1#0.639
1911.10470v2.pdf	Question Answering#HotpotQA#ANS-EM#0.600$Question Answering#HotpotQA#ANS-F1#0.730$Question Answering#HotpotQA#SUP-EM#0.491$Question Answering#HotpotQA#SUP-F1#0.764$Question Answering#HotpotQA#JOINT-EM#0.354$Question Answering#HotpotQA#JOINT-F1#0.612
1911.03631v4.pdf	Question Answering#HotpotQA#ANS-EM#0.567$Question Answering#HotpotQA#ANS-F1#0.692$Question Answering#HotpotQA#SUP-EM#0.500$Question Answering#HotpotQA#SUP-F1#0.764$Question Answering#HotpotQA#JOINT-EM#0.356$Question Answering#HotpotQA#JOINT-F1#0.599
1905.06933v3.pdf	Question Answering#HotpotQA#JOINT-F1#0.5982
1809.09600v1.pdf	Question Answering#HotpotQA#ANS-EM#0.589$Question Answering#HotpotQA#ANS-F1#0.716$Question Answering#HotpotQA#SUP-EM#0.480$Question Answering#HotpotQA#SUP-F1#0.757$Question Answering#HotpotQA#JOINT-EM#0.345$Question Answering#HotpotQA#JOINT-F1#0.598$Question Answering#HotpotQA#ANS-EM#0.240$Question Answering#HotpotQA#ANS-F1#0.329$Question Answering#HotpotQA#SUP-EM#0.039$Question Answering#HotpotQA#SUP-F1#0.377$Question Answering#HotpotQA#JOINT-EM#0.019$Question Answering#HotpotQA#JOINT-F1#0.162
2004.06753v1.pdf	Question Answering#HotpotQA#ANS-EM#0.555$Question Answering#HotpotQA#ANS-F1#0.675$Question Answering#HotpotQA#SUP-EM#0.456$Question Answering#HotpotQA#SUP-F1#0.730$Question Answering#HotpotQA#JOINT-EM#0.329$Question Answering#HotpotQA#JOINT-F1#0.562
1909.08041v1.pdf	Question Answering#HotpotQA#ANS-EM#0.453$Question Answering#HotpotQA#ANS-F1#0.573$Question Answering#HotpotQA#SUP-EM#0.387$Question Answering#HotpotQA#SUP-F1#0.708$Question Answering#HotpotQA#JOINT-EM#0.251$Question Answering#HotpotQA#JOINT-F1#0.476
1910.07000v1.pdf	Question Answering#HotpotQA#ANS-EM#0.379$Question Answering#HotpotQA#ANS-F1#0.486$Question Answering#HotpotQA#SUP-EM#0.307$Question Answering#HotpotQA#SUP-F1#0.642$Question Answering#HotpotQA#JOINT-EM#0.180$Question Answering#HotpotQA#JOINT-F1#0.391
1905.05460v2.pdf	Question Answering#HotpotQA#ANS-EM#0.371$Question Answering#HotpotQA#ANS-F1#0.489$Question Answering#HotpotQA#SUP-EM#0.228$Question Answering#HotpotQA#SUP-F1#0.577$Question Answering#HotpotQA#JOINT-EM#0.124$Question Answering#HotpotQA#JOINT-F1#0.349
1906.06606v1.pdf	Question Answering#HotpotQA#ANS-EM#0.306$Question Answering#HotpotQA#ANS-F1#0.403$Question Answering#HotpotQA#SUP-EM#0.167$Question Answering#HotpotQA#SUP-F1#0.473$Question Answering#HotpotQA#JOINT-EM#0.109$Question Answering#HotpotQA#JOINT-F1#0.270
1911.02170v1.pdf	Question Answering#HotpotQA#ANS-EM#0.277$Question Answering#HotpotQA#ANS-F1#0.372$Question Answering#HotpotQA#SUP-EM#0.127$Question Answering#HotpotQA#SUP-F1#0.472$Question Answering#HotpotQA#JOINT-EM#0.070$Question Answering#HotpotQA#JOINT-F1#0.247
1905.08511v2.pdf	Question Answering#HotpotQA#ANS-EM#0.287$Question Answering#HotpotQA#ANS-F1#0.381$Question Answering#HotpotQA#SUP-EM#0.142$Question Answering#HotpotQA#SUP-F1#0.444$Question Answering#HotpotQA#JOINT-EM#0.087$Question Answering#HotpotQA#JOINT-F1#0.231
1906.02916v2.pdf	Question Answering#HotpotQA#ANS-EM#0.300$Question Answering#HotpotQA#ANS-F1#0.407$Question Answering#HotpotQA#SUP-EM#0.000$Question Answering#HotpotQA#SUP-F1#0.000$Question Answering#HotpotQA#JOINT-EM#0.000$Question Answering#HotpotQA#JOINT-F1#0.000
2109.04912v1.pdf	Question Answering#HotpotQA#Joint F1#34.1$Question Answering#TriviaQA#F1#45.5$Question Answering#TriviaQA#F1#37.2$Semantic Parsing#HotpotQA#F1-Score#22.4$Semantic Parsing#GraphQuestions#F1 Score#41.3
2105.07624v2.pdf	Question Answering#TAT-QA#Exact Match (EM)#50.1
1903.03033v1.pdf	Question Answering#RACE#RACE-m#76.7$Question Answering#RACE#RACE-h#69.6$Question Answering#RACE#RACE#71.7
1901.09381v2.pdf	Question Answering#RACE#RACE-m#73.4$Question Answering#RACE#RACE-h#68.1$Question Answering#RACE#RACE#69.7
1803.09074v1.pdf	Question Answering#RACE#RACE-m#60.2$Question Answering#RACE#RACE-h#50.3$Question Answering#RACE#RACE#53.3
1909.04849v1.pdf	Question Answering#NarrativeQA#Rouge-L#58.8
1811.04210v2.pdf	Question Answering#NarrativeQA#BLEU-1#44.35$Question Answering#NarrativeQA#BLEU-4#27.61$Question Answering#NarrativeQA#METEOR#21.80$Question Answering#NarrativeQA#Rouge-L#44.69$Question Answering#Quasart-T#EM#38.6$Question Answering#NewsQA#F1#66.3$Question Answering#NewsQA#EM#53.1$Open-Domain Question Answering#SearchQA#EM#62.2$Open-Domain Question Answering#SearchQA#Unigram Acc#62.2$Open-Domain Question Answering#SearchQA#N-gram F1#70.8$Open-Domain Question Answering#SearchQA#EM#56.8$Open-Domain Question Answering#SearchQA#F1#63.6$Open-Domain Question Answering#Quasar#EM (Quasar-T)#38.6$Open-Domain Question Answering#Quasar#F1 (Quasar-T)#46.9
1809.06309v3.pdf	Question Answering#NarrativeQA#BLEU-1#43.63$Question Answering#NarrativeQA#BLEU-4#21.07$Question Answering#NarrativeQA#METEOR#19.03$Question Answering#NarrativeQA#Rouge-L#44.16$Question Answering#WikiHop#Test#57.9
2012.04584v2.pdf	Question Answering#NarrativeQA#BLEU-1#35.3$Question Answering#NarrativeQA#BLEU-4#7.5$Question Answering#NarrativeQA#METEOR#11.1$Question Answering#NarrativeQA#Rouge-L#32$Question Answering#TriviaQA#EM#72.1
1712.07040v1.pdf	Question Answering#NarrativeQA#BLEU-1#54.60/55.55$Question Answering#NarrativeQA#BLEU-4#26.71/27.78
2203.13947v1.pdf	Question Answering#FairytaleQA#Rouge-L#0.533$Question Answering#FairytaleQA#F1#0.536$Question Answering#FairytaleQA#Rouge-L#0.475$Question Answering#FairytaleQA#F1#0.492$Question Answering#FairytaleQA#Rouge-L#0.108$Question Answering#FairytaleQA#F1#0.088$Question Answering#FairytaleQA#Rouge-L#0.097$Question Answering#FairytaleQA#F1#0.082$Question Generation#FairytaleQA#ROUGE-L#0.527$Question Generation#FairytaleQA#ROUGE-L#0.519$Question Generation#FairytaleQA#ROUGE-L#0.442
1908.08167v2.pdf	Question Answering#Quasart-T#EM#51.1$Open-Domain Question Answering#SearchQA#EM#65.1
2103.00418v1.pdf	Question Answering#Mathematics Dataset#Accuracy#0.98667
1910.06611v2.pdf	Question Answering#Mathematics Dataset#Accuracy#0.8192
1904.01557v1.pdf	Question Answering#Mathematics Dataset#Accuracy#0.76$Question Answering#Mathematics Dataset#Accuracy#0.57
1810.13441v2.pdf	Question Answering#Story Cloze Test#Accuracy#88.3
1803.05547v1.pdf	Question Answering#Story Cloze Test#Accuracy#76.5
2202.01764v1.pdf	Question Answering#JaQuAD#F1#78.92$Question Answering#JaQuAD#Exact Match#63.38
2001.09694v4.pdf	Question Answering#SQuAD2.0#EM#90.578$Question Answering#SQuAD2.0#F1#92.978$Question Answering#SQuAD2.0#EM#90.115$Question Answering#SQuAD2.0#F1#92.580$Question Answering#SQuAD2.0#EM#89.562$Question Answering#SQuAD2.0#F1#92.052$Question Answering#SQuAD2.0#EM#88.107$Question Answering#SQuAD2.0#F1#91.419
2110.09665v1.pdf	Question Answering#SQuAD2.0#F1#90.123
2105.08050v2.pdf	Question Answering#SQuAD2.0#F1#78.3$Natural Language Inference#MultiNLI#Matched#86.2$Natural Language Inference#MultiNLI#Mismatched#86.5$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.8$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#Number of params#73M$Image Classification#ImageNet#GFLOPs#31.6
2109.04223v2.pdf	Question Answering#MultiRC#F1#70.8$Question Answering#MultiRC#EM#27.2$Question Answering#COPA#Accuracy#78.0$Common Sense Reasoning#ReCoRD#F1#89.6$Common Sense Reasoning#ReCoRD#EM#89.1$Common Sense Reasoning#ReCoRD#F1#76.7$Common Sense Reasoning#ReCoRD#EM#76.2
2007.01282v2.pdf	Question Answering#ConditionalQA#Conditional (answers)#45.2 / 49.7$Question Answering#ConditionalQA#Conditional (w/ conditions)#4.7 / 5.8$Question Answering#ConditionalQA#Overall (answers)#44.4 / 50.8$Question Answering#ConditionalQA#Overall (w/ conditions)#35.0 / 40.6$Question Answering#Natural Questions#EM#54.7$Question Answering#Natural Questions#EM#51.4$Question Answering#TriviaQA#EM#67.6$Question Answering#SQuAD#F1#56.7
2106.00200v2.pdf	Question Answering#ConditionalQA#Conditional (answers)#42.0 / 46.4$Question Answering#ConditionalQA#Conditional (w/ conditions)#3.1 / 3.8$Question Answering#ConditionalQA#Overall (answers)#40.6 / 45.2$Question Answering#ConditionalQA#Overall (w/ conditions)#31.9 / 36.0$Question Answering#HybridQA#ANS-EM#46.3
2004.08483v5.pdf	Question Answering#ConditionalQA#Conditional (answers)#39.4 / 41.8$Question Answering#ConditionalQA#Conditional (w/ conditions)#2.5 / 3.4$Question Answering#ConditionalQA#Overall (answers)#35.6 / 39.8$Question Answering#ConditionalQA#Overall (w/ conditions)#26.9 / 30.8
2002.06071v2.pdf	Question Answering#FQuAD#EM#82.1$Question Answering#FQuAD#F1#92.2$Question Answering#FQuAD#EM#79.0$Question Answering#FQuAD#F1#89.5$Question Answering#FQuAD#EM#78.4$Question Answering#FQuAD#F1#88.4$Question Answering#FQuAD#EM#75.3$Question Answering#FQuAD#F1#85.9
2007.00968v1.pdf	Question Answering#FQuAD#EM#77.0$Question Answering#FQuAD#F1#88.4
2010.03813v2.pdf	Question Answering#FQuAD#EM#57.2$Question Answering#FQuAD#F1#70.71
1912.09723v3.pdf	Question Answering#SberQuAD#EM#66.30+-0.24$Question Answering#SberQuAD#F1#84.60+-0.11$Question Answering#SberQuAD#EM#64.35+-0.39$Question Answering#SberQuAD#F1#83.39+-0.08$Question Answering#SberQuAD#EM#60.62$Question Answering#SberQuAD#F1#80.04
2110.06176v2.pdf	Question Answering#ComplexWebQuestions#EM#47.7$Question Answering#TriviaQA#EM#65.8$Passage Retrieval#EntityQuestions#Recall@20#0.838
2210.09338v2.pdf	Question Answering#MedQA-USMLE#Accuracy#47.5$Common Sense Reasoning#CommonsenseQA#Accuracy#78.2$Riddle Sense#Riddle Sense#Accuracy (%)#71.3
2104.06378v4.pdf	Question Answering#MedQA-USMLE#Accuracy#38.0$Question Answering#OpenBookQA#Accuracy#82.8$Common Sense Reasoning#CommonsenseQA#Accuracy#76.1$Riddle Sense#Riddle Sense#Accuracy (%)#67
2004.12934v1.pdf	Question Answering#SCDE#BA#0.717$Question Answering#SCDE#PA#0.299$Question Answering#SCDE#DE#0.661
2112.07337v2.pdf	Question Answering#HybridQA#ANS-EM#64.3
2109.04312v1.pdf	Question Answering#HybridQA#ANS-EM#62.7
2004.07347v3.pdf	Question Answering#HybridQA#ANS-EM#43.8
1803.09720v1.pdf	Question Answering#CliCR#F1#33.9$Question Answering#CliCR#F1#27.2
1906.02829v1.pdf	Question Answering#TrecQA#MAP#0.7773$Question Answering#TrecQA#MRR#0.7416$Multi-Label Text Classification#EUR-Lex#nDCG@5#68.8$Multi-Label Text Classification#EUR-Lex#P@1#80.2$Multi-Label Text Classification#EUR-Lex#P@3#65.48$Multi-Label Text Classification#EUR-Lex#P@5#52.83$Multi-Label Text Classification#EUR-Lex#nDCG@3#71.11$Multi-Label Text Classification#EUR-Lex#nDCG@1#80.2$Text Classification#RCV1#P@1#97.05$Text Classification#RCV1#P@3#81.27$Text Classification#RCV1#P@5#56.33$Text Classification#RCV1#nDCG@1#97.05$Text Classification#RCV1#nDCG@3#92.47$Text Classification#RCV1#nDCG@5#93.11
1801.01641v2.pdf	Question Answering#TrecQA#MAP#0.750$Question Answering#TrecQA#MRR#0.811
2109.03502v1.pdf	Question Answering#Natural Questions#EM#59.9$Open-Domain Question Answering#Natural Questions#Exact Match#55.9$Passage Retrieval#Natural Questions#Precision@20#85.26$Passage Retrieval#Natural Questions#Precision@100#88.25$Passage Retrieval#Natural Questions#Precision@20#84.46$Passage Retrieval#Natural Questions#Precision@100#88.03
2106.05346v2.pdf	Question Answering#Natural Questions#EM#52.5$Question Answering#TriviaQA#EM#71.4$Open-Domain Question Answering#Natural Questions (short)#Exact Match#52.5$Open-Domain Question Answering#WebQuestions#Exact Match#48.7
2112.04426v3.pdf	Question Answering#Natural Questions#EM#45.5
1706.02596v3.pdf	Question Answering#TriviaQA#EM#50.56$Question Answering#TriviaQA#F1#56.73
2004.11546v3.pdf	Question Answering#CODAH#Accuracy#84.0
1904.04365v4.pdf	Question Answering#CODAH#Accuracy#69.6$Common Sense Reasoning#CODAH#Accuracy#69.6
1907.10738v1.pdf	Question Answering#OpenBookQA#Accuracy#72.0
2009.07448v1.pdf	Question Answering#DROP Test#F1#88.38
2201.11473v2.pdf	Question Answering#DROP Test#F1#87.6
1909.00109v2.pdf	Question Answering#DROP Test#F1#81.78
1909.13375v4.pdf	Question Answering#DROP Test#F1#80.7
1908.05514v2.pdf	Question Answering#DROP Test#F1#79.88
2004.04487v1.pdf	Question Answering#DROP Test#F1#72.4
1910.06701v1.pdf	Question Answering#DROP Test#F1#67.97
1903.00161v2.pdf	Question Answering#DROP Test#F1#47.01$Question Answering#DROP Test#F1#32.7
1604.04315v3.pdf	Question Answering#Aristo Kaggle Allen AI 8th grade questions#1:1 Accuracy#59.31$Question Answering#Aristo Kaggle Allen AI 8th grade questions#1:1 Accuracy#58.26
2112.05785v1.pdf	Question Answering#CronQuestions#Hits@1#91.8$Question Answering#CronQuestions#Hits@1#79.9$Question Answering#CronQuestions#Hits@1#74.5$Question Answering#CronQuestions#Hits@1#24.3$Question Answering#CronQuestions#Hits@1#22.5
2203.00255v1.pdf	Question Answering#CronQuestions#Hits@1#83.1
2106.01515v1.pdf	Question Answering#CronQuestions#Hits@1#64.7
2105.03011v1.pdf	Question Answering#QASPER#Token F1#33.63
2004.05150v2.pdf	Question Answering#WikiHop#Test#81.9$Language Modelling#enwik8#Bit per Character (BPC)#0.99$Language Modelling#enwik8#Number of params#102M$Language Modelling#enwik8#Bit per Character (BPC)#1.00$Language Modelling#enwik8#Number of params#41M$Language Modelling#Hutter Prize#Bit per Character (BPC)#0.99$Language Modelling#Hutter Prize#Number of params#102M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.00$Language Modelling#Hutter Prize#Number of params#41M
1910.02610v2.pdf	Question Answering#WikiHop#Test#76.5
1901.00603v2.pdf	Question Answering#WikiHop#Test#70.6
1804.05922v1.pdf	Question Answering#WikiHop#Test#59.3
1710.06481v2.pdf	Question Answering#WikiHop#Test#42.9
2012.15466v1.pdf	Question Answering#Quora Question Pairs#Accuracy#90.3%$Natural Language Inference#QNLI#Accuracy#93.4%$Natural Language Inference#RTE#Accuracy#79.8%$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.905$Semantic Textual Similarity#MRPC#Accuracy#90.6%$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.5$Linguistic Acceptability#CoLA#Accuracy#64.3%
1907.12412v2.pdf	Question Answering#Quora Question Pairs#Accuracy#90.1%$Question Answering#Quora Question Pairs#Accuracy#89.8%$Open-Domain Question Answering#DuReader#EM#64.2$Open-Domain Question Answering#DuReader#EM#61.3$Natural Language Inference#XNLI Chinese Dev#Accuracy#82.6$Natural Language Inference#XNLI Chinese Dev#Accuracy#81.2$Natural Language Inference#QNLI#Accuracy#94.6%$Natural Language Inference#QNLI#Accuracy#92.9%$Natural Language Inference#WNLI#Accuracy#67.8%$Natural Language Inference#XNLI Chinese#Accuracy#81$Natural Language Inference#XNLI Chinese#Accuracy#79.7$Natural Language Inference#RTE#Accuracy#80.2%$Natural Language Inference#RTE#Accuracy#74.8%$Natural Language Inference#MultiNLI#Matched#88.7$Natural Language Inference#MultiNLI#Mismatched#88.8$Natural Language Inference#MultiNLI#Matched#86.1$Natural Language Inference#MultiNLI#Mismatched#85.5$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.912$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.876$Semantic Textual Similarity#MRPC#Accuracy#87.4%$Semantic Textual Similarity#MRPC#Accuracy#86.1%$Sentiment Analysis#SST-2 Binary classification#Accuracy#95$Chinese Named Entity Recognition#MSRA#F1#95$Chinese Named Entity Recognition#MSRA#F1#93.8$Chinese Named Entity Recognition#MSRA Dev#F1#96.3$Chinese Named Entity Recognition#MSRA Dev#F1#95.2$Linguistic Acceptability#CoLA#Accuracy#63.5%$Linguistic Acceptability#CoLA#Accuracy#55.2%
2003.10555v1.pdf	Question Answering#Quora Question Pairs#Accuracy#90.1%$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.9
1910.01108v4.pdf	Question Answering#Quora Question Pairs#Accuracy#89.2%$Question Answering#SQuAD1.1 dev#EM#77.7$Question Answering#SQuAD1.1 dev#F1#85.8$Natural Language Inference#QNLI#Accuracy#90.2%$Natural Language Inference#WNLI#Accuracy#44.4%$Natural Language Inference#RTE#Accuracy#62.9%$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.907$Semantic Textual Similarity#MRPC#Accuracy#90.2%$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.3$Sentiment Analysis#IMDb#Accuracy#92.82$Linguistic Acceptability#CoLA#Accuracy#49.1%
2006.11316v1.pdf	Question Answering#Quora Question Pairs#Accuracy#80.3%$Natural Language Inference#QNLI#Accuracy#90.1%$Natural Language Inference#WNLI#Accuracy#65.1%$Natural Language Inference#RTE#Accuracy#73.2%$Natural Language Inference#MultiNLI#Matched#82.0$Natural Language Inference#MultiNLI#Mismatched#81.1$Semantic Textual Similarity#MRPC#Accuracy#87.8%$Semantic Textual Similarity#MRPC#Number of Params#51.1M$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.4$Linguistic Acceptability#CoLA#Accuracy#46.5%
2104.07705v2.pdf	Question Answering#Quora Question Pairs#Accuracy#70.7$Natural Language Inference#QNLI#Accuracy#90.6$Natural Language Inference#RTE#Accuracy#57.7%$Natural Language Inference#MultiNLI#Matched#84.4$Natural Language Inference#MultiNLI#Mismatched#83.8$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.820$Semantic Textual Similarity#MRPC#Accuracy#87.5%$Sentiment Analysis#SST-2 Binary classification#Accuracy#93.0$Linguistic Acceptability#CoLA#Accuracy#57.1
2106.11517v1.pdf	Question Answering#SQuAD#Exact Match#40.02
1801.08290v1.pdf	Question Answering#NewsQA#F1#63.7$Question Answering#NewsQA#EM#48.4$Open-Domain Question Answering#SearchQA#Unigram Acc#46.8$Open-Domain Question Answering#SearchQA#N-gram F1#56.6$Open-Domain Question Answering#SearchQA#EM#-$Open-Domain Question Answering#SearchQA#F1#-
1805.08092v1.pdf	Question Answering#NewsQA#F1#63.2$Question Answering#NewsQA#EM#50.1
2104.12377v1.pdf	Question Answering#Molweni#F1#61.5$Question Answering#Molweni#EM#46.5
2103.07449v3.pdf	Question Answering#MRQA out-of-domain#Average F1#68.4
2111.05754v1.pdf	Question Answering#SQuAD1.1 dev#EM#83.35$Question Answering#SQuAD1.1 dev#F1#90.2$Question Answering#SQuAD1.1 dev#EM#83.22$Question Answering#SQuAD1.1 dev#F1#90.02$Question Answering#SQuAD1.1 dev#EM#81.1$Question Answering#SQuAD1.1 dev#F1#88.42$Question Answering#SQuAD1.1 dev#EM#80.84$Question Answering#SQuAD1.1 dev#F1#88.24$Question Answering#SQuAD1.1 dev#EM#79.83$Question Answering#SQuAD1.1 dev#F1#87.25$Question Answering#SQuAD1.1 dev#EM#78.1$Question Answering#SQuAD1.1 dev#F1#85.82$Question Answering#SQuAD1.1 dev#EM#77.03$Question Answering#SQuAD1.1 dev#F1#85.13$Question Answering#SQuAD1.1 dev#EM#76.91$Question Answering#SQuAD1.1 dev#F1#84.82$Question Answering#SQuAD1.1 dev#EM#75.62$Question Answering#SQuAD1.1 dev#F1#83.87$Natural Language Inference#MultiNLI Dev#Matched#83.74$Natural Language Inference#MultiNLI Dev#Mismatched#84.2$Natural Language Inference#MultiNLI Dev#Matched#83.47$Natural Language Inference#MultiNLI Dev#Mismatched#84.08$Natural Language Inference#MultiNLI Dev#Matched#82.71$Natural Language Inference#MultiNLI Dev#Mismatched#83.67$Natural Language Inference#MultiNLI Dev#Matched#81.45$Natural Language Inference#MultiNLI Dev#Mismatched#82.43$Natural Language Inference#MultiNLI Dev#Matched#81.4$Natural Language Inference#MultiNLI Dev#Mismatched#82.51$Natural Language Inference#MultiNLI Dev#Matched#81.35$Natural Language Inference#MultiNLI Dev#Mismatched#82.03$Natural Language Inference#MultiNLI Dev#Matched#80.68$Natural Language Inference#MultiNLI Dev#Mismatched#81.47$Natural Language Inference#MultiNLI Dev#Matched#80.66$Natural Language Inference#MultiNLI Dev#Mismatched#81.14$Natural Language Inference#MultiNLI Dev#Matched#78.8$Natural Language Inference#MultiNLI Dev#Mismatched#80.4
1910.13461v1.pdf	Question Answering#SQuAD1.1 dev#F1#90.8$Text Summarization#X-Sum#ROUGE-1#45.14$Text Summarization#X-Sum#ROUGE-2#22.27$Text Summarization#X-Sum#ROUGE-3#37.25$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.16$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.28$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#40.90
1904.00962v5.pdf	Question Answering#SQuAD1.1 dev#F1#90.584
2003.02645v5.pdf	Question Answering#YahooCQA#P@1#0.757$Question Answering#YahooCQA#MRR#0.863$Question Answering#YahooCQA#P@1#0.683$Question Answering#YahooCQA#MRR#0.818
2012.14610v3.pdf	Open-Domain Question Answering#TQA#Exact Match#65.5$Open-Domain Question Answering#Natural Questions#Exact Match#54.9$Open-Domain Question Answering#WebQuestions#Exact Match#57.7$Knowledge Base Question Answering#WebQuestionsSP#Hits@1#79.1$Knowledge Base Question Answering#WebQuestionsSP#Hits@1#76.7
2106.00882v1.pdf	Open-Domain Question Answering#TQA#Exact Match#56.8$Open-Domain Question Answering#Natural Questions#Exact Match#41.6
2207.06300v1.pdf	Open-Domain Question Answering#KILT: TriviaQA#KILT-EM#57.91$Open-Domain Question Answering#KILT: TriviaQA#R-Prec#72.68$Open-Domain Question Answering#KILT: TriviaQA#Recall@5#74.23$Open-Domain Question Answering#KILT: TriviaQA#EM#76.27$Open-Domain Question Answering#KILT: TriviaQA#F1#81.4$Open-Domain Question Answering#KILT: TriviaQA#KILT-F1#61.78$Open-Domain Question Answering#KILT: Natural Questions#KILT-EM#43.56$Open-Domain Question Answering#KILT: Natural Questions#R-Prec#70.78$Open-Domain Question Answering#KILT: Natural Questions#Recall@5#76.63$Open-Domain Question Answering#KILT: Natural Questions#EM#51.73$Open-Domain Question Answering#KILT: Natural Questions#F1#60.97$Open-Domain Question Answering#KILT: Natural Questions#KILT-F1#49.8$Slot Filling#KILT: T-REx#KILT-AC#75.84$Slot Filling#KILT: T-REx#R-Prec#80.7$Slot Filling#KILT: T-REx#Recall@5#89.0$Slot Filling#KILT: T-REx#Accuracy#87.68$Slot Filling#KILT: T-REx#F1#89.93$Slot Filling#KILT: T-REx#KILT-F1#77.05$Fact Verification#KILT: FEVER#KILT-AC#78.53$Fact Verification#KILT: FEVER#R-Prec#88.92$Fact Verification#KILT: FEVER#Recall@5#92.52$Fact Verification#KILT: FEVER#Accuracy#89.55$Open-Domain Dialog#KILT: Wizard of Wikipedia#KILT-RL#11.39$Open-Domain Dialog#KILT: Wizard of Wikipedia#R-Prec#60.1$Open-Domain Dialog#KILT: Wizard of Wikipedia#Recall@5#79.98$Open-Domain Dialog#KILT: Wizard of Wikipedia#ROUGE-L#16.76$Open-Domain Dialog#KILT: Wizard of Wikipedia#F1#18.9$Open-Domain Dialog#KILT: Wizard of Wikipedia#KILT-F1#12.98
2009.02252v4.pdf	Open-Domain Question Answering#KILT: TriviaQA#KILT-EM#0.0$Open-Domain Question Answering#KILT: TriviaQA#R-Prec#0.0$Open-Domain Question Answering#KILT: TriviaQA#Recall@5#0.0$Open-Domain Question Answering#KILT: TriviaQA#EM#18.11$Open-Domain Question Answering#KILT: TriviaQA#F1#27.83$Open-Domain Question Answering#KILT: TriviaQA#KILT-F1#0.0$Open-Domain Question Answering#KILT: Natural Questions#KILT-EM#0.0$Open-Domain Question Answering#KILT: Natural Questions#R-Prec#0.0$Open-Domain Question Answering#KILT: Natural Questions#Recall@5#0.0$Open-Domain Question Answering#KILT: Natural Questions#EM#19.6$Open-Domain Question Answering#KILT: Natural Questions#F1#27.73$Open-Domain Question Answering#KILT: Natural Questions#KILT-F1#0.0$Open-Domain Question Answering#KILT: ELI5#KILT-RL#0.0$Open-Domain Question Answering#KILT: ELI5#R-Prec#0.0$Open-Domain Question Answering#KILT: ELI5#Recall@5#0.0$Open-Domain Question Answering#KILT: ELI5#ROUGE-L#19.08$Open-Domain Question Answering#KILT: ELI5#F1#16.1$Open-Domain Question Answering#KILT: ELI5#KILT-F1#0.0$Open-Domain Question Answering#KILT: HotpotQA#KILT-EM#0.0$Open-Domain Question Answering#KILT: HotpotQA#R-Prec#0.0$Open-Domain Question Answering#KILT: HotpotQA#Recall@5#0.0$Open-Domain Question Answering#KILT: HotpotQA#EM#12.64$Open-Domain Question Answering#KILT: HotpotQA#F1#19.57$Open-Domain Question Answering#KILT: HotpotQA#KILT-F1#0.0$Entity Linking#KILT: AIDA-YAGO2#KILT-AC#74.05$Entity Linking#KILT: AIDA-YAGO2#R-Prec#74.05$Entity Linking#KILT: AIDA-YAGO2#Recall@5#74.05$Entity Linking#KILT: AIDA-YAGO2#Accuracy#74.05$Entity Linking#KILT: WNED-WIKI#KILT-AC#47.13$Entity Linking#KILT: WNED-WIKI#R-Prec#47.13$Entity Linking#KILT: WNED-WIKI#Recall@5#47.13$Entity Linking#KILT: WNED-WIKI#Accuracy#47.13$Entity Linking#KILT: WNED-CWEB#KILT-AC#49.29$Entity Linking#KILT: WNED-CWEB#R-Prec#49.29$Entity Linking#KILT: WNED-CWEB#Recall@5#49.29$Entity Linking#KILT: WNED-CWEB#Accuracy#49.29$Slot Filling#KILT: Zero Shot RE#KILT-AC#0.0$Slot Filling#KILT: Zero Shot RE#R-Prec#0.0$Slot Filling#KILT: Zero Shot RE#Recall@5#0.0$Slot Filling#KILT: Zero Shot RE#Accuracy#9.02$Slot Filling#KILT: Zero Shot RE#F1#13.52$Slot Filling#KILT: Zero Shot RE#KILT-F1#0.0$Slot Filling#KILT: T-REx#KILT-AC#0.0$Slot Filling#KILT: T-REx#R-Prec#0.0$Slot Filling#KILT: T-REx#Recall@5#0.0$Slot Filling#KILT: T-REx#Accuracy#43.56$Slot Filling#KILT: T-REx#F1#50.61$Slot Filling#KILT: T-REx#KILT-F1#0.0$Fact Verification#KILT: FEVER#KILT-AC#53.45$Fact Verification#KILT: FEVER#R-Prec#61.94$Fact Verification#KILT: FEVER#Recall@5#75.55$Fact Verification#KILT: FEVER#Accuracy#86.31$Fact Verification#KILT: FEVER#KILT-AC#0.0$Fact Verification#KILT: FEVER#R-Prec#0.0$Fact Verification#KILT: FEVER#Recall@5#0.0$Fact Verification#KILT: FEVER#Accuracy#76.3$Open-Domain Dialog#KILT: Wizard of Wikipedia#KILT-RL#0.0$Open-Domain Dialog#KILT: Wizard of Wikipedia#R-Prec#0.0$Open-Domain Dialog#KILT: Wizard of Wikipedia#Recall@5#0.0$Open-Domain Dialog#KILT: Wizard of Wikipedia#ROUGE-L#12.4$Open-Domain Dialog#KILT: Wizard of Wikipedia#F1#13.53$Open-Domain Dialog#KILT: Wizard of Wikipedia#KILT-F1#0.0
2009.13013v1.pdf	Open-Domain Question Answering#SQuAD1.1 dev#EM#59.3
1904.06652v1.pdf	Open-Domain Question Answering#SQuAD1.1 dev#EM#50.2
1902.01718v2.pdf	Open-Domain Question Answering#SQuAD1.1 dev#EM#38.6
1709.00023v2.pdf	Open-Domain Question Answering#SearchQA#Unigram Acc#-$Open-Domain Question Answering#SearchQA#N-gram F1#-$Open-Domain Question Answering#SearchQA#EM#49.0$Open-Domain Question Answering#SearchQA#F1#55.3$Open-Domain Question Answering#Quasar#EM (Quasar-T)#35.3$Open-Domain Question Answering#Quasar#F1 (Quasar-T)#41.7
1806.04342v1.pdf	Open-Domain Question Answering#SearchQA#Unigram Acc#46.8$Open-Domain Question Answering#SearchQA#N-gram F1#53.4
2103.06332v2.pdf	Open-Domain Question Answering#KILT: ELI5#KILT-RL#2.36$Open-Domain Question Answering#KILT: ELI5#R-Prec#10.67$Open-Domain Question Answering#KILT: ELI5#Recall@5#24.56$Open-Domain Question Answering#KILT: ELI5#ROUGE-L#23.19$Open-Domain Question Answering#KILT: ELI5#F1#22.88$Open-Domain Question Answering#KILT: ELI5#KILT-F1#2.34
1711.05116v2.pdf	Open-Domain Question Answering#Quasar#EM (Quasar-T)#42.3$Open-Domain Question Answering#Quasar#F1 (Quasar-T)#49.6
2203.13926v3.pdf	Answer Selection#CICERO#Exact Match#77.68$Answer Selection#CICERO#Exact Match#77.51$Generative Question Answering#CICERO#ROUGE#0.2980$Generative Question Answering#CICERO#ROUGE#0.2946$Generative Question Answering#CICERO#ROUGE#0.2878$Generative Question Answering#CICERO#ROUGE#0.2837$Answer Generation#CICERO#ROUGE#0.2980$Answer Generation#CICERO#ROUGE#0.2947
1710.03430v3.pdf	Answer Selection#Ubuntu Dialogue (v2, Ranking)#1 in 10 R@1#0.652$Answer Selection#Ubuntu Dialogue (v2, Ranking)#1 in 10 R@2#0.815$Answer Selection#Ubuntu Dialogue (v2, Ranking)#1 in 10 R@5#0.966$Answer Selection#Ubuntu Dialogue (v2, Ranking)#1 in 2 R@1#0.915$Answer Selection#Ubuntu Dialogue (v1, Ranking)#1 in 10 R@1#0.684$Answer Selection#Ubuntu Dialogue (v1, Ranking)#1 in 2 R@1#0.916$Answer Selection#Ubuntu Dialogue (v1, Ranking)#1 in 10 R@2#0.822$Answer Selection#Ubuntu Dialogue (v1, Ranking)#1 in 10 R@5#0.960
1808.04126v1.pdf	Knowledge Base Question Answering#WebQSP-WD#Avg F1#0.2588
2202.00120v2.pdf	Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.4459$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.3171$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.3039$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.23$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.2143$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.1998$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.1506$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.1503$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.124$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.0957$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.087$Knowledge Base Question Answering#QALD-9-Plus#Macro F1#0.0417
2104.08762v2.pdf	Knowledge Base Question Answering#ComplexWebQuestions#Accuracy#70.4$Knowledge Base Question Answering#ComplexWebQuestions#Accuracy#45.9$Knowledge Base Question Answering#ComplexWebQuestions#Accuracy#44.1$Semantic Parsing#WebQuestionsSP#Accuracy#70
2101.03737v2.pdf	Knowledge Base Question Answering#ComplexWebQuestions#Accuracy#53.9$Semantic Parsing#WebQuestionsSP#Accuracy#74.3
2203.14371v1.pdf	Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Test Set (Acc-%)#0.41$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Dev Set (Acc-%)#0.40$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Test Set (Acc-%)#0.39$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Dev Set (Acc-%)#0.39$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Test Set (Acc-%)#0.37$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Dev Set (Acc-%)#0.38$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Test Set (Acc-%)#0.33$Multiple Choice Question Answering (MCQA)#MedMCQA (w/o Context)#Dev Set (Acc-%)#0.35$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Test Set (Acc-%)#0.47$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Dev Set (Acc-%)#0.43$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Test Set (Acc-%)#0.43$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Dev Set (Acc-%)#0.41$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Test Set (Acc-%)#0.42$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Dev Set (Acc-%)#0.39$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Test Set (Acc-%)#0.37$Multiple Choice Question Answering (MCQA)#MedMCQA (with Context)#Dev Set (Acc-%)#0.35
2201.12501v1.pdf	Multiple Choice Question Answering (MCQA)#IndicGLUE WSTP Pa#Accuracy#77.55$Multiple Choice Question Answering (MCQA)#IndicGLUE WSTP Pa#Accuracy#74.33$Sentiment Analysis#IITP Product Reviews Sentiment#Accuracy#77.18$Sentiment Analysis#IITP Product Reviews Sentiment#Accuracy#76.33$Sentiment Analysis#IITP Movie Reviews Sentiment#Accuracy#66.34$Sentiment Analysis#IITP Movie Reviews Sentiment#Accuracy#65.91$News Classification#Soham News Article Classification#Accuracy#93.89$News Classification#Soham News Article Classification#Accuracy#93.22$News Classification#BBC Hindi News Article Classification#Accuracy#79.14$News Classification#BBC Hindi News Article Classification#Accuracy#77.28
2001.11314v3.pdf	Generative Question Answering#CoQA#F1-Score#84.5$Text Summarization#GigaWord#ROUGE-1#39.46$Text Summarization#GigaWord#ROUGE-2#20.34$Text Summarization#GigaWord#ROUGE-L#36.74$Text Summarization#GigaWord#ROUGE-1#39.25$Text Summarization#GigaWord#ROUGE-2#20.25$Text Summarization#GigaWord#ROUGE-L#36.53$Text Summarization#GigaWord#ROUGE-1#38.83$Text Summarization#GigaWord#ROUGE-2#20.04$Text Summarization#GigaWord#ROUGE-L#36.20$Text Summarization#GigaWord-10k#ROUGE-L#33.23$Text Summarization#GigaWord-10k#ROUGE-1#35.51$Text Summarization#GigaWord-10k#ROUGE-2#16.79$Text Summarization#GigaWord-10k#ROUGE-L#32.50$Text Summarization#GigaWord-10k#ROUGE-1#35.05$Text Summarization#GigaWord-10k#ROUGE-2#16.10$Text Summarization#GigaWord-10k#ROUGE-L#31.35$Text Summarization#GigaWord-10k#ROUGE-1#33.75$Text Summarization#GigaWord-10k#ROUGE-2#15.23$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.31$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.35$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.60$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.02$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.17$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.26$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#42.30$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.92$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#39.68$Question Generation#SQuAD1.1#BLEU-4#25.41
1905.03197v3.pdf	Generative Question Answering#CoQA#F1-Score#82.5$Text Summarization#GigaWord#ROUGE-1#38.90$Text Summarization#GigaWord#ROUGE-2#20.05$Text Summarization#GigaWord#ROUGE-L#36.00$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#43.08$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#20.43$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#40.34$Document Summarization#CNN / Daily Mail#ROUGE-1#43.08$Document Summarization#CNN / Daily Mail#ROUGE-2#20.43$Document Summarization#CNN / Daily Mail#ROUGE-L#40.34$Question Generation#SQuAD1.1#BLEU-4#22.78
2105.04165v3.pdf	Mathematical Question Answering#Geometry3K#Accuracy (%)#90.9$Mathematical Question Answering#Geometry3K#Accuracy (%)#78.3$Mathematical Question Answering#Geometry3K#Accuracy (%)#57.5$Mathematical Question Answering#Geometry3K#Accuracy (%)#56.9$Mathematical Question Answering#Geometry3K#Accuracy (%)#25.0$Mathematical Question Answering#GeoS#Accuracy (%)#67$Scene Parsing#PGDP5K#Total Accuracy#27.3
2205.09363v1.pdf	Mathematical Question Answering#Geometry3K#Accuracy (%)#74.1$Scene Parsing#PGDP5K#Total Accuracy#84.7
2010.06823v1.pdf	Math Word Problem Solving#ALG514#Accuracy (%)#57.39$Math Word Problem Solving#Math23K#Accuracy (5-fold)#74.84
2203.10316v4.pdf	Math Word Problem Solving#MAWPS#Accuracy (%)#92$Math Word Problem Solving#MathQA#Answer Accuracy#78.6$Math Word Problem Solving#Math23K#Accuracy (5-fold)#83$Math Word Problem Solving#SVAMP#Execution Accuracy#47.3
2107.13435v2.pdf	Math Word Problem Solving#MathQA#Answer Accuracy#76.6$Math Word Problem Solving#Math23K#Accuracy (5-fold)#82.4$Math Word Problem Solving#Math23K#Accuracy (training-test)#84.7
2109.03034v1.pdf	Math Word Problem Solving#Math23K#Accuracy (5-fold)#84.3$Math Word Problem Solving#Math23K#Accuracy (training-test)#85.4
2109.13112v1.pdf	Math Word Problem Solving#Math23K#Accuracy (5-fold)#80.8$Math Word Problem Solving#Math23K#Accuracy (training-test)#82.3
2012.10582v2.pdf	Math Word Problem Solving#Math23K#weakly-supervised#59.8
2103.07191v2.pdf	Math Word Problem Solving#SVAMP#Execution Accuracy#43.8$Math Word Problem Solving#SVAMP#Execution Accuracy#41.0$Math Word Problem Solving#SVAMP#Execution Accuracy#40.3$Math Word Problem Solving#SVAMP#Execution Accuracy#38.9
2103.03874v2.pdf	Math Word Problem Solving#MATH#Accuracy#6.9$Math Word Problem Solving#MATH#Parameters (Billions)#1.5$Math Word Problem Solving#MATH#Accuracy#6.4$Math Word Problem Solving#MATH#Parameters (Billions)#0.7$Math Word Problem Solving#MATH#Accuracy#6.2$Math Word Problem Solving#MATH#Parameters (Billions)#0.3$Math Word Problem Solving#MATH#Accuracy#5.6$Math Word Problem Solving#MATH#Parameters (Billions)#13$Math Word Problem Solving#MATH#Accuracy#5.4$Math Word Problem Solving#MATH#Parameters (Billions)#0.1$Math Word Problem Solving#MATH#Accuracy#5.2$Math Word Problem Solving#MATH#Parameters (Billions)#175$Math Word Problem Solving#MATH#Accuracy#3.0$Math Word Problem Solving#MATH#Accuracy#2.9$Math Word Problem Solving#MATH#Parameters (Billions)#2.7
2010.12821v1.pdf	Cross-Lingual Question Answering#XQuAD#EM#46.9$Cross-Lingual Question Answering#XQuAD#F1#63.8$Cross-Lingual Question Answering#XQuAD#EM#46.2$Cross-Lingual Question Answering#XQuAD#F1#63.2$Cross-Lingual Question Answering#TyDiQA-GoldP#EM#42.8$Cross-Lingual Question Answering#TyDiQA-GoldP#F1#58.1$Cross-Lingual Question Answering#MLQA#EM#37.3$Cross-Lingual Question Answering#MLQA#F1#53.1$Cross-Lingual Natural Language Inference#XNLI#Accuracy#71.3$Cross-Lingual Natural Language Inference#XNLI#Accuracy#70.7$Cross-Lingual NER#NER#F1#69.2$Cross-Lingual NER#NER#F1#68.9
2110.08151v3.pdf	Cross-Lingual Question Answering#XQuAD#Average F1#74.2
2209.09513v2.pdf	Science Question Answering#ScienceQA#Natural Science#75.44$Science Question Answering#ScienceQA#Social Science#70.87$Science Question Answering#ScienceQA#Language Science#78.09$Science Question Answering#ScienceQA#Text Context#74.68$Science Question Answering#ScienceQA#Image Context#67.43$Science Question Answering#ScienceQA#No Context#79.93$Science Question Answering#ScienceQA#Grades 1-6#78.23$Science Question Answering#ScienceQA#Grades 7-12#69.68$Science Question Answering#ScienceQA#Avg. Accuracy#75.17$Science Question Answering#ScienceQA#Natural Science#76.60$Science Question Answering#ScienceQA#Social Science#65.92$Science Question Answering#ScienceQA#Language Science#77.55$Science Question Answering#ScienceQA#Text Context#75.51$Science Question Answering#ScienceQA#Image Context#66.09$Science Question Answering#ScienceQA#No Context#79.58$Science Question Answering#ScienceQA#Grades 1-6#78.49$Science Question Answering#ScienceQA#Grades 7-12#67.63$Science Question Answering#ScienceQA#Avg. Accuracy#74.61$Science Question Answering#ScienceQA#Natural Science#71.00$Science Question Answering#ScienceQA#Social Science#76.04$Science Question Answering#ScienceQA#Language Science#78.91$Science Question Answering#ScienceQA#Text Context#66.42$Science Question Answering#ScienceQA#Image Context#66.53$Science Question Answering#ScienceQA#No Context#81.81$Science Question Answering#ScienceQA#Grades 1-6#77.06$Science Question Answering#ScienceQA#Grades 7-12#68.82$Science Question Answering#ScienceQA#Avg. Accuracy#74.11$Science Question Answering#ScienceQA#Natural Science#74.64$Science Question Answering#ScienceQA#Social Science#69.74$Science Question Answering#ScienceQA#Language Science#76.00$Science Question Answering#ScienceQA#Text Context#74.44$Science Question Answering#ScienceQA#Image Context#67.28$Science Question Answering#ScienceQA#No Context#77.42$Science Question Answering#ScienceQA#Grades 1-6#76.80$Science Question Answering#ScienceQA#Grades 7-12#68.89$Science Question Answering#ScienceQA#Avg. Accuracy#73.97
2006.01432v1.pdf	Multilingual Machine Comprehension in English Hindi#Extended XQuAD#F1 (QE-PE)#76.51$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#F1 (QE-PH)#57.31$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#F1(QH-PE)#51.04$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#F1(QH-PH)#59.80$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#EM(QE-PE)#64.29$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#EM(QE-PH)#44.71$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#EM(QH-PE)#41.01$Multilingual Machine Comprehension in English Hindi#Extended XQuAD#EM(QH-PH)#45.63
2005.00513v2.pdf	Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-1#39.34$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-2#12.56$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-L#34.89$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-1#38.57$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-2#10.93$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-L#34.33$Unsupervised Extractive Summarization#Pubmed#ROUGE-1#43.58$Unsupervised Extractive Summarization#Pubmed#ROUGE-2#17.00$Unsupervised Extractive Summarization#Pubmed#ROUGE-L#39.31$Unsupervised Extractive Summarization#Pubmed#ROUGE-1#39.79$Unsupervised Extractive Summarization#Pubmed#ROUGE-2#14.00$Unsupervised Extractive Summarization#Pubmed#ROUGE-L#36.09
1804.05685v2.pdf	Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-1#33.85$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-2#10.73$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-L#28.99$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-1#29.91$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-2#7.42$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-L#25.67$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-1#29.47$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-2#6.95$Unsupervised Extractive Summarization#arXiv Summarization Dataset#ROUGE-L#26.30$Unsupervised Extractive Summarization#Pubmed#ROUGE-1#39.19$Unsupervised Extractive Summarization#Pubmed#ROUGE-2#13.89$Unsupervised Extractive Summarization#Pubmed#ROUGE-L#34.59$Unsupervised Extractive Summarization#Pubmed#ROUGE-1#37.15$Unsupervised Extractive Summarization#Pubmed#ROUGE-2#11.36$Unsupervised Extractive Summarization#Pubmed#ROUGE-L#33.43$Unsupervised Extractive Summarization#Pubmed#ROUGE-1#33.89$Unsupervised Extractive Summarization#Pubmed#ROUGE-2#9.93$Unsupervised Extractive Summarization#Pubmed#ROUGE-L#29.70$Text Summarization#arXiv#ROUGE-1#35.80$Text Summarization#Pubmed#ROUGE-1#38.93
2106.00130v2.pdf	Unsupervised Extractive Summarization#FacetSum#ROUGE-L#42.89$Unsupervised Extractive Summarization#FacetSum#ROUGE-L#42.18$Unsupervised Extractive Summarization#FacetSum#ROUGE-L#41.87$Unsupervised Extractive Summarization#FacetSum#ROUGE-L#38.71$Unsupervised Extractive Summarization#FacetSum#ROUGE-L#35.98
1606.01847v3.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#70.1$Visual Question Answering#VQA v1 test-dev#Accuracy#64.2$Visual Question Answering#VQA v2 test-dev#Accuracy#64.7$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#66.5$Visual Question Answering#Visual7W#Percentage correct#62.2$Phrase Grounding#ReferIt#Accuracy#28.91$Phrase Grounding#Flickr30k Entities Test#Accuracy#48.69
1711.06794v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#70.04$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#66.09
1805.09701v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#69.60$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#65.69
1711.04323v1.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#69.3
1606.03647v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#67.3$Visual Question Answering#VQA v1 test-dev#Accuracy#63.3$Visual Question Answering#VQA v1 test-std#Accuracy#63.2$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#63.2
1606.01455v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#66.3$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#61.8
1604.01485v1.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#64.2$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#59.5
1505.00468v7.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#63.1$Visual Question Answering#COCO Visual Question Answering (VQA) abstract 1.0 multiple choice#Percentage correct#71.18$Visual Question Answering#COCO Visual Question Answering (VQA) abstract 1.0 multiple choice#Percentage correct#69.21$Visual Question Answering#COCO Visual Question Answering (VQA) abstract 1.0 multiple choice#Percentage correct#61.41$Visual Question Answering#COCO Visual Question Answering (VQA) real images 2.0 open ended#Percentage correct#68.16$Visual Question Answering#COCO Visual Question Answering (VQA) real images 2.0 open ended#Percentage correct#68.07$Visual Question Answering#COCO Visual Question Answering (VQA) abstract images 1.0 open ended#Percentage correct#69.73$Visual Question Answering#COCO Visual Question Answering (VQA) abstract images 1.0 open ended#Percentage correct#65.02$Visual Question Answering#COCO Visual Question Answering (VQA) abstract images 1.0 open ended#Percentage correct#57.19$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#58.2
1512.02167v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#Percentage correct#62.0$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#55.9
2206.01201v2.pdf	Visual Question Answering#OK-VQA#Accuracy#58$Visual Question Answering#OK-VQA#Accuracy#56.6
2210.13626v1.pdf	Visual Question Answering#OK-VQA#Accuracy#43.1$Visual Question Answering#A-OKVQA#DA VQA Score#38.05
2210.08773v1.pdf	Visual Question Answering#OK-VQA#Accuracy#35.9$Visual Question Answering#GQA test-dev#Accuracy#41.9$Visual Question Answering#VQA v2 val#Accuracy#63.3$Visual Question Answering#VQA v2 test-dev#Accuracy#64.8
2206.06336v1.pdf	Visual Question Answering#OK-VQA#Accuracy#11.4$Visual Question Answering#VQA v2 val#Accuracy#41.1$Image Captioning#Flickr30k Captions test#CIDEr#43.3$Image Captioning#Flickr30k Captions test#SPICE#11.7$Image Captioning#nocaps val#CIDEr#58.7$Image Captioning#nocaps val#SPICE#8.6$Image Captioning#COCO Captions Karpathy Test#BLEU-4#24.5$Image Captioning#COCO Captions Karpathy Test#CIDEr#82.2$Image Captioning#COCO Captions Karpathy Test#METEOR#22.5$Image Captioning#COCO Captions Karpathy Test#SPICE#15.7
2106.13884v2.pdf	Visual Question Answering#OK-VQA#Accuracy#5.9$Visual Question Answering#VQA v2 val#Accuracy#29.5
2007.00398v3.pdf	Visual Question Answering#DocVQA val#ANLS#0.655$Visual Question Answering#DocVQA val#Accuracy#54.48$Visual Question Answering#DocVQA test#ANLS#0.981$Visual Question Answering#DocVQA test#Accuracy#94.36$Visual Question Answering#DocVQA test#ANLS#0.665$Visual Question Answering#DocVQA test#Accuracy#55.77
1908.01801v2.pdf	Visual Question Answering#FigureQA - test 1#1:1 Accuracy#94.88$Visual Question Answering#PlotQA-D1#1:1 Accuracy#57.91$Visual Question Answering#PlotQA-D2#1:1 Accuracy#10.37
2111.14792v2.pdf	Visual Question Answering#FigureQA - test 1#1:1 Accuracy#94.23$Visual Question Answering#PlotQA-D1#1:1 Accuracy#76.94$Visual Question Answering#PlotQA-D2#1:1 Accuracy#34.44
1710.07300v2.pdf	Visual Question Answering#FigureQA - test 1#1:1 Accuracy#76.52
1908.08530v4.pdf	Visual Question Answering#VCR (Q-AR) dev#Accuracy#58.9$Visual Question Answering#VCR (Q-AR) dev#Accuracy#55.2$Visual Question Answering#VCR (QA-R) dev#Accuracy#77.9$Visual Question Answering#VCR (QA-R) dev#Accuracy#74.4$Visual Question Answering#VCR (Q-A) dev#Accuracy#75.5$Visual Question Answering#VCR (Q-A) dev#Accuracy#73.8$Visual Question Answering#VCR (Q-AR) test#Accuracy#59.7$Visual Question Answering#VQA v2 test-dev#Accuracy#71.79$Visual Question Answering#VQA v2 test-dev#Accuracy#71.16$Visual Question Answering#VQA v2 test-std#overall#72.2$Visual Question Answering#VCR (QA-R) test#Accuracy#78.4$Visual Question Answering#VCR (Q-A) test#Accuracy#75.8
1908.03557v1.pdf	Visual Question Answering#VCR (Q-AR) dev#Accuracy#52.2$Visual Question Answering#VCR (QA-R) dev#Accuracy#73.2$Visual Question Answering#VCR (Q-A) dev#Accuracy#70.8$Visual Question Answering#VCR (Q-AR) test#Accuracy#52.4$Visual Question Answering#VQA v2 test-dev#Accuracy#70.8$Visual Question Answering#VQA v2 test-std#overall#71$Visual Question Answering#VCR (QA-R) test#Accuracy#73.2$Visual Question Answering#VCR (Q-A) test#Accuracy#71.6$Visual Reasoning#NLVR2 Dev#Accuracy#66.7$Visual Reasoning#NLVR#Accuracy (Dev)#67.4%$Visual Reasoning#NLVR#Accuracy (Test-P)#67%$Visual Reasoning#NLVR#Accuracy (Test-U)#67.3%$Phrase Grounding#Flickr30k Entities Dev#R@1#70.4$Phrase Grounding#Flickr30k Entities Dev#R@10#86.31$Phrase Grounding#Flickr30k Entities Dev#R@5#84.49$Phrase Grounding#Flickr30k Entities Test#R@1#71.33$Phrase Grounding#Flickr30k Entities Test#R@10#86.51$Phrase Grounding#Flickr30k Entities Test#R@5#84.98
2102.09550v3.pdf	Visual Question Answering#DocVQA test#ANLS#0.8705$Visual Question Answering#DocVQA test#ANLS#0.8392$Visual Question Answering#DocVQA#ANLS#87.05$Visual Question Answering#DocVQA#ANLS#83.92$Document Image Classification#RVL-CDIP#Accuracy#95.52%$Document Image Classification#RVL-CDIP#Accuracy#95.25%$Document Image Classification#RVL-CDIP#Parameters#230M
2012.14740v4.pdf	Visual Question Answering#DocVQA test#ANLS#0.867$Document Image Classification#RVL-CDIP#Accuracy#95.64$Document Image Classification#RVL-CDIP#Accuracy#95.25$Document Image Classification#RVL-CDIP#Parameters#200M
1611.09978v1.pdf	Visual Question Answering#Visual Genome (pairs)#Percentage correct#28.52$Visual Question Answering#Visual Genome (subjects)#Percentage correct#44.24$Visual Question Answering#Visual7W#Percentage correct#72.53
1609.05600v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) abstract 1.0 multiple choice#Percentage correct#74.37$Visual Question Answering#COCO Visual Question Answering (VQA) abstract images 1.0 open ended#Percentage correct#70.42
2205.11169v1.pdf	Visual Question Answering#GQA#Accuracy#77$Visual Commonsense Reasoning#VCR (QA-R) test#Accuracy#76.7$Visual Commonsense Reasoning#VCR (QA-R) dev#Accuracy#76.4$Visual Commonsense Reasoning#VCR (Q-A) dev#Accuracy#75.1$Visual Commonsense Reasoning#VCR (Q-AR) test#Accuracy#58.6$Visual Commonsense Reasoning#VCR (Q-A) test#Accuracy#76.0$Visual Commonsense Reasoning#VCR (Q-AR) dev#Accuracy#57.8$Visual Relationship Detection#Visual Genome#R@50#64.4$Visual Relationship Detection#Visual Genome#R@100#66.3$Visual Relationship Detection#Visual Genome#mR@50#21.7$Visual Relationship Detection#Visual Genome#mR@100#23.5$Phrase Grounding#Flickr30k Entities Dev#R@1#84.1$Phrase Grounding#Flickr30k Entities Test#R@1#84.4
2204.11167v2.pdf	Visual Question Answering#GQA#Accuracy#65.54$Human-Object Interaction Detection#HICO#mAP#43.98
2110.13214v4.pdf	Visual Question Answering#IconQA#Sub-tasks (Img.)#82.66$Visual Question Answering#IconQA#Sub-tasks (Txt.)#75.19$Visual Question Answering#IconQA#Sub-tasks (Blank)#83.62$Visual Question Answering#IconQA#Reasoning (Geo.)#81.87$Visual Question Answering#IconQA#Reasoning (Cou.)#77.81$Visual Question Answering#IconQA#Reasoning (Com.)#87.00$Visual Question Answering#IconQA#Reasoning (Spa.)#55.62$Visual Question Answering#IconQA#Reasoning (Sce.)#62.39$Visual Question Answering#IconQA#Reasoning (Pat.)#68.75$Visual Question Answering#IconQA#Reasoning (Tim.)#77.98$Visual Question Answering#IconQA#Reasoning (Fra.)#82.13$Visual Question Answering#IconQA#Reasoning (Est.)#98.24$Visual Question Answering#IconQA#Reasoning (Alg.)#56.73$Visual Question Answering#IconQA#Reasoning (Mea.)#97.98$Visual Question Answering#IconQA#Reasoning (Sen.)#92.49$Visual Question Answering#IconQA#Reasoning (Pro.)#95.73$Visual Question Answering#IconQA#Sub-tasks (Img.)#79.67$Visual Question Answering#IconQA#Sub-tasks (Txt.)#72.69$Visual Question Answering#IconQA#Sub-tasks (Blank)#79.27$Visual Question Answering#IconQA#Reasoning (Geo.)#82.61$Visual Question Answering#IconQA#Reasoning (Cou.)#71.13$Visual Question Answering#IconQA#Reasoning (Com.)#84.95$Visual Question Answering#IconQA#Reasoning (Spa.)#53.38$Visual Question Answering#IconQA#Reasoning (Sce.)#66.72$Visual Question Answering#IconQA#Reasoning (Pat.)#59.22$Visual Question Answering#IconQA#Reasoning (Tim.)#69.99$Visual Question Answering#IconQA#Reasoning (Fra.)#75.81$Visual Question Answering#IconQA#Reasoning (Est.)#99.02$Visual Question Answering#IconQA#Reasoning (Alg.)#50.55$Visual Question Answering#IconQA#Reasoning (Mea.)#98.91$Visual Question Answering#IconQA#Reasoning (Sen.)#86.10$Visual Question Answering#IconQA#Reasoning (Pro.)#87.65$Visual Question Answering#IconQA#Sub-tasks (Img.)#79.15$Visual Question Answering#IconQA#Sub-tasks (Txt.)#72.34$Visual Question Answering#IconQA#Sub-tasks (Blank)#78.92$Visual Question Answering#IconQA#Reasoning (Geo.)#82.60$Visual Question Answering#IconQA#Reasoning (Cou.)#70.84$Visual Question Answering#IconQA#Reasoning (Com.)#82.12$Visual Question Answering#IconQA#Reasoning (Spa.)#54.64$Visual Question Answering#IconQA#Reasoning (Sce.)#68.80$Visual Question Answering#IconQA#Reasoning (Pat.)#58.46$Visual Question Answering#IconQA#Reasoning (Tim.)#68.66$Visual Question Answering#IconQA#Reasoning (Fra.)#77.41$Visual Question Answering#IconQA#Reasoning (Est.)#98.95$Visual Question Answering#IconQA#Reasoning (Alg.)#51.10$Visual Question Answering#IconQA#Reasoning (Mea.)#98.76$Visual Question Answering#IconQA#Reasoning (Sen.)#84.72$Visual Question Answering#IconQA#Reasoning (Pro.)#86.07$Visual Question Answering#IconQA#Sub-tasks (Img.)#78.71$Visual Question Answering#IconQA#Sub-tasks (Txt.)#72.39$Visual Question Answering#IconQA#Sub-tasks (Blank)#78.53$Visual Question Answering#IconQA#Reasoning (Geo.)#81.31$Visual Question Answering#IconQA#Reasoning (Cou.)#71.01$Visual Question Answering#IconQA#Reasoning (Com.)#83.67$Visual Question Answering#IconQA#Reasoning (Spa.)#48.34$Visual Question Answering#IconQA#Reasoning (Sce.)#61.25$Visual Question Answering#IconQA#Reasoning (Pat.)#60.81$Visual Question Answering#IconQA#Reasoning (Tim.)#69.77$Visual Question Answering#IconQA#Reasoning (Fra.)#78.37$Visual Question Answering#IconQA#Reasoning (Est.)#99.41$Visual Question Answering#IconQA#Reasoning (Alg.)#49.18$Visual Question Answering#IconQA#Reasoning (Mea.)#99.38$Visual Question Answering#IconQA#Reasoning (Pro.)#87.84$Visual Question Answering#IconQA#Sub-tasks (Img.)#77.72$Visual Question Answering#IconQA#Sub-tasks (Txt.)#72.17$Visual Question Answering#IconQA#Sub-tasks (Blank)#78.28$Visual Question Answering#IconQA#Reasoning (Geo.)#81.80$Visual Question Answering#IconQA#Reasoning (Cou.)#70.68$Visual Question Answering#IconQA#Reasoning (Com.)#81.69$Visual Question Answering#IconQA#Reasoning (Spa.)#51.42$Visual Question Answering#IconQA#Reasoning (Sce.)#67.01$Visual Question Answering#IconQA#Reasoning (Pat.)#56.60$Visual Question Answering#IconQA#Reasoning (Tim.)#67.72$Visual Question Answering#IconQA#Reasoning (Fra.)#77.60$Visual Question Answering#IconQA#Reasoning (Alg.)#50.27$Visual Question Answering#IconQA#Reasoning (Mea.)#98.83$Visual Question Answering#IconQA#Reasoning (Sen.)#84.11$Visual Question Answering#IconQA#Reasoning (Pro.)#85.70$Visual Question Answering#IconQA#Sub-tasks (Img.)#77.36$Visual Question Answering#IconQA#Sub-tasks (Txt.)#71.25$Visual Question Answering#IconQA#Sub-tasks (Blank)#74.52$Visual Question Answering#IconQA#Reasoning (Geo.)#79.86$Visual Question Answering#IconQA#Reasoning (Cou.)#68.94$Visual Question Answering#IconQA#Reasoning (Com.)#82.73$Visual Question Answering#IconQA#Reasoning (Spa.)#49.70$Visual Question Answering#IconQA#Reasoning (Sce.)#62.49$Visual Question Answering#IconQA#Reasoning (Pat.)#54.79$Visual Question Answering#IconQA#Reasoning (Tim.)#68.00$Visual Question Answering#IconQA#Reasoning (Fra.)#76.20$Visual Question Answering#IconQA#Reasoning (Est.)#99.08$Visual Question Answering#IconQA#Reasoning (Alg.)#47.32$Visual Question Answering#IconQA#Reasoning (Mea.)#98.99$Visual Question Answering#IconQA#Reasoning (Sen.)#83.25$Visual Question Answering#IconQA#Reasoning (Pro.)#84.87$Visual Question Answering#IconQA#Sub-tasks (Img.)#76.66$Visual Question Answering#IconQA#Sub-tasks (Txt.)#70.47$Visual Question Answering#IconQA#Sub-tasks (Blank)#77.08$Visual Question Answering#IconQA#Reasoning (Geo.)#80.05$Visual Question Answering#IconQA#Reasoning (Cou.)#71.05$Visual Question Answering#IconQA#Reasoning (Com.)#75.60$Visual Question Answering#IconQA#Reasoning (Spa.)#49.46$Visual Question Answering#IconQA#Reasoning (Sce.)#58.52$Visual Question Answering#IconQA#Reasoning (Pat.)#62.78$Visual Question Answering#IconQA#Reasoning (Tim.)#66.72$Visual Question Answering#IconQA#Reasoning (Fra.)#74.09$Visual Question Answering#IconQA#Reasoning (Est.)#99.22$Visual Question Answering#IconQA#Reasoning (Alg.)#50.62$Visual Question Answering#IconQA#Reasoning (Mea.)#99.07$Visual Question Answering#IconQA#Reasoning (Sen.)#81.78$Visual Question Answering#IconQA#Reasoning (Pro.)#70.94$Visual Question Answering#IconQA#Sub-tasks (Img.)#76.33$Visual Question Answering#IconQA#Sub-tasks (Txt.)#70.82$Visual Question Answering#IconQA#Sub-tasks (Blank)#75.54$Visual Question Answering#IconQA#Reasoning (Geo.)#79.99$Visual Question Answering#IconQA#Reasoning (Cou.)#67.56$Visual Question Answering#IconQA#Reasoning (Spa.)#53.20$Visual Question Answering#IconQA#Reasoning (Sce.)#66.92$Visual Question Answering#IconQA#Reasoning (Pat.)#55.67$Visual Question Answering#IconQA#Reasoning (Tim.)#66.50$Visual Question Answering#IconQA#Reasoning (Fra.)#73.77$Visual Question Answering#IconQA#Reasoning (Est.)#97.06$Visual Question Answering#IconQA#Reasoning (Alg.)#47.46$Visual Question Answering#IconQA#Reasoning (Mea.)#96.50$Visual Question Answering#IconQA#Reasoning (Sen.)#82.12$Visual Question Answering#IconQA#Reasoning (Pro.)#82.45$Visual Question Answering#IconQA#Sub-tasks (Img.)#75.92$Visual Question Answering#IconQA#Sub-tasks (Txt.)#68.51$Visual Question Answering#IconQA#Sub-tasks (Blank)#73.03$Visual Question Answering#IconQA#Reasoning (Geo.)#80.07$Visual Question Answering#IconQA#Reasoning (Cou.)#65.01$Visual Question Answering#IconQA#Reasoning (Com.)#80.65$Visual Question Answering#IconQA#Reasoning (Spa.)#45.78$Visual Question Answering#IconQA#Reasoning (Sce.)#58.22$Visual Question Answering#IconQA#Reasoning (Pat.)#55.01$Visual Question Answering#IconQA#Reasoning (Tim.)#68.28$Visual Question Answering#IconQA#Reasoning (Fra.)#72.43$Visual Question Answering#IconQA#Reasoning (Est.)#99.54$Visual Question Answering#IconQA#Reasoning (Alg.)#50.00$Visual Question Answering#IconQA#Reasoning (Mea.)#99.46$Visual Question Answering#IconQA#Reasoning (Sen.)#84.54$Visual Question Answering#IconQA#Reasoning (Pro.)#83.75$Visual Question Answering#IconQA#Sub-tasks (Img.)#41.70$Visual Question Answering#IconQA#Sub-tasks (Txt.)#36.87$Visual Question Answering#IconQA#Sub-tasks (Blank)#0.29$Visual Question Answering#IconQA#Reasoning (Geo.)#30.30$Visual Question Answering#IconQA#Reasoning (Cou.)#18.38$Visual Question Answering#IconQA#Reasoning (Com.)#41.20$Visual Question Answering#IconQA#Reasoning (Spa.)#36.49$Visual Question Answering#IconQA#Reasoning (Sce.)#34.25$Visual Question Answering#IconQA#Reasoning (Pat.)#34.81$Visual Question Answering#IconQA#Reasoning (Tim.)#35.82$Visual Question Answering#IconQA#Reasoning (Fra.)#34.84$Visual Question Answering#IconQA#Reasoning (Est.)#3.62$Visual Question Answering#IconQA#Reasoning (Alg.)#11.12$Visual Question Answering#IconQA#Reasoning (Mea.)#0.36$Visual Question Answering#IconQA#Reasoning (Sen.)#45.16$Visual Question Answering#IconQA#Reasoning (Pro.)#38.81$Visual Question Answering#IconQA#Sub-tasks (Img.)#41.64$Visual Question Answering#IconQA#Sub-tasks (Txt.)#36.86$Visual Question Answering#IconQA#Sub-tasks (Blank)#28.45$Visual Question Answering#IconQA#Reasoning (Geo.)#38.03$Visual Question Answering#IconQA#Reasoning (Cou.)#33.63$Visual Question Answering#IconQA#Reasoning (Com.)#48.19$Visual Question Answering#IconQA#Reasoning (Spa.)#37.14$Visual Question Answering#IconQA#Reasoning (Sce.)#35.37$Visual Question Answering#IconQA#Reasoning (Pat.)#33.66$Visual Question Answering#IconQA#Reasoning (Tim.)#48.09$Visual Question Answering#IconQA#Reasoning (Fra.)#33.06$Visual Question Answering#IconQA#Reasoning (Est.)#40.46$Visual Question Answering#IconQA#Reasoning (Alg.)#28.02$Visual Question Answering#IconQA#Reasoning (Mea.)#38.07$Visual Question Answering#IconQA#Reasoning (Sen.)#45.25$Visual Question Answering#IconQA#Reasoning (Pro.)#40.76$Visual Question Answering#IconQA#Sub-tasks (Img.)#41.56$Visual Question Answering#IconQA#Sub-tasks (Txt.)#36.02$Visual Question Answering#IconQA#Sub-tasks (Blank)#46.65$Visual Question Answering#IconQA#Reasoning (Geo.)#38.71$Visual Question Answering#IconQA#Reasoning (Cou.)#37.64$Visual Question Answering#IconQA#Reasoning (Com.)#45.26$Visual Question Answering#IconQA#Reasoning (Spa.)#37.52$Visual Question Answering#IconQA#Reasoning (Sce.)#35.47$Visual Question Answering#IconQA#Reasoning (Pat.)#36.29$Visual Question Answering#IconQA#Reasoning (Tim.)#47.37$Visual Question Answering#IconQA#Reasoning (Fra.)#32.48$Visual Question Answering#IconQA#Reasoning (Est.)#62.29$Visual Question Answering#IconQA#Reasoning (Alg.)#31.73$Visual Question Answering#IconQA#Reasoning (Mea.)#64.02$Visual Question Answering#IconQA#Reasoning (Pro.)#37.51
2206.05281v1.pdf	Visual Question Answering#VizWiz 2020 Answerability#average_precision#84.13$Visual Question Answering#VizWiz 2020 Answerability#average_precision#82.86$Visual Question Answering#VizWiz 2020 VQA#overall#61.64$Visual Question Answering#VizWiz 2020 VQA#overall#60.66
2202.02317v2.pdf	Visual Question Answering#A-OKVQA#MC Accuracy#53.7$Visual Question Answering#A-OKVQA#DA VQA Score#40.7$Visual Question Answering#GRIT#VQA (ablation)#63.5$Visual Question Answering#GRIT#VQA (test)#63.2$Object Localization#GRIT#Localization (ablation)#53.6$Object Localization#GRIT#Localization (test)#53.6$Object Categorization#GRIT#Categorization (ablation)#54.7$Object Categorization#GRIT#Categorization (test)#55.1
2012.11014v1.pdf	Visual Question Answering#A-OKVQA#MC Accuracy#42.2$Visual Question Answering#A-OKVQA#DA VQA Score#42.2
1908.02265v1.pdf	Visual Question Answering#A-OKVQA#MC Accuracy#42.1$Visual Question Answering#A-OKVQA#DA VQA Score#12.0$Visual Question Answering#A-OKVQA#MC Accuracy#41.5$Visual Question Answering#A-OKVQA#DA VQA Score#25.9$Visual Question Answering#A-OKVQA#MC Accuracy#34.1$Visual Question Answering#A-OKVQA#DA VQA Score#92$Visual Question Answering#VQA v2 test-dev#Accuracy#70.55
1908.07490v3.pdf	Visual Question Answering#A-OKVQA#MC Accuracy#41.6$Visual Question Answering#A-OKVQA#DA VQA Score#25.9$Visual Question Answering#GQA test-std#Accuracy#60.3$Visual Question Answering#GQA test-dev#Accuracy#60.0$Visual Question Answering#VizWiz 2018#overall#55.4$Visual Question Answering#VizWiz 2018#yes/no#74.0$Visual Question Answering#VizWiz 2018#number#24.76$Visual Question Answering#VizWiz 2018#other#39.0$Visual Question Answering#VizWiz 2018#unanswerable#82.26$Visual Question Answering#GQA Test2019#Accuracy#62.71$Visual Question Answering#GQA Test2019#Binary#79.79$Visual Question Answering#GQA Test2019#Open#47.64$Visual Question Answering#GQA Test2019#Consistency#93.1$Visual Question Answering#GQA Test2019#Plausibility#85.21$Visual Question Answering#GQA Test2019#Validity#96.36$Visual Question Answering#GQA Test2019#Distribution#6.42$Visual Question Answering#GQA Test2019#Accuracy#60.33$Visual Question Answering#GQA Test2019#Binary#77.16$Visual Question Answering#GQA Test2019#Open#45.47$Visual Question Answering#GQA Test2019#Consistency#89.59$Visual Question Answering#GQA Test2019#Plausibility#84.53$Visual Question Answering#GQA Test2019#Validity#96.35$Visual Question Answering#GQA Test2019#Distribution#5.69$Visual Question Answering#VQA v2 test-dev#Accuracy#69.9$Visual Question Answering#VQA v2 test-std#overall#72.5$Visual Reasoning#NLVR2 Dev#Accuracy#74.9$Visual Reasoning#NLVR2 Test#Accuracy#76.2
1807.09956v2.pdf	Visual Question Answering#A-OKVQA#MC Accuracy#40.1$Visual Question Answering#A-OKVQA#DA VQA Score#21.9
2206.08916v2.pdf	Visual Question Answering#GRIT#VQA (ablation)#74.5$Visual Question Answering#GRIT#VQA (test)#74.5$Object Localization#GRIT#Localization (ablation)#67.0$Object Localization#GRIT#Localization (test)#67.1$Object Segmentation#GRIT#Segmentation (ablation)#56.3$Object Segmentation#GRIT#Segmentation (test)#56.5$Object Categorization#GRIT#Categorization (ablation)#61.7$Object Categorization#GRIT#Categorization (test)#60.8
2202.03052v2.pdf	Visual Question Answering#GRIT#VQA (ablation)#72.4$Visual Question Answering#VQA v2 test-dev#Accuracy#82.0$Visual Question Answering#VQA v2 test-std#overall#81.98$Visual Question Answering#VQA v2 test-std#yes/no#94.66$Visual Question Answering#VQA v2 test-std#number#71.44$Visual Question Answering#VQA v2 test-std#other#73.35$Visual Entailment#SNLI-VE test#Accuracy#91.2$Visual Entailment#SNLI-VE val#Accuracy#91.0$Image Captioning#COCO Captions#BLEU-4#44.9$Image Captioning#COCO Captions#METEOR#32.5$Image Captioning#COCO Captions#CIDER#154.9$Image Captioning#COCO Captions#SPICE#26.6$Text Summarization#GigaWord#ROUGE-1#39.81$Text Summarization#GigaWord#ROUGE-2#20.66$Text Summarization#GigaWord#ROUGE-L#37.11$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#473M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#85.6%$Object Categorization#GRIT#Categorization (ablation)#22.6
1902.09487v1.pdf	Visual Question Answering#TDIUC#Accuracy#88.2$Visual Question Answering#VQA v2 test-dev#Accuracy#68.03$Visual Question Answering#VQA v2 test-std#overall#68.4$Visual Question Answering#VQA-CP#Score#39.54
1909.11874v1.pdf	Visual Question Answering#TDIUC#Accuracy#87$Visual Question Answering#VQA v2 test-dev#Accuracy#67.4$Visual Question Answering#Visual7W#Percentage correct#72.3
2110.00804v2.pdf	Visual Question Answering#GQA test-std#Accuracy#65.14
1907.03950v4.pdf	Visual Question Answering#GQA test-std#Accuracy#63.17$Visual Question Answering#GQA test-dev#Accuracy#62.95$Visual Question Answering#VQA-CP#Score#45.8
2104.12763v2.pdf	Visual Question Answering#GQA test-std#Accuracy#62.45$Visual Question Answering#CLEVR#Accuracy#99.7$Visual Question Answering#CLEVR-Humans#Accuracy#81.7$Phrase Grounding#Flickr30k Entities Test#R@1#84.3$Phrase Grounding#Flickr30k Entities Test#R@10#95.8$Phrase Grounding#Flickr30k Entities Test#R@5#93.9$Referring Expression Segmentation#PhraseCut#Mean IoU#53.7$Referring Expression Segmentation#PhraseCut#Pr@0.5#57.5$Referring Expression Segmentation#PhraseCut#Pr@0.7#39.9$Referring Expression Segmentation#PhraseCut#Pr@0.9#11.9
1905.04405v2.pdf	Visual Question Answering#GQA test-std#Accuracy#56.1$Visual Question Answering#CLEVR#Accuracy#97.9$Visual Question Answering#GQA test-dev#Accuracy#55.8
1902.09506v3.pdf	Visual Question Answering#GQA test-std#Accuracy#54.06$Visual Question Answering#GQA test-std#Accuracy#46.55
1810.02338v2.pdf	Visual Question Answering#CLEVR#Accuracy#99.8$Visual Question Answering#CLEVR-Humans#Accuracy#67.8
2011.11603v2.pdf	Visual Question Answering#CLEVR#Accuracy#99.4
1803.05268v2.pdf	Visual Question Answering#CLEVR#Accuracy#99.1
1904.12584v1.pdf	Visual Question Answering#CLEVR#Accuracy#98.9
1803.03067v2.pdf	Visual Question Answering#CLEVR#Accuracy#98.9$Visual Question Answering#CLEVR-Humans#Accuracy#81.5
1808.00300v1.pdf	Visual Question Answering#CLEVR#Accuracy#98.8$Visual Question Answering#VQA-CP#Score#28.65
1803.11361v1.pdf	Visual Question Answering#CLEVR#Accuracy#98.3
1709.07871v2.pdf	Visual Question Answering#CLEVR#Accuracy#97.7$Visual Question Answering#CLEVR-Humans#Accuracy#75.9$Image Retrieval with Multi-Modal Query#MIT-States#Recall@1#10.1$Image Retrieval with Multi-Modal Query#MIT-States#Recall@5#27.7$Image Retrieval with Multi-Modal Query#MIT-States#Recall@10#38.3
1812.01855v2.pdf	Visual Question Answering#CLEVR#Accuracy#97.7
1705.03633v1.pdf	Visual Question Answering#CLEVR#Accuracy#96.9$Visual Question Answering#CLEVR-Humans#Accuracy#66.6
1706.01427v1.pdf	Visual Question Answering#CLEVR#Accuracy#95.50$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#13$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#40.5$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#62.4
1808.02632v1.pdf	Visual Question Answering#CLEVR#Accuracy#65.90$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#65.90
2110.02526v2.pdf	Visual Question Answering#GQA test-dev#Accuracy#72.1$Visual Question Answering#VQA v2 test-dev#Accuracy#72.5$Visual Question Answering#Visual7W#Percentage correct#71.9
2208.00934v1.pdf	Visual Question Answering#MSVD-QA#Accuracy#.486$Visual Question Answering#MSRVTT-QA#Accuracy#.457$Video Question Answering#iVQA#Accuracy#.382
2107.04768v1.pdf	Visual Question Answering#MSVD-QA#Accuracy#0.390$Visual Question Answering#MSRVTT-QA#Accuracy#0.355
2002.10698v3.pdf	Visual Question Answering#MSVD-QA#Accuracy#0.361$Visual Question Answering#MSRVTT-QA#Accuracy#0.356$Video Question Answering#SUTD-TrafficQA#1/4#36.49$Video Question Answering#SUTD-TrafficQA#1/2#63.79
1904.04357v1.pdf	Visual Question Answering#MSVD-QA#Accuracy#0.337$Visual Question Answering#MSRVTT-QA#Accuracy#0.33
1803.10906v1.pdf	Visual Question Answering#MSVD-QA#Accuracy#0.317$Visual Question Answering#MSRVTT-QA#Accuracy#0.32
1704.04497v3.pdf	Visual Question Answering#MSVD-QA#Accuracy#0.313$Visual Question Answering#MSRVTT-QA#Accuracy#0.309
1904.08920v2.pdf	Visual Question Answering#VizWiz 2018#overall#54.72$Visual Question Answering#VQA v2 test-dev#Accuracy#69.21
1909.02097v1.pdf	Visual Question Answering#VizWiz 2018#overall#53.68$Visual Question Answering#VizWiz 2018#yes/no#68.12$Visual Question Answering#VizWiz 2018#number#28.81$Visual Question Answering#VizWiz 2018#other#35.41$Visual Question Answering#VizWiz 2018#unanswerable#84.03
1704.03162v2.pdf	Visual Question Answering#VQA v1 test-dev#Accuracy#64.5$Visual Question Answering#VQA v1 test-std#Accuracy#64.6
1611.00471v2.pdf	Visual Question Answering#VQA v1 test-dev#Accuracy#64.3$Image Retrieval#Flickr30K 1K test#R@1#39.4$Image Retrieval#Flickr30K 1K test#R@10#79.1$Image Retrieval#Flickr30K 1K test#R@5#69.2
1603.01417v1.pdf	Visual Question Answering#VQA v1 test-dev#Accuracy#60.3$Visual Question Answering#VQA v1 test-std#Accuracy#60.4$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#60.4
1511.02799v4.pdf	Visual Question Answering#VQA v1 test-dev#Accuracy#58.6$Visual Question Answering#VQA v1 test-std#Accuracy#58.7
2107.05348v4.pdf	Visual Question Answering#ZS-F-VQA#Hit@1#29.39
1612.00837v3.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 2.0 open ended#Percentage correct#62.27$Visual Question Answering#COCO Visual Question Answering (VQA) real images 2.0 open ended#Percentage correct#54.22$Visual Question Answering#VQA v2 test-std#overall#62.27$Visual Question Answering#VQA v2 test-std#overall#44.26$Visual Question Answering#VQA v2 test-std#overall#25.98
1909.00997v3.pdf	Visual Question Answering#PlotQA-D1#1:1 Accuracy#53.96$Visual Question Answering#PlotQA-D2#1:1 Accuracy#22.52
1511.02274v2.pdf	Visual Question Answering#VQA v1 test-std#Accuracy#58.9$Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#58.9
2006.16934v3.pdf	Visual Question Answering#VCR (Q-AR) test#Accuracy#70.5$Visual Question Answering#VQA v2 test-std#overall#74.93$Visual Question Answering#VQA v2 test-std#yes/no#90.83$Visual Question Answering#VQA v2 test-std#number#56.79$Visual Question Answering#VQA v2 test-std#other#65.24$Visual Question Answering#VCR (QA-R) test#Accuracy#86.1$Visual Question Answering#VCR (Q-A) test#Accuracy#81.6
1909.11740v3.pdf	Visual Question Answering#VCR (Q-AR) test#Accuracy#62.8$Visual Question Answering#VQA v2 test-dev#Accuracy#73.24$Visual Question Answering#VQA v2 test-std#overall#73.4$Visual Question Answering#VCR (QA-R) test#Accuracy#83.4$Visual Question Answering#VCR (QA-R) test#Accuracy#80.8$Visual Question Answering#VCR (Q-A) test#Accuracy#79.8$Visual Question Answering#VCR (Q-A) test#Accuracy#77.3$Visual Reasoning#NLVR2 Test#Accuracy#79.5$Visual Entailment#SNLI-VE test#Accuracy#78.98$Visual Entailment#SNLI-VE val#Accuracy#78.98
2012.07000v1.pdf	Visual Question Answering#VCR (Q-AR) test#Accuracy#60.3$Visual Question Answering#VCR (QA-R) test#Accuracy#78.6$Visual Question Answering#VCR (Q-A) test#Accuracy#76.4
2102.02779v2.pdf	Visual Question Answering#VCR (Q-AR) test#Accuracy#58.9$Visual Question Answering#VCR (QA-R) test#Accuracy#77.8$Visual Question Answering#VCR (Q-A) test#Accuracy#75.3$Image Captioning#Flickr30k Captions test#CIDEr#2.6$Image Captioning#Flickr30k Captions test#SPICE#2.0$Image Captioning#nocaps val#CIDEr#4.4$Image Captioning#nocaps val#SPICE#5.3
2101.00529v2.pdf	Visual Question Answering#GQA Test2019#Accuracy#64.65$Visual Question Answering#GQA Test2019#Binary#82.63$Visual Question Answering#GQA Test2019#Open#48.77$Visual Question Answering#GQA Test2019#Consistency#94.35$Visual Question Answering#GQA Test2019#Plausibility#84.98$Visual Question Answering#GQA Test2019#Validity#96.62$Visual Question Answering#GQA Test2019#Distribution#4.72$Visual Question Answering#VQA v2 test-std#overall#77.45$Visual Question Answering#VQA v2 test-std#yes/no#92.38$Visual Question Answering#VQA v2 test-std#number#62.55$Visual Question Answering#VQA v2 test-std#other#67.87$Visual Question Answering#VQA v2 test-std#overall#76.63$Visual Question Answering#VQA v2 test-std#yes/no#92.04$Visual Question Answering#VQA v2 test-std#number#61.5$Visual Question Answering#VQA v2 test-std#other#66.68$Image Captioning#COCO Captions#BLEU-4#41.0$Image Captioning#COCO Captions#METEOR#31.1$Image Captioning#COCO Captions#CIDER#140.9$Image Captioning#COCO Captions#SPICE#25.2$Image Captioning#nocaps entire#CIDEr#92.46$Image Captioning#nocaps entire#B1#81.59$Image Captioning#nocaps entire#B2#65.15$Image Captioning#nocaps entire#B3#45.04$Image Captioning#nocaps entire#B4#26.15$Image Captioning#nocaps entire#ROUGE-L#56.96$Image Captioning#nocaps entire#METEOR#27.57$Image Captioning#nocaps entire#SPICE#13.07$Image Captioning#nocaps near-domain#CIDEr#95.16$Image Captioning#nocaps near-domain#B1#82.77$Image Captioning#nocaps near-domain#B2#66.94$Image Captioning#nocaps near-domain#B3#47.02$Image Captioning#nocaps near-domain#B4#27.97$Image Captioning#nocaps near-domain#ROUGE-L#57.95$Image Captioning#nocaps near-domain#METEOR#28.24$Image Captioning#nocaps near-domain#SPICE#13.36$Image Captioning#nocaps in-domain#CIDEr#97.99$Image Captioning#nocaps in-domain#B1#83.24$Image Captioning#nocaps in-domain#B2#68.04$Image Captioning#nocaps in-domain#B3#49.68$Image Captioning#nocaps in-domain#B4#30.62$Image Captioning#nocaps in-domain#ROUGE-L#58.54$Image Captioning#nocaps in-domain#METEOR#29.51$Image Captioning#nocaps in-domain#SPICE#13.63$Image Captioning#nocaps-val-out-domain#CIDEr#88.3$Image Captioning#nocaps-val-out-domain#SPICE#12.1$Image Captioning#nocaps-val-out-domain#Pretrain (#images)#5.7M$Image Captioning#nocaps-val-overall#CIDEr#95.5$Image Captioning#nocaps-val-overall#SPICE#13.5$Image Captioning#nocaps-val-overall#Pretrain (#images)#5.7M$Image Captioning#nocaps out-of-domain#CIDEr#78.01$Image Captioning#nocaps out-of-domain#B1#75.78$Image Captioning#nocaps out-of-domain#B2#56.1$Image Captioning#nocaps out-of-domain#B3#34.02$Image Captioning#nocaps out-of-domain#B4#15.86$Image Captioning#nocaps out-of-domain#ROUGE-L#51.99$Image Captioning#nocaps out-of-domain#METEOR#23.55$Image Captioning#nocaps out-of-domain#SPICE#11.48$Image Captioning#nocaps-val-in-domain#CIDEr#103.1$Image Captioning#nocaps-val-in-domain#SPICE#14.2$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#5.7M$Image Captioning#nocaps-val-near-domain#CIDEr#96.1$Image Captioning#nocaps-val-near-domain#SPICE#13.8$Image Captioning#nocaps-val-near-domain#Pre-train (#images)#5.7M
1907.09815v2.pdf	Visual Question Answering#GQA Test2019#Accuracy#61.22$Visual Question Answering#GQA Test2019#Binary#78.69$Visual Question Answering#GQA Test2019#Open#45.81$Visual Question Answering#GQA Test2019#Consistency#90.31$Visual Question Answering#GQA Test2019#Plausibility#85.43$Visual Question Answering#GQA Test2019#Validity#96.36$Visual Question Answering#GQA Test2019#Distribution#6.77$Visual Question Answering#VQA v2 test-std#overall#75.92$Visual Question Answering#VQA v2 test-std#yes/no#90.89$Visual Question Answering#VQA v2 test-std#number#61.13$Visual Question Answering#VQA v2 test-std#other#66.28
1707.07998v3.pdf	Visual Question Answering#GQA Test2019#Accuracy#49.74$Visual Question Answering#GQA Test2019#Binary#66.64$Visual Question Answering#GQA Test2019#Open#34.83$Visual Question Answering#GQA Test2019#Consistency#78.71$Visual Question Answering#GQA Test2019#Plausibility#84.57$Visual Question Answering#GQA Test2019#Validity#96.18$Visual Question Answering#GQA Test2019#Distribution#5.98$Visual Question Answering#VQA v2 test-std#overall#70.34
2208.10442v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#84.19$Visual Question Answering#VQA v2 test-std#overall#84.03$Visual Reasoning#NLVR2 Dev#Accuracy#91.51$Visual Reasoning#NLVR2 Test#Accuracy#92.58$Semantic Segmentation#ADE20K#Validation mIoU#62.8$Semantic Segmentation#ADE20K val#mIoU#62.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#84.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#98.3$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#96.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#67.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#92.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#87.7$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#98.0$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#100.0$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#100.0$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#90.3$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#99.5$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#98.7$Object Detection#COCO test-dev#box AP#63.7$Instance Segmentation#COCO test-dev#mask AP#54.8
2111.02358v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#82.78$Visual Question Answering#VQA v2 test-std#overall#81.30$Visual Question Answering#VQA v2 test-std#yes/no#94.68$Visual Question Answering#VQA v2 test-std#number#67.26$Visual Question Answering#VQA v2 test-std#other#72.87$Visual Reasoning#NLVR2 Dev#Accuracy#85.64$Visual Reasoning#NLVR2 Test#Accuracy#86.86
2205.12005v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#82.43$Image Captioning#COCO Captions#BLEU-4#46.5$Image Captioning#COCO Captions#METEOR#32.0$Image Captioning#COCO Captions#CIDER#155.1$Image Captioning#COCO Captions#SPICE#26.0
2111.08896v3.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#81.26
2108.10904v3.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#80.03$Visual Question Answering#VQA v2 test-std#overall#80.34$Visual Reasoning#NLVR2 Dev#Accuracy#84.53$Visual Reasoning#NLVR2 Test#Accuracy#85.15$Visual Entailment#SNLI-VE test#Accuracy#86.32$Visual Entailment#SNLI-VE val#Accuracy#86.21$Image Captioning#COCO Captions#BLEU-4#40.6$Image Captioning#COCO Captions#METEOR#33.4$Image Captioning#COCO Captions#CIDER#143.3$Image Captioning#COCO Captions#SPICE#25.4$Image Captioning#nocaps entire#CIDEr#110.31$Image Captioning#nocaps entire#B1#83.78$Image Captioning#nocaps entire#B2#68.86$Image Captioning#nocaps entire#B3#51.06$Image Captioning#nocaps entire#B4#32.2$Image Captioning#nocaps entire#ROUGE-L#59.86$Image Captioning#nocaps entire#METEOR#30.55$Image Captioning#nocaps entire#SPICE#14.49$Image Captioning#nocaps near-domain#CIDEr#110.76$Image Captioning#nocaps near-domain#B1#84.36$Image Captioning#nocaps near-domain#B2#69.83$Image Captioning#nocaps near-domain#B3#52.42$Image Captioning#nocaps near-domain#B4#33.74$Image Captioning#nocaps near-domain#ROUGE-L#60.46$Image Captioning#nocaps near-domain#METEOR#30.97$Image Captioning#nocaps near-domain#SPICE#14.61$Image Captioning#nocaps in-domain#CIDEr#108.98$Image Captioning#nocaps in-domain#B1#84.64$Image Captioning#nocaps in-domain#B2#70.0$Image Captioning#nocaps in-domain#B3#52.96$Image Captioning#nocaps in-domain#B4#34.66$Image Captioning#nocaps in-domain#ROUGE-L#61.01$Image Captioning#nocaps in-domain#METEOR#31.97$Image Captioning#nocaps in-domain#SPICE#14.6$Image Captioning#nocaps-val-out-domain#CIDEr#115.2$Image Captioning#nocaps-val-out-domain#SPICE#-$Image Captioning#nocaps-val-out-domain#Pretrain (#images)#1.8B$Image Captioning#nocaps-val-overall#CIDEr#112.2$Image Captioning#nocaps-val-overall#SPICE#-$Image Captioning#nocaps-val-overall#Pretrain (#images)#1.8B$Image Captioning#nocaps out-of-domain#CIDEr#109.49$Image Captioning#nocaps out-of-domain#B1#80.89$Image Captioning#nocaps out-of-domain#B2#64.21$Image Captioning#nocaps out-of-domain#B3#44.38$Image Captioning#nocaps out-of-domain#B4#24.47$Image Captioning#nocaps out-of-domain#ROUGE-L#56.69$Image Captioning#nocaps out-of-domain#METEOR#27.91$Image Captioning#nocaps out-of-domain#SPICE#13.89$Image Captioning#nocaps-val-in-domain#CIDEr#113.7$Image Captioning#nocaps-val-in-domain#SPICE#-$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#1.8B$Image Captioning#nocaps-val-near-domain#CIDEr#110.9$Image Captioning#nocaps-val-near-domain#SPICE#-$Image Captioning#nocaps-val-near-domain#Pre-train (#images)#1.8B
2111.08276v3.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#78.22$Visual Reasoning#NLVR2 Dev#Accuracy#84.41$Visual Reasoning#NLVR2 Test#Accuracy#84.76$Image Captioning#COCO Captions#BLEU-4#41.3$Image Captioning#COCO Captions#CIDER#140.8$Image Retrieval#Flickr30K 1K test#R@1#86.9$Image Retrieval#Flickr30K 1K test#R@10#98.7$Image Retrieval#Flickr30K 1K test#R@5#97.3$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#81.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#98.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#95.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#63.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#91.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#85.8$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#97.1$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#100.0$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#100.0$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#86.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#98.7$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#97.3$Visual Grounding#RefCOCO+ testA#Accuracy (%)#89.00$Visual Grounding#RefCOCO+ test B#Accuracy (%)#76.91$Visual Grounding#RefCOCO+ val#Accuracy (%)#84.51
2107.07651v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#75.84$Visual Question Answering#VQA v2 test-std#overall#76.04$Visual Reasoning#NLVR2 Dev#Accuracy#83.14$Visual Reasoning#NLVR2 Test#Accuracy#82.55$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#77.6$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#97.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#94.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#60.7$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#90.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#84.3
2004.06165v5.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#73.82$Image Captioning#COCO Captions#BLEU-4#41.7$Image Captioning#COCO Captions#METEOR#30.6$Image Captioning#COCO Captions#CIDER#140$Image Captioning#COCO Captions#SPICE#24.5$Text-Image Retrieval#COCO#Recall@10#99.8$Text-Image Retrieval#COCO (image as query)#Recall@10#98.3$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#73.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#96.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#92.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#57.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#89.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#82.8
2001.03615v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#72.59$Visual Question Answering#VQA v2 test-std#overall#74.16$Visual Question Answering#VQA v2 test-std#yes/no#89.18$Visual Question Answering#VQA v2 test-std#number#58.01$Visual Question Answering#VQA v2 test-std#other#64.77$Visual Question Answering#VQA v2 test-std#overall#72.71
2102.03334v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#71.26$Visual Reasoning#NLVR2 Dev#Accuracy#75.7$Visual Reasoning#NLVR2 Test#Accuracy#76.13$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#61.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#92.7$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#86.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#42.7$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#83.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#72.9$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#83.5$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#98.6$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#96.7$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#64.4$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#93.8$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#88.7
2002.12204v3.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#71.21$Visual Question Answering#VQA v2 test-std#overall#71.49$Image Captioning#COCO Captions#BLEU-4#39.5$Image Captioning#COCO Captions#METEOR#29.3$Image Captioning#COCO Captions#ROUGE-L#59.3$Image Captioning#COCO Captions#CIDEr-D#131.6
1906.10770v1.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#70.63$Visual Question Answering#VQA v2 test-std#overall#70.9
1805.07932v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#70.04$Visual Question Answering#VQA v2 test-std#overall#70.4$Phrase Grounding#Flickr30k Entities Test#R@1#69.69$Phrase Grounding#Flickr30k Entities Test#R@10#86.35$Phrase Grounding#Flickr30k Entities Test#R@5#84.22
1708.02711v1.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#69.87$Visual Question Answering#VQA v2 test-std#overall#70.3
1802.05766v1.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#68.09$Visual Question Answering#VQA v2 test-std#overall#68.4
1902.00038v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#67.58$Visual Question Answering#VQA v2 test-std#overall#67.9$Visual Relationship Detection#VRD Relationship Detection#R@100#20.96$Visual Relationship Detection#VRD Relationship Detection#R@50#19.06$Visual Relationship Detection#VRD Phrase Detection#R@100#28.96$Visual Relationship Detection#VRD Phrase Detection#R@50#26.32$Visual Relationship Detection#VRD Predicate Detection#R@100#92.58$Visual Relationship Detection#VRD Predicate Detection#R@50#86.58
1705.06676v1.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#67.42$Visual Question Answering#VQA v2 test-std#overall#67.4
2006.07214v3.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#65.96$Visual Question Answering#VQA v2 test-std#overall#66.27
1906.10169v2.pdf	Visual Question Answering#VQA v2 test-dev#Accuracy#63.18$Visual Question Answering#VQA-CP#Score#47.11
2208.02532v1.pdf	Visual Question Answering#VQA v2 test-std#overall#78.53$Visual Entailment#SNLI-VE test#Accuracy#90.12$Visual Entailment#SNLI-VE val#Accuracy#90.04$Image Captioning#COCO Captions#BLEU-4#41.81$Image Captioning#COCO Captions#METEOR#31.51$Image Captioning#COCO Captions#CIDER#141.4$Image Captioning#COCO Captions#SPICE#24.42
2004.12070v2.pdf	Visual Question Answering#VQA v2 test-std#overall#73.86$Visual Question Answering#VQA v2 test-std#yes/no#89.46$Visual Question Answering#VQA v2 test-std#number#58.62$Visual Question Answering#VQA v2 test-std#other#63.78
1909.11059v3.pdf	Visual Question Answering#VQA v2 test-std#overall#70.7$Image Captioning#Flickr30k Captions test#BLEU-4#30.1$Image Captioning#Flickr30k Captions test#CIDEr#67.4$Image Captioning#Flickr30k Captions test#METEOR#23$Image Captioning#Flickr30k Captions test#SPICE#17$Image Captioning#COCO Captions test#BLEU-4#36.5$Image Captioning#COCO Captions test#CIDEr#116.9$Image Captioning#COCO Captions test#METEOR#28.4$Image Captioning#COCO Captions test#SPICE#21.2
1906.00513v3.pdf	Visual Question Answering#VQA v2 test-std#overall#69.7
2205.03075v1.pdf	Visual Question Answering#QLEVR#Overall Accuracy#66.5$Visual Question Answering#QLEVR#Overall Accuracy#65.9$Visual Question Answering#QLEVR#Overall Accuracy#65.8$Visual Question Answering#QLEVR#Overall Accuracy#64.6$Visual Question Answering#QLEVR#Overall Accuracy#50.0
2102.06183v1.pdf	Visual Question Answering#MSRVTT-QA#Accuracy#0.374
2204.10496v2.pdf	Visual Question Answering#VCR (Q-A) test#Accuracy#79.6$Visual Entailment#SNLI-VE test#Accuracy#80.32
2003.06576v1.pdf	Visual Question Answering#VQA-CP#Score#58.95
2107.12651v4.pdf	Visual Question Answering#VQA-CP#Score#57.32
2010.10802v1.pdf	Visual Question Answering#VQA-CP#Score#56.74$Visual Question Answering#VQA-CP#Score#54.55
1909.03683v1.pdf	Visual Question Answering#VQA-CP#Score#52.05
1905.09998v3.pdf	Visual Question Answering#VQA-CP#Score#49.45
2104.03149v3.pdf	Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#34.41$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#34.36$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#34.27$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#34.26$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#33.91$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#33.26$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#33.14$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#32.91$Visual Question Answering#VQA-CE#Accuracy (Counterexamples)#32.25
1603.02814v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#59.5
1511.05234v2.pdf	Visual Question Answering#COCO Visual Question Answering (VQA) real images 1.0 open ended#Percentage correct#58.2
2103.14517v2.pdf	Video Question Answering#KnowIT VQA#Accuracy#78.1
1906.02467v1.pdf	Video Question Answering#ActivityNet-QA#Accuracy#0.318$Video Question Answering#ActivityNet-QA#Accuracy#0.271$Video Question Answering#ActivityNet-QA#Accuracy#0.251
2207.05342v3.pdf	Video Question Answering#NExT-QA#Accuracy#56.89
2206.01720v1.pdf	Video Question Answering#NExT-QA#Accuracy#54.3
2209.06650v1.pdf	Video Question Answering#WildQA#ROUGE-1#34.0 ± 0.5$Video Question Answering#WildQA#ROUGE-2#18.8 ± 0.7$Video Question Answering#WildQA#ROUGE-L#32.8 ± 0.6$Video Question Answering#WildQA#ROUGE-1#33.8 ± 0.8$Video Question Answering#WildQA#ROUGE-2#18.5 ± 0.7$Video Question Answering#WildQA#ROUGE-L#32.5 ± 0.8$Video Question Answering#WildQA#ROUGE-1#33.8 ± 0.2$Video Question Answering#WildQA#ROUGE-2#17.7 ± 0.1$Video Question Answering#WildQA#ROUGE-L#32.4 ± 0.3$Video Question Answering#WildQA#ROUGE-1#33.1 ± 0.3$Video Question Answering#WildQA#ROUGE-2#17.3 ± 0.4$Video Question Answering#WildQA#ROUGE-L#31.9 ± 0.2$Video Question Answering#WildQA#ROUGE-1#0.8 ± 0.0$Video Question Answering#WildQA#ROUGE-2#0.0 ± 0.0$Video Question Answering#WildQA#ROUGE-L#0.8 ± 0.0
2103.15538v3.pdf	Video Question Answering#SUTD-TrafficQA#1/4#37.05$Video Question Answering#SUTD-TrafficQA#1/2#64.77
1809.01696v2.pdf	Video Question Answering#SUTD-TrafficQA#1/4#35.16$Video Question Answering#SUTD-TrafficQA#1/2#63.15
1505.02074v4.pdf	Video Question Answering#SUTD-TrafficQA#1/4#29.91$Video Question Answering#SUTD-TrafficQA#1/2#54.25
2011.07735v1.pdf	Video Question Answering#TVQA#Accuracy#76.96$Dense Video Captioning#ActivityNet Captions#METEOR#7.87$Dense Video Captioning#ActivityNet Captions#BLEU-3#2.93$Dense Video Captioning#ActivityNet Captions#BLEU-4#1.29
1904.11574v2.pdf	Video Question Answering#TVQA#Accuracy#70.50
2203.12616v2.pdf	Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>3 Days)#71.4%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>3 Days)#70.3%
1907.08322v2.pdf	Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>3 Days)#69.5%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>7 Days)#92.3%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>3 Days)#68.6%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>7 Days)#91.9%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>3 Days)#68.3%$Length-of-Stay prediction#MIMIC-III#Accuracy (LOS>7 Days)#91.2%
2102.04110v1.pdf	Length-of-Stay prediction#Clinical Admission Notes from MIMIC-III#AUROC#72.53$Length-of-Stay prediction#Clinical Admission Notes from MIMIC-III#AUROC#71.59$Length-of-Stay prediction#Clinical Admission Notes from MIMIC-III#AUROC#70.40$Medical Diagnosis#Clinical Admission Notes from MIMIC-III#AUROC#83.54$Medical Diagnosis#Clinical Admission Notes from MIMIC-III#AUROC#82.81$Medical Diagnosis#Clinical Admission Notes from MIMIC-III#AUROC#82.08$Mortality Prediction#Clinical Admission Notes from MIMIC-III#AUROC#84.04$Mortality Prediction#Clinical Admission Notes from MIMIC-III#AUROC#82.55$Mortality Prediction#Clinical Admission Notes from MIMIC-III#AUROC#81.13$Medical Procedure#Clinical Admission Notes from MIMIC-III#AUROC#88.37$Medical Procedure#Clinical Admission Notes from MIMIC-III#AUROC#86.36$Medical Procedure#Clinical Admission Notes from MIMIC-III#AUROC#85.84
2111.08536v4.pdf	Remaining Length of Stay#HiRID#MAE#56.9±0.4$Remaining Length of Stay#HiRID#MAE#57.0±0.3$Remaining Length of Stay#HiRID#MAE#59.5±2.8$Remaining Length of Stay#HiRID#MAE#59.8±2.8$Remaining Length of Stay#HiRID#MAE#60.6±0.9$Remaining Length of Stay#HiRID#MAE#60.7±1.6$ICU Mortality#HiRID#AUPRC#0.626±0.000$ICU Mortality#HiRID#AUPRC#0.610±0.008$ICU Mortality#HiRID#AUPRC#0.603 ±0.016$ICU Mortality#HiRID#AUPRC#0.602±0.011$ICU Mortality#HiRID#AUPRC#0.600±0.009$ICU Mortality#HiRID#AUPRC#0.581±0.000$ICU Mortality#HiRID#AUPRC#0.546±0.008$Patient Phenotyping#HiRID#Balanced Accuracy#45.8±2.0$Patient Phenotyping#HiRID#Balanced Accuracy#42.7±1.4$Patient Phenotyping#HiRID#Balanced Accuracy#41.6±2.3$Patient Phenotyping#HiRID#Balanced Accuracy#40.4±0.8$Patient Phenotyping#HiRID#Balanced Accuracy#39.5±1.2$Patient Phenotyping#HiRID#Balanced Accuracy#39.2±2.1$Patient Phenotyping#HiRID#Balanced Accuracy#39.1±0.0$Circulatory Failure#HiRID#AUPRC#0.389±0.003$Circulatory Failure#HiRID#AUPRC#0.388±0.002$Circulatory Failure#HiRID#AUPRC#0.368±0.005$Circulatory Failure#HiRID#AUPRC#0.352±0.006$Circulatory Failure#HiRID#AUPRC#0.305±0.000$Circulatory Failure#HiRID#AUPRC#0.32.2±0.008$Circulatory Failure#HiRID#AUPRC#0.35.8±0.006$Kidney Function#HiRID#MAE#0.45±0.00$Kidney Function#HiRID#MAE#0.48±0.02$Kidney Function#HiRID#MAE#0.49±0.02$Kidney Function#HiRID#MAE#0.50±0.01$Respiratory Failure#HiRID#AUPRC#0.604±0.002$Respiratory Failure#HiRID#AUPRC#0.594±0.003$Respiratory Failure#HiRID#AUPRC#0.592±0.003$Respiratory Failure#HiRID#AUPRC#0.589±0.003$Respiratory Failure#HiRID#AUPRC#0.585±0.001$Respiratory Failure#HiRID#AUPRC#0.569±0.003$Respiratory Failure#HiRID#AUPRC#0.530±0.000
1801.04503v2.pdf	Time Series Classification#NetFlow#Accuracy#0.95$Time Series Classification#DigitShapes#Accuracy#1$Time Series Classification#LP3#Accuracy#0.73$Time Series Classification#pendigits#Accuracy#0.97$Time Series Classification#KickvsPunch#Accuracy#1$Time Series Classification#Wafer#Accuracy#0.99$Time Series Classification#LP1#Accuracy#0.82$Time Series Classification#WalkvsRun#Accuracy#1$Time Series Classification#UWave#Accuracy#0.98$Time Series Classification#AUSLAN#Accuracy#0.96$Time Series Classification#SHAPES#Accuracy#1$Time Series Classification#CharacterTrajectories#Accuracy#1$Time Series Classification#ECG#Accuracy#0.86$Time Series Classification#LP2#Accuracy#0.77$Time Series Classification#Libras#Accuracy#0.97$Time Series Classification#ArabicDigits#Accuracy#0.99$Time Series Classification#JapaneseVowels#Accuracy#0.99$Time Series Classification#LP5#Accuracy#0.67$Time Series Classification#CMUsubject16#Accuracy#1$Time Series Classification#LP4#Accuracy#0.93
1906.08215v2.pdf	Time Series Classification#NetFlow#Accuracy#0.945$Time Series Classification#NetFlow#NLL#0.168$Time Series Classification#NetFlow#Accuracy#0.937$Time Series Classification#NetFlow#NLL#0.189$Time Series Classification#NetFlow#Accuracy#0.931$Time Series Classification#NetFlow#NLL#0.218$Time Series Classification#NetFlow#Accuracy#0.928$Time Series Classification#NetFlow#NLL#0.251$Time Series Classification#NetFlow#Accuracy#0.926$Time Series Classification#NetFlow#NLL#0.194$Time Series Classification#NetFlow#Accuracy#0.921$Time Series Classification#NetFlow#NLL#0.259$Time Series Classification#PenDigits#Accuracy#0.955$Time Series Classification#PenDigits#NLL#0.146$Time Series Classification#PenDigits#Accuracy#0.953$Time Series Classification#PenDigits#NLL#0.185$Time Series Classification#PenDigits#Accuracy#0.951$Time Series Classification#PenDigits#NLL#0.187$Time Series Classification#PenDigits#Accuracy#0.946$Time Series Classification#PenDigits#NLL#0.181$Time Series Classification#PenDigits#Accuracy#0.928$Time Series Classification#PenDigits#NLL#0.289$Time Series Classification#PenDigits#Accuracy#0.902$Time Series Classification#PenDigits#NLL#0.399$Time Series Classification#DigitShapes#Accuracy#1.000$Time Series Classification#DigitShapes#NLL#0.008$Time Series Classification#DigitShapes#NLL#0.013$Time Series Classification#DigitShapes#NLL#0.021$Time Series Classification#DigitShapes#NLL#0.035$Time Series Classification#DigitShapes#Accuracy#0.812$Time Series Classification#DigitShapes#NLL#0.727$Time Series Classification#KickvsPunch#Accuracy#0.900$Time Series Classification#KickvsPunch#NLL#0.224$Time Series Classification#KickvsPunch#NLL#0.301$Time Series Classification#KickvsPunch#Accuracy#0.820$Time Series Classification#KickvsPunch#NLL#0.493$Time Series Classification#KickvsPunch#Accuracy#0.700$Time Series Classification#KickvsPunch#NLL#0.662$Time Series Classification#KickvsPunch#Accuracy#0.620$Time Series Classification#KickvsPunch#NLL#0.696$Time Series Classification#KickvsPunch#Accuracy#0.600$Time Series Classification#KickvsPunch#NLL#0.674$Time Series Classification#Wafer#Accuracy#0.994$Time Series Classification#Wafer#NLL#0.029$Time Series Classification#Wafer#Accuracy#0.988$Time Series Classification#Wafer#NLL#0.048$Time Series Classification#Wafer#Accuracy#0.984$Time Series Classification#Wafer#NLL#0.085$Time Series Classification#Wafer#Accuracy#0.978$Time Series Classification#Wafer#NLL#0.081$Time Series Classification#Wafer#Accuracy#0.966$Time Series Classification#Wafer#NLL#0.105$Time Series Classification#Wafer#Accuracy#0.965$Time Series Classification#WalkvsRun#Accuracy#1.000$Time Series Classification#WalkvsRun#NLL#0.023$Time Series Classification#WalkvsRun#NLL#0.028$Time Series Classification#WalkvsRun#NLL#0.030$Time Series Classification#WalkvsRun#NLL#0.048$Time Series Classification#WalkvsRun#NLL#0.066$Time Series Classification#UWave#Accuracy#0.970$Time Series Classification#UWave#NLL#0.113$Time Series Classification#UWave#Accuracy#0.968$Time Series Classification#UWave#NLL#0.121$Time Series Classification#UWave#Accuracy#0.964$Time Series Classification#UWave#NLL#0.140$Time Series Classification#UWave#Accuracy#0.947$Time Series Classification#UWave#NLL#0.189$Time Series Classification#UWave#Accuracy#0.870$Time Series Classification#UWave#NLL#0.745$Time Series Classification#UWave#Accuracy#0.763$Time Series Classification#UWave#NLL#1.168$Time Series Classification#AUSLAN#Accuracy#0.983$Time Series Classification#AUSLAN#NLL#0.106$Time Series Classification#AUSLAN#Accuracy#0.978$Time Series Classification#AUSLAN#NLL#0.123$Time Series Classification#AUSLAN#Accuracy#0.949$Time Series Classification#AUSLAN#NLL#0.248$Time Series Classification#AUSLAN#Accuracy#0.925$Time Series Classification#AUSLAN#NLL#0.550$Time Series Classification#AUSLAN#Accuracy#0.880$Time Series Classification#AUSLAN#NLL#0.650$Time Series Classification#AUSLAN#Accuracy#0.784$Time Series Classification#AUSLAN#NLL#1.900$Time Series Classification#SHAPES#Accuracy#1.000$Time Series Classification#SHAPES#NLL#0.011$Time Series Classification#SHAPES#NLL#0.012$Time Series Classification#SHAPES#NLL#0.014$Time Series Classification#SHAPES#NLL#0.016$Time Series Classification#SHAPES#Accuracy#0.867$Time Series Classification#SHAPES#NLL#0.168$Time Series Classification#CharacterTrajectories#Accuracy#0.991$Time Series Classification#CharacterTrajectories#NLL#0.031$Time Series Classification#CharacterTrajectories#Accuracy#0.979$Time Series Classification#CharacterTrajectories#NLL#0.108$Time Series Classification#CharacterTrajectories#Accuracy#0.941$Time Series Classification#CharacterTrajectories#NLL#0.409$Time Series Classification#CharacterTrajectories#Accuracy#0.925$Time Series Classification#CharacterTrajectories#NLL#0.258$Time Series Classification#CharacterTrajectories#Accuracy#0.233$Time Series Classification#CharacterTrajectories#NLL#2.506$Time Series Classification#CharacterTrajectories#Accuracy#0.114$Time Series Classification#CharacterTrajectories#NLL#3.523$Time Series Classification#ECG#Accuracy#0.848$Time Series Classification#ECG#NLL#0.356$Time Series Classification#ECG#Accuracy#0.832$Time Series Classification#ECG#NLL#0.431$Time Series Classification#ECG#Accuracy#0.816$Time Series Classification#ECG#NLL#0.402$Time Series Classification#ECG#Accuracy#0.782$Time Series Classification#ECG#NLL#0.496$Time Series Classification#ECG#Accuracy#0.760$Time Series Classification#ECG#NLL#0.543$Time Series Classification#ECG#Accuracy#0.734$Time Series Classification#ECG#NLL#0.601$Time Series Classification#Libras#Accuracy#0.923$Time Series Classification#Libras#NLL#0.259$Time Series Classification#Libras#Accuracy#0.921$Time Series Classification#Libras#NLL#0.320$Time Series Classification#Libras#Accuracy#0.899$Time Series Classification#Libras#NLL#0.346$Time Series Classification#Libras#Accuracy#0.776$Time Series Classification#Libras#NLL#0.911$Time Series Classification#Libras#Accuracy#0.742$Time Series Classification#Libras#NLL#1.110$Time Series Classification#Libras#Accuracy#0.698$Time Series Classification#Libras#NLL#1.608$Time Series Classification#ArabicDigits#Accuracy#0.994$Time Series Classification#ArabicDigits#NLL#0.023$Time Series Classification#ArabicDigits#Accuracy#0.992$Time Series Classification#ArabicDigits#NLL#0.047$Time Series Classification#ArabicDigits#Accuracy#0.986$Time Series Classification#ArabicDigits#NLL#0.066$Time Series Classification#ArabicDigits#Accuracy#0.985$Time Series Classification#ArabicDigits#NLL#0.082$Time Series Classification#ArabicDigits#Accuracy#0.984$Time Series Classification#ArabicDigits#NLL#0.050$Time Series Classification#ArabicDigits#Accuracy#0.979$Time Series Classification#ArabicDigits#NLL#0.071$Time Series Classification#PEMS#Accuracy#0.820$Time Series Classification#PEMS#NLL#0.520$Time Series Classification#PEMS#Accuracy#0.794$Time Series Classification#PEMS#NLL#0.537$Time Series Classification#PEMS#Accuracy#0.775$Time Series Classification#PEMS#NLL#1.100$Time Series Classification#PEMS#Accuracy#0.769$Time Series Classification#PEMS#NLL#0.784$Time Series Classification#PEMS#Accuracy#0.763$Time Series Classification#PEMS#NLL#0.704$Time Series Classification#PEMS#Accuracy#0.745$Time Series Classification#PEMS#NLL#1.194$Time Series Classification#JapaneseVowels#Accuracy#0.986$Time Series Classification#JapaneseVowels#NLL#0.052$Time Series Classification#JapaneseVowels#NLL#0.067$Time Series Classification#JapaneseVowels#Accuracy#0.985$Time Series Classification#JapaneseVowels#NLL#0.053$Time Series Classification#JapaneseVowels#Accuracy#0.982$Time Series Classification#JapaneseVowels#NLL#0.061$Time Series Classification#JapaneseVowels#NLL#0.069$Time Series Classification#JapaneseVowels#Accuracy#0.981$Time Series Classification#JapaneseVowels#NLL#0.080$Time Series Classification#CMUsubject16#Accuracy#1.000$Time Series Classification#CMUsubject16#NLL#0.040$Time Series Classification#CMUsubject16#NLL#0.088$Time Series Classification#CMUsubject16#Accuracy#0.993$Time Series Classification#CMUsubject16#NLL#0.089$Time Series Classification#CMUsubject16#Accuracy#0.979$Time Series Classification#CMUsubject16#Accuracy#0.924$Time Series Classification#CMUsubject16#NLL#0.270$Time Series Classification#CMUsubject16#Accuracy#0.897$Time Series Classification#CMUsubject16#NLL#0.255
1909.12064v3.pdf	Time Series Classification#PhysioNet Challenge 2012#AUC#86.99%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.22%$Time Series Classification#PhysioNet Challenge 2012#AUC#86.28%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.35%$Time Series Classification#PhysioNet Challenge 2012#AUC#86.24%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.38%$Time Series Classification#PhysioNet Challenge 2012#AUC#85.14%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.13%$Time Series Classification#PhysioNet Challenge 2012#AUC#81.69%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.43%$Time Series Classification#PhysioNet Challenge 2012#AUC#79.94%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#1.17%
1909.07782v1.pdf	Time Series Classification#PhysioNet Challenge 2012#AUC#86.42%$Time Series Classification#PhysioNet Challenge 2012#AUC Stdev#0.18%
2101.10318v2.pdf	Time Series Classification#PhysioNet Challenge 2012#AUC#85.8%$Time Series Classification#PhysioNet Challenge 2012#AUC#85.4%
2107.14293v2.pdf	Time Series Classification#PhysioNet Challenge 2012#AUC#83.90%
2007.00586v3.pdf	Time Series Classification#s2-agri#mIoU#51.7$Time Series Classification#s2-agri#oAcc#94.3
1911.07757v1.pdf	Time Series Classification#s2-agri#mIoU#50.9$Time Series Classification#s2-agri#oAcc#94.2
2106.09296v3.pdf	Time Series Classification#Earthquakes#Accuracy (Test)#78.42$Time Series Classification#FordA#Acc. (test)#100$ECG Classification#UCR Time Series Classification Archive#Accuracy (Test)#93.96
1711.11343v4.pdf	Time Series Classification#AATLD Gesture Recognition#Absolute Time (ms)#133656
1805.03473v2.pdf	Time Series Classification#Physionet 2017 Atrial Fibrillation#AUC#0.732
1607.00148v2.pdf	Time Series Classification#Physionet 2017 Atrial Fibrillation#AUC#0.719$Outlier Detection#ECG5000#Accuracy#0.934
2110.04744v2.pdf	Time Series Classification#EigenWorms#% Test Accuracy#92.3$Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#60.5$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.5%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#96.6%
2103.05487v2.pdf	Time Series Classification#EigenWorms#% Test Accuracy#90.3$Time Series Classification#EigenWorms#% Test Accuracy#86.7$Time Series Classification#EigenWorms#% Test Accuracy#49.7$Time Series Classification#EigenWorms#% Test Accuracy#40.0$Sentiment Analysis#IMDb#Accuracy#88.4$Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#62.4%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.4%
2009.08295v4.pdf	Time Series Classification#EigenWorms#% Test Accuracy#83.8
2010.00567v1.pdf	Time Series Classification#FordA#mean average precision#97%$Time Series Classification#FordA#F1 score#97%
1910.04963v2.pdf	Human Interaction Recognition#NTU RGB+D 120#Accuracy (Cross-Subject)#77.7$Human Interaction Recognition#NTU RGB+D 120#Accuracy (Cross-Setup)#79.6$Human Interaction Recognition#UT-Interaction#Accuracy (Set 1)#98.3$Human Interaction Recognition#UT-Interaction#Accuracy (Set 2)#96.7$Human Interaction Recognition#NTU RGB+D#Accuracy (Cross-Subject)#90.5$Human Interaction Recognition#NTU RGB+D#Accuracy (Cross-View)#93.5$Human Interaction Recognition#SBU#Accuracy#98.2
1811.00270v1.pdf	Human Interaction Recognition#UT#Accuracy#98.33$Human Interaction Recognition#BIT#Accuracy#94.03$Group Activity Recognition#Volleyball#Accuracy#88.4$Group Activity Recognition#Collective Activity#Accuracy#83.75
1706.00931v1.pdf	Human Interaction Recognition#UT#Accuracy#95.00$Human Interaction Recognition#BIT#Accuracy#92.88
1411.4389v4.pdf	Human Interaction Recognition#UT#Accuracy#85.00$Human Interaction Recognition#BIT#Accuracy#80.13
2012.13823v2.pdf	One-Shot 3D Action Recognition#NTU RGB+D 120#Accuracy#54.2%
2004.11085v4.pdf	One-Shot 3D Action Recognition#NTU RGB+D 120#Accuracy#49.6%
2102.08997v4.pdf	One-Shot 3D Action Recognition#NTU RGB+D 120#Accuracy#46.5%
1905.04757v2.pdf	One-Shot 3D Action Recognition#NTU RGB+D 120#Accuracy#45.3%
2105.15189v1.pdf	Time Series Prediction#Data Collected with Package Delivery Quadcopter Drone#Average mean absolute error#9.06
2103.14250v2.pdf	Time Series Prediction#Sunspot#RMSE#00
2106.09305v3.pdf	Time Series Forecasting#PeMSD4#12 Steps MAE#19.02$Time Series Forecasting#ETTh1 (336)#MSE#0.087$Time Series Forecasting#ETTh1 (336)#MAE#0.231$Time Series Forecasting#ETTh1 (336)#MSE#0.491$Time Series Forecasting#ETTh1 (336)#MAE#0.494$Time Series Forecasting#PeMSD7#12 Steps MAE#21.59$Time Series Forecasting#ETTh2 (720)#MSE#0.249$Time Series Forecasting#ETTh2 (720)#MAE#0.399$Time Series Forecasting#ETTh2 (720)#MSE#1.074$Time Series Forecasting#ETTh2 (720)#MAE#0.761$Time Series Forecasting#ETTh1 (168)#MSE#0.075$Time Series Forecasting#ETTh1 (168)#MAE#0.215$Time Series Forecasting#ETTh1 (168)#MSE#0.497$Time Series Forecasting#ETTh1 (168)#MAE#0.491$Time Series Forecasting#ETTh2 (48)#MSE#0.089$Time Series Forecasting#ETTh2 (48)#MAE#0.227$Time Series Forecasting#ETTh2 (48)#MSE#0.259$Time Series Forecasting#ETTh2 (48)#MAE#0.341$Time Series Forecasting#ETTh1 (720)#MSE#0.156$Time Series Forecasting#ETTh1 (720)#MAE#0.316$Time Series Forecasting#ETTh1 (720)#MSE#0.612$Time Series Forecasting#ETTh1 (720)#MAE#0.582$Time Series Forecasting#ETTh1 (48)#MAE#0.171$Time Series Forecasting#ETTh1 (48)#MSE#0.364$Time Series Forecasting#ETTh1 (48)#MAE#0.388$Time Series Forecasting#ETTh2 (168)#MSE#0.156$Time Series Forecasting#ETTh2 (168)#MAE#0.312$Time Series Forecasting#ETTh2 (168)#MSE#0.528$Time Series Forecasting#ETTh2 (168)#MAE#0.509$Time Series Forecasting#ETTh1 (24)#MSE#0.028$Time Series Forecasting#ETTh1 (24)#MAE#0.128$Time Series Forecasting#ETTh1 (24)#MSE#0.311$Time Series Forecasting#ETTh1 (24)#MAE#0.348$Time Series Forecasting#ETTh2 (336)#MSE#0.173$Time Series Forecasting#ETTh2 (336)#MAE#0.338$Time Series Forecasting#ETTh2 (336)#MSE#0.648$Time Series Forecasting#ETTh2 (336)#MAE#0.608$Time Series Forecasting#ETTh2 (24)#MSE#0.068$Time Series Forecasting#ETTh2 (24)#MAE#0.189$Time Series Forecasting#ETTh2 (24)#MSE#0.183$Time Series Forecasting#ETTh2 (24)#MAE#0.271$Univariate Time Series Forecasting#Solar-Power#RRSE#0.1609$Univariate Time Series Forecasting#Solar-Power#RRSE#0.2194$Univariate Time Series Forecasting#Solar-Power#RRSE#0.2878$Univariate Time Series Forecasting#Solar-Power#RRSE#0.4032$Univariate Time Series Forecasting#Electricity#RRSE#0.0678$Univariate Time Series Forecasting#Electricity#RRSE#0.0818$Univariate Time Series Forecasting#Electricity#RRSE#0.0926$Univariate Time Series Forecasting#Electricity#RRSE#0.0957$Traffic Prediction#PeMS04#12 Steps MAE#19.02
2205.13504v3.pdf	Time Series Forecasting#ETTh1 (336)#MSE#0.081$Time Series Forecasting#ETTh1 (336)#MAE#0.226$Time Series Forecasting#ETTh1 (336)#MSE#0.098$Time Series Forecasting#ETTh1 (336)#MAE#0.244$Time Series Forecasting#ETTh2 (720)#MSE#0.224$Time Series Forecasting#ETTh2 (720)#MAE#0.380$Time Series Forecasting#ETTh2 (720)#MSE#0.276$Time Series Forecasting#ETTh2 (720)#MAE#0.426$Time Series Forecasting#ETTh1 (168)#MSE#0.066$Time Series Forecasting#ETTh1 (168)#MAE#0.199$Time Series Forecasting#ETTh2 (48)#MSE#0.096$Time Series Forecasting#ETTh2 (48)#MAE#0.235$Time Series Forecasting#ETTh1 (720)#MSE#0.080$Time Series Forecasting#ETTh1 (720)#MAE#0.226$Time Series Forecasting#ETTh1 (720)#MAE#0.274$Time Series Forecasting#ETTh1 (720)#MSE#0.440$Time Series Forecasting#ETTh1 (720)#MAE#0.453$Time Series Forecasting#ETTh1 (48)#MSE#0.045$Time Series Forecasting#ETTh1 (48)#MAE#0.150$Time Series Forecasting#ETTh1 (24)#MSE#0.028$Time Series Forecasting#ETTh1 (24)#MAE#0.123$Time Series Forecasting#ETTh2 (336)#MSE#0.209$Time Series Forecasting#ETTh2 (336)#MAE#0.367$Time Series Forecasting#ETTh2 (24)#MSE#0.066$Time Series Forecasting#ETTh2 (24)#MAE#0.193
2205.08897v4.pdf	Time Series Forecasting#ETTh1 (336)#MSE#0.083$Time Series Forecasting#ETTh1 (336)#MAE#0.229$Time Series Forecasting#ETTh1 (336)#MSE#0.442$Time Series Forecasting#ETTh1 (336)#MAE#0.445$Time Series Forecasting#ETTh2 (720)#MSE#0.241$Time Series Forecasting#ETTh2 (720)#MAE#0.396$Time Series Forecasting#ETTh2 (720)#MSE#0.439$Time Series Forecasting#ETTh2 (720)#MAE#0.456$Time Series Forecasting#ETTh1 (720)#MSE#0.09$Time Series Forecasting#ETTh1 (720)#MAE#0.240$Time Series Forecasting#ETTh1 (720)#MSE#0.465$Time Series Forecasting#ETTh1 (720)#MAE#0.472$Time Series Forecasting#ETTh2 (336)#MSE#0.204$Time Series Forecasting#ETTh2 (336)#MAE#0.367$Time Series Forecasting#ETTh2 (336)#MSE#0.377$Time Series Forecasting#ETTh2 (336)#MAE#0.417
2107.08687v2.pdf	Time Series Forecasting#ETTh1 (336)#MSE#0.1267$Time Series Forecasting#ETTh1 (336)#MAE#0.2844$Time Series Forecasting#ETTh1 (336)#MSE#0.1541$Time Series Forecasting#ETTh1 (336)#MAE#0.3201$Time Series Forecasting#ETTh2 (720)#MSE#0.2585$Time Series Forecasting#ETTh2 (720)#MAE#0.4130$Time Series Forecasting#ETTh2 (720)#MSE#0.2853$Time Series Forecasting#ETTh2 (720)#MAE#0.4340$Time Series Forecasting#ETTh1 (168)#MSE#0.0935$Time Series Forecasting#ETTh1 (168)#MAE#0.2371$Time Series Forecasting#ETTh1 (168)#MSE#0.1049$Time Series Forecasting#ETTh1 (168)#MAE#0.2539$Time Series Forecasting#ETTh2 (48)#MSE#0.1117$Time Series Forecasting#ETTh2 (48)#MAE#0.2622$Time Series Forecasting#ETTh2 (48)#MSE#0.1218$Time Series Forecasting#ETTh2 (48)#MAE#0.2763$Time Series Forecasting#ETTh1 (720)#MSE#0.2136$Time Series Forecasting#ETTh1 (720)#MAE#0.3730$Time Series Forecasting#ETTh1 (720)#MSE#0.2501$Time Series Forecasting#ETTh1 (720)#MAE#0.4213$Time Series Forecasting#ETTh1 (48)#MSE#0.0740$Time Series Forecasting#ETTh1 (48)#MAE#0.2118$Time Series Forecasting#ETTh1 (48)#MAE#0.2144$Time Series Forecasting#ETTh2 (168)#MSE#0.1753$Time Series Forecasting#ETTh2 (168)#MAE#0.3322$Time Series Forecasting#ETTh2 (168)#MSE#0.1974$Time Series Forecasting#ETTh2 (168)#MAE#0.3547$Time Series Forecasting#ETTh1 (24)#MSE#0.0436$Time Series Forecasting#ETTh1 (24)#MAE#0.1616$Time Series Forecasting#ETTh1 (24)#MSE#0.0548$Time Series Forecasting#ETTh1 (24)#MAE#0.1830$Time Series Forecasting#ETTh2 (336)#MSE#0.2088$Time Series Forecasting#ETTh2 (336)#MAE#0.3710$Time Series Forecasting#ETTh2 (336)#MSE#0.2191$Time Series Forecasting#ETTh2 (336)#MAE#0.3805$Time Series Forecasting#ETTh2 (24)#MSE#0.0843$Time Series Forecasting#ETTh2 (24)#MAE#0.2239$Time Series Forecasting#ETTh2 (24)#MSE#0.0999$Time Series Forecasting#ETTh2 (24)#MAE#0.2479$Multivariate Time Series Forecasting#BPI challenge '12#Accuracy#0.79$Multivariate Time Series Forecasting#Helpdesk#Accuracy#0.743
2110.08255v2.pdf	Time Series Forecasting#ETTh1 (336)#MSE#0.195$Time Series Forecasting#ETTh1 (336)#MAE#0.365$Time Series Forecasting#ETTh2 (720)#MSE#0.211$Time Series Forecasting#ETTh2 (720)#MAE#0.382$Time Series Forecasting#ETTh1 (168)#MSE#0.111$Time Series Forecasting#ETTh1 (168)#MAE#0.268$Time Series Forecasting#ETTh2 (48)#MSE#0.172$Time Series Forecasting#ETTh2 (48)#MAE#0.334$Time Series Forecasting#ETTh1 (720)#MSE#0.226$Time Series Forecasting#ETTh1 (720)#MAE#0.394$Time Series Forecasting#ETTh1 (48)#MSE#0.139$Time Series Forecasting#ETTh1 (48)#MAE#0.308$Time Series Forecasting#ETTh2 (168)#MSE#0.174$Time Series Forecasting#ETTh2 (168)#MAE#0.337$Time Series Forecasting#ETTh1 (24)#MSE#0.082$Time Series Forecasting#ETTh1 (24)#MAE#0.230$Time Series Forecasting#ETTh2 (336)#MSE#0.224$Time Series Forecasting#ETTh2 (336)#MAE#0.391$Time Series Forecasting#ETTh2 (24)#MSE#0.082$Time Series Forecasting#ETTh2 (24)#MAE#0.221
2012.07436v3.pdf	Time Series Forecasting#ETTh1 (336)#MSE#0.222$Time Series Forecasting#ETTh1 (336)#MAE#0.387$Time Series Forecasting#ETTh1 (336)#MSE#0.468$Time Series Forecasting#ETTh1 (336)#MAE#0.593$Time Series Forecasting#ETTh2 (720)#MSE#0.277$Time Series Forecasting#ETTh2 (720)#MAE#0.431$Time Series Forecasting#ETTh2 (720)#MSE#2.878$Time Series Forecasting#ETTh2 (720)#MAE#1.044$Time Series Forecasting#ETTh1 (168)#MSE#0.183$Time Series Forecasting#ETTh1 (168)#MAE#0.346$Time Series Forecasting#ETTh1 (168)#MSE#0.396$Time Series Forecasting#ETTh1 (168)#MAE#0.504$Time Series Forecasting#ETTh2 (48)#MSE#0.155$Time Series Forecasting#ETTh2 (48)#MAE#0.314$Time Series Forecasting#ETTh2 (48)#MSE#3.190$Time Series Forecasting#ETTh2 (48)#MAE#0.474$Time Series Forecasting#ETTh1 (720)#MSE#0.269$Time Series Forecasting#ETTh1 (720)#MAE#0.435$Time Series Forecasting#ETTh1 (720)#MSE#0.659$Time Series Forecasting#ETTh1 (720)#MAE#0.766$Time Series Forecasting#ETTh1 (48)#MSE#0.158$Time Series Forecasting#ETTh1 (48)#MAE#0.319$Time Series Forecasting#ETTh1 (48)#MSE#0.175$Time Series Forecasting#ETTh1 (48)#MAE#0.424$Time Series Forecasting#ETTh2 (168)#MSE#0.232$Time Series Forecasting#ETTh2 (168)#MAE#0.389$Time Series Forecasting#ETTh2 (168)#MSE#2.800$Time Series Forecasting#ETTh2 (168)#MAE#0.595$Time Series Forecasting#ETTh1 (24)#MSE#0.098$Time Series Forecasting#ETTh1 (24)#MAE#0.247$Time Series Forecasting#ETTh1 (24)#MSE#0.108$Time Series Forecasting#ETTh1 (24)#MAE#0.284$Time Series Forecasting#ETTh2 (336)#MSE#0.263$Time Series Forecasting#ETTh2 (336)#MAE#0.417$Time Series Forecasting#ETTh2 (336)#MSE#2.753$Time Series Forecasting#ETTh2 (336)#MAE#0.738$Time Series Forecasting#ETTh2 (24)#MSE#0.093$Time Series Forecasting#ETTh2 (24)#MAE#0.240$Time Series Forecasting#ETTh2 (24)#MSE#3.554$Time Series Forecasting#ETTh2 (24)#MAE#0.455
1709.04875v4.pdf	Time Series Forecasting#PeMSD7#9 steps MAE#3.57$Time Series Forecasting#PeMSD7#9 steps MAE#3.79$Traffic Prediction#METR-LA#MAE @ 12 step#4.45$Traffic Prediction#PeMS-M#MAE (60 min)#4.02$Traffic Prediction#PeMS07#MAE@1h#25.38
1707.01926v3.pdf	Time Series Forecasting#PeMSD7#9 steps MAE#4.01$Traffic Prediction#METR-LA#MAE @ 12 step#3.60$Traffic Prediction#PEMS-BAY#MAE @ 12 step#2.07$Traffic Prediction#PEMS-BAY#RMSE#4.74$Traffic Prediction#PeMS-M#MAE (60 min)#3.83$Traffic Prediction#PeMS07#MAE@1h#25.30
2106.01100v5.pdf	Multivariate Time Series Forecasting#ExtMarker#MAE#0.845$Multivariate Time Series Forecasting#ExtMarker#RMSE#1.275$Multivariate Time Series Forecasting#ExtMarker#normalized RMSE#0.2824$Multivariate Time Series Forecasting#ExtMarker#Maximum error#8.81$Multivariate Time Series Forecasting#ExtMarker#Jitter#0.9672
1612.02130v2.pdf	Multivariate Time Series Forecasting#BPI challenge '12#Accuracy#0.7600$Multivariate Time Series Forecasting#Helpdesk#Accuracy#0.7123
1905.12374v2.pdf	Multivariate Time Series Forecasting#USHCN-Daily#MSE#0.43$Multivariate Time Series Forecasting#MIMIC-III#MSE#0.48$Multivariate Time Series Forecasting#MIMIC-III#NegLL#0.83
1609.09869v2.pdf	Multivariate Time Series Forecasting#USHCN-Daily#MSE#0.83$Multivariate Time Series Forecasting#MIMIC-III#MSE#0.92$Multivariate Time Series Forecasting#MIMIC-III#NegLL#1.39
1903.12549v1.pdf	Probabilistic Time Series Forecasting#Internet Traffic dataset (A5M)#CRPS#6.84e7$Probabilistic Time Series Forecasting#Internet Traffic dataset (A5M)#KLD#2.84e-11$Probabilistic Time Series Forecasting#Lorenz dataset#CRPS#1.511$Probabilistic Time Series Forecasting#Lorenz dataset#KLD#1.67e-2$Probabilistic Time Series Forecasting#Mackey-Glass dataset#CRPS#1.91e-4$Probabilistic Time Series Forecasting#Mackey-Glass dataset#KLD#3.18e-3
1703.07015v3.pdf	Univariate Time Series Forecasting#Solar-Power#RRSE#0.4643$Univariate Time Series Forecasting#Electricity#RRSE#0.0864$Univariate Time Series Forecasting#Electricity#RRSE#0.0931$Univariate Time Series Forecasting#Electricity#RRSE#0.1007
2005.11650v1.pdf	Univariate Time Series Forecasting#Electricity#RRSE#0.0745$Univariate Time Series Forecasting#Electricity#RRSE#0.0878$Univariate Time Series Forecasting#Electricity#RRSE#0.0916$Univariate Time Series Forecasting#Electricity#RRSE#0.0953
1809.04206v3.pdf	Univariate Time Series Forecasting#Electricity#RRSE#0.0823$Univariate Time Series Forecasting#Electricity#RRSE#0.0916$Univariate Time Series Forecasting#Electricity#RRSE#0.0964$Univariate Time Series Forecasting#Electricity#RRSE#0.1006
2207.11001v1.pdf	New Product Sales Forecasting#VISUELLE#MAE#28.62$New Product Sales Forecasting#VISUELLE#WAPE#52.39
2204.04014v2.pdf	New Product Sales Forecasting#VISUELLE#MAE#28.75$New Product Sales Forecasting#VISUELLE#WAPE#52.63
2109.09824v5.pdf	New Product Sales Forecasting#VISUELLE#MAE#29.6$New Product Sales Forecasting#VISUELLE#WAPE#54.2$New Product Sales Forecasting#VISUELLE#MAE#30.2$New Product Sales Forecasting#VISUELLE#WAPE#55.2
2004.01547v1.pdf	Scene Understanding#ADE20K val#Mean IoU#46.3$Semantic Segmentation#ADE20K#Validation mIoU#46.27$Semantic Segmentation#ADE20K val#mIoU#46.27$Semantic Segmentation#PASCAL Context#mIoU#53.9$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.3%
2209.08844v1.pdf	Monocular Cross-View Road Scene Parsing(Road)#Kitti Odometry#mAP#88.28%$Monocular Cross-View Road Scene Parsing(Road)#Kitti Odometry#mIOU#77.15%$Monocular Cross-View Road Scene Parsing(Road)#Kitti Raw#mIoU#65.86%$Monocular Cross-View Road Scene Parsing(Road)#Kitti Raw#mAP#86.56%$Monocular Cross-View Road Scene Parsing(Road)#Argoverse#mAP#88.87%$Monocular Cross-View Road Scene Parsing(Road)#Argoverse#mIOU#76.71%$Monocular Cross-View Road Scene Parsing(Vehicle)#Argoverse#mIoU#48.04%$Monocular Cross-View Road Scene Parsing(Vehicle)#Argoverse#mAP#68.96%$Monocular Cross-View Road Scene Parsing(Vehicle)#KITTI2012#mIoU#39.44%$Monocular Cross-View Road Scene Parsing(Vehicle)#KITTI2012#mAP#58.89%
1611.06403v3.pdf	Outdoor Light Source Estimation#SUN360#Median Relighting Error#1.25
2207.06966v1.pdf	Scene Text Recognition#SVTP#Accuracy#95.7±0.9$Scene Text Recognition#IIIT5k#Accuracy#99.1±0.1$Scene Text Recognition#ICDAR2015#Accuracy#89.6±0.3$Scene Text Recognition#CUTE80#Accuracy#98.3±0.6$Scene Text Recognition#SVT#Accuracy#97.9±0.2$Scene Text Recognition#ICDAR2013#Accuracy#98.4±0.2
2112.12916v1.pdf	Scene Text Recognition#SVTP#Accuracy#90.6$Scene Text Recognition#IIIT5k#Accuracy#97.5$Scene Text Recognition#ICDAR2015#Accuracy#87.3$Scene Text Recognition#CUTE80#Accuracy#94.7$Scene Text Recognition#SVT#Accuracy#95.8$Scene Text Recognition#ICDAR2013#Accuracy#97.8
2111.15263v3.pdf	Scene Text Recognition#SVTP#Accuracy#90.6$Scene Text Recognition#IIIT5k#Accuracy#96.6$Scene Text Recognition#ICDAR2015#Accuracy#86.6$Scene Text Recognition#CUTE80#Accuracy#93.5$Scene Text Recognition#SVT#Accuracy#95$Scene Text Recognition#ICDAR2013#Accuracy#97.9
2111.11011v3.pdf	Scene Text Recognition#SVTP#Accuracy#89.77$Scene Text Recognition#IIIT5k#Accuracy#96.57$Scene Text Recognition#ICDAR2015#Accuracy#86.25$Scene Text Recognition#CUTE80#Accuracy#89.58$Scene Text Recognition#SVT#Accuracy#93.82$Scene Text Recognition#ICDAR2013#Accuracy#97.67
2106.06960v2.pdf	Scene Text Recognition#ICDAR2015#Accuracy#82.2$Scene Text Recognition#SVT#Accuracy#91.8$Scene Text Recognition#ICDAR2013#Accuracy#94.7
2102.10884v3.pdf	Scene Text Recognition#ICDAR2015#Accuracy#81.6$Scene Text Recognition#SVT#Accuracy#90.6$Scene Text Recognition#ICDAR 2003#Accuracy#94.8$Scene Text Recognition#ICDAR2013#Accuracy#93.2
2107.13938v1.pdf	Scene Text Recognition#ICDAR2015#Accuracy#80.2$Scene Text Recognition#SVT#Accuracy#94.7$Scene Text Recognition#ICDAR 2003#Accuracy#97.1$Scene Text Recognition#ICDAR2013#Accuracy#96.8
1912.12422v2.pdf	Scene Text Recognition#ICDAR2015#Accuracy#79.4$Scene Text Recognition#SVT#Accuracy#90.1$Scene Text Recognition#ICDAR2013#Accuracy#92.9
1910.04396v1.pdf	Scene Text Recognition#ICDAR2015#Accuracy#79.0$Scene Text Recognition#SVT#Accuracy#91.3$Scene Text Recognition#ICDAR 2003#Accuracy#96.7$Scene Text Recognition#ICDAR2013#Accuracy#94.1
2201.00132v1.pdf	Scene Text Recognition#ICDAR2015#Accuracy#77.5$Scene Text Recognition#SVT#Accuracy#88.6$Scene Text Recognition#ICDAR 2003#Accuracy#95.0$Scene Text Recognition#ICDAR2013#Accuracy#92.8
1912.10205v1.pdf	Scene Text Recognition#ICDAR2015#Accuracy#74.5$Scene Text Recognition#SVT#Accuracy#89.2$Scene Text Recognition#ICDAR 2003#Accuracy#95.0$Scene Text Recognition#ICDAR2013#Accuracy#93.9$Handwritten Text Recognition#IAM#CER#6.4$Handwritten Text Recognition#IAM#WER#19.6
1711.04226v2.pdf	Scene Text Recognition#ICDAR2015#Accuracy#73.0$Scene Text Recognition#ICDAR 2003#Accuracy#91.5
2105.08582v1.pdf	Scene Text Recognition#ICDAR2015#Accuracy#72.6$Scene Text Recognition#SVT#Accuracy#87.7$Scene Text Recognition#ICDAR 2003#Accuracy#94.3$Scene Text Recognition#ICDAR2013#Accuracy#92.4
1904.01906v4.pdf	Scene Text Recognition#ICDAR2015#Accuracy#71.8$Scene Text Recognition#SVT#Accuracy#87.5$Scene Text Recognition#ICDAR 2003#Accuracy#94.4$Scene Text Recognition#ICDAR2013#Accuracy#92.3
1804.02047v2.pdf	Scene Text Recognition#MSDA#Average Accuracy#19.02%
1809.06508v2.pdf	Scene Text Recognition#SVT#Accuracy#86.4$Scene Text Recognition#ICDAR2013#Accuracy#91.5
1603.03915v2.pdf	Scene Text Recognition#SVT#Accuracy#81.9$Scene Text Recognition#ICDAR 2003#Accuracy#90.1$Scene Text Recognition#ICDAR2013#Accuracy#88.6
1406.2227v4.pdf	Scene Text Recognition#SVT#Accuracy#68.0$Scene Text Recognition#ICDAR2013#Accuracy#79.5
2002.11949v3.pdf	Scene Graph Generation#Visual Genome#Recall@50#31.93$Scene Graph Generation#Visual Genome#mean Recall @20#6.9$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#20.9$Unbiased Scene Graph Generation#Visual Genome#mR@20#19.2$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#18.7$Unbiased Scene Graph Generation#Visual Genome#mR@20#17.4$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#12.4$Unbiased Scene Graph Generation#Visual Genome#mR@20#11.2$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#10.7$Unbiased Scene Graph Generation#Visual Genome#mR@20#9.9$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#7.8$Unbiased Scene Graph Generation#Visual Genome#mR@20#6.8$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#7.4$Unbiased Scene Graph Generation#Visual Genome#mR@20#9.7
2103.02221v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#31.74$Scene Graph Generation#Visual Genome#mean Recall @20#7.1
2003.12962v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#28.9
2106.08543v3.pdf	Scene Graph Generation#Visual Genome#Recall@50#28.2$Scene Graph Generation#Visual Genome#Recall@20#22.2$Scene Graph Generation#Visual Genome#Recall@100#31.4
1812.01880v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#27.9$Panoptic Scene Graph Generation#PSG Dataset#R@20#20.6$Panoptic Scene Graph Generation#PSG Dataset#mR@20#9.70
2001.04735v3.pdf	Scene Graph Generation#Visual Genome#Recall@50#27.7$Scene Graph Generation#Visual Genome#Recall@20#21.6
1903.03326v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#27.1
2107.02112v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#25.4$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#30.0$Unbiased Scene Graph Generation#Visual Genome#mR@20#22.1$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#29.1$Unbiased Scene Graph Generation#Visual Genome#mR@20#20.8$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#21.6$Unbiased Scene Graph Generation#Visual Genome#mR@20#15.8$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#17.6$Unbiased Scene Graph Generation#Visual Genome#mR@20#12.8$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#11.8$Unbiased Scene Graph Generation#Visual Genome#mR@20#8.6$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#11.7
2203.11654v2.pdf	Scene Graph Generation#Visual Genome#Recall@50#23.5$Scene Graph Generation#Visual Genome#Recall@100#27.2$Scene Graph Generation#Visual Genome#mean Recall @100#18.0$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#36.0$Unbiased Scene Graph Generation#Visual Genome#mR@20#28.9$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#21.8$Unbiased Scene Graph Generation#Visual Genome#mR@20#17.5$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#13.4$Unbiased Scene Graph Generation#Visual Genome#mR@20#10.9
1808.00191v1.pdf	Scene Graph Generation#Visual Genome#Recall@50#11.4
1707.09700v2.pdf	Scene Graph Generation#Visual Genome#Recall@50#10.72$Object Detection#Visual Genome#MAP#7.43
2203.09160v1.pdf	Scene Graph Generation#Visual Genome#mean Recall @20#11.63$Scene Graph Generation#Visual Genome#mean Recall @100#17.24
2009.07526v2.pdf	Scene Graph Generation#Visual Genome#mean Recall @20#7.9$Unbiased Scene Graph Generation#Visual Genome#mR@20#22.0$Unbiased Scene Graph Generation#Visual Genome#mR@20#20.9$Unbiased Scene Graph Generation#Visual Genome#mR@20#15.4$Unbiased Scene Graph Generation#Visual Genome#mR@20#12.1$Unbiased Scene Graph Generation#Visual Genome#mR@20#7.9$Unbiased Scene Graph Generation#Visual Genome#mR@20#7.8
1806.11538v2.pdf	Scene Graph Generation#VRD#Recall@50#18.32
1608.00187v1.pdf	Scene Graph Generation#VRD#Recall@50#18.16$Visual Relationship Detection#VRD Relationship Detection#R@100#14.70$Visual Relationship Detection#VRD Relationship Detection#R@50#13.86$Visual Relationship Detection#VRD Phrase Detection#R@100#17.03$Visual Relationship Detection#VRD Phrase Detection#R@50#16.17$Visual Relationship Detection#VRD Predicate Detection#R@100#47.87$Visual Relationship Detection#VRD Predicate Detection#R@50#47.87
2103.14898v3.pdf	Scene Graph Generation#3R-Scan#Top-5 Accuracy#0.87$Scene Graph Generation#3R-Scan#Top-5 Accuracy#0.66$Panoptic Segmentation#ScanNetV2#PQ#31.5$Panoptic Segmentation#ScanNetV2#SQ#72.9$Panoptic Segmentation#ScanNetV2#RQ#42.2$3D Object Classification#3R-Scan#Top-5 Accuracy#0.7$3D Object Classification#3R-Scan#Top-10 Accuracy#0.8$3D Object Classification#3R-Scan#Top-5 Accuracy#0.68$3D Object Classification#3R-Scan#Top-10 Accuracy#0.78
2203.11937v1.pdf	Scene Graph Generation#4D-OR#F1#0.75
2009.00893v1.pdf	Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#25.6$Unbiased Scene Graph Generation#Visual Genome#mR@20#19.3$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#25.1$Unbiased Scene Graph Generation#Visual Genome#mR@20#18.7$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#17.2$Unbiased Scene Graph Generation#Visual Genome#mR@20#12.7$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#13.1$Unbiased Scene Graph Generation#Visual Genome#mR@20#9.9$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#9.9$Unbiased Scene Graph Generation#Visual Genome#mR@20#8.1$Unbiased Scene Graph Generation#Visual Genome#ng-mR@20#9.8$Unbiased Scene Graph Generation#Visual Genome#mR@20#8.0
2203.09811v2.pdf	Unbiased Scene Graph Generation#Visual Genome#mR@20#35.6
2207.11247v1.pdf	Panoptic Scene Graph Generation#PSG Dataset#R@20#28.4$Panoptic Scene Graph Generation#PSG Dataset#mR@20#16.6$Panoptic Scene Graph Generation#PSG Dataset#R@20#18.0$Panoptic Scene Graph Generation#PSG Dataset#mR@20#14.8
1711.06640v2.pdf	Panoptic Scene Graph Generation#PSG Dataset#R@20#20.0$Panoptic Scene Graph Generation#PSG Dataset#mR@20#9.10
1701.02426v2.pdf	Panoptic Scene Graph Generation#PSG Dataset#R@20#16.5$Panoptic Scene Graph Generation#PSG Dataset#mR@20#6.52
1909.02410v3.pdf	Scene Recognition#ADE20K#Top 1 Accuracy#62.55$Scene Recognition#SUN397#Accuracy#74.04$Scene Recognition#Places365#Top 1 Accuracy#56.51$Scene Recognition#Places365#Top 5 Accuracy#86.00$Scene Recognition#MIT Indoor Scenes#Accuracy#87.10
2004.12349v2.pdf	Scene Recognition#SUN-RGBD#Accuracy (%)#60.7
1907.07570v2.pdf	Scene Recognition#SUN397#Accuracy#77.28$Scene Recognition#Places365#Top 1 Accuracy#60.14$Scene Recognition#Places365#Top 5 Accuracy#88.86$Scene Recognition#MIT Indoor Scenes#Accuracy#90.3
1808.03833v3.pdf	Scene Recognition#ScanNet#Average Recall#54.28$Semantic Segmentation#SUN-RGBD#Mean IoU#45.73$Semantic Segmentation#SUN-RGBD#Mean IoU#38.4$Semantic Segmentation#ScanNetV2#Mean IoU#57.7$Semantic Segmentation#ScanNetV2#Mean IoU#50.3$Semantic Segmentation#Freiburg Forest#Mean IoU#84.18$Semantic Segmentation#Freiburg Forest#Mean IoU#83.09$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.3%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.24%$Semantic Segmentation#SYNTHIA-CVPR’16#Mean IoU#92.1$Semantic Segmentation#SYNTHIA-CVPR’16#Mean IoU#87.87
2102.02717v3.pdf	Face Parsing#LaPa#Mean F1#92.5$Face Parsing#iBugMask#Average F1#86.466666667
2203.14448v1.pdf	Face Parsing#LaPa#Mean F1#92.4$Face Parsing#Helen#Mean F1#93.8$Face Parsing#CelebAMask-HQ#Mean F1#86.1
2101.07034v3.pdf	Face Parsing#LaPa#Mean F1#92.3$Face Parsing#CelebAMask-HQ#Mean F1#85.5
2007.11240v1.pdf	Face Parsing#LaPa#Mean F1#91.1$Face Parsing#CelebAMask-HQ#Mean F1#85.1
2106.05375v1.pdf	Plan2Scene#Rent3D++#COLOR (All Surfaces)#0.591$Plan2Scene#Rent3D++#FREQ (All Surfaces)#0.034$Plan2Scene#Rent3D++#SUBS (All Surfaces)#0.392$Plan2Scene#Rent3D++#FID (All Surfaces)#196.2$Plan2Scene#Rent3D++#TILE (All Surfaces)#17.6
1805.02473v3.pdf	Text Generation#LDC2016E25#BLEU#22$Graph-to-Sequence#LDC2015E86:#BLEU#33.6
1705.11001v3.pdf	Text Generation#Chinese Poems#BLEU-2#0.812$Text Generation#COCO Captions#BLEU-2#0.850$Text Generation#COCO Captions#BLEU-3#0.672$Text Generation#COCO Captions#BLEU-4#0.557$Text Generation#COCO Captions#BLEU-5#0.544$Text Generation#EMNLP2017 WMT#BLEU-2#0.778$Text Generation#EMNLP2017 WMT#BLEU-3#0.478$Text Generation#EMNLP2017 WMT#BLEU-4#0.411$Text Generation#EMNLP2017 WMT#BLEU-5#0.463
1609.05473v6.pdf	Text Generation#Chinese Poems#BLEU-2#0.738$Text Generation#COCO Captions#BLEU-2#0.831$Text Generation#COCO Captions#BLEU-3#0.642$Text Generation#COCO Captions#BLEU-4#0.521$Text Generation#COCO Captions#BLEU-5#0.427$Text Generation#EMNLP2017 WMT#BLEU-2#0.859$Text Generation#EMNLP2017 WMT#BLEU-3#0.6015$Text Generation#EMNLP2017 WMT#BLEU-4#0.4541$Text Generation#EMNLP2017 WMT#BLEU-5#0.4498
1709.08624v2.pdf	Text Generation#Chinese Poems#BLEU-2#0.456$Text Generation#COCO Captions#BLEU-2#0.950$Text Generation#COCO Captions#BLEU-3#0.880$Text Generation#COCO Captions#BLEU-4#0.778$Text Generation#COCO Captions#BLEU-5#0.686$Text Generation#COCO Captions#BLEU-2#0.910$Text Generation#COCO Captions#BLEU-3#0.713$Text Generation#COCO Captions#BLEU-4#O.753$Text Generation#COCO Captions#BLEU-5#0.590$Text Generation#EMNLP2017 WMT#BLEU-2#0.956$Text Generation#EMNLP2017 WMT#BLEU-3#0.819$Text Generation#EMNLP2017 WMT#BLEU-4#0.627$Text Generation#EMNLP2017 WMT#BLEU-5#0.498
1808.08795v1.pdf	Text Generation#DailyDialog#BLEU-1#14.17$Text Generation#DailyDialog#BLEU-2#5.69$Text Generation#DailyDialog#BLEU-3#3.78$Text Generation#DailyDialog#BLEU-4#2.84
2110.08329v2.pdf	Text Generation#DART#METEOR#0.411$Data-to-Text Generation#WebNLG Full#BLEU#62.27$Data-to-Text Generation#WebNLG Full#BLEU#61.94$Data-to-Text Generation#Cleaned E2E NLG Challenge#BLEU (Test set)#44.15$Data-to-Text Generation#WebNLG#BLEU#67.32$Data-to-Text Generation#WebNLG#BLEU#67.15$Text Simplification#ASSET#SARI (EASSE>=0.2.1)#43.58$Text Simplification#ASSET#FKGL#5.97$Text Simplification#ASSET#QuestEval (Reference-less, BERTScore)#0.64$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#42.32$Text Simplification#TurkCorpus#FKGL#7.74$Text Simplification#TurkCorpus#QuestEval (Reference-less, BERTScore)#0.66$Text Summarization#X-Sum#Human Overall (GENIE, External)#0.51
2206.09363v1.pdf	Text Generation#ReDial#Distinct-3#0.648$Text Generation#ReDial#Distinct-4#0.832$Text Generation#ReDial#Distinct-2#0.492$Recommendation Systems#ReDial#Recall@1#0.051$Recommendation Systems#ReDial#Recall@10#0.224$Recommendation Systems#ReDial#Recall@50#0.428
2007.04032v1.pdf	Text Generation#ReDial#Distinct-3#0.434$Text Generation#ReDial#Distinct-4#0.519$Text Generation#ReDial#Distinct-2#0.289$Recommendation Systems#ReDial#Recall@1#0.039$Recommendation Systems#ReDial#Recall@10#0.183$Recommendation Systems#ReDial#Recall@50#0.378
2201.02732v2.pdf	Text Generation#ReDial#Distinct-3#0.334$Text Generation#ReDial#Distinct-4#0.424$Text Generation#ReDial#Distinct-2#0.189$Recommendation Systems#ReDial#Recall@1#0.053$Recommendation Systems#ReDial#Recall@10#0.233$Recommendation Systems#ReDial#Recall@50#0.407
1908.05391v2.pdf	Text Generation#ReDial#Perplexity#17.9$Text Generation#ReDial#Distinct-3#0.3$Text Generation#ReDial#Distinct-4#0.45$Recommendation Systems#ReDial#Recall@1#0.03$Recommendation Systems#ReDial#Recall@10#0.163$Recommendation Systems#ReDial#Recall@50#0.338
1911.03705v4.pdf	Text Generation#CommonGen#CIDEr#14.92
1901.05534v2.pdf	Text Generation#Yahoo Questions#NLL#326.7$Text Generation#Yahoo Questions#KL#5.7$Text Generation#Yahoo Questions#Perplexity#59.7
1802.02550v7.pdf	Text Generation#Yahoo Questions#NLL#327.5$Text Generation#Yahoo Questions#KL#7.19$Text Generation#Yahoo Questions#Perplexity#60.4
1702.08139v2.pdf	Text Generation#Yahoo Questions#NLL#332.1$Text Generation#Yahoo Questions#KL#10.0$Text Generation#Yahoo Questions#Perplexity#63.9
2112.08726v1.pdf	Text Generation#ROCStories#Perplexity#2.14$Text Generation#ROCStories#BLEU-1#34.4$Text Generation#ROCStories#Perplexity#2.16$Text Generation#ROCStories#Perplexity#2.11$Text Generation#ROCStories#BLEU-1#34.3$Text Generation#ROCStories#Perplexity#2.24$Text Generation#ROCStories#BLEU-1#33.7
1808.08703v3.pdf	Text Generation#CMU-SE#BLEU-3#0.617
2004.07159v2.pdf	Text Generation#CNN/Daily Mail#ROUGE-L#41.41$Text Summarization#GigaWord#ROUGE-1#39.45$Text Summarization#GigaWord#ROUGE-2#20.37$Text Summarization#GigaWord#ROUGE-L#36.75$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.30$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.12$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.41
2005.00969v1.pdf	Data-to-Text Generation#Wikipedia Person and Animal Dataset#BLEU#24.56
2005.10433v3.pdf	Data-to-Text Generation#ToTTo#BLEU#49.5$Data-to-Text Generation#ToTTo#PARENT#58.4$Data-to-Text Generation#MULTIWOZ 2.1#BLEU#35.1$Data-to-Text Generation#WebNLG Full#BLEU#57.1$Data-to-Text Generation#WebNLG#BLEU#64.7
2205.03972v1.pdf	Data-to-Text Generation#ToTTo#BLEU#48.4$Data-to-Text Generation#ToTTo#PARENT#58.1
2004.14373v3.pdf	Data-to-Text Generation#ToTTo#BLEU#44$Data-to-Text Generation#ToTTo#PARENT#52.6$Data-to-Text Generation#ToTTo#BLEU#41.6$Data-to-Text Generation#ToTTo#PARENT#51.6$Data-to-Text Generation#ToTTo#BLEU#19.2$Data-to-Text Generation#ToTTo#PARENT#29.2
2103.09120v2.pdf	Data-to-Text Generation#AMR3.0#Bleu#48.0
2112.10360v1.pdf	Data-to-Text Generation#MLB Dataset (Content Selection)#Precision#49.39$Data-to-Text Generation#MLB Dataset (Content Selection)#Recall#50.89$Data-to-Text Generation#RotoWire (Content Ordering)#DLD#17.26%$Data-to-Text Generation#RotoWire (Content Ordering)#BLEU#15.8$Data-to-Text Generation#RotoWire#BLEU#17.26$Data-to-Text Generation#MLB Dataset#BLEU#10.5$Data-to-Text Generation#MLB Dataset (Relation Generation)#Precision#84.50$Data-to-Text Generation#MLB Dataset (Relation Generation)#count#21.05$Data-to-Text Generation#Rotowire (Content Selection)#Precision#34.34%$Data-to-Text Generation#Rotowire (Content Selection)#Recall#48.85%$Data-to-Text Generation#RotoWire (Relation Generation)#count#27.37$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#95.40%$Data-to-Text Generation#MLB Dataset (Content Ordering)#DLD#21.16
2202.13756v1.pdf	Data-to-Text Generation#MLB Dataset (Content Selection)#Precision#43.3$Data-to-Text Generation#MLB Dataset (Content Selection)#Recall#53.5$Data-to-Text Generation#MLB Dataset#BLEU#14.29$Data-to-Text Generation#MLB Dataset (Relation Generation)#Precision#95.9$Data-to-Text Generation#MLB Dataset (Relation Generation)#count#28.9$Data-to-Text Generation#RotoWire (Relation Generation)#count#46.7$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#97.6$Data-to-Text Generation#MLB Dataset (Content Ordering)#DLD#22.7
2102.02723v1.pdf	Data-to-Text Generation#MLB Dataset (Content Selection)#Precision#40.8$Data-to-Text Generation#MLB Dataset (Content Selection)#Recall#54.9$Data-to-Text Generation#RotoWire (Content Ordering)#DLD#17.7%$Data-to-Text Generation#RotoWire#BLEU#15.46$Data-to-Text Generation#MLB Dataset#BLEU#12.62$Data-to-Text Generation#MLB Dataset (Relation Generation)#Precision#94.4$Data-to-Text Generation#MLB Dataset (Relation Generation)#count#30.8$Data-to-Text Generation#MLB Dataset (Relation Generation)#Precision#81.1$Data-to-Text Generation#MLB Dataset (Relation Generation)#count#23.8$Data-to-Text Generation#Rotowire (Content Selection)#Precision#34.1%$Data-to-Text Generation#Rotowire (Content Selection)#Recall#57.8%$Data-to-Text Generation#RotoWire (Relation Generation)#count#42.1$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#97.6$Data-to-Text Generation#MLB Dataset (Content Ordering)#DLD#21.8$Data-to-Text Generation#MLB Dataset (Content Ordering)#DLD#20.7
2004.15006v2.pdf	Data-to-Text Generation#MULTIWOZ 2.1#BLEU#34.96$Data-to-Text Generation#MULTIWOZ 2.1#BLEU#34.91
2002.12328v1.pdf	Data-to-Text Generation#MULTIWOZ 2.1#BLEU#30.76
1905.12866v3.pdf	Data-to-Text Generation#MULTIWOZ 2.1#BLEU#26.48
1911.02808v1.pdf	Data-to-Text Generation#SR11Deep#BLEU#80.49
1810.09995v1.pdf	Data-to-Text Generation#SR11Deep#BLEU#0.666$Data-to-Text Generation#WebNLG#BLEU#55.9
1912.10011v1.pdf	Data-to-Text Generation#RotoWire (Content Ordering)#DLD#18.90%$Data-to-Text Generation#RotoWire (Content Ordering)#BLEU#17.50$Data-to-Text Generation#RotoWire#BLEU#17.50$Data-to-Text Generation#Rotowire (Content Selection)#Precision#39.47%$Data-to-Text Generation#Rotowire (Content Selection)#Recall#51.64%$Data-to-Text Generation#RotoWire (Relation Generation)#count#21.17$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#89.46%
1809.00582v2.pdf	Data-to-Text Generation#RotoWire (Content Ordering)#DLD#18.58%$Data-to-Text Generation#RotoWire (Content Ordering)#BLEU#16.50$Data-to-Text Generation#RotoWire#BLEU#16.50$Data-to-Text Generation#Rotowire (Content Selection)#Precision#34.18%$Data-to-Text Generation#Rotowire (Content Selection)#Recall#51.22%$Data-to-Text Generation#RotoWire (Relation Generation)#count#34.28$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#87.47%
1707.08052v1.pdf	Data-to-Text Generation#RotoWire (Content Ordering)#DLD#8.68%$Data-to-Text Generation#RotoWire (Content Ordering)#BLEU#14.49$Data-to-Text Generation#RotoWire#BLEU#14.19$Data-to-Text Generation#Rotowire (Content Selection)#Precision#29.49%$Data-to-Text Generation#Rotowire (Content Selection)#Recall#36.18%$Data-to-Text Generation#RotoWire (Relation Generation)#count#23.72$Data-to-Text Generation#RotoWire (Relation Generation)#Precision#74.80%
1904.01301v2.pdf	Data-to-Text Generation#E2E NLG Challenge#BLEU#68.60$Data-to-Text Generation#E2E NLG Challenge#NIST#8.73$Data-to-Text Generation#E2E NLG Challenge#METEOR#45.25$Data-to-Text Generation#E2E NLG Challenge#ROUGE-L#70.82$Data-to-Text Generation#E2E NLG Challenge#CIDEr#2.37
1904.11838v4.pdf	Data-to-Text Generation#E2E NLG Challenge#BLEU#67.05$Data-to-Text Generation#E2E NLG Challenge#NIST#8.5150$Data-to-Text Generation#E2E NLG Challenge#METEOR#44.49$Data-to-Text Generation#E2E NLG Challenge#ROUGE-L#68.94$Data-to-Text Generation#E2E NLG Challenge#CIDEr#2.2355$Data-to-Text Generation#E2E NLG Challenge#BLEU#65.80$Data-to-Text Generation#E2E NLG Challenge#NIST#8.5615$Data-to-Text Generation#E2E NLG Challenge#METEOR#45.16$Data-to-Text Generation#E2E NLG Challenge#ROUGE-L#67.40$Data-to-Text Generation#E2E NLG Challenge#CIDEr#2.1803
1805.06553v1.pdf	Data-to-Text Generation#E2E NLG Challenge#BLEU#66.19$Data-to-Text Generation#E2E NLG Challenge#NIST#8.6130$Data-to-Text Generation#E2E NLG Challenge#METEOR#44.54$Data-to-Text Generation#E2E NLG Challenge#ROUGE-L#67.72
1810.01170v1.pdf	Data-to-Text Generation#E2E NLG Challenge#BLEU#65.93$Data-to-Text Generation#E2E NLG Challenge#NIST#8.6094$Data-to-Text Generation#E2E NLG Challenge#METEOR#44.83$Data-to-Text Generation#E2E NLG Challenge#ROUGE-L#68.50$Data-to-Text Generation#E2E NLG Challenge#CIDEr#2.2338
2105.08021v2.pdf	Data-to-Text Generation#WebNLG Full#BLEU#60.56$Data-to-Text Generation#WebNLG#BLEU#66.07
2007.08426v3.pdf	Data-to-Text Generation#WebNLG Full#BLEU#59.70$Data-to-Text Generation#WebNLG#BLEU#65.05$KG-to-Text Generation#WebNLG (Unseen)#BLEU#53.67$KG-to-Text Generation#WebNLG (Unseen)#METEOR#42.26$KG-to-Text Generation#WebNLG (Unseen)#chrF++#72.25$KG-to-Text Generation#WebNLG (Unseen)#BLEU#43.97$KG-to-Text Generation#WebNLG (Unseen)#METEOR#38.61$KG-to-Text Generation#WebNLG (Unseen)#chrF++#66.53$KG-to-Text Generation#WebNLG (All)#BLEU#59.70$KG-to-Text Generation#WebNLG (All)#METEOR#44.18$KG-to-Text Generation#WebNLG (All)#chrF++#75.40$KG-to-Text Generation#WebNLG (All)#BLEU#54.72$KG-to-Text Generation#WebNLG (All)#METEOR#42.23$KG-to-Text Generation#WebNLG (All)#chrF++#72.29$KG-to-Text Generation#WebNLG (Seen)#BLEU#64.71$KG-to-Text Generation#WebNLG (Seen)#METEOR#45.85$KG-to-Text Generation#WebNLG (Seen)#chrF++#78.29$KG-to-Text Generation#WebNLG (Seen)#BLEU#63.45$KG-to-Text Generation#WebNLG (Seen)#METEOR#45.49$KG-to-Text Generation#WebNLG (Seen)#chrF++#77.57$KG-to-Text Generation#AGENDA#BLEU#25.66$KG-to-Text Generation#AGENDA#BLEU#23.65
2107.06955v1.pdf	Data-to-Text Generation#WebNLG Full#BLEU#56.3$Data-to-Text Generation#WebNLG#BLEU#65.4$Table-to-Text Generation#E2E#BLEU#70.3$Table-to-Text Generation#E2E#NIST#8.90$Table-to-Text Generation#E2E#METEOR#46.3$Table-to-Text Generation#E2E#ROUGE-L#70.8$Table-to-Text Generation#E2E#CIDEr#2.47$Table-to-Text Generation#E2E#BLEU#68.5$Table-to-Text Generation#E2E#NIST#8.78$Table-to-Text Generation#E2E#METEOR#46.0$Table-to-Text Generation#E2E#ROUGE-L#69.9$Table-to-Text Generation#E2E#CIDEr#2.45$Table-to-Text Generation#WebNLG (Unseen)#BLEU#48.4$Table-to-Text Generation#WebNLG (Unseen)#METEOR#0.39$Table-to-Text Generation#WebNLG (Unseen)#TER#0.51$Table-to-Text Generation#WebNLG (Unseen)#BLEU#43.1$Table-to-Text Generation#WebNLG (Unseen)#METEOR#0.38$Table-to-Text Generation#WebNLG (Unseen)#TER#0.53$Table-to-Text Generation#WebNLG (All)#BLEU#55.6$Table-to-Text Generation#WebNLG (All)#METEOR#0.42$Table-to-Text Generation#WebNLG (All)#TER#0.4$Table-to-Text Generation#WebNLG (All)#BLEU#55.5$Table-to-Text Generation#WebNLG (All)#TER#0.42$Table-to-Text Generation#DART#BLEU#47.2$Table-to-Text Generation#DART#METEOR#0.39$Table-to-Text Generation#DART#TER#0.44$Table-to-Text Generation#DART#Mover#0.51$Table-to-Text Generation#DART#BERT#0.94$Table-to-Text Generation#DART#BLEURT#0.4$Table-to-Text Generation#DART#BLEU#47.0$Table-to-Text Generation#DART#TER#0.46$Table-to-Text Generation#WebNLG (Seen)#BLEU#65.4$Table-to-Text Generation#WebNLG (Seen)#METEOR#0.46$Table-to-Text Generation#WebNLG (Seen)#TER#0.33$Table-to-Text Generation#WebNLG (Seen)#BLEU#65.3
2004.06577v2.pdf	Data-to-Text Generation#WebNLG Full#BLEU#52.9$Data-to-Text Generation#Cleaned E2E NLG Challenge#BLEU (Test set)#43.6$Data-to-Text Generation#ViGGO#BLEU#53.6
1908.09022v2.pdf	Data-to-Text Generation#WebNLG Full#BLEU#51.68$Data-to-Text Generation#WebNLG#BLEU#57.20
1906.03221v1.pdf	Data-to-Text Generation#MLB Dataset#BLEU#11.50
2004.02077v1.pdf	Data-to-Text Generation#Czech Restaurant NLG#BLEU score#26.35$Data-to-Text Generation#Czech Restaurant NLG#METEOR#25.81$Data-to-Text Generation#Czech Restaurant NLG#CIDER#2.60$Data-to-Text Generation#Czech Restaurant NLG#NIST#5.24$Data-to-Text Generation#Czech Restaurant NLG#BLEU score#17.72$Data-to-Text Generation#Czech Restaurant NLG#METEOR#21.16$Data-to-Text Generation#Czech Restaurant NLG#CIDER#1.75$Data-to-Text Generation#Czech Restaurant NLG#NIST#4.22
1911.03905v1.pdf	Data-to-Text Generation#Cleaned E2E NLG Challenge#BLEU (Test set)#40.73
2001.11003v2.pdf	Data-to-Text Generation#WebNLG#BLEU#63.69$KG-to-Text Generation#AGENDA#BLEU#18.01$Graph-to-Sequence#WebNLG#BLEU#63.69
2102.06749v1.pdf	Data-to-Text Generation#WebNLG#BLEU#62.89
2006.09242v3.pdf	Data-to-Text Generation#WebNLG#BLEU#61.15$KG-to-Text Generation#AGENDA#BLEU#17.80
1904.03396v2.pdf	Data-to-Text Generation#WebNLG#BLEU#47.4
1910.12129v1.pdf	Data-to-Text Generation#ViGGO#BLEU#52.1
1804.09160v2.pdf	Visual Storytelling#VIST#BLEU-1#63.8$Visual Storytelling#VIST#BLEU-2#39.1$Visual Storytelling#VIST#BLEU-3#23.2$Visual Storytelling#VIST#BLEU-4#14.1$Visual Storytelling#VIST#METEOR#35$Visual Storytelling#VIST#ROUGE#29.5$Visual Storytelling#VIST#CIDEr#9.4
2004.14813v2.pdf	KG-to-Text Generation#ENT-DESC#BLEU#26.4
2106.10502v1.pdf	KG-to-Text Generation#WebNLG 2.0 (Constrained)#BLEU#61.01$KG-to-Text Generation#WebNLG 2.0 (Constrained)#METEOR#46.32$KG-to-Text Generation#WebNLG 2.0 (Constrained)#ROUGE#73.57$KG-to-Text Generation#WebNLG 2.0 (Constrained)#BLEU#58.66$KG-to-Text Generation#WebNLG 2.0 (Constrained)#METEOR#46.04$KG-to-Text Generation#WebNLG 2.0 (Constrained)#ROUGE#73.06$KG-to-Text Generation#WebNLG 2.0 (Constrained)#BLEU#58.55$KG-to-Text Generation#WebNLG 2.0 (Constrained)#METEOR#45.01$KG-to-Text Generation#WebNLG 2.0 (Constrained)#ROUGE#72.31$KG-to-Text Generation#WebNLG 2.0 (Constrained)#BLEU#56.65$KG-to-Text Generation#WebNLG 2.0 (Constrained)#METEOR#44.51$KG-to-Text Generation#WebNLG 2.0 (Constrained)#ROUGE#70.94$KG-to-Text Generation#PathQuestion#BLEU#65.89$KG-to-Text Generation#PathQuestion#METEOR#48.25$KG-to-Text Generation#PathQuestion#ROUGE#78.87$KG-to-Text Generation#PathQuestion#BLEU#63.74$KG-to-Text Generation#PathQuestion#METEOR#47.23$KG-to-Text Generation#PathQuestion#ROUGE#77.76$KG-to-Text Generation#PathQuestion#BLEU#60.45$KG-to-Text Generation#PathQuestion#METEOR#45.38$KG-to-Text Generation#PathQuestion#ROUGE#77.59$KG-to-Text Generation#PathQuestion#BLEU#58.95$KG-to-Text Generation#PathQuestion#METEOR#44.72$KG-to-Text Generation#PathQuestion#ROUGE#76.58$KG-to-Text Generation#WebQuestions#BLEU#30.02$KG-to-Text Generation#WebQuestions#METEOR#32.05$KG-to-Text Generation#WebQuestions#ROUGE#55.6$KG-to-Text Generation#WebQuestions#BLEU#29.61$KG-to-Text Generation#WebQuestions#METEOR#31.48$KG-to-Text Generation#WebQuestions#ROUGE#55.42$KG-to-Text Generation#WebQuestions#BLEU#28.95$KG-to-Text Generation#WebQuestions#METEOR#31.29$KG-to-Text Generation#WebQuestions#ROUGE#54.47$KG-to-Text Generation#WebQuestions#BLEU#28.78$KG-to-Text Generation#WebQuestions#METEOR#30.55$KG-to-Text Generation#WebQuestions#ROUGE#55.12$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#BLEU#66.14$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#METEOR#47.25$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#ROUGE#75.91$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#BLEU#65.92$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#METEOR#47.15$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#ROUGE#76.10$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#BLEU#64.55$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#METEOR#46.51$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#ROUGE#75.13$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#BLEU#64.42$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#METEOR#46.58$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#ROUGE#74.77
2004.06015v3.pdf	KG-to-Text Generation#PathQuestion#BLEU#61.48$KG-to-Text Generation#PathQuestion#METEOR#44.57$KG-to-Text Generation#PathQuestion#ROUGE#77.72$KG-to-Text Generation#WebQuestions#BLEU#29.45$KG-to-Text Generation#WebQuestions#METEOR#30.96$KG-to-Text Generation#WebQuestions#ROUGE#55.45
2101.00916v1.pdf	KG-to-Text Generation#AGENDA#BLEU#19.60
1904.02342v3.pdf	KG-to-Text Generation#AGENDA#BLEU#14.3
2010.02307v2.pdf	KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#BLEU#64.11$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#METEOR#46.30$KG-to-Text Generation#WebNLG 2.0 (Unconstrained)#ROUGE#74.57
2107.09556v1.pdf	KG-to-Text Generation#WikiGraphs#Test perplexity#25.85$KG-to-Text Generation#WikiGraphs#rBLEU (Valid)#10.97$KG-to-Text Generation#WikiGraphs#rBLEU (Test)#9.98$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Valid)#27.98$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Test)#24.07$KG-to-Text Generation#WikiGraphs#Test perplexity#26.65$KG-to-Text Generation#WikiGraphs#rBLEU (Valid)#29.53$KG-to-Text Generation#WikiGraphs#rBLEU (Test)#24.41$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Valid)#32.41$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Test)#27.39$KG-to-Text Generation#WikiGraphs#Test perplexity#26.93$KG-to-Text Generation#WikiGraphs#rBLEU (Valid)#31.39$KG-to-Text Generation#WikiGraphs#rBLEU (Test)#26.22$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Valid)#32.65$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Test)#28.35$KG-to-Text Generation#WikiGraphs#Test perplexity#27.4$KG-to-Text Generation#WikiGraphs#rBLEU (Valid)#30.51$KG-to-Text Generation#WikiGraphs#rBLEU (Test)#25.31$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Valid)#32.60$KG-to-Text Generation#WikiGraphs#rBLEU(w/title)(Test)#27.43
1904.09447v4.pdf	Unsupervised KG-to-Text Generation#WebNLG v2.1#BLEU#37.7$Unsupervised KG-to-Text Generation#VG graph-text#BLEU#23.2$Unsupervised semantic parsing#VG graph-text#F1#21.7$Unsupervised semantic parsing#WebNLG v2.1#F1#39.1
1812.06220v1.pdf	Multi-Document Summarization#review#1-of-100 Accuracy#100
2110.08499v2.pdf	Multi-Document Summarization#Multi-News#ROUGE-2#21.1$Multi-Document Summarization#Multi-News#ROUGE-1#49.9$Multi-Document Summarization#Multi-News#ROUGE-L#25.9$Multi-Document Summarization#WCEP#ROUGE-1#46.1$Multi-Document Summarization#WCEP#ROUGE-2#25.2$Multi-Document Summarization#WCEP#ROUGE-L#37.9$Text Summarization#arXiv Summarization Dataset#ROUGE-1#47.6$Text Summarization#arXiv Summarization Dataset#ROUGE-2#20.8$Text Summarization#arXiv Summarization Dataset#ROUGE-L#42.6
2112.07916v2.pdf	Multi-Document Summarization#Multi-News#ROUGE-2#19.43$Multi-Document Summarization#Multi-News#ROUGE-1#48.17$Multi-Document Summarization#Multi-News#ROUGE-SU4#24.94$Long-range modeling#SCROLLS#GovRep#54.7 / 28.2 / 30.2$Long-range modeling#SCROLLS#SumScr#35.8 / 9.6 / 21.1$Long-range modeling#SCROLLS#QMSum#34.9 / 11.8 / 23.5$Long-range modeling#SCROLLS#Qspr#53.1$Long-range modeling#SCROLLS#Nrtv#29.3$Long-range modeling#SCROLLS#QALT EM-T/H#46.0 / 42.1$Long-range modeling#SCROLLS#CNLI#88.2$Long-range modeling#SCROLLS#Avg.#41.89$Long-range modeling#SCROLLS#GovRep#54.2 / 27.8 / 29.8$Long-range modeling#SCROLLS#SumScr#35.6 / 9.2 / 21.2$Long-range modeling#SCROLLS#QMSum#35.1 / 12.0 / 23.3$Long-range modeling#SCROLLS#Qspr#52.3$Long-range modeling#SCROLLS#Nrtv#27.2$Long-range modeling#SCROLLS#QALT EM-T/H#40.6 / 38.6$Long-range modeling#SCROLLS#CNLI#87.3$Long-range modeling#SCROLLS#Avg.#40.47$Long-range modeling#SCROLLS#GovRep#53.5 / 27.3 / 29.3$Long-range modeling#SCROLLS#SumScr#34.8 / 9.6 / 21.1$Long-range modeling#SCROLLS#QMSum#33.9 / 11.0 / 22.8$Long-range modeling#SCROLLS#Qspr#46.6$Long-range modeling#SCROLLS#Nrtv#23.0$Long-range modeling#SCROLLS#QALT EM-T/H#37.9 / 36.6$Long-range modeling#SCROLLS#CNLI#85.6$Long-range modeling#SCROLLS#Avg.#38.22$Text Summarization#BigPatent#ROUGE-1#76.87$Text Summarization#BigPatent#ROUGE-2#66.06$Text Summarization#BigPatent#ROUGE-L#70.76$Text Summarization#arXiv#ROUGE-1#48.35$Text Summarization#arXiv#ROUGE-2#21.92$Text Summarization#arXiv#ROUGE-L#44.27$Text Summarization#Pubmed#ROUGE-1#50.23$Text Summarization#Pubmed#ROUGE-2#24.76$Text Summarization#Pubmed#ROUGE-L#46.67$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#43.94$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.40$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.28
1808.10792v2.pdf	Multi-Document Summarization#Multi-News#ROUGE-2#14.03$Multi-Document Summarization#Multi-News#ROUGE-1#43.57$Multi-Document Summarization#Multi-News#ROUGE-SU4#17.37$Multi-Document Summarization#Multi-News#ROUGE-2#14.19$Multi-Document Summarization#Multi-News#ROUGE-1#42.80$Multi-Document Summarization#Multi-News#ROUGE-SU4#16.75$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.22$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.68$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.34$Document Summarization#CNN / Daily Mail#PPL#32.75$Document Summarization#CNN / Daily Mail#ROUGE-1#41.22$Document Summarization#CNN / Daily Mail#ROUGE-2#18.68$Document Summarization#CNN / Daily Mail#ROUGE-L#38.34
1906.01749v3.pdf	Multi-Document Summarization#Multi-News#ROUGE-2#14.89$Multi-Document Summarization#Multi-News#ROUGE-1#43.47$Multi-Document Summarization#Multi-News#ROUGE-SU4#17.41
1706.06681v3.pdf	Multi-Document Summarization#DUC 2004#ROUGE-1#38.23
2105.02685v1.pdf	Text Style Transfer#Yelp Review Dataset (Large)#BLEU#30
1908.06809v2.pdf	Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#74.56
1804.06437v1.pdf	Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#54.64$Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#54.11
1711.06861v2.pdf	Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#45.02$Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#31.31
1705.09655v2.pdf	Text Style Transfer#Yelp Review Dataset (Small)#G-Score (BLEU, Accuracy)#38.66
2203.13620v1.pdf	Formality Style Transfer#GYAFC#BLEU#81.37
2109.08833v2.pdf	Story Generation#Fandom test#BLEU#28.4$Story Generation#Fandom test#ROUGE-1#63.2$Story Generation#Fandom test#ROUGE-2#32.9$Story Generation#Fandom test#ROUGE-L#61.5$Story Generation#Fandom test#Perplexity#18.2$Story Generation#Fandom dev#BLEU#28.4$Story Generation#Fandom dev#ROUGE-1#63.0$Story Generation#Fandom dev#ROUGE-2#32.8$Story Generation#Fandom dev#ROUGE-L#61.2$Story Generation#Fandom dev#Perplexity#17.9$Story Generation#TVMegaSite dev#BLEU#30.9$Story Generation#TVMegaSite dev#ROUGE-1#68.3$Story Generation#TVMegaSite dev#ROUGE-2#44.0$Story Generation#TVMegaSite dev#ROUGE-L#67.5$Story Generation#TVMegaSite dev#Perplexity#15.7$Story Generation#TVMegaSite test#BLEU#28.1$Story Generation#TVMegaSite test#ROUGE-1#67.0$Story Generation#TVMegaSite test#ROUGE-2#40.9$Story Generation#TVMegaSite test#Perplexity#18.3$Story Generation#TVMegaSite test#ROUGE-L#66.2
2203.03463v2.pdf	Paraphrase Generation#MSCOCO#iBLEU#19.04$Paraphrase Generation#MSCOCO#BLEU#27.90$Paraphrase Generation#Quora Question Pairs#iBLEU#18.42$Paraphrase Generation#Quora Question Pairs#BLEU#33.11$Paraphrase Generation#Paralex#iBLEU#24.93$Paraphrase Generation#Paralex#BLEU#39.49
2105.15053v1.pdf	Paraphrase Generation#Quora Question Pairs#iBLEU#5.84$Paraphrase Generation#Paralex#iBLEU#14.84
1711.09724v1.pdf	Table-to-Text Generation#WikiBio#BLEU#44.89$Table-to-Text Generation#WikiBio#ROUGE#41.21$Table-to-Text Generation#WikiBio#BLEU#44.71$Table-to-Text Generation#WikiBio#ROUGE#41.65
2102.02810v2.pdf	Table-to-Text Generation#WikiBio#BLEU#41.56$Table-to-Text Generation#WikiBio#PARENT#56.16
1603.07771v3.pdf	Table-to-Text Generation#WikiBio#BLEU#34.70$Table-to-Text Generation#WikiBio#ROUGE#25.80
2002.01127v2.pdf	Table-to-Text Generation#Wikipedia Person and Animal Dataset#BLEU#25.22$Table-to-Text Generation#Wikipedia Person and Animal Dataset#ROUGE#45.36
1809.01797v2.pdf	Table-to-Text Generation#Wikipedia Person and Animal Dataset#BLEU#23.2$Table-to-Text Generation#Wikipedia Person and Animal Dataset#ROUGE#23.4$Table-to-Text Generation#Wikipedia Person and Animal Dataset#METEOR#42.0$KB-to-Language Generation#Wikipedia Person and Animal Dataset#BLEU#23.2$KB-to-Language Generation#Wikipedia Person and Animal Dataset#METEOR#23.4$KB-to-Language Generation#Wikipedia Person and Animal Dataset#ROUGE#42.0
2010.05384v1.pdf	Distractor Generation#RACE#BLEU-1#39.81$Distractor Generation#RACE#BLEU-2#24.81$Distractor Generation#RACE#BLEU-3#17.66$Distractor Generation#RACE#BLEU-4#13.56$Distractor Generation#RACE#ROUGE-L#34.01
1907.07347v1.pdf	Concept-To-Text Generation#COCO Captions#BLEU-2#2
1805.06064v1.pdf	Paper generation#ACL Title and Abstract Dataset#ROUGE-L#20.3$Paper generation#ACL Title and Abstract Dataset#METEOR#14.0
2007.00916v1.pdf	Fact-based Text Editing#WebEdit#BLEU#75.68$Fact-based Text Editing#WebEdit#SARI#72.2$Fact-based Text Editing#WebEdit#KEEP#0.9184$Fact-based Text Editing#WebEdit#ADD#47.69$Fact-based Text Editing#WebEdit#DELETE#0.7707$Fact-based Text Editing#WebEdit#Exact Match#24.8$Fact-based Text Editing#WebEdit#Precision#96.88$Fact-based Text Editing#WebEdit#Recall#89.74$Fact-based Text Editing#WebEdit#F1#93.17$Fact-based Text Editing#WebEdit#BLEU#71.03$Fact-based Text Editing#WebEdit#SARI#69.59$Fact-based Text Editing#WebEdit#KEEP#0.8949$Fact-based Text Editing#WebEdit#ADD#43.82$Fact-based Text Editing#WebEdit#DELETE#0.7548$Fact-based Text Editing#WebEdit#Exact Match#20.96$Fact-based Text Editing#WebEdit#Precision#98.06$Fact-based Text Editing#WebEdit#Recall#87.56$Fact-based Text Editing#WebEdit#F1#92.51$Fact-based Text Editing#WebEdit#BLEU#33.75$Fact-based Text Editing#WebEdit#SARI#43.83$Fact-based Text Editing#WebEdit#KEEP#0.5144$Fact-based Text Editing#WebEdit#ADD#27.86$Fact-based Text Editing#WebEdit#DELETE#0.5219$Fact-based Text Editing#WebEdit#Exact Match#5.78$Fact-based Text Editing#WebEdit#Precision#98.23$Fact-based Text Editing#WebEdit#Recall#83.72$Fact-based Text Editing#WebEdit#F1#90.4$Fact-based Text Editing#WebEdit#BLEU#63.61$Fact-based Text Editing#WebEdit#SARI#58.73$Fact-based Text Editing#WebEdit#KEEP#0.8262$Fact-based Text Editing#WebEdit#ADD#25.77$Fact-based Text Editing#WebEdit#DELETE#0.678$Fact-based Text Editing#WebEdit#Exact Match#6.22$Fact-based Text Editing#WebEdit#Precision#81.93$Fact-based Text Editing#WebEdit#Recall#77.16$Fact-based Text Editing#WebEdit#F1#79.48$Fact-based Text Editing#WebEdit#BLEU#66.67$Fact-based Text Editing#WebEdit#SARI#31.51$Fact-based Text Editing#WebEdit#KEEP#0.7862$Fact-based Text Editing#WebEdit#ADD#3.91$Fact-based Text Editing#WebEdit#DELETE#0.1202$Fact-based Text Editing#WebEdit#Exact Match#0$Fact-based Text Editing#WebEdit#Precision#84.49$Fact-based Text Editing#WebEdit#Recall#76.34$Fact-based Text Editing#WebEdit#F1#80.21$Fact-based Text Editing#RotoEdit#BLEU#84.43$Fact-based Text Editing#RotoEdit#SARI#74.72$Fact-based Text Editing#RotoEdit#KEEP#98.41$Fact-based Text Editing#RotoEdit#ADD#41.5$Fact-based Text Editing#RotoEdit#DELETE#84.24$Fact-based Text Editing#RotoEdit#Exact Match#2.65$Fact-based Text Editing#RotoEdit#Precision#78.84$Fact-based Text Editing#RotoEdit#Recall#52.3$Fact-based Text Editing#RotoEdit#F1#63.39
2012.15329v3.pdf	Natural Language Landmark Navigation Instructions Generation#map2seq#SNT#66.4
2107.03374v2.pdf	Code Generation#APPS#Introductory#4.14$Code Generation#APPS#Interview#0.14$Code Generation#APPS#Competition#0.02
2105.09938v3.pdf	Code Generation#APPS#Introductory#3.90$Code Generation#APPS#Interview#0.57$Code Generation#APPS#Competition#0.00
2203.07814v1.pdf	Code Generation#APPS#Introductory Pass@1000#17.67$Code Generation#APPS#Interview Pass@1000#5.24$Code Generation#APPS#Competition Pass@1000#7.06$Code Generation#HumanEval#Pass@1#17.1$Code Generation#HumanEval#Pass@10#28.2$Code Generation#HumanEval#Pass@100#45.3$Code Generation#CodeContests#Test Set 10@100k#29.6
2207.10397v1.pdf	Code Generation#HumanEval#Pass@1#65.8$Code Generation#HumanEval#Pass@10#86.6$Code Generation#HumanEval#Pass@1#65.2$Code Generation#HumanEval#Pass@10#86.8$Code Generation#HumanEval#Pass@1#45.2$Code Generation#HumanEval#Pass@10#66.0$Code Generation#HumanEval#Pass@1#44.5$Code Generation#HumanEval#Pass@10#65.7
2106.04447v1.pdf	Code Generation#CoNaLa-Ext#BLEU#35.32$Code Generation#CoNaLa-Ext#BLEU#34.35$Code Generation#CoNaLa#BLEU#30.55$Code Generation#CoNaLa#BLEU#26.24
2004.09015v1.pdf	Code Generation#CoNaLa-Ext#BLEU#20.54$Code Generation#CoNaLa-Ext#BLEU#20.37$Code Generation#CoNaLa#BLEU#32.26$Code Generation#CoNaLa#BLEU#30.69
1810.02720v1.pdf	Code Generation#CoNaLa-Ext#BLEU#18.85$Code Generation#Django#Accuracy#73.7$Code Generation#WikiSQL#Execution Accuracy#78.6$Code Generation#WikiSQL#Exact Match Accuracy#68.6$Code Generation#CoNaLa#BLEU#24.30$Semantic Parsing#Geo#Accuracy#87.7$Semantic Parsing#ATIS#Accuracy#86.2
2101.00259v2.pdf	Code Generation#Django#Accuracy#81.77$Code Generation#CoNaLa#BLEU#33.41
1603.06744v2.pdf	Code Generation#Django#Accuracy#62.3$Code Generation#Django#Accuracy#31.5
1910.07179v5.pdf	Code Generation#WikiSQL#Execution Accuracy#89.2$Code Generation#WikiSQL#Exact Match Accuracy#83.7$Semantic Parsing#WikiSQL#Accuracy#89
1804.09769v1.pdf	Code Generation#WikiSQL#Execution Accuracy#82.6$Code Generation#WikiSQL#Execution Accuracy#73.5
1804.08338v1.pdf	Code Generation#WikiSQL#Execution Accuracy#74.6$Code Generation#WikiSQL#Exact Match Accuracy#61.0$Code Generation#WikiSQL#Execution Accuracy#74.4$Code Generation#WikiSQL#Exact Match Accuracy#60.7
1803.02400v4.pdf	Code Generation#WikiSQL#Execution Accuracy#68.0$Code Generation#WikiSQL#Exact Match Accuracy#62.8
1709.00103v7.pdf	Code Generation#WikiSQL#Execution Accuracy#59.4$Code Generation#WikiSQL#Exact Match Accuracy#48.3$Code Generation#WikiSQL#Execution Accuracy#35.9$Code Generation#WikiSQL#Exact Match Accuracy#23.4
2108.11601v2.pdf	Code Generation#CodeXGLUE - CodeSearchNet#Java#10.21$Code Generation#CodeXGLUE - CodeSearchNet#Python#9.61$Code Generation#CONCODE#Exact Match#23.4$Code Generation#CONCODE#BLEU#42.5$Code Generation#CONCODE#CodeBLEU#43.4
2202.13972v2.pdf	Code Generation#CoNaLa#BLEU#34.20
1805.04836v1.pdf	Code Generation#Android Repos#Perplexity#2.65$Recipe Generation#Now You're Cooking!#Perplexity#9.67
2109.00859v1.pdf	Code Generation#CONCODE#Exact Match#22.70$Code Generation#CONCODE#BLEU#41.48$Code Generation#CONCODE#CodeBLEU#44.10
2202.03755v1.pdf	Code Generation#Shellcode_IA32#BLEU-4#91.70$Code Generation#Shellcode_IA32#Exact Match Accuracy#89.75$Code Generation#Shellcode_IA32#BLEU-4#90.03$Code Generation#Shellcode_IA32#Exact Match Accuracy#82.92
2104.13100v4.pdf	Code Generation#Shellcode_IA32#BLEU-4#62.97$Code Generation#Shellcode_IA32#Exact Match Accuracy#51.55
2002.08155v4.pdf	Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#26.79$Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#26.66$Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#26.39$Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#26.09$Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#26.02$Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#23.48$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#25.61$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#9.54$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#8.73$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#8.51$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#8.3$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#6.88$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#5.72$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#21.32$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#21$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#20.71$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#20.25$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#19.9$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#18.4$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#18.25$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#8.46$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#7.95$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#7.87$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#7.39$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#7.26$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#6.96$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#15.48$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#15.41$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#15.05$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#14.92$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#13.44$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#13.04$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#15.99$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#15.55$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#15.15$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#15.03$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#14.52$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#14.31$Code Documentation Generation#CodeSearchNet#Smoothed BLEU-4#13.36$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#14.56$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#13.59$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#13.2$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#13.07$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#12.72$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#12.57$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#11.42$Type prediction#ManyTypes4TypeScript#Average Accuracy#61.72$Type prediction#ManyTypes4TypeScript#Average Precision#59.34$Type prediction#ManyTypes4TypeScript#Average Recall#59.80$Type prediction#ManyTypes4TypeScript#Average F1#59.57$Code Search#CodeSearchNet#Overall#76.0$Code Search#CodeSearchNet#Go#69.3$Code Search#CodeSearchNet#Ruby#70.6$Code Search#CodeSearchNet#Python#84.0$Code Search#CodeSearchNet#Java#86.8$Code Search#CodeSearchNet#JS#74.8$Code Search#CodeSearchNet#PHP#70.6
2104.02443v2.pdf	Code Documentation Generation#CodeSearchNet - Go#Smoothed BLEU-4#19.54$Code Documentation Generation#CodeSearchNet - JavaScript#Smoothed BLEU-4#18.98$Code Documentation Generation#CodeSearchNet - Php#Smoothed BLEU-4#26.23$Code Documentation Generation#CodeSearchNet - Ruby#Smoothed BLEU-4#15.26$Code Documentation Generation#CodeSearchNet - Python#Smoothed BLEU-4#20.39$Code Documentation Generation#CodeSearchNet - Java#Smoothed BLEU-4#21.87$Program Synthesis#AlgoLisp#Accuracy#90.31$Source Code Summarization#Summarizing Source Code using a Neural Attention Model - SQL#Smoothed BLEU-4#19.98$Source Code Summarization#Summarizing Source Code using a Neural Attention Model - C##Smoothed BLEU-4#23.57$Source Code Summarization#Summarizing Source Code using a Neural Attention Model - Python#Smoothed BLEU-4#13.37$Git Commit Message Generation#CommitGen#BLEU-4#44.41$API Sequence Recommendation#DeepAPI#BLEU-4#73.39$Code Comment Generation#DeepCom#Smoothed BLEU-4#39.50
2102.10590v3.pdf	Activity Recognition#RWF-2000#Accuracy#89.75
1911.05913v3.pdf	Activity Recognition#RWF-2000#Accuracy#87.25
2108.07917v6.pdf	Activity Recognition#Self-Stimulatory Behavior Dataset#Activity Recognition#0.76
2207.05254v1.pdf	Group Activity Recognition#Volleyball#Accuracy#96.0$Group Activity Recognition#Collective Activity#Accuracy#96.5
2112.05892v3.pdf	Group Activity Recognition#Volleyball#Accuracy#94.69$Group Activity Recognition#Collective Activity#Accuracy#96.2
2108.11743v1.pdf	Group Activity Recognition#Volleyball#Accuracy#93.6
2105.06754v1.pdf	Group Activity Recognition#Volleyball#Accuracy#91.0$Group Activity Recognition#Volleyball#Accuracy#89.4
1704.03058v1.pdf	Group Activity Recognition#Volleyball#Accuracy#83.6
1904.10117v1.pdf	Group Activity Recognition#Collective Activity#Accuracy#91
1511.04196v2.pdf	Group Activity Recognition#Collective Activity#Accuracy#81.2
1905.13533v1.pdf	Multimodal Activity Recognition#CMU Multi-Modal Activity (CMU-MMAC)#Accuracy#86.64%
2008.01148v1.pdf	Multimodal Activity Recognition#UT-Kinect#Accuracy (CS)#97.56$Multimodal Activity Recognition#UTD-MHAD#Accuracy (CS)#95.12$Multimodal Activity Recognition#UCSD-MIT Human Motion#F1-score#81.52
1507.08761v1.pdf	Multimodal Activity Recognition#MSR Daily Activity3D dataset#Accuracy#91.3
1904.12602v2.pdf	Multimodal Activity Recognition#EV-Action#Accuracy#67.4$Multimodal Activity Recognition#EV-Action#Accuracy#64.4$Multimodal Activity Recognition#EV-Action#Accuracy#44.1
1901.02858v1.pdf	Multimodal Activity Recognition#LboroHAR#Accuracy#97.90$Multimodal Activity Recognition#LboroHAR#Accuracy#95.00$Multimodal Activity Recognition#LboroHAR#Accuracy#92.50
1908.08498v1.pdf	Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#19.06$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S1)#34.8
1905.09035v2.pdf	Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#19.49$Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S1)#33.06$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#33.04$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#22.78$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#14.39$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#79.55$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#50.95$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#33.73$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#27.01$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#15.19$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#8.16$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#69.55$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#34.38$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#21.10
1811.10698v3.pdf	Egocentric Activity Recognition#EPIC-KITCHENS-55#Actions Top-1 (S2)#16.63$Egocentric Activity Recognition#EGTEA#Average Accuracy#61.9$Egocentric Activity Recognition#EGTEA#Mean class accuracy#-
2011.03920v1.pdf	Egocentric Activity Recognition#EGTEA#Average Accuracy#69.58$Egocentric Activity Recognition#EGTEA#Mean class accuracy#62.84
2002.03137v1.pdf	Egocentric Activity Recognition#EGTEA#Average Accuracy#62.7$Egocentric Activity Recognition#EGTEA#Mean class accuracy#-
1807.11794v1.pdf	Egocentric Activity Recognition#EGTEA#Average Accuracy#60.8$Egocentric Activity Recognition#EGTEA#Mean class accuracy#-
2110.11191v3.pdf	Human action generation#NTU RGB+D 2D#MMDa (CS)#0.256$Human action generation#NTU RGB+D 2D#MMDs (CS)#0.273$Human action generation#NTU RGB+D 2D#MMDa (CV)#0.295$Human action generation#NTU RGB+D 2D#MMDs (CV)#0.310$Human action generation#NTU RGB+D 120#FID (CS)#5.967$Human action generation#NTU RGB+D 120#FID (CV)#6.751$Human action generation#NTU RGB+D#FID (CS)#3.618$Human action generation#NTU RGB+D#FID (CV)#4.235$Human action generation#Human3.6M#MMDa#0.071$Human action generation#Human3.6M#MMDs#0.082
2007.01971v3.pdf	Human action generation#NTU RGB+D 2D#MMDa (CS)#0.285$Human action generation#NTU RGB+D 2D#MMDs (CS)#0.299$Human action generation#NTU RGB+D 2D#MMDa (CV)#0.316$Human action generation#NTU RGB+D 2D#MMDs (CV)#0.335$Human action generation#Human3.6M#MMDa#0.146$Human action generation#Human3.6M#MMDs#0.134
1411.1784v1.pdf	Human action generation#NTU RGB+D 2D#MMDa (CS)#0.334$Human action generation#NTU RGB+D 2D#MMDs (CS)#0.354$Human action generation#NTU RGB+D 2D#MMDa (CV)#0.365$Human action generation#NTU RGB+D 2D#MMDs (CV)#0.373$Human action generation#NTU RGB+D 120#FID (CS)#54.403$Human action generation#NTU RGB+D 120#FID (CV)#58.531$Human action generation#NTU RGB+D#FID (CS)#27.480$Human action generation#NTU RGB+D#FID (CV)#31.875$Human action generation#Human3.6M#MMDa#0.161$Human action generation#Human3.6M#MMDs#0.187
1912.10150v1.pdf	Human action generation#NTU RGB+D 2D#MMDa (CS)#0.338$Human action generation#NTU RGB+D 2D#MMDs (CS)#0.402$Human action generation#NTU RGB+D 2D#MMDa (CV)#0.371$Human action generation#NTU RGB+D 2D#MMDs (CV)#0.398$Human action generation#Human3.6M#MMDa#0.195$Human action generation#Human3.6M#MMDs#0.218
1711.08682v3.pdf	Human action generation#NTU RGB+D 2D#MMDa (CS)#0.698$Human action generation#NTU RGB+D 2D#MMDs (CS)#0.788$Human action generation#NTU RGB+D 2D#MMDa (CV)#0.999$Human action generation#NTU RGB+D 2D#MMDs (CV)#1.311$Human action generation#Human3.6M#MMDa#0.419$Human action generation#Human3.6M#MMDs#0.436
2106.14112v1.pdf	Recognizing And Localizing Human Actions#HAR#1:1 Accuracy#90.37$Automatic Sleep Stage Classification#Sleep-EDF#1:1 Accuracy#83.0$Epilepsy Prediction#Epilepsy seizure prediction#1:1 Accuracy#97.23
2007.06477v3.pdf	Relational Reasoning#CLUTRR (k=3)#4 Hops#0.99$Relational Reasoning#CLUTRR (k=3)#5 Hops#0.99$Relational Reasoning#CLUTRR (k=3)#6 Hops#0.99$Relational Reasoning#CLUTRR (k=3)#7 Hops#0.96$Relational Reasoning#CLUTRR (k=3)#8 Hops#0.94$Relational Reasoning#CLUTRR (k=3)#9 Hops#0.89$Relational Reasoning#CLUTRR (k=3)#10 Hops#0.90
1506.05908v1.pdf	Knowledge Tracing#Assistments#AUC#0.86$Knowledge Tracing#Assistments#AUC#0.67
2010.12042v2.pdf	Knowledge Tracing#EdNet#AUC#0.7914$Knowledge Tracing#EdNet#Acc#72.52$Knowledge Tracing#EdNet#AUC#0.7663$Knowledge Tracing#EdNet#Acc#70.79$Knowledge Tracing#EdNet#AUC#0.7638$Knowledge Tracing#EdNet#Acc#70.6$Knowledge Tracing#EdNet#Acc#70.73
2002.07033v5.pdf	Knowledge Tracing#EdNet#AUC#0.7811$Knowledge Tracing#EdNet#Acc#73.68
2012.05031v1.pdf	Knowledge Tracing#EdNet#AUC#0.7765$Knowledge Tracing#EdNet#AUC#0.7757
2009.05991v1.pdf	Knowledge Tracing#EdNet#AUC#0.7523
2103.09430v3.pdf	Knowledge Graphs#WikiKG90M-LSC#Validation MRR#0.8494$Knowledge Graphs#WikiKG90M-LSC#Test MRR#85.48$Knowledge Graphs#WikiKG90M-LSC#Validation MRR#0.8425$Knowledge Graphs#WikiKG90M-LSC#Test MRR#0.8637$Knowledge Graphs#WikiKG90M-LSC#Validation MRR#0.7052$Knowledge Graphs#WikiKG90M-LSC#Test MRR#0.7186$Knowledge Graphs#WikiKG90M-LSC#Validation MRR#0.6039$Knowledge Graphs#WikiKG90M-LSC#Test MRR#0.6288$Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.1753$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.1760$Graph Regression#PCQM4M-LSC#Validation MAE#0.1396$Graph Regression#PCQM4M-LSC#Test MAE#14.87$Graph Regression#PCQM4M-LSC#Validation MAE#0.1536$Graph Regression#PCQM4M-LSC#Test MAE#15.79$Graph Regression#PCQM4M-LSC#Test MAE#16.78$Graph Regression#PCQM4M-LSC#Validation MAE#0.1684$Graph Regression#PCQM4M-LSC#Test MAE#18.38$Graph Regression#PCQM4M-LSC#Validation MAE#0.2044$Graph Regression#PCQM4M-LSC#Test MAE#20.68$Node Classification#MAG240M-LSC#Test Accuracy#68.94$Node Classification#MAG240M-LSC#Test Accuracy#66.63$Node Classification#MAG240M-LSC#Test Accuracy#66.25$Node Classification#MAG240M-LSC#Validation Accuracy#66.64$Node Classification#MAG240M-LSC#Test Accuracy#66.09
2210.08922v2.pdf	Knowledge Graph Completion#DPB-5L (French)#MRR#64.5$Knowledge Graph Completion#DBP-5L (Greek)#MRR#71.7$Knowledge Graph Completion#DBP-5L (English)#MRR#44.6
2010.03158v2.pdf	Knowledge Graph Completion#DPB-5L (French)#MRR#59.5$Knowledge Graph Completion#DBP-5L (English)#MRR#41.3
2203.14987v1.pdf	Knowledge Graph Completion#DPB-5L (French)#MRR#36.6$Knowledge Graph Completion#DBP-5L (Greek)#MRR#35.3$Knowledge Graph Completion#DBP-5L (English)#MRR#32.1
1902.06236v1.pdf	Knowledge Graph Completion#DBbook2014#Hits@10#60.75$Knowledge Graph Completion#DBbook2014#Mean Rank#499$Knowledge Graph Completion#MovieLens 1M#Hits@10#48.9$Knowledge Graph Completion#MovieLens 1M#Mean Rank#527$Recommendation Systems#MovieLens 1M#HR@10#0.8903$Recommendation Systems#MovieLens 1M#NDCG#0.6992$Recommendation Systems#DBbook2014#HR@10#0.3461$Recommendation Systems#DBbook2014#NDCG#0.2762
2104.08804v1.pdf	Knowledge Graph Completion#DBP-5L (Greek)#MRR#69.4
2010.03496v3.pdf	Inductive knowledge graph completion#Wikidata5m-ind#MRR#0.493$Inductive knowledge graph completion#Wikidata5m-ind#Hits@1#0.289$Inductive knowledge graph completion#Wikidata5m-ind#Hits@10#0.877$Inductive knowledge graph completion#Wikidata5m-ind#Hits@3#0.664$Inductive knowledge graph completion#FB15k-237-ind#MRR#0.195$Inductive knowledge graph completion#FB15k-237-ind#Hit@1#0.113$Inductive knowledge graph completion#FB15k-237-ind#Hits@3#0.213$Inductive knowledge graph completion#FB15k-237-ind#Hits@10#0.363$Inductive knowledge graph completion#WN18RR-ind#MRR#0.285$Inductive knowledge graph completion#WN18RR-ind#Hits@3#0.361$Inductive knowledge graph completion#WN18RR-ind#Hit@10#0.58$Inductive knowledge graph completion#WN18RR-ind#Hits@1#0.156
2011.03459v4.pdf	Complex Query Answering#FB15k#MRR 1p#0.892$Complex Query Answering#FB15k#MRR 2p#0.653$Complex Query Answering#FB15k#MRR 3p#0.297$Complex Query Answering#FB15k#MRR 2i#0.771$Complex Query Answering#FB15k#MRR 3i#0.806$Complex Query Answering#FB15k#MRR pi#0.706$Complex Query Answering#FB15k#MRR ip#0.716$Complex Query Answering#FB15k#MRR 2u#0.723$Complex Query Answering#FB15k#MRR up#0.594$Complex Query Answering#NELL-995#MRR 1p#0.604$Complex Query Answering#NELL-995#MRR 2p#0.226$Complex Query Answering#NELL-995#MRR 3p#0.136$Complex Query Answering#NELL-995#MRR 2i#0.436$Complex Query Answering#NELL-995#MRR 3i#0.530$Complex Query Answering#NELL-995#MRR pi#0.312$Complex Query Answering#NELL-995#MRR ip#0.256$Complex Query Answering#NELL-995#MRR 2u#0.199$Complex Query Answering#NELL-995#MRR up#0.167$Complex Query Answering#FB15k-237#MRR 1p#0.467$Complex Query Answering#FB15k-237#MRR 2p#0.133$Complex Query Answering#FB15k-237#MRR 3p#0.079$Complex Query Answering#FB15k-237#MRR 2i#0.349$Complex Query Answering#FB15k-237#MRR 3i#0.486$Complex Query Answering#FB15k-237#MRR pi#0.271$Complex Query Answering#FB15k-237#MRR ip#0.204$Complex Query Answering#FB15k-237#MRR 2u#0.176$Complex Query Answering#FB15k-237#MRR up#0.115
2002.05969v2.pdf	Complex Query Answering#FB15k#MRR 1p#0.68$Complex Query Answering#FB15k#MRR 2p#0.21$Complex Query Answering#FB15k#MRR 3p#0.142$Complex Query Answering#FB15k#MRR 2i#0.551$Complex Query Answering#FB15k#MRR 3i#0.665$Complex Query Answering#FB15k#MRR pi#0.394$Complex Query Answering#FB15k#MRR ip#0.261$Complex Query Answering#FB15k#MRR 2u#0.351$Complex Query Answering#FB15k#MRR up#0.167$Complex Query Answering#NELL-995#MRR 1p#0.422$Complex Query Answering#NELL-995#MRR 2p#0.140$Complex Query Answering#NELL-995#MRR 3p#0.112$Complex Query Answering#NELL-995#MRR 2i#0.333$Complex Query Answering#NELL-995#MRR 3i#0.445$Complex Query Answering#NELL-995#MRR pi#0.224$Complex Query Answering#NELL-995#MRR ip#0.168$Complex Query Answering#NELL-995#MRR 2u#0.113$Complex Query Answering#NELL-995#MRR up#0.1103$Complex Query Answering#FB15k-237#MRR 1p#0.406$Complex Query Answering#FB15k-237#MRR 2p#0.094$Complex Query Answering#FB15k-237#MRR 3p#0.068$Complex Query Answering#FB15k-237#MRR 2i#0.295$Complex Query Answering#FB15k-237#MRR 3i#0.423$Complex Query Answering#FB15k-237#MRR pi#0.212$Complex Query Answering#FB15k-237#MRR ip#0.126$Complex Query Answering#FB15k-237#MRR 2u#0.113$Complex Query Answering#FB15k-237#MRR up#0.076
2010.11465v1.pdf	Complex Query Answering#FB15k#MRR 1p#0.651$Complex Query Answering#FB15k#MRR 2p#0.257$Complex Query Answering#FB15k#MRR 3p#0.247$Complex Query Answering#FB15k#MRR 2i#0.558$Complex Query Answering#FB15k#MRR 3i#0.665$Complex Query Answering#FB15k#MRR pi#0.439$Complex Query Answering#FB15k#MRR ip#0.281$Complex Query Answering#FB15k#MRR 2u#0.401$Complex Query Answering#FB15k#MRR up#0.252$Complex Query Answering#NELL-995#MRR 1p#0.53$Complex Query Answering#NELL-995#MRR 2p#0.13$Complex Query Answering#NELL-995#MRR 3p#0.114$Complex Query Answering#NELL-995#MRR 2i#0.376$Complex Query Answering#NELL-995#MRR 3i#0.475$Complex Query Answering#NELL-995#MRR pi#0.241$Complex Query Answering#NELL-995#MRR ip#0.143$Complex Query Answering#NELL-995#MRR 2u#0.122$Complex Query Answering#NELL-995#MRR up#0.085$Complex Query Answering#FB15k-237#MRR 1p#0.39$Complex Query Answering#FB15k-237#MRR 2p#0.109$Complex Query Answering#FB15k-237#MRR 3p#0.1$Complex Query Answering#FB15k-237#MRR 2i#0.288$Complex Query Answering#FB15k-237#MRR 3i#0.425$Complex Query Answering#FB15k-237#MRR pi#0.224$Complex Query Answering#FB15k-237#MRR ip#0.126$Complex Query Answering#FB15k-237#MRR 2u#0.124$Complex Query Answering#FB15k-237#MRR up#0.097
1806.01445v4.pdf	Complex Query Answering#FB15k#MRR 1p#0.546$Complex Query Answering#FB15k#MRR 2p#0.153$Complex Query Answering#FB15k#MRR 3p#0.108$Complex Query Answering#FB15k#MRR 2i#0.397$Complex Query Answering#FB15k#MRR 3i#0.514$Complex Query Answering#FB15k#MRR pi#0.276$Complex Query Answering#FB15k#MRR ip#0.191$Complex Query Answering#FB15k#MRR 2u#0.221$Complex Query Answering#FB15k#MRR up#0.116$Complex Query Answering#FB15k-237#MRR 1p#0.35$Complex Query Answering#FB15k-237#MRR 2p#0.072$Complex Query Answering#FB15k-237#MRR 3p#0.053$Complex Query Answering#FB15k-237#MRR 2i#0.233$Complex Query Answering#FB15k-237#MRR 3i#0.346$Complex Query Answering#FB15k-237#MRR pi#0.165$Complex Query Answering#FB15k-237#MRR ip#0.107$Complex Query Answering#FB15k-237#MRR 2u#0.082$Complex Query Answering#FB15k-237#MRR up#0.057
2202.05821v2.pdf	Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#93.09$Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#91.61$Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#91.33$Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#90.18$Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#86.98$Video & Kinematic Base Workflow Recognition#PETRAW#Average AD-Accuracy#84.8$Semantic Segmentation#PETRAW#Mean IoU (class)#96.9$Semantic Segmentation#PETRAW#Mean IoU (class)#96.4$Semantic Segmentation#PETRAW#Mean IoU (class)#94$Semantic Segmentation#PETRAW#Mean IoU (class)#85$Video, Kinematic & Segmentation Base Workflow Recognition#PETRAW#Average AD-Accuracy#93.09$Video, Kinematic & Segmentation Base Workflow Recognition#PETRAW#Average AD-Accuracy#91.37$Video, Kinematic & Segmentation Base Workflow Recognition#PETRAW#Average AD-Accuracy#91.27$Video, Kinematic & Segmentation Base Workflow Recognition#PETRAW#Average AD-Accuracy#89.81$Video Based Workflow Recognition#PETRAW#Average AD-Accuracy#90.77$Video Based Workflow Recognition#PETRAW#Average AD-Accuracy#90.51$Video Based Workflow Recognition#PETRAW#Average AD-Accuracy#89.15$Video Based Workflow Recognition#PETRAW#Average AD-Accuracy#87.77$Video Based Workflow Recognition#PETRAW#Average AD-Accuracy#84.31$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#90.72$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#90.32$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#89.71$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#89.66$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#86.45$Kinematic Based Workflow Recognition#PETRAW#Average AD-Accuracy#84.31$Segmentation Based Workflow Recognition#PETRAW#Average AD-Accuracy#88.51$Segmentation Based Workflow Recognition#PETRAW#Average AD-Accuracy#87.71$Segmentation Based Workflow Recognition#PETRAW#Average AD-Accuracy#87.22$Segmentation Based Workflow Recognition#PETRAW#Average AD-Accuracy#60.28
2104.05845v2.pdf	VGSI#wikiHow-image#Accuracy#0.7494
2206.05253v2.pdf	Crowd Counting#UCF-QNRF#MAE#81.6$Crowd Counting#ShanghaiTech A#MAE#54.8$Crowd Counting#ShanghaiTech A#MSE#89.1$Crowd Counting#UCF CC 50#MAE#186.3$Crowd Counting#ShanghaiTech B#MAE#6.2$Crowd Counting#JHU-CROWD++#MAE#58.2$Crowd Counting#JHU-CROWD++#MSE#245.1$Object Counting#TRANCOS#MAE#2.1$Object Counting#TRANCOS#MSE#2.6
2009.13077v2.pdf	Crowd Counting#UCF-QNRF#MAE#85.6
2003.05586v5.pdf	Crowd Counting#UCF-QNRF#MAE#85.6$Crowd Counting#ShanghaiTech A#MAE#57.55$Crowd Counting#ShanghaiTech A#MSE#94.48$Crowd Counting#UCF CC 50#MAE#162.33$Crowd Counting#WorldExpo’10#Average MAE#7.32$Crowd Counting#ShanghaiTech B#MAE#6.32$Crowd Counting#ShanghaiTech B#MSE#10.06
1911.07990v2.pdf	Crowd Counting#UCF-QNRF#MAE#87.6$Crowd Counting#UCF-QNRF#MAE#89.1$Crowd Counting#ShanghaiTech A#MAE#57.6$Crowd Counting#ShanghaiTech A#MAE#58$Crowd Counting#UCF CC 50#MAE#221.9$Crowd Counting#UCF CC 50#MAE#224.6$Crowd Counting#ShanghaiTech B#MAE#6.3$Crowd Counting#ShanghaiTech B#MAE#6.6
1811.10452v2.pdf	Crowd Counting#UCF-QNRF#MAE#107$Crowd Counting#ShanghaiTech A#MAE#62.3$Crowd Counting#UCF CC 50#MAE#212.2$Crowd Counting#Venice#MAE#20.5$Crowd Counting#Venice#MAE#23.5$Crowd Counting#WorldExpo’10#Average MAE#7.2$Crowd Counting#WorldExpo’10#Average MAE#7.4$Crowd Counting#ShanghaiTech B#MAE#7.8
1808.01050v1.pdf	Crowd Counting#UCF-QNRF#MAE#132
1708.00199v2.pdf	Crowd Counting#UCF-QNRF#MAE#228$Crowd Counting#ShanghaiTech A#MAE#90.4$Crowd Counting#UCF CC 50#MAE#318.1$Crowd Counting#Venice#MAE#52.8$Crowd Counting#WorldExpo’10#Average MAE#9.4$Crowd Counting#ShanghaiTech B#MAE#21.6
1707.09605v2.pdf	Crowd Counting#UCF-QNRF#MAE#252$Crowd Counting#ShanghaiTech A#MAE#101.3$Crowd Counting#ShanghaiTech A#MSE#152.4$Crowd Counting#UCF CC 50#MAE#322.8$Crowd Counting#ShanghaiTech B#MAE#20
2107.12746v3.pdf	Crowd Counting#ShanghaiTech A#MAE#52.74$Crowd Counting#ShanghaiTech A#MSE#85.06
1908.06473v1.pdf	Crowd Counting#ShanghaiTech A#MAE#58.3$Crowd Counting#ShanghaiTech B#MAE#6.7
1909.07057v1.pdf	Crowd Counting#ShanghaiTech A#MAE#59.4$Crowd Counting#ShanghaiTech A#MSE#92.5$Crowd Counting#UCF CC 50#MAE#232.6$Crowd Counting#WorldExpo’10#Average MAE#7.7$Crowd Counting#ShanghaiTech B#MAE#6.5
2202.13660v1.pdf	Crowd Counting#ShanghaiTech A#MAE#62.2$Crowd Counting#ShanghaiTech A#MSE#101.2$Crowd Counting#ShanghaiTech B#MAE#6.9$Crowd Counting#ShanghaiTech B#MSE#11.8
1906.07538v3.pdf	Crowd Counting#ShanghaiTech A#MAE#66.4$Crowd Counting#UCF CC 50#MAE#225.6$Crowd Counting#ShanghaiTech B#MAE#8.1
1802.10062v4.pdf	Crowd Counting#ShanghaiTech A#MAE#68.2$Crowd Counting#UCF CC 50#MAE#266.1$Crowd Counting#Venice#MAE#35.8$Crowd Counting#WorldExpo’10#Average MAE#8.6$Crowd Counting#ShanghaiTech B#MAE#10.6
1807.09959v1.pdf	Crowd Counting#ShanghaiTech A#MAE#68.5$Crowd Counting#UCF CC 50#MAE#260.9$Crowd Counting#WorldExpo’10#Average MAE#10.3$Crowd Counting#ShanghaiTech B#MAE#10.7
1807.09993v1.pdf	Crowd Counting#ShanghaiTech A#MAE#72.5$Crowd Counting#UCF CC 50#MAE#291.4$Crowd Counting#WorldExpo’10#Average MAE#11.3$Crowd Counting#ShanghaiTech B#MAE#13.6
1708.00953v1.pdf	Crowd Counting#ShanghaiTech A#MAE#73.6$Crowd Counting#UCF CC 50#MAE#295.8$Crowd Counting#WorldExpo’10#Average MAE#8.9$Crowd Counting#ShanghaiTech B#MAE#20.1
1803.03095v1.pdf	Crowd Counting#ShanghaiTech A#MAE#73.6$Crowd Counting#UCF CC 50#MAE#337.6$Crowd Counting#ShanghaiTech B#MAE#13.7
2201.08959v5.pdf	Crowd Counting#ShanghaiTech A#MAE#73.70$Crowd Counting#ShanghaiTech B#MAE#9.98$Object Counting#CARPK#MAE#5.33$Object Counting#CARPK#RMSE#7.04$Object Counting#FSC147#MAE(val)#15.28$Object Counting#FSC147#RMSE(val)#47.20$Object Counting#FSC147#MAE(test)#14.32$Object Counting#FSC147#RMSE(test)#85.54
1712.06679v2.pdf	Crowd Counting#WorldExpo’10#Average MAE#9.23
1909.12743v1.pdf	Crowd Counting#DLR-ACD#MAE#906$Crowd Counting#DLR-ACD#MNAE#0.21$Crowd Counting#DLR-ACD#RMSE#1307.4$Crowd Counting#DLR-ACD#Precision#0.51$Crowd Counting#DLR-ACD#Recall#0.48$Crowd Counting#DLR-ACD#F1-score#0.49$Crowd Counting#DLR-ACD#MAE#1481.3$Crowd Counting#DLR-ACD#MNAE#0.72$Crowd Counting#DLR-ACD#RMSE#2087$Crowd Counting#DLR-ACD#Precision#0.44$Crowd Counting#DLR-ACD#Recall#0.52$Crowd Counting#DLR-ACD#F1-score#0.46$Crowd Counting#DLR-ACD#MAE#833.3$Crowd Counting#DLR-ACD#MNAE#0.25$Crowd Counting#DLR-ACD#RMSE#1085.9$Crowd Counting#DLR-ACD#Precision#45$Crowd Counting#DLR-ACD#Recall#0.44$Crowd Counting#DLR-ACD#F1-score#0.44$Crowd Counting#DLR-ACD#MAE#1989.7$Crowd Counting#DLR-ACD#MNAE#0.87$Crowd Counting#DLR-ACD#RMSE#3016.3$Crowd Counting#DLR-ACD#Precision#0.43$Crowd Counting#DLR-ACD#Recall#0.41$Crowd Counting#DLR-ACD#F1-score#0.39$Crowd Counting#DLR-ACD#MAE#3388.8$Crowd Counting#DLR-ACD#MNAE#0.71$Crowd Counting#DLR-ACD#RMSE#4456.5$Crowd Counting#DLR-ACD#Precision#0.2$Crowd Counting#DLR-ACD#Recall#0.33$Crowd Counting#DLR-ACD#F1-score#0.24
2008.02265v5.pdf	Visual Reasoning#PHYRE-1B-Cross#AUCCESS#42.2$Visual Reasoning#PHYRE-1B-Within#AUCCESS#85.2
2006.10734v2.pdf	Visual Reasoning#PHYRE-1B-Cross#AUCCESS#40.3$Visual Reasoning#PHYRE-1B-Within#AUCCESS#80.0
2102.10336v2.pdf	Visual Reasoning#PHYRE-1B-Cross#AUCCESS#39.9$Visual Reasoning#PHYRE-1B-Within#AUCCESS#85.2
1908.05656v1.pdf	Visual Reasoning#PHYRE-1B-Cross#AUCCESS#36.8$Visual Reasoning#PHYRE-1B-Within#AUCCESS#77.6
2204.03162v2.pdf	Visual Reasoning#Winoground#Text Score#38.00$Visual Reasoning#Winoground#Image Score#14.00$Visual Reasoning#Winoground#Group Score#10.50$Visual Reasoning#Winoground#Text Score#37.75$Visual Reasoning#Winoground#Image Score#17.75$Visual Reasoning#Winoground#Group Score#14.50
2104.03135v2.pdf	Visual Reasoning#NLVR2 Dev#Accuracy#76.37$Visual Reasoning#NLVR2 Test#Accuracy#77.32$Visual Entailment#SNLI-VE test#Accuracy#84.95$Visual Entailment#SNLI-VE val#Accuracy#85.00
2207.12576v2.pdf	Visual Reasoning#WinoGAViL#Jaccard Index#90$Visual Reasoning#WinoGAViL#Jaccard Index#52$Visual Reasoning#WinoGAViL#Jaccard Index#46$Visual Reasoning#WinoGAViL#Jaccard Index#41$Visual Reasoning#WinoGAViL#Jaccard Index#40$Visual Reasoning#WinoGAViL#Jaccard Index#38$Visual Reasoning#WinoGAViL#Jaccard Index#35$Visual Reasoning#WinoGAViL#Jaccard Index#15$Common Sense Reasoning#WinoGAViL#Jaccard Index#52
2205.00363v1.pdf	Visual Reasoning#VSR#accuracy#72.5$Visual Reasoning#VSR#accuracy#71.0$Visual Reasoning#VSR#accuracy#57.4
2109.06860v1.pdf	Visual Commonsense Reasoning#GD-VCR#Accuracy#88.84$Visual Commonsense Reasoning#GD-VCR#Accuracy#59.99$Visual Commonsense Reasoning#GD-VCR#Gap (West)#-7.28$Visual Commonsense Reasoning#GD-VCR#Accuracy#53.95$Visual Commonsense Reasoning#GD-VCR#Gap (West)#-10.42$Visual Commonsense Reasoning#GD-VCR#Accuracy#35.33
2104.08955v4.pdf	Speech Separation#WSJ0-5mix#SI-SDRi#13.22$Speech Separation#Libri5Mix#SI-SDRi#12.72$Speech Separation#Libri10Mix#SI-SDRi#7.78$Speech Separation#Libri15Mix#SI-SDRi#5.66$Speech Separation#Libri20Mix#SI-SDRi#4.26
2006.14150v1.pdf	Speech Separation#WSJ0-5mix#SI-SDRi#11.7$Speech Separation#WSJ0-4mix#SI-SDRi#12.5
2009.03692v4.pdf	Speech Separation#WSJ0-5mix#SI-SDRi#11.14
2003.01531v4.pdf	Speech Separation#WSJ0-5mix#SI-SDRi#10.56$Speech Separation#WHAMR!#SI-SDRi#12.2$Speech Separation#WSJ0-4mix#SI-SDRi#12.88$Speech Separation#WSJ0-3mix#SI-SDRi#16.85$Speech Separation#WSJ0-2mix#SI-SDRi#20.12
2011.12022v2.pdf	Speech Separation#WSJ0-5mix#SI-SDRi#5.9$Speech Separation#WSJ0-4mix#SI-SDRi#9.3
2205.11801v3.pdf	Speech Separation#Libri5Mix#SI-SDRi#13.7$Speech Separation#Libri10Mix#SI-SDRi#8.2$Speech Separation#WSJ0-3mix#SI-SDRi#20.1$Speech Separation#WSJ0-2mix#SI-SDRi#22.4
2210.00471v2.pdf	Speech Separation#Libri5Mix#SI-SDRi#13.4
2209.15200v3.pdf	Speech Separation#Libri2Mix#SI-SDRi#17.4$Speech Separation#Libri2Mix#SI-SDRi#16.9$Speech Separation#WHAM!#SI-SDRi#15.2$Speech Separation#WHAM!#SI-SDRi#14.8
2010.15366v3.pdf	Speech Separation#Libri2Mix#SI-SDRi#14.1$Speech Separation#Libri2Mix#SDRi#14.6$Speech Separation#Libri2Mix#SI-SDRi#13.7$Speech Separation#Libri2Mix#SDRi#14.1$Speech Separation#Libri2Mix#SI-SDRi#13.2$Speech Separation#Libri2Mix#SDRi#13.6$Speech Separation#WSJ0-2mix#SI-SDRi#21.3$Speech Separation#WSJ0-2mix#SDRi#21.5
1811.02480v3.pdf	Speech Separation#GRID corpus (mixed-speech)#SDR#8.05$Speech Separation#TCD-TIMIT corpus (mixed-speech)#SDR#10.55$Speech Enhancement#TCD-TIMIT corpus (mixed-speech)#PESQ#3.03$Speech Enhancement#GRID corpus (mixed-speech)#PESQ#2.70
2103.02644v2.pdf	Speech Separation#WHAMR!#SI-SDRi#13.5$Speech Separation#WSJ0-2mix#SI-SDRi#19.5
2002.08933v2.pdf	Speech Separation#WHAMR!#SI-SDRi#13.2$Speech Separation#WSJ0-2mix#SI-SDRi#22.2$Speech Separation#WSJ0-2mix#SDRi#22.3$Speech Separation#WSJ0-2mix#SI-SDRi#19.0
2110.04791v2.pdf	Speech Separation#WHAMR!#SI-SDRi#12.3
2007.06833v1.pdf	Speech Separation#WHAMR!#SI-SDRi#12.1$Speech Separation#WSJ0-2mix#SI-SDRi#18.9
2210.15305v2.pdf	Speech Separation#WHAMR!#SI-SDRi#11.1$Speech Separation#WHAMR!#SDRi#10.3$Speech Separation#WSJ0-2mix#SI-SDRi#17.2$Speech Separation#WSJ0-2mix#SDRi#17.4
1907.01160v1.pdf	Speech Separation#WHAMR!#SI-SDRi#9.2
2010.13154v2.pdf	Speech Separation#WSJ0-3mix#SI-SDRi#19.5$Speech Separation#WSJ0-2mix#SI-SDRi#22.3$Speech Separation#WSJ0-2mix#SDRi#22.4
2103.00819v2.pdf	Speech Separation#WSJ0-3mix#SI-SDRi#17.1$Speech Separation#WSJ0-2mix#SI-SDRi#21.0
2101.05014v1.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#20.3
2007.13975v3.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#20.2
1910.06379v2.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#18.8
1904.11148v1.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#17.7
1910.12706v1.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#17.5
1904.07845v1.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#16.6
1910.09804v2.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#16.1
1711.00541v2.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#10.8
1508.04306v1.pdf	Speech Separation#WSJ0-2mix#SI-SDRi#10.8
1901.10125v5.pdf	Chinese Word Segmentation#PKU#F1#96.7$Chinese Word Segmentation#PKU#Precision#97.1$Chinese Word Segmentation#PKU#Recall#96.4$Chinese Word Segmentation#AS#F1#96.7$Chinese Word Segmentation#AS#Precision#96.6$Chinese Word Segmentation#AS#Recall#96.8$Chinese Word Segmentation#MSR#F1#98.3$Chinese Word Segmentation#MSR#Precision#98.2$Chinese Word Segmentation#MSR#Recall#98.3$Chinese Word Segmentation#CITYU#F1#97.9$Chinese Word Segmentation#CITYU#Precision#97.9$Chinese Word Segmentation#CITYU#Recall#98$Chinese Named Entity Recognition#Resume NER#F1#96.54$Chinese Named Entity Recognition#Resume NER#Precision#96.62$Chinese Named Entity Recognition#Resume NER#Recall#96.48$Chinese Named Entity Recognition#MSRA#F1#95.54$Chinese Named Entity Recognition#MSRA#Precision#95.57$Chinese Named Entity Recognition#MSRA#Recall#95.51$Chinese Named Entity Recognition#OntoNotes 4#F1#80.62$Chinese Named Entity Recognition#OntoNotes 4#Precision#81.87$Chinese Named Entity Recognition#OntoNotes 4#Recall#81.4$Chinese Named Entity Recognition#Weibo NER#F1#67.6$Chinese Named Entity Recognition#Weibo NER#Precision#67.68$Chinese Named Entity Recognition#Weibo NER#Recall#67.71
1911.00720v1.pdf	Chinese Word Segmentation#MSR#F1#98.35$Chinese Word Segmentation#MSR#F1#97.89$Chinese Named Entity Recognition#MSRA#F1#95.25$Chinese Named Entity Recognition#MSRA#F1#93.24
1909.04800v2.pdf	Common Sense Reasoning#Visual Dialog  v0.9#1 in 10 R@5#81.0$Common Sense Reasoning#Visual Dialog  v0.9#Recall@10#90.5
2112.03254v3.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#89.4
2012.04808v3.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#83.3
1909.05311v2.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#75.3
1910.14087v1.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#73.2
2203.14465v2.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#73.0$Common Sense Reasoning#CommonsenseQA#Accuracy#72.3$Common Sense Reasoning#CommonsenseQA#Accuracy#68.8$Common Sense Reasoning#CommonsenseQA#Accuracy#60.0$Common Sense Reasoning#CommonsenseQA#Accuracy#55.6$Common Sense Reasoning#CommonsenseQA#Accuracy#36.6$Common Sense Reasoning#CommonsenseQA#Accuracy#20.9
1906.02361v1.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#64.7
1908.06725v5.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#62.2
1909.02151v1.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#58.9
1811.00937v2.pdf	Common Sense Reasoning#CommonsenseQA#Accuracy#55.9
1805.06939v2.pdf	Common Sense Reasoning#Event2Mind dev#Average Cross-Ent#4.44$Common Sense Reasoning#Event2Mind dev#Average Cross-Ent#4.25$Common Sense Reasoning#Event2Mind test#Average Cross-Ent#4.4$Common Sense Reasoning#Event2Mind test#Average Cross-Ent#4.22
1907.11983v1.pdf	Common Sense Reasoning#Winograd Schema Challenge#Score#75.1$Natural Language Understanding#PDP60#Accuracy#90$Natural Language Understanding#WNLI#Accuracy#83.6
1905.06290v2.pdf	Common Sense Reasoning#Winograd Schema Challenge#Score#72.2$Common Sense Reasoning#Winograd Schema Challenge#Score#70.3$Natural Language Understanding#WNLI#Accuracy#71.9$Natural Language Understanding#WNLI#Accuracy#70.5
1806.02847v2.pdf	Common Sense Reasoning#Winograd Schema Challenge#Score#63.7$Common Sense Reasoning#Winograd Schema Challenge#Score#62.6$Common Sense Reasoning#Winograd Schema Challenge#Score#57.9
1904.01938v1.pdf	Common Sense Reasoning#Winograd Schema Challenge#Score#63.0$Natural Language Understanding#PDP60#Accuracy#75.0
1808.05326v1.pdf	Common Sense Reasoning#SWAG#Dev#59.1$Common Sense Reasoning#SWAG#Test#59.2$Common Sense Reasoning#SWAG#Dev#51.9$Common Sense Reasoning#SWAG#Test#52.7
2210.11610v2.pdf	Common Sense Reasoning#OpenBookQA#Accuracy#94.4$Common Sense Reasoning#OpenBookQA#Accuracy#93$Common Sense Reasoning#OpenBookQA#Accuracy#92$Common Sense Reasoning#OpenBookQA#Accuracy#90$Common Sense Reasoning#OpenBookQA#Accuracy#86.4$Common Sense Reasoning#OpenBookQA#Accuracy#84.4$Common Sense Reasoning#ARC-c#Accuracy#89.8$Common Sense Reasoning#ARC-c#Accuracy#88.7$Common Sense Reasoning#ARC-c#Accuracy#88.3$Common Sense Reasoning#ARC-c#Accuracy#87.2$Common Sense Reasoning#ARC-c#Accuracy#87.1$Common Sense Reasoning#ARC-c#Accuracy#85.2$Natural Language Inference#ANLI-A2#Accuracy#66.5$Natural Language Inference#ANLI-A2#Accuracy#65.3$Natural Language Inference#ANLI-A2#Accuracy#64.8$Natural Language Inference#ANLI-A2#Accuracy#64.5$Natural Language Inference#ANLI-A2#Accuracy#58.9$Natural Language Inference#ANLI-A2#Accuracy#55.8$Natural Language Inference#ANLI-A3#Accuracy#67.9$Natural Language Inference#ANLI-A3#Accuracy#67.3$Natural Language Inference#ANLI-A3#Accuracy#66.9$Natural Language Inference#ANLI-A3#Accuracy#63.4$Natural Language Inference#ANLI-A3#Accuracy#60.6$Natural Language Inference#ANLI-A3#Accuracy#55.8$Arithmetic Reasoning#GSM8K#Accuracy#82.1$Arithmetic Reasoning#GSM8K#Accuracy#74.4$Arithmetic Reasoning#GSM8K#Accuracy#73.5$Arithmetic Reasoning#GSM8K#Accuracy#56.5$Arithmetic Reasoning#GSM8K#Accuracy#32.2$Arithmetic Reasoning#GSM8K#Accuracy#17.9$Arithmetic Reasoning#DROP#Accuracy#83$Arithmetic Reasoning#DROP#Accuracy#78.2$Arithmetic Reasoning#DROP#Accuracy#76.2$Arithmetic Reasoning#DROP#Accuracy#71.7$Arithmetic Reasoning#DROP#Accuracy#70.6$Arithmetic Reasoning#DROP#Accuracy#60
2203.11130v3.pdf	Physical Commonsense Reasoning#Physical Audiovisual CommonSense#With Audio (Acc %)#96.3 ± 2.1$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#90.5 ± 3.1$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#With Audio (Acc %)#70.1 ± 1.0$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#68.4 ± 0.7$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#With Audio (Acc %)#60.0 ± 0.9$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#56.3 ± 0.7$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#With Audio (Acc %)#55.0 ± 1.1$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#52.5 ± 1.6$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#With Audio (Acc %)#50.4$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#50.4$Physical Commonsense Reasoning#Physical Audiovisual CommonSense#Without Audio (Acc %)#60.6 ± 2.2
2210.02890v2.pdf	Multiview Contextual Commonsense Inference#CICERO#Accuracy#27.54$Multiview Contextual Commonsense Inference#CICERO#Accuracy#25.66$Multiview Contextual Commonsense Inference#CICEROv2#Accuracy#73.80$Multiview Contextual Commonsense Inference#CICEROv2#Accuracy#71.95
1909.10430v2.pdf	Word Sense Disambiguation#SensEval 3 Lexical Sample#F1#80.12$Word Sense Disambiguation#SemEval 2007 Task 17#F1#63.17$Word Sense Disambiguation#SemEval 2007 Task 17#F1#60.94$Word Sense Disambiguation#SemEval 2007 Task 7#F1#85.32$Word Sense Disambiguation#SemEval 2007 Task 7#F1#81.20$Word Sense Disambiguation#SensEval 2 Lexical Sample#F1#76.52
1606.03568v2.pdf	Word Sense Disambiguation#SensEval 3 Lexical Sample#F1#73.4$Word Sense Disambiguation#SensEval 2 Lexical Sample#F1#66.9
1802.09059v1.pdf	Word Sense Disambiguation#SensEval 3 Lexical Sample#F1#72.5
1905.05677v3.pdf	Word Sense Disambiguation#SemEval 2013 Task 12#F1#78.7$Word Sense Disambiguation#SensEval 2#F1#79.7$Word Sense Disambiguation#Supervised:#Senseval 2#79.7$Word Sense Disambiguation#Supervised:#Senseval 3#77.8$Word Sense Disambiguation#Supervised:#SemEval 2007#73.4$Word Sense Disambiguation#Supervised:#SemEval 2013#78.7$Word Sense Disambiguation#Supervised:#SemEval 2015#82.6$Word Sense Disambiguation#SemEval 2007 Task 17#F1#73.4$Word Sense Disambiguation#SemEval 2007 Task 7#F1#90.4$Word Sense Disambiguation#SensEval 3 Task 1#F1#77.8$Word Sense Disambiguation#SemEval 2015 Task 13#F1#82.6
1811.00960v1.pdf	Word Sense Disambiguation#SemEval 2013 Task 12#F1#72.63$Word Sense Disambiguation#SensEval 2#F1#75.15$Word Sense Disambiguation#Supervised:#Senseval 2#75.15$Word Sense Disambiguation#Supervised:#Senseval 3#70.11$Word Sense Disambiguation#Supervised:#SemEval 2007#66.81$Word Sense Disambiguation#Supervised:#SemEval 2013#72.63$Word Sense Disambiguation#Supervised:#SemEval 2015#74.46$Word Sense Disambiguation#SemEval 2007 Task 17#F1#66.81$Word Sense Disambiguation#SemEval 2007 Task 7#F1#86.02$Word Sense Disambiguation#SensEval 3 Task 1#F1#70.11$Word Sense Disambiguation#SemEval 2015 Task 13#F1#74.46
1603.07012v2.pdf	Word Sense Disambiguation#SemEval 2013 Task 12#F1#69.5$Word Sense Disambiguation#SemEval 2013 Task 12#F1#68.1$Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.9$Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.3$Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.0$Word Sense Disambiguation#SensEval 2#F1#74.4$Word Sense Disambiguation#SensEval 2#F1#73.9$Word Sense Disambiguation#SensEval 2#F1#73.8$Word Sense Disambiguation#SensEval 2#F1#73.6$Word Sense Disambiguation#SensEval 2#F1#72.4$Word Sense Disambiguation#SemEval 2007 Task 17#F1#64.2$Word Sense Disambiguation#SemEval 2007 Task 17#F1#63.7$Word Sense Disambiguation#SemEval 2007 Task 17#F1#63.5$Word Sense Disambiguation#SemEval 2007 Task 17#F1#63.3$Word Sense Disambiguation#SemEval 2007 Task 17#F1#60.7$Word Sense Disambiguation#SemEval 2007 Task 7#F1#84.3$Word Sense Disambiguation#SemEval 2007 Task 7#F1#83.6$Word Sense Disambiguation#SemEval 2007 Task 7#F1#83.3$Word Sense Disambiguation#SemEval 2007 Task 7#F1#82.8$Word Sense Disambiguation#SemEval 2007 Task 7#F1#81.1$Word Sense Disambiguation#SensEval 3 Task 1#F1#71.8$Word Sense Disambiguation#SensEval 3 Task 1#F1#71.1$Word Sense Disambiguation#SensEval 3 Task 1#F1#71.0$Word Sense Disambiguation#SensEval 3 Task 1#F1#69.2$Word Sense Disambiguation#SensEval 3 Task 1#F1#64.3
1805.08028v2.pdf	Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.2$Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.1$Word Sense Disambiguation#SemEval 2013 Task 12#F1#67.0$Word Sense Disambiguation#SemEval 2013 Task 12#F1#66.7$Word Sense Disambiguation#SensEval 2#F1#72.4$Word Sense Disambiguation#SensEval 2#F1#72.2$Word Sense Disambiguation#SensEval 2#F1#72.1$Word Sense Disambiguation#SensEval 2#F1#72.0$Word Sense Disambiguation#Supervised:#Senseval 2#72.2$Word Sense Disambiguation#Supervised:#Senseval 3#70.5$Word Sense Disambiguation#Supervised:#SemEval 2007#--*$Word Sense Disambiguation#Supervised:#SemEval 2013#67.2$Word Sense Disambiguation#Supervised:#SemEval 2015#72.6$Word Sense Disambiguation#Supervised:#Senseval 2#72.0$Word Sense Disambiguation#Supervised:#Senseval 3#70.0$Word Sense Disambiguation#Supervised:#SemEval 2013#66.7$Word Sense Disambiguation#Supervised:#SemEval 2015#71.6$Word Sense Disambiguation#SensEval 3 Task 1#F1#70.5$Word Sense Disambiguation#SensEval 3 Task 1#F1#70.2$Word Sense Disambiguation#SensEval 3 Task 1#F1#70.1$Word Sense Disambiguation#SensEval 3 Task 1#F1#70.0$Word Sense Disambiguation#SemEval 2015 Task 13#F1#72.6$Word Sense Disambiguation#SemEval 2015 Task 13#F1#72.1$Word Sense Disambiguation#SemEval 2015 Task 13#F1#71.8$Word Sense Disambiguation#SemEval 2015 Task 13#F1#71.6
1707.08084v1.pdf	Word Sense Disambiguation#SemEval 2013 Task 12#F1#63.05$Word Sense Disambiguation#SemEval 2013 Task 12#Unsupervised#yes$Word Sense Disambiguation#SemEval 2007 Task 7#F1#81.22$Word Sense Disambiguation#SemEval 2007 Task 7#Unsupervised#yes
1908.07245v4.pdf	Word Sense Disambiguation#Supervised:#Senseval 2#77.7$Word Sense Disambiguation#Supervised:#Senseval 3#75.2$Word Sense Disambiguation#Supervised:#SemEval 2007#72.5$Word Sense Disambiguation#Supervised:#SemEval 2013#76.1$Word Sense Disambiguation#Supervised:#SemEval 2015#80.4$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: all#75.9$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: general purpose#75.2$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: domain specific#76.7$Entity Linking#WiC-TSV#Task 1 Accuracy: all#75.9$Entity Linking#WiC-TSV#Task 1 Accuracy: general purpose#75.2$Entity Linking#WiC-TSV#Task 1 Accuracy: domain specific#76.7
1910.00194v2.pdf	Word Sense Disambiguation#Supervised:#Senseval 2#75.5$Word Sense Disambiguation#Supervised:#Senseval 3#73.6$Word Sense Disambiguation#Supervised:#SemEval 2007#68.1$Word Sense Disambiguation#Supervised:#SemEval 2013#71.1$Word Sense Disambiguation#Supervised:#SemEval 2015#76.2$Word Sense Disambiguation#Supervised:#Senseval 2#73.8$Word Sense Disambiguation#Supervised:#Senseval 3#71.6$Word Sense Disambiguation#Supervised:#SemEval 2007#63.3$Word Sense Disambiguation#Supervised:#SemEval 2013#69.2$Word Sense Disambiguation#Supervised:#SemEval 2015#74.4
1801.01900v1.pdf	Word Sense Disambiguation#Knowledge-based:#All#66.9$Word Sense Disambiguation#Knowledge-based:#Senseval 2#**69.0**$Word Sense Disambiguation#Knowledge-based:#Senseval 3#**66.9**$Word Sense Disambiguation#Knowledge-based:#SemEval 2007#**55.6**$Word Sense Disambiguation#Knowledge-based:#SemEval 2013#65.3$Word Sense Disambiguation#Knowledge-based:#SemEval 2015#69.6
2004.15016v3.pdf	Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: all#75.3$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: general purpose#73.3$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: domain specific#77.9$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: all#71.7$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: general purpose#68.6$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: domain specific#74.7$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: all#76.6$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: general purpose#73.5$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: domain specific#80.4$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: all#54.4$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: general purpose#49.2$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: domain specific#60.6$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: all#62.8$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: general purpose#57.6$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: domain specific#69.1$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: all#60.5$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: general purpose#54.4$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: domain specific#67.9$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: all#53.7$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: general purpose#56.2$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: domain specific#50.6$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: all#52.7$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: general purpose#56.8$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: domain specific#47.7$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: all#53.4$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: general purpose#57.1$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: domain specific#49.0$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: all#50.8$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: general purpose#53.8$Word Sense Disambiguation#WiC-TSV#Task 1 Accuracy: domain specific#47.0$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: all#50.8$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: general purpose#53.8$Word Sense Disambiguation#WiC-TSV#Task 2 Accuracy: domain specific#47.0$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: all#50.8$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: general purpose#53.8$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: domain specific#47.0$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: all#85.3$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: general purpose#82.1$Word Sense Disambiguation#WiC-TSV#Task 3 Accuracy: domain specific#89.2$Entity Linking#WiC-TSV#Task 1 Accuracy: all#75.3$Entity Linking#WiC-TSV#Task 1 Accuracy: general purpose#73.3$Entity Linking#WiC-TSV#Task 1 Accuracy: domain specific#77.9$Entity Linking#WiC-TSV#Task 2 Accuracy: all#71.7$Entity Linking#WiC-TSV#Task 2 Accuracy: general purpose#68.6$Entity Linking#WiC-TSV#Task 2 Accuracy: domain specific#74.7$Entity Linking#WiC-TSV#Task 3 Accuracy: all#76.6$Entity Linking#WiC-TSV#Task 3 Accuracy: general purpose#73.5$Entity Linking#WiC-TSV#Task 3 Accuracy: domain specific#80.4$Entity Linking#WiC-TSV#Task 1 Accuracy: all#54.4$Entity Linking#WiC-TSV#Task 1 Accuracy: general purpose#49.2$Entity Linking#WiC-TSV#Task 1 Accuracy: domain specific#60.6$Entity Linking#WiC-TSV#Task 2 Accuracy: all#62.8$Entity Linking#WiC-TSV#Task 2 Accuracy: general purpose#57.6$Entity Linking#WiC-TSV#Task 2 Accuracy: domain specific#69.1$Entity Linking#WiC-TSV#Task 3 Accuracy: all#60.5$Entity Linking#WiC-TSV#Task 3 Accuracy: general purpose#54.4$Entity Linking#WiC-TSV#Task 3 Accuracy: domain specific#67.9$Entity Linking#WiC-TSV#Task 1 Accuracy: all#53.7$Entity Linking#WiC-TSV#Task 1 Accuracy: general purpose#56.2$Entity Linking#WiC-TSV#Task 1 Accuracy: domain specific#50.6$Entity Linking#WiC-TSV#Task 2 Accuracy: all#52.7$Entity Linking#WiC-TSV#Task 2 Accuracy: general purpose#56.8$Entity Linking#WiC-TSV#Task 2 Accuracy: domain specific#47.7$Entity Linking#WiC-TSV#Task 3 Accuracy: all#53.4$Entity Linking#WiC-TSV#Task 3 Accuracy: general purpose#57.1$Entity Linking#WiC-TSV#Task 3 Accuracy: domain specific#49.0$Entity Linking#WiC-TSV#Task 1 Accuracy: all#50.8$Entity Linking#WiC-TSV#Task 1 Accuracy: general purpose#53.8$Entity Linking#WiC-TSV#Task 1 Accuracy: domain specific#47.0$Entity Linking#WiC-TSV#Task 2 Accuracy: all#50.8$Entity Linking#WiC-TSV#Task 2 Accuracy: general purpose#53.8$Entity Linking#WiC-TSV#Task 2 Accuracy: domain specific#47.0$Entity Linking#WiC-TSV#Task 3 Accuracy: all#50.8$Entity Linking#WiC-TSV#Task 3 Accuracy: general purpose#53.8$Entity Linking#WiC-TSV#Task 3 Accuracy: domain specific#47.0$Entity Linking#WiC-TSV#Task 3 Accuracy: all#85.3$Entity Linking#WiC-TSV#Task 3 Accuracy: general purpose#82.1$Entity Linking#WiC-TSV#Task 3 Accuracy: domain specific#89.2
2010.07835v3.pdf	Word Sense Disambiguation#Words in Context#Accuracy#85.3
1905.12598v2.pdf	Word Sense Induction#SemEval 2010 WSI#F-Score#71.3$Word Sense Induction#SemEval 2010 WSI#V-Measure#40.4$Word Sense Induction#SemEval 2010 WSI#AVG#53.6$Word Sense Induction#SemEval 2013#F-BC#64.0$Word Sense Induction#SemEval 2013#F_NMI#21.4$Word Sense Induction#SemEval 2013#AVG#37.0
1811.09242v1.pdf	Word Sense Induction#SemEval 2010 WSI#F-Score#61.7$Word Sense Induction#SemEval 2010 WSI#V-Measure#9.8$Word Sense Induction#SemEval 2010 WSI#AVG#24.59$Word Sense Induction#SemEval 2013#F-BC#61.7$Word Sense Induction#SemEval 2013#F_NMI#7.96$Word Sense Induction#SemEval 2013#AVG#22.16
1606.05409v2.pdf	Word Sense Induction#SemEval 2010 WSI#F-Score#55.1$Word Sense Induction#SemEval 2010 WSI#V-Measure#9.8$Word Sense Induction#SemEval 2010 WSI#AVG#23.24
1808.08518v2.pdf	Word Sense Induction#SemEval 2013#F-BC#57.5$Word Sense Induction#SemEval 2013#F_NMI#11.3$Word Sense Induction#SemEval 2013#AVG#25.4
1911.03221v4.pdf	Sleep Stage Detection#MASS SS3#Accuracy#89.1%$Sleep Stage Detection#MASS SS3#Accuracy#88.8%$Sleep Stage Detection#DODO#Accuracy#88.7$Sleep Stage Detection#DODO#Kappa#82.3$Sleep Stage Detection#DODO#Accuracy#87.5$Sleep Stage Detection#DODO#Kappa#80.4$Sleep Stage Detection#DODO#Accuracy#85.5$Sleep Stage Detection#DODO#Kappa#77.2$Sleep Stage Detection#DODH#Accuracy#89.9$Sleep Stage Detection#DODH#Kappa#84.6$Sleep Stage Detection#DODH#Accuracy#89.6$Sleep Stage Detection#DODH#Kappa#84.3
2207.07753v2.pdf	Sleep Stage Detection#MASS SS3#Accuracy#86.7%$Sleep Stage Detection#MASS SS3#Macro-F1#0.817$Sleep Stage Detection#MASS SS3#Cohen's kappa#0.803$Sleep Stage Detection#Sleep-EDF#Accuracy#86.6%$Sleep Stage Detection#Sleep-EDF#Macro-F1#0.810$Sleep Stage Detection#Sleep-EDF#Cohen's kappa#0.816$Sleep Stage Detection#Sleep-EDF#Accuracy#86.3%$Sleep Stage Detection#Sleep-EDF#Macro-F1#0.805$Sleep Stage Detection#Sleep-EDF#Cohen's kappa#0.813$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Accuracy#83.6%$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Macro-F1#0.795$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Cohen's kappa#0.765$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Accuracy#82.9%$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Macro-F1#0.792$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Cohen's kappa#0.759$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Accuracy#86.4%$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Macro-F1#0.802$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Cohen's kappa#0.812$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Accuracy#85.7%$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Macro-F1#0.809$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Cohen's kappa#0.806
1703.04046v2.pdf	Sleep Stage Detection#MASS SS3#Accuracy#86.2%$Sleep Stage Detection#MASS SS3#Macro-F1#0.817$Sleep Stage Detection#MASS SS3#Cohen's kappa#0.8$Sleep Stage Detection#Sleep-EDF#Accuracy#82%$Sleep Stage Detection#Sleep-EDF#Macro-F1#0.769$Sleep Stage Detection#Sleep-EDF#Cohen's kappa#0.76
1902.06562v2.pdf	Sleep Stage Detection#MASS SS2#Accuracy#84.5%$Sleep Stage Detection#Sleep-EDF#Accuracy#84.0%
1805.06546v3.pdf	Sleep Stage Detection#MASS SS2#Accuracy#78.6%$Sleep Stage Detection#Sleep-EDF#Accuracy#81.9%
2112.07252v2.pdf	Sleep Stage Detection#Montreal Archive of Sleep Studies#Weighted F1#0.85$W-R-L-D Sleep Staging#Montreal Archive of Sleep Studies#Weighted F1#0.85$W-R-L-D Sleep Staging#Montreal Archive of Sleep Studies#Weighted F1#0.51$W-R-N Sleep Staging#Montreal Archive of Sleep Studies#Weighted F1#0.90$W-R-N Sleep Staging#Montreal Archive of Sleep Studies#Weighted F1#0.66
1710.00633v1.pdf	Sleep Stage Detection#Sleep-EDF#Accuracy#81.3%
1910.06100v1.pdf	Sleep Stage Detection#ISRUC-Sleep#Accuracy#78.5$Sleep Stage Detection#ISRUC-Sleep#AUROC#84.7$Sleep Stage Detection#ISRUC-Sleep#Kappa#0.72$Automatic Sleep Stage Classification#ISRUC-Sleep#Accuracy#80.1$Automatic Sleep Stage Classification#ISRUC-Sleep#AUROC#86$Automatic Sleep Stage Classification#ISRUC-Sleep#Kappa#0.741
1812.04079v1.pdf	Spindle Detection#Stanford Sleep Cohort (SSC)#F1-score (@IoU = 0.3)#0.48$Spindle Detection#MASS SS2#F1-score (@IoU = 0.3)#0.75$Spindle Detection#Wisconsin Sleep Cohort (WSC)#F1-score (@IoU = 0.3)#0.46$Sleep apnea detection#Dreem_NCT03657329#Accuracy#81%$Sleep apnea detection#Dreem_NCT03657329#F1-score (@IoU = 0.3)#0.57 ± 0.23$Sleep apnea detection#Dreem_NCT03657329#Mean AHI Error#4.69 ± 4.25$Sleep Arousal Detection#MESA#F1-score (@IoU = 0.3)#0.71$Sleep Arousal Detection#MESA#F1-score (@IoU = 0.3)#0.61$K-complex detection#MASS SS2#F1-score (@IoU = 0.3)#0.6
2005.07795v2.pdf	Spindle Detection#MASS SS2#F1-score (@IoU = 0.3)#0.812$Spindle Detection#MASS SS2#F1-score (@IoU = 0.2)#0.812$Spindle Detection#MASS SS2#F1-score (@IoU = 0.3)#0.809$Spindle Detection#MASS SS2#F1-score (@IoU = 0.2)#0.809$K-complex detection#MASS SS2#F1-score (@IoU = 0.3)#0.827$K-complex detection#MASS SS2#F1-score (@IoU = 0.2)#0.828$K-complex detection#MASS SS2#F1-score (@IoU = 0.3)#0.825$K-complex detection#MASS SS2#F1-score (@IoU = 0.2)#0.826
2202.05158v2.pdf	Spindle Detection#MODA dataset#F1-score (@IoU = 0.2, all age groups)#0.82$Spindle Detection#MODA dataset#F1-score (@IoU = 0.2, young individuals)#0.84$Spindle Detection#MODA dataset#F1-score (@IoU = 0.2, older individuals)#0.79
1907.13177v3.pdf	Multimodal Sleep Stage Detection#Surrey-cEEGGrid#Accuracy#81.5%$Multimodal Sleep Stage Detection#Sleep-EDF-ST#Accuracy#79.6%$Multimodal Sleep Stage Detection#Sleep-EDF-SC#Accuracy#82.2%$Multimodal Sleep Stage Detection#Surrey-PSG#Accuracy#79.9%
1812.01840v2.pdf	Natural Language Inference#Quora Question Pairs#Accuracy#88.01$Natural Language Inference#SNLI#% Test Accuracy#88.1$Natural Language Inference#MultiNLI#Matched#73.9$Natural Language Inference#MultiNLI#Mismatched#73.9
1912.05372v4.pdf	Natural Language Inference#XNLI French#Accuracy#83.4$Natural Language Inference#XNLI French#Accuracy#80.6
1809.05053v1.pdf	Natural Language Inference#XNLI French#Accuracy#68.3
1909.02950v2.pdf	Natural Language Inference#V-SNLI#Accuracy#90.5
1806.05645v1.pdf	Natural Language Inference#V-SNLI#Accuracy#86.99$Natural Language Inference#V-SNLI#Accuracy#86.41
2203.12942v1.pdf	Natural Language Inference#HANS#1:1 Accuracy#78.65
2105.14167v3.pdf	Natural Language Inference#MED#1:1 Accuracy#0.934$Natural Language Inference#SICK#1:1 Accuracy#0.903
2010.02329v4.pdf	Natural Language Inference#ANLI test#A1#75$Natural Language Inference#ANLI test#A2#50.5$Natural Language Inference#ANLI test#A3#47.7$Natural Language Inference#ANLI test#ANLI#58.3
2004.08994v2.pdf	Natural Language Inference#ANLI test#A1#72.3$Natural Language Inference#ANLI test#A2#52.1$Natural Language Inference#ANLI test#A3#48.4$Natural Language Inference#ANLI test#ANLI#57
2106.08087v6.pdf	Natural Language Inference#KUAKE-QQR#Accuracy#84.7$Natural Language Inference#KUAKE-QTR#Accuracy#62.9$Semantic Similarity#CHIP-STS#Macro F1#85.6$Medical Relation Extraction#CMeIE#Micro F1#55.9$Intent Classification#KUAKE-QIC#Accuracy#85.5$Named Entity Recognition#CMeEE#Micro F1#62.4$Sentence Classification#CHIP-CTC#Macro F1#70.9
2009.08820v2.pdf	Natural Language Inference#FarsTail#% Test Accuracy#83.38$Natural Language Inference#FarsTail#% Test Accuracy#82.99$Natural Language Inference#FarsTail#% Test Accuracy#78.13$Natural Language Inference#FarsTail#% Test Accuracy#75.83$Natural Language Inference#FarsTail#% Test Accuracy#74.62$Natural Language Inference#FarsTail#% Test Accuracy#72.44$Natural Language Inference#FarsTail#% Test Accuracy#71.16$Natural Language Inference#FarsTail#% Test Accuracy#70.46$Natural Language Inference#FarsTail#% Test Accuracy#66.62$Natural Language Inference#FarsTail#% Test Accuracy#66.04
1904.09223v1.pdf	Natural Language Inference#XNLI Chinese Dev#Accuracy#79.9$Natural Language Inference#XNLI Chinese#Accuracy#78.4$Chinese Named Entity Recognition#MSRA#F1#93.8$Chinese Named Entity Recognition#MSRA Dev#F1#95
2012.01786v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#92.3$Natural Language Inference#SNLI#Parameters#340$Paraphrase Identification#Quora Question Pairs#Accuracy#80$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#59.1
2009.09139v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#92.1$Natural Language Inference#SNLI#% Train Accuracy#92.6$Natural Language Inference#SNLI#Parameters#340m$Natural Language Inference#SciTail#Accuracy#96.8
1901.11504v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#91.6$Natural Language Inference#SNLI#% Train Accuracy#97.2$Natural Language Inference#SNLI#Parameters#330m$Natural Language Inference#SNLI#% Test Accuracy#90.5$Natural Language Inference#SNLI#% Train Accuracy#99.1$Natural Language Inference#SNLI#Parameters#220$Natural Language Inference#SciTail#Accuracy#94.1$Natural Language Inference#MultiNLI#Matched#86.7$Natural Language Inference#MultiNLI#Mismatched#86.0$Paraphrase Identification#Quora Question Pairs#Accuracy#89.6$Paraphrase Identification#Quora Question Pairs#F1#72.4$Sentiment Analysis#SST-2 Binary classification#Accuracy#95.6$Linguistic Acceptability#CoLA#Accuracy#68.4%
1911.03437v5.pdf	Natural Language Inference#SNLI#% Test Accuracy#91.6$Natural Language Inference#QNLI#Accuracy#95.4%$Natural Language Inference#SciTail#Accuracy#96.1$Natural Language Inference#WNLI#Accuracy#91.89%$Natural Language Inference#MultiNLI#Matched#91.0$Natural Language Inference#MultiNLI#Mismatched#90.8$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.929$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.925$Semantic Textual Similarity#MRPC#Accuracy#93.7%$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.5
1809.02794v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#91.3$Natural Language Inference#SNLI#% Train Accuracy#95.7$Natural Language Inference#SNLI#Parameters#308m$Natural Language Inference#SNLI#% Test Accuracy#89.1$Natural Language Inference#SNLI#% Train Accuracy#89.1$Natural Language Inference#SNLI#Parameters#6.1m
1805.11360v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#90.1$Natural Language Inference#SNLI#% Train Accuracy#95.0$Natural Language Inference#SNLI#Parameters#53.3m$Natural Language Inference#SNLI#% Test Accuracy#88.9$Natural Language Inference#SNLI#% Train Accuracy#93.1$Natural Language Inference#SNLI#Parameters#6.7m$Natural Language Inference#SNLI#% Test Accuracy#86.5$Natural Language Inference#SNLI#% Train Accuracy#91.4$Natural Language Inference#SNLI#Parameters#5.6m
1907.09692v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#89.6$Natural Language Inference#SNLI#% Train Accuracy#96.1$Natural Language Inference#SNLI#Parameters#79m$Natural Language Inference#SNLI#% Test Accuracy#88.8$Natural Language Inference#SNLI#% Train Accuracy#95.4$Natural Language Inference#SNLI#Parameters#9.2m
1802.05577v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#89.3$Natural Language Inference#SNLI#% Train Accuracy#94.8$Natural Language Inference#SNLI#Parameters#45m$Natural Language Inference#SNLI#% Test Accuracy#88.5$Natural Language Inference#SNLI#% Train Accuracy#94.1$Natural Language Inference#SNLI#Parameters#7.5m
1801.00102v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#89.3$Natural Language Inference#SNLI#% Train Accuracy#92.5$Natural Language Inference#SNLI#Parameters#17.5m$Natural Language Inference#SNLI#% Test Accuracy#88.5$Natural Language Inference#SNLI#% Train Accuracy#89.8$Natural Language Inference#SNLI#Parameters#4.7m$Natural Language Inference#SNLI#% Test Accuracy#85.9$Natural Language Inference#SNLI#% Train Accuracy#87.3$Natural Language Inference#SNLI#Parameters#3.7m$Natural Language Inference#SciTail#Accuracy#83.3
1711.04289v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#89.1$Natural Language Inference#SNLI#% Train Accuracy#93.6$Natural Language Inference#SNLI#Parameters#43m$Natural Language Inference#SNLI#% Test Accuracy#88.6$Natural Language Inference#SNLI#% Train Accuracy#94.1$Natural Language Inference#SNLI#Parameters#4.3m
1709.04348v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.9$Natural Language Inference#SNLI#% Train Accuracy#92.3$Natural Language Inference#SNLI#Parameters#17m$Natural Language Inference#SNLI#% Test Accuracy#88.0$Natural Language Inference#SNLI#% Train Accuracy#91.2$Natural Language Inference#SNLI#Parameters#4.4m$Paraphrase Identification#Quora Question Pairs#Accuracy#89.06
1702.03814v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.8$Natural Language Inference#SNLI#% Train Accuracy#93.2$Natural Language Inference#SNLI#Parameters#6.4m$Natural Language Inference#SNLI#% Test Accuracy#87.5$Natural Language Inference#SNLI#% Train Accuracy#90.9$Natural Language Inference#SNLI#Parameters#1.6m$Paraphrase Identification#Quora Question Pairs#Accuracy#88.17
1609.06038v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.6$Natural Language Inference#SNLI#% Train Accuracy#93.5$Natural Language Inference#SNLI#Parameters#7.7m$Natural Language Inference#SNLI#% Test Accuracy#88.0
1804.07888v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.5$Natural Language Inference#SNLI#% Train Accuracy#93.3$Natural Language Inference#SNLI#Parameters#3.5m
1408.5882v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.1$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#48.90$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#34.37$Sentiment Analysis#SST-2 Binary classification#Accuracy#88.1
1503.00075v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#88.0$Natural Language Inference#SNLI#% Test Accuracy#86.3$Natural Language Inference#SNLI#% Test Accuracy#84.9$Semantic Similarity#SICK#MSE#0.2532$Semantic Similarity#SICK#Pearson Correlation#0.8676$Semantic Similarity#SICK#Spearman Correlation#0.8083$Semantic Similarity#SICK#MSE#0.2736$Semantic Similarity#SICK#Pearson Correlation#0.8567$Semantic Similarity#SICK#Spearman Correlation#0.7966$Semantic Similarity#SICK#MSE#0.2831$Semantic Similarity#SICK#Pearson Correlation#0.8528$Semantic Similarity#SICK#Spearman Correlation#0.7911$Sentiment Analysis#SST-2 Binary classification#Accuracy#88.0$Sentiment Analysis#SST-2 Binary classification#Accuracy#86.3$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#51.0
1808.07383v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#87.4$Natural Language Inference#SNLI#% Train Accuracy#89.0$Natural Language Inference#SNLI#Parameters#7.0m$Natural Language Inference#SNLI#% Test Accuracy#86.8$Natural Language Inference#SNLI#% Train Accuracy#87.3$Natural Language Inference#SNLI#Parameters#2.1m
1607.04492v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#87.3$Natural Language Inference#SNLI#% Train Accuracy#88.5$Natural Language Inference#SNLI#Parameters#3.2m$Natural Language Inference#SNLI#% Test Accuracy#83.4$Natural Language Inference#SNLI#% Train Accuracy#82.5$Natural Language Inference#SNLI#Parameters#4.0m
1809.02279v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#87$Paraphrase Identification#Quora Question Pairs#Accuracy#88.6$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.3$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#53.6
1606.01933v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.8$Natural Language Inference#SNLI#% Train Accuracy#90.5$Natural Language Inference#SNLI#Parameters#580k$Natural Language Inference#SNLI#% Test Accuracy#86.3$Natural Language Inference#SNLI#% Train Accuracy#89.5$Natural Language Inference#SNLI#Parameters#380k
1404.2188v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.8
1812.01216v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.73
1804.07983v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.7$Natural Language Inference#SNLI#% Train Accuracy#91.6$Natural Language Inference#SNLI#Parameters#9m
1806.09828v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.6$Natural Language Inference#SNLI#% Train Accuracy#94.9$Natural Language Inference#SNLI#Parameters#65m$Sentiment Analysis#Yelp Fine-grained classification#Error#33.45
1808.08762v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.6$Natural Language Inference#SNLI#% Train Accuracy#89.9$Natural Language Inference#SNLI#Parameters#22m$Natural Language Inference#SciTail#Accuracy#86.0
1801.10296v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.3$Natural Language Inference#SNLI#% Train Accuracy#92.6$Natural Language Inference#SNLI#Parameters#3.1m
1712.02047v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.3$Natural Language Inference#SNLI#% Train Accuracy#89.6$Natural Language Inference#SNLI#Parameters#4.7m
1601.06733v7.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.3$Natural Language Inference#SNLI#% Train Accuracy#88.5$Natural Language Inference#SNLI#Parameters#3.4m$Natural Language Inference#SNLI#% Test Accuracy#85.7$Natural Language Inference#SNLI#% Train Accuracy#87.3$Natural Language Inference#SNLI#Parameters#1.7m
1512.08849v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.1$Natural Language Inference#SNLI#% Train Accuracy#92.0$Natural Language Inference#SNLI#Parameters#1.9m
1707.02786v4.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.0$Natural Language Inference#SNLI#% Train Accuracy#93.1$Natural Language Inference#SNLI#Parameters#10m$Natural Language Inference#SNLI#% Test Accuracy#85.6$Natural Language Inference#SNLI#% Train Accuracy#91.2$Natural Language Inference#SNLI#Parameters#2.9m
1708.02312v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.0$Natural Language Inference#SNLI#% Train Accuracy#91.0$Natural Language Inference#SNLI#Parameters#29m$Natural Language Inference#SNLI#% Test Accuracy#85.7$Natural Language Inference#SNLI#% Train Accuracy#89.8$Natural Language Inference#SNLI#Parameters#9.7m
1902.09113v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#86.0$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#53.0
1709.04696v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#85.6$Natural Language Inference#SNLI#% Train Accuracy#91.1$Natural Language Inference#SNLI#Parameters#2.4m
1708.01353v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#85.5$Natural Language Inference#SNLI#% Train Accuracy#90.5$Natural Language Inference#SNLI#Parameters#12m
1605.05573v2.pdf	Natural Language Inference#SNLI#% Test Accuracy#85.1$Natural Language Inference#SNLI#% Train Accuracy#86.7$Natural Language Inference#SNLI#Parameters#190k
1605.09090v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#85.0$Natural Language Inference#SNLI#% Train Accuracy#85.9$Natural Language Inference#SNLI#Parameters#2.8m$Natural Language Inference#SNLI#% Test Accuracy#84.2$Natural Language Inference#SNLI#% Train Accuracy#84.5$Natural Language Inference#SNLI#% Test Accuracy#83.3$Natural Language Inference#SNLI#% Train Accuracy#86.4$Natural Language Inference#SNLI#Parameters#2.0m
1811.00706v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#84.8$Natural Language Inference#SNLI#% Test Accuracy#84.5$Natural Language Inference#SNLI#% Test Accuracy#84.4$Natural Language Inference#MultiNLI#Matched#71.4$Natural Language Inference#MultiNLI#Mismatched#72.2$Natural Language Inference#MultiNLI#Matched#70.7$Natural Language Inference#MultiNLI#Mismatched#71.1$Natural Language Inference#MultiNLI#Mismatched#70.5$Fake News Detection#FNC-1#Weighted Accuracy#82.23$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#51.34$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#10.33$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#81.52$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#96.74
1705.02364v5.pdf	Natural Language Inference#SNLI#% Test Accuracy#84.5$Natural Language Inference#SNLI#% Train Accuracy#85.6$Natural Language Inference#SNLI#Parameters#40m$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-French#Accuracy#67.7%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-French#Accuracy#60.3%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-Spanish#Accuracy#68.7%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-Spanish#Accuracy#60.7%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-German#Accuracy#67.7%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-German#Accuracy#61.0%$Semantic Textual Similarity#SentEval#MRPC#76.2/83.1$Semantic Textual Similarity#SentEval#SICK-R#0.884$Semantic Textual Similarity#SentEval#SICK-E#86.3$Semantic Textual Similarity#SentEval#STS#75.8/75.5$Semantic Textual Similarity#MRPC#Accuracy#76.2%$Semantic Textual Similarity#MRPC#F1#83.1%
1509.06664v4.pdf	Natural Language Inference#SNLI#% Test Accuracy#83.5$Natural Language Inference#SNLI#% Train Accuracy#85.3$Natural Language Inference#SNLI#Parameters#250k
1603.06021v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#83.2$Natural Language Inference#SNLI#% Train Accuracy#89.2$Natural Language Inference#SNLI#Parameters#3.7m$Natural Language Inference#SNLI#% Test Accuracy#80.6$Natural Language Inference#SNLI#% Train Accuracy#83.9$Natural Language Inference#SNLI#Parameters#3.0m
1512.08422v3.pdf	Natural Language Inference#SNLI#% Test Accuracy#82.1$Natural Language Inference#SNLI#% Train Accuracy#83.3$Natural Language Inference#SNLI#Parameters#3.5m
1511.06361v6.pdf	Natural Language Inference#SNLI#% Test Accuracy#81.4$Natural Language Inference#SNLI#% Train Accuracy#98.8$Natural Language Inference#SNLI#Parameters#15m
1908.01853v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#80.7$Named Entity Recognition#CoNLL 2003 (English)#F1#92.2$Named Entity Recognition#CoNLL 2003 (English)#F1#84.6$Intent Detection#ATIS#Accuracy#97.40$Intent Detection#ATIS#F1#0.952$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#27.3$Text Classification#TREC-6#Error#7.8$Text Classification#Yahoo! Answers#Accuracy#75.1
1508.05326v1.pdf	Natural Language Inference#SNLI#% Test Accuracy#78.2$Natural Language Inference#SNLI#% Train Accuracy#99.7$Natural Language Inference#SNLI#% Test Accuracy#77.6$Natural Language Inference#SNLI#% Train Accuracy#84.8$Natural Language Inference#SNLI#Parameters#220k$Natural Language Inference#SNLI#% Test Accuracy#50.4$Natural Language Inference#SNLI#% Train Accuracy#49.4
1908.04577v3.pdf	Natural Language Inference#QNLI#Accuracy#99.2%$Natural Language Inference#WNLI#Accuracy#89.7%$Natural Language Inference#RTE#Accuracy#88.7%$Natural Language Inference#MultiNLI#Matched#91.1$Natural Language Inference#MultiNLI#Mismatched#90.7$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.928$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.924$Semantic Textual Similarity#MRPC#Accuracy#91.5%$Semantic Textual Similarity#MRPC#F1#93.6%$Paraphrase Identification#WikiHop#Accuracy#90.7%$Paraphrase Identification#Quora Question Pairs#Accuracy#90.7$Paraphrase Identification#Quora Question Pairs#F1#74.4$Sentiment Analysis#SST-2 Binary classification#Accuracy#97.1$Linguistic Acceptability#CoLA#Accuracy#69.2%
2208.07339v1.pdf	Natural Language Inference#QNLI#Accuracy#94.7%$Natural Language Inference#RTE#Accuracy#85.4%$Natural Language Inference#MultiNLI#Matched#90.2$Language Modelling#C4#Perplexity#12.45$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.919$Semantic Textual Similarity#MRPC#Accuracy#91.0%$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.4$Linguistic Acceptability#CoLA#Accuracy#68.6%
2003.07000v1.pdf	Natural Language Inference#QNLI#Accuracy#94.08%$Paraphrase Identification#Quora Question Pairs#Accuracy#88.28$Text Classification#GLUE SST2#Accuracy#94.38$Text Classification#GLUE COLA#Accuracy#64.81$Text Classification#GLUE MRPC#Accuracy#90.45$Text Classification#GLUE RTE#Accuracy#79.78$Text Classification#GLUE STSB#Accuracy#90.43
2012.11747v3.pdf	Natural Language Inference#QNLI#Accuracy#91.89%$Natural Language Inference#RTE#Accuracy#73.65%$Natural Language Inference#MultiNLI#Matched#86.28$Natural Language Inference#MultiNLI#Mismatched#86.34$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.9011$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8988$Semantic Textual Similarity#MRPC#Accuracy#87.01%$Semantic Textual Similarity#MRPC#F1#90.91%$Paraphrase Identification#Quora Question Pairs#Accuracy#91.34$Paraphrase Identification#Quora Question Pairs#F1#88.28$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.04$Linguistic Acceptability#CoLA#Accuracy#59.83%
2106.12672v3.pdf	Natural Language Inference#QNLI#Accuracy#91.0%$Natural Language Inference#MultiNLI#Matched#83.7$Natural Language Inference#MultiNLI#Mismatched#84.4$Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.873$Semantic Textual Similarity#MRPC#Accuracy#87.5%$Semantic Textual Similarity#MRPC#F1#91.4$Paraphrase Identification#Quora Question Pairs#Accuracy#91.4$Paraphrase Identification#Quora Question Pairs#F1#88.5$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.6$Linguistic Acceptability#CoLA#Accuracy#51.8%
2102.03902v3.pdf	Natural Language Inference#QNLI#Accuracy#88.7%$Semantic Textual Similarity#MRPC#F1#88.1%$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.4$Sentiment Analysis#IMDb#Accuracy#93.2
2105.03824v4.pdf	Natural Language Inference#QNLI#Accuracy#85%$Natural Language Inference#RTE#Accuracy#69%$Natural Language Inference#MultiNLI#Matched#88$Natural Language Inference#MultiNLI#Mismatched#88$Natural Language Inference#MultiNLI#Matched#78$Natural Language Inference#MultiNLI#Mismatched#76$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.84$Semantic Textual Similarity#MRPC#Accuracy#88%$Paraphrase Identification#Quora Question Pairs#F1#85$Sentiment Analysis#SST-2 Binary classification#Accuracy#94$Linguistic Acceptability#CoLA#Accuracy#78%
2210.14814v1.pdf	Natural Language Inference#BioNLI#Macro F1#0.77
1904.09482v1.pdf	Natural Language Inference#MultiNLI#Matched#87.9$Natural Language Inference#MultiNLI#Mismatched#87.4$Semantic Textual Similarity#SentEval#MRPC#92.7/90.3$Semantic Textual Similarity#SentEval#SICK-R#-$Semantic Textual Similarity#SentEval#SICK-E#-$Semantic Textual Similarity#SentEval#STS#91.1/90.7*$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.5
1810.02840v2.pdf	Natural Language Inference#MultiNLI#Matched#87.6$Natural Language Inference#MultiNLI#Mismatched#87.2$Semantic Textual Similarity#SentEval#MRPC#91.5/88.5$Semantic Textual Similarity#SentEval#SICK-R#-$Semantic Textual Similarity#SentEval#SICK-E#-$Semantic Textual Similarity#SentEval#STS#90.1/89.7*$Paraphrase Identification#Quora Question Pairs#Accuracy#89.9$Paraphrase Identification#Quora Question Pairs#F1#73.1$Sentiment Analysis#SST-2 Binary classification#Accuracy#96.2
1804.07461v3.pdf	Natural Language Inference#MultiNLI#Matched#72.2$Natural Language Inference#MultiNLI#Mismatched#72.1
1804.00079v1.pdf	Natural Language Inference#MultiNLI#Matched#71.4$Natural Language Inference#MultiNLI#Mismatched#71.3$Semantic Textual Similarity#SentEval#MRPC#78.6/84.4$Semantic Textual Similarity#SentEval#SICK-R#0.888$Semantic Textual Similarity#SentEval#SICK-E#87.8$Semantic Textual Similarity#SentEval#STS#78.9/78.6$Semantic Textual Similarity#MRPC#Accuracy#78.6%$Semantic Textual Similarity#MRPC#F1#84.4%$Paraphrase Identification#Quora Question Pairs#Accuracy#87.01
1901.06706v1.pdf	Visual Entailment#SNLI-VE test#Accuracy#70.47$Visual Entailment#SNLI-VE val#Accuracy#70.81
2107.06383v1.pdf	Visual Entailment#SNLI-VE val#Accuracy#80.20
2006.06195v2.pdf	Visual Entailment#SNLI-VE val#Accuracy#80.18
2008.03156v1.pdf	Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-French#Accuracy#84.7%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-Spanish#Accuracy#85.2%$Cross-Lingual Natural Language Inference#XNLI Zero-Shot English-to-German#Accuracy#84.2%$Text Summarization#GigaWord#ROUGE-1#40.45$Text Summarization#GigaWord#ROUGE-2#20.69$Text Summarization#GigaWord#ROUGE-L#36.56$Text Summarization#Reddit TIFU#ROUGE-1#30.31$Text Summarization#Reddit TIFU#ROUGE-2#10.98$Text Summarization#Reddit TIFU#ROUGE-L#24.74$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.38$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.53$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.17
1904.08378v1.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.940$Language Modelling#enwik8#Number of params#277M$Language Modelling#Hutter Prize#Bit per Character (BPC)#0.94$Language Modelling#Hutter Prize#Number of params#277M$Language Modelling#Text8#Bit per Character (BPC)#1.038$Language Modelling#Text8#Number of params#277M$Language Modelling#WikiText-103#Validation perplexity#15.8$Language Modelling#WikiText-103#Test perplexity#16.4$Language Modelling#WikiText-103#Number of params#257M$Language Modelling#WikiText-103#Validation perplexity#16.3$Language Modelling#WikiText-103#Test perplexity#17.0
2105.06548v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.95$Language Modelling#enwik8#Number of params#208M
2102.12459v3.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.95$Language Modelling#enwik8#Number of params#195M$Language Modelling#enwik8#Bit per Character (BPC)#0.97$Language Modelling#enwik8#Number of params#108M$Language Modelling#One Billion Word#PPL#23.5$Language Modelling#One Billion Word#Number of params#465M$Language Modelling#One Billion Word#PPL#25.1$Language Modelling#One Billion Word#Number of params#328M$Language Modelling#WikiText-103#Validation perplexity#16.4$Language Modelling#WikiText-103#Test perplexity#17.1$Language Modelling#WikiText-103#Number of params#234M$Language Modelling#WikiText-103#Validation perplexity#17.5$Language Modelling#WikiText-103#Test perplexity#18.3$Language Modelling#WikiText-103#Number of params#148M
2002.09402v3.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.96$Language Modelling#enwik8#Number of params#77M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.160$Language Modelling#Penn Treebank (Character Level)#Number of params#10.7M$Language Modelling#WikiText-103#Validation perplexity#17.5$Language Modelling#WikiText-103#Test perplexity#18.2$Language Modelling#WikiText-103#Number of params#139M$Language Modelling#WikiText-103#Validation perplexity#21.4$Language Modelling#WikiText-103#Test perplexity#22.4$Language Modelling#WikiText-103#Number of params#44M
1911.03864v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.968$Language Modelling#enwik8#Number of params#209M$Language Modelling#WikiText-103#Test perplexity#17.96$Language Modelling#WikiText-103#Number of params#247M
1911.05507v1.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.97$Language Modelling#enwik8#Number of params#277M$Language Modelling#Hutter Prize#Bit per Character (BPC)#0.97$Language Modelling#WikiText-103#Validation perplexity#16.0$Language Modelling#WikiText-103#Test perplexity#17.1
2107.02192v3.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.97$Language Modelling#enwik8#Number of params#110M$Language Modelling#enwik8#Bit per Character (BPC)#0.99$Language Modelling#Text8 dev#Bit per Character (BPC)#1.03$Language Modelling#enwik8 dev#Bit per Character (BPC)#1.01$Language Modelling#Text8#Bit per Character (BPC)#1.09
1905.07799v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.98$Language Modelling#enwik8#Number of params#209M$Language Modelling#enwik8#Bit per Character (BPC)#1.02$Language Modelling#enwik8#Number of params#39M$Language Modelling#Text8#Bit per Character (BPC)#1.07$Language Modelling#Text8#Number of params#209M$Language Modelling#Text8#Bit per Character (BPC)#1.11$Language Modelling#Text8#Number of params#38M
1901.02860v3.pdf	Language Modelling#enwik8#Bit per Character (BPC)#0.99$Language Modelling#enwik8#Number of params#277M$Language Modelling#enwik8#Bit per Character (BPC)#1.03$Language Modelling#enwik8#Number of params#88M$Language Modelling#enwik8#Bit per Character (BPC)#1.06$Language Modelling#enwik8#Number of params#41M$Language Modelling#One Billion Word#PPL#21.8$Language Modelling#One Billion Word#Number of params#0.8B$Language Modelling#One Billion Word#PPL#23.5$Language Modelling#One Billion Word#Number of params#0.46B$Language Modelling#Hutter Prize#Bit per Character (BPC)#0.99$Language Modelling#Hutter Prize#Number of params#277M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.03$Language Modelling#Hutter Prize#Number of params#88M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.06$Language Modelling#Hutter Prize#Number of params#41M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#56.72$Language Modelling#Penn Treebank (Word Level)#Test perplexity#54.55$Language Modelling#Penn Treebank (Word Level)#Params#24M$Language Modelling#Text8#Bit per Character (BPC)#1.08$Language Modelling#Text8#Number of params#277M$Language Modelling#WikiText-103#Validation perplexity#18.2$Language Modelling#WikiText-103#Test perplexity#18.3$Language Modelling#WikiText-103#Number of params#257M$Language Modelling#WikiText-103#Validation perplexity#23.1$Language Modelling#WikiText-103#Test perplexity#24.0$Language Modelling#WikiText-103#Number of params#151M
1907.01470v1.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.01$Language Modelling#enwik8#Number of params#39M$Language Modelling#enwik8#Number of params#114M$Language Modelling#Text8#Bit per Character (BPC)#1.08$Language Modelling#Text8#Number of params#114M$Language Modelling#Text8#Bit per Character (BPC)#1.11$Language Modelling#Text8#Number of params#38M$Language Modelling#WikiText-103#Validation perplexity#19.7$Language Modelling#WikiText-103#Test perplexity#20.6$Language Modelling#WikiText-103#Number of params#133M
1808.04444v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.06$Language Modelling#enwik8#Number of params#235M$Language Modelling#enwik8#Bit per Character (BPC)#1.11$Language Modelling#enwik8#Number of params#44M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.06$Language Modelling#Hutter Prize#Number of params#235M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.11$Language Modelling#Hutter Prize#Number of params#44M$Language Modelling#Text8#Bit per Character (BPC)#1.13$Language Modelling#Text8#Number of params#235M$Language Modelling#Text8#Bit per Character (BPC)#1.18$Language Modelling#Text8#Number of params#44M
1911.11423v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.068$Language Modelling#enwik8#Number of params#54M$Language Modelling#enwik8#Bit per Character (BPC)#1.076$Language Modelling#enwik8#Number of params#52M$Language Modelling#enwik8#Bit per Character (BPC)#1.33$Language Modelling#enwik8#Number of params#51M
1909.01792v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.146$Language Modelling#enwik8#Number of params#48M$Language Modelling#enwik8#Bit per Character (BPC)#1.195$Language Modelling#WikiText-2#Validation perplexity#40.2$Language Modelling#WikiText-2#Test perplexity#38.6$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#WikiText-2#Validation perplexity#57.3$Language Modelling#WikiText-2#Test perplexity#55.1$Language Modelling#Hutter Prize#Bit per Character (BPC)#0.988$Language Modelling#Hutter Prize#Number of params#96M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.122$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.083$Language Modelling#Penn Treebank (Character Level)#Number of params#24M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.120$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#44.8$Language Modelling#Penn Treebank (Word Level)#Test perplexity#44.9$Language Modelling#Penn Treebank (Word Level)#Params#24M
1803.08240v1.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.232$Language Modelling#enwik8#Number of params#47M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.232$Language Modelling#Hutter Prize#Number of params#47M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.175$Language Modelling#Penn Treebank (Character Level)#Number of params#13.8M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.187$Language Modelling#WikiText-103#Validation perplexity#32.0$Language Modelling#WikiText-103#Test perplexity#33.0$Language Modelling#WikiText-103#Number of params#151M
1609.07959v3.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.24$Language Modelling#enwik8#Number of params#46M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.24$Language Modelling#Hutter Prize#Number of params#46M$Language Modelling#Text8#Bit per Character (BPC)#1.27$Language Modelling#Text8#Number of params#45M$Language Modelling#Text8#Bit per Character (BPC)#1.40
1705.08639v2.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.25$Language Modelling#enwik8#Number of params#47M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.245$Language Modelling#Hutter Prize#Number of params#47M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.277$Language Modelling#Hutter Prize#Number of params#27M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.190$Language Modelling#Penn Treebank (Character Level)#Number of params#27M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.193
1607.03474v5.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.27$Language Modelling#enwik8#Number of params#46M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.27$Language Modelling#Hutter Prize#Number of params#46M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.31$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#67.9$Language Modelling#Penn Treebank (Word Level)#Test perplexity#65.4$Language Modelling#Penn Treebank (Word Level)#Params#23M$Language Modelling#Text8#Bit per Character (BPC)#1.27$Language Modelling#Text8#Number of params#46M
1609.01704v7.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.32$Language Modelling#enwik8#Number of params#35M$Language Modelling#Text8#Bit per Character (BPC)#1.29$Language Modelling#Text8#Number of params#35M
1609.09106v4.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.34$Language Modelling#enwik8#Number of params#27M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.219$Language Modelling#Penn Treebank (Character Level)#Number of params#14.4M
1308.0850v5.pdf	Language Modelling#enwik8#Bit per Character (BPC)#1.67
2112.04184v1.pdf	Language Modelling#language-modeling-recommendation#1:1 Accuracy#48.8
1809.10853v3.pdf	Language Modelling#One Billion Word#PPL#23.02$Language Modelling#One Billion Word#Number of params#1.0B$Language Modelling#One Billion Word#Validation perplexity#22.92$Language Modelling#One Billion Word#PPL#23.91$Language Modelling#One Billion Word#Number of params#0.46B$Language Modelling#One Billion Word#Validation perplexity#23.83$Language Modelling#WikiText-103#Validation perplexity#17.97$Language Modelling#WikiText-103#Test perplexity#18.70$Language Modelling#WikiText-103#Number of params#247M
1602.02410v2.pdf	Language Modelling#One Billion Word#PPL#23.7$Language Modelling#One Billion Word#Number of params#43B$Language Modelling#One Billion Word#PPL#30.0$Language Modelling#One Billion Word#Number of params#1.04B$Language Modelling#One Billion Word#PPL#30.6$Language Modelling#One Billion Word#Number of params#1.8B
1811.02084v1.pdf	Language Modelling#One Billion Word#PPL#24.0$Language Modelling#One Billion Word#Number of params#4.9B
1612.08083v3.pdf	Language Modelling#One Billion Word#PPL#31.9$Language Modelling#WikiText-103#Validation perplexity#-$Language Modelling#WikiText-103#Test perplexity#37.2$Language Modelling#WikiText-103#Test perplexity#44.9
1703.10722v3.pdf	Language Modelling#One Billion Word#PPL#36.0
1312.3005v3.pdf	Language Modelling#One Billion Word#PPL#51.3$Language Modelling#One Billion Word#Number of params#20B
1412.1454v2.pdf	Language Modelling#One Billion Word#PPL#52.9$Language Modelling#One Billion Word#Number of params#33B
2107.11906v1.pdf	Language Modelling#One Billion Word#Number of params#53M$Language Modelling#One Billion Word#Validation perplexity#23.95$Language Modelling#One Billion Word#Number of params#144M$Language Modelling#One Billion Word#Validation perplexity#20.25
2201.11990v3.pdf	Language Modelling#LAMBADA#Accuracy#87.2$Sentence Completion#HellaSwag#Accuracy#82.4$Sentence Completion#HellaSwag#Accuracy#80.2
2103.10360v2.pdf	Language Modelling#LAMBADA#Accuracy#72.35$Language Modelling#LAMBADA#Accuracy#67.18$Language Modelling#WikiText-103#Test perplexity#11.33$Language Modelling#WikiText-103#Number of params#10000M$Language Modelling#WikiText-103#Test perplexity#12.22$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.7$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.4$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.4$Document Summarization#CNN / Daily Mail#ROUGE-1#44.7$Document Summarization#CNN / Daily Mail#ROUGE-2#21.4$Document Summarization#CNN / Daily Mail#ROUGE-L#41.4
2004.04662v4.pdf	Language Modelling#LAMBADA#Accuracy#54.34$Music Transcription#MusicNet#APS#78.02$Music Transcription#MusicNet#Number of params#3.06M
1610.08431v3.pdf	Language Modelling#LAMBADA#Accuracy#49.0
2009.04534v3.pdf	Language Modelling#enwiki8#Bit per Character (BPC)#1.11$Language Modelling#Text8#Bit per Character (BPC)#1.18$Language Modelling#WikiText-103#Test perplexity#18.4$Language Modelling#WikiText-103#Test perplexity#22.7$Paraphrase Identification#MRPC#Accuracy#89.2$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.6
2110.08633v7.pdf	Language Modelling#WikiText-2#Validation perplexity#15.69$Language Modelling#WikiText-2#Test perplexity#15.17$Language Modelling#WikiText-2#Number of params#1542M
1904.09408v2.pdf	Language Modelling#WikiText-2#Validation perplexity#37.7$Language Modelling#WikiText-2#Test perplexity#34.1$Language Modelling#WikiText-2#Number of params#395M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#36.1$Language Modelling#Penn Treebank (Word Level)#Test perplexity#31.3$Language Modelling#Penn Treebank (Word Level)#Params#395M$Language Modelling#WikiText-103#Validation perplexity#19.6$Language Modelling#WikiText-103#Test perplexity#20.4$Language Modelling#WikiText-103#Number of params#395M
1808.05908v4.pdf	Language Modelling#WikiText-2#Validation perplexity#42.0$Language Modelling#WikiText-2#Test perplexity#40.3$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.169$Language Modelling#Penn Treebank (Character Level)#Number of params#13.8M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#48.0$Language Modelling#Penn Treebank (Word Level)#Test perplexity#47.3$Language Modelling#Penn Treebank (Word Level)#Params#22M
1708.08863v2.pdf	Language Modelling#WikiText-2#Validation perplexity#42.19$Language Modelling#WikiText-2#Test perplexity#40.46$Language Modelling#WikiText-2#Number of params#38M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#46.64$Language Modelling#Penn Treebank (Word Level)#Test perplexity#46.34$Language Modelling#Penn Treebank (Word Level)#Params#26M
1711.03953v4.pdf	Language Modelling#WikiText-2#Validation perplexity#42.41$Language Modelling#WikiText-2#Test perplexity#40.68$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#WikiText-2#Validation perplexity#63.88$Language Modelling#WikiText-2#Test perplexity#61.45$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#48.33$Language Modelling#Penn Treebank (Word Level)#Test perplexity#47.69$Language Modelling#Penn Treebank (Word Level)#Params#22M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#56.54$Language Modelling#Penn Treebank (Word Level)#Test perplexity#54.44
1709.07432v2.pdf	Language Modelling#WikiText-2#Validation perplexity#46.4$Language Modelling#WikiText-2#Test perplexity#44.3$Language Modelling#WikiText-2#Number of params#33M$Language Modelling#Hutter Prize#Bit per Character (BPC)#1.08$Language Modelling#Hutter Prize#Number of params#46M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#51.6$Language Modelling#Penn Treebank (Word Level)#Test perplexity#51.1$Language Modelling#Penn Treebank (Word Level)#Params#24M$Language Modelling#Text8#Bit per Character (BPC)#1.19$Language Modelling#Text8#Number of params#45M
1708.02182v1.pdf	Language Modelling#WikiText-2#Validation perplexity#53.8$Language Modelling#WikiText-2#Test perplexity#52.0$Language Modelling#WikiText-2#Number of params#33M$Language Modelling#WikiText-2#Validation perplexity#68.6$Language Modelling#WikiText-2#Test perplexity#65.8$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#53.9$Language Modelling#Penn Treebank (Word Level)#Test perplexity#52.8$Language Modelling#Penn Treebank (Word Level)#Params#24M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#60.0$Language Modelling#Penn Treebank (Word Level)#Test perplexity#57.3
1808.10143v2.pdf	Language Modelling#WikiText-2#Validation perplexity#54.19$Language Modelling#WikiText-2#Test perplexity#53.09$Language Modelling#WikiText-2#Number of params#185M$Language Modelling#WikiText-2#Validation perplexity#60.29$Language Modelling#WikiText-2#Test perplexity#58.03$Language Modelling#WikiText-2#Number of params#37M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#48.63$Language Modelling#Penn Treebank (Word Level)#Test perplexity#47.17$Language Modelling#Penn Treebank (Word Level)#Params#185M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#54.12$Language Modelling#Penn Treebank (Word Level)#Test perplexity#52.38$Language Modelling#Penn Treebank (Word Level)#Params#23M$Constituency Parsing#Penn Treebank#F1 score#94.47
1903.04167v2.pdf	Language Modelling#WikiText-2#Validation perplexity#60.16$Language Modelling#WikiText-2#Test perplexity#57.85$Language Modelling#WikiText-2#Number of params#37M$Language Modelling#WikiText-2#Validation perplexity#62.38$Language Modelling#WikiText-2#Test perplexity#59.98$Language Modelling#WikiText-2#Number of params#35M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#53.79$Language Modelling#Penn Treebank (Word Level)#Test perplexity#52.0$Language Modelling#Penn Treebank (Word Level)#Params#23M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#55.89$Language Modelling#Penn Treebank (Word Level)#Test perplexity#53.92$Language Modelling#Penn Treebank (Word Level)#Params#22M
1711.00066v4.pdf	Language Modelling#WikiText-2#Validation perplexity#66.8$Language Modelling#WikiText-2#Test perplexity#64.1$Language Modelling#WikiText-2#Number of params#34M$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#58.9$Language Modelling#Penn Treebank (Word Level)#Test perplexity#56.8$Language Modelling#Penn Treebank (Word Level)#Params#24M
1909.08700v1.pdf	Language Modelling#WikiText-2#Validation perplexity#67.47$Language Modelling#WikiText-2#Test perplexity#64.73$Language Modelling#WikiText-2#Number of params#33M$Language Modelling#WikiText-103#Validation perplexity#31.92$Language Modelling#WikiText-103#Test perplexity#32.85
1707.05589v2.pdf	Language Modelling#WikiText-2#Validation perplexity#69.3$Language Modelling#WikiText-2#Test perplexity#65.9$Language Modelling#WikiText-2#Number of params#24M
1612.04426v1.pdf	Language Modelling#WikiText-2#Test perplexity#68.9$Language Modelling#WikiText-2#Test perplexity#99.3$Language Modelling#WikiText-103#Test perplexity#40.8$Language Modelling#WikiText-103#Test perplexity#44.8$Language Modelling#WikiText-103#Test perplexity#48.7
1611.01462v3.pdf	Language Modelling#WikiText-2#Validation perplexity#91.5$Language Modelling#WikiText-2#Test perplexity#87.0$Language Modelling#WikiText-2#Validation perplexity#92.3$Language Modelling#WikiText-2#Test perplexity#87.7$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#68.1$Language Modelling#Penn Treebank (Word Level)#Test perplexity#66.0
2109.08668v2.pdf	Language Modelling#C4#Steps#1M$Language Modelling#C4#TPUv3 Hours#17.3K$Language Modelling#C4#Perplexity#12.35$Language Modelling#C4#TPUv3 Hours#16.5K$Language Modelling#C4#Perplexity#12.69$Language Modelling#C4#TPUv3 Hours#15.7K$Language Modelling#C4#Perplexity#13.25
2202.10447v2.pdf	Language Modelling#Wiki-40B#Perplexity#14.998
1810.06682v2.pdf	Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.158$Language Modelling#Penn Treebank (Character Level)#Number of params#13.4M$Language Modelling#Penn Treebank (Word Level)#Test perplexity#54.19$Language Modelling#WikiText-103#Test perplexity#29.19$Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#73.42%
1611.01578v2.pdf	Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.214$Language Modelling#Penn Treebank (Character Level)#Number of params#16.3M$Language Modelling#Penn Treebank (Word Level)#Test perplexity#64.0$Language Modelling#Penn Treebank (Word Level)#Params#25M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.4$Neural Architecture Search#CIFAR-10 Image Classification#Params#27.6M$Image Classification#CIFAR-10#Percentage correct#96.4
1907.05572v1.pdf	Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.24$Language Modelling#Penn Treebank (Word Level)#Test perplexity#84.38$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.1%$Music Modeling#Nottingham#NLL#2.37$Music Modeling#Nottingham#NLL#3.34
1803.01271v2.pdf	Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.31$Language Modelling#Penn Treebank (Word Level)#Test perplexity#78.93$Language Modelling#Penn Treebank (Word Level)#Test perplexity#92.48$Language Modelling#WikiText-103#Test perplexity#45.19$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.0%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#97.2%$Music Modeling#JSB Chorales#NLL#8.10$Music Modeling#Nottingham#NLL#3.07$Music Modeling#Nottingham#NLL#3.29$Music Modeling#Nottingham#NLL#3.46$Music Modeling#Nottingham#NLL#4.05
1905.10347v1.pdf	Language Modelling#Penn Treebank (Character Level)#Bit per Character (BPC)#1.38$Language Modelling#Text8#Bit per Character (BPC)#1.23
1805.09208v2.pdf	Language Modelling#Penn Treebank (Word Level)#Validation perplexity#57.1$Language Modelling#Penn Treebank (Word Level)#Test perplexity#55.3$Language Modelling#Penn Treebank (Word Level)#Params#24M
1806.09055v2.pdf	Language Modelling#Penn Treebank (Word Level)#Validation perplexity#58.3$Language Modelling#Penn Treebank (Word Level)#Test perplexity#56.1$Language Modelling#Penn Treebank (Word Level)#Params#23M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.83$Neural Architecture Search#CIFAR-10 Image Classification#Params#3.4M$Neural Architecture Search#CIFAR-10 Image Classification#Search Time (GPU days)#4$Neural Architecture Search#ImageNet#Top-1 Error Rate#26.7$Neural Architecture Search#ImageNet#Accuracy#73.3$Neural Architecture Search#ImageNet#Params#4.9M$Neural Architecture Search#ImageNet#MACs#595M$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#16.43$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#16.32$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#10890$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#29902$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.76%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#4$Neural Architecture Search#CIFAR-10#Parameters#3.3$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#3%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#1.5
1909.01377v2.pdf	Language Modelling#Penn Treebank (Word Level)#Test perplexity#57.1$Language Modelling#Penn Treebank (Word Level)#Params#24M$Language Modelling#WikiText-103#Test perplexity#23.2$Language Modelling#WikiText-103#Number of params#110M$Language Modelling#WikiText-103#Test perplexity#29.0$Language Modelling#WikiText-103#Number of params#180M$Language Modelling#WikiText-103#Test perplexity#32.4$Language Modelling#WikiText-103#Number of params#138M
1802.03268v2.pdf	Language Modelling#Penn Treebank (Word Level)#Validation perplexity#60.8$Language Modelling#Penn Treebank (Word Level)#Test perplexity#58.6$Language Modelling#Penn Treebank (Word Level)#Params#24M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.89$Neural Architecture Search#CIFAR-10 Image Classification#Params#4.6M
1512.05287v5.pdf	Language Modelling#Penn Treebank (Word Level)#Validation perplexity#77.9$Language Modelling#Penn Treebank (Word Level)#Test perplexity#75.2$Language Modelling#Penn Treebank (Word Level)#Validation perplexity#81.9$Language Modelling#Penn Treebank (Word Level)#Test perplexity#79.7
1603.09025v5.pdf	Language Modelling#Text8#Bit per Character (BPC)#1.36$Language Modelling#Text8#Number of params#16M$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#95.4%
1602.08210v3.pdf	Language Modelling#Text8#Bit per Character (BPC)#1.49$Language Modelling#Text8#Bit per Character (BPC)#1.63
1911.00172v2.pdf	Language Modelling#WikiText-103#Validation perplexity#15.81$Language Modelling#WikiText-103#Test perplexity#15.79$Language Modelling#WikiText-103#Number of params#247M
2004.14996v2.pdf	Language Modelling#WikiText-103#Test perplexity#17.1$Language Modelling#WikiText-103#Number of params#257M
1906.01702v1.pdf	Language Modelling#WikiText-103#Test perplexity#17.4$Language Modelling#WikiText-103#Number of params#257M
2012.15832v2.pdf	Language Modelling#WikiText-103#Validation perplexity#16.89$Language Modelling#WikiText-103#Test perplexity#17.56$Language Modelling#WikiText-103#Number of params#247M$Language Modelling#WikiText-103#Validation perplexity#17.47$Language Modelling#WikiText-103#Test perplexity#18.15
2104.09987v3.pdf	Language Modelling#WikiText-103#Test perplexity#18.0$Image Classification#ImageNet#Top 1 Accuracy#82.0
2111.00396v3.pdf	Language Modelling#WikiText-103#Test perplexity#21.28$Language Modelling#WikiText-103#Number of params#249M$Long-range modeling#LRA#ListOps#58.35$Long-range modeling#LRA#Text#76.02$Long-range modeling#LRA#Retrieval#87.09$Long-range modeling#LRA#Image#87.26$Long-range modeling#LRA#Pathfinder#86.05$Long-range modeling#LRA#Avg#80.48$Long-range modeling#LRA#Pathfinder-X#88.1$Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#91.13%$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.63%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.70%
2104.03474v1.pdf	Language Modelling#WikiText-103#Validation perplexity#24.1$Language Modelling#WikiText-103#Test perplexity#25.2$Language Modelling#WikiText-103#Number of params#148M
2107.10932v1.pdf	Language Modelling#WikiText-103#Test perplexity#25.81$Language Modelling#WikiText-103#Number of params#144.4M
1803.10049v1.pdf	Language Modelling#WikiText-103#Validation perplexity#29.0$Language Modelling#WikiText-103#Test perplexity#29.2$Language Modelling#WikiText-103#Validation perplexity#29.9$Language Modelling#WikiText-103#Test perplexity#29.7$Language Modelling#WikiText-103#Validation perplexity#34.1$Language Modelling#WikiText-103#Test perplexity#34.3$Language Modelling#WikiText-103#Validation perplexity#36.0$Language Modelling#WikiText-103#Test perplexity#36.4
1806.01822v2.pdf	Language Modelling#WikiText-103#Validation perplexity#30.8$Language Modelling#WikiText-103#Test perplexity#31.6
2005.08199v2.pdf	Language Modelling#WikiText-103#Validation perplexity#52.73$Language Modelling#WikiText-103#Validation perplexity#53.78$Language Modelling#WikiText-103#Validation perplexity#76.67
2209.10052v1.pdf	Long-range modeling#SCROLLS#GovRep#59.4 / 29.8 / 30.8$Long-range modeling#SCROLLS#SumScr#37.7 / 10.2 / 21.5$Long-range modeling#SCROLLS#QMSum#35.1 / 11.0 / 22.0$Long-range modeling#SCROLLS#Qspr#48.7$Long-range modeling#SCROLLS#Nrtv#26.2$Long-range modeling#SCROLLS#QALT EM-T/H#37.8 / 34.0$Long-range modeling#SCROLLS#CNLI#87.1$Long-range modeling#SCROLLS#Avg.#39.76$Text Summarization#GovReport#ROUGE-1#62.0$Text Summarization#arXiv#ROUGE-1#50.2$Text Summarization#QMSum#ROUGE-1#37.9$Text Summarization#Pubmed#ROUGE-1#50.3$Text Summarization#BookSum#ROUGE#38.5
2208.00748v1.pdf	Long-range modeling#SCROLLS#GovRep#57.5 / 26.3 / 27.4$Long-range modeling#SCROLLS#SumScr#35.2 / 8.7 / 19.4$Long-range modeling#SCROLLS#QMSum#34.2 / 11.0 / 22.0$Long-range modeling#SCROLLS#Qspr#46.9$Long-range modeling#SCROLLS#Nrtv#24.1$Long-range modeling#SCROLLS#QALT EM-T/H#34.8 / 34.8$Long-range modeling#SCROLLS#CNLI#87.3$Long-range modeling#SCROLLS#Avg.#37.99
2205.05131v2.pdf	Long-range modeling#SCROLLS#GovRep#53.6 / 26.1 / 28.8$Long-range modeling#SCROLLS#SumScr#32.9 / 7.8 / 19.4$Long-range modeling#SCROLLS#QMSum#31.1 / 8.5 / 20.4$Long-range modeling#SCROLLS#Qspr#37.6$Long-range modeling#SCROLLS#Nrtv#24.2$Long-range modeling#SCROLLS#QALT EM-T/H#45.8 / 40.7$Long-range modeling#SCROLLS#CNLI#88.7$Long-range modeling#SCROLLS#Avg.#37.87
2201.03533v2.pdf	Long-range modeling#SCROLLS#GovRep#56.2 / 26.6 / 28.8$Long-range modeling#SCROLLS#SumScr#24.2 / 4.5 / 15.4$Long-range modeling#SCROLLS#QMSum#25.1 / 6.7 / 18.8$Long-range modeling#SCROLLS#Qspr#26.6$Long-range modeling#SCROLLS#Nrtv#18.5$Long-range modeling#SCROLLS#QALT EM-T/H#25.8 / 25.4$Long-range modeling#SCROLLS#CNLI#71.5$Long-range modeling#SCROLLS#Avg.#29.16$Long-range modeling#SCROLLS#GovRep#47.9 / 18.6 / 22.7$Long-range modeling#SCROLLS#SumScr#27.2 / 4.9 / 16.7$Long-range modeling#SCROLLS#QMSum#30.2 / 8.7 / 20.7$Long-range modeling#SCROLLS#Qspr#26.3$Long-range modeling#SCROLLS#Nrtv#15.4$Long-range modeling#SCROLLS#QALT EM-T/H#26.0 / 25.9$Long-range modeling#SCROLLS#CNLI#77.4$Long-range modeling#SCROLLS#Avg.#29.01$Long-range modeling#SCROLLS#GovRep#45.3 / 17.9 / 20.8$Long-range modeling#SCROLLS#SumScr#19.6 / 1.8 / 11.0$Long-range modeling#SCROLLS#QMSum#14.2 / 2.0 / 9.3$Long-range modeling#SCROLLS#Qspr#3.4$Long-range modeling#SCROLLS#Nrtv#1.5$Long-range modeling#SCROLLS#QALT EM-T/H#25.2 / 26.1$Long-range modeling#SCROLLS#CNLI#66$Long-range modeling#SCROLLS#Avg.#19.35
2208.04347v1.pdf	Long-range modeling#SCROLLS#GovRep#60.3 / 30.0 / 31.5$Long-range modeling#SCROLLS#SumScr#35.7 / 9.1 / 20.6$Long-range modeling#SCROLLS#QMSum#33.2 / 9.6 / 21.6$Long-range modeling#SCROLLS#GovRep#59.3 / 29.3 / 30.9$Long-range modeling#SCROLLS#SumScr#35.0 / 8.9 / 20.4$Long-range modeling#SCROLLS#QMSum#32.9 / 9.8 / 21.4$Text Summarization#arXiv#ROUGE-1#50.0$Text Summarization#arXiv#ROUGE-2#21.8$Text Summarization#arXiv#ROUGE-L#44.6
2208.04933v2.pdf	Long-range modeling#LRA#ListOps#62.15$Long-range modeling#LRA#Text#89.31$Long-range modeling#LRA#Retrieval#91.4$Long-range modeling#LRA#Image#88$Long-range modeling#LRA#Pathfinder#95.33$Long-range modeling#LRA#Avg#87.46$Long-range modeling#LRA#Pathfinder-X#98.58
2209.12951v1.pdf	Long-range modeling#LRA#ListOps#62.75$Long-range modeling#LRA#Text#89.02$Long-range modeling#LRA#Retrieval#91.20$Long-range modeling#LRA#Image#89.50$Long-range modeling#LRA#Pathfinder#94.8$Long-range modeling#LRA#Avg#87.32$Long-range modeling#LRA#Pathfinder-X#96.66
2206.12037v2.pdf	Long-range modeling#LRA#ListOps#59.60$Long-range modeling#LRA#Text#86.82$Long-range modeling#LRA#Retrieval#90.90$Long-range modeling#LRA#Image#88.65$Long-range modeling#LRA#Pathfinder#94.20$Long-range modeling#LRA#Avg#86.09$Long-range modeling#LRA#Pathfinder-X#96.35
2206.11893v2.pdf	Long-range modeling#LRA#ListOps#60.52$Long-range modeling#LRA#Text#87.34$Long-range modeling#LRA#Retrieval#91.09$Long-range modeling#LRA#Image#88.19$Long-range modeling#LRA#Pathfinder#93.96$Long-range modeling#LRA#Avg#85.65$Long-range modeling#LRA#Pathfinder-X#92.80
2203.14343v3.pdf	Long-range modeling#LRA#ListOps#60.6$Long-range modeling#LRA#Text#84.8$Long-range modeling#LRA#Retrieval#87.8$Long-range modeling#LRA#Image#85.7$Long-range modeling#LRA#Pathfinder#84.6$Long-range modeling#LRA#Avg#81.88$Long-range modeling#LRA#Pathfinder-X#87.8
2201.02143v2.pdf	Long-range modeling#LRA#ListOps#60.6$Long-range modeling#LRA#Text#87.61$Long-range modeling#LRA#Retrieval#84.27$Long-range modeling#LRA#Image#64.49$Long-range modeling#LRA#Pathfinder#91.00$Long-range modeling#LRA#Avg#73.00$Long-range modeling#LRA#Pathfinder-X#50$Audio Classification#UCR Time Series Classification Archive#FruitFlies#97.09$Audio Classification#UCR Time Series Classification Archive#RightWhaleCalls#91.99$Audio Classification#UCR Time Series Classification Archive#MosquitoSound#91.54
2109.08184v1.pdf	Long-range modeling#LRA#ListOps#38.85$Long-range modeling#LRA#Text#77.32$Long-range modeling#LRA#Retrieval#76.51$Long-range modeling#LRA#Image#45.01$Long-range modeling#LRA#Pathfinder#80.49$Long-range modeling#LRA#Avg#63.64
2204.10670v1.pdf	Long-range modeling#LRA#ListOps#39.57$Long-range modeling#LRA#Text#83.32$Long-range modeling#LRA#Image#46.58$Long-range modeling#LRA#Pathfinder#80.49$Long-range modeling#LRA#Avg#62.49
2011.04006v1.pdf	Long-range modeling#LRA#ListOps#36.05$Long-range modeling#LRA#Text#64.02$Long-range modeling#LRA#Retrieval#59.29$Long-range modeling#LRA#Image#40.83$Long-range modeling#LRA#Pathfinder#74.87$Long-range modeling#LRA#Avg#55.01$Long-range modeling#LRA#ListOps#36.37$Long-range modeling#LRA#Text#64.27$Long-range modeling#LRA#Retrieval#57.46$Long-range modeling#LRA#Image#42.44$Long-range modeling#LRA#Pathfinder#71.4$Long-range modeling#LRA#Avg#54.39$Long-range modeling#LRA#ListOps#35.63$Long-range modeling#LRA#Text#62.85$Long-range modeling#LRA#Retrieval#56.89$Long-range modeling#LRA#Image#42.22$Long-range modeling#LRA#Pathfinder#69.71$Long-range modeling#LRA#Avg#53.46$Long-range modeling#LRA#ListOps#36.99$Long-range modeling#LRA#Text#61.68$Long-range modeling#LRA#Retrieval#54.67$Long-range modeling#LRA#Image#41.61$Long-range modeling#LRA#Pathfinder#69.45$Long-range modeling#LRA#Avg#52.88$Long-range modeling#LRA#ListOps#18.01$Long-range modeling#LRA#Text#65.4$Long-range modeling#LRA#Retrieval#53.82$Long-range modeling#LRA#Image#42.77$Long-range modeling#LRA#Pathfinder#77.05$Long-range modeling#LRA#Avg#51.41$Long-range modeling#LRA#ListOps#33.67$Long-range modeling#LRA#Text#61.2$Long-range modeling#LRA#Retrieval#53.83$Long-range modeling#LRA#Image#41.23$Long-range modeling#LRA#Pathfinder#67.45$Long-range modeling#LRA#Avg#51.39$Long-range modeling#LRA#ListOps#35.7$Long-range modeling#LRA#Text#53.94$Long-range modeling#LRA#Retrieval#52.27$Long-range modeling#LRA#Image#38.56$Long-range modeling#LRA#Pathfinder#76.34$Long-range modeling#LRA#Avg#51.36$Long-range modeling#LRA#ListOps#17.07$Long-range modeling#LRA#Text#63.58$Long-range modeling#LRA#Retrieval#59.59$Long-range modeling#LRA#Image#44.24$Long-range modeling#LRA#Pathfinder#71.71$Long-range modeling#LRA#Avg#51.24$Long-range modeling#LRA#ListOps#37.27$Long-range modeling#LRA#Text#56.1$Long-range modeling#LRA#Retrieval#53.4$Long-range modeling#LRA#Image#38.07$Long-range modeling#LRA#Pathfinder#68.5$Long-range modeling#LRA#Avg#50.67$Long-range modeling#LRA#ListOps#16.13$Long-range modeling#LRA#Text#65.9$Long-range modeling#LRA#Retrieval#53.09$Long-range modeling#LRA#Image#42.34$Long-range modeling#LRA#Pathfinder#75.3$Long-range modeling#LRA#Avg#50.55$Long-range modeling#LRA#ListOps#15.82$Long-range modeling#LRA#Text#52.98$Long-range modeling#LRA#Retrieval#53.39$Long-range modeling#LRA#Image#41.46$Long-range modeling#LRA#Pathfinder#66.63$Long-range modeling#LRA#Avg#46.06
1506.06726v1.pdf	Semantic Similarity#SICK#MSE#0.2687$Semantic Similarity#SICK#Pearson Correlation#0.8584$Semantic Similarity#SICK#Spearman Correlation#0.7916
1707.02377v1.pdf	Semantic Similarity#SICK#MSE#0.3053$Semantic Similarity#SICK#Pearson Correlation#0.8381$Semantic Similarity#SICK#Spearman Correlation#0.7621$Sentiment Analysis#IMDb#Accuracy#88.3
2101.00406v2.pdf	Cross-Document Language Modeling#MultiNews test#Perplexity#1.76$Cross-Document Language Modeling#MultiNews test#Perplexity#1.93$Cross-Document Language Modeling#MultiNews test#Perplexity#2.34$Cross-Document Language Modeling#MultiNews val#Perplexity#1.69$Cross-Document Language Modeling#MultiNews val#Perplexity#1.88$Cross-Document Language Modeling#MultiNews val#Perplexity#2.03
2204.13496v1.pdf	Speaker Identification#EVI pl-PL#Top-1 (%)#95.13$Speaker Identification#EVI en-GB#Top-1 (%)#67.77$Speaker Identification#EVI fr-FR#Top-1 (%)#80.83
2207.06405v2.pdf	Speaker Identification#VoxCeleb1#Top-1 (%)#94.8$Speaker Identification#VoxCeleb1#Accuracy#94.8$Speaker Identification#VoxCeleb1#Top-1 (%)#94.1$Speaker Identification#VoxCeleb1#Accuracy#94.1$Audio Classification#AudioSet#Test mAP#0.468
2204.12076v3.pdf	Speaker Identification#VoxCeleb1#Top-1 (%)#94.3$Speaker Identification#VoxCeleb1#Accuracy#94.3$Audio Classification#Balanced Audio Set#Mean AP#37.4$Spoken Command Recognition#Speech Command v2#Accuracy#98.0
2005.03215v2.pdf	Speaker Identification#VoxCeleb1#Top-1 (%)#87.66$Speaker Identification#VoxCeleb1#Top-5 (%)#96.01$Speaker Identification#VoxCeleb1#Number of Params#18M$Speaker Identification#VoxCeleb1#Accuracy#87.66
2110.09784v2.pdf	Speaker Identification#VoxCeleb1#Top-1 (%)#80.8$Speaker Identification#VoxCeleb1#Accuracy#80.8$Speaker Identification#VoxCeleb1#Top-1 (%)#64.2$Speaker Identification#VoxCeleb1#Accuracy#64.2$Audio Classification#Balanced Audio Set#Mean AP#31.0$Audio Classification#Balanced Audio Set#Mean AP#29.2$Spoken Command Recognition#Speech Command v2#Accuracy#98.1$Spoken Command Recognition#Speech Command v2#Accuracy#98.0
2010.10915v1.pdf	Speaker Identification#VoxCeleb1#Top-1 (%)#37.7$Speaker Identification#VoxCeleb1#Accuracy#37.7$Spoken Command Recognition#Speech Command v2#Accuracy#95.5
2110.04410v1.pdf	Speaker Diarization#AMI MixHeadset#DER(%)#1.73$Speaker Diarization#AMI MixHeadset#DER(%)#1.78$Speaker Diarization#AMI MixHeadset#DER(%)#1.79$Speaker Diarization#AMI MixHeadset#DER(%)#2.22$Speaker Diarization#AMI Lapel#DER(%)#1.99$Speaker Diarization#AMI Lapel#DER(%)#2.00$Speaker Diarization#AMI Lapel#DER(%)#2.03$Speaker Diarization#AMI Lapel#DER(%)#2.36$Speaker Diarization#CH109#DER(%)#1.11$Speaker Diarization#CH109#DER(%)#1.13$Speaker Diarization#CH109#DER(%)#1.19$Speaker Diarization#CH109#DER(%)#9.72$Speaker Diarization#NIST-SRE 2000#DER(%)#5.73$Speaker Diarization#NIST-SRE 2000#DER(%)#6.37$Speaker Diarization#NIST-SRE 2000#DER(%)#6.47$Speaker Diarization#NIST-SRE 2000#DER(%)#6.73$Speaker Diarization#NIST-SRE 2000#DER(%)#8.39
1911.01266v3.pdf	Speaker Diarization#DIHARD II#DER(%)#27.3$Speaker Diarization#DIHARD II#DER - no overlap#19.4
1810.04719v7.pdf	Speaker Diarization#Hub5'00 CallHome#V#10.6
1911.01255v1.pdf	Speaker Diarization#ETAPE#DER(%)#4.9$Speaker Diarization#ETAPE#FA#4.2$Speaker Diarization#ETAPE#Miss#0.7$Speaker Diarization#ETAPE#DER(%)#5.6$Speaker Diarization#ETAPE#FA#5.2$Speaker Diarization#ETAPE#Miss#0.4$Speaker Diarization#ETAPE#DER(%)#7.7$Speaker Diarization#ETAPE#FA#7.5$Speaker Diarization#ETAPE#Miss#0.2$Speaker Diarization#DIHARD#DER(%)#9.9$Speaker Diarization#DIHARD#FA#5.7$Speaker Diarization#DIHARD#Miss#4.2$Speaker Diarization#DIHARD#DER(%)#10.5$Speaker Diarization#DIHARD#FA#6.8$Speaker Diarization#DIHARD#Miss#3.7$Speaker Diarization#DIHARD#DER(%)#11.2$Speaker Diarization#DIHARD#FA#6.5$Speaker Diarization#DIHARD#Miss#4.7$Speaker Diarization#AMI#DER(%)#6.0$Speaker Diarization#AMI#FA#3.6$Speaker Diarization#AMI#Miss#2.4$Speaker Diarization#AMI#DER(%)#6.3$Speaker Diarization#AMI#FA#3.5$Speaker Diarization#AMI#Miss#2.7
1710.10468v7.pdf	Speaker Diarization#CALLHOME-109#DER(%)#12.54
2003.02405v1.pdf	Speaker Diarization#CALLHOME#DER(%)#7.29$Speaker Diarization#CALLHOME#DER(%)#8.39$Speaker Diarization#CALLHOME#DER(%)#8.78$Speaker Diarization#CALLHOME#DER(%)#21.13$Speaker Diarization#CALLHOME#DER(%)#24.05
1909.06247v1.pdf	Speaker Diarization#CALLHOME#DER(%)#10.76$Speaker Diarization#CALLHOME#FA#6.68$Speaker Diarization#CALLHOME#MI#2.40$Speaker Diarization#CALLHOME#CF#1.68$Speaker Diarization#CALLHOME#DER(%)#12.66$Speaker Diarization#CALLHOME#FA#7.42$Speaker Diarization#CALLHOME#MI#3.93$Speaker Diarization#CALLHOME#CF#1.31
2109.15053v2.pdf	Speaker Recognition#VoxCeleb1#EER#1.88
1710.10467v5.pdf	Speaker Verification#CALLHOME#Cosine EER#3.55$Speaker Verification#CALLHOME#Cosine EER#2.38
1806.05622v2.pdf	Speaker Verification#VoxCeleb2#EER#100
2111.02735v3.pdf	Speaker Verification#VoxCeleb1#EER#2.36$Speech Emotion Recognition#IEMOCAP#WA#0.796$Intent Classification#SLURP#Accuracy (%)#87.51$Slot Filling#SLURP#F1#0.753
2110.01077v3.pdf	Speaker Verification#VoxCeleb#EER#1.98
2104.01541v2.pdf	Speaker Verification#CN-CELEB#EER#10.12$Speaker Verification#CN-CELEB#EER#10.77
2107.05124v1.pdf	Product Recommendation#Coveo Data Challenge Dataset#MRR#0.2784$Product Recommendation#Coveo Data Challenge Dataset#F1#0.0748
2011.07457v1.pdf	Drug Discovery#QM9#Error ratio#0.38$Formation Energy#QM9#MAE#0.137
2003.03123v2.pdf	Drug Discovery#QM9#Error ratio#0.44$Formation Energy#QM9#MAE#0.185
1704.01212v2.pdf	Drug Discovery#QM9#Error ratio#0.68$Graph Regression#Lipophilicity#RMSE#0.719$Graph Regression#ZINC-500k#MAE#0.145$Graph Regression#ZINC-500k#MAE#0.252$Graph Regression#ZINC 100k#MAE#0.288$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#64.0$Formation Energy#QM9#MAE#0.49
1511.05493v4.pdf	Drug Discovery#QM9#Error ratio#1.36$Graph Classification#IPC-grounded#Accuracy#77.9%$Graph Classification#IPC-lifted#Accuracy#81.4%$SQL-to-Text#WikiSQL#BLEU-4#35.53$Node Classification#Cora (3%)#Accuracy#73.1%$Node Classification#CiteSeer (1%)#Accuracy#56.0%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#64.6%$Node Classification#PubMed (0.05%)#Accuracy#63.3%$Node Classification#PubMed (0.03%)#Accuracy#55.8%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#77.6%$Node Classification#Cora (0.5%)#Accuracy#48.2%$Node Classification#PubMed (0.1%)#Accuracy#70.4%$Node Classification#Cora (1%)#Accuracy#60.5%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#75.8%
1603.00856v3.pdf	Drug Discovery#QM9#Error ratio#2.59$Graph Regression#Lipophilicity#RMSE#0.715
1905.13343v2.pdf	Drug Discovery#Tox21#AUC#0.871
1806.04449v1.pdf	Drug Discovery#Tox21#AUC#0.862
1709.03741v2.pdf	Drug Discovery#Tox21#AUC#0.854$Drug Discovery#ToxCast#AUC#0.768$Drug Discovery#PCBA#AUC#0.867$Drug Discovery#MUV#AUC#0.845$Drug Discovery#HIV dataset#AUC#0.851
1509.09292v2.pdf	Drug Discovery#Tox21#AUC#0.846$Drug Discovery#ToxCast#AUC#0.754$Drug Discovery#PCBA#AUC#0.855$Drug Discovery#MUV#AUC#0.836$Drug Discovery#HIV dataset#AUC#0.822$Graph Regression#Lipophilicity#RMSE#0.655$Node Classification#Cora (3%)#Accuracy#71.7%$Node Classification#CiteSeer (1%)#Accuracy#54.3%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#61.5%$Node Classification#PubMed (0.05%)#Accuracy#63.2%$Node Classification#PubMed (0.03%)#Accuracy#56.2%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#74.6%$Node Classification#CiteSeer (0.5%)#Accuracy#43.9%$Node Classification#Cora (0.5%)#Accuracy#50.5%$Node Classification#PubMed (0.1%)#Accuracy#70.3%$Node Classification#Cora (1%)#Accuracy#59.6%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#76.0%
1706.02515v5.pdf	Drug Discovery#Tox21#AUC#0.845
1905.12265v3.pdf	Drug Discovery#Tox21#AUC#0.781$Drug Discovery#BACE#AUC#0.845$Drug Discovery#ToxCast#AUC#0.657$Drug Discovery#ClinTox#AUC#0.726$Drug Discovery#MUV#AUC#0.813$Drug Discovery#HIV dataset#AUC#0.799$Drug Discovery#SIDER#AUC#0.627$Drug Discovery#BBBP#AUC#0.687$Molecular Property Prediction#ClinTox#ROC-AUC#72.6$Molecular Property Prediction#SIDER#ROC-AUC#62.7$Molecular Property Prediction#QM7#MAE#113.2$Molecular Property Prediction#FreeSolv#RMSE#2.764$Molecular Property Prediction#QM8#MAE#0.0200$Molecular Property Prediction#ToxCast#ROC-AUC#65.7$Molecular Property Prediction#BACE#ROC-AUC#84.5$Molecular Property Prediction#Tox21#ROC-AUC#78.1$Molecular Property Prediction#Lipophilicity#RMSE#0.739$Molecular Property Prediction#BBBP#ROC-AUC#68.7$Molecular Property Prediction#QM9#MAE#0.00922
1903.02541v2.pdf	Drug Discovery#Tox21#AUC#0.748$Drug Discovery#MUV#AUC#0.648$Drug Discovery#HIV dataset#AUC#0.627
1909.13488v2.pdf	Drug Discovery#BACE#AUC#0.874$Drug Discovery#SIDER#AUC#0.685$Drug Discovery#PDBbind#RMSE#1.219
2006.04804v6.pdf	Drug Discovery#BACE#AUC#0.873$Drug Discovery#BBBP#AUC#0.92$Graph Regression#Lipophilicity#RMSE#0.580$Graph Regression#ESOL#RMSE#.594
1609.02907v4.pdf	Drug Discovery#Lipophilicity(scaffold)#RMSE#0.799$Drug Discovery#ToxCast(scaffold)#AUC#0.678$Drug Discovery#BACE(scaffold)#AUC#0.797$Document Classification#Cora#Accuracy#81.5%$Graph Regression#Tox21#AUC@80%Train#0.75$Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.1379$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.1398$Node Classification#Flickr#Accuracy#0.546$Node Classification#Flickr#Accuracy#0.479$Node Classification#Pubmed#Accuracy#79.0$Node Classification#Wiki-Vote#Accuracy#49.5$Node Classification#Wiki-Vote#Accuracy#32.9$Node Classification#USA Air-Traffic#Accuracy#43.2$Node Classification#Facebook#Accuracy#64.6$Node Classification#Facebook#Accuracy#57.5$Node Classification#Cora#Accuracy#83.0%$Node Classification#Brazil Air-Traffic#Accuracy#0.516$Node Classification#Brazil Air-Traffic#Accuracy#0.432$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#68.7$Node Classification#Citeseer#Accuracy#70.3$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#80.5%$Node Classification#NELL#Accuracy#66.0$Node Classification#Europe Air-Traffic#Accuracy#46.0$Node Classification#Europe Air-Traffic#Accuracy#37.1$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#77.8%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#82.46 ± 3.11$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#75.5 ± 2.92$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#83.11 ± 3.2$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#62.23±0.53$Link Property Prediction#ogbl-ppa#Test Hits@100#0.1867 ± 0.0132$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.1845 ± 0.0140$Link Property Prediction#ogbl-ppa#Number of params#278529$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.8474 ± 0.0021$Link Property Prediction#ogbl-citation2#Validation MRR#0.8479 ± 0.0023$Link Property Prediction#ogbl-citation2#Number of params#296449$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.6056 ± 0.0869$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.6776 ± 0.0095$Link Property Prediction#ogbl-ddi#Number of params#1421571$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.3707 ± 0.0507$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.5550 ± 0.0208$Link Property Prediction#ogbl-ddi#Number of params#1289985$Link Property Prediction#ogbl-collab#Test Hits@50#0.4714 ± 0.0145$Link Property Prediction#ogbl-collab#Validation Hits@50#0.5263 ± 0.0115$Link Property Prediction#ogbl-collab#Number of params#296449$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.4475 ± 0.0107$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.6857 ± 0.0061$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6511 ± 0.0048$Graph Property Prediction#ogbg-ppa#Number of params#1930537$Graph Property Prediction#ogbg-ppa#Ext. data#No$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.6839 ± 0.0084$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6497 ± 0.0034$Graph Property Prediction#ogbg-ppa#Number of params#479437$Graph Property Prediction#ogbg-molpcba#Test AP#0.2424 ± 0.0034$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2495 ± 0.0042$Graph Property Prediction#ogbg-molpcba#Number of params#2017028$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2020 ± 0.0024$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2059 ± 0.0033$Graph Property Prediction#ogbg-molpcba#Number of params#565928$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7606 ± 0.0097$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8204 ± 0.0141$Graph Property Prediction#ogbg-molhiv#Number of params#527701$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7599 ± 0.0119$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8384 ± 0.0091$Graph Property Prediction#ogbg-molhiv#Number of params#1978801$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7549 ± 0.0163$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8042 ± 0.0107$Graph Property Prediction#ogbg-code2#Test F1 score#0.1595 ± 0.0018$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1461 ± 0.0013$Graph Property Prediction#ogbg-code2#Number of params#12484310$Graph Property Prediction#ogbg-code2#Ext. data#No$Graph Property Prediction#ogbg-code2#Test F1 score#0.1507 ± 0.0018$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1399 ± 0.0017$Graph Property Prediction#ogbg-code2#Number of params#11033210
1907.11223v2.pdf	Drug Discovery#DRD2#Diversity#0.192$Drug Discovery#DRD2#Success#85.9%$Drug Discovery#QED#Diversity#0.477$Drug Discovery#QED#Success#76.9%
1906.05168v3.pdf	Drug Discovery#egfr-inh#AUC#0.91
2210.17401v1.pdf	Drug Response Prediction#GDSCv2#Pearson correlation coefficient (PCC)#0.93807$Drug Response Prediction#GDSCv2#mRMSE#0.0229
2204.11817v2.pdf	Text-based de novo Molecule Generation#ChEBI-20#Text2Mol#55.4$Text-based de novo Molecule Generation#ChEBI-20#BLEU#85.4$Text-based de novo Molecule Generation#ChEBI-20#Exact Match#30.2$Text-based de novo Molecule Generation#ChEBI-20#Levenshtein#16.07$Text-based de novo Molecule Generation#ChEBI-20#MACCS FTS#83.4$Text-based de novo Molecule Generation#ChEBI-20#RDK FTS#74.6$Text-based de novo Molecule Generation#ChEBI-20#Morgan FTS#68.4$Text-based de novo Molecule Generation#ChEBI-20#Frechet ChemNet Distance (FCD)#11.6$Text-based de novo Molecule Generation#ChEBI-20#Validity#90.5$Molecule Captioning#ChEBI-20#BLEU-2#59.4$Molecule Captioning#ChEBI-20#BLEU-4#50.8$Molecule Captioning#ChEBI-20#ROUGE-1#65$Molecule Captioning#ChEBI-20#ROUGE-2#50.9$Molecule Captioning#ChEBI-20#ROUGE-L#60.5$Molecule Captioning#ChEBI-20#METEOR#59.1$Molecule Captioning#ChEBI-20#Text2Mol#58.2
1908.10432v1.pdf	Seizure Detection#CHB-MIT#Accuracy#89.63%
2201.08780v2.pdf	Seizure Detection#TUH EEG Seizure Corpus#AUROC#0.92
2004.03500v2.pdf	Medical Diagnosis#BreastDICOM4#Average Precision#0.74$Medical Diagnosis#BreastDICOM4#Average Recall#0.68
2205.07139v1.pdf	Thoracic Disease Classification#ChestX-ray14#AUROC#78.33
2007.09483v4.pdf	Predicting Patient Outcomes#eICU Collaborative Research Database#Kappa#0.58
1806.11078v1.pdf	Ecg Risk Stratification#ngm#520#34.5
2012.04936v1.pdf	Atrial Fibrillation Detection#PhysioNet Challenge 2017#F1#0.8843$Atrial Fibrillation Detection#PhysioNet Challenge 2017#PR-AUC#0.9584$Atrial Fibrillation Detection#PhysioNet Challenge 2017#ROC-AUC#0.9550
1905.11333v3.pdf	Atrial Fibrillation Detection#PhysioNet Challenge 2017#F1#0.8342$Atrial Fibrillation Detection#PhysioNet Challenge 2017#PR-AUC#0.9436$Atrial Fibrillation Detection#PhysioNet Challenge 2017#ROC-AUC#0.9488
1812.07422v2.pdf	Atrial Fibrillation Detection#MIT-BIH AF#Accuracy#99.40%
1903.11775v1.pdf	Atrial Fibrillation Detection#MIT-BIH AF#Accuracy#93.16%
2101.03814v1.pdf	Skin Lesion Classification#ISIC 2019#Accuracy#0.634
1801.00318v2.pdf	Malware Classification#Malimg Dataset#Accuracy#0.8492$Malware Classification#Malimg Dataset#Accuracy#0.8047$Malware Classification#Malimg Dataset#Accuracy#0.7723
1807.08265v1.pdf	Malware Classification#Microsoft Malware Classification Challenge#Accuracy (5-fold)#98.20$Malware Classification#Microsoft Malware Classification Challenge#F1 score (5-fold)#96.05
1707.05005v1.pdf	Malware Detection#Android Malware Dataset#Accuracy#99.03$Graph Classification#NCI109#Accuracy#74.26$Graph Classification#PTC#Accuracy#60.17% ± 6.86%$Graph Classification#PROTEINS#Accuracy#73.3% ± 2.05%$Graph Classification#NCI1#Accuracy#73.22% ± 1.81%$Graph Classification#MUTAG#Accuracy#83.15% ± 9.25%
1702.06921v1.pdf	Malware Detection#Android Malware Dataset#Accuracy#76.83
2208.07049v1.pdf	Malware Detection#MalNet#F1 score#0.878$Malware Detection#MalNet#F1 score#0.876$Malware Detection#MalNet#F1 score#0.854
1903.00179v2.pdf	Saliency Detection#ECSSD#MAE#0.0328$Saliency Detection#DUT-OMRON#MAE#0.0414$Saliency Detection#PASCAL-S#MAE#0.0677$Saliency Detection#HKU-IS#MAE#0.0324$Saliency Detection#DUTS-test#MAE#0.0405
2008.11048v1.pdf	Saliency Detection#DUT-OMRON#MAE#0.051$Saliency Detection#HKU-IS#MAE#0.027$Salient Object Detection#HKU-IS#MAE#0.027$Salient Object Detection#HKU-IS#E-measure#0.953$Salient Object Detection#HKU-IS#max_F1#0.939$Salient Object Detection#HKU-IS#S-measure#0.919$Salient Object Detection#ECSSD#MAE#0.033$Salient Object Detection#ECSSD#max_F1#0.950$Salient Object Detection#ECSSD#S-measure#0.924$Salient Object Detection#ECSSD#E-measure#0.924$Salient Object Detection#DUTS-TE#MAE#0.034$Salient Object Detection#DUTS-TE#max_F1#0.897$Salient Object Detection#DUTS-TE#E-measure#0.909$Salient Object Detection#DUTS-TE#S-measure#0.892$Salient Object Detection#PASCAL-S#MAE#0.059$Salient Object Detection#PASCAL-S#max_F1#0.874$Salient Object Detection#PASCAL-S#S-measure#0.856$Salient Object Detection#PASCAL-S#E-measure#0.865$Salient Object Detection#DUT-OMRON#max_F1#0.819$Salient Object Detection#DUT-OMRON#MAE#0.051$Salient Object Detection#DUT-OMRON#E-measure#0.873$Salient Object Detection#DUT-OMRON#S-measure#0.838
2005.09007v3.pdf	Saliency Detection#DUT-OMRON#MAE#0.054$Saliency Detection#DUT-OMRON#MAE#0.06$Saliency Detection#DUT-OMRON#{max}Fβ#0.813$Saliency Detection#DUT-OMRON#Fwβ#0.731$Saliency Detection#DUT-OMRON#Sm#0.837$Saliency Detection#DUT-OMRON#relaxFbβ#0.676$Saliency Detection#HKU-IS#MAE#0.037$Saliency Detection#HKU-IS#{max}Fβ#0.928$Saliency Detection#HKU-IS#Fwβ#0.867$Saliency Detection#HKU-IS#Sm#0.908$Saliency Detection#HKU-IS#relaxFbβ#0.794$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.694$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.601$Dichotomous Image Segmentation#DIS-TE1#MAE#0.083$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.760$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.801$Dichotomous Image Segmentation#DIS-TE1#HCE#224$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.756$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.668$Dichotomous Image Segmentation#DIS-TE2#MAE#0.085$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.788$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.833$Dichotomous Image Segmentation#DIS-TE2#HCE#490$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.798$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.707$Dichotomous Image Segmentation#DIS-TE3#MAE#0.079$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.809$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.858$Dichotomous Image Segmentation#DIS-TE3#HCE#965$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.795$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.705$Dichotomous Image Segmentation#DIS-TE4#MAE#0.087$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.807$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.847$Dichotomous Image Segmentation#DIS-TE4#HCE#3653$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.748$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.656$Dichotomous Image Segmentation#DIS-VD#MAE#0.090$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.781$Dichotomous Image Segmentation#DIS-VD#E-measure#0.823$Dichotomous Image Segmentation#DIS-VD#HCE#1413$Salient Object Detection#SOD#{max}Fβ#0.841$Salient Object Detection#SOD#MAE#0.124$Salient Object Detection#SOD#Fwβ#0.697$Salient Object Detection#SOD#Sm#0.759$Salient Object Detection#SOD#relaxFbβ#0.559
1708.02031v1.pdf	Saliency Detection#DUT-OMRON#MAE#0.1203$RGB Salient Object Detection#DUTS-TE#MAE#0.116$RGB Salient Object Detection#DUTS-TE#F-measure#0.771
2110.03593v3.pdf	Saliency Prediction#MIT300#CC#0.807$Saliency Prediction#MIT300#SIM#0.6895$Saliency Prediction#MIT300#NSS#2.4134$Saliency Prediction#MIT300#sAUC#0.7467$Saliency Prediction#MIT300#AUC-Judd#0.8734$Saliency Prediction#MIT300#KLD#1.0141$Saliency Prediction#SALICON#CC#0.907$Saliency Prediction#SALICON#SIM#0.803$Saliency Prediction#SALICON#NSS#2.014$Saliency Prediction#SALICON#sAUC#0.747$Saliency Prediction#SALICON#AUC#0.868$Saliency Prediction#SALICON#KLD#0.373
2007.05104v1.pdf	Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - EUB#NSS#1.8831$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - EUB#AUC#0.8494$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - EUB#CC#0.7442$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 10-shot#NSS#1.6439$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 10-shot#AUC#0.8276$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 10-shot#CC#0.6605$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 5-shot#NSS#1.6085$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 5-shot#AUC#0.8200$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 5-shot#CC#0.6468$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#NSS#1.5077$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#AUC#0.8051$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#CC#0.6121$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#NSS#1.4272$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#AUC#0.7983$Few-Shot Transfer Learning for Saliency Prediction#SALICON->WebpageSaliency - 1-shot#CC#0.5817
2205.15469v3.pdf	Co-Salient Object Detection#CoSal2015#MAE#0.0563$Co-Salient Object Detection#CoSal2015#S-measure#0.881$Co-Salient Object Detection#CoSal2015#max F-measure#0.891$Co-Salient Object Detection#CoSal2015#max E-measure#0.924$Co-Salient Object Detection#CoSal2015#mean E-measure#0.902$Co-Salient Object Detection#CoSal2015#mean F-measure#0.870$Co-Salient Object Detection#CoCA#S-measure#0.738$Co-Salient Object Detection#CoCA#max F-measure#0.637$Co-Salient Object Detection#CoCA#mean E-measure#0.783$Co-Salient Object Detection#CoCA#Mean F-measure#0.612$Co-Salient Object Detection#CoCA#max E-measure#0.814$Co-Salient Object Detection#CoCA#MAE#0.081$Co-Salient Object Detection#CoSOD3k#S-measure#0.843$Co-Salient Object Detection#CoSOD3k#max E-measure#0.901$Co-Salient Object Detection#CoSOD3k#max F-measure#0.834$Co-Salient Object Detection#CoSOD3k#MAE#0.062$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.872$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.813
2110.00338v1.pdf	Co-Salient Object Detection#CoSal2015#MAE#0.064$Co-Salient Object Detection#CoSal2015#S-measure#0.866$Co-Salient Object Detection#CoSal2015#max F-measure#0.864$Co-Salient Object Detection#CoSal2015#max E-measure#0.906$Co-Salient Object Detection#CoSal2015#mean E-measure#0.874$Co-Salient Object Detection#CoSal2015#mean F-measure#0.825$Co-Salient Object Detection#CoCA#S-measure#0.68$Co-Salient Object Detection#CoCA#max F-measure#0.550$Co-Salient Object Detection#CoCA#mean E-measure#0.69$Co-Salient Object Detection#CoCA#Mean F-measure#0.503$Co-Salient Object Detection#CoCA#max E-measure#0.745$Co-Salient Object Detection#CoCA#MAE#0.133$Co-Salient Object Detection#CoSOD3k#S-measure#0.815$Co-Salient Object Detection#CoSOD3k#max E-measure#0.854$Co-Salient Object Detection#CoSOD3k#max F-measure#0.778$Co-Salient Object Detection#CoSOD3k#MAE#0.087$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.823$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.742
2203.05787v1.pdf	Co-Salient Object Detection#CoSal2015#MAE#0.067$Co-Salient Object Detection#CoSal2015#S-measure#0.838$Co-Salient Object Detection#CoSal2015#max F-measure#0.856$Co-Salient Object Detection#CoSal2015#max E-measure#0.893$Co-Salient Object Detection#CoSal2015#mean E-measure#0.889$Co-Salient Object Detection#CoSal2015#mean F-measure#0.850$Co-Salient Object Detection#CoCA#S-measure#0.710$Co-Salient Object Detection#CoCA#max F-measure#0.598$Co-Salient Object Detection#CoCA#mean E-measure#0.778$Co-Salient Object Detection#CoCA#Mean F-measure#0.593$Co-Salient Object Detection#CoCA#max E-measure#0.783$Co-Salient Object Detection#CoCA#MAE#0.085$Co-Salient Object Detection#CoSOD3k#S-measure#0.809$Co-Salient Object Detection#CoSOD3k#max E-measure#0.871$Co-Salient Object Detection#CoSOD3k#max F-measure#0.805$Co-Salient Object Detection#CoSOD3k#MAE#0.067$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.871$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.800
2104.01108v2.pdf	Co-Salient Object Detection#CoSal2015#MAE#0.068$Co-Salient Object Detection#CoSal2015#S-measure#0.845$Co-Salient Object Detection#CoSal2015#max F-measure#0.847$Co-Salient Object Detection#CoSal2015#max E-measure#0.888$Co-Salient Object Detection#CoSal2015#mean E-measure#0.884$Co-Salient Object Detection#CoSal2015#mean F-measure#0.838$Co-Salient Object Detection#CoCA#S-measure#0.673$Co-Salient Object Detection#CoCA#max F-measure#0.544$Co-Salient Object Detection#CoCA#mean E-measure#0.739$Co-Salient Object Detection#CoCA#Mean F-measure#0.531$Co-Salient Object Detection#CoCA#max E-measure#0.760$Co-Salient Object Detection#CoCA#MAE#0.105$Co-Salient Object Detection#CoSOD3k#S-measure#0.802$Co-Salient Object Detection#CoSOD3k#max E-measure#0.860$Co-Salient Object Detection#CoSOD3k#max F-measure#0.777$Co-Salient Object Detection#CoSOD3k#MAE#0.071$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.857$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.770
2004.13364v3.pdf	Co-Salient Object Detection#CoSal2015#MAE#0.071$Co-Salient Object Detection#CoSal2015#S-measure#0.844$Co-Salient Object Detection#CoSal2015#max F-measure#0.844$Co-Salient Object Detection#CoSal2015#max E-measure#0.887$Co-Salient Object Detection#CoSal2015#mean E-measure#0.883$Co-Salient Object Detection#CoSal2015#mean F-measure#0.835$Co-Salient Object Detection#CoCA#S-measure#0.658$Co-Salient Object Detection#CoCA#max F-measure#0.513$Co-Salient Object Detection#CoCA#mean E-measure#0.701$Co-Salient Object Detection#CoCA#Mean F-measure#0.504$Co-Salient Object Detection#CoCA#max E-measure#0.715$Co-Salient Object Detection#CoCA#MAE#0.126$Co-Salient Object Detection#CoSOD3k#S-measure#0.797$Co-Salient Object Detection#CoSOD3k#max E-measure#0.848$Co-Salient Object Detection#CoSOD3k#max F-measure#0.770$Co-Salient Object Detection#CoSOD3k#MAE#0.079$Co-Salient Object Detection#CoSOD3k#mean E-measure#0.845$Co-Salient Object Detection#CoSOD3k#mean F-measure#0.763
2007.03380v4.pdf	Co-Salient Object Detection#CoCA#S-measure#0.612$Co-Salient Object Detection#CoCA#max F-measure#0.493$Co-Salient Object Detection#CoCA#mean E-measure#0.679$Co-Salient Object Detection#CoCA#Mean F-measure#0.450$Co-Salient Object Detection#CoCA#max E-measure#0.717$Co-Salient Object Detection#CoCA#MAE#0.106
2012.06170v3.pdf	Video Saliency Detection#DIEM#CC#0.632$Video Saliency Detection#Hollywood2#CC#0.693$Video Saliency Detection#UCFSports#CC#0.673$Video Saliency Detection#DHF1K#NSS#2.87$Video Saliency Detection#DHF1K#CC#0.51$Video Saliency Detection#DHF1K#s-AUC#0.728$Video Saliency Detection#DHF1K#AUC-J#0.908
2010.01220v4.pdf	Video Saliency Detection#DHF1K#NSS#2.812$Video Saliency Detection#DHF1K#CC#0.503$Video Saliency Detection#DHF1K#s-AUC#0.70$Video Saliency Detection#DHF1K#AUC-J#0.908$Video Saliency Detection#DHF1K#SIM#0.406
1908.05786v1.pdf	Video Saliency Detection#DHF1K#NSS#2.667
2104.07886v2.pdf	Fraud Detection#Amazon-Fraud#AUC-ROC#96.19$Fraud Detection#Yelp-Fraud#AUC-ROC#83.54$Node Classification#Yelp-Fraud#AUC-ROC#83.54$Node Classification#Amazon-Fraud#AUC-ROC#96.19
2008.08692v1.pdf	Fraud Detection#Amazon-Fraud#AUC-ROC#89.73$Fraud Detection#Yelp-Fraud#AUC-ROC#75.70$Node Classification#Yelp-Fraud#AUC-ROC#75.70$Node Classification#Amazon-Fraud#AUC-ROC#89.73
2104.01404v2.pdf	Fraud Detection#Yelp-Fraud#AUC-ROC#90.04$Node Classification#Deezer Europe#1:1 Accuracy#67.22±0.90$Node Classification#Deezer Europe#1:1 Accuracy#67.21±0.56$Node Classification#Deezer Europe#1:1 Accuracy#66.90±0.50$Node Classification#Deezer Europe#1:1 Accuracy#66.80±0.58$Node Classification#Deezer Europe#1:1 Accuracy#66.55±0.72$Node Classification#Deezer Europe#1:1 Accuracy#64.60±0.57$Node Classification#Deezer Europe#1:1 Accuracy#64.52±0.62$Node Classification#Deezer Europe#1:1 Accuracy#62.23±0.53$Node Classification#Deezer Europe#1:1 Accuracy#61.56±0.51$Node Classification#Deezer Europe#1:1 Accuracy#61.09±0.77$Node Classification#Deezer Europe#1:1 Accuracy#60.99±0.14$Node Classification#Deezer Europe#1:1 Accuracy#59.73±0.12$Node Classification#Deezer Europe#1:1 Accuracy#59.66±0.92$Node Classification#Deezer Europe#1:1 Accuracy#57.71±0.36$Node Classification#Deezer Europe#1:1 Accuracy#56.96±0.26$Node Classification#Deezer Europe#1:1 Accuracy#56.50±0.41$Node Classification#Yelp-Fraud#AUC-ROC#90.04$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#93.87 ± 3.33$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#69.50 ± 3.12$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#62.50 ± 15.75$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.55±0.72$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#60.99±0.14$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#59.66±0.92$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#57.71±0.36$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#56.96±0.26$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#56.50±0.41
2010.04543v1.pdf	Hate Speech Detection#ToLD-Br#F1-score#0.75$Hate Speech Detection#ToLD-Br#F1-score#0.74
2106.15537v1.pdf	Hate Speech Detection#Ethos Binary#F1-score#0.7971$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.8015$Hate Speech Detection#Ethos Binary#Precision#0.8037
2006.08328v2.pdf	Hate Speech Detection#Ethos Binary#F1-score#0.7883$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.7664$Hate Speech Detection#Ethos Binary#Precision#79.17$Hate Speech Detection#Ethos Binary#F1-score#0.768$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.7734$Hate Speech Detection#Ethos Binary#Precision#77.76$Hate Speech Detection#Ethos Binary#F1-score#0.7441$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.7515$Hate Speech Detection#Ethos Binary#Precision#74.92$Hate Speech Detection#Ethos Binary#F1-score#0.6607$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.6643$Hate Speech Detection#Ethos Binary#Precision#66.47$Hate Speech Detection#Ethos Binary#F1-score#0.6441$Hate Speech Detection#Ethos Binary#Classification Accuracy#0.6504$Hate Speech Detection#Ethos Binary#Precision#64.69$Hate Speech Detection#Ethos MultiLabel#Hamming Loss#0.2948$Hate Speech Detection#Ethos MultiLabel#Hamming Loss#0.1606$Hate Speech Detection#Ethos MultiLabel#Hamming Loss#0.1395$Hate Speech Detection#Ethos MultiLabel#Hamming Loss#0.132$Hate Speech Detection#Ethos MultiLabel#Hamming Loss#0.1097
2205.01068v4.pdf	Hate Speech Detection#Ethos Binary#F1-score#0.759$Hate Speech Detection#Ethos Binary#F1-score#0.713$Hate Speech Detection#Ethos Binary#F1-score#0.667$Hate Speech Detection#Ethos Binary#F1-score#0.628$Hate Speech Detection#Ethos Binary#F1-score#0.616$Hate Speech Detection#Ethos Binary#F1-score#0.354$Stereotypical Bias Analysis#CrowS-Pairs#Gender#62.6$Stereotypical Bias Analysis#CrowS-Pairs#Religion#73.3$Stereotypical Bias Analysis#CrowS-Pairs#Race/Color#64.7$Stereotypical Bias Analysis#CrowS-Pairs#Sexual Orientation#76.2$Stereotypical Bias Analysis#CrowS-Pairs#Age#64.4$Stereotypical Bias Analysis#CrowS-Pairs#Nationality#61.6$Stereotypical Bias Analysis#CrowS-Pairs#Disability#76.7$Stereotypical Bias Analysis#CrowS-Pairs#Physical Appearance#74.6$Stereotypical Bias Analysis#CrowS-Pairs#Socioeconomic status#73.8$Stereotypical Bias Analysis#CrowS-Pairs#Gender#65.7$Stereotypical Bias Analysis#CrowS-Pairs#Religion#68.6$Stereotypical Bias Analysis#CrowS-Pairs#Race/Color#68.6$Stereotypical Bias Analysis#CrowS-Pairs#Sexual Orientation#78.6$Stereotypical Bias Analysis#CrowS-Pairs#Age#67.8$Stereotypical Bias Analysis#CrowS-Pairs#Nationality#62.9$Stereotypical Bias Analysis#CrowS-Pairs#Physical Appearance#76.2$Stereotypical Bias Analysis#CrowS-Pairs#Socioeconomic status#76.2
2010.12472v2.pdf	Hate Speech Detection#AbusEval#Macro F1#0.742$Hate Speech Detection#AbusEval#Macro F1#0.724$Hate Speech Detection#OffensEval 2019#Macro F1#0.805$Hate Speech Detection#OffensEval 2019#Macro F1#0.803$Hate Speech Detection#HatEval#Macro F1#0.494$Hate Speech Detection#HatEval#Macro F1#0.48
2012.10289v2.pdf	Hate Speech Detection#HateXplain#AUROC#0.851$Hate Speech Detection#HateXplain#Accuracy#0.698$Hate Speech Detection#HateXplain#Macro F1#0.687$Hate Speech Detection#HateXplain#AUROC#0.843$Hate Speech Detection#HateXplain#Accuracy#0.69$Hate Speech Detection#HateXplain#Macro F1#0.674$Hate Speech Detection#HateXplain#AUROC#0.805$Hate Speech Detection#HateXplain#Macro F1#0.629$Hate Speech Detection#HateXplain#AUROC#0.795$Hate Speech Detection#HateXplain#Accuracy#0.621$Hate Speech Detection#HateXplain#AUROC#0.793$Hate Speech Detection#HateXplain#Accuracy#0.629$Hate Speech Detection#HateXplain#Macro F1#0.614$Hate Speech Detection#HateXplain#AUROC#0.767$Hate Speech Detection#HateXplain#Accuracy#0.595$Hate Speech Detection#HateXplain#Macro F1#0.575
2004.06465v3.pdf	Hate Speech Detection#Automatic Misogynistic Identification#Accuracy#0.832$Question Similarity#Q2Q Arabic Benchmark#F1 score#0.8365
1812.06700v1.pdf	Hate Speech Detection#Automatic Misogynistic Identification#Accuracy#0.704
2101.05494v1.pdf	Hate Speech Detection#Hostility Detection Dataset in Hindi#F1 score#0.5725$Fake News Detection#Hostility Detection Dataset in Hindi#F1 score#0.7741
2107.13592v3.pdf	Hate Speech Detection#SHAJ#F1#0.77
1908.04531v1.pdf	Hate Speech Detection#DKhate#F1#0.70
2108.04616v2.pdf	Hope Speech Detection#KanHope#F1-score (Weighted)#0.650
2009.08451v4.pdf	Intrusion Detection#CIC-DDoS#AUC#0.94$Intrusion Detection#UNSW-NB15#AUC#0.90$Intrusion Detection#CIC-DoS#AUC#0.95
1709.03082v8.pdf	Intrusion Detection#20NEWS#Actions Top-1 (S2)#action
2102.01873v1.pdf	Network Intrusion Detection#UNSW-NB15#Accuracy#99.6$Network Intrusion Detection#UNSW-NB15#Precision#99.5$Network Intrusion Detection#UNSW-NB15#Recall#99.75$Network Intrusion Detection#UNSW-NB15#Accuracy#99.5$Network Intrusion Detection#UNSW-NB15#Recall#99.55
2207.02117v1.pdf	Network Intrusion Detection#CICIDS2017#Avg F1#0.94$Network Intrusion Detection#CICIDS2017#Recall#99.7$Network Intrusion Detection#CICIDS2017#Precision#88.7$Network Intrusion Detection#CICIDS2017#Avg F1#0.873$Network Intrusion Detection#CICIDS2017#Recall#99.5$Network Intrusion Detection#CICIDS2017#Precision#81.7
1911.04211v4.pdf	Negation Scope Resolution#*sem 2012 Shared Task: Sherlock Dataset#F1#92.36$Negation Scope Resolution#BioScope : Abstracts#F1#95.68$Negation Scope Resolution#BioScope : Full Papers#F1#91.24$Negation Scope Resolution#SFU Review Corpus#F1#90.95$Negation and Speculation Cue Detection#*sem 2012 Shared Task: Sherlock Dataset#F1#92.94
2001.02885v1.pdf	Negation Scope Resolution#*sem 2012 Shared Task: Sherlock Dataset#F1#91.59$Negation Scope Resolution#BioScope : Abstracts#F1#95.74$Negation Scope Resolution#BioScope : Full Papers#F1#94.4$Negation Scope Resolution#SFU Review Corpus#F1#91.25$Speculation Scope Resolution#BioScope : Full Papers#F1#96.91$Speculation Scope Resolution#SFU Review Corpus#F1#91.00$Speculation Scope Resolution#BioScope : Abstracts#F1#97.87
2202.05538v1.pdf	Outlier Detection#SKAB#Average F1#0.74$Change Point Detection#SKAB#NAB (standard)#27.77$Change Point Detection#SKAB#NAB (lowFP)#17.14$Change Point Detection#SKAB#NAB (LowFN)#31.59
1709.05206v1.pdf	Outlier Detection#ECG5000#Accuracy#0.9496
1910.12948v2.pdf	Outlier Detection#ECG5000#Accuracy#0.94
1704.07221v1.pdf	Stance Detection#RumourEval#Accuracy#0.784
1809.01574v2.pdf	Stance Detection#RuStance#F1#0.865
2005.09649v2.pdf	Stance Detection#Trump Midterm Elections 2018#Avg F1#0.86$Stance Detection#Trump Midterm Elections 2018#Macro Precision#0.89$Stance Detection#Trump Midterm Elections 2018#Macro Recall#0.84$Stance Detection#Turkish Elections 2018#Macro Precision#0.90$Stance Detection#Turkish Elections 2018#Macro Recall#0.79$Stance Detection#Turkish Elections 2018#Avg F1#0.84
1904.13353v2.pdf	Edge Detection#BSDS500#F1#0.824
1705.09759v1.pdf	Edge Detection#SBD#Maximum F-measure#71.4%$Edge Detection#Cityscapes test#Maximum F-measure#71.3%$Edge Detection#Cityscapes test#AP#70.8%
1511.07803v1.pdf	Edge Detection#SBD#Maximum F-measure#52%
2112.02250v1.pdf	Edge Detection#MDBD#ODS#0.894$Edge Detection#MDBD#ODS#0.891$Edge Detection#BIPED#ODS#0.895$Edge Detection#BIPED#Number of parameters (M)#35M
2011.09808v2.pdf	Edge Detection#MDBD#ODS#0.891$Edge Detection#BIPED#ODS#0.887
1902.10903v1.pdf	Edge Detection#MDBD#ODS#0.887$Edge Detection#BRIND#ODS#0.789$Edge Detection#BRIND#Number of parameters (M)#16M$Edge Detection#BIPED#ODS#0.890$Edge Detection#BIPED#Number of parameters (M)#16.3M
1612.02103v3.pdf	Edge Detection#MDBD#ODS#0.879$Edge Detection#BIPED#ODS#0.849$Edge Detection#BIPED#Number of parameters (M)#14.8M
2108.07009v1.pdf	Edge Detection#BRIND#ODS#0.789$Edge Detection#BRIND#Number of parameters (M)#710K
1909.01955v2.pdf	Edge Detection#CID#ODS#0.65
2107.00239v1.pdf	Boundary Detection#Kinetics-400#Pairwise F1#0.814$Boundary Detection#Kinetics-400#Recall#83.8$Boundary Detection#Kinetics-400#Precision#82.8
2203.10930v1.pdf	Adversarial Attack#miniImageNet#Accuracy#87.00$Adversarial Defense#miniImageNet#Accuracy#88.54
2105.09109v2.pdf	Adversarial Attack#CIFAR-10#Attack: PGD20#78.680$Adversarial Attack#CIFAR-10#Attack: DeepFool#51.310$Adversarial Attack#CIFAR-10#Attack: AutoAttack#44.150
1706.06083v4.pdf	Adversarial Attack#CIFAR-10#Attack: PGD20#48.440
1901.08573v3.pdf	Adversarial Attack#CIFAR-10#Attack: PGD20#45.900
2203.04420v1.pdf	Adversarial Attack#WSJ0-2mix#SDR#0.70dB
2112.02671v1.pdf	Adversarial Defense#CIFAR-10#Accuracy#84.3$Adversarial Defense#CIFAR-10#Attack: AutoAttack#82.6$Adversarial Defense#CIFAR-10#Accuracy#83.4$Adversarial Defense#CIFAR-10#Accuracy#81.87$Adversarial Defense#CIFAR-10#Attack: AutoAttack#74.71$Adversarial Defense#CIFAR-10#Attack: AutoAttack#81.22$Adversarial Robustness#CIFAR-10#Attack: AutoAttack#82.6$Adversarial Robustness#CIFAR-10#Accuracy#92.26$Adversarial Robustness#CIFAR-10#Robust Accuracy#84.3$Adversarial Robustness#CIFAR-10#Attack: AutoAttack#81.22$Adversarial Robustness#CIFAR-10#Accuracy#91.88$Adversarial Robustness#CIFAR-10#Robust Accuracy#83.4
1904.00887v4.pdf	Adversarial Defense#CIFAR-10#Accuracy#46.7
1812.03411v2.pdf	Adversarial Defense#CAAD 2018#Accuracy#50.6%$Adversarial Defense#ImageNet (targeted PGD, max perturbation=16)#Accuracy#42.8$Adversarial Defense#ImageNet (targeted PGD, max perturbation=16)#Accuracy#40.4$Adversarial Defense#ImageNet (targeted PGD, max perturbation=16)#Accuracy#39.0$Adversarial Defense#ImageNet#Accuracy#49.5%
2007.14433v1.pdf	Adversarial Defense#TrojAI Round 0#Detection Accuracy#92.5±1.1$Adversarial Defense#TrojAI Round 1#Detection Accuracy#92.0 ± 1.3
2006.14536v2.pdf	Adversarial Defense#ImageNet (non-targeted PGD, max perturbation=4)#Accuracy#58.6%
1907.02610v2.pdf	Adversarial Defense#ImageNet (non-targeted PGD, max perturbation=4)#Accuracy#47.0%
1904.12843v2.pdf	Adversarial Defense#ImageNet (non-targeted PGD, max perturbation=4)#Accuracy#36.0%$Adversarial Defense#ImageNet (non-targeted PGD, max perturbation=4)#Accuracy#34.3%$Adversarial Defense#ImageNet (non-targeted PGD, max perturbation=4)#Accuracy#31.8%
2011.11164v2.pdf	Adversarial Defense#CIFAR-100#autoattack#62.55/30.20$Adversarial Defense#CIFAR-100#autoattack#70.25/27.16
2101.10226v1.pdf	Robotic Grasping#Jacquard dataset#Accuracy (%)#95.6
1909.04810v4.pdf	Robotic Grasping#Jacquard dataset#Accuracy (%)#94.6$Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#97.7
2107.05287v2.pdf	Robotic Grasping#Jacquard dataset#Accuracy (%)#92.95$Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#98.2
1802.00520.pdf	Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#96
1611.08036v4.pdf	Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#89.21
1412.3128v2.pdf	Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#88
1804.05172v2.pdf	Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#73
1301.3592v6.pdf	Robotic Grasping#Cornell Grasp Dataset#5 fold cross validation#60.5
2007.09545v1.pdf	Grasp Contact Prediction#ContactPose#AUC#84.74
1904.06830v1.pdf	Grasp Contact Prediction#ContactDB#Error rate#8.72$Grasp Contact Prediction#ContactDB#Error rate#17.27$Grasp Contact Prediction#ContactDB#Error rate#21.82$Grasp Contact Prediction#ContactDB#Error rate#29.89
2208.06991v1.pdf	Automatic Sleep Stage Classification#Sleep-EDF#Number of parameters (M)#1.42$Automatic Sleep Stage Classification#Sleep-EDF#Accuracy#83.7$Automatic Sleep Stage Classification#Sleep-EDF#Cohen’s Kappa score#0.776$Automatic Sleep Stage Classification#Sleep-EDF#Number of parameters (M)#0.32$Automatic Sleep Stage Classification#Sleep-EDF#Accuracy#80.8$Automatic Sleep Stage Classification#Sleep-EDF#Cohen’s Kappa score#0.736
2105.14829v2.pdf	Robot Task Planning#RLBench#Success Rate#0.65
2007.11121v1.pdf	Robot Task Planning#PackIt#Average Reward#64.9$Robot Task Planning#PackIt#Average Reward#59.2$Robot Task Planning#PackIt#Average Reward#49.4$Robot Task Planning#PackIt#Average Reward#41.9
1901.10879v6.pdf	Open Information Extraction#OIE2016#F1#68.65
2109.06850v2.pdf	Open Information Extraction#BenchIE#Precision#0.50$Open Information Extraction#BenchIE#Recall#0.26$Open Information Extraction#BenchIE#F1#0.34$Open Information Extraction#BenchIE#Precision#0.43$Open Information Extraction#BenchIE#Recall#0.28$Open Information Extraction#BenchIE#Precision#0.39$Open Information Extraction#BenchIE#F1#0.23$Open Information Extraction#BenchIE#Precision#0.37$Open Information Extraction#BenchIE#Recall#0.08$Open Information Extraction#BenchIE#F1#0.13$Open Information Extraction#BenchIE#Precision#0.31$Open Information Extraction#BenchIE#Recall#0.21$Open Information Extraction#BenchIE#F1#0.25$Open Information Extraction#BenchIE#Precision#0.26$Open Information Extraction#BenchIE#Recall#0.13$Open Information Extraction#BenchIE#F1#0.17$Open Information Extraction#BenchIE#Precision#0.20$Open Information Extraction#BenchIE#Recall#0.09$Open Information Extraction#BenchIE#Precision#0.11$Open Information Extraction#BenchIE#Recall#0.16$Open Information Extraction#BenchIE#Precision#0.09$Open Information Extraction#BenchIE#Recall#0.03$Open Information Extraction#BenchIE#F1#0.04$Open Information Extraction#BenchIE#Precision#0.03$Open Information Extraction#BenchIE#Recall#0.02$Open Information Extraction#BenchIE#F1#0.03
2009.09335v3.pdf	Event Extraction#GENIA#F1#60.06
1906.04943v1.pdf	Temporal Information Extraction#TempEval-3#Temporal awareness#67.2
2109.14927v3.pdf	Temporal Tagging#TempEval-3#Strict Detection (Pr.)#96.37$Temporal Tagging#TempEval-3#Strict Detection (Re.)#96.37$Temporal Tagging#TempEval-3#Strict Detection (F1)#96.37$Temporal Tagging#TempEval-3#Relaxed Detection (Pr.)#100$Temporal Tagging#TempEval-3#Relaxed Detection (Re.)#100$Temporal Tagging#TempEval-3#Relaxed Detection (F1)#100$Temporal Tagging#TempEval-3#Type#90.43$Temporal Tagging#TempEval-3#Strict Detection (Pr.)#94.11$Temporal Tagging#TempEval-3#Strict Detection (Re.)#81.01$Temporal Tagging#TempEval-3#Strict Detection (F1)#87.07$Temporal Tagging#TempEval-3#Relaxed Detection (Re.)#86.09$Temporal Tagging#TempEval-3#Relaxed Detection (F1)#92.52$Temporal Tagging#TempEval-3#Type#83.79$Temporal Tagging#TempEval-3#Strict Detection (Pr.)#82.72$Temporal Tagging#TempEval-3#Strict Detection (Re.)#85.79$Temporal Tagging#TempEval-3#Strict Detection (F1)#84.21$Temporal Tagging#TempEval-3#Relaxed Detection (Pr.)#90.95$Temporal Tagging#TempEval-3#Relaxed Detection (Re.)#94.35$Temporal Tagging#TempEval-3#Relaxed Detection (F1)#92.60$Temporal Tagging#TempEval-3#Type#86.21$Temporal Tagging#TempEval-3#Strict Detection (Pr.)#81.83$Temporal Tagging#TempEval-3#Strict Detection (Re.)#79.56$Temporal Tagging#TempEval-3#Strict Detection (F1)#80.67$Temporal Tagging#TempEval-3#Relaxed Detection (Pr.)#91.37$Temporal Tagging#TempEval-3#Relaxed Detection (Re.)#88.84$Temporal Tagging#TempEval-3#Relaxed Detection (F1)#90.08$Temporal Tagging#TempEval-3#Type#82.00
2005.09392v1.pdf	Temporal Tagging#TempEval-3#F1#74.8$Temporal Tagging#Spanish TimeBank 1.0#F1#79.55$Temporal Tagging#French Timebank#F1#62.58$Temporal Tagging#TimeBankPT#F1#75.47$Temporal Tagging#Basque TimeBank#F1#47.87$Temporal Tagging#Catalan TimeBank 1.0#F1#64.21$Temporal Tagging#KRAUTS#F1#66.53
1911.09812v1.pdf	Low Resource Named Entity Recognition#CONLL 2003 German#F1 score#65.24$Low Resource Named Entity Recognition#Conll 2003 Spanish#F1 score#75.93$Low Resource Named Entity Recognition#CONLL 2003 Dutch#F1 score#74.61
2206.03377v1.pdf	Document-level Event Extraction#ChFinAnn#F1#81.9
2105.14924v1.pdf	Document-level Event Extraction#ChFinAnn#F1#80.3
2112.06013v2.pdf	Document-level Event Extraction#ChFinAnn#F1#79.4
1904.07535v2.pdf	Document-level Event Extraction#ChFinAnn#F1#76.3
1805.05593v1.pdf	Drug–drug Interaction Extraction#DDI extraction 2013 corpus#F1#0.7255$Drug–drug Interaction Extraction#DDI extraction 2013 corpus#Micro F1#72.55
1806.04185v1.pdf	Participant Intervention Comparison Outcome Extraction#EBM-NLP#F1#66.30
1909.00105v1.pdf	Recipe Generation#Food.com#BLEU-1#28.046$Recipe Generation#Food.com#BLEU-4#3.211$Recipe Generation#Food.com#BPE Perplexity#9.516$Recipe Generation#Food.com#D-1#0.233$Recipe Generation#Food.com#D-2#2.08$Recipe Generation#Food.com#Rouge-L#24.794
1611.01628v5.pdf	Recipe Generation#allrecipes.com#BLEU#15.41$Recipe Generation#allrecipes.com#Perplexity#4.97
1812.06164v2.pdf	Recipe Generation#Recipe1M#Mean IoU#32.11$Recipe Generation#Recipe1M#F1#48.61
2203.10395v1.pdf	Semantic Segmentation#DADA-seg#mIoU#46.97
2108.09174v1.pdf	Semantic Segmentation#DADA-seg#mIoU#39.20$Semantic Segmentation#Cityscapes val#mIoU#81.54%
2112.05006v1.pdf	Semantic Segmentation#DADA-seg#mIoU#32.04
2008.08974v2.pdf	Semantic Segmentation#DADA-seg#mIoU#29.97$Semantic Segmentation#EventScape#mIoU#43.61$Semantic Segmentation#DensePASS#mIoU#32.04%
2105.15203v3.pdf	Semantic Segmentation#DADA-seg#mIoU#27.0$Semantic Segmentation#DADA-seg#mIoU#21.2$Semantic Segmentation#DADA-seg#mIoU#16.6$Semantic Segmentation#Cityscapes val#mIoU#84.0$Semantic Segmentation#SynPASS#mIoU#37.24%$Semantic Segmentation#EventScape#mIoU#59.86$Semantic Segmentation#EventScape#mIoU#58.69$Semantic Segmentation#DensePASS#mIoU#42.4%$Semantic Segmentation#DensePASS#mIoU#38.5%$Semantic Segmentation#ADE20K#Validation mIoU#51.8$Semantic Segmentation#ADE20K#Params (M)#84.7$Semantic Segmentation#ADE20K#Validation mIoU#51.1$Semantic Segmentation#ADE20K#Params (M)#64.1$Semantic Segmentation#ADE20K#Validation mIoU#37.4$Semantic Segmentation#ADE20K#Params (M)#3.8$Semantic Segmentation#ADE20K val#mIoU#51.8$Semantic Segmentation#COCO-Stuff full#Mean IoU (class)#46.7$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.1%$Semantic Segmentation#ZJU-RGB-P#mIoU#89.6$Thermal Image Segmentation#MFN Dataset#mIOU#54.8$Thermal Image Segmentation#MFN Dataset#mIOU#53.2
2003.08040v3.pdf	Semantic Segmentation#DADA-seg#mIoU#26.85$Semantic Segmentation#DensePASS#mIoU#44.58%
1902.04502v1.pdf	Semantic Segmentation#DADA-seg#mIoU#26.32$Semantic Segmentation#Cityscapes val#mIoU#69.19%$Semantic Segmentation#SynPASS#mIoU#21.30%$Semantic Segmentation#EventScape#mIoU#44.27$Semantic Segmentation#DensePASS#mIoU#24.6%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#68%$Thermal Image Segmentation#MFN Dataset#mIOU#32.8
2201.01615v1.pdf	Semantic Segmentation#DADA-seg#mIoU#25.16$Semantic Segmentation#Cityscapes test#Mean IoU (class)#84.4%
1809.02983v4.pdf	Semantic Segmentation#DADA-seg#mIoU#22.24$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.6%$Semantic Segmentation#DensePASS#mIoU#28.5%$Semantic Segmentation#COCO-Stuff test#mIoU#39.7%$Semantic Segmentation#PASCAL Context#mIoU#52.6$Semantic Segmentation#Trans10K#mIoU#68.81%$Semantic Segmentation#Trans10K#GFLOPs#198.00$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.5%$Thermal Image Segmentation#MFN Dataset#mIOU#41.3
1903.08469v2.pdf	Semantic Segmentation#DADA-seg#mIoU#20.5$Semantic Segmentation#EventScape#mIoU#36.67$Semantic Segmentation#DensePASS#mIoU#25.67%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#75.5%$Semantic Segmentation#ZJU-RGB-P#mIoU#80.3$Real-Time Semantic Segmentation#Cityscapes test#mIoU#75.5%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#39.9
2004.08955v2.pdf	Semantic Segmentation#DADA-seg#mIoU#19.99$Semantic Segmentation#Cityscapes val#mIoU#82.7$Semantic Segmentation#ADE20K#Validation mIoU#48.36$Semantic Segmentation#ADE20K#Validation mIoU#47.60$Semantic Segmentation#ADE20K#Validation mIoU#46.91$Semantic Segmentation#ADE20K val#mIoU#48.36$Semantic Segmentation#ADE20K val#mIoU#47.60$Semantic Segmentation#ADE20K val#mIoU#46.91$Semantic Segmentation#PASCAL Context#mIoU#58.9$Semantic Segmentation#PASCAL Context#mIoU#58.4$Semantic Segmentation#PASCAL Context#mIoU#56.5$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.3%$Panoptic Segmentation#COCO minival#PQ#47.9$Panoptic Segmentation#COCO minival#PQth#55.1$Panoptic Segmentation#COCO minival#PQst#37.0$Object Detection#COCO test-dev#box AP#53.3$Object Detection#COCO test-dev#AP50#72.0$Object Detection#COCO test-dev#AP75#58.0$Object Detection#COCO test-dev#APS#35.1$Object Detection#COCO test-dev#APM#56.2$Object Detection#COCO test-dev#APL#66.8$Object Detection#COCO minival#box AP#52.47$Object Detection#COCO minival#AP50#71.00$Object Detection#COCO minival#AP75#57.07$Object Detection#COCO minival#APS#36.80$Object Detection#COCO minival#APM#56.36$Object Detection#COCO minival#APL#66.29$Object Detection#COCO minival#box AP#50.91$Object Detection#COCO minival#AP50#69.53$Object Detection#COCO minival#AP75#55.40$Object Detection#COCO minival#APS#32.67$Object Detection#COCO minival#APM#54.66$Object Detection#COCO minival#APL#65.83$Object Detection#COCO minival#box AP#50.54$Object Detection#COCO minival#AP50#68.78$Object Detection#COCO minival#AP75#55.17$Object Detection#COCO minival#APM#54.2$Object Detection#COCO minival#APL#63.9$Image Classification#ImageNet#Top 1 Accuracy#84.5%$Image Classification#ImageNet#Number of params#111M$Image Classification#ImageNet#Top 1 Accuracy#83.9%$Image Classification#ImageNet#Number of params#70M$Image Classification#ImageNet#Top 1 Accuracy#83.0%$Image Classification#ImageNet#Number of params#48M$Image Classification#ImageNet#Top 1 Accuracy#81.13%$Image Classification#ImageNet#Number of params#27.5M$Image Classification#ImageNet#GFLOPs#5.39$Image Classification#ImageNet#Top 1 Accuracy#80.64%$Image Classification#ImageNet#GFLOPs#4.34$Instance Segmentation#COCO test-dev#mask AP#43%$Instance Segmentation#COCO test-dev#AP50#70.2$Instance Segmentation#COCO test-dev#AP75#51.5$Instance Segmentation#COCO test-dev#APS#30.0$Instance Segmentation#COCO test-dev#APM#49.6$Instance Segmentation#COCO test-dev#APL#60.6$Instance Segmentation#COCO minival#mask AP#46.25$Instance Segmentation#COCO minival#mask AP#44.5$Instance Segmentation#COCO minival#mask AP#44.21$Instance Segmentation#COCO minival#mask AP#41.56
2006.06668v2.pdf	Semantic Segmentation#DADA-seg#mIoU#19.7$Semantic Segmentation#DensePASS#mIoU#32.1%$Semantic Segmentation#ADE20K#Validation mIoU#45.97$Semantic Segmentation#ADE20K val#mIoU#45.97$Semantic Segmentation#PASCAL Context#mIoU#55.3$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83%
1901.02446v2.pdf	Semantic Segmentation#DADA-seg#mIoU#19.59$Semantic Segmentation#DensePASS#mIoU#28.8%$Panoptic Segmentation#COCO test-dev#PQ#40.9$Panoptic Segmentation#COCO test-dev#PQst#29.7$Panoptic Segmentation#COCO test-dev#PQth#48.3$Panoptic Segmentation#Cityscapes val#PQ#58.1$Panoptic Segmentation#Cityscapes val#PQst#62.5$Panoptic Segmentation#Cityscapes val#PQth#52.0$Panoptic Segmentation#Cityscapes val#mIoU#75.7$Panoptic Segmentation#Cityscapes val#AP#33.0$Panoptic Segmentation#Indian Driving Dataset#PQ#46.7$Panoptic Segmentation#KITTI Panoptic Segmentation#PQ#39.3
1905.02244v5.pdf	Semantic Segmentation#DADA-seg#mIoU#18.2$Semantic Segmentation#Cityscapes test#Mean IoU (class)#72.6%$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.669$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.595$Dichotomous Image Segmentation#DIS-TE1#MAE#0.083$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.740$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.818$Dichotomous Image Segmentation#DIS-TE1#HCE#274$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.743$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.672$Dichotomous Image Segmentation#DIS-TE2#MAE#0.083$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.777$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.856$Dichotomous Image Segmentation#DIS-TE2#HCE#600$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.772$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.702$Dichotomous Image Segmentation#DIS-TE3#MAE#0.078$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.764$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.880$Dichotomous Image Segmentation#DIS-TE3#HCE#1136$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.736$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.664$Dichotomous Image Segmentation#DIS-TE4#MAE#0.098$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.770$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.848$Dichotomous Image Segmentation#DIS-TE4#HCE#3817$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.714$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.642$Dichotomous Image Segmentation#DIS-VD#MAE#0.092$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.758$Dichotomous Image Segmentation#DIS-VD#E-measure#0.841$Dichotomous Image Segmentation#DIS-VD#HCE#1625$Image Classification#ImageNet#Top 1 Accuracy#75.2%$Image Classification#ImageNet#Number of params#5.4M$Image Classification#ImageNet#GFLOPs#0.438
1912.10917v2.pdf	Semantic Segmentation#BDD#mIoU#55.1$Semantic Segmentation#Cityscapes val#mIoU#73.1%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.5%
2203.14508v1.pdf	Semantic Segmentation#S3DIS Area5#mIoU#72.0$Semantic Segmentation#S3DIS Area5#oAcc#91.5$Semantic Segmentation#S3DIS Area5#mAcc#78.1
2203.05272v2.pdf	Semantic Segmentation#S3DIS Area5#mIoU#71.6$Semantic Segmentation#S3DIS Area5#oAcc#91.2$Semantic Segmentation#S3DIS Area5#mAcc#77.9$Semantic Segmentation#S3DIS#Mean IoU#73.1$Semantic Segmentation#S3DIS#mAcc#79.4$Semantic Segmentation#S3DIS#oAcc#89.6
2111.11187v5.pdf	Semantic Segmentation#S3DIS Area5#mIoU#71.4$Semantic Segmentation#S3DIS Area5#mAcc#77.4$Semantic Segmentation#S3DIS Area5#Number of params#6.5M$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.6$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.4$3D Point Cloud Classification#ModelNet40#Number of params#6.5M
2206.04670v2.pdf	Semantic Segmentation#S3DIS Area5#mIoU#71.1$Semantic Segmentation#S3DIS Area5#oAcc#91.0$Semantic Segmentation#S3DIS Area5#mAcc#77.2$Semantic Segmentation#S3DIS#Mean IoU#74.9$Semantic Segmentation#S3DIS#mAcc#83.0$Semantic Segmentation#S3DIS#oAcc#90.3$Semantic Segmentation#S3DIS#FLOPs#84.8G$Semantic Segmentation#S3DIS#Number of params#41.6M$Semantic Segmentation#S3DIS#Mean IoU#73.9$Semantic Segmentation#S3DIS#mAcc#82.2$Semantic Segmentation#S3DIS#oAcc#89.9$Semantic Segmentation#S3DIS#FLOPs#15.2G$Semantic Segmentation#S3DIS#Number of params#7.1M$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#87.1$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#88.2$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#86.8$3D Point Cloud Classification#ScanObjectNN#Number of params#1.4M$3D Point Cloud Classification#ScanObjectNN#FLOPs#1.64G$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.0$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.1$3D Point Cloud Classification#ModelNet40#Number of params#4.5M$3D Point Cloud Classification#ModelNet40#FLOPs#6.5G
2205.05740v2.pdf	Semantic Segmentation#S3DIS Area5#mIoU#68.9$Semantic Segmentation#S3DIS Area5#oAcc#90.2$Semantic Segmentation#S3DIS Area5#mAcc#76.0$Semantic Segmentation#S3DIS Area5#Number of params#0.97M$Semantic Segmentation#S3DIS Area5#FLOPs#1.04G$Semantic Segmentation#S3DIS#Mean IoU#74.3$Semantic Segmentation#S3DIS#mAcc#82.6$Semantic Segmentation#S3DIS#oAcc#90.8$Semantic Segmentation#S3DIS#FLOPs#1.04G$Semantic Segmentation#S3DIS#Number of params#0.97M$3D Object Detection#ScanNetV2#mAP@0.25#71.2$3D Object Detection#ScanNetV2#mAP@0.5#54.8$3D Object Detection#SUN-RGBD val#mAP@0.25#64.9$3D Object Detection#SUN-RGBD val#mAP@0.5#47.7$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#86.0$3D Point Cloud Classification#ScanObjectNN#Number of params#6.80M$3D Point Cloud Classification#ScanObjectNN#FLOPs#2.43G$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#84.6$3D Point Cloud Classification#ScanObjectNN#Number of params#1.48M$3D Point Cloud Classification#ScanObjectNN#FLOPs#0.81G$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.7$3D Point Cloud Classification#ModelNet40#Number of params#1.48M$3D Point Cloud Classification#ModelNet40#FLOPs#0.81G
2111.00207v3.pdf	Semantic Segmentation#S3DIS Area5#mIoU#67.3$Semantic Segmentation#ShapeNet#Mean IoU#86.5%
2110.10538v2.pdf	Semantic Segmentation#S3DIS Area5#mIoU#66.8$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.1$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.9
2009.08924?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529.pdf	Semantic Segmentation#S3DIS Area5#mIoU#63.5$Semantic Segmentation#S3DIS Area5#oAcc#88.1$Semantic Segmentation#S3DIS#Mean IoU#69.8$Semantic Segmentation#S3DIS#oAcc#88.5
1909.10469v1.pdf	Semantic Segmentation#S3DIS Area5#mIoU#61.85$Semantic Segmentation#S3DIS Area5#oAcc#87.18$Semantic Segmentation#S3DIS Area5#mAcc#68.3
1904.02113v1.pdf	Semantic Segmentation#S3DIS Area5#mIoU#61.7$Semantic Segmentation#S3DIS Area5#oAcc#87.9$Semantic Segmentation#S3DIS Area5#mAcc#68.2$Semantic Segmentation#S3DIS#Mean IoU#68.4$Semantic Segmentation#S3DIS#mAcc#78.3$Semantic Segmentation#S3DIS#oAcc#87.9
1907.12046v3.pdf	Semantic Segmentation#S3DIS Area5#mIoU#61.28
1710.07563v1.pdf	Semantic Segmentation#S3DIS Area5#mIoU#48.9$Semantic Segmentation#S3DIS Area5#mAcc#57.4$Semantic Segmentation#Semantic3D#mIoU#61.3%$Semantic Segmentation#Semantic3D#mIoU#58.2%
2101.06742v1.pdf	Semantic Segmentation#S3DIS Area5#mAcc#67.0
1812.01593v3.pdf	Semantic Segmentation#CamVid#Mean IoU#81.7%$Semantic Segmentation#KITTI Semantic Segmentation#Mean IoU (class)#72.83$Semantic Segmentation#KITTI Semantic Segmentation#class iIoU#48.68$Semantic Segmentation#KITTI Semantic Segmentation#Category IoU#88.99$Semantic Segmentation#KITTI Semantic Segmentation#Category iIoU#75.26
2002.11433v2.pdf	Semantic Segmentation#CamVid#Mean IoU#76.3$Video Semantic Segmentation#CamVid#Mean IoU#76.3
1807.03148v1.pdf	Semantic Segmentation#CamVid#Mean IoU#75.2
1808.00897v1.pdf	Semantic Segmentation#CamVid#Mean IoU#68.7%$Semantic Segmentation#Trans10K#mIoU#58.40%$Semantic Segmentation#Trans10K#GFLOPs#19.91$Semantic Segmentation#Cityscapes test#Mean IoU (class)#78.9%$Semantic Segmentation#SkyScapes-Dense#Mean IoU#30.82$Real-Time Semantic Segmentation#CamVid#mIoU#68.7%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#74.7%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#15.2$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#65.5$Real-Time Semantic Segmentation#Cityscapes test#mIoU#68.4%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#9.5$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#105.8$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.595$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.474$Dichotomous Image Segmentation#DIS-TE1#MAE#0.108$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.695$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.741$Dichotomous Image Segmentation#DIS-TE1#HCE#288$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.680$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.564$Dichotomous Image Segmentation#DIS-TE2#MAE#0.111$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.740$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.781$Dichotomous Image Segmentation#DIS-TE2#HCE#621$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.710$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.595$Dichotomous Image Segmentation#DIS-TE3#MAE#0.109$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.757$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.801$Dichotomous Image Segmentation#DIS-TE3#HCE#1146$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.710$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.598$Dichotomous Image Segmentation#DIS-TE4#MAE#0.114$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.755$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.788$Dichotomous Image Segmentation#DIS-TE4#HCE#3999$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.662$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.548$Dichotomous Image Segmentation#DIS-VD#MAE#0.116$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.728$Dichotomous Image Segmentation#DIS-VD#E-measure#0.767$Dichotomous Image Segmentation#DIS-VD#HCE#1660
1611.09326v3.pdf	Semantic Segmentation#CamVid#Global Accuracy#91.5%$Semantic Segmentation#CamVid#Mean IoU#66.9%
1809.06323v3.pdf	Semantic Segmentation#CamVid#Global Accuracy#90.8$Semantic Segmentation#CamVid#Mean IoU#66.4$Semantic Segmentation#Cityscapes test#Mean IoU (class)#67.3$Real-Time Semantic Segmentation#CamVid#mIoU#66.4$Real-Time Semantic Segmentation#Cityscapes test#mIoU#67.3$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#9.2$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#108.7 (1080Ti)
1511.07122v3.pdf	Semantic Segmentation#CamVid#Mean IoU#65.3%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#67.6%$Semantic Segmentation#ADE20K#Validation mIoU#32.31$Semantic Segmentation#Cityscapes test#Mean IoU (class)#67.1%$Real-Time Semantic Segmentation#CamVid#mIoU#65.3%$Real-Time Semantic Segmentation#CamVid#Time (ms)#227$Real-Time Semantic Segmentation#CamVid#Frame (fps)#4.4
1904.02216v1.pdf	Semantic Segmentation#CamVid#Mean IoU#64.7%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.3%$SMAC+#Def_Infantry_parallel#Median Win Rate#45.0
1904.02365v2.pdf	Semantic Segmentation#CamVid#Mean IoU#63.9%$Semantic Segmentation#CamVid#Mean IoU#63.2%$Semantic Segmentation#Cityscapes val#mIoU#69.5%$Semantic Segmentation#Cityscapes val#mIoU#68.1%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#67.8%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#67.7%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#67.8%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#97$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#10$Real-Time Semantic Segmentation#Cityscapes test#mIoU#67.7%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#52$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#19
1809.03994v1.pdf	Semantic Segmentation#CamVid#Mean IoU#63.5$Real-Time Semantic Segmentation#CamVid#mIoU#63.5$Real-Time Semantic Segmentation#CamVid#Time (ms)#29.1$Real-Time Semantic Segmentation#CamVid#Frame (fps)#34.4 (1080)
1807.11037v1.pdf	Semantic Segmentation#CamVid#Mean IoU#62.5
1412.7062v4.pdf	Semantic Segmentation#CamVid#Mean IoU#61.6%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.6%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#63.1%$Scene Segmentation#SUN-RGBD#Mean IoU#32.08$Real-Time Semantic Segmentation#CamVid#mIoU#61.6%$Real-Time Semantic Segmentation#CamVid#Time (ms)#203$Real-Time Semantic Segmentation#CamVid#Frame (fps)#4.9$Real-Time Semantic Segmentation#Cityscapes test#mIoU#63.1%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#4000$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#0.25
1511.07053v3.pdf	Semantic Segmentation#CamVid#Global Accuracy#88.7%$Semantic Segmentation#CamVid#Mean IoU#58.8%
2109.08937v4.pdf	Semantic Segmentation#UAVid#Mean IoU#67.8$Semantic Segmentation#ISPRS Vaihingen#Overall Accuracy#91.6$Semantic Segmentation#ISPRS Vaihingen#Average F1#91.3$Semantic Segmentation#ISPRS Vaihingen#Category mIoU#84.1$Semantic Segmentation#ISPRS Vaihingen#Overall Accuracy#91.0$Semantic Segmentation#ISPRS Vaihingen#Average F1#90.4$Semantic Segmentation#ISPRS Vaihingen#Category mIoU#82.7$Semantic Segmentation#LoveDA#Category mIoU#52.40$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#92.0$Semantic Segmentation#ISPRS Potsdam#Mean F1#93.3$Semantic Segmentation#ISPRS Potsdam#Mean IoU#87.5$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.3$Semantic Segmentation#ISPRS Potsdam#Mean F1#92.8$Semantic Segmentation#ISPRS Potsdam#Mean IoU#86.8$Scene Segmentation#UAVid#Category mIoU#67.8
2106.12413v2.pdf	Semantic Segmentation#UAVid#Mean IoU#64.6$Semantic Segmentation#ISPRS Vaihingen#Overall Accuracy#90.5$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.06
2102.02531v1.pdf	Semantic Segmentation#UAVid#Mean IoU#63.79$Semantic Segmentation#ISPRS Vaihingen#Overall Accuracy#90.7$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.3
2203.13131v1.pdf	Semantic Segmentation#COCO Visual Question Answering (VQA) real images 1.0 multiple choice#FID#7.55
2107.00782v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#86.93$Pose Estimation#COCO test-dev#AP#79.5$Pose Estimation#COCO test-dev#AP50#93.6$Pose Estimation#COCO test-dev#AP75#85.9$Pose Estimation#COCO test-dev#APL#84.3$Pose Estimation#COCO test-dev#APM#76.3$Pose Estimation#COCO test-dev#AR#81.9$Pose Estimation#COCO test-dev#AP#78.9$Pose Estimation#COCO test-dev#AP75#85.8$Pose Estimation#COCO test-dev#APL#83.6$Pose Estimation#COCO test-dev#APM#76.1$Pose Estimation#COCO test-dev#AR#81.4$Keypoint Detection#COCO#Validation AP#79.5
2005.10821v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#86.3$Panoptic Segmentation#Mapillary val#PQ#17.6
2112.12782v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#84.98$Semantic Segmentation#Cityscapes val#mIoU#80.39$Semantic Segmentation#ADE20K#Validation mIoU#58.2$Semantic Segmentation#ADE20K#Validation mIoU#57.5$Semantic Segmentation#ADE20K#Validation mIoU#57.0$Semantic Segmentation#ADE20K#Validation mIoU#56.2$Semantic Segmentation#ADE20K#Validation mIoU#53.52$Semantic Segmentation#ADE20K#Validation mIoU#50.98$Semantic Segmentation#ADE20K#Params (M)#96$Semantic Segmentation#ADE20K#Validation mIoU#47.63$Semantic Segmentation#ADE20K#Params (M)#56$Semantic Segmentation#ADE20K#Validation mIoU#43.16$Semantic Segmentation#ADE20K#Params (M)#35$Semantic Segmentation#ADE20K val#mIoU#58.2$Semantic Segmentation#ADE20K val#mIoU#57.5$Semantic Segmentation#ADE20K val#mIoU#57.0$Semantic Segmentation#ADE20K val#mIoU#56.2$Semantic Segmentation#ADE20K val#mIoU#53.5
2106.13112v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#84.3$Semantic Segmentation#ADE20K#Validation mIoU#54.3$Semantic Segmentation#Graz-02#Pixel Accuracy#85$Image Classification#ImageNet#Top 1 Accuracy#87.1%$Image Classification#ImageNet#Number of params#296M$Image Classification#ImageNet#Top 1 Accuracy#86.8%$Image Classification#ImageNet#Number of params#193M$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#Number of params#86M$Image Classification#ImageNet#Top 1 Accuracy#86%$Image Classification#ImageNet#Number of params#59M$Image Classification#ImageNet#Top 1 Accuracy#85.2%$Image Classification#ImageNet#Number of params#27M$Image Classification#ImageNet ReaL#Accuracy#90.6%$Image Classification#ImageNet ReaL#Accuracy#90.5%$Image Classification#ImageNet V2#Top 1 Accuracy#78$Image Classification#ImageNet V2#Top 1 Accuracy#77.8
2112.01527v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#84.3$Semantic Segmentation#ADE20K#Validation mIoU#57.7$Semantic Segmentation#ADE20K#Validation mIoU#57.3$Semantic Segmentation#ADE20K#Validation mIoU#56.4$Semantic Segmentation#ADE20K val#mIoU#57.7$Semantic Segmentation#ADE20K val#mIoU#56.4$Panoptic Segmentation#COCO test-dev#PQ#58.3$Panoptic Segmentation#COCO test-dev#PQst#48.1$Panoptic Segmentation#COCO test-dev#PQth#65.1$Panoptic Segmentation#COCO minival#PQ#57.8$Panoptic Segmentation#COCO minival#PQth#64.2$Panoptic Segmentation#COCO minival#PQst#48.1$Panoptic Segmentation#Cityscapes val#PQ#66.6$Panoptic Segmentation#Cityscapes val#mIoU#82.9$Panoptic Segmentation#Cityscapes val#AP#43.6$Panoptic Segmentation#ADE20K val#PQ#48.1$Panoptic Segmentation#ADE20K val#AP#34.2$Panoptic Segmentation#ADE20K val#mIoU#54.5$Panoptic Segmentation#ADE20K val#PQ#46.2$Panoptic Segmentation#ADE20K val#AP#33.2$Panoptic Segmentation#ADE20K val#mIoU#55.4$Panoptic Segmentation#ADE20K val#PQ#39.7$Panoptic Segmentation#ADE20K val#PQ#37.9$Panoptic Segmentation#ADE20K val#mIoU#50$Panoptic Segmentation#ADE20K val#AP#26.5$Panoptic Segmentation#ADE20K val#mIoU#46.1$Instance Segmentation#COCO test-dev#mask AP#50.5$Instance Segmentation#COCO test-dev#AP50#74.9$Instance Segmentation#COCO test-dev#AP75#54.9$Instance Segmentation#COCO test-dev#APS#29.1$Instance Segmentation#COCO test-dev#APM#53.8$Instance Segmentation#COCO test-dev#APL#71.2$Instance Segmentation#Cityscapes val#mask AP#43.7$Instance Segmentation#Cityscapes val#mask AP#42$Instance Segmentation#Cityscapes val#mask AP#41.8$Instance Segmentation#Cityscapes val#mask AP#39.7$Instance Segmentation#Cityscapes val#mask AP#38.5$Instance Segmentation#Cityscapes val#mask AP#37.4$Instance Segmentation#ADE20K val#AP#34.9$Instance Segmentation#ADE20K val#APS#16.3$Instance Segmentation#ADE20K val#APM#40$Instance Segmentation#ADE20K val#APL#54.7$Instance Segmentation#ADE20K val#AP#33.4$Instance Segmentation#ADE20K val#APS#14.6$Instance Segmentation#ADE20K val#APM#37.6$Instance Segmentation#ADE20K val#APL#54.6$Instance Segmentation#ADE20K val#AP#26.4$Instance Segmentation#ADE20K val#APS#10.4$Instance Segmentation#ADE20K val#APM#28.9$Instance Segmentation#ADE20K val#APL#43.1$Instance Segmentation#COCO minival#mask AP#50.1$Instance Segmentation#COCO minival#APL#72.1$Instance Segmentation#COCO minival#APM#53.9$Instance Segmentation#COCO minival#APS#29.9
1909.11065v6.pdf	Semantic Segmentation#Cityscapes val#mIoU#83.6$Semantic Segmentation#Cityscapes val#mIoU#80.6$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84.5%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84.3%$Semantic Segmentation#ADE20K#Validation mIoU#47.98$Semantic Segmentation#ADE20K#Validation mIoU#45.66$Semantic Segmentation#ADE20K#Validation mIoU#45.28$Semantic Segmentation#ADE20K val#mIoU#47.98$Semantic Segmentation#ADE20K val#mIoU#45.66$Semantic Segmentation#ADE20K val#mIoU#45.28$Semantic Segmentation#COCO-Stuff test#mIoU#45.2%$Semantic Segmentation#COCO-Stuff test#mIoU#40.5%$Semantic Segmentation#COCO-Stuff test#mIoU#39.5%$Semantic Segmentation#PASCAL Context#mIoU#59.6$Semantic Segmentation#PASCAL Context#mIoU#56.2$Semantic Segmentation#PASCAL Context#mIoU#54.8$Semantic Segmentation#Cityscapes test#Mean IoU (class)#84.5%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.7%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.4%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.8%$Semantic Segmentation#LIP val#mIoU#58.2%$Semantic Segmentation#LIP val#mIoU#56.65%$Semantic Segmentation#LIP val#mIoU#55.6%
2104.12753v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#83.6%$Semantic Segmentation#ADE20K#Validation mIoU#54.4$Semantic Segmentation#ADE20K val#mIoU#54.4%
2111.01236v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#83.16%$Semantic Segmentation#Cityscapes val#mIoU#82.81%$Semantic Segmentation#Cityscapes val#mIoU#81.63%$Semantic Segmentation#ADE20K#Validation mIoU#50.2$Semantic Segmentation#ADE20K#Params (M)#28.7$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#67.9$Semantic Segmentation#ADE20K#Validation mIoU#48.76$Semantic Segmentation#ADE20K#Params (M)#20.8$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#28.0$Semantic Segmentation#ADE20K#Validation mIoU#45.88$Semantic Segmentation#ADE20K#Params (M)#8.2$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#14.6
2103.12270v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#83.04%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#85.64%
2203.04838v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#82.6%$Semantic Segmentation#Cityscapes val#mIoU#81.6%$Semantic Segmentation#EventScape#mIoU#64.28$Semantic Segmentation#EventScape#mIoU#61.90$Semantic Segmentation#SUN-RGBD#Mean IoU#52.4%$Semantic Segmentation#SUN-RGBD#Mean IoU#52.1%$Semantic Segmentation#SUN-RGBD#Mean IoU#49.7%$Semantic Segmentation#Stanford2D3D#mIoU#62.1$Semantic Segmentation#Stanford2D3D#mIoU#61.2$Semantic Segmentation#RSMSS#mIoU#65.5%$Semantic Segmentation#ScanNetV2#Mean IoU#61.3%$Semantic Segmentation#NYU Depth v2#Mean IoU#56.9%$Semantic Segmentation#NYU Depth v2#Mean IoU#56.3%$Semantic Segmentation#NYU Depth v2#Mean IoU#54.4%$Semantic Segmentation#ZJU-RGB-P#mIoU#92.6$Semantic Segmentation#ZJU-RGB-P#mIoU#92.2$Thermal Image Segmentation#MFN Dataset#mIOU#59.7$Thermal Image Segmentation#MFN Dataset#mIOU#58.2
2105.02358v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#81.7%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84%$Semantic Segmentation#ADE20K#Validation mIoU#45.33$Semantic Segmentation#ADE20K val#mIoU#45.33$Image Classification#ImageNet#Top 1 Accuracy#81.7%
1911.10194v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#81.5%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#84.2%$Panoptic Segmentation#Mapillary val#PQ#40.5$Panoptic Segmentation#COCO test-dev#PQ#41.4$Panoptic Segmentation#COCO test-dev#PQst#35.9$Panoptic Segmentation#COCO test-dev#PQth#45.1$Panoptic Segmentation#Cityscapes val#PQ#64.1$Panoptic Segmentation#Cityscapes val#mIoU#81.5$Panoptic Segmentation#Cityscapes val#AP#38.5$Panoptic Segmentation#Cityscapes test#PQ#65.5$Instance Segmentation#Cityscapes test#Average Precision#39.0$Instance Segmentation#Cityscapes test#Average Precision#34.6
2203.01452v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#81.1%$Semantic Segmentation#Cityscapes val#mIoU#79.1%$Semantic Segmentation#SynPASS#mIoU#38.57%$Semantic Segmentation#DensePASS#mIoU#56.38%$Semantic Segmentation#DensePASS#mIoU#55.25%$Semantic Segmentation#Stanford2D3D Panoramic#mIoU#53.0%
2101.03697v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#80.57%$Image Classification#ImageNet#Top 1 Accuracy#78.78%$Image Classification#ImageNet#Number of params#80.31M$Image Classification#ImageNet#GFLOPs#18.4$Image Classification#ImageNet#Top 1 Accuracy#78.5%$Image Classification#ImageNet#Number of params#55.77M$Image Classification#ImageNet#GFLOPs#11.3
1901.02985v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#80.33%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#85.6%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#82.04%$Semantic Segmentation#ADE20K#Validation mIoU#43.98$Semantic Segmentation#ADE20K val#mIoU#43.98$Semantic Segmentation#ADE20K val#Pixel Accuracy#81.72$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.1%
2006.08656v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#80.3%$Semantic Segmentation#Cityscapes val#mIoU#77.8%$Image Classification#ImageNet#Top 1 Accuracy#79.2%$Image Classification#ImageNet#Number of params#81M
1912.08193v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#78.6$Instance Segmentation#COCO 2017 val#mask AP*#39.7$Instance Segmentation#Cityscapes val#mask AP#35.8
1706.05587v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#78.5%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#86.9%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#82.7%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.3%$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.601$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.506$Dichotomous Image Segmentation#DIS-TE1#MAE#0.102$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.694$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.772$Dichotomous Image Segmentation#DIS-TE1#HCE#234$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.681$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.587$Dichotomous Image Segmentation#DIS-TE2#MAE#0.105$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.729$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.813$Dichotomous Image Segmentation#DIS-TE2#HCE#516$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.717$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.623$Dichotomous Image Segmentation#DIS-TE3#MAE#0.102$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.749$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.833$Dichotomous Image Segmentation#DIS-TE3#HCE#999$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.715$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.621$Dichotomous Image Segmentation#DIS-TE4#MAE#0.111$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.744$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.820$Dichotomous Image Segmentation#DIS-TE4#HCE#3709$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.660$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.568$Dichotomous Image Segmentation#DIS-VD#MAE#0.114$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.716$Dichotomous Image Segmentation#DIS-VD#E-measure#0.796$Dichotomous Image Segmentation#DIS-VD#HCE#1520
2204.13492v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#78.2$Semantic Segmentation#Cityscapes val#FPS#1.1$Semantic Segmentation#Cityscapes val#mIoU#71.5$Semantic Segmentation#Cityscapes val#FPS#1.9$Semantic Segmentation#Cityscapes val#mIoU#57.9$Semantic Segmentation#Cityscapes val#FPS#2.9$Semantic Segmentation#Cityscapes val#mIoU#45.5$Semantic Segmentation#Cityscapes val#FPS#4.3
2103.10957v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#77.0%
2108.06156v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#76.8$Neural Architecture Search#CIFAR-10 Image Classification#Params#3.6$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.8$Neural Architecture Search#ImageNet#Accuracy#76.2$Neural Architecture Search#ImageNet#Top-1 Error Rate#25.7$Neural Architecture Search#ImageNet#Accuracy#74.3$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.46%$Object Detection#PASCAL VOC 2007#MAP#81.8%$Image Classification#CIFAR-100#Percentage correct#84.98
2112.00390v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#76.44
2112.11081v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#76.27$Image Classification#ImageNet#Top 1 Accuracy#81.8%
2205.14375v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#75.32$Image Classification#Tiny ImageNet Classification#Validation Acc#52.38%$Image Classification#CIFAR-100#Percentage correct#70.20$Image Classification#SVHN#Percentage error#1.86$Image Classification#iNat2021-mini#Top 1 Accuracy#33.23$Image Classification#EMNIST-Byclass#Accuracy#88.43$Image Classification#ImageNet64x64#Top 1 Accuracy#60.56$Image Classification#Caltech-256#Accuracy#54.62$Image Classification#EMNIST-Bymerge#Accuracy#91.80$Image Classification#STL-10#Percentage correct#70.88$Image Classification#EMNIST-Digits#Accuracy (%)#99.80$Image Classification#EMNIST-Balanced#Accuracy#91.06$Image Classification#Places365-Standard#Top 1 Accuracy#49.83$Image Classification#MNIST#Percentage error#0.25$Image Classification#Fashion-MNIST#Percentage error#5.68$Image Classification#EMNIST-Letters#Accuracy#95.96$Image Classification#CIFAR-10#Percentage correct#92.97
1908.01748v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#75.2%$Semantic Segmentation#Cityscapes val#mIoU#73.6%$Semantic Segmentation#Cityscapes val#mIoU#68.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#72.5%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#66.8%
2201.05119v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#75.2$Semantic Segmentation#Cityscapes val#mIoU#74.6$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#77.9%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#77.3%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#75.7%$Image Classification#ObjectNet#Top-1 Accuracy#25.9$Image Classification#ObjectNet#Top-1 Accuracy#23.8$Image Classification#ObjectNet#Top-1 Accuracy#23$Image Classification#ObjectNet#Top-1 Accuracy#14.6$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.2$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#72.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#81.3$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#58.1%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#80.6%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.8%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.3%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.7%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#77.1%
1907.05740v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#74.7%$Semantic Segmentation#Cityscapes val#mIoU#73.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.8%
1912.03183v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#74%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#79.6%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#80.41%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.5%
2105.07209v1.pdf	Semantic Segmentation#Cityscapes val#mIoU#72.8%
2002.10570v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#72.5%$Semantic Segmentation#EventScape#mIoU#41.34
1909.07721v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#72.1%$Semantic Segmentation#DensePASS#mIoU#23.66%
1809.09077v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#68.48%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.3$Real-Time Semantic Segmentation#Cityscapes val#mIoU#68.48%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#71.3%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#18.4 (1080Ti)
1805.04554v4.pdf	Semantic Segmentation#Cityscapes val#mIoU#65.9%
1906.03516v3.pdf	Semantic Segmentation#Cityscapes val#mIoU#63.4$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#67.31%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#66.5%$Image Classification#ImageNet#Top 1 Accuracy#75.1%$Image Classification#ImageNet#GFLOPs#0.553
1907.10015v2.pdf	Semantic Segmentation#Cityscapes val#mIoU#61.6
2104.12137v6.pdf	Semantic Segmentation#ISPRS Vaihingen#Overall Accuracy#91.6$Semantic Segmentation#ISPRS Vaihingen#Average F1#90.7$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#92.0$Semantic Segmentation#ISPRS Potsdam#Mean F1#93.25$Semantic Segmentation#ISPRS Potsdam#Mean IoU#87.56
1411.4038v2.pdf	Semantic Segmentation#SkyScapes-Lane#Mean IoU#13.74$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#62.2%$Semantic Segmentation#ADE20K#Validation mIoU#29.39$Semantic Segmentation#COCO-Stuff test#mIoU#22.7%$Semantic Segmentation#PASCAL Context#mIoU#37.8$Semantic Segmentation#Trans10K#mIoU#62.75%$Semantic Segmentation#Trans10K#GFLOPs#42.23$Semantic Segmentation#SkyScapes-Dense#Mean IoU#33.06$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.797$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#31.2
2012.02024v1.pdf	Semantic Segmentation#DroneDeploy#Mean IoU (val)#69.9$Semantic Segmentation#DroneDeploy#Mean IoU (test)#52.5
2207.11860v2.pdf	Semantic Segmentation#SynPASS#mIoU#39.16%$Semantic Segmentation#DensePASS#mIoU#57.23%$Semantic Segmentation#DensePASS#mIoU#56.45%$Semantic Segmentation#Stanford2D3D Panoramic#mIoU#54.0%
2102.12122v2.pdf	Semantic Segmentation#SynPASS#mIoU#32.68%$Semantic Segmentation#DensePASS#mIoU#31.20%$Object Detection#COCO minival#box AP#43.4$Object Detection#COCO minival#AP50#63.6$Object Detection#COCO minival#AP75#46.1$Object Detection#COCO minival#APS#26.1$Object Detection#COCO minival#APM#46.0$Object Detection#COCO minival#APL#59.5$Object Detection#COCO minival#box AP#42.6$Object Detection#COCO minival#AP50#63.7$Object Detection#COCO minival#AP75#45.4$Object Detection#COCO minival#APS#25.8$Object Detection#COCO minival#APL#58.4
2007.09183v1.pdf	Semantic Segmentation#EventScape#mIoU#53.94$Semantic Segmentation#SUN-RGBD#Mean IoU#49.4%$Semantic Segmentation#NYU Depth v2#Mean IoU#52.4%$Thermal Image Segmentation#MFN Dataset#mIOU#45.8
2107.03172v2.pdf	Semantic Segmentation#EventScape#mIoU#51.86$Semantic Segmentation#Trans10K#mIoU#75.14%$Semantic Segmentation#Trans10K#GFLOPs#34.38$Semantic Segmentation#Trans10K#mIoU#74.15%$Semantic Segmentation#Trans10K#GFLOPs#19.92$Semantic Segmentation#Trans10K#mIoU#68.63%$Semantic Segmentation#Trans10K#GFLOPs#10.45
1811.08201v2.pdf	Semantic Segmentation#EventScape#mIoU#44.75
1711.08588v2.pdf	Semantic Segmentation#ShapeNet#Mean IoU#85.8%$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.8$3D Object Detection#NYU Depth v2#MAP#41.3$3D Object Detection#ScanNetV2#mAP@0.25#20.7$Instance Segmentation#NYU Depth v2#mAP@0.5#30.5$3D Semantic Instance Segmentation#ScanNetV1#mAP@0.25#35.1$3D Semantic Instance Segmentation#ScanNetV2#mAP@0.50#14.3
1912.09654v1.pdf	Semantic Segmentation#ShapeNet#Mean IoU#85.8%$Semantic Segmentation#S3DIS#Mean IoU#61.7$Semantic Segmentation#S3DIS#mAcc#71.7$Semantic Segmentation#S3DIS#oAcc#88.7$3D Instance Segmentation#S3DIS#mRec#53.9$3D Instance Segmentation#S3DIS#mPrec#66.9$3D Instance Segmentation#S3DIS#mCov#54.1$3D Instance Segmentation#S3DIS#mWCov#58
2209.08575v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#90.6%
2006.06882v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#90.5%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#90.0%$Object Detection#COCO test-dev#box AP#54.3$Object Detection#COCO minival#box AP#54.2
2011.08577v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#88.4%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.0%
1907.13426v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#88.2%$Semantic Segmentation#COCO-Stuff test#mIoU#39.9%$Semantic Segmentation#PASCAL Context#mIoU#53.1
2110.14759v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#88.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.6%
1804.03821v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#87.9%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#85.8%
1809.04184v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#87.9%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.7%$Human Part Segmentation#PASCAL-Part#mIoU#71.34
2003.11883v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#86.9%$Semantic Segmentation#ADE20K#Validation mIoU#47.12$Semantic Segmentation#ADE20K val#mIoU#47.12$Semantic Segmentation#PASCAL Context#mIoU#55.6$Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.6%
1708.04943v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#86.6%
1804.09337v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#86.2%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.7%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#80.60%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#80.3%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#79.3%
1909.03402v4.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#86.1%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#83.2%
1803.08904v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#85.9%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.9%$Semantic Segmentation#ADE20K#Validation mIoU#44.65$Semantic Segmentation#ADE20K#Test Score#55.67$Semantic Segmentation#ADE20K val#mIoU#44.65$Semantic Segmentation#PASCAL Context#mIoU#51.7
1611.10080v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84.9%$Semantic Segmentation#PASCAL Context#mIoU#48.1$Semantic Segmentation#Cityscapes test#Mean IoU (class)#78.4%
1611.06612v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84.2%$Semantic Segmentation#ADE20K#Validation mIoU#40.7$Semantic Segmentation#ADE20K val#mIoU#40.70$Semantic Segmentation#ADE20K val#mIoU#40.20$Semantic Segmentation#COCO-Stuff test#mIoU#33.6%$Semantic Segmentation#PASCAL Context#mIoU#47.3$Semantic Segmentation#NYU Depth v2#Mean IoU#46.5%$Semantic Segmentation#Trans10K#mIoU#58.18%$Semantic Segmentation#Trans10K#GFLOPs#44.56$Semantic Segmentation#Cityscapes test#Mean IoU (class)#73.6%
1811.11254v6.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#84.2%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#79.0%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#74.8%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#16.9$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#59.2
1703.02719v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#83.6%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#81.0%
1809.09299v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#83.3%
1702.08502v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#83.1%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#77.6%
1704.01344v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.7%
1810.03272v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.7%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#82.0%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#81.1%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#79.2%$Semantic Segmentation#NYU Depth v2#Mean IoU#44.4%$Semantic Segmentation#NYU Depth v2#Mean IoU#43.6%$Semantic Segmentation#NYU Depth v2#Mean IoU#41.7%$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#44.4$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#36$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#43.6$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#27$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#41.7$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#20
1603.08358v4.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#80.2%
2206.10589v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#80.2%$Semantic Segmentation#PASCAL VOC 2012 test#FLOPS#8.7G$Semantic Segmentation#PASCAL VOC 2012 test#Params#6.5M$Object Detection#COCO test-dev#box AP#27.9$Object Detection#COCO test-dev#Params (M)#6.2M$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Number of params#5.6M$Image Classification#ImageNet#GFLOPs#2.6$Image Classification#ImageNet#Top 1 Accuracy#71.2%$Image Classification#ImageNet#Number of params#1.3M$Image Classification#ImageNet#GFLOPs#0.522
1606.00915v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#79.7%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#77.69%$Semantic Segmentation#PASCAL Context#mIoU#45.7$Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.4%
1705.08790v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#79.00%$Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#79.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#63.06%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#63.1%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#13$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#76.9
1502.03240v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#74.7%$Semantic Segmentation#PASCAL Context#mIoU#39.3$Real-Time Semantic Segmentation#Cityscapes test#mIoU#62.5%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#700$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#1.4
1603.07485v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#72.8%$Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.6
1506.04579v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.8%$Semantic Segmentation#PASCAL Context#mIoU#40.4
1707.08254v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69%$Semantic Segmentation#PASCAL Context#mIoU#42.6$Semantic Segmentation#NYU Depth v2#Mean IoU#32.3%$Scene Segmentation#NYU Depth v2#Mean IoU#32.3%
1811.11431v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#68.0%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#66.2%$Object Detection#COCO test-dev#box AP#26.0$Object Detection#COCO test-dev#Operations per network pass#0.28G$Image Classification#ImageNet#Top 1 Accuracy#74.9%$Image Classification#ImageNet#Number of params#5.9M$Image Classification#ImageNet#GFLOPs#0.602
1911.08039v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#66.5$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#66.3
1911.01370v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#65.5$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#64.9
1503.01640v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#64.6%$Semantic Segmentation#PASCAL Context#mIoU#40.5
2011.04626v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#63.8%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#62.8%$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#63.8
1803.06815v3.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#63.01%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#60.3%
1701.08261v2.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#56.7%$Semantic Segmentation#PASCAL VOC 2012 val#mIoU#55.7%
1407.1808v1.pdf	Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#51.6%$Object Detection#PASCAL VOC 2012#MAP#50.7
2103.10670v1.pdf	Semantic Segmentation#SBCoseg#Jaccard#0.951
2204.01678v1.pdf	Semantic Segmentation#Hypersim#mIoU#37.0$Semantic Segmentation#Hypersim#mIoU#36.5$Semantic Segmentation#Hypersim#mIoU#32.5$Semantic Segmentation#Hypersim#mIoU#31.7$Semantic Segmentation#ADE20K#Validation mIoU#46.2$Semantic Segmentation#ADE20K val#mIoU#46.2$Semantic Segmentation#NYU Depth v2#Mean IoU#56.0%
2011.14284v2.pdf	Semantic Segmentation#ManipalUAVid#mIoU#0.79
2204.08721v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#53%$Semantic Segmentation#NYU Depth v2#Mean IoU#54.2%$3D Object Detection#ScanNetV2#mAP@0.25#70.8$3D Object Detection#ScanNetV2#mAP@0.5#54.2$3D Object Detection#SUN-RGBD val#mAP@0.25#64.9$3D Object Detection#SUN-RGBD val#mAP@0.5#48.3
2105.04102v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#50.6%$Semantic Segmentation#NYU Depth v2#Mean IoU#52.0%
2201.01427v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#49.6%$Semantic Segmentation#NYU Depth v2#Mean IoU#52.5%
2210.06747v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#49.6%$Semantic Segmentation#NYU Depth v2#Mean IoU#53.3%
2108.10528v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.6$Semantic Segmentation#Stanford2D3D#mIoU#60.6$Semantic Segmentation#RSMSS#mIoU#63.2%$Semantic Segmentation#NYU Depth v2#Mean IoU#51.3
2004.04534v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.6%$Semantic Segmentation#RSMSS#mIoU#63.5%$Semantic Segmentation#NYU Depth v2#Mean IoU#51.0%
2207.04526v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.47%$Semantic Segmentation#NYU Depth v2#Mean IoU#53.34%$Panoptic Segmentation#SUN-RGBD#PQ#52.84$Panoptic Segmentation#NYU Depth v2#PQ#47.38
2002.12041v4.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.3%
2011.06961v3.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.17$Semantic Segmentation#NYU Depth v2#Mean IoU#50.30$Semantic Segmentation#Cityscapes test#Mean IoU (class)#80.09%
1905.10089v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#48.1$Semantic Segmentation#RSMSS#mIoU#62.1%$Semantic Segmentation#NYU Depth v2#Mean IoU#48.3%$Thermal Image Segmentation#MFN Dataset#mIOU#46.3
1806.01054v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#47.8%$Semantic Segmentation#RSMSS#mIoU#62.3%
1912.11691v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#47.0%$Semantic Segmentation#Stanford2D3D#mIoU#52.9$Semantic Segmentation#NYU Depth v2#Mean IoU#44.8%
1705.07238v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#45.1%$Semantic Segmentation#NYU Depth v2#Mean IoU#44.5%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#78.2%
2107.13800v2.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#44.3%$Semantic Segmentation#NYU Depth v2#Mean IoU#42.6%
1803.06791v1.pdf	Semantic Segmentation#SUN-RGBD#Mean IoU#42.0%$Semantic Segmentation#Stanford2D3D#mIoU#39.5$Semantic Segmentation#NYU Depth v2#Mean IoU#43.9%$Thermal Image Segmentation#MFN Dataset#mIOU#46.1
2009.06469v2.pdf	Semantic Segmentation#Cityscapes VIPriors subset#mIoU#58.03$Semantic Segmentation#Cityscapes VIPriors subset#Accuracy#81.68
2011.09980v7.pdf	Semantic Segmentation#SpaceNet 1#Mean IoU#78.48$Semantic Segmentation#SpaceNet 1#Mean IoU#78.05$Semantic Segmentation#SpaceNet 1#Mean IoU#75.57$Semantic Segmentation#SpaceNet 1#Mean IoU#75.23$Semantic Segmentation#SpaceNet 1#Mean IoU#74.93
2105.05409v1.pdf	Semantic Segmentation#FoodSeg103#mIoU#43.9$Semantic Segmentation#FoodSeg103#mIoU#36.8
1811.11721v2.pdf	Semantic Segmentation#FoodSeg103#mIoU#35.5$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.4%$Thermal Image Segmentation#MFN Dataset#mIOU#43.3
1901.05946v2.pdf	Semantic Segmentation#Nighttime Driving#mIoU#45.6$Semantic Segmentation#Dark Zurich#mIoU#42.0
1908.05868v1.pdf	Semantic Segmentation#Nighttime Driving#mIoU#45.09
2108.05137v2.pdf	Semantic Segmentation#Nighttime Driving#mIoU#41.6$Semantic Segmentation#Dark Zurich#mIoU#34.5
1810.02575v1.pdf	Semantic Segmentation#Nighttime Driving#mIoU#36.1
2111.11567v1.pdf	Semantic Segmentation#ATLANTIS#A-acc#68.63$Semantic Segmentation#ATLANTIS#A-mIoU#50.34$Semantic Segmentation#ATLANTIS#Accuracy#75.18$Semantic Segmentation#ATLANTIS#mIoU#42.22
2204.02825v2.pdf	Semantic Segmentation#iSAID#mIoU#65.3$Semantic Segmentation#iSAID#mIoU#64.3$Semantic Segmentation#iSAID#mIoU#64.1$Semantic Segmentation#iSAID#mIoU#61.6$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.6$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.21$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#90.78$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#90.61$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9702$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9681$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.96$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9521$Building change detection for remote sensing images#LEVIR-CD#F1#91.26$Building change detection for remote sensing images#LEVIR-CD#F1#90.93$Building change detection for remote sensing images#LEVIR-CD#F1#90.10$Object Detection In Aerial Images#HRSC2016#mAP-07#90.4$Object Detection In Aerial Images#HRSC2016#mAP-07#90.3$Object Detection In Aerial Images#HRSC2016#mAP-07#90.0$Object Detection In Aerial Images#DOTA#mAP#77.72%$Object Detection In Aerial Images#DOTA#mAP#77.38%$Object Detection In Aerial Images#DOTA#mAP#76.50%$Object Detection In Aerial Images#DOTA#mAP#76.12%
2208.03987v2.pdf	Semantic Segmentation#iSAID#mIoU#64.49$Semantic Segmentation#iSAID#mIoU#63.85$Semantic Segmentation#LoveDA#Category mIoU#52.44$Semantic Segmentation#LoveDA#Category mIoU#51.95$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#91.22$Semantic Segmentation#ISPRS Potsdam#Overall Accuracy#90.77$Object Detection In Aerial Images#DOTA#mAP#81.16%$Object Detection In Aerial Images#DOTA#mAP#81.01%$Object Detection In Aerial Images#DIOR-R#mAP#71.05$Object Detection In Aerial Images#DIOR-R#mAP#70.85
2011.09766v1.pdf	Semantic Segmentation#iSAID#mIoU#63.71
1912.09216v1.pdf	Semantic Segmentation#INRIA Aerial Image Labeling#IoU#80.32$Semantic Segmentation#AIRS#IoU#91.7
2012.07177v2.pdf	Semantic Segmentation#PASCAL VOC 2012 val#mIoU#86.6%$Object Detection#COCO test-dev#box AP#57.3$Object Detection#COCO test-dev#box AP#54.8$Object Detection#COCO minival#box AP#57.0$Object Detection#COCO minival#box AP#54.5$Object Detection#LVIS v1.0 val#box AP#41.6$Object Detection#PASCAL VOC 2007#MAP#89.3%$Instance Segmentation#COCO test-dev#mask AP#49.1$Instance Segmentation#COCO test-dev#mask AP#46.9$Instance Segmentation#LVIS v1.0 val#mask AP#38.1$Instance Segmentation#COCO minival#mask AP#48.9$Instance Segmentation#COCO minival#mask AP#46.8
2012.11582v2.pdf	Semantic Segmentation#PASCAL VOC 2012 val#mIoU#80.61%$Real-Time Semantic Segmentation#CamVid#mIoU#79.1$Real-Time Semantic Segmentation#CamVid#Time (ms)#60.2$Real-Time Semantic Segmentation#CamVid#Frame (fps)#16.6$Real-Time Semantic Segmentation#CamVid#mIoU#78.4$Real-Time Semantic Segmentation#CamVid#Time (ms)#26.3$Real-Time Semantic Segmentation#CamVid#Frame (fps)#38.0$Real-Time Semantic Segmentation#Cityscapes test#mIoU#75.8%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#27.1$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#36.9$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.695$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.597$Dichotomous Image Segmentation#DIS-TE1#MAE#0.082$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.761$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.803$Dichotomous Image Segmentation#DIS-TE1#HCE#205$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.759$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.667$Dichotomous Image Segmentation#DIS-TE2#MAE#0.085$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.794$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.832$Dichotomous Image Segmentation#DIS-TE2#HCE#451$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.792$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.701$Dichotomous Image Segmentation#DIS-TE3#MAE#0.079$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.811$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.857$Dichotomous Image Segmentation#DIS-TE3#HCE#887$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.782$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.693$Dichotomous Image Segmentation#DIS-TE4#MAE#0.091$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.802$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.842$Dichotomous Image Segmentation#DIS-TE4#HCE#3331$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.734$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.640$Dichotomous Image Segmentation#DIS-VD#MAE#0.096$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.773$Dichotomous Image Segmentation#DIS-VD#E-measure#0.814$Dichotomous Image Segmentation#DIS-VD#HCE#1324
1904.01169v3.pdf	Semantic Segmentation#PASCAL VOC 2012 val#mIoU#79.3%$Object Detection#COCO minival#box AP#47.5$Object Detection#COCO minival#AP50#66.5$Object Detection#COCO minival#AP75#51.3$Object Detection#COCO minival#APS#28.6$Object Detection#COCO minival#APM#51.6$Object Detection#COCO minival#APL#62.1$Object Detection#COCO minival#box AP#33.7$Object Detection#COCO minival#AP50#53.6$Object Detection#COCO minival#APS#14$Object Detection#COCO minival#APM#38.3$Object Detection#COCO minival#APL#51.1$RGB Salient Object Detection#HKU-IS#MAE#0.05$RGB Salient Object Detection#HKU-IS#F-measure#0.905$RGB Salient Object Detection#PASCAL-S#MAE#0.099$RGB Salient Object Detection#PASCAL-S#F-measure#0.841$RGB Salient Object Detection#DUT-OMRON#MAE#0.071$RGB Salient Object Detection#DUT-OMRON#F-measure#0.800$RGB Salient Object Detection#ECSSD#MAE#0.056$RGB Salient Object Detection#ECSSD#F-measure#0.926$Image Classification#CIFAR-100#Percentage correct#83.44$Image Classification#ImageNet#Top 1 Accuracy#81.23%$Image Classification#ImageNet#Top 5 Accuracy#94.43%$Image Classification#ImageNet#Top 1 Accuracy#78.59%$Image Classification#ImageNet#Top 5 Accuracy#94.12%$Image Classification#GasHisSDB#Accuracy#98.68$Image Classification#GasHisSDB#Precision#99.91$Image Classification#GasHisSDB#F1-Score#99.29$Instance Segmentation#COCO minival#mask AP#41.3$Instance Segmentation#COCO minival#mask AP#35.6$Instance Segmentation#COCO minival#AP50#57.6$Instance Segmentation#COCO minival#APL#53.7$Instance Segmentation#COCO minival#APM#37.9$Instance Segmentation#COCO minival#APS#15.7$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#93.37$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#96.25$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.93$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.17
1707.02968v2.pdf	Semantic Segmentation#PASCAL VOC 2012 val#mIoU#76.5%$Semantic Segmentation#PASCAL VOC 2007#Mean IoU#81.3$Pose Estimation#COCO test-dev#AP#64.4$Pose Estimation#COCO test-dev#AP50#85.7$Pose Estimation#COCO test-dev#AP75#70.7$Pose Estimation#COCO test-dev#APL#69.8$Pose Estimation#COCO test-dev#APM#61.8$Object Detection#COCO test-dev#box AP#37.4$Object Detection#COCO test-dev#AP50#58$Object Detection#COCO test-dev#AP75#40.1$Object Detection#COCO test-dev#APS#17.5$Object Detection#COCO test-dev#APM#41.1$Object Detection#COCO test-dev#APL#51.2$Image Classification#ImageNet#Top 1 Accuracy#79.2%$Image Classification#ImageNet#Top 5 Accuracy#94.7%
1804.00880v1.pdf	Semantic Segmentation#PASCAL VOC 2012 val#mIoU#53.4%$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#26.8$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#44.3$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#9.0
2103.16765v1.pdf	Semantic Segmentation#DensePASS#mIoU#53.83%
2110.11062v1.pdf	Semantic Segmentation#DensePASS#mIoU#48.52%$Semantic Segmentation#DensePASS#mIoU#41.99%
2111.11418v3.pdf	Semantic Segmentation#DensePASS#mIoU#43.18%$Semantic Segmentation#ADE20K#Validation mIoU#42.7$Object Detection#COCO minival#box AP#41.0$Object Detection#COCO minival#AP50#63.1$Object Detection#COCO minival#AP75#44.8$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Number of params#73M$Image Classification#ImageNet#GFLOPs#23.2
2103.05687v1.pdf	Semantic Segmentation#DensePASS#mIoU#43.02%
2107.08391v2.pdf	Semantic Segmentation#DensePASS#mIoU#42.05%
2107.10224v4.pdf	Semantic Segmentation#DensePASS#mIoU#40.16%$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#76M$Image Classification#ImageNet#GFLOPs#12.3
2107.14467v1.pdf	Semantic Segmentation#DensePASS#mIoU#36.50%
1905.01220v1.pdf	Semantic Segmentation#DensePASS#mIoU#34.14%$Panoptic Segmentation#Indian Driving Dataset#PQ#48.5$Panoptic Segmentation#KITTI Panoptic Segmentation#PQ#42.2
1811.10323v3.pdf	Semantic Segmentation#DensePASS#mIoU#30.87%$Semantic Segmentation#DensePASS#mIoU#26.98%
2007.03815v2.pdf	Semantic Segmentation#DensePASS#mIoU#26.9%
2205.14141v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#61.4$Semantic Segmentation#ADE20K val#mIoU#61.4$Object Detection#COCO test-dev#box AP#64.2$Image Classification#ImageNet#Top 1 Accuracy#89.0%$Image Classification#ImageNet#Number of params#307M$Instance Segmentation#COCO test-dev#mask AP#55.4
2206.02777v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#60.8$Semantic Segmentation#ADE20K#Params (M)#223$Panoptic Segmentation#COCO test-dev#PQ#59.5$Panoptic Segmentation#COCO test-dev#PQst#-$Panoptic Segmentation#COCO test-dev#PQth#-$Panoptic Segmentation#COCO minival#PQ#59.4$Instance Segmentation#COCO test-dev#mask AP#54.7$Instance Segmentation#COCO minival#mask AP#54.5
2207.14284v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#57.9$Object Detection#COCO minival#box AP#59.2$Image Classification#ImageNet#Top 1 Accuracy#87.7%$Image Classification#ImageNet#GFLOPs#101.8
2204.01244v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#57.7
2204.01969v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#57.7
2111.13280v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#57.1$Semantic Segmentation#ADE20K#Validation mIoU#54.2$Semantic Segmentation#ADE20K val#mIoU#57.1$Semantic Segmentation#ADE20K val#mIoU#54.2$Semantic Segmentation#COCO-Stuff test#mIoU#50.1%$Semantic Segmentation#PASCAL Context#mIoU#64.0$Semantic Segmentation#PASCAL Context#mIoU#56.6
2106.08254v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#57.0$Semantic Segmentation#ADE20K val#mIoU#57.0$Document Image Classification#RVL-CDIP#Accuracy#91.09%$Document Image Classification#RVL-CDIP#Parameters#87M$Image Classification#ImageNet#Top 1 Accuracy#88.60%$Image Classification#ImageNet#Top 5 Accuracy#98.66%$Image Classification#ImageNet#Number of params#331M$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#Number of params#86M$Image Classification#OmniBenchmark#Average Top-1 Accuracy#30.1$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#86.3%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#86M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.6%$Document Layout Analysis#PubLayNet val#Text#0.934$Document Layout Analysis#PubLayNet val#Title#0.866$Document Layout Analysis#PubLayNet val#List#0.924$Document Layout Analysis#PubLayNet val#Table#0.973$Document Layout Analysis#PubLayNet val#Figure#0.957$Document Layout Analysis#PubLayNet val#Overall#0.931
2108.07058v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#56.7$Semantic Segmentation#ADE20K val#mIoU#56.7
2209.03917v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#56.2$Semantic Segmentation#ADE20K#Validation mIoU#55.2$Semantic Segmentation#ADE20K#Validation mIoU#52.9$Semantic Segmentation#ADE20K#Validation mIoU#50.8$Object Detection#COCO test-dev#box AP#56.1$Object Detection#COCO test-dev#box AP#53.5$Image Classification#ImageNet#Top 1 Accuracy#89.0%$Image Classification#ImageNet#Top 1 Accuracy#88.2%$Image Classification#ImageNet#Top 1 Accuracy#87.8%$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#632M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#89.0%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#88.0%$Instance Segmentation#COCO test-dev#mask AP#48.3$Instance Segmentation#COCO test-dev#mask AP#46.3
2107.00652v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#55.70$Semantic Segmentation#ADE20K val#mIoU#55.7$Image Classification#ImageNet#Top 1 Accuracy#87.5%$Image Classification#ImageNet#Number of params#173M$Image Classification#ImageNet#GFLOPs#96.8
2107.06278v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#55.6$Semantic Segmentation#ADE20K#Validation mIoU#48.1$Semantic Segmentation#ADE20K val#mIoU#55.6$Semantic Segmentation#Mapillary val#mIoU#55.4$Panoptic Segmentation#COCO test-dev#PQ#53.3$Panoptic Segmentation#COCO test-dev#PQst#44.5$Panoptic Segmentation#COCO test-dev#PQth#59.1$Panoptic Segmentation#COCO minival#PQ#52.7$Panoptic Segmentation#COCO minival#SQ#81.8$Panoptic Segmentation#COCO minival#RQ#63.5$Panoptic Segmentation#COCO minival#PQth#58.5$Panoptic Segmentation#COCO minival#PQst#44.0$Panoptic Segmentation#ADE20K val#PQ#35.7
2107.00641v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#55.40$Semantic Segmentation#ADE20K val#mIoU#55.4$Object Detection#COCO test-dev#box AP#58.9$Object Detection#COCO minival#box AP#58.7$Object Detection#COCO minival#AP50#77.2$Object Detection#COCO minival#APL#73.4$Instance Segmentation#COCO test-dev#mask AP#51.3$Instance Segmentation#COCO test-dev#AP50#75.4$Instance Segmentation#COCO test-dev#AP75#56.5$Instance Segmentation#COCO test-dev#APS#35.6$Instance Segmentation#COCO test-dev#APL#64.2$Instance Segmentation#COCO minival#mask AP#50.9
2202.03026v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#54.7$Object Detection#COCO minival#box AP#54.5$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#86.3%
2202.09741v5.pdf	Semantic Segmentation#ADE20K#Validation mIoU#54.7$Semantic Segmentation#ADE20K#Validation mIoU#50.2$Semantic Segmentation#ADE20K#Params (M)#55$Semantic Segmentation#ADE20K#Validation mIoU#48.1$Semantic Segmentation#ADE20K#Params (M)#49$Semantic Segmentation#ADE20K#Validation mIoU#46.7$Semantic Segmentation#ADE20K#Validation mIoU#42.9$Semantic Segmentation#ADE20K#Params (M)#18$Semantic Segmentation#ADE20K#Validation mIoU#38.5$Semantic Segmentation#ADE20K#Params (M)#8$Panoptic Segmentation#COCO panoptic#PQ#58.2$Image Classification#ImageNet#Top 1 Accuracy#87.8%$Image Classification#ImageNet#Number of params#200M$Image Classification#ImageNet#GFLOPs#114.3$Image Classification#ImageNet#Top 1 Accuracy#87%$Image Classification#ImageNet#Number of params#90M$Image Classification#ImageNet#GFLOPs#50.6$Image Classification#ImageNet#Top 1 Accuracy#86.6%$Image Classification#ImageNet#Number of params#60M$Image Classification#ImageNet#GFLOPs#35.9$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#GFLOPs#17.2$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Image Classification#ImageNet#GFLOPs#12.2$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#26.6M$Image Classification#ImageNet#GFLOPs#5$Image Classification#ImageNet#Top 1 Accuracy#81.1%$Image Classification#ImageNet#Number of params#13.9M$Image Classification#ImageNet#GFLOPs#2.5$Image Classification#ImageNet#Top 1 Accuracy#75.4%$Image Classification#ImageNet#Number of params#4.1M$Image Classification#ImageNet#GFLOPs#0.9
2209.15001v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#54.6$Semantic Segmentation#ADE20K#Validation mIoU#50.4$Semantic Segmentation#ADE20K#Validation mIoU#49.9$Semantic Segmentation#ADE20K#Validation mIoU#48.8$Semantic Segmentation#ADE20K#Validation mIoU#47.2$Image Classification#ImageNet#Top 1 Accuracy#87.4%$Image Classification#ImageNet#Number of params#197M$Image Classification#ImageNet#GFLOPs#101.5$Image Classification#ImageNet#Top 1 Accuracy#87.31%$Image Classification#ImageNet#Number of params#200M$Image Classification#ImageNet#GFLOPs#92.4$Image Classification#ImageNet#Top 1 Accuracy#87.18%$Image Classification#ImageNet#GFLOPs#89.7$Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#GFLOPs#34.5$Image Classification#ImageNet#Top 1 Accuracy#84.4%$Image Classification#ImageNet#Number of params#90M$Image Classification#ImageNet#GFLOPs#13.7$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Number of params#51M$Image Classification#ImageNet#GFLOPs#7.8$Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#4.3$Image Classification#ImageNet#Top 1 Accuracy#81.8%$Image Classification#ImageNet#Number of params#20M$Image Classification#ImageNet#GFLOPs#2.7
2106.14855v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#54.3$Semantic Segmentation#ADE20K val#mIoU#54.3$Panoptic Segmentation#COCO test-dev#PQ#55.2$Panoptic Segmentation#COCO test-dev#PQst#46.2$Panoptic Segmentation#COCO test-dev#PQth#61.2$Panoptic Segmentation#COCO test-dev#PQ#48.3$Panoptic Segmentation#COCO test-dev#PQst#39.7$Panoptic Segmentation#COCO test-dev#PQth#54$Instance Segmentation#COCO test-dev#mask AP#40.6%$Instance Segmentation#COCO test-dev#AP50#63.3$Instance Segmentation#COCO test-dev#APS#18.8$Instance Segmentation#COCO test-dev#APM#43.3$Instance Segmentation#COCO test-dev#APL#59$Instance Segmentation#COCO test-dev#mask AP#40.1%$Instance Segmentation#COCO test-dev#AP50#62.8$Instance Segmentation#COCO test-dev#APS#18.7$Instance Segmentation#COCO test-dev#APM#42.7$Instance Segmentation#COCO test-dev#APL#58.8
2105.05633v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#53.63$Semantic Segmentation#ADE20K#Validation mIoU#50.0$Semantic Segmentation#ADE20K#Validation mIoU#49.61$Semantic Segmentation#ADE20K val#mIoU#53.63$Semantic Segmentation#ADE20K val#mIoU#50.0$Semantic Segmentation#ADE20K val#mIoU#49.61$Semantic Segmentation#ADE20K val#Pixel Accuracy#83.37$Semantic Segmentation#PASCAL Context#mIoU#59.0
2112.13692v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#52.9$Semantic Segmentation#ADE20K#Validation mIoU#52.8$Semantic Segmentation#ADE20K#Validation mIoU#51.1$Semantic Segmentation#ADE20K#Validation mIoU#49.3$Semantic Segmentation#ADE20K val#mIoU#52.9$Semantic Segmentation#ADE20K val#mIoU#52.8$Semantic Segmentation#ADE20K val#mIoU#51.1$Semantic Segmentation#ADE20K val#mIoU#49.3$Object Detection#COCO minival#box AP#47.0$Object Detection#COCO minival#box AP#46.4$Image Classification#ImageNet#Top 1 Accuracy#87.1%$Image Classification#ImageNet#Number of params#334.3M$Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#Number of params#99.4M$Image Classification#ImageNet#Top 1 Accuracy#85.4%$Image Classification#ImageNet#Number of params#25.2M$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Number of params#188.6M$Image Classification#ImageNet#Top 1 Accuracy#83.5%$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#47.7M$Image Classification#ImageNet#Top 1 Accuracy#82.1%
2104.10858v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#51.8$Semantic Segmentation#ADE20K#Params (M)#209$Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Number of params#151M$Image Classification#ImageNet#GFLOPs#214.8$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Number of params#56M$Image Classification#ImageNet#GFLOPs#16$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#26M$Image Classification#ImageNet#GFLOPs#6.6
2108.00154v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#51.4$Semantic Segmentation#ADE20K val#mIoU#51.4%$Semantic Segmentation#ADE20K val#Pixel Accuracy#84.0%
2203.06108v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#51.1$Semantic Segmentation#ADE20K#Params (M)#108$Object Detection#COCO minival#box AP#52.3$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Number of params#76.4M$Image Classification#ImageNet#GFLOPs#12.3$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Number of params#27.2M$Image Classification#ImageNet#GFLOPs#4
2106.03650v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#50.5$Semantic Segmentation#ADE20K#Validation mIoU#47.6$Semantic Segmentation#ADE20K val#mIoU#50.5$Semantic Segmentation#ADE20K val#mIoU#49.6$Semantic Segmentation#ADE20K val#mIoU#47.6
2112.12786v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#50.3$Semantic Segmentation#ADE20K val#mIoU#50.3$Object Detection#COCO minival#box AP#51.6$Object Detection#COCO minival#AP50#70.5$Object Detection#COCO minival#AP75#56.0$Object Detection#COCO minival#box AP#48.3$Object Detection#COCO minival#AP50#70.4$Object Detection#COCO minival#AP75#52.9$Image Classification#ImageNet#Top 1 Accuracy#87.2%$Image Classification#ImageNet#Number of params#298M$Image Classification#ImageNet#GFLOPs#437$Image Classification#ImageNet#Top 1 Accuracy#84.7%$Image Classification#ImageNet#Number of params#27M$Image Classification#ImageNet#GFLOPs#8$Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#4.8$Instance Segmentation#COCO minival#mask AP#44.4$Instance Segmentation#COCO minival#AP50#67.8$Instance Segmentation#COCO minival#AP75#47.8$Instance Segmentation#COCO minival#mask AP#43.0$Instance Segmentation#COCO minival#AP50#67.3$Instance Segmentation#COCO minival#AP75#46.4
2104.13840v4.pdf	Semantic Segmentation#ADE20K#Validation mIoU#50.2$Semantic Segmentation#ADE20K val#mIoU#50.2$Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Number of params#99.2M$Image Classification#ImageNet#GFLOPs#15.1
2204.07143v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#49.7$Semantic Segmentation#ADE20K#Params (M)#123$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1137$Semantic Segmentation#ADE20K#Validation mIoU#49.5$Semantic Segmentation#ADE20K#Params (M)#82$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1010$Semantic Segmentation#ADE20K#Validation mIoU#48.4$Semantic Segmentation#ADE20K#Params (M)#58$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#934$Semantic Segmentation#ADE20K#Validation mIoU#46.4$Semantic Segmentation#ADE20K#Params (M)#50$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#900$Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Number of params#90M$Image Classification#ImageNet#GFLOPs#13.7$Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Number of params#51M$Image Classification#ImageNet#GFLOPs#7.8$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#4.3$Image Classification#ImageNet#Top 1 Accuracy#81.8%$Image Classification#ImageNet#Number of params#20M$Image Classification#ImageNet#GFLOPs#2.7
2204.03645v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#49.4$Semantic Segmentation#ADE20K#Validation mIoU#46.3$Semantic Segmentation#ADE20K val#mIoU#48.8$Semantic Segmentation#ADE20K val#mIoU#46.3$Object Detection#COCO minival#box AP#49.9$Object Detection#COCO minival#box AP#49.5$Object Detection#COCO minival#box AP#47.4$Image Classification#ImageNet#Top 1 Accuracy#90.4%$Image Classification#ImageNet#Number of params#1437M$Image Classification#ImageNet#GFLOPs#1038$Image Classification#ImageNet#Top 1 Accuracy#90.2%$Image Classification#ImageNet#Number of params#362M$Image Classification#ImageNet#GFLOPs#334$Image Classification#ImageNet#Top 1 Accuracy#87.5%$Image Classification#ImageNet#Number of params#196.8M$Image Classification#ImageNet#GFLOPs#103$Image Classification#ImageNet#Top 1 Accuracy#86.9%$Image Classification#ImageNet#Number of params#87.9M$Image Classification#ImageNet#GFLOPs#46.4$Image Classification#ImageNet#Top 1 Accuracy#84.6%$Image Classification#ImageNet#GFLOPs#15.5$Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#Number of params#49.7M$Image Classification#ImageNet#GFLOPs#8.8$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#28.3M$Image Classification#ImageNet#GFLOPs#4.5$Instance Segmentation#COCO minival#mask AP#44.6$Instance Segmentation#COCO minival#mask AP#44.3$Instance Segmentation#COCO minival#mask AP#42.9
2201.00520v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#49.38$Semantic Segmentation#ADE20K#Params (M)#121$Semantic Segmentation#ADE20K#Validation mIoU#48.31$Semantic Segmentation#ADE20K#Params (M)#81$Semantic Segmentation#ADE20K#Validation mIoU#45.54$Semantic Segmentation#ADE20K#Params (M)#60$Object Detection#COCO test-dev#AP#47.9$Object Detection#COCO test-dev#AP50#69.6$Object Detection#COCO test-dev#AP75#51.2$Object Detection#COCO test-dev#APS#32.3$Object Detection#COCO test-dev#APM#51.8$Object Detection#COCO test-dev#APL#63.4$Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#GFLOPs#49.8$Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Number of params#50M$Image Classification#ImageNet#GFLOPs#9.0$Image Classification#ImageNet#Top 1 Accuracy#82.0%$Image Classification#ImageNet#Number of params#29M$Image Classification#ImageNet#GFLOPs#4.6
2201.10801v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#49.2$Semantic Segmentation#ADE20K#Validation mIoU#47.9$Semantic Segmentation#ADE20K#Validation mIoU#47.8$Semantic Segmentation#ADE20K#Validation mIoU#46.3$Object Detection#COCO minival#APM#42.3$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#GFLOPs#15.2$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#50M$Image Classification#ImageNet#GFLOPs#8.5$Image Classification#ImageNet#Top 1 Accuracy#81.7%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#4.4
2206.09959v3.pdf	Semantic Segmentation#ADE20K#Validation mIoU#49$Semantic Segmentation#ADE20K#Params (M)#125$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1348$Semantic Segmentation#ADE20K#Validation mIoU#48.3$Semantic Segmentation#ADE20K#Params (M)#84$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#1163$Semantic Segmentation#ADE20K#Validation mIoU#46.5$Semantic Segmentation#ADE20K#Params (M)#58$Semantic Segmentation#ADE20K#GFLOPs (512 x 512)#947$Image Classification#ImageNet#Top 1 Accuracy#84.5%$Image Classification#ImageNet#Number of params#90M$Image Classification#ImageNet#GFLOPs#14.8$Image Classification#ImageNet#Top 1 Accuracy#84.0%$Image Classification#ImageNet#Number of params#51M$Image Classification#ImageNet#GFLOPs#8.5$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#4.7$Image Classification#ImageNet#Top 1 Accuracy#82.0%$Image Classification#ImageNet#Number of params#20M$Image Classification#ImageNet#GFLOPs#2.6$Image Classification#ImageNet#Top 1 Accuracy#79.8%$Image Classification#ImageNet#Number of params#12M$Image Classification#ImageNet#GFLOPs#2.1
1905.05173v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#48.8$Image Classification#10,000 People - Human Pose Recognition Data#0..5sec#1
2106.09681v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#48.4$Semantic Segmentation#ADE20K#Validation mIoU#48.1$Semantic Segmentation#ADE20K#Validation mIoU#47.1$Semantic Segmentation#ADE20K#Validation mIoU#46.9$Semantic Segmentation#ADE20K#Validation mIoU#46.6$Semantic Segmentation#ADE20K#Validation mIoU#44.2$Object Detection#COCO minival#box AP#48.5$Object Detection#COCO minival#box AP#48.1$Image Classification#ImageNet#Top 1 Accuracy#86%$Image Classification#ImageNet#Number of params#189M$Image Classification#ImageNet#GFLOPs#417.9$Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#84M$Image Classification#ImageNet#GFLOPs#188$Image Classification#ImageNet#Top 1 Accuracy#85.6%$Image Classification#ImageNet#Number of params#48M$Image Classification#ImageNet#GFLOPs#106$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Number of params#26M$Image Classification#ImageNet#GFLOPs#55.6$Instance Segmentation#COCO minival#mask AP#43.7$Instance Segmentation#COCO minival#mask AP#43.0
2109.10322v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#47.54$Semantic Segmentation#ADE20K#Validation mIoU#47.38$Semantic Segmentation#PASCAL Context#mIoU#57$Semantic Segmentation#PASCAL Context#mIoU#56.0
2006.11538v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.99$Semantic Segmentation#ADE20K#Test Score#56.52$Semantic Segmentation#ADE20K val#mIoU#45.99$Semantic Segmentation#ADE20K val#Pixel Accuracy#82.49$Image Classification#ImageNet#Top 1 Accuracy#81.49%$Image Classification#ImageNet#Top 5 Accuracy#95.72%$Image Classification#ImageNet#Number of params#42.3M
1911.01664v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.90$Semantic Segmentation#ADE20K val#mIoU#45.90
2003.13328v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.6$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.0%
2105.04553v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.58$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75%$Self-Supervised Image Classification#ImageNet#Number of Params#29M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#72.8%$Self-Supervised Image Classification#ImageNet#Number of Params#22M
1908.07678v5.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.24$Semantic Segmentation#ADE20K val#mIoU#45.24$Semantic Segmentation#COCO-Stuff test#mIoU#37.2%$Semantic Segmentation#PASCAL Context#mIoU#52.8$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.3%
1911.05250v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#45.02$Semantic Segmentation#ADE20K#Test Score#56.32$Semantic Segmentation#ADE20K#Validation mIoU#44.55$Semantic Segmentation#ADE20K#Test Score#56.41$Semantic Segmentation#ADE20K val#mIoU#45.02$Semantic Segmentation#PASCAL Context#mIoU#53.9
1903.11816v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#44.34$Semantic Segmentation#ADE20K#Test Score#55.84$Semantic Segmentation#PASCAL Context#mIoU#53.1
1803.06067v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#43.68$Semantic Segmentation#ADE20K val#mIoU#43.68$Semantic Segmentation#Cityscapes test#Mean IoU (class)#77.8%
1807.10221v1.pdf	Semantic Segmentation#ADE20K#Validation mIoU#42.66$Semantic Segmentation#ADE20K val#mIoU#42.66
2111.10007v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#40.4$Neural Architecture Search#ImageNet#Top-1 Error Rate#18.2$Neural Architecture Search#ImageNet#FLOPs#726M$Neural Architecture Search#ImageNet#Top-1 Error Rate#18.3$Neural Architecture Search#ImageNet#Accuracy#81.7$Neural Architecture Search#ImageNet#FLOPs#685M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.8$Neural Architecture Search#ImageNet#Accuracy#77.2$Neural Architecture Search#ImageNet#FLOPs#215M$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#GFLOPs#2.1$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#GFLOPs#1$Image Classification#ImageNet#Top 1 Accuracy#81.8%$Image Classification#ImageNet#GFLOPs#0.726$Image Classification#ImageNet#Top 1 Accuracy#81.7%$Image Classification#ImageNet#GFLOPs#0.685$Image Classification#ImageNet#Top 1 Accuracy#78.4%$Image Classification#ImageNet#GFLOPs#0.280$Image Classification#ImageNet#Top 1 Accuracy#77.2%$Image Classification#ImageNet#GFLOPs#0.215
2109.04454v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#40$Semantic Segmentation#ADE20K#Validation mIoU#38.6$Semantic Segmentation#ADE20K#Validation mIoU#35.8$Image Classification#CIFAR-100#Percentage correct#89.1$Image Classification#CIFAR-100#Percentage correct#88.6$Image Classification#CIFAR-100#Percentage correct#87.4$Image Classification#ImageNet#Top 1 Accuracy#80.2%$Image Classification#ImageNet#Number of params#42.7M$Image Classification#ImageNet#Top 1 Accuracy#79%$Image Classification#ImageNet#Number of params#17.4M$Image Classification#ImageNet#Top 1 Accuracy#76.8$Image Classification#ImageNet#Number of params#9M$Image Classification#Flowers-102#Accuracy#99.5$Image Classification#CIFAR-10#Percentage correct#98.6$Image Classification#CIFAR-10#Percentage correct#98
2003.13880v2.pdf	Semantic Segmentation#ADE20K#Validation mIoU#35.8$Semantic Segmentation#ADE20K#Validation mIoU#32.42$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.0$Neural Architecture Search#CIFAR-10 Image Classification#Params#2.1M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#200M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.4$Neural Architecture Search#ImageNet#Accuracy#76.6$Neural Architecture Search#ImageNet#Params#4.0M$Neural Architecture Search#ImageNet#MACs#318M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.7$Neural Architecture Search#ImageNet#Accuracy#75.3$Neural Architecture Search#ImageNet#Params#3.4M$Neural Architecture Search#ImageNet#MACs#218M$Neural Architecture Search#ImageNet#Top-1 Error Rate#28.4$Neural Architecture Search#ImageNet#Accuracy#71.6$Neural Architecture Search#ImageNet#Params#2.4M$Neural Architecture Search#ImageNet#MACs#117M$Neural Architecture Search#ImageNet#Top-1 Error Rate#33.3$Neural Architecture Search#ImageNet#Accuracy#66.7$Neural Architecture Search#ImageNet#Params#1.8M$Neural Architecture Search#ImageNet#MACs#66M$Neural Architecture Search#CIFAR-100#FLOPS#200M$Neural Architecture Search#CIFAR-100#Percentage Error#13.9$Neural Architecture Search#CIFAR-100#PARAMS#2.1M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.0%$Neural Architecture Search#CIFAR-10#Parameters#2.1M$Neural Architecture Search#CIFAR-10#FLOPS#200M$Image Classification#CIFAR-100#Percentage correct#86.1$Image Classification#CIFAR-100#PARAMS#2.1M$Image Classification#ImageNet#Top 1 Accuracy#76.6%$Image Classification#ImageNet#Top 5 Accuracy#93.2$Image Classification#ImageNet#Number of params#4.0M$Image Classification#ImageNet#GFLOPs#0.636$Image Classification#ImageNet#Top 1 Accuracy#75.3%$Image Classification#ImageNet#Top 5 Accuracy#92.5$Image Classification#ImageNet#Number of params#3.4M$Image Classification#ImageNet#GFLOPs#0.436$Image Classification#ImageNet#Top 1 Accuracy#71.6%$Image Classification#ImageNet#Top 5 Accuracy#90.3$Image Classification#ImageNet#Number of params#2.4M$Image Classification#ImageNet#GFLOPs#0.234$Image Classification#ImageNet#Top 1 Accuracy#66.7%$Image Classification#ImageNet#Top 5 Accuracy#86.8$Image Classification#ImageNet#Number of params#1.8M$Image Classification#ImageNet#GFLOPs#0.132$Image Classification#CIFAR-10#Percentage correct#98.0$Image Classification#CIFAR-10#PARAMS#2.1M$Pneumonia Detection#ChestX-ray14#AUROC#0.841$Pneumonia Detection#ChestX-ray14#Params#2.1M$Pneumonia Detection#ChestX-ray14#FLOPS#200M
2105.10203v1.pdf	Semantic Segmentation#Semantic3D#mIoU#77.8%
1908.06295v1.pdf	Semantic Segmentation#Semantic3D#mIoU#69.3%$Semantic Segmentation#S3DIS#Mean IoU#66.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.1
1804.03583v1.pdf	Semantic Segmentation#Semantic3D#mIoU#65.3%
1808.00495v1.pdf	Semantic Segmentation#Semantic3D#mIoU#62.7%
1705.03428v1.pdf	Semantic Segmentation#Semantic3D#mIoU#58.5%
2110.08733v6.pdf	Semantic Segmentation#LoveDA#Category mIoU#49.79
1505.07110v2.pdf	Semantic Segmentation#S3DIS#Mean IoU#74.4$Semantic Segmentation#S3DIS#mAcc#83.2$Semantic Segmentation#S3DIS#oAcc#90.6$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#87.0$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#88.4$3D Point Cloud Classification#ScanObjectNN#Number of params#1.4M$3D Point Cloud Classification#ScanObjectNN#FLOPs#1.64G
2108.12468v1.pdf	Semantic Segmentation#S3DIS#Mean IoU#70.8$Semantic Segmentation#ScanNet#3DIoU#0.682$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.1
2112.04702v2.pdf	Semantic Segmentation#S3DIS#Mean IoU#70.3
2003.00492v3.pdf	Semantic Segmentation#S3DIS#Mean IoU#68.7$Semantic Segmentation#S3DIS#mAcc#79.0$Semantic Segmentation#S3DIS#oAcc#88.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.2
2004.04462v3.pdf	Semantic Segmentation#S3DIS#Mean IoU#68.4$LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.827
1904.02375v5.pdf	Semantic Segmentation#S3DIS#Mean IoU#68.2$Semantic Segmentation#S3DIS#oAcc#88.8$3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.4$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.8$LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.759$LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.720
2007.06888v1.pdf	Semantic Segmentation#S3DIS#Mean IoU#67.7
2007.11679v4.pdf	Semantic Segmentation#S3DIS#Mean IoU#67.4
1904.08017v1.pdf	Semantic Segmentation#S3DIS#Mean IoU#65.4$Semantic Segmentation#S3DIS#oAcc#88.1$Semantic Segmentation#S3DIS#Mean IoU#62.9$Semantic Segmentation#S3DIS#oAcc#87.3$Semantic Segmentation#S3DIS#Mean IoU#62.1$Semantic Segmentation#S3DIS#oAcc#85.5$Semantic Segmentation#S3DIS#Mean IoU#56.3$Semantic Segmentation#S3DIS#oAcc#86.9$Semantic Segmentation#S3DIS#Mean IoU#47.6$Semantic Segmentation#S3DIS#oAcc#78.5$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.6
2111.10332v4.pdf	Semantic Segmentation#S3DIS#Mean IoU#63.3$Semantic Segmentation#S3DIS#mAcc#70.9$3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.9$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.5$3D Point Cloud Classification#ModelNet40#Number of params#1.16M
1902.09852v2.pdf	Semantic Segmentation#S3DIS#Mean IoU#59.3$3D Instance Segmentation#S3DIS#mRec#47.5$3D Instance Segmentation#S3DIS#mPrec#63.6
1802.04402v2.pdf	Semantic Segmentation#S3DIS#Mean IoU#56.5$Semantic Segmentation#S3DIS#mAcc#66.5
2204.07118v1.pdf	Semantic Segmentation#ADE20K val#mIoU#55.6$Semantic Segmentation#ADE20K val#mIoU#54.1$Image Classification#ImageNet#Top 1 Accuracy#86.7%$Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#304.8M$Image Classification#ImageNet#GFLOPs#191.2$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Image Classification#ImageNet#Top 1 Accuracy#85.2%$Image Classification#ImageNet#Top 1 Accuracy#85.0%$Image Classification#ImageNet#Number of params#87M$Image Classification#ImageNet#Top 1 Accuracy#84.9%$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Number of params#22M$Image Classification#ImageNet#GFLOPs#15.5$Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Top 1 Accuracy#81.4%$Image Classification#ImageNet ReaL#Top 1 Accuracy#87.7%$Image Classification#ImageNet ReaL#Number of params#304M$Image Classification#ImageNet ReaL#Top 1 Accuracy#87.2%$Image Classification#ImageNet ReaL#Number of params#632M$Image Classification#ImageNet ReaL#Top 1 Accuracy#87.0%
2205.13137v3.pdf	Semantic Segmentation#ADE20K val#mIoU#53.8$Semantic Segmentation#ADE20K val#mIoU#50.3$Object Detection#COCO 2017#mAP#54.1$Object Detection#COCO 2017#mAP#52.2$Image Classification#Places205#Top 1 Accuracy#69.3$Image Classification#Places205#Top 1 Accuracy#68.3$Image Classification#iNaturalist 2018#Top-1 Accuracy#80.3%$Image Classification#iNaturalist 2018#Top-1 Accuracy#77.5%$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#GFLOPs#16.3$Image Classification#iNaturalist 2019#Top-1 Accuracy#83.9$Image Classification#Places365#Top 1 Accuracy#60.3$Image Classification#Places365#Top 1 Accuracy#58.9
2208.11718v1.pdf	Semantic Segmentation#ADE20K val#mIoU#49.69$Semantic Segmentation#ADE20K val#Pixel Accuracy#83.43$Semantic Segmentation#ADE20K val#mIoU#47.63$Semantic Segmentation#ADE20K val#Pixel Accuracy#82.60$Semantic Segmentation#ADE20K val#mIoU#45.07$Semantic Segmentation#ADE20K val#Pixel Accuracy#81.79$Image Classification#ImageNet#Top 1 Accuracy#83.01%$Image Classification#ImageNet#Top 5 Accuracy#96.32%$Image Classification#ImageNet#Number of params#39.8M$Image Classification#ImageNet#GFLOPs#7.0$Image Classification#ImageNet#Top 1 Accuracy#81.71%$Image Classification#ImageNet#Top 5 Accuracy#95.80%$Image Classification#ImageNet#Number of params#21.8M$Image Classification#ImageNet#GFLOPs#3.6$Image Classification#ImageNet#Top 1 Accuracy#80.32%$Image Classification#ImageNet#Top 5 Accuracy#95.08%$Image Classification#ImageNet#Number of params#15.5M$Image Classification#ImageNet#GFLOPs#2.3$Instance Segmentation#COCO test-dev#mask AP#45.03$Instance Segmentation#COCO test-dev#mask AP#44.16$Instance Segmentation#COCO test-dev#mask AP#42.87
2103.17070v1.pdf	Semantic Segmentation#RSMSS#mIoU#33.1%$Unsupervised Semantic Segmentation#COCO-All#mIoU#14.36$Unsupervised Semantic Segmentation#COCO-All#Pixel Accuracy#49.99$Unsupervised Semantic Segmentation#COCO-All#mIoU#13.84$Unsupervised Semantic Segmentation#COCO-All#Pixel Accuracy#48.09$Unsupervised Semantic Segmentation#COCO-Stuff#Pixel Accuracy#31.48$Unsupervised Semantic Segmentation#Cityscapes test#mIoU#12.3$Unsupervised Semantic Segmentation#Cityscapes test#Accuracy#65.5
1807.05520v2.pdf	Semantic Segmentation#RSMSS#mIoU#30.8%$Unsupervised Semantic Segmentation#Cityscapes test#mIoU#7.1$Unsupervised Semantic Segmentation#Cityscapes test#Accuracy#40.7$Image Clustering#CIFAR-100#Accuracy#0.189$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#CIFAR-10#Accuracy#0.374$Image Clustering#CIFAR-10#NMI#-$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#-$Image Clustering#CIFAR-10#Backbone#ResNet-34
2102.06191v3.pdf	Semantic Segmentation#RSMSS#mIoU#27.1%$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Linear Classifier [mIoU]#63.9$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#44.2$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Linear Classifier [mIoU]#58.4$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#35.0
1807.06653v4.pdf	Semantic Segmentation#RSMSS#mIoU#20.3%$Unsupervised Semantic Segmentation#Potsdam-3#Accuracy#45.4$Unsupervised Semantic Segmentation#COCO-Stuff#Pixel Accuracy#27.7$Unsupervised Semantic Segmentation#Potsdam#Accuracy#65.1$Unsupervised Semantic Segmentation#COCO-Stuff-3#Accuracy#72.3$Unsupervised Semantic Segmentation#COCO-Stuff-15#Accuracy#27.7$Image Clustering#CIFAR-10#Accuracy#0.617$Image Clustering#CIFAR-10#NMI#0.511$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.411$Image Clustering#CIFAR-10#Backbone#ResNet-34$Image Classification#STL-10#Percentage correct#88.8$Semi-Supervised Image Classification#STL-10#Accuracy#88.8$Unsupervised Image Classification#MNIST#Accuracy#99.3$Unsupervised Image Classification#CIFAR-20#Accuracy#25.7$Unsupervised Image Classification#CIFAR-10#Accuracy#61.7$Unsupervised Image Classification#STL-10#Accuracy#61.00
2101.07434v5.pdf	Semantic Segmentation#COCO-Stuff test#mIoU#45.4%$Semantic Segmentation#COCO-Stuff test#mIoU#41.2%$Semantic Segmentation#PASCAL Context#mIoU#60.5$Semantic Segmentation#PASCAL Context#mIoU#60.1$Semantic Segmentation#PASCAL Context#mIoU#55.0$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.6%
1909.02651v1.pdf	Semantic Segmentation#COCO-Stuff test#mIoU#39.6%$Semantic Segmentation#PASCAL Context#mIoU#53.2$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.0%
1509.00552v2.pdf	Semantic Segmentation#COCO-Stuff test#mIoU#31.2%
1910.00694v1.pdf	Semantic Segmentation#OpenEDS#mIOU#95.3
1901.00326v3.pdf	Semantic Segmentation#PASCAL VOC 2011 test#Mean IoU#72.2
1605.06211v1.pdf	Semantic Segmentation#PASCAL VOC 2011 test#Mean IoU#32$Semantic Segmentation#PASCAL VOC 2011 test#Mean IoU#22.4$Semantic Segmentation#NYU Depth v2#Mean Accuracy#44$Semantic Segmentation#Cityscapes test#Mean IoU (class)#65.3%$Scene Segmentation#SUN-RGBD#Mean IoU#27.39$Video Semantic Segmentation#Cityscapes val#mIoU#70.1
2210.04218v1.pdf	Semantic Segmentation#Mila Simulated Floods#mIoU#0.93$Semantic Segmentation#Graz-02#Pixel Accuracy#0.96
2207.13297v2.pdf	Semantic Segmentation#Dark Zurich#mIoU#46.4
1907.00135v2.pdf	Semantic Segmentation#ScanNetV2#Mean IoU#59.2%
1803.10409v1.pdf	Semantic Segmentation#ScanNetV2#Mean IoU#49.8%$Semantic Segmentation#ScanNet#3DIoU#0.484$Scene Segmentation#ScanNet#Average Accuracy#75.0%
2112.13762v1.pdf	Semantic Segmentation#ScanNetV2#Mean IoU#48.5%
1606.02147v1.pdf	Semantic Segmentation#ScanNetV2#Mean IoU#37.6%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#58.3%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#58.3%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#13$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#76.9
1702.04405v2.pdf	Semantic Segmentation#ScanNetV2#Mean IoU#33.0%$Semantic Segmentation#ScanNet#3DIoU#0.306
1906.06792v1.pdf	Semantic Segmentation#ScanNetV2#Pixel Accuracy#65.6$Surface Normals Estimation#ScanNetV2#% < 11.25#50.9$Surface Normals Estimation#ScanNetV2#% < 22.5#65.2$Surface Normals Estimation#ScanNetV2#% < 30#70$Surface Normals Estimation#ScanNetV2#Mean Angle Error#28$Surface Normals Estimation#NYU Depth v2#% < 11.25#59.5$Surface Normals Estimation#NYU Depth v2#% < 22.5#72.2$Surface Normals Estimation#NYU Depth v2#% < 30#77.3$Surface Normals Estimation#NYU Depth v2#Mean Angle Error#19.7$Surface Normals Estimation#NYU Depth v2#RMSE#19.3
2203.07160v2.pdf	Semantic Segmentation#PASCAL Context#mIoU#64.1
1909.06121v3.pdf	Semantic Segmentation#PASCAL Context#mIoU#53.7$Semantic Segmentation#Cityscapes test#Mean IoU (class)#82%
1909.00179v1.pdf	Semantic Segmentation#PASCAL Context#mIoU#53.6$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.4%
1903.02120v3.pdf	Semantic Segmentation#PASCAL Context#mIoU#52.5
1605.06885v1.pdf	Semantic Segmentation#PASCAL Context#mIoU#44.5
1504.01013v4.pdf	Semantic Segmentation#PASCAL Context#mIoU#43.3$Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.6%
1511.08119v4.pdf	Semantic Segmentation#PASCAL Context#mIoU#41.3
1412.1283v4.pdf	Semantic Segmentation#PASCAL Context#mIoU#34.4
2005.02551v1.pdf	Semantic Segmentation#BIG#IoU#93.93$Semantic Segmentation#BIG#mBA#75.32$Semantic Segmentation#BIG#IoU#92.79$Semantic Segmentation#BIG#mBA#74.77$Semantic Segmentation#BIG#IoU#92.23$Semantic Segmentation#BIG#mBA#74.59$Semantic Segmentation#BIG#IoU#77.87$Semantic Segmentation#BIG#mBA#67.04
2111.02333v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#53.5%
2104.02745v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#53.1%
2112.02252v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#52.5%
2109.13432v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#52.2%
2108.05009v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#51.2%
2206.03939v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#51.2%
2204.00102v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#51.0%
2011.02572v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#50.7%
2111.12608v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#50.4%
2106.11059v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#49.14%
2001.06902v5.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#49.0
2103.14431v3.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#48.88%
2007.09365v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#48.8%
2107.02575v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#48.1%
2104.13874v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#46.33%
2101.07422v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#45.0%
2004.01800v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#43.5$Semantic Segmentation#NYU Depth v2#Mean IoU#37.4$Real-Time Semantic Segmentation#CamVid#mIoU#76.0$Real-Time Semantic Segmentation#CamVid#Time (ms)#90$Real-Time Semantic Segmentation#CamVid#Frame (fps)#11(TitanX)$Real-Time Semantic Segmentation#CamVid#mIoU#72.6$Real-Time Semantic Segmentation#CamVid#Time (ms)#40$Real-Time Semantic Segmentation#CamVid#Frame (fps)#25(TitanX)$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#43.5$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#35$Real-Time Semantic Segmentation#NYU Depth v2#mIoU#37.4$Real-Time Semantic Segmentation#NYU Depth v2#Speed(ms/f)#19$Real-Time Semantic Segmentation#Cityscapes test#mIoU#74.9%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#21$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#47.6 (Titan X)$Video Semantic Segmentation#Cityscapes val#mIoU#79.9
1801.08297v4.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#43.3%
2210.06989v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#41.51%
1707.06426v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#41.2%
2206.08927v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#40.84%
1604.02388v3.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#40.1%
2210.00923v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#39.31%
1703.04977v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#37.3%
2002.02200v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#33.49%
2210.07239v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#33.48%
1911.12423v2.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#29.6%
2210.01384v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#22.1%
1604.03539v1.pdf	Semantic Segmentation#NYU Depth v2#Mean IoU#19.3%
2101.08461v3.pdf	Semantic Segmentation#Trans10K#mIoU#72.15%$Semantic Segmentation#Trans10K#GFLOPs#49.03
2003.13948v3.pdf	Semantic Segmentation#Trans10K#mIoU#69.00%$Semantic Segmentation#Trans10K#GFLOPs#61.31
1809.00916v4.pdf	Semantic Segmentation#Trans10K#mIoU#66.31%$Semantic Segmentation#Trans10K#GFLOPs#43.31$Semantic Segmentation#Cityscapes test#Mean IoU (class)#81.7%
1704.08545v2.pdf	Semantic Segmentation#Trans10K#mIoU#23.39%$Semantic Segmentation#Trans10K#GFLOPs#10.64$Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.6%$Real-Time Semantic Segmentation#CamVid#mIoU#67.1%$Real-Time Semantic Segmentation#CamVid#Time (ms)#36$Real-Time Semantic Segmentation#CamVid#Frame (fps)#27.8$Real-Time Semantic Segmentation#Cityscapes test#mIoU#70.6%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#33$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#30.3$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.631$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.535$Dichotomous Image Segmentation#DIS-TE1#MAE#0.095$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.716$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.784$Dichotomous Image Segmentation#DIS-TE1#HCE#234$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.716$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.627$Dichotomous Image Segmentation#DIS-TE2#MAE#0.095$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.759$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.826$Dichotomous Image Segmentation#DIS-TE2#HCE#512$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.752$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.664$Dichotomous Image Segmentation#DIS-TE3#MAE#0.091$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.780$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.852$Dichotomous Image Segmentation#DIS-TE3#HCE#1001$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.749$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.663$Dichotomous Image Segmentation#DIS-TE4#MAE#0.099$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.776$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.837$Dichotomous Image Segmentation#DIS-TE4#HCE#3690$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.697$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.609$Dichotomous Image Segmentation#DIS-VD#MAE#0.102$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.747$Dichotomous Image Segmentation#DIS-VD#E-measure#0.811$Dichotomous Image Segmentation#DIS-VD#HCE#1503
2206.07298v2.pdf	Semantic Segmentation#Cityscapes#mIoU#77.8$Real-Time Semantic Segmentation#CamVid#mIoU#74.2$Real-Time Semantic Segmentation#CamVid#mIoU#71.0$Real-Time Semantic Segmentation#CamVid#Frame (fps)#107.2$Real-Time Semantic Segmentation#CamVid#mIoU#69.5$Real-Time Semantic Segmentation#CamVid#Frame (fps)#124.2$Real-Time Semantic Segmentation#Cityscapes#mIoU#77.4$Real-Time Semantic Segmentation#Cityscapes#mIoU#76.2
2107.07933v4.pdf	Semantic Segmentation#PASTIS#Number of Params#1.1M$Semantic Segmentation#PASTIS#Overall Accuracy#83.2$Semantic Segmentation#PASTIS#Mean IoU (test)#63.1$Panoptic Segmentation#PASTIS#SQ#81.3$Panoptic Segmentation#PASTIS#RQ#49.2$Panoptic Segmentation#PASTIS#PQ#40.4
2011.12025v2.pdf	Semantic Segmentation#Mapillary val#mIoU#39.7$Real-Time Semantic Segmentation#Cityscapes test#mIoU#73.8%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#48.6 (1080Ti)
2004.02307v3.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#84.21%$Panoptic Segmentation#Mapillary val#PQ#40.6$Panoptic Segmentation#Cityscapes val#PQ#67.5$Panoptic Segmentation#Cityscapes val#PQst#70.3$Panoptic Segmentation#Cityscapes val#PQth#63.2$Panoptic Segmentation#Cityscapes val#mIoU#82.1$Panoptic Segmentation#Cityscapes val#AP#43.5$Panoptic Segmentation#Cityscapes val#PQ#64.9$Panoptic Segmentation#Cityscapes val#PQst#67.7$Panoptic Segmentation#Cityscapes val#PQth#61.0$Panoptic Segmentation#Cityscapes val#mIoU#90.3$Panoptic Segmentation#Cityscapes val#AP#39.1$Panoptic Segmentation#Cityscapes test#PQ#67.1$Panoptic Segmentation#Cityscapes test#PQ#62.9$Panoptic Segmentation#Indian Driving Dataset#PQ#51.1$Panoptic Segmentation#KITTI Panoptic Segmentation#PQ#43.7$Instance Segmentation#Cityscapes test#Average Precision#39.1
1909.07229v1.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.3%$Semantic Segmentation#PASCAL VOC 2007#Mean IoU#83
2003.05128v3.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#83.2%
2101.06085v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.4%$Real-Time Semantic Segmentation#CamVid#mIoU#80.6$Real-Time Semantic Segmentation#CamVid#Time (ms)#10.6$Real-Time Semantic Segmentation#CamVid#Frame (fps)#94(2080Ti)$Real-Time Semantic Segmentation#CamVid#mIoU#74.7$Real-Time Semantic Segmentation#CamVid#Time (ms)#4.3$Real-Time Semantic Segmentation#CamVid#Frame (fps)#230(2080Ti)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#77.4%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#9.8$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#101.6(2080Ti)
1904.01803v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#82.3%
2011.11844v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#80.8%
1803.10335v3.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#79.1%
2111.13163v1.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#76.9
2007.12685v3.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#72.4%
1611.08323v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.8%$Thermal Image Segmentation#MFN Dataset#mIOU#44.2$Real-Time Semantic Segmentation#Cityscapes test#mIoU#71.8%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#469$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#2.1
1605.02264v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#71.8%
1912.06683v1.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.75%$Semantic Segmentation#Cityscapes test#Category mIoU#88.29$Semantic Segmentation#Cityscapes test#Mean IoU (class)#67.81%$Semantic Segmentation#Cityscapes test#Category mIoU#86.79$Semantic Segmentation#Cityscapes test#Mean IoU (class)#65.17%$Semantic Segmentation#Cityscapes test#Category mIoU#85.39$Real-Time Semantic Segmentation#Cityscapes val#mIoU#67.8%
1906.09826v1.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.7%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#70.7%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#16$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#63
1905.02423v3.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#70.6%$Real-Time Semantic Segmentation#Cityscapes test#mIoU#70.6%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#14$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#71
1509.02634v2.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#66.8%
1911.09099v4.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#66.5%
2101.10837v4.pdf	Semantic Segmentation#Cityscapes test#Mean IoU (class)#54.82%$Semantic Segmentation#Cityscapes test#Category mIoU#82.22%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#45.02%$Semantic Segmentation#Cityscapes test#Category mIoU#76.73%$Semantic Segmentation#Cityscapes test#Mean IoU (class)#42.07%$Semantic Segmentation#Cityscapes test#Category mIoU#75.61%
2001.08768v2.pdf	Semantic Segmentation#38-Cloud#Jaccard (Mean)#88.90
1901.10077v1.pdf	Semantic Segmentation#38-Cloud#Jaccard (Mean)#87.32
2201.08295v2.pdf	Semantic Segmentation#DIVA-HisDB#Mean IoU (class)#97.26
2011.13313v2.pdf	Semantic Segmentation#ZJU-RGB-P#mIoU#85.7$Semantic Segmentation#ZJU-RGB-P#mIoU#85.4$Semantic Segmentation#ZJU-RGB-P#mIoU#83.4
1712.02616v3.pdf	Semantic Segmentation#KITTI Semantic Segmentation#Mean IoU (class)#69.56
1803.05675v2.pdf	Semantic Segmentation#KITTI Semantic Segmentation#Mean IoU (class)#61.24
1807.11699v1.pdf	Semantic Segmentation#KITTI Semantic Segmentation#Mean IoU (class)#59.10
1805.01556v2.pdf	Semantic Segmentation#KITTI Semantic Segmentation#Mean IoU (class)#47.96
1910.09777v1.pdf	Semantic Segmentation#LIP val#mIoU#59.36%$Human Part Segmentation#PASCAL-Part#mIoU#71.46$Human Part Segmentation#CIHP#Mean IoU#67.47
1804.01984v1.pdf	Semantic Segmentation#LIP val#mIoU#51.37%
1807.08260v2.pdf	Semantic Segmentation#LIP val#mIoU#46.81%
1703.05446v2.pdf	Semantic Segmentation#LIP val#mIoU#44.73%
1910.02550v2.pdf	Semantic Segmentation#Cleargrasp (Novel)#Mean IoU#58
2107.11008v2.pdf	Semantic Segmentation#Cleargrasp (Novel)#Mean IoU#53.16$Semantic Segmentation#Cleargrasp (Novel)#Accuracy#95.6
2110.02210v2.pdf	Semantic Segmentation#ScanNet#3DIoU#0.781
1712.01537v1.pdf	Semantic Segmentation#ScanNet#3DIoU#0.762$3D Object Classification#ModelNet40#Classification Accuracy#89.9%
2210.05666v2.pdf	Semantic Segmentation#ScanNet#3DIoU#0.752
2103.14326v1.pdf	Semantic Segmentation#ScanNet#3DIoU#0.749
2007.13138v1.pdf	Semantic Segmentation#ScanNet#3DIoU#0.746
2107.01579v3.pdf	Semantic Segmentation#ScanNet#3DIoU#0.654
1812.00020v2.pdf	Semantic Segmentation#ScanNet#3DIoU#0.566
1811.07246v3.pdf	Semantic Segmentation#ScanNet#3DIoU#0.556$3D Part Segmentation#IntrA#IoU (V)#94.65$3D Part Segmentation#IntrA#DSC (V)#97.18$3D Part Segmentation#IntrA#IoU (A)#79.53$3D Part Segmentation#IntrA#DSC (A)#86.52$3D Part Segmentation#ShapeNet-Part#Class Average IoU#82.8$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.7$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.883$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.5
1903.01177v2.pdf	Semantic Segmentation#ScanNet#3DIoU#0.529$Panoptic Segmentation#ScanNetV2#PQ#33.5$Panoptic Segmentation#ScanNetV2#SQ#73.0$Panoptic Segmentation#ScanNetV2#RQ#45.3
1808.06840v1.pdf	Semantic Segmentation#ScanNet#3DIoU#0.447
1808.04952v2.pdf	Semantic Segmentation#ScanNet#3DIoU#0.442
2103.04233v5.pdf	Semantic Segmentation#RELLIS-3D Dataset#Mean IoU (class)#74.44
2207.02437v1.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#52.2%
2011.11498v3.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#52.0%
2203.09283v2.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#48.9%
1912.09390v3.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#45.6%
2006.10731v2.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#43.4%
1907.12849v1.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#43.3%
1902.04615v3.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#39.4%
1901.02039v1.pdf	Semantic Segmentation#Stanford2D3D Panoramic#mIoU#38.3%
2011.11964v2.pdf	Panoptic Segmentation#SemanticKITTI#PQ#0.559$Panoptic Segmentation#SemanticKITTI#PQ_dagger#0.625$Panoptic Segmentation#SemanticKITTI#RQ#0.667$Panoptic Segmentation#SemanticKITTI#SQ#0.823$Panoptic Segmentation#SemanticKITTI#PQth#0.551$Panoptic Segmentation#SemanticKITTI#RQth#0.628$Panoptic Segmentation#SemanticKITTI#SQth#0.872$Panoptic Segmentation#SemanticKITTI#PQst#0.565$Panoptic Segmentation#SemanticKITTI#RQst#0.695$Panoptic Segmentation#SemanticKITTI#SQst#0.787$Panoptic Segmentation#SemanticKITTI#mIoU#0.616
2011.11675v2.pdf	Panoptic Segmentation#Mapillary val#PQ#44.8$Panoptic Segmentation#Mapillary val#mIoU#60.0$Panoptic Segmentation#Mapillary val#PQth#39.3$Panoptic Segmentation#Mapillary val#PQst#51.9$Panoptic Segmentation#COCO test-dev#PQ#46.5$Panoptic Segmentation#COCO test-dev#PQst#38.2$Panoptic Segmentation#COCO test-dev#PQth#52.0$Panoptic Segmentation#Cityscapes val#PQ#69.6$Panoptic Segmentation#Cityscapes val#mIoU#85.3$Panoptic Segmentation#Cityscapes val#AP#46.8$Panoptic Segmentation#Cityscapes test#PQ#68.5
2003.07853v2.pdf	Panoptic Segmentation#Mapillary val#PQ#41.1$Panoptic Segmentation#Mapillary val#mIoU#58.4$Panoptic Segmentation#Mapillary val#PQth#33.4$Panoptic Segmentation#Mapillary val#PQst#51.3$Panoptic Segmentation#COCO test-dev#PQ#44.2$Panoptic Segmentation#COCO test-dev#PQst#36.8$Panoptic Segmentation#COCO test-dev#PQth#49.2$Panoptic Segmentation#COCO test-dev#PQ#43.6$Panoptic Segmentation#COCO test-dev#PQst#35.6$Panoptic Segmentation#COCO test-dev#PQth#48.9$Panoptic Segmentation#COCO minival#PQ#43.9$Panoptic Segmentation#COCO minival#PQ#43.4$Panoptic Segmentation#COCO minival#PQth#48.5$Panoptic Segmentation#COCO minival#PQst#35.6$Panoptic Segmentation#COCO minival#PQth#48.6$Panoptic Segmentation#COCO minival#PQst#36.8$Panoptic Segmentation#Cityscapes val#PQ#68.5$Panoptic Segmentation#Cityscapes val#mIoU#84.6$Panoptic Segmentation#Cityscapes val#AP#44.2$Panoptic Segmentation#Cityscapes test#PQ#66.6
1909.07829v1.pdf	Panoptic Segmentation#Mapillary val#PQ#40.3$Panoptic Segmentation#Mapillary val#mIoU#56.8$Panoptic Segmentation#COCO test-dev#PQ#42.8$Panoptic Segmentation#COCO test-dev#PQst#31.8$Panoptic Segmentation#COCO test-dev#PQth#50.1$Panoptic Segmentation#Cityscapes val#PQ#62.0$Panoptic Segmentation#Cityscapes val#PQst#64.4$Panoptic Segmentation#Cityscapes val#PQth#58.7$Panoptic Segmentation#Cityscapes val#mIoU#79.2$Panoptic Segmentation#Cityscapes val#AP#36.3$Panoptic Segmentation#Cityscapes val#PQ#60.6$Panoptic Segmentation#Cityscapes val#PQst#62.9$Panoptic Segmentation#Cityscapes val#PQth#57.5$Panoptic Segmentation#Cityscapes val#mIoU#77.2$Panoptic Segmentation#Cityscapes val#AP#33.9$Panoptic Segmentation#Cityscapes val#PQ#59.0$Panoptic Segmentation#Cityscapes val#PQst#61.3$Panoptic Segmentation#Cityscapes val#PQth#55.8$Panoptic Segmentation#Cityscapes val#mIoU#75.3$Panoptic Segmentation#Cityscapes val#AP#32.3
2012.00720v2.pdf	Panoptic Segmentation#Mapillary val#PQ#36.9$Panoptic Segmentation#Mapillary val#PQth#32.9$Panoptic Segmentation#Mapillary val#PQst#42.3$Panoptic Segmentation#Mapillary val#PQth#40.8$Panoptic Segmentation#COCO test-dev#PQ#52.7$Panoptic Segmentation#COCO test-dev#PQth#59.4$Panoptic Segmentation#COCO test-dev#PQ#47.5$Panoptic Segmentation#COCO test-dev#PQst#38.2$Panoptic Segmentation#COCO test-dev#PQth#53.7$Panoptic Segmentation#COCO minival#PQ#44.3$Panoptic Segmentation#COCO minival#SQ#80.7$Panoptic Segmentation#COCO minival#RQ#53$Panoptic Segmentation#COCO minival#PQth#50$Panoptic Segmentation#COCO minival#SQth#83.4$Panoptic Segmentation#COCO minival#RQth#59.3$Panoptic Segmentation#COCO minival#PQst#35.6$Panoptic Segmentation#COCO minival#SQst#76.7$Panoptic Segmentation#COCO minival#RQst#43.5$Panoptic Segmentation#COCO minival#SQ#83.2$Panoptic Segmentation#COCO minival#RQ#61.6$Panoptic Segmentation#COCO minival#PQth#58.5$Panoptic Segmentation#COCO minival#SQth#84.6$Panoptic Segmentation#COCO minival#RQth#68.6$Panoptic Segmentation#COCO minival#SQst#81.1$Panoptic Segmentation#COCO minival#RQst#51.1$Panoptic Segmentation#Cityscapes val#PQ#61.4$Panoptic Segmentation#Cityscapes val#PQth#54.8$Panoptic Segmentation#Cityscapes val#PQst#70.6$Panoptic Segmentation#Cityscapes val#PQth#59.5$Panoptic Segmentation#Cityscapes val#PQst#66.6
1809.02110v2.pdf	Panoptic Segmentation#Mapillary val#PQ#35.9$Panoptic Segmentation#COCO test-dev#PQ#27.2$Panoptic Segmentation#COCO test-dev#PQst#23.4$Panoptic Segmentation#COCO test-dev#PQth#29.6
2207.04044v3.pdf	Panoptic Segmentation#COCO test-dev#PQ#58.5$Panoptic Segmentation#COCO test-dev#PQst#49.0$Panoptic Segmentation#COCO test-dev#PQth#64.8$Panoptic Segmentation#COCO minival#PQ#58.1$Panoptic Segmentation#COCO minival#PQth#64.3$Panoptic Segmentation#COCO minival#PQst#48.8$Panoptic Segmentation#Cityscapes val#PQ#68.4$Panoptic Segmentation#Cityscapes val#mIoU#83.5$Panoptic Segmentation#Cityscapes val#AP#44.0$Panoptic Segmentation#Cityscapes test#PQ#66.2
2109.03814v4.pdf	Panoptic Segmentation#COCO test-dev#PQ#56.2$Panoptic Segmentation#COCO test-dev#PQst#47.0$Panoptic Segmentation#COCO test-dev#PQth#62.3$Panoptic Segmentation#COCO test-dev#PQ#55.8$Panoptic Segmentation#COCO test-dev#PQst#46.5$Panoptic Segmentation#COCO test-dev#PQth#61.9$Panoptic Segmentation#COCO test-dev#PQ#50.9$Panoptic Segmentation#COCO test-dev#PQst#43.0$Panoptic Segmentation#COCO test-dev#PQth#56.2$Panoptic Segmentation#COCO test-dev#PQ#50.2$Panoptic Segmentation#COCO test-dev#PQst#42.4$Panoptic Segmentation#COCO test-dev#PQth#55.3$Panoptic Segmentation#COCO minival#PQ#55.8$Panoptic Segmentation#COCO minival#PQth#61.7$Panoptic Segmentation#COCO minival#PQst#46.9$Panoptic Segmentation#COCO minival#PQ#50.6$Panoptic Segmentation#COCO minival#PQth#55.5$Panoptic Segmentation#COCO minival#PQst#43.2
2012.00759v3.pdf	Panoptic Segmentation#COCO test-dev#PQ#51.3$Panoptic Segmentation#COCO test-dev#PQst#42.4$Panoptic Segmentation#COCO test-dev#PQth#57.2$Panoptic Segmentation#COCO minival#PQ#51.1$Panoptic Segmentation#COCO minival#PQth#57.0$Panoptic Segmentation#COCO minival#PQst#42.2
2006.02334v2.pdf	Panoptic Segmentation#COCO test-dev#PQ#50$Panoptic Segmentation#COCO test-dev#PQst#37.2$Panoptic Segmentation#COCO test-dev#PQth#58.5$Object Detection#COCO test-dev#box AP#55.7$Object Detection#COCO test-dev#AP50#74.2$Object Detection#COCO test-dev#AP75#61.1$Object Detection#COCO test-dev#APS#37.7$Object Detection#COCO test-dev#APM#58.4$Object Detection#COCO test-dev#APL#68.1$Object Detection#COCO test-dev#box AP#54.7$Object Detection#COCO test-dev#AP50#73.5$Object Detection#COCO test-dev#AP75#60.1$Object Detection#COCO test-dev#APS#37.4$Object Detection#COCO test-dev#APM#57.3$Object Detection#COCO test-dev#APL#66.4$Object Detection#COCO test-dev#box AP#53.3$Object Detection#COCO test-dev#AP50#71.6$Object Detection#COCO test-dev#AP75#58.5$Object Detection#COCO test-dev#APS#33.9$Object Detection#COCO test-dev#APM#56.5$Object Detection#COCO test-dev#APL#66.9$Object Detection#AI-TOD#AP#14.8$Object Detection#AI-TOD#AP50#32.8$Object Detection#AI-TOD#AP75#11.4$Object Detection#AI-TOD#APvt#0.0$Object Detection#AI-TOD#APt#10.8$Object Detection#AI-TOD#APs#28.3$Object Detection#AI-TOD#APm#28.0$Instance Segmentation#COCO test-dev#mask AP#48.5$Instance Segmentation#COCO test-dev#AP50#72.0$Instance Segmentation#COCO test-dev#AP75#53.3$Instance Segmentation#COCO test-dev#APS#31.6$Instance Segmentation#COCO test-dev#APM#50.9$Instance Segmentation#COCO test-dev#APL#61.5$Instance Segmentation#COCO test-dev#mask AP#47.1$Instance Segmentation#COCO test-dev#AP50#71.1$Instance Segmentation#COCO test-dev#AP75#51.6$Instance Segmentation#COCO test-dev#APS#30.3$Instance Segmentation#COCO test-dev#APM#49.5$Instance Segmentation#COCO test-dev#APL#59.6
1910.08787v3.pdf	Panoptic Segmentation#COCO test-dev#PQ#48.5$Panoptic Segmentation#COCO test-dev#PQst#37.9$Panoptic Segmentation#COCO test-dev#PQth#55.5
2012.03603v1.pdf	Panoptic Segmentation#COCO test-dev#PQ#48.5$Panoptic Segmentation#COCO test-dev#PQst#37.6$Panoptic Segmentation#COCO test-dev#PQth#55.7
1911.07527v1.pdf	Panoptic Segmentation#COCO test-dev#PQ#47.8$Panoptic Segmentation#Cityscapes test#PQ#60
1901.03784v2.pdf	Panoptic Segmentation#COCO test-dev#PQ#46.6$Panoptic Segmentation#COCO test-dev#PQst#36.7$Panoptic Segmentation#COCO test-dev#PQth#53.2$Panoptic Segmentation#Cityscapes val#PQ#61.8$Panoptic Segmentation#Cityscapes val#PQst#64.8$Panoptic Segmentation#Cityscapes val#PQth#57.6$Panoptic Segmentation#Cityscapes val#mIoU#79.2$Panoptic Segmentation#Cityscapes val#AP#39.0$Panoptic Segmentation#Cityscapes val#PQ#60.5$Panoptic Segmentation#Cityscapes val#PQst#63.0$Panoptic Segmentation#Cityscapes val#PQth#57.0$Panoptic Segmentation#Cityscapes val#mIoU#77.8$Panoptic Segmentation#Cityscapes val#AP#37.8$Panoptic Segmentation#Cityscapes val#PQ#59.3$Panoptic Segmentation#Cityscapes val#PQst#62.7$Panoptic Segmentation#Cityscapes val#PQth#54.6$Panoptic Segmentation#Cityscapes val#mIoU#75.2$Panoptic Segmentation#Cityscapes val#AP#33.3$Panoptic Segmentation#Indian Driving Dataset#PQ#47.1$Panoptic Segmentation#KITTI Panoptic Segmentation#PQ#39.9
1906.05896v4.pdf	Panoptic Segmentation#COCO test-dev#PQ#46.6$Panoptic Segmentation#COCO test-dev#PQst#35.7$Panoptic Segmentation#COCO test-dev#PQth#54.0
1812.03904v2.pdf	Panoptic Segmentation#COCO test-dev#PQ#46.5$Panoptic Segmentation#COCO test-dev#PQst#32.5$Panoptic Segmentation#COCO test-dev#PQth#55.8$Panoptic Segmentation#COCO test-dev#PQ#45.5$Panoptic Segmentation#COCO test-dev#PQst#31.6$Panoptic Segmentation#COCO test-dev#PQth#54.7$Panoptic Segmentation#COCO test-dev#PQ#45.2$Panoptic Segmentation#COCO test-dev#PQst#31.3$Panoptic Segmentation#COCO test-dev#PQth#54.4$Panoptic Segmentation#Cityscapes val#PQ#59.0$Panoptic Segmentation#Cityscapes val#PQst#62.1$Panoptic Segmentation#Cityscapes val#PQth#54.8$Panoptic Segmentation#Cityscapes val#mIoU#75.6$Panoptic Segmentation#Cityscapes val#AP#34.4
1812.01192v2.pdf	Panoptic Segmentation#COCO test-dev#PQ#40.7$Panoptic Segmentation#COCO test-dev#PQst#31.0$Panoptic Segmentation#COCO test-dev#PQth#47.0$Panoptic Segmentation#Cityscapes val#PQ#60.4$Panoptic Segmentation#Cityscapes val#PQst#63.3$Panoptic Segmentation#Cityscapes val#PQth#56.1$Panoptic Segmentation#Cityscapes val#mIoU#78$Panoptic Segmentation#Cityscapes val#AP#39$Panoptic Segmentation#Cityscapes val#PQ#59.2$Panoptic Segmentation#Cityscapes val#PQst#61.5$Panoptic Segmentation#Cityscapes val#PQth#56$Panoptic Segmentation#Cityscapes val#mIoU#77.8$Panoptic Segmentation#Cityscapes val#AP#37.6
2003.10142v3.pdf	Panoptic Segmentation#COCO test-dev#PQ#38.9$Panoptic Segmentation#COCO test-dev#PQst#31.0$Panoptic Segmentation#COCO test-dev#PQth#44.1
2106.03188v3.pdf	Panoptic Segmentation#COCO test-dev#PQ#38.5$Panoptic Segmentation#COCO test-dev#PQst#34.8$Panoptic Segmentation#COCO test-dev#PQth#41.0$Panoptic Segmentation#Cityscapes val#PQ#62.1$Panoptic Segmentation#Cityscapes val#PQst#67.2$Panoptic Segmentation#Cityscapes val#PQth#55.1$Panoptic Segmentation#Cityscapes val#mIoU#79.3$Panoptic Segmentation#Cityscapes val#AP#34.1$Panoptic Segmentation#Cityscapes test#PQ#60
2004.01849v1.pdf	Panoptic Segmentation#COCO test-dev#PQ#37.7$Panoptic Segmentation#COCO test-dev#PQst#33.1$Panoptic Segmentation#COCO test-dev#PQth#40.7
1801.00868v3.pdf	Panoptic Segmentation#Cityscapes val#PQ#61.2$Panoptic Segmentation#Cityscapes val#PQst#66.4$Panoptic Segmentation#Cityscapes val#PQth#54$Panoptic Segmentation#Cityscapes val#AP#36.4
1902.05093v2.pdf	Panoptic Segmentation#Cityscapes val#PQ#56.5
1808.03575v3.pdf	Panoptic Segmentation#Cityscapes val#PQ#53.8$Panoptic Segmentation#Cityscapes val#PQst#62.1$Panoptic Segmentation#Cityscapes val#PQth#42.5$Panoptic Segmentation#Cityscapes val#mIoU#79.8$Panoptic Segmentation#Cityscapes val#AP#28.6
1704.02386v1.pdf	Panoptic Segmentation#Cityscapes test#PQ#55.4$Instance Segmentation#Cityscapes test#Average Precision#23.4
2204.06754v3.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#74.4$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#69.5$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#46.4$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#42.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#73.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.6
2110.07110v3.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#72.3$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#73.5
2203.09653v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#72.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#72.8
2204.03206v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#72.1$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#44.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#73.0
2101.11253v4.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.9$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#66.9$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#72.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#67.7
2112.02841v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#72.3
2110.03740v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#72.0
2112.07431v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.1$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#69.5$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#69.4$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#41.5$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#40.8$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#40.7$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#40.5$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.5$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.7
2105.08965v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.0$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.9$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#35.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.8
2103.07246v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#71.0$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.4$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.7
2110.14309v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.8
2202.04812v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.6$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#36.2$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#36.1$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.1$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.4
2203.16045v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#69.5$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#44.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.6
2203.03860v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.1
2110.06530v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.2$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.3$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#43.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.0$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#68.6
2203.12459v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.1$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.8
2108.12995v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#70.0$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.5$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#40.2$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#36.7$Weakly-Supervised Semantic Segmentation#COCO 2014 val#Mean IoU#36.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#70.5$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.0
2203.10278v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#69.3$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#67.2$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#35.0$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.4$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#67.6
2203.02909v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.8$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#43.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.7
2103.16762v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#66.7$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#69.3$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#68.8
2012.05007v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.2$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#28.4$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#68.5
2103.08896v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#68.1
2108.03852v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#67.8$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#68.5
1910.05475v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#67.1$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#33.6$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#67.2
2007.01947v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#66.2
2008.01183v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#66.1
2009.12547v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#66.1$Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#33.4
2004.04581v1.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#64.5
1904.05044v3.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 val#Mean IoU#63.5$Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#64.8$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#46.7$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.7#23.5
2203.02664v2.pdf	Weakly-Supervised Semantic Segmentation#COCO 2014 val#mIoU#38.9
2105.00957v2.pdf	Weakly-Supervised Semantic Segmentation#PASCAL VOC 2012 test#Mean IoU#71.6
2204.10266v1.pdf	Thermal Image Segmentation#MFN Dataset#mIOU#57.3
2110.08988v1.pdf	Thermal Image Segmentation#MFN Dataset#mIOU#55.3
2210.14530v1.pdf	Thermal Image Segmentation#MFN Dataset#mIOU#54.9
2112.05144v1.pdf	Thermal Image Segmentation#MFN Dataset#mIOU#54.8
1909.10980v1.pdf	Thermal Image Segmentation#MFN Dataset#mIOU#48.4
2004.02147v1.pdf	Real-Time Semantic Segmentation#COCO-Stuff#Frame (fps)#42.5(1080Ti)$Real-Time Semantic Segmentation#COCO-Stuff#mIoU#28.7$Real-Time Semantic Segmentation#COCO-Stuff#Frame (fps)#87.9(1080Ti)$Real-Time Semantic Segmentation#COCO-Stuff#mIoU#25.2$Real-Time Semantic Segmentation#CamVid#mIoU#78.5$Real-Time Semantic Segmentation#CamVid#Time (ms)#30.6$Real-Time Semantic Segmentation#CamVid#Frame (fps)#32.7$Real-Time Semantic Segmentation#CamVid#mIoU#76.7$Real-Time Semantic Segmentation#CamVid#Time (ms)#8.0$Real-Time Semantic Segmentation#CamVid#Frame (fps)#124.5$Real-Time Semantic Segmentation#CamVid#mIoU#73.2$Real-Time Semantic Segmentation#CamVid#mIoU#72.4$Real-Time Semantic Segmentation#Cityscapes test#mIoU#75.3%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#21.1$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#47.3$Real-Time Semantic Segmentation#Cityscapes test#mIoU#72.6%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#6.4$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#156
2206.02066v2.pdf	Real-Time Semantic Segmentation#Cityscapes val#mIoU#80.9%$Real-Time Semantic Segmentation#Cityscapes val#Frame (fps)#31.1(3090)$Real-Time Semantic Segmentation#Cityscapes val#Time (ms)#32.2$Real-Time Semantic Segmentation#Cityscapes val#mIoU#79.9%$Real-Time Semantic Segmentation#Cityscapes val#Frame (fps)#42.2(3090)$Real-Time Semantic Segmentation#Cityscapes val#Time (ms)#23.7$Real-Time Semantic Segmentation#Cityscapes val#mIoU#78.8%$Real-Time Semantic Segmentation#Cityscapes val#Frame (fps)#93.2(3090)$Real-Time Semantic Segmentation#Cityscapes val#Time (ms)#10.7$Real-Time Semantic Segmentation#CamVid#mIoU#82.0$Real-Time Semantic Segmentation#CamVid#Time (ms)#11.7$Real-Time Semantic Segmentation#CamVid#Frame (fps)#85.6(3090)$Real-Time Semantic Segmentation#CamVid#mIoU#80.1$Real-Time Semantic Segmentation#CamVid#Time (ms)#6.5$Real-Time Semantic Segmentation#CamVid#Frame (fps)#153.7(3090)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#80.6%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#32.2$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#31.1(3090)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#79.8%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#23.7$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#42.2(3090)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#78.6%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#10.7$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#93.2(3090)
2204.02681v1.pdf	Real-Time Semantic Segmentation#Cityscapes val#mIoU#78.2$Real-Time Semantic Segmentation#Cityscapes val#mIoU#76$Real-Time Semantic Segmentation#Cityscapes val#mIoU#75.3$Real-Time Semantic Segmentation#Cityscapes val#mIoU#73.1$Real-Time Semantic Segmentation#CamVid#mIoU#75$Real-Time Semantic Segmentation#CamVid#Frame (fps)#154.8$Real-Time Semantic Segmentation#CamVid#mIoU#73.3$Real-Time Semantic Segmentation#CamVid#Frame (fps)#222.3$Real-Time Semantic Segmentation#Cityscapes test#mIoU#77.5%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#102.6(1080Ti)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#74.9%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#143.6(1080Ti)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#73.9%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#195.3(1080Ti)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#72.0%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#273.6(1080Ti)
2111.09957v2.pdf	Real-Time Semantic Segmentation#CamVid#mIoU#80.9$Real-Time Semantic Segmentation#CamVid#Time (ms)#14$Real-Time Semantic Segmentation#CamVid#Frame (fps)#70$Real-Time Semantic Segmentation#Cityscapes test#mIoU#78.3%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#33$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#30
2206.08194v2.pdf	Real-Time Semantic Segmentation#HelixNet#mIoU (1/5 rotation)#78.7$Real-Time Semantic Segmentation#HelixNet#Inference Time (ms) (1/5 rotation)#19
2002.10120v3.pdf	Real-Time Semantic Segmentation#Cityscapes test#mIoU#80.4%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#39.2$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#25.7(1080Ti)
2104.13188v1.pdf	Real-Time Semantic Segmentation#Cityscapes test#mIoU#76.8%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#97.0(1080Ti)$Real-Time Semantic Segmentation#Cityscapes test#mIoU#75.3%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#126.7$Real-Time Semantic Segmentation#Cityscapes test#mIoU#73.4%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#188.6$Real-Time Semantic Segmentation#Cityscapes test#mIoU#71.9%$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#250.4(1080Ti)$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.648$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.562$Dichotomous Image Segmentation#DIS-TE1#MAE#0.090$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.723$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.798$Dichotomous Image Segmentation#DIS-TE1#HCE#249$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.720$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.636$Dichotomous Image Segmentation#DIS-TE2#MAE#0.092$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.759$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.834$Dichotomous Image Segmentation#DIS-TE2#HCE#556$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.745$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.662$Dichotomous Image Segmentation#DIS-TE3#MAE#0.090$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.771$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.855$Dichotomous Image Segmentation#DIS-TE3#HCE#1081$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.731$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.652$Dichotomous Image Segmentation#DIS-TE4#MAE#0.102$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.762$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.841$Dichotomous Image Segmentation#DIS-TE4#HCE#3819$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.696$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.613$Dichotomous Image Segmentation#DIS-VD#MAE#0.103$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.740$Dichotomous Image Segmentation#DIS-VD#E-measure#0.817$Dichotomous Image Segmentation#DIS-VD#HCE#1598
1909.00948v1.pdf	Real-Time Semantic Segmentation#Cityscapes test#mIoU#75.9%$Real-Time Semantic Segmentation#Cityscapes test#Time (ms)#18.8$Real-Time Semantic Segmentation#Cityscapes test#Frame (fps)#53
(1080Ti)
(1080Ti)
2106.01226v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#77.62%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#77.68%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#76.44%$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#40.7$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#60.8$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#64.9$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#68.0$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#80.21%$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#33.7$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#50.0$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#52.8$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#54.6$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#36.5$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#52.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#56.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#57.4$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#79.21%
2112.07528v4.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#77.61%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#78.97$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#75.85$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#77.99%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#74.21$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#79.29%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#80.26$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#76.65$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#78.41%
2111.12903v3.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#77.12%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#78.72$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#78.20%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#75.70%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#79.22%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 1464 labels#Validation mIoU#80.01 %$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 1464 labels#Validation mIoU#78.08%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#79.76%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#78.38%
2207.00026v1.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#77.1%$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#55.3$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#69.9$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#71.8$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#73.2$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#49.5$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#68.2$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#70.6$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#73.0$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#79.1%$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#44.2$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#53.7$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#55.1$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#56.8$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#38.3$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#54.4$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#55.6$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#58.7$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#50.6$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#60.0$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#61.9$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#62.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#43.4$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#58.8$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#59.4$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#61.4$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#78.3%
2203.03884v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#76.48%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#79.30$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 6.25% labeled#Validation mIoU#77.21$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#79.01%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#79.12%$Semi-Supervised Semantic Segmentation#Cityscapes 6.25% labeled#Validation mIoU#74.90%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#80.50%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#78.51%
2104.07256v4.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#74.1%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#78.7%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#77.8%
2204.02078v3.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#70.33%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#76.58%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#74.63%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#72.52%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#70.52%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#75.10%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#73.2%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#75.33%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#73.52%
2012.10782v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#68.01%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#62.09%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#69.38%
2104.04465v4.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#66.44%$Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#64.94%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#73.66%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#68.85%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#60.28%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#56.53%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#71.00%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#68.69%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#72.14%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#66.41%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#63.60%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#63.16%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#68.50%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#67.53%
2106.15064v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#65.8%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#77.8%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#75.5%$Semi-Supervised Semantic Segmentation#PASCAL Context 25% labeled#Validation mIoU#41.7%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#56.9%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 500 labels#Validation mIoU#65.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#76.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#73.4%$Semi-Supervised Semantic Segmentation#PASCAL Context 12.5% labeled#Validation mIoU#40.3%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 1000 labels#Validation mIoU#68.1%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#69.8%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 1464 labels#Validation mIoU#73.7$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#78.2%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 50%#Validation mIoU#76.5%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#67.5%
2104.13415v3.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#64.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#70.0%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#64.9%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#59.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#71.6%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#67.9%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#65.9%
2004.08514v4.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#63.03%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#69.92%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#54.80%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#72.70%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#67.15%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#63.04%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 1464 labels#Validation mIoU#74.85 %$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#5.79
2103.17105v3.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#62.57%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#69.40%$Semi-Supervised Semantic Segmentation#Cityscapes 5% labeled#Validation mIoU#59.98%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#58.70%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#70.76%$Semi-Supervised Semantic Segmentation#Cityscapes 2% labeled#Validation mIoU#53.51%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#67.21%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#65.14%
2007.07936v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#61.35%$Semi-Supervised Semantic Segmentation#PASCAL VOC 2012 25% labeled#Validation mIoU#72.45$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#67.77%$Semi-Supervised Semantic Segmentation#Cityscapes 5% labeled#Validation mIoU#58.77%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#54.07%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#71.00%$Semi-Supervised Semantic Segmentation#Cityscapes 2% labeled#Validation mIoU#52.14%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#66.29%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#66.15%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#54.18%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#63.63%
1906.01916v5.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#60.34%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#69.57%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#66.48%$Semi-Supervised Semantic Segmentation#Cityscapes 100 samples labeled#Validation mIoU#51.2$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#72.45%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#67.6%$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#43.8$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#63.9$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#64.8$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#69.8$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#67.05%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#64.81%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#59.52%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 1% labeled#Validation mIoU#53.79%$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#36.7$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#50.7$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#52.9$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#54.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#37.4$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#54.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#56.6$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#57.6$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#63.87%
1908.05724v1.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#59.3%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#67.2%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#66.6%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#62.9%$Semi-Supervised Semantic Segmentation#Cityscapes 5% labeled#Validation mIoU#55.61%$Semi-Supervised Semantic Segmentation#PASCAL Context 25% labeled#Validation mIoU#37.8$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#71.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#70.4%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#67.3%$Semi-Supervised Semantic Segmentation#Cityscapes 2% labeled#Validation mIoU#50.48%$Semi-Supervised Semantic Segmentation#PASCAL Context 12.5% labeled#Validation mIoU#35.3$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#63.3%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#62.6%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#60.4%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#61.9%
1802.07934v2.pdf	Semi-Supervised Semantic Segmentation#Cityscapes 12.5% labeled#Validation mIoU#57.1%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 5% labeled#Validation mIoU#59.1%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 12.5% labeled#Validation mIoU#64.3%$Semi-Supervised Semantic Segmentation#Cityscapes 50% labeled#Validation mIoU#65.70%$Semi-Supervised Semantic Segmentation#Pascal VOC 2012 2% labeled#Validation mIoU#49.2%$Semi-Supervised Semantic Segmentation#Cityscapes 25% labeled#Validation mIoU#60.5%
1703.01780v6.pdf	Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#51.6$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#66.0$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#67.1$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#71.7$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#42.1$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#60.4$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#65.4$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#69.4$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#41.0$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#50.1$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#52.8$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#53.9$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#34.2$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#49.8$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#51.6$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#53.3$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#45.4$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#57.1$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#59.2$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#60.0$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (1% Labels)#37.5$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (10% Labels)#53.1$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (20% Labels)#56.1$Semi-Supervised Semantic Segmentation#SemanticKITTI#mIoU (50% Labels)#57.4$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.05$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.28$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#90.89%$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#93.55$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#47.32
2109.03787v1.pdf	Semi-Supervised Semantic Segmentation#nuScenes#mIoU (1% Labels)#38.3$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (10% Labels)#57.5$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (20% Labels)#62.7$Semi-Supervised Semantic Segmentation#nuScenes#mIoU (50% Labels)#67.6$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (1% Labels)#33.1$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (10% Labels)#47.7$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (20% Labels)#49.9$Semi-Supervised Semantic Segmentation#ScribbleKITTI#mIoU (50% Labels)#52.5
2112.04863v2.pdf	3D Part Segmentation#IntrA#IoU (V)#94.82$3D Part Segmentation#IntrA#DSC (V)#97.29$3D Part Segmentation#IntrA#IoU (A)#82.39$3D Part Segmentation#IntrA#DSC (A)#89.71$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.936$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.4$3D Point Cloud Classification#ModelNet40#Number of params#1.54M
1803.04249v4.pdf	3D Part Segmentation#IntrA#IoU (V)#94.46$3D Part Segmentation#IntrA#DSC (V)#97.09$3D Part Segmentation#IntrA#IoU (A)#81.40$3D Part Segmentation#IntrA#DSC (A)#88.76$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#84.9$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.868$3D Point Cloud Classification#ModelNet40#Overall Accuracy#90.9$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#87.5
1801.07791v5.pdf	3D Part Segmentation#IntrA#IoU (V)#93.59$3D Part Segmentation#IntrA#DSC (V)#96.62$3D Part Segmentation#IntrA#IoU (A)#74.11$3D Part Segmentation#IntrA#DSC (A)#81.74$3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.6$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.14$3D Instance Segmentation#S3DIS#mIoU#65.39%$3D Instance Segmentation#S3DIS#mAcc#75.61$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#78.5$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#75.1
1803.11527v3.pdf	3D Part Segmentation#IntrA#IoU (V)#90.16$3D Part Segmentation#IntrA#DSC (V)#94.53$3D Part Segmentation#IntrA#IoU (A)#67.25$3D Part Segmentation#IntrA#DSC (A)#75.82$3D Part Segmentation#ShapeNet-Part#Class Average IoU#82.4$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.3$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.872$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#73.7$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#69.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.4
2101.11987v1.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#85.9$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#90.5
2003.05593v4.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.6$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#88.8
2205.09962v1.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#87.2$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#87.2$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#86.2$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.3$3D Point Cloud Classification#ModelNet40#Mean Accuracy#89.6
2111.08799v5.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.9$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.6$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#84.7$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8$3D Point Cloud Classification#ModelNet40#Mean class accuracy#91.2
1909.09287v2.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.9$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.8$3D Object Classification#ModelNet40#Classification Accuracy#89.3%
1903.00343v1.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.4$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.8
2105.01288v2.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.2$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.927
2012.10921v3.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#85.0$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.5$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.892$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#0.923
2012.04708v2.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.3$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.5
2108.06076v4.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.5$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.0
2208.02812v2.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.5$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#89.3$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#88.5$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.0$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.6
1909.03669v1.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.2$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.4
2005.06734v2.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#83.7$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.4$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#80.3$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#78.0$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.1
2012.09688v4.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.4$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.914$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.255$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.2$3D Point Cloud Classification#ModelNet40#Number of params#2.88M$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.925
1908.04512v1.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.0$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.3$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.0
1904.07601v3.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.2$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.262$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.9$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.130
1706.01307v1.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#86.0
2011.00931v2.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.9$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.8
2109.00452v3.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.5$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.39$3D Point Cloud Classification#ModelNet40#Mean Accuracy#89.88$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.31$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.71
1801.07829v2.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.2$3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.738$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.259$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#78.1$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#73.6$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.9$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.2$3D Point Cloud Classification#ModelNet40#Number of params#1.81M$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.000$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.000
1811.02565v2.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.2$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.6
1803.10091v1.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#85.1$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.3
1612.00606v1.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#82.0$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#84.7
1606.06650v1.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#84.6$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#31.9
1711.08241v1.pdf	3D Part Segmentation#ShapeNet-Part#Instance Average IoU#84.3$3D Point Cloud Classification#ModelNet40#Overall Accuracy#91.6
1704.01222v2.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#77.4$3D Part Segmentation#ShapeNet-Part#Instance Average IoU#82.3$3D Point Cloud Classification#ModelNet40#Overall Accuracy#91.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#90.6
1903.00709v5.pdf	3D Part Segmentation#ShapeNet-Part#Class Average IoU#84.1$3D Instance Segmentation#S3DIS#mRec#43.4%
2203.08414v1.pdf	Unsupervised Semantic Segmentation#COCO-All#mIoU#28.2$Unsupervised Semantic Segmentation#COCO-All#Pixel Accuracy#56.9$Unsupervised Semantic Segmentation#Potsdam-3#Accuracy#77.0$Unsupervised Semantic Segmentation#Cityscapes test#mIoU#21.0$Unsupervised Semantic Segmentation#Cityscapes test#Accuracy#73.2
2202.11981v1.pdf	Unsupervised Semantic Segmentation#COCO-All#mIoU#15.69
2110.03477v1.pdf	Unsupervised Semantic Segmentation#Potsdam-3#Pixel Accuracy#71.6$Unsupervised Semantic Segmentation#COCO-Stuff#Pixel Accuracy#38.8$Unsupervised Semantic Segmentation#Potsdam#Pixel Accuracy#57.3$Unsupervised Semantic Segmentation#COCO-Persons#Pixel Accuracy#69.6$Unsupervised Semantic Segmentation#COCO-Stuff-3#Pixel Accuracy#73.8$Unsupervised Semantic Segmentation#COCO-Stuff-15#Pixel Accuracy#38.8
2204.13101v2.pdf	Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#47.2$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#FCN [mIoU]#76.3$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Linear Classifier [mIoU]#69.3$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#41.7$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#FCN [mIoU]#71.4
2206.06363v1.pdf	Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Linear Classifier [mIoU]#58.7$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#45.8
1910.06962v2.pdf	Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Linear Classifier [mIoU]#55.86 (KNN)$Unsupervised Semantic Segmentation#PASCAL VOC 2012 val#Clustering [mIoU]#-
2203.11160v1.pdf	Unsupervised Semantic Segmentation#Cityscapes val#mIoU#21.8$Unsupervised Semantic Segmentation#Nighttime Driving#mIoU#18.9$Unsupervised Semantic Segmentation#ACDC (Adverse Conditions Dataset with Correspondences)#mIoU#16.7$Unsupervised Semantic Segmentation#Dark Zurich#mIoU#14.2
2203.11075v2.pdf	Unsupervised Semantic Segmentation#COCO-All#mIoU#16.4
2107.00691v1.pdf	Unsupervised Semantic Segmentation#COCO-Stuff#Pixel Accuracy#31.0
2007.08247v1.pdf	Unsupervised Semantic Segmentation#COCO-Stuff#Pixel Accuracy#30.8
2106.03149v3.pdf	Unsupervised Semantic Segmentation#ImageNet-S#mIoU (val)#11.5$Unsupervised Semantic Segmentation#ImageNet-S#mIoU (test)#11.0$Unsupervised Semantic Segmentation#ImageNet-S-50#mIoU (val)#32.4$Unsupervised Semantic Segmentation#ImageNet-S-50#mIoU (test)#32$Unsupervised Semantic Segmentation#ImageNet-S-300#mIoU (val)#18$Unsupervised Semantic Segmentation#ImageNet-S-300#mIoU (test)#18.1
2206.07045v1.pdf	Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#mIoU#24.2$Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#pixel accuracy#83.7$Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#mIoU#19.3$Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#pixel accuracy#74.6$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#mIoU#32.6$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#pixel accuracy#54.1$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#mIoU#26.3$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#pixel accuracy#46.1$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#mIoU#31.9$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#pixel accuracy#75.3$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#mIoU#29.8$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#pixel accuracy#70.6
2112.01071v2.pdf	Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#mIoU#10.0$Unsupervised Semantic Segmentation with Language-image Pre-training#Cityscapes val#pixel accuracy#35.9$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#mIoU#19.6$Unsupervised Semantic Segmentation with Language-image Pre-training#COCO-Stuff-27#pixel accuracy#32.2$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#mIoU#15.3$Unsupervised Semantic Segmentation with Language-image Pre-training#KITTI-STEP#pixel accuracy#34.1
1803.09597v2.pdf	One-Shot Segmentation#Cluttered Omniglot#IoU [32 distractors]#65.6$One-Shot Segmentation#Cluttered Omniglot#IoU [4 distractors]#95.8$One-Shot Segmentation#Cluttered Omniglot#IoU [256 distractors]#43.7$One-Shot Segmentation#Cluttered Omniglot#IoU [32 distractors]#62.4$One-Shot Segmentation#Cluttered Omniglot#IoU [4 distractors]#97.1$One-Shot Segmentation#Cluttered Omniglot#IoU [256 distractors]#38.4
1802.02080v4.pdf	UNET Segmentation#Munich Sentinel2 Crop Segmentation#Overall Accuracy#89.60
2109.07701v1.pdf	Road Segementation#DeepGlobe#APLS#0.7414$Road Segementation#DeepGlobe#IoU#0.6702$Road Segementation#Massachusetts Roads Dataset#IoU#65.24$Road Segementation#Massachusetts Roads Dataset#APLS#72.49
1906.11894v2.pdf	Text-Line Extraction#DIVA-HisDB#Line IoU#99.42$Text-Line Extraction#DIVA-HisDB#Pixel IoU#96.11
2202.11542v1.pdf	Amodal Panoptic Segmentation#BDD100K-APS#APQ#46.3$Amodal Panoptic Segmentation#BDD100K-APS#APC#47.3$Amodal Panoptic Segmentation#BDD100K-APS#AP#29.2$Amodal Panoptic Segmentation#BDD100K-APS#mIoU#53.3
1711.08488v2.pdf	Object Localization#KITTI Cars Moderate#AP#84.0%$Object Localization#KITTI Cyclists Easy#AP#75.38%$Object Localization#KITTI Cyclists Hard#AP#54.68%$Object Localization#KITTI Pedestrians Easy#AP#58.09%$Object Localization#KITTI Cars Hard#AP#75.33%$Object Localization#KITTI Pedestrians Hard#AP#47.2%$Object Localization#KITTI Cyclists Moderate#AP#61.96%$Object Localization#KITTI Pedestrians Moderate#AP#50.22%$Object Localization#KITTI Cars Easy#AP#88.7%$Object Detection#KITTI Cars Hard#AP#62.19$3D Object Detection#KITTI Cyclists Easy#AP#71.96%$3D Object Detection#KITTI Pedestrians Easy#AP#51.21%$3D Object Detection#KITTI Cars Hard val#AP#62.56$3D Object Detection#KITTI Cars Moderate#AP#70.39%$3D Object Detection#KITTI Pedestrian Moderate val#AP#61.32$3D Object Detection#KITTI Pedestrian Moderate val#AP#55.85$3D Object Detection#KITTI Cyclists Moderate#AP#56.77%$3D Object Detection#KITTI Cyclist Easy val#AP#77.15$3D Object Detection#KITTI Cyclist Easy val#AP#74.54$3D Object Detection#KITTI Pedestrians Moderate#AP#42.15%$3D Object Detection#KITTI Cyclist Moderate val#AP#56.49$3D Object Detection#KITTI Cyclist Moderate val#AP#55.95$3D Object Detection#KITTI Cars Easy val#AP#83.26$3D Object Detection#KITTI Cars Moderate val#AP#69.28$3D Object Detection#KITTI Cars Easy#AP#81.2%$3D Object Detection#KITTI Pedestrians Hard#AP#40.23%$3D Object Detection#KITTI Cars Hard#AP#62.19%$3D Object Detection#KITTI Pedestrian Easy val#AP#70.00$3D Object Detection#KITTI Pedestrian Easy val#AP#65.08$3D Object Detection#KITTI Cyclist Hard val#AP#53.37$3D Object Detection#KITTI Cyclist Hard val#AP#52.65$3D Object Detection#KITTI Cyclists Hard#AP#50.39%$3D Object Detection#KITTI Pedestrian Hard val#AP#53.59$3D Object Detection#KITTI Pedestrian Hard val#AP#49.28$3D Object Detection#SUN-RGBD#mAP@0.25#54.0$3D Object Detection#SUN-RGBD val#mAP@0.25#54.0$Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#56.8$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#61.96%$Birds Eye View Object Detection#KITTI Pedestrians Moderate#AP#50.22%
1711.06396v1.pdf	Object Localization#KITTI Cars Moderate#AP#79.26%$Object Localization#KITTI Cyclists Easy#AP#66.7%$Object Localization#KITTI Cyclists Hard#AP#50.55%$Object Localization#KITTI Pedestrians Easy#AP#46.13%$Object Localization#KITTI Cars Hard#AP#77.39%$Object Localization#KITTI Pedestrians Hard#AP#38.11%$Object Localization#KITTI Cyclists Moderate#AP#54.76%$Object Localization#KITTI Pedestrians Moderate#AP#40.74%$Object Localization#KITTI Cars Easy#AP#89.35%$3D Object Detection#KITTI Cyclists Easy#AP#61.22$3D Object Detection#KITTI Pedestrians Easy#AP#39.48%$3D Object Detection#KITTI Cars Moderate#AP#65.11%$3D Object Detection#KITTI Cyclists Moderate#AP#48.36$3D Object Detection#KITTI Pedestrians Moderate#AP#33.69%$3D Object Detection#KITTI Cars Easy#AP#77.47%$3D Object Detection#KITTI Pedestrians Hard#AP#31.51%$3D Object Detection#KITTI Cars Hard#AP#57.73%$3D Object Detection#KITTI Cyclists Hard#AP#44.37$Birds Eye View Object Detection#KITTI Cyclist Moderate val#AP#52.18$Birds Eye View Object Detection#KITTI Cars Easy#AP#89.35%$Birds Eye View Object Detection#KITTI Cars Moderate#AP#79.26%$Birds Eye View Object Detection#KITTI Cars Hard val#AP#78.57$Birds Eye View Object Detection#KITTI Pedestrian Moderate val#AP#61.05$Birds Eye View Object Detection#KITTI Cyclist Hard val#AP#50.49$Birds Eye View Object Detection#KITTI Cars Moderate val#AP#84.81$Birds Eye View Object Detection#KITTI Cyclist Easy val#AP#74.41$Birds Eye View Object Detection#KITTI Pedestrian Hard val#AP#56.98$Birds Eye View Object Detection#KITTI Pedestrian Easy val#AP#65.95$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#54.76%$Birds Eye View Object Detection#KITTI Cars Easy val#AP#89.6$Birds Eye View Object Detection#KITTI Pedestrians Moderate#AP#40.74%$Birds Eye View Object Detection#KITTI Cars Hard#AP#77.39
1612.03236v3.pdf	Object Localization#PASCAL VOC 2007#CorLoc#41.2$Object Localization#PASCAL VOC 2012#CorLoc#47.45
1806.07564v2.pdf	Object Localization#Mall#Precision#88.1$Object Localization#Pupil#Recall#89.2$Object Localization#Plant#F-Score#88.6
2207.10447v1.pdf	Weakly-Supervised Object Localization#CUB-200-2011#average top-1 classification accuracy#78.5$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Localization Accuracy#76.4$Weakly-Supervised Object Localization#CUB-200-2011#GT-known localization accuracy#96.6$Weakly-Supervised Object Localization#ImageNet#GT-known localization accuracy#68.8$Weakly-Supervised Object Localization#ImageNet#Top-1 Localization Accuracy#56.1$Weakly-Supervised Object Localization#ImageNet#average top-1 classification accuracy#76.7
1911.10688v4.pdf	Weakly-Supervised Object Localization#Tiny ImageNet#Top-1 Localization Accuracy#43.34$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Error Rate#54.17$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Localization Accuracy#55.83$Image Classification#Imbalanced CUB-200-2011#Average Per-Class Accuracy#87.69$Image Classification#Imbalanced CUB-200-2011#Accuracy#89.73$Fine-Grained Image Classification#Imbalanced CUB-200-2011#Average Per-Class Accuracy#87.69$Fine-Grained Image Classification#Imbalanced CUB-200-2011#Accuracy#89.73
1512.04150v1.pdf	Weakly-Supervised Object Localization#Tiny ImageNet#Top-1 Localization Accuracy#40.55$Weakly-Supervised Object Localization#ILSVRC 2015#Top-1 Error Rate#67.19$Weakly-Supervised Object Localization#ILSVRC 2016#Top-5 Error#45.14$Weakly-Supervised Object Localization#ILSVRC 2016#Top-5 Error#52.16
1802.07888v2.pdf	Weakly-Supervised Object Localization#Tiny ImageNet#Top-1 Localization Accuracy#36.00
1807.08902v2.pdf	Weakly-Supervised Object Localization#ILSVRC 2015#Top-1 Error Rate#51.40$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Error Rate#53.36$Weakly-Supervised Object Localization#CUB-200-2011#Top-5 Error#42.28$Weakly-Supervised Object Localization#ILSVRC 2016#Top-5 Error#40.00
2202.11539v2.pdf	Weakly-Supervised Object Localization#ImageNet#GT-known localization accuracy#65.4$Weakly-Supervised Object Localization#ImageNet#Top-1 Localization Accuracy#52.3$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Localization Accuracy#72.9$Weakly-Supervised Object Localization#CUB#Top-1 Localization Accuracy#72.9$Single-object discovery#COCO_20k#CorLoc#62.6$Single-object discovery#COCO_20k#CorLoc#58.8
2109.14279v1.pdf	Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Localization Accuracy#71.3$Single-object discovery#COCO_20k#CorLoc#57.5$Single-object discovery#COCO_20k#CorLoc#50.7
1911.13073v4.pdf	Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Error Rate#34.8$Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Localization Accuracy#65.22
1908.10028v1.pdf	Weakly-Supervised Object Localization#CUB-200-2011#Top-1 Error Rate#37.71
1804.06962v1.pdf	Weakly-Supervised Object Localization#ILSVRC 2016#Top-5 Error#42.58
2008.11646v3.pdf	Image-Based Localization#cvact#Recall@1#79.99$Image-Based Localization#cvact#Recall@5#90.63$Image-Based Localization#cvact#Recall@10#92.56$Image-Based Localization#cvact#Recall@1 (%)#97.03$Image-Based Localization#cvusa#Recall@10#96.98$Image-Based Localization#cvusa#Recall@1#85.79$Image-Based Localization#cvusa#Recall@5#95.38$Image-Based Localization#cvusa#Recall@top1%#99.41$Drone navigation#University-1652#AP#74.79$Drone navigation#University-1652#Recall@1#86.45$Drone-view target localization#University-1652#AP#79.14$Drone-view target localization#University-1652#Recall@1#75.93
2002.12186v2.pdf	Image-Based Localization#cvusa#Recall@10#74.58$Image-Based Localization#cvusa#Recall@1#43.91$Image-Based Localization#cvusa#Recall@5#66.38$Image-Based Localization#cvusa#Recall@top1%#91.78$Drone navigation#University-1652#AP#58.74$Drone navigation#University-1652#Recall@1#71.18$Drone-view target localization#University-1652#AP#63.13$Drone-view target localization#University-1652#Recall@1#58.49
2101.05484v1.pdf	Emotion Recognition#SEED#Accuracy#96.10
2203.07378v2.pdf	Emotion Recognition#MSP-Podcast#Concordance correlation coefficient (CCC)#0.638$Speech Emotion Recognition#MSP-Podcast (Dominance)#CCC#0.655$Speech Emotion Recognition#MSP-Podcast (Valence)#CCC#0.638$Speech Emotion Recognition#MSP-Podcast (Activation)#CCC#0.745
2107.05677v1.pdf	Emotion Recognition#Emomusic#EmoA#72.1$Emotion Recognition#Emomusic#EmoV#61.7$Emotion Recognition#Emomusic#EmoA#67.8$Emotion Recognition#Emomusic#EmoV#45.8
2201.11095v1.pdf	Emotion Recognition#RAVDESS#Accuracy#81.58%$Facial Emotion Recognition#RAVDESS#Accuracy#74.92%
2106.01621v7.pdf	Emotion Recognition#RAVDESS#Accuracy#74.8$Audio Classification#ESC-50#Top-1 Accuracy#96.1$Audio Classification#ESC-50#PRE-TRAINING DATASET#AudioSet$Audio Classification#ESC-50#Accuracy (5-fold)#96.1$Audio Classification#AudioSet#Test mAP#0.450$Audio Classification#AudioSet#AUC#0.976$Audio Classification#AudioSet#d-prime#2.804$Audio Classification#RAVDESS#Top-1 Accuracy#74.8$Audio Tagging#AudioSet#mean average precision#0.450$Emotion Classification#RAVDESS#Top-1 Accuracy#74.8
2102.06357v1.pdf	Speech Emotion Recognition#MSP-Podcast (Dominance)#CCC#0.639$Speech Emotion Recognition#MSP-Podcast (Valence)#CCC#0.377$Speech Emotion Recognition#MSP-Podcast (Activation)#CCC#0.706
2204.13601v1.pdf	Speech Emotion Recognition#ShEMO#Unweighted Accuracy#65.20
2202.01252v1.pdf	Speech Emotion Recognition#IEMOCAP#WA#0.81
1904.06022v1.pdf	Speech Emotion Recognition#IEMOCAP#F1#0.718$Speech Emotion Recognition#IEMOCAP#UA#0.701
1802.05630v2.pdf	Speech Emotion Recognition#IEMOCAP#UA#0.65
2205.09180v1.pdf	Speech Emotion Recognition#CREMA-D#Accuracy#70.95$Audio Classification#ESC-50#Top-1 Accuracy#91.58$Audio Classification#ESC-50#Accuracy (5-fold)#91.58
2203.09581v3.pdf	Speech Emotion Recognition#CREMA-D#Accuracy#70.47$Audio Classification#ESC-50#Top-1 Accuracy#91.13$Audio Classification#ESC-50#PRE-TRAINING DATASET#-$Time Series#Speech Commands#% Test Accuracy#98.51
2103.11988v2.pdf	Speech Emotion Recognition#CREMA-D#Accuracy#68.12
2003.03229v3.pdf	Speech Emotion Recognition#CREMA-D#Accuracy#65.15
2001.04316v2.pdf	Speech Emotion Recognition#CREMA-D#Accuracy#55.01
2203.13504v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#71.77$Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#69.49$Emotion Recognition in Conversation#MELD#Weighted-F1#64.00$Emotion Recognition in Conversation#MELD#Weighted-F1#63.51
2206.02187v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#69.86$Emotion Recognition in Conversation#IEMOCAP#Accuracy#69.69$Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#66.2$Emotion Recognition in Conversation#IEMOCAP#Accuracy#66.05$Emotion Recognition in Conversation#IEMOCAP#Macro-F1#66.38$Emotion Recognition in Conversation#MELD#Weighted-F1#66.71$Emotion Recognition in Conversation#MELD#Accuracy#67.85$Emotion Recognition in Conversation#MELD#Weighted-F1#66.23$Emotion Recognition in Conversation#MELD#Accuracy#67.24
2112.11718v2.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#68.73$Emotion Recognition in Conversation#DailyDialog#Micro-F1#59.76
2112.12389v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#68.72$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#39.14$Emotion Recognition in Conversation#MELD#Weighted-F1#63.32$Emotion Recognition in Conversation#DailyDialog#Micro-F1#64.07
2108.12009v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#68.57$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#48.09$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#44.60$Emotion Recognition in Conversation#MELD#Weighted-F1#65.61
2203.02385v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#68.18$Emotion Recognition in Conversation#IEMOCAP#Accuracy#68.21$Emotion Recognition in Conversation#MELD#Weighted-F1#59.46$Emotion Recognition in Conversation#MELD#Accuracy#62.49
2105.12907v2.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#68.03$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#39.02$Emotion Recognition in Conversation#MELD#Weighted-F1#63.65$Emotion Recognition in Conversation#DailyDialog#Micro-F1#59.33
2108.11626v3.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#66.61$Emotion Recognition in Conversation#IEMOCAP#Accuracy#66.76$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#37.37$Emotion Recognition in Conversation#MELD#Weighted-F1#66.52$Emotion Recognition in Conversation#DailyDialog#Macro F1#53.15$Emotion Recognition in Conversation#DailyDialog#Micro-F1#60.34
2106.01978v2.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#66.33$Emotion Recognition in Conversation#SEMAINE#MAE (Valence)#0.173$Emotion Recognition in Conversation#SEMAINE#MAE (Arousal)#0.152$Emotion Recognition in Conversation#SEMAINE#MAE (Expectancy)#0.175$Emotion Recognition in Conversation#SEMAINE#MAE (Power)#8.20$Emotion Recognition in Conversation#MELD#Weighted-F1#58.39$Emotion Recognition in Conversation#MELD#Accuracy#60.73
2012.08695v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#66.2$Emotion Recognition in Conversation#IEMOCAP#Accuracy#66.3$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#51.24$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#46.96$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#34.73$Emotion Recognition in Conversation#MELD#Weighted-F1#62.41$Emotion Recognition in Conversation#DailyDialog#Micro-F1#54.93
2012.14781v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#65.94$Emotion Recognition in Conversation#MELD#Weighted-F1#62.36
2010.02795v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#65.30$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#38.11$Emotion Recognition in Conversation#MELD#Weighted-F1#65.21$Emotion Recognition in Conversation#DailyDialog#Macro F1#51.05$Emotion Recognition in Conversation#DailyDialog#Micro-F1#58.48
2006.00492v3.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#65.22$Emotion Recognition in Conversation#MELD#Weighted-F1#60.84
1908.11540v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#64.37$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#47.69$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#45.12$Emotion Recognition in Conversation#SEMAINE#MAE (Valence)#0.157$Emotion Recognition in Conversation#SEMAINE#MAE (Arousal)#0.161$Emotion Recognition in Conversation#SEMAINE#MAE (Expectancy)#0.168$Emotion Recognition in Conversation#SEMAINE#MAE (Power)#7.68$Emotion Recognition in Conversation#MELD#Weighted-F1#58.10$Emotion Recognition in Conversation#MELD#Accuracy#59.46
1911.09075v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#64.10
1811.00405v4.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#63.5$Emotion Recognition in Conversation#IEMOCAP#Accuracy#63.5$Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#48.57$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#44.11$Emotion Recognition in Conversation#SEMAINE#MAE (Valence)#0.168$Emotion Recognition in Conversation#SEMAINE#MAE (Arousal)#0.165$Emotion Recognition in Conversation#SEMAINE#MAE (Expectancy)#0.175$Emotion Recognition in Conversation#SEMAINE#MAE (Power)#7.9$Emotion Recognition in Conversation#MELD#Weighted-F1#57.03$Emotion Recognition in Conversation#MELD#Accuracy#59.54
2106.01071v1.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#62.75$Emotion Recognition in Conversation#IEMOCAP#Accuracy#63.4$Emotion Recognition in Conversation#IEMOCAP#Macro-F1#60.66$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#38.69$Emotion Recognition in Conversation#EmoryNLP#Micro-F1#42.38$Emotion Recognition in Conversation#MELD#Weighted-F1#65.47$Emotion Recognition in Conversation#DailyDialog#Micro-F1#58.47$Emotion Recognition in Conversation#DailyDialog#Weighted F1#52.56
1909.10681v2.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#61.33$Emotion Recognition in Conversation#IEMOCAP#Micro-F1#61.11$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#34.39$Emotion Recognition in Conversation#MELD#Weighted-F1#58.18$Emotion Recognition in Conversation#EC#Micro-F1#0.7413$Emotion Recognition in Conversation#DailyDialog#Micro-F1#53.37
1910.04980v3.pdf	Emotion Recognition in Conversation#IEMOCAP#Weighted-F1#59.56$Emotion Recognition in Conversation#DailyDialog#Micro-F1#48.4
2205.14727v1.pdf	Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#51.50$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#48.02$Personalized and Emotional Conversation#CPED#PPL#17.48$Personalized and Emotional Conversation#CPED#BLEU#0.1342$Personalized and Emotional Conversation#CPED#Distinct-1#0.0614$Personalized and Emotional Conversation#CPED#Distinct-2#0.3430$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.4996$Personalized and Emotional Conversation#CPED#Average Embedding#0.5588$Personalized and Emotional Conversation#CPED#bertscore#0.5709$Personalized and Emotional Conversation#CPED#PPL#17.70$Personalized and Emotional Conversation#CPED#BLEU#0.1403$Personalized and Emotional Conversation#CPED#Distinct-1#0.0602$Personalized and Emotional Conversation#CPED#Distinct-2#0.3388$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.5026$Personalized and Emotional Conversation#CPED#Average Embedding#0.5617$Personalized and Emotional Conversation#CPED#bertscore#0.5719$Personalized and Emotional Conversation#CPED#PPL#17.72$Personalized and Emotional Conversation#CPED#BLEU#0.1372$Personalized and Emotional Conversation#CPED#Distinct-1#0.0605$Personalized and Emotional Conversation#CPED#Distinct-2#0.3389$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.5017$Personalized and Emotional Conversation#CPED#Average Embedding#0.5610$Personalized and Emotional Conversation#CPED#bertscore#0.5703$Personalized and Emotional Conversation#CPED#PPL#17.80$Personalized and Emotional Conversation#CPED#BLEU#0.1382$Personalized and Emotional Conversation#CPED#Distinct-1#0.0601$Personalized and Emotional Conversation#CPED#Distinct-2#0.3404$Personalized and Emotional Conversation#CPED#Greedy Embedding#05012$Personalized and Emotional Conversation#CPED#Average Embedding#0.5608$Personalized and Emotional Conversation#CPED#bertscore#0.5722$Personalized and Emotional Conversation#CPED#PPL#18.08$Personalized and Emotional Conversation#CPED#Distinct-1#0.0592$Personalized and Emotional Conversation#CPED#Distinct-2#0.3363$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.5009$Personalized and Emotional Conversation#CPED#Average Embedding#0.5606$Personalized and Emotional Conversation#CPED#bertscore#0.5715$Personalized and Emotional Conversation#CPED#PPL#20.07$Personalized and Emotional Conversation#CPED#BLEU#0.1171$Personalized and Emotional Conversation#CPED#Distinct-1#0.0482$Personalized and Emotional Conversation#CPED#Distinct-2#0.2738$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.4922$Personalized and Emotional Conversation#CPED#Average Embedding#0.5509$Personalized and Emotional Conversation#CPED#bertscore#0.5629$Personalized and Emotional Conversation#CPED#PPL#21.60$Personalized and Emotional Conversation#CPED#BLEU#0.1304$Personalized and Emotional Conversation#CPED#Distinct-1#0.0476$Personalized and Emotional Conversation#CPED#Distinct-2#0.2785$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.4962$Personalized and Emotional Conversation#CPED#Average Embedding#0.5552$Personalized and Emotional Conversation#CPED#bertscore#0.5674$Personalized and Emotional Conversation#CPED#PPL#22.09$Personalized and Emotional Conversation#CPED#BLEU#0.1272$Personalized and Emotional Conversation#CPED#Distinct-1#0.0473$Personalized and Emotional Conversation#CPED#Distinct-2#0.2790$Personalized and Emotional Conversation#CPED#Average Embedding#0.5556$Personalized and Emotional Conversation#CPED#bertscore#0.5669$Personalized and Emotional Conversation#CPED#PPL#22.84$Personalized and Emotional Conversation#CPED#BLEU#0.1252$Personalized and Emotional Conversation#CPED#Distinct-1#0.0451$Personalized and Emotional Conversation#CPED#Distinct-2#0.2746$Personalized and Emotional Conversation#CPED#Greedy Embedding#0.4964$Personalized and Emotional Conversation#CPED#Average Embedding#0.5564$Personalized and Emotional Conversation#CPED#bertscore#0.5666$Personality Recognition in Conversation#CPED#Accuracy (%)#67.25$Personality Recognition in Conversation#CPED#Macro-F1#74.08$Personality Recognition in Conversation#CPED#Accuracy of Neurotism#53.27$Personality Recognition in Conversation#CPED#Accuracy of Extraversion#78.21$Personality Recognition in Conversation#CPED#Accuracy of Openness#55.42$Personality Recognition in Conversation#CPED#Accuracy of Agreeableness#85.89$Personality Recognition in Conversation#CPED#Accuracy of Conscientiousness#63.48$Personality Recognition in Conversation#CPED#Accuracy (%)#67.23$Personality Recognition in Conversation#CPED#Macro-F1#72.93$Personality Recognition in Conversation#CPED#Accuracy of Neurotism#50.75$Personality Recognition in Conversation#CPED#Accuracy of Extraversion#78.08$Personality Recognition in Conversation#CPED#Accuracy of Openness#57.93$Personality Recognition in Conversation#CPED#Accuracy of Agreeableness#85.76$Personality Recognition in Conversation#CPED#Accuracy of Conscientiousness#63.60$Personality Recognition in Conversation#CPED#Accuracy (%)#66.32$Personality Recognition in Conversation#CPED#Macro-F1#72.69$Personality Recognition in Conversation#CPED#Accuracy of Neurotism#55.29$Personality Recognition in Conversation#CPED#Accuracy of Openness#53.90$Personality Recognition in Conversation#CPED#Accuracy of Agreeableness#80.98$Personality Recognition in Conversation#CPED#Accuracy of Conscientiousness#63.35$Personality Recognition in Conversation#CPED#Accuracy (%)#66.02$Personality Recognition in Conversation#CPED#Macro-F1#71.89$Personality Recognition in Conversation#CPED#Accuracy of Neurotism#53.4$Personality Recognition in Conversation#CPED#Accuracy of Extraversion#77.71$Personality Recognition in Conversation#CPED#Accuracy of Agreeableness#81.99$Personality Recognition in Conversation#CPED#Accuracy of Conscientiousness#61.59
1607.01759v3.pdf	Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#48.62$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#30.33$Sentiment Analysis#Amazon Review Polarity#Accuracy#94.6$Sentiment Analysis#Sogou News#Accuracy#96.8$Sentiment Analysis#Yelp Fine-grained classification#Error#36.1$Sentiment Analysis#Amazon Review Full#Accuracy#60.2$Sentiment Analysis#Yelp Binary classification#Error#4.3$Text Classification#DBpedia#Error#1.4$Text Classification#AG News#Error#7.5$Text Classification#Yahoo! Answers#Accuracy#72.3
1605.05101v1.pdf	Emotion Recognition in Conversation#CPED#Accuracy of Sentiment#47.89$Emotion Recognition in Conversation#CPED#Macro-F1 of Sentiment#37.07
2112.11202v2.pdf	Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#39.04$Emotion Recognition in Conversation#EmoryNLP#Micro-F1#42.58$Emotion Recognition in Conversation#MELD#Weighted-F1#64.81$Emotion Recognition in Conversation#DailyDialog#Micro-F1#54.71$Emotion Recognition in Conversation#DailyDialog#Weighted F1#54.71
2003.01478v2.pdf	Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#35.92$Emotion Recognition in Conversation#EmoryNLP#Weighted-F1#34.54$Emotion Recognition in Conversation#MELD#Weighted-F1#61.90$Emotion Recognition in Conversation#MELD#Weighted-F1#60.69
2109.04919v2.pdf	Emotion Recognition in Conversation#EmoWoz#Weighted F1#79.7$Emotion Recognition in Conversation#EmoWoz#Macro F1#54.3$Emotion Recognition in Conversation#EmoWoz#Weighted F1#77.1$Emotion Recognition in Conversation#EmoWoz#Macro F1#56.3$Emotion Recognition in Conversation#EmoWoz#Weighted F1#75.5$Emotion Recognition in Conversation#EmoWoz#Macro F1#52.1$Emotion Recognition in Conversation#EmoWoz#Weighted F1#74.6$Emotion Recognition in Conversation#EmoWoz#Macro F1#40.1$Emotion Recognition in Conversation#EmoWoz#Weighted F1#73.5$Emotion Recognition in Conversation#EmoWoz#Macro F1#50.1
2002.07551v1.pdf	Emotion Recognition in Conversation#EmotionPush#Weighted Accuracy#86.92$Emotion Recognition in Conversation#EmotionPush#Unweighted Accuracy#63.03
1904.03223v1.pdf	Emotion Recognition in Conversation#EC#Micro-F1#0.7765
1904.00132v2.pdf	Emotion Recognition in Conversation#EC#Micro-F1#0.7709
1906.07020v1.pdf	Emotion Recognition in Conversation#EC#Micro-F1#0.7582
1905.02947v1.pdf	Emotion Recognition in Conversation#EC#Micro-F1#0.758
2205.02455v1.pdf	Multimodal Emotion Recognition#IEMOCAP#UA#0.682 (6-class)$Multimodal Emotion Recognition#IEMOCAP#F1#0.845 (4-class) 0.676 (6-class)
1806.06228v1.pdf	Multimodal Emotion Recognition#IEMOCAP#UA#0.765$Multimodal Emotion Recognition#IEMOCAP#F1#0.768$Multimodal Emotion Recognition#IEMOCAP#UA#0.761$Multimodal Emotion Recognition#IEMOCAP#F1#0.760$Multimodal Emotion Recognition#IEMOCAP#UA#0.759$Multimodal Emotion Recognition#IEMOCAP#F1#0.756$Multimodal Sentiment Analysis#MOSI#Accuracy#76.5%
1804.05788v3.pdf	Multimodal Emotion Recognition#Expressive hands and faces dataset (EHF).#v2v error#52.9
2002.10710v3.pdf	Emotion-Cause Pair Extraction#ECPE#F1#62.8
1906.01267v1.pdf	Emotion-Cause Pair Extraction#ECPE#F1#61.28
1906.01236v1.pdf	Emotion Cause Extraction#ECE#F1#76.77
1906.01230v1.pdf	Emotion Cause Extraction#ECE#F1#72.42
1708.05482v2.pdf	Emotion Cause Extraction#ECE#F1#69.55
1907.07835v4.pdf	EEG Emotion Recognition#SEED-IV#Accuracy#79.37$EEG Emotion Recognition#SEED-IV#Accuracy#56.61
2003.06692v1.pdf	Emotion Recognition in Context#EMOTIC#mAP#35.48$Emotion Recognition in Context#EMOTIC#mAP#32.03
2003.13401v1.pdf	Emotion Recognition in Context#EMOTIC#mAP#29.45$Emotion Recognition in Context#EMOTIC#mAP#27.70$Emotion Recognition in Context#EMOTIC#mAP#27.38
1908.05913v1.pdf	Emotion Recognition in Context#EMOTIC#mAP#20.84
2105.10859v1.pdf	Action Segmentation#Assembly101#MoF#39.2$Action Segmentation#Assembly101#F1@10%#33.3$Action Segmentation#Assembly101#F1@25%#29.0$Action Segmentation#Assembly101#F1@50%#21.3$Action Segmentation#Assembly101#Edit#32.4$Action Segmentation#50 Salads#F1@10%#84.3$Action Segmentation#50 Salads#Edit#76.4$Action Segmentation#50 Salads#Acc#84.9$Action Segmentation#50 Salads#F1@25%#81.8$Action Segmentation#50 Salads#F1@50%#72.6$Action Segmentation#Breakfast#F1@10%#72.2$Action Segmentation#Breakfast#F1@50%#57.6$Action Segmentation#Breakfast#Acc#76.0$Action Segmentation#Breakfast#Edit#69.6$Action Segmentation#Breakfast#F1@25%#68.7$Action Segmentation#GTEA#F1@10%#90.3$Action Segmentation#GTEA#F1@50%#77.7$Action Segmentation#GTEA#Acc#80.8$Action Segmentation#GTEA#Edit#86.4$Action Segmentation#GTEA#F1@25%#88.8
2006.09220v2.pdf	Action Segmentation#Assembly101#MoF#37.1$Action Segmentation#Assembly101#F1@10%#31.6$Action Segmentation#Assembly101#F1@25%#27.8$Action Segmentation#Assembly101#F1@50%#20.6$Action Segmentation#Assembly101#Edit#30.7$Action Segmentation#50 Salads#F1@10%#80.7$Action Segmentation#50 Salads#Edit#74.3$Action Segmentation#50 Salads#Acc#83.7$Action Segmentation#50 Salads#F1@25%#78.5$Action Segmentation#50 Salads#F1@50%#70.1$Action Segmentation#50 Salads#F1@10%#78.7$Action Segmentation#50 Salads#Edit#70.7$Action Segmentation#50 Salads#Acc#82.2$Action Segmentation#50 Salads#F1@25%#76.6$Action Segmentation#50 Salads#F1@50%#68.3$Action Segmentation#Breakfast#F1@10%#64.1$Action Segmentation#Breakfast#F1@50%#45.9$Action Segmentation#Breakfast#Acc#67.6$Action Segmentation#Breakfast#Edit#65.6$Action Segmentation#Breakfast#F1@25%#58.6$Action Segmentation#Breakfast#F1@10%#63.3$Action Segmentation#Breakfast#F1@50%#44.5$Action Segmentation#Breakfast#Acc#67.3$Action Segmentation#Breakfast#Edit#64.9$Action Segmentation#Breakfast#F1@25%#57.7$Action Segmentation#GTEA#F1@10%#88.8$Action Segmentation#GTEA#F1@50%#76.0$Action Segmentation#GTEA#Acc#80.1$Action Segmentation#GTEA#Edit#83.5$Action Segmentation#GTEA#F1@25%#85.7$Action Segmentation#GTEA#F1@10%#88.2$Action Segmentation#GTEA#F1@50%#75.9$Action Segmentation#GTEA#Acc#79.7$Action Segmentation#GTEA#Edit#83.0$Action Segmentation#GTEA#F1@25%#86.2
2011.07231v1.pdf	Action Segmentation#COIN#Frame accuracy#57.0
2205.13425v1.pdf	Action Segmentation#50Salads#F1@10%#89.2$Action Segmentation#50Salads#F1@25%#87.5$Action Segmentation#50Salads#F1@50%#81$Action Segmentation#50Salads#Edit#82.9$Action Segmentation#50Salads#Acc#87.4$Action Segmentation#Breakfast#F1@10%#76.2$Action Segmentation#Breakfast#F1@50%#59.8$Action Segmentation#Breakfast#Acc#75$Action Segmentation#Breakfast#Edit#74.6$Action Segmentation#Breakfast#F1@25%#71.8$Action Segmentation#GTEA#F1@10%#88.2$Action Segmentation#GTEA#F1@50%#74$Action Segmentation#GTEA#Acc#77$Action Segmentation#GTEA#Edit#83.9$Action Segmentation#GTEA#F1@25%#87.2
2103.11264v4.pdf	Action Segmentation#MPII Cooking 2 Dataset#Accuracy#42$Action Segmentation#MPII Cooking 2 Dataset#mIoU#23.1$Action Segmentation#50 Salads#Acc#66.5$Action Segmentation#Breakfast#Acc#62.7$Action Segmentation#Breakfast#mIoU#42.3
2209.05653v2.pdf	Action Segmentation#50 Salads#F1@10%#91.5$Action Segmentation#50 Salads#Edit#89.1$Action Segmentation#50 Salads#Acc#88.6$Action Segmentation#50 Salads#F1@25%#90.2$Action Segmentation#50 Salads#F1@50%#87.3$Action Segmentation#GTEA#F1@10%#95.7$Action Segmentation#GTEA#F1@50%#91.3$Action Segmentation#GTEA#Acc#89.8$Action Segmentation#GTEA#Edit#92.0$Action Segmentation#GTEA#F1@25%#94.2
2209.00638v2.pdf	Action Segmentation#50 Salads#F1@10%#89.1$Action Segmentation#50 Salads#Edit#83.9$Action Segmentation#50 Salads#Acc#87.4$Action Segmentation#50 Salads#F1@25%#87.6$Action Segmentation#50 Salads#F1@50%#81.7$Action Segmentation#Breakfast#F1@10%#76.9$Action Segmentation#Breakfast#F1@50%#58$Action Segmentation#Breakfast#Acc#69.7$Action Segmentation#Breakfast#Edit#77.1$Action Segmentation#Breakfast#F1@25%#71.5$Action Segmentation#GTEA#F1@10%#92.7$Action Segmentation#GTEA#F1@50%#81$Action Segmentation#GTEA#Acc#80.2$Action Segmentation#GTEA#Edit#92.1$Action Segmentation#GTEA#F1@25%#91.3
2203.14104v1.pdf	Action Segmentation#50 Salads#F1@10%#89.2$Action Segmentation#50 Salads#Edit#83.8$Action Segmentation#50 Salads#Acc#88.1$Action Segmentation#50 Salads#F1@25%#87.8$Action Segmentation#50 Salads#F1@50%#81.3$Action Segmentation#GTEA#F1@10%#94.1$Action Segmentation#GTEA#F1@50%#83.0$Action Segmentation#GTEA#Acc#81.2$Action Segmentation#GTEA#Edit#91.6$Action Segmentation#GTEA#F1@25%#92.0
2205.09445v1.pdf	Action Segmentation#50 Salads#F1@10%#87.6$Action Segmentation#50 Salads#Edit#81.7$Action Segmentation#50 Salads#Acc#86.9$Action Segmentation#50 Salads#F1@25%#86.5$Action Segmentation#50 Salads#F1@50%#80.1$Action Segmentation#Breakfast#F1@10%#79.3$Action Segmentation#Breakfast#F1@50%#61.9$Action Segmentation#Breakfast#Acc#74.9$Action Segmentation#Breakfast#Edit#77.8$Action Segmentation#Breakfast#F1@25%#74.3$Action Segmentation#GTEA#F1@10%#91.8$Action Segmentation#GTEA#F1@50%#81.3$Action Segmentation#GTEA#Acc#80.3$Action Segmentation#GTEA#Edit#87.9$Action Segmentation#GTEA#F1@25%#91.2
2110.08568v1.pdf	Action Segmentation#50 Salads#F1@10%#85.1$Action Segmentation#50 Salads#Edit#81.9$Action Segmentation#50 Salads#Acc#85.9$Action Segmentation#50 Salads#F1@25%#85.4$Action Segmentation#50 Salads#F1@50%#79.3$Action Segmentation#50 Salads#Edit#79.6$Action Segmentation#50 Salads#Acc#85.6$Action Segmentation#50 Salads#F1@25%#83.4$Action Segmentation#50 Salads#F1@50%#76.0$Action Segmentation#Breakfast#F1@10%#76.0$Action Segmentation#Breakfast#F1@50%#57.4$Action Segmentation#Breakfast#Acc#73.5$Action Segmentation#Breakfast#Edit#75.0$Action Segmentation#Breakfast#F1@25%#70.6$Action Segmentation#GTEA#F1@10%#90.1$Action Segmentation#GTEA#F1@50%#79.2$Action Segmentation#GTEA#Acc#79.7$Action Segmentation#GTEA#Edit#84.6$Action Segmentation#GTEA#F1@25%#88.8
2007.06866v1.pdf	Action Segmentation#50 Salads#F1@10%#84.9$Action Segmentation#50 Salads#Edit#79.3$Action Segmentation#50 Salads#Acc#84.5$Action Segmentation#50 Salads#F1@25%#83.5$Action Segmentation#50 Salads#F1@50%#77.3$Action Segmentation#Breakfast#F1@10%#74.3$Action Segmentation#Breakfast#F1@50%#56.1$Action Segmentation#Breakfast#Acc#67.6$Action Segmentation#Breakfast#Edit#72.4$Action Segmentation#Breakfast#F1@25%#68.9$Action Segmentation#GTEA#F1@10%#89.4$Action Segmentation#GTEA#F1@50%#79.8$Action Segmentation#GTEA#Acc#77.3$Action Segmentation#GTEA#Edit#83.7$Action Segmentation#GTEA#F1@25%#87.8
2003.02824v3.pdf	Action Segmentation#50 Salads#F1@10%#83.0$Action Segmentation#50 Salads#Edit#75.8$Action Segmentation#50 Salads#Acc#83.2$Action Segmentation#50 Salads#F1@25%#81.5$Action Segmentation#50 Salads#F1@50%#73.8$Action Segmentation#Breakfast#F1@10%#75.0$Action Segmentation#Breakfast#F1@50%#55.2$Action Segmentation#Breakfast#Acc#70.2$Action Segmentation#Breakfast#Edit#73.7$Action Segmentation#Breakfast#F1@25%#69.1$Action Segmentation#GTEA#F1@10%#90.0$Action Segmentation#GTEA#F1@50%#78.0$Action Segmentation#GTEA#Acc#79.8$Action Segmentation#GTEA#Edit#86.2$Action Segmentation#GTEA#F1@25%#89.1
2104.07461v2.pdf	Action Segmentation#50 Salads#F1@10%#82.0$Action Segmentation#50 Salads#Edit#75.2$Action Segmentation#50 Salads#Acc#83.2$Action Segmentation#50 Salads#F1@25%#80.1$Action Segmentation#50 Salads#F1@50%#72.5$Action Segmentation#Breakfast#F1@10%#74.2$Action Segmentation#Breakfast#F1@50%#56.5$Action Segmentation#Breakfast#Acc#71.0$Action Segmentation#Breakfast#Edit#73.6$Action Segmentation#Breakfast#F1@25%#68.6$Action Segmentation#GTEA#F1@10%#90.5$Action Segmentation#GTEA#F1@50%#76.2$Action Segmentation#GTEA#Acc#80.0$Action Segmentation#GTEA#Edit#85.8$Action Segmentation#GTEA#F1@25%#88.4
2101.00910v2.pdf	Action Segmentation#50 Salads#F1@10%#80.3$Action Segmentation#50 Salads#Edit#73.4$Action Segmentation#50 Salads#Acc#82.2$Action Segmentation#50 Salads#F1@25%#78$Action Segmentation#50 Salads#F1@50%#69.8$Action Segmentation#Breakfast#F1@10%#76.3$Action Segmentation#Breakfast#F1@50%#54.6$Action Segmentation#Breakfast#Acc#70.8$Action Segmentation#Breakfast#Edit#74.5$Action Segmentation#Breakfast#F1@25%#69.9
2012.07508v1.pdf	Action Segmentation#50 Salads#F1@10%#79.1$Action Segmentation#50 Salads#Edit#72$Action Segmentation#50 Salads#Acc#80$Action Segmentation#50 Salads#F1@25%#75.9$Action Segmentation#50 Salads#F1@50%#66.1$Action Segmentation#Breakfast#F1@10%#68.7$Action Segmentation#Breakfast#F1@50%#46.6$Action Segmentation#Breakfast#Acc#68.3$Action Segmentation#Breakfast#Edit#68.9$Action Segmentation#Breakfast#F1@25%#61.9
1903.01945v2.pdf	Action Segmentation#50 Salads#F1@10%#76.3$Action Segmentation#50 Salads#Edit#67.9$Action Segmentation#50 Salads#Acc#80.7$Action Segmentation#50 Salads#F1@25%#74.0$Action Segmentation#50 Salads#F1@50%#64.5$Action Segmentation#Breakfast#F1@10%#58.2$Action Segmentation#Breakfast#F1@50%#40.8$Action Segmentation#Breakfast#Acc#65.1$Action Segmentation#Breakfast#Edit#61.4$Action Segmentation#Breakfast#F1@25%#52.9$Action Segmentation#Breakfast#F1@10%#52.6$Action Segmentation#Breakfast#F1@50%#37.9$Action Segmentation#Breakfast#Acc#66.3$Action Segmentation#Breakfast#Edit#61.7$Action Segmentation#Breakfast#F1@25%#48.1$Action Segmentation#GTEA#F1@10%#87.5$Action Segmentation#GTEA#F1@50%#74.6$Action Segmentation#GTEA#Acc#79.2$Action Segmentation#GTEA#Edit#81.4$Action Segmentation#GTEA#F1@25%#85.4
2108.03894v1.pdf	Action Segmentation#Breakfast#F1@10%#75.5$Action Segmentation#Breakfast#F1@50%#54.8$Action Segmentation#Breakfast#Acc#68.6$Action Segmentation#Breakfast#Edit#78.5$Action Segmentation#Breakfast#F1@25%#70.2$Weakly Supervised Action Segmentation (Transcript)#Breakfast#Acc#51.3
1904.03116v4.pdf	Action Segmentation#Breakfast#F1@10%#73.2$Action Segmentation#Breakfast#F1@50%#48.4$Action Segmentation#Breakfast#Acc#62.8$Action Segmentation#Breakfast#Edit#76.3$Action Segmentation#Breakfast#F1@25%#66.1$Weakly Supervised Action Segmentation (Transcript)#Breakfast#Acc#48.5
2105.00067v1.pdf	Action Segmentation#Breakfast#F1@50%#31.9$Action Segmentation#Breakfast#Acc#47.4
2206.06637v2.pdf	Action Segmentation#Breakfast#Acc#70.8$Object Detection#COCO 2017 val#AP#50.9$Instance Segmentation#COCO 2017 val#AP#44.3
1602.02995v4.pdf	Action Segmentation#GTEA#F1@10%#58.7$Action Segmentation#GTEA#F1@50%#41.9$Action Segmentation#GTEA#Acc#60.6$Action Segmentation#GTEA#Edit#-$Action Segmentation#GTEA#F1@25%#54.4$Action Segmentation#JIGSAWS#Edit Distance#66.56
2011.01619v2.pdf	Action Segmentation#JIGSAWS#Edit Distance#89.3
2002.08718v1.pdf	Action Segmentation#JIGSAWS#Edit Distance#88.53
1806.08089v1.pdf	Action Segmentation#JIGSAWS#Edit Distance#87.96
1705.07818v1.pdf	Action Segmentation#JIGSAWS#Edit Distance#86.8
1801.09571v1.pdf	Action Segmentation#JIGSAWS#Edit Distance#86.21
1608.08242v1.pdf	Action Segmentation#JIGSAWS#Edit Distance#83.1
1909.13155v1.pdf	Weakly Supervised Action Segmentation (Transcript)#Breakfast#Acc#50.2
1901.02598v2.pdf	Weakly Supervised Action Segmentation (Transcript)#Breakfast#Acc#45.7
1805.06875v1.pdf	Weakly Supervised Action Segmentation (Transcript)#Breakfast#Acc#43
2106.08061v2.pdf	Spatio-Temporal Action Localization#AVA-Kinetics#val mAP#40.97$Spatio-Temporal Action Localization#AVA-Kinetics#test mAP#40.67$Spatio-Temporal Action Localization#AVA-Kinetics#val mAP#37.95
2103.01486v1.pdf	Visual Localization#Extended CMU Seasons#Acc @ .25m, 2°#0.118$Visual Localization#Extended CMU Seasons#Acc @ .5m, 5°#0.362$Visual Localization#Extended CMU Seasons#Acc @ 5m, 10°#0.962$Visual Localization#RobotCar Seasons v2#Acc @ .25m, 2°#0.096$Visual Localization#RobotCar Seasons v2#Acc @ .5m, 5°#0.353$Visual Localization#RobotCar Seasons v2#Acc @ 5m, 10°#0.909$Visual Place Recognition#Pittsburgh-30k-test#Recall@1#88.7$Visual Place Recognition#Pittsburgh-30k-test#Recall@5#94.5$Visual Place Recognition#Pittsburgh-30k-test#Recall@10#95.9$Visual Place Recognition#Mapillary val#Recall@1#79.5$Visual Place Recognition#Mapillary val#Recall@5#86.2$Visual Place Recognition#Mapillary val#Recall@10#87.7$Visual Place Recognition#Nordland#Recall@1#44.9$Visual Place Recognition#Nordland#Recall@5#50.2$Visual Place Recognition#Nordland#Recall@10#52.2$Visual Place Recognition#Tokyo247#Recall@1#86$Visual Place Recognition#Tokyo247#Recall@5#88.6$Visual Place Recognition#Tokyo247#Recall@10#90.5
2203.15458v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#6.4$Hand Pose Estimation#ICVL Hands#Average 3D Error#4.79$Hand Pose Estimation#ICVL#Error (mm)#4.76$Hand Pose Estimation#HANDS 2019#Average 3D Error#12.51
2007.09590v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#7.48$Hand Pose Estimation#ICVL Hands#Average 3D Error#5.98$Hand Pose Estimation#HANDS 2017#Average 3D Error#7.48$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.15$Hand Pose Estimation#HANDS 2019#Average 3D Error#13.76
2206.07117v2.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#7.68$Hand Pose Estimation#ICVL Hands#Average 3D Error#5.73$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.13
1711.07399v3.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#8.42$Hand Pose Estimation#ICVL Hands#Average 3D Error#6.28$Hand Pose Estimation#HANDS 2017#Average 3D Error#9.95$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.49$Pose Estimation#ITOP front-view#Mean mAP#88.74$Pose Estimation#ITOP top-view#Mean mAP#83.44
2108.05545v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#8.58$Hand Pose Estimation#ICVL Hands#Average 3D Error#5.95$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.34
1905.02085v2.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#9.173$Hand Pose Estimation#ICVL Hands#Average 3D Error#6.152$Hand Pose Estimation#HANDS 2017#Average 3D Error#10.57$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.985
1711.08996v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#10.2$Hand Pose Estimation#ICVL Hands#Average 3D Error#7.3$Hand Pose Estimation#MSRA Hands#Average 3D Error#7.2
1708.03416v2.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#11.8$Hand Pose Estimation#ICVL Hands#Average 3D Error#6.8$Hand Pose Estimation#HANDS 2017#Average 3D Error#11.70$Hand Pose Estimation#MSRA Hands#Average 3D Error#8.6
1708.08325v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#12.3$Hand Pose Estimation#ICVL Hands#Average 3D Error#8.1$Hand Pose Estimation#MSRA Hands#Average 3D Error#9.5
1702.02447v2.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#12.7$Hand Pose Estimation#ICVL Hands#Average 3D Error#7.5$Hand Pose Estimation#MSRA Hands#Average 3D Error#9.8
1707.07248v1.pdf	Hand Pose Estimation#NYU Hands#Average 3D Error#15.6$Hand Pose Estimation#ICVL Hands#Average 3D Error#7.31$Pose Estimation#ITOP front-view#Mean mAP#84.9$Pose Estimation#ITOP top-view#Mean mAP#75.5
2105.12281v1.pdf	Hand Pose Estimation#Custom FINNgers#1:1 Accuracy#98%
1712.03917v2.pdf	Hand Pose Estimation#HANDS 2017#Average 3D Error#9.97$Hand Pose Estimation#HANDS 2017#Average 3D Error#11.91
2001.00702v2.pdf	Hand Pose Estimation#HANDS 2019#Average 3D Error#13.66
1909.04349v3.pdf	3D Hand Pose Estimation#FreiHAND#PA-MPVPE#10.9$3D Hand Pose Estimation#FreiHAND#PA-MPJPE#11.0$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#51.6$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#93.4
2012.06087v2.pdf	3D Hand Pose Estimation#FreiHAND#PA-MPJPE#15.7
1902.03451v1.pdf	3D Hand Pose Estimation#FreiHAND#PA-MPVPE#13.0$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#43.5$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#89.8
1904.05767v1.pdf	3D Hand Pose Estimation#FreiHAND#PA-MPVPE#13.2$3D Hand Pose Estimation#FreiHAND#PA-F@5mm#43.6$3D Hand Pose Estimation#FreiHAND#PA-F@15mm#90.8
2006.01320v4.pdf	3D Canonical Hand Pose Estimation#Ego3DHands#AUC#0.681$3D Canonical Hand Pose Estimation#STB#AUC#0.995$3D Canonical Hand Pose Estimation#RHP#AUC#0.942
1808.04859v2.pdf	Gesture-to-Gesture Translation#NTU Hand Digit#MSE#105.7286$Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#32.6091$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.5532$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#26.1$Gesture-to-Gesture Translation#Senz3D#MSE#169.9219$Gesture-to-Gesture Translation#Senz3D#PSNR#27.9749$Gesture-to-Gesture Translation#Senz3D#IS#3.4107$Gesture-to-Gesture Translation#Senz3D#AMT#22.6
1707.01058v2.pdf	Gesture-to-Gesture Translation#NTU Hand Digit#PSNR#28.0185$Gesture-to-Gesture Translation#NTU Hand Digit#IS#2.4919$Gesture-to-Gesture Translation#NTU Hand Digit#AMT#2.6$Gesture-to-Gesture Translation#Senz3D#PSNR#26.9545$Gesture-to-Gesture Translation#Senz3D#IS#3.3285$Gesture-to-Gesture Translation#Senz3D#AMT#2.3
1710.03476v1.pdf	Lexical Normalization#LexNorm#Accuracy#87.63
1904.06100v1.pdf	Lexical Normalization#LexNorm#Accuracy#83.94
2110.06865v2.pdf	Semantic Role Labeling#OntoNotes#F1#88.32$Semantic Role Labeling#OntoNotes#F1#87.57$Semantic Role Labeling#CoNLL 2005#F1#89.54$Semantic Role Labeling#CoNLL 2005#F1#89.03$Semantic Role Labeling#CoNLL 2005#F1#87.87
2109.06660v2.pdf	Semantic Role Labeling#OntoNotes#F1#88.3$Semantic Role Labeling#CoNLL 2005#F1#90.0
2106.07306v5.pdf	Semantic Role Labeling#OntoNotes#F1#87.51$Semantic Role Labeling#OntoNotes#F1#87.27
1810.02245v1.pdf	Semantic Role Labeling#OntoNotes#F1#87.0$Semantic Role Labeling#OntoNotes#F1#86.2$Semantic Role Labeling#CoNLL 2005#F1#88.5$Semantic Role Labeling#CoNLL 2005#F1#87.6
1901.05280v1.pdf	Semantic Role Labeling#OntoNotes#F1#86.0$Semantic Role Labeling#CoNLL 2005#F1#87.7$Semantic Role Labeling#CoNLL 2005#F1#86.3$Semantic Role Labeling#CoNLL 2005#F1#83.0
1805.04787v2.pdf	Semantic Role Labeling#OntoNotes#F1#85.5$Semantic Role Labeling#OntoNotes#F1#82.1$Semantic Role Labeling#CoNLL 2005#F1#86.0$Semantic Role Labeling#CoNLL 2005#F1#82.5$Semantic Role Labeling (predicted predicates)#CoNLL 2012#F1#82.9$Semantic Role Labeling (predicted predicates)#CoNLL 2012#F1#79.8$Semantic Role Labeling (predicted predicates)#CoNLL 2005#F1#86.0$Semantic Role Labeling (predicted predicates)#CoNLL 2005#F1#82.5
1712.01586v1.pdf	Semantic Role Labeling#OntoNotes#F1#82.7
2101.00394v1.pdf	Semantic Role Labeling#CoNLL-2009#F1 (Arg.)#90.2$Semantic Role Labeling#CoNLL-2009#F1 (Prd.)#95.5
2104.07704v1.pdf	Semantic Role Labeling#CoNLL 2005#F1#88.93
1804.08199v3.pdf	Semantic Role Labeling#CoNLL 2005#F1#86.04$Predicate Detection#CoNLL 2005#F1#98.4$Predicate Detection#CoNLL 2012#F1#97.2$Semantic Role Labeling (predicted predicates)#CoNLL 2012#F1#83.38$Semantic Role Labeling (predicted predicates)#CoNLL 2012#F1#82.33$Semantic Role Labeling (predicted predicates)#CoNLL 2005#F1#86.90$Semantic Role Labeling (predicted predicates)#CoNLL 2005#F1#84.99
2111.05412v1.pdf	Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.927$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.931
1803.11175v2.pdf	Semantic Textual Similarity#STS Benchmark#Pearson Correlation#0.782$Sentiment Analysis#CR#Accuracy#87.45$Sentiment Analysis#MPQA#Accuracy#88.14$Sentiment Analysis#SST-2 Binary classification#Accuracy#87.21$Sentiment Analysis#MR#Accuracy#81.59$Subjectivity Analysis#SUBJ#Accuracy#93.90$Text Classification#TREC-6#Error#1.93$Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#47.7%
2203.06875v2.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8787$Semantic Textual Similarity#STS15#Spearman Correlation#0.8808$Semantic Textual Similarity#STS13#Spearman Correlation#0.8897$Semantic Textual Similarity#STS12#Spearman Correlation#0.7956$Semantic Textual Similarity#STS16#Spearman Correlation#0.8496$Semantic Textual Similarity#SICK#Spearman Correlation#0.8243$Semantic Textual Similarity#STS14#Spearman Correlation#0.8381
2104.08821v4.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.867$Semantic Textual Similarity#STS15#Spearman Correlation#0.8666$Semantic Textual Similarity#STS13#Spearman Correlation#0.8727$Semantic Textual Similarity#STS13#Spearman Correlation#0.8241$Semantic Textual Similarity#STS13#Spearman Correlation#0.8136$Semantic Textual Similarity#STS12#Spearman Correlation#0.7746$Semantic Textual Similarity#STS12#Spearman Correlation#0.7016$Semantic Textual Similarity#STS16#Spearman Correlation#0.8393$Semantic Textual Similarity#SICK#Spearman Correlation#0.8195$Semantic Textual Similarity#STS14#Spearman Correlation#0.8236
2109.13059v4.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.867$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8655$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8616$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8465$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.839$Semantic Textual Similarity#STS15#Spearman Correlation#0.8863$Semantic Textual Similarity#STS15#Spearman Correlation#0.8816$Semantic Textual Similarity#STS15#Spearman Correlation#0.8577$Semantic Textual Similarity#STS15#Spearman Correlation#0.8508$Semantic Textual Similarity#STS15#Spearman Correlation#0.8444$Semantic Textual Similarity#STS13#Spearman Correlation#0.8851$Semantic Textual Similarity#STS13#Spearman Correlation#0.8831$Semantic Textual Similarity#STS13#Spearman Correlation#0.8559$Semantic Textual Similarity#STS13#Spearman Correlation#0.851$Semantic Textual Similarity#STS12#Spearman Correlation#0.7828$Semantic Textual Similarity#STS12#Spearman Correlation#0.7819$Semantic Textual Similarity#STS12#Spearman Correlation#0.7637$Semantic Textual Similarity#STS12#Spearman Correlation#0.7509$Semantic Textual Similarity#STS16#Spearman Correlation#0.8503$Semantic Textual Similarity#STS16#Spearman Correlation#0.8481$Semantic Textual Similarity#STS16#Spearman Correlation#0.8377$Semantic Textual Similarity#STS16#Spearman Correlation#0.8305$Semantic Textual Similarity#SICK#Spearman Correlation#0.7276$Semantic Textual Similarity#SICK#Spearman Correlation#0.7192$Semantic Textual Similarity#SICK#Spearman Correlation#0.7163$Semantic Textual Similarity#SICK#Spearman Correlation#0.7133$Semantic Textual Similarity#SICK#Spearman Correlation#0.6952$Semantic Textual Similarity#STS14#Spearman Correlation#0.8194$Semantic Textual Similarity#STS14#Spearman Correlation#0.8176$Semantic Textual Similarity#STS14#Spearman Correlation#0.8137$Semantic Textual Similarity#STS14#Spearman Correlation#0.7903$Semantic Textual Similarity#STS14#Spearman Correlation#0.779
1908.10084v1.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8615$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8479$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.8445$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.79$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.7777$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.7703$Semantic Textual Similarity#STS15#Spearman Correlation#0.8185$Semantic Textual Similarity#STS13#Spearman Correlation#0.7846$Semantic Textual Similarity#STS12#Spearman Correlation#0.7453$Semantic Textual Similarity#STS16#Spearman Correlation#0.7682$Semantic Textual Similarity#SICK#Spearman Correlation#0.7446$Semantic Textual Similarity#SICK#Spearman Correlation#0.7429$Semantic Textual Similarity#SICK#Spearman Correlation#0.7375$Semantic Textual Similarity#SICK#Spearman Correlation#0.7291$Semantic Textual Similarity#STS14#Spearman Correlation#0.7490000000000001
2104.08027v2.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.787$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.764$Semantic Textual Similarity#STS15#Spearman Correlation#0.814$Semantic Textual Similarity#STS15#Spearman Correlation#0.798$Semantic Textual Similarity#STS13#Spearman Correlation#0.819$Semantic Textual Similarity#STS13#Spearman Correlation#0.796$Semantic Textual Similarity#STS12#Spearman Correlation#0.674$Semantic Textual Similarity#STS12#Spearman Correlation#0.648$Semantic Textual Similarity#STS16#Spearman Correlation#0.78$Semantic Textual Similarity#STS16#Spearman Correlation#0.743$Semantic Textual Similarity#SICK#Spearman Correlation#0.706$Semantic Textual Similarity#SICK#Spearman Correlation#0.703$Semantic Textual Similarity#STS14#Spearman Correlation#0.732$Semantic Textual Similarity#STS14#Spearman Correlation#0.713
2104.07540v3.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.7782$Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.7651$Semantic Textual Similarity#STS15#Spearman Correlation#0.8049$Semantic Textual Similarity#STS13#Spearman Correlation#0.8126$Semantic Textual Similarity#STS12#Spearman Correlation#0.7027$Semantic Textual Similarity#STS16#Spearman Correlation#0.7718$Semantic Textual Similarity#SICK#Spearman Correlation#0.7426$Semantic Textual Similarity#SICK#Spearman Correlation#0.6809$Semantic Textual Similarity#STS14#Spearman Correlation#0.7125
2011.05864v1.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.7226$Semantic Textual Similarity#STS15#Spearman Correlation#0.7492$Semantic Textual Similarity#STS13#Spearman Correlation#0.7339$Semantic Textual Similarity#STS12#Spearman Correlation#0.6520$Semantic Textual Similarity#STS16#Spearman Correlation#0.7763$Semantic Textual Similarity#SICK#Spearman Correlation#0.6544$Semantic Textual Similarity#STS14#Spearman Correlation#0.6942
2009.12061v2.pdf	Semantic Textual Similarity#STS Benchmark#Spearman Correlation#0.6921$Semantic Textual Similarity#STS15#Spearman Correlation#0.7523$Semantic Textual Similarity#STS13#Spearman Correlation#0.6924$Semantic Textual Similarity#STS12#Spearman Correlation#0.5677$Semantic Textual Similarity#STS16#Spearman Correlation#0.7016$Semantic Textual Similarity#SICK#Spearman Correlation#0.6425$Semantic Textual Similarity#STS14#Spearman Correlation#0.6121
2204.10298v1.pdf	Semantic Textual Similarity#STS15#Spearman Correlation#0.8390$Semantic Textual Similarity#STS15#Spearman Correlation#0.8281$Semantic Textual Similarity#STS13#Spearman Correlation#0.8443$Semantic Textual Similarity#STS13#Spearman Correlation#0.8343$Semantic Textual Similarity#STS12#Spearman Correlation#0.7228$Semantic Textual Similarity#STS12#Spearman Correlation#0.7005$Semantic Textual Similarity#STS16#Spearman Correlation#0.8212$Semantic Textual Similarity#STS16#Spearman Correlation#0.8054$Semantic Textual Similarity#STS14#Spearman Correlation#0.7647$Semantic Textual Similarity#STS14#Spearman Correlation#0.7549
2210.07316v1.pdf	Semantic Textual Similarity#MTEB#Spearman Correlation#82.63$Semantic Textual Similarity#MTEB#Spearman Correlation#81.83$Semantic Textual Similarity#MTEB#Spearman Correlation#81.66$Semantic Textual Similarity#MTEB#Spearman Correlation#81.14$Semantic Textual Similarity#MTEB#Spearman Correlation#80.73$Semantic Textual Similarity#MTEB#Spearman Correlation#80.53$Semantic Textual Similarity#MTEB#Spearman Correlation#80.28$Semantic Textual Similarity#MTEB#Spearman Correlation#79.8$Semantic Textual Similarity#MTEB#Spearman Correlation#79.12$Semantic Textual Similarity#MTEB#Spearman Correlation#78.92$Semantic Textual Similarity#MTEB#Spearman Correlation#78.6$Semantic Textual Similarity#MTEB#Spearman Correlation#78.38$Semantic Textual Similarity#MTEB#Spearman Correlation#78.19$Semantic Textual Similarity#MTEB#Spearman Correlation#78.1$Semantic Textual Similarity#MTEB#Spearman Correlation#77.8$Semantic Textual Similarity#MTEB#Spearman Correlation#77.74$Semantic Textual Similarity#MTEB#Spearman Correlation#77.07$Semantic Textual Similarity#MTEB#Spearman Correlation#76.83$Semantic Textual Similarity#MTEB#Spearman Correlation#76.47$Semantic Textual Similarity#MTEB#Spearman Correlation#75.74$Semantic Textual Similarity#MTEB#Spearman Correlation#74.71$Semantic Textual Similarity#MTEB#Spearman Correlation#74.33$Semantic Textual Similarity#MTEB#Spearman Correlation#73.41$Semantic Textual Similarity#MTEB#Spearman Correlation#70.8$Semantic Textual Similarity#MTEB#Spearman Correlation#62.47$Semantic Textual Similarity#MTEB#Spearman Correlation#61.85$Semantic Textual Similarity#MTEB#Spearman Correlation#61.02$Semantic Textual Similarity#MTEB#Spearman Correlation#55.32$Semantic Textual Similarity#MTEB#Spearman Correlation#54.36$Text Clustering#MTEB#V-Measure#43.71$Text Clustering#MTEB#V-Measure#43.69$Text Clustering#MTEB#V-Measure#42.42$Text Clustering#MTEB#V-Measure#42.35$Text Clustering#MTEB#V-Measure#42.34$Text Clustering#MTEB#V-Measure#41.81$Text Clustering#MTEB#V-Measure#41.65$Text Clustering#MTEB#V-Measure#41.6$Text Clustering#MTEB#V-Measure#41.51$Text Clustering#MTEB#V-Measure#41.1$Text Clustering#MTEB#V-Measure#40.35$Text Clustering#MTEB#V-Measure#40.21$Text Clustering#MTEB#V-Measure#39.92$Text Clustering#MTEB#V-Measure#39.83$Text Clustering#MTEB#V-Measure#38.93$Text Clustering#MTEB#V-Measure#38.63$Text Clustering#MTEB#V-Measure#38.4$Text Clustering#MTEB#V-Measure#37.64$Text Clustering#MTEB#V-Measure#37.52$Text Clustering#MTEB#V-Measure#37.14$Text Clustering#MTEB#V-Measure#36.98$Text Clustering#MTEB#V-Measure#35.79$Text Clustering#MTEB#V-Measure#34.06$Text Clustering#MTEB#V-Measure#33.43$Text Clustering#MTEB#V-Measure#30.95$Text Clustering#MTEB#V-Measure#30.12$Text Clustering#MTEB#V-Measure#29.55$Text Clustering#MTEB#V-Measure#29.04$Text Clustering#MTEB#V-Measure#27.73$Text Clustering#MTEB#V-Measure#26.57$Text Clustering#MTEB#V-Measure#15.28$Text Summarization#MTEB#Spearman Correlation#31.57$Text Summarization#MTEB#Spearman Correlation#31.39$Text Summarization#MTEB#Spearman Correlation#31.15$Text Summarization#MTEB#Spearman Correlation#30.81$Text Summarization#MTEB#Spearman Correlation#30.67$Text Summarization#MTEB#Spearman Correlation#30.64$Text Summarization#MTEB#Spearman Correlation#30.49$Text Summarization#MTEB#Spearman Correlation#30.36$Text Summarization#MTEB#Spearman Correlation#30.26$Text Summarization#MTEB#Spearman Correlation#30.21$Text Summarization#MTEB#Spearman Correlation#30.08$Text Summarization#MTEB#Spearman Correlation#29.91$Text Summarization#MTEB#Spearman Correlation#29.82$Text Summarization#MTEB#Spearman Correlation#29.67$Text Summarization#MTEB#Spearman Correlation#29.64$Text Summarization#MTEB#Spearman Correlation#29.5$Text Summarization#MTEB#Spearman Correlation#28.87$Text Summarization#MTEB#Spearman Correlation#27.9$Text Summarization#MTEB#Spearman Correlation#27.66$Text Summarization#MTEB#Spearman Correlation#27.49$Text Summarization#MTEB#Spearman Correlation#26.94$Text Summarization#MTEB#Spearman Correlation#26.8$Text Summarization#MTEB#Spearman Correlation#25.44$Text Summarization#MTEB#Spearman Correlation#24.99$Text Summarization#MTEB#Spearman Correlation#24.75$Text Summarization#MTEB#Spearman Correlation#23.31$Text Classification#MTEB#Accuracy#73.42$Text Classification#MTEB#Accuracy#72.84$Text Classification#MTEB#Accuracy#72.31$Text Classification#MTEB#Accuracy#70.44$Text Classification#MTEB#Accuracy#70.14$Text Classification#MTEB#Accuracy#69.81$Text Classification#MTEB#Accuracy#68.13$Text Classification#MTEB#Accuracy#67.91$Text Classification#MTEB#Accuracy#67.41$Text Classification#MTEB#Accuracy#67.32$Text Classification#MTEB#Accuracy#67.14$Text Classification#MTEB#Accuracy#67.13$Text Classification#MTEB#Accuracy#67.11$Text Classification#MTEB#Accuracy#66.68$Text Classification#MTEB#Accuracy#66.52$Text Classification#MTEB#Accuracy#66.19$Text Classification#MTEB#Accuracy#65.25$Text Classification#MTEB#Accuracy#65.07$Text Classification#MTEB#Accuracy#64.71$Text Classification#MTEB#Accuracy#64.3$Text Classification#MTEB#Accuracy#63.21$Text Classification#MTEB#Accuracy#63.06$Text Classification#MTEB#Accuracy#62.71$Text Classification#MTEB#Accuracy#62.5$Text Classification#MTEB#Accuracy#61.66$Text Classification#MTEB#Accuracy#61.46$Text Classification#MTEB#Accuracy#60.72$Text Classification#MTEB#Accuracy#57.65$Text Classification#MTEB#Accuracy#57.29$Text Classification#MTEB#Accuracy#53.65$Text Classification#MTEB#Accuracy#52.37$Information Retrieval#MTEB#nDCG@10#50.25
2107.07445v2.pdf	Semantic Textual Similarity#MRPC#Accuracy#90.7%$Semantic Textual Similarity#MRPC#Number of Params#318M$Semantic Textual Similarity#MRPC#Accuracy#90.5%$Semantic Textual Similarity#MRPC#Number of Params#104M
2004.02984v2.pdf	Semantic Textual Similarity#MRPC#Accuracy#88.8%$Semantic Textual Similarity#MRPC#Number of Params#25.3M
2109.05125v1.pdf	Semantic Textual Similarity#CxC#avg ± std#74.5 ± 0.4$Semantic Textual Similarity#CxC#avg ± std#74.1 ± 0.4$Semantic Textual Similarity#CxC#avg ± std#72.9 ± 0.4
2106.07691v1.pdf	Paraphrase Identification#AP#MCC#0.525
2104.06979v3.pdf	Paraphrase Identification#TURL#AP#76.8$Paraphrase Identification#PIT#AP#69.2$Information Retrieval#CQADupStack#mAP@100#0.145
1911.07405v1.pdf	Paraphrase Identification#Quora Question Pairs#Accuracy#88.86
1704.04565v2.pdf	Paraphrase Identification#Quora Question Pairs#Accuracy#88.40
1806.04330v2.pdf	Paraphrase Identification#2017_test set#10 fold Cross validation#50
2107.07653v3.pdf	Semantic Parsing#WikiTableQuestions#Accuracy (Dev)#57.0$Semantic Parsing#WikiTableQuestions#Accuracy (Test)#57.5$Semantic Parsing#SQA#Denotation Accuracy#74.5$Semantic Parsing#WikiSQL#Denotation accuracy (test)#89.5$Table-based Fact Verification#TabFact#Test#84.2$Table-based Fact Verification#TabFact#Val#84.6
2005.08314v1.pdf	Semantic Parsing#WikiTableQuestions#Accuracy (Dev)#52.2$Semantic Parsing#WikiTableQuestions#Accuracy (Test)#51.8$Text-To-Sql#spider#Accuracy (Dev)#64.5
1909.04165v1.pdf	Semantic Parsing#WikiTableQuestions#Accuracy (Dev)#43.7$Semantic Parsing#WikiTableQuestions#Accuracy (Test)#44.5
2004.02349v2.pdf	Semantic Parsing#WikiTableQuestions#Accuracy (Dev)#/$Semantic Parsing#WikiTableQuestions#Accuracy (Test)#48.8$Semantic Parsing#SQA#Accuracy#67.2$Semantic Parsing#WikiSQL#Denotation accuracy (test)#83.6
2011.00758v1.pdf	Semantic Parsing#EDS (english, MRP 2020)#F1#92.73$Semantic Parsing#DRG (english, MRP 2020)#F1#94.16$Semantic Parsing#UCCA (german, MRP 2020)#F1#81.01$Semantic Parsing#PTG (czech, MRP 2020)#F1#92.24$Semantic Parsing#UCCA (english, MRP 2020)#F1#76.4$Semantic Parsing#AMR (english, MRP 2020)#F1#80.23$Semantic Parsing#AMR (chinese, MRP 2020)#F1#80.52$Semantic Parsing#PTG (english, MRP 2020)#F1#89.19$Semantic Parsing#DRG (german, MRP 2020)#F1#89.83
2010.05710v1.pdf	Semantic Parsing#EDS (english, MRP 2020)#F1#80$Semantic Parsing#DRG (english, MRP 2020)#F1#63$Semantic Parsing#UCCA (german, MRP 2020)#F1#75$Semantic Parsing#PTG (czech, MRP 2020)#F1#58$Semantic Parsing#UCCA (english, MRP 2020)#F1#73$Semantic Parsing#AMR (english, MRP 2020)#F1#52$Semantic Parsing#AMR (chinese, MRP 2020)#F1#45$Semantic Parsing#PTG (english, MRP 2020)#F1#54$Semantic Parsing#DRG (german, MRP 2020)#F1#62
2105.11314v2.pdf	Semantic Parsing#PTG (czech, MRP 2020)#F1#92.36
1805.04793v1.pdf	Semantic Parsing#Geo#Accuracy#88.2
2111.00653v3.pdf	Semantic Parsing#spider#Accuracy#70.1$Text-To-Sql#spider#Accuracy (Dev)#73.1$Text-To-Sql#spider#Accuracy (Test)#70.1
2012.10309v1.pdf	Semantic Parsing#spider#Accuracy#69.7$Text-To-Sql#spider#Accuracy (Dev)#71.8
2009.13845v2.pdf	Semantic Parsing#spider#Accuracy#69.6
1911.04942v5.pdf	Semantic Parsing#spider#Accuracy#65.6
1809.08887v5.pdf	Semantic Parsing#spider#Accuracy#19.7
2210.13650v1.pdf	Semantic Parsing#WebQuestionsSP#Accuracy#76.4
1704.07535v1.pdf	Semantic Parsing#ATIS#Accuracy#85.3
1411.5379v3.pdf	Semantic Parsing#ATIS#Accuracy#84.2
2203.07836v4.pdf	AMR Parsing#Bio#Smatch#63.2$AMR Parsing#The Little Prince#Smatch#79.8$AMR Parsing#LDC2017T10#Smatch#85.4$AMR Parsing#LDC2020T02#Smatch#84.2$AMR Parsing#New3#Smatch#76.9
2110.09131v2.pdf	AMR Parsing#Bio#Smatch#62.8$AMR Parsing#The Little Prince#Smatch#79.52$AMR Parsing#LDC2017T10#Smatch#86.26$AMR Parsing#LDC2017T10#Smatch#85.85$AMR Parsing#LDC2020T02#Smatch#84.87$AMR Parsing#LDC2020T02#Smatch#84.41$AMR Parsing#New3#Smatch#76.32
1810.03541v1.pdf	AMR Parsing#LDC2014T12#F1 Full#68.4$AMR Parsing#LDC2014T12#F1 Newswire#73.3$AMR Parsing#LDC2014T12:#F1 Newswire#0.73$AMR Parsing#LDC2014T12:#F1 Full#0.68
1707.07755v2.pdf	AMR Parsing#LDC2014T12#F1 Full#63$AMR Parsing#LDC2014T12#F1 Newswire#68
2010.10673v1.pdf	AMR Parsing#LDC2014T12#F1 Full#78.2$AMR Parsing#LDC2017T10#Smatch#81.3
2004.05572v2.pdf	AMR Parsing#LDC2014T12#F1 Full#75.4$AMR Parsing#LDC2017T10#Smatch#80.2
1909.02607v2.pdf	AMR Parsing#LDC2014T12#F1 Full#71.3$AMR Parsing#LDC2017T10#Smatch#77.0$UCCA Parsing#SemEval 2019 Task 1#English-Wiki (open) F1#76.6
1905.08704v2.pdf	AMR Parsing#LDC2014T12#F1 Full#70.2$AMR Parsing#LDC2017T10#Smatch#76.3$AMR Parsing#LDC2014T12:#F1 Newswire#0.75$AMR Parsing#LDC2014T12:#F1 Full#0.70
1805.05286v1.pdf	AMR Parsing#LDC2015E86#Smatch#73.7$AMR Parsing#LDC2017T10#Smatch#74.4
1608.06111v5.pdf	AMR Parsing#LDC2015E86#Smatch#64.0
1704.08381v3.pdf	AMR Parsing#LDC2015E86#Smatch#62.1
2112.07790v2.pdf	AMR Parsing#LDC2017T10#Smatch#86.7$AMR Parsing#LDC2017T10#Smatch#85.9$AMR Parsing#LDC2020T02#Smatch#85.4$AMR Parsing#LDC2020T02#Smatch#84.3
2204.08875v2.pdf	AMR Parsing#LDC2017T10#Smatch#85.3$AMR Parsing#LDC2017T10#Smatch#85.2$AMR Parsing#LDC2020T02#Smatch#84.0
2110.15534v1.pdf	AMR Parsing#LDC2017T10#Smatch#84.7
2104.14674v3.pdf	AMR Parsing#LDC2017T10#Smatch#82.6$AMR Parsing#LDC2020T02#Smatch#80.4
2010.01771v1.pdf	AMR Parsing#LDC2017T10#Smatch#81.4
2107.04152v1.pdf	AMR Parsing#LDC2017T10#Smatch#80
2010.12676v2.pdf	AMR Parsing#LDC2017T10#Smatch#76.1
1905.13370v1.pdf	AMR Parsing#LDC2017T10#Smatch#73.4
1909.04303v2.pdf	AMR Parsing#LDC2017T10#Smatch#73.2
1705.09980v2.pdf	AMR Parsing#LDC2017T10#Smatch#71.0
1906.07880v3.pdf	Semantic Dependency Parsing#DM#In-domain#94.0$Semantic Dependency Parsing#DM#Out-of-domain#89.7$Semantic Dependency Parsing#PAS#In-domain#94.1$Semantic Dependency Parsing#PAS#Out-of-domain#91.3$Semantic Dependency Parsing#PSD#In-domain#81.4$Semantic Dependency Parsing#PSD#Out-of-domain#79.6
1807.01396v1.pdf	Semantic Dependency Parsing#DM#In-domain#93.7$Semantic Dependency Parsing#DM#Out-of-domain#88.9$Semantic Dependency Parsing#PAS#In-domain#93.9$Semantic Dependency Parsing#PAS#Out-of-domain#90.6$Semantic Dependency Parsing#PSD#In-domain#81.0$Semantic Dependency Parsing#PSD#Out-of-domain#79.4
1805.00287v1.pdf	UCCA Parsing#SemEval 2019 Task 1#English-Wiki (open) F1#73.5$UCCA Parsing#SemEval 2019 Task 1#English-20K (open) F1#68.4
1704.00552v2.pdf	UCCA Parsing#SemEval 2019 Task 1#English-Wiki (open) F1#72.8$UCCA Parsing#SemEval 2019 Task 1#English-20K (open) F1#67.2
2011.04308v1.pdf	DRS Parsing#PMB-2.2.0#F1#88.3$DRS Parsing#PMB-3.0.0#F1#89.3
1810.12579v1.pdf	DRS Parsing#PMB-2.2.0#F1#83.3$DRS Parsing#PMB-3.0.0#F1#84.9
1910.00051v2.pdf	DRS Parsing#PMB-2.2.0#F1#76.4
1807.01270v5.pdf	Grammatical Error Correction#Unrestricted#F0.5#61.34$Grammatical Error Correction#Unrestricted#GLEU#62.37
2106.03830v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#68.87$Grammatical Error Correction#Falko-MERLIN#F0.5#75.96
2005.12592v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#66.5$Grammatical Error Correction#CoNLL-2014 Shared Task#Precision#78.2$Grammatical Error Correction#CoNLL-2014 Shared Task#Recall#41.5$Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#65.3$Grammatical Error Correction#CoNLL-2014 Shared Task#Precision#77.5$Grammatical Error Correction#CoNLL-2014 Shared Task#Recall#40.1$Grammatical Error Correction#BEA-2019 (test)#F0.5#73.6$Grammatical Error Correction#BEA-2019 (test)#F0.5#72.4
2109.06822v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#65.8$Grammatical Error Correction#GMEG-wiki#F0.5#50.6$Grammatical Error Correction#BEA-2019 (test)#F0.5#72.9$Grammatical Error Correction#GMEG-yahoo#F0.5#52.2
2005.00987v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#65.2$Grammatical Error Correction#JFLEG#GLEU#62.0$Grammatical Error Correction#BEA-2019 (test)#F0.5#69.8
1909.00502v1.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#65.0$Grammatical Error Correction#BEA-2019 (test)#F0.5#70.2
2105.04443v1.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#63.7$Grammatical Error Correction#JFLEG#GLEU#62.1$Grammatical Error Correction#BEA-2019 (test)#F0.5#68.9$Grammatical Error Detection#FCE#F0.5#72.2$Grammatical Error Detection#CoNLL-2014 A1#F0.5#54.3$Grammatical Error Detection#CoNLL-2014 A2#F0.5#63.1
2005.11849v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#63.0$Grammatical Error Correction#CoNLL-2014 Shared Task#Precision#69.9$Grammatical Error Correction#CoNLL-2014 Shared Task#Recall#45.1
1910.02893v2.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#61.2$Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#59.7
1903.00138v3.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#61.15$Grammatical Error Correction#CoNLL-2014 Shared Task#Precision#71.57$Grammatical Error Correction#CoNLL-2014 Shared Task#Recall#38.65$Grammatical Error Correction#JFLEG#GLEU#61.0
1804.05945v1.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#56.25$Grammatical Error Correction#JFLEG#GLEU#61.5$Grammatical Error Correction#CoNLL-2014 Shared Task (10 annotations)#F0.5#72.04
1804.05940v1.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#55.8$Grammatical Error Correction#Restricted#F0.5#55.8$Grammatical Error Correction#_Restricted_#GLEU#59.9$Grammatical Error Correction#JFLEG#GLEU#59.9
1801.08831v1.pdf	Grammatical Error Correction#CoNLL-2014 Shared Task#F0.5#54.79$Grammatical Error Correction#Restricted#F0.5#70.14 (measured by Ge et al., 2018)$Grammatical Error Correction#_Restricted_#GLEU#57.47$Grammatical Error Correction#JFLEG#GLEU#57.47$Grammatical Error Correction#CoNLL-2014 Shared Task (10 annotations)#F0.5#70.14
1910.00353v3.pdf	Grammatical Error Correction#Falko-MERLIN#F0.5#73.71$Grammatical Error Correction#Falko-MERLIN#F0.5#51.41
1906.03897v1.pdf	Grammatical Error Correction#BEA-2019 (test)#F0.5#73.2
1907.01256v1.pdf	Grammatical Error Correction#BEA-2019 (test)#F0.5#69.0
2210.12364v1.pdf	Grammatical Error Correction#FCGEC#exact match#34.10$Grammatical Error Correction#FCGEC#F0.5#45.48
1811.05949v1.pdf	Grammatical Error Detection#JFLEG#F0.5#52.52$Grammatical Error Detection#FCE#F0.5#52.07$Grammatical Error Detection#CoNLL-2014 A1#F0.5#22.14$Grammatical Error Detection#CoNLL-2014 A2#F0.5#29.65
1707.05236v1.pdf	Grammatical Error Detection#FCE#F0.5#49.11$Grammatical Error Detection#CoNLL-2014 A1#F0.5#21.87$Grammatical Error Detection#CoNLL-2014 A2#F0.5#30.13
1707.05227v1.pdf	Grammatical Error Detection#FCE#F0.5#47.7$Grammatical Error Detection#CoNLL-2014 A1#F0.5#36.1$Grammatical Error Detection#CoNLL-2014 A1#F0.5#17.5$Grammatical Error Detection#CoNLL-2014 A2#F0.5#45.1$Grammatical Error Detection#CoNLL-2014 A2#F0.5#26.2
1607.06153v1.pdf	Grammatical Error Detection#FCE#F0.5#41.1$Grammatical Error Detection#CoNLL-2014 A1#F0.5#34.3$Grammatical Error Detection#CoNLL-2014 A1#F0.5#16.4$Grammatical Error Detection#CoNLL-2014 A2#F0.5#44.0$Grammatical Error Detection#CoNLL-2014 A2#F0.5#23.9
1904.02099v3.pdf	Dependency Parsing#French GSD#LAS#91.45$Dependency Parsing#French GSD#UAS#93.60$Dependency Parsing#ParTUT#LAS#88.06$Dependency Parsing#ParTUT#UAS#90.55$Dependency Parsing#Sequoia Treebank#LAS#90.05$Dependency Parsing#Sequoia Treebank#UAS#92.53$Dependency Parsing#Spoken Corpus#LAS#80.01$Dependency Parsing#Spoken Corpus#UAS#85.24$Dependency Parsing#Universal Dependencies#LAS#80.43$Dependency Parsing#Universal Dependencies#UAS#85.69
2010.05003v2.pdf	Dependency Parsing#Chinese Treebank#LAS#91.69$Dependency Parsing#Chinese Treebank#UAS#92.78$Dependency Parsing#Penn Treebank#UAS#96.91$Dependency Parsing#Penn Treebank#LAS#95.34
1808.03731v2.pdf	Dependency Parsing#GENIA - UAS#F1#92.84$Dependency Parsing#GENIA - LAS#F1#91.92
2005.00975v2.pdf	Dependency Parsing#CoNLL-2009#LAS#86.52$Dependency Parsing#CoNLL-2009#UAS#89.63$Dependency Parsing#NLPCC-2019#LAS#72.33$Dependency Parsing#NLPCC-2019#UAS#78.02$Dependency Parsing#Penn Treebank#UAS#96.14$Dependency Parsing#Penn Treebank#LAS#94.49
1611.01734v3.pdf	Dependency Parsing#CoNLL-2009#LAS#85.38$Dependency Parsing#CoNLL-2009#UAS#88.90$Dependency Parsing#Penn Treebank#UAS#97.29$Dependency Parsing#Penn Treebank#LAS#95.75$Dependency Parsing#Penn Treebank#UAS#95.87$Dependency Parsing#Penn Treebank#LAS#94.22
1804.08228v1.pdf	Dependency Parsing#Tweebank#Labelled Attachment Score#79.4$Dependency Parsing#Tweebank#Unlabeled Attachment Score#83.4
2201.07281v2.pdf	Dependency Parsing#Tweebank#Labelled Attachment Score#79.39$Dependency Parsing#Tweebank#Unlabeled Attachment Score#83.82
1911.03875v3.pdf	Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#97.42$Dependency Parsing#Penn Treebank#LAS#96.26$Constituency Parsing#Penn Treebank#F1 score#96.38
1907.02684v4.pdf	Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#97.20$Dependency Parsing#Penn Treebank#LAS#95.72$Constituency Parsing#Penn Treebank#F1 score#96.33$Constituency Parsing#Penn Treebank#F1 score#95.84$Constituency Parsing#CTB5#F1 score#89.40
2003.13118v2.pdf	Dependency Parsing#Penn Treebank#UAS#96.66$Dependency Parsing#Penn Treebank#LAS#95.01
1903.08445v1.pdf	Dependency Parsing#Penn Treebank#UAS#96.04$Dependency Parsing#Penn Treebank#LAS#94.43
1805.01087v1.pdf	Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#95.87$Dependency Parsing#Penn Treebank#LAS#94.19
1807.03955v2.pdf	Dependency Parsing#Penn Treebank#POS#97.97$Dependency Parsing#Penn Treebank#UAS#95.51$Dependency Parsing#Penn Treebank#LAS#93.87
1603.06042v2.pdf	Dependency Parsing#Penn Treebank#POS#97.44$Dependency Parsing#Penn Treebank#UAS#94.61$Dependency Parsing#Penn Treebank#LAS#92.79
1609.07561v1.pdf	Dependency Parsing#Penn Treebank#POS#97.44$Dependency Parsing#Penn Treebank#UAS#94.26$Dependency Parsing#Penn Treebank#LAS#92.06
1506.06158v1.pdf	Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#94.01$Dependency Parsing#Penn Treebank#LAS#92.06
1603.04351v3.pdf	Dependency Parsing#Penn Treebank#POS#97.44$Dependency Parsing#Penn Treebank#UAS#93.99$Dependency Parsing#Penn Treebank#LAS#91.9$Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#93.1$Dependency Parsing#Penn Treebank#LAS#91.0
1603.03793v2.pdf	Dependency Parsing#Penn Treebank#POS#97.3$Dependency Parsing#Penn Treebank#UAS#93.56$Dependency Parsing#Penn Treebank#LAS#91.42
1908.07448v1.pdf	Dependency Parsing#Universal Dependencies#LAS#84.60$Dependency Parsing#Universal Dependencies#UAS#87.64
1807.03121v3.pdf	Dependency Parsing#Universal Dependencies#LAS#75.84
1901.10457v1.pdf	Dependency Parsing#Universal Dependencies#LAS#74.16$Dependency Parsing#Universal Dependencies#UAS#62.08$Dependency Parsing#Universal Dependencies#BLEX#65.28
1504.04666v1.pdf	Unsupervised Dependency Parsing#Penn Treebank#UAS#66.2
2010.14720v1.pdf	Dependency Grammar Induction#WSJ#UAS#67.5$Dependency Grammar Induction#WSJ10#UAS#79.9
1902.09492v2.pdf	Cross-lingual zero-shot dependency parsing#Universal Dependency Treebank#LAS#77.3$Cross-lingual zero-shot dependency parsing#Universal Dependency Treebank#UAS#84.2
1602.01595v4.pdf	Cross-lingual zero-shot dependency parsing#Universal Dependency Treebank#LAS#70.5
2206.00664v1.pdf	General Classification#Shrutime#Accuracy#86.39 ± 0.04$General Classification#Shrutime#Accuracy#86.18 ± 0.02$General Classification#Shrutime#Accuracy#86.12 ± 0.09$General Classification#Shrutime#Accuracy#85.62 ± 0.07$General Classification#Shrutime#Accuracy#84.58 ± 0.00
1901.09346v2.pdf	General Classification#ISOLET#Accuracy#68.5$General Classification#Activity#Accuracy#42$General Classification#Fashion-MNIST#Accuracy#67.7$General Classification#MNIST#Accuracy#90.6$General Classification#Mice Protein#Accuracy#13.4
2102.11498v1.pdf	General Classification#CVE to CWE mapping#5 fold cross validation#89-98
2010.04524v2.pdf	General Classification#Wine#Accuracy#100$General Classification#iris#Accuracy#100
2005.13166v1.pdf	General Classification#XOR#Accuracy#93.1045$General Classification#XOR#Accuracy#92.962$General Classification#XOR#Accuracy#92.8179$General Classification#XOR#Accuracy#77.2217
2104.07916v2.pdf	Audio Classification#Speech Commands#Accuracy#97.8$Image Classification#CIFAR-100#Percentage correct#77.9$Image Classification#ImageNet#Top 1 Accuracy#71.6%$Image Classification#ImageNet#Number of params#11.51M
2103.06508v3.pdf	Audio Classification#ESC-50#Top-1 Accuracy#90.5$Audio Classification#AudioSet#Test mAP#0.376
2103.03483v4.pdf	Audio Classification#ESC-50#Top-1 Accuracy#87.1$Audio Classification#ESC-50#Accuracy (5-fold)#87.1
1705.08168v2.pdf	Audio Classification#ESC-50#Top-1 Accuracy#79.3$Audio Classification#AudioSet#Test mAP#0.249
2108.01991v1.pdf	Audio Classification#ICBHI Respiratory Sound Database#ICBHI Score#58.29$Audio Classification#ICBHI Respiratory Sound Database#Sensitivity#37.24$Audio Classification#ICBHI Respiratory Sound Database#Specificity#79.34
2210.16192v1.pdf	Audio Classification#ICBHI Respiratory Sound Database#ICBHI Score#57.55$Audio Classification#ICBHI Respiratory Sound Database#Sensitivity#39.15$Audio Classification#ICBHI Respiratory Sound Database#Specificity#75.95$Audio Classification#ICBHI Respiratory Sound Database#ICBHI Score#54.74$Audio Classification#ICBHI Respiratory Sound Database#Sensitivity#33.84$Audio Classification#ICBHI Respiratory Sound Database#Specificity#75.35
2011.00196v2.pdf	Audio Classification#ICBHI Respiratory Sound Database#ICBHI Score#56.20$Audio Classification#ICBHI Respiratory Sound Database#Sensitivity#40.10$Audio Classification#ICBHI Respiratory Sound Database#Specificity#72.30
2210.11328v1.pdf	Audio Classification#VGGSound#Top 1 Accuracy#53.7$Audio Classification#VGGSound#Top 5 Accuracy#79.2$Audio Classification#VGGSound#Mean AP#56.1$Audio Classification#VGGSound#AUC#97.8$Audio Classification#VGGSound#d-prime#2.846$Audio Classification#EPIC-KITCHENS-100#Top-1 Verb#47$Audio Classification#EPIC-KITCHENS-100#Top-5 Verb#78.7$Audio Classification#EPIC-KITCHENS-100#Top-1 Noun#23.1$Audio Classification#EPIC-KITCHENS-100#Top-5 Noun#45.1$Audio Classification#EPIC-KITCHENS-100#Top-1 Action#15.9$Audio Classification#EPIC-KITCHENS-100#Top-5 Action#29.2$Audio Classification#AudioSet#Test mAP#0.477
2205.03433v2.pdf	Audio Classification#VocalSound#Accuracy#90.5
2110.05069v3.pdf	Audio Classification#AudioSet#Test mAP#0.496$Audio Classification#AudioSet#Test mAP#0.471$Audio Classification#FSD50K#mAP#65.55$Audio Classification#FSD50K#mAP#64.2$Audio Tagging#AudioSet#mean average precision#0.496
2102.01243v3.pdf	Audio Classification#AudioSet#Test mAP#0.474$Audio Classification#AudioSet#AUC#0.981$Audio Classification#AudioSet#d-prime#2.936$Audio Classification#AudioSet#Test mAP#0.443$Audio Classification#AudioSet#AUC#0.975$Audio Classification#AudioSet#d-prime#2.778$Audio Classification#FSD50K#mAP#56.71$Audio Tagging#AudioSet#mean average precision#0.474
2006.01595v1.pdf	Audio Classification#AudioSet#Test mAP#0.462$Audio Classification#AudioSet#AUC#0.975
2103.03206v2.pdf	Audio Classification#AudioSet#Test mAP#0.449$Image Classification#ImageNet#Top 1 Accuracy#78%$Image Classification#ImageNet#Number of params#44.9M$Image Classification#ImageNet#GFLOPs#707.2$Image Classification#ImageNet#Top 1 Accuracy#76.4%$3D Point Cloud Classification#ModelNet40#Mean Accuracy#14.3
1912.10211v5.pdf	Audio Classification#AudioSet#Test mAP#0.431$Audio Classification#AudioSet#AUC#0.973$Audio Classification#AudioSet#d-prime#2.732$Audio Tagging#AudioSet#mean average precision#0.431
2110.07313v3.pdf	Audio Classification#AudioSet#Test mAP#0.411$Audio Classification#Balanced Audio Set#Mean AP#27.6
2007.00144v1.pdf	Audio Classification#AudioSet#Test mAP#0.398$Audio Classification#AudioSet#AUC#0.972
1711.02209v1.pdf	Audio Classification#AudioSet#Test mAP#0.244
2110.14131v2.pdf	Audio Classification#FSD50K#mAP#54.8
2105.00335v1.pdf	Audio Classification#FSD50K#mAP#53.7
2106.13043v1.pdf	Environmental Sound Classification#ESC-50#Accuracy#97.15$Environmental Sound Classification#UrbanSound8K#Accuracy#90.07
1904.08990v1.pdf	Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#89
1608.04363v2.pdf	Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#79$Environmental Sound Classification#UrbanSound8K#Accuracy (10-fold)#73
1911.06721v1.pdf	Scene Classification#UC Merced Land Use Dataset#Accuracy (%)#99.61$Multi-Label Image Classification#BigEarthNet#mean average precision#75.36$Image Classification#So2Sat LCZ42#Accuracy#63.25$Image Classification#EuroSAT#Accuracy (%)#99.2$Image Classification#RESISC45#Top 1 Accuracy#96.83
2103.10368v2.pdf	Scene Classification#UC Merced Land Use Dataset#Accuracy (%)#98.33$Image Classification#EuroSAT#Accuracy (%)#98.65$Image Classification#EuroSAT#Accuracy (%)#98.14
1904.06836v2.pdf	Scene Classification#Places365-Standard#Top 1 Error#43.68$Scene Classification#Places365-Standard#Top 5 Error#13.73$Image Classification#iNaturalist#Top 3 Error#14.625
2105.11856v1.pdf	Acoustic Scene Classification#DCASE 2019 Mobile#Accuracy#70.4
2011.01447v1.pdf	Acoustic Scene Classification#TAU Urban Acoustic Scenes 2019#1:1 Accuracy#81.9
2210.15366v2.pdf	Acoustic Scene Classification#TUT Urban Acoustic Scenes 2018#Acc#78.1
2103.10180v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#99.5%$Pose Estimation#UPenn Action#Mean PCK@0.2#99.4$Pose Estimation#MPII#PCKh@0.2#92.3$Pose Estimation#COCO test-dev#AP#76.4$Pose Estimation#COCO test-dev#AP50#92.6$Pose Estimation#COCO test-dev#AP75#83.7$Pose Estimation#COCO test-dev#APL#82.6$Pose Estimation#COCO test-dev#APM#72.6$Pose Estimation#COCO test-dev#AR#81.2$Multi-Person Pose Estimation#COCO#AP#0.795$Multi-Person Pose Estimation#COCO#Validation AP#79.5
2002.11098v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#94.8%$Pose Estimation#MPII Human Pose#PCKh-0.5#94.1
2001.08095v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#94.5%$Pose Estimation#UPenn Action#Mean PCK@0.2#99.3$Pose Estimation#MPII Human Pose#PCKh-0.5#92.7
1805.09707v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#94.5%$Pose Estimation#MPII Human Pose#PCKh-0.5#91.5
1707.02439v2.pdf	Pose Estimation#Leeds Sports Poses#PCK#94%$Pose Estimation#MPII Human Pose#PCKh-0.5#91.8
1708.01101v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#93.9%$Pose Estimation#MPII Human Pose#PCKh-0.5#92.0
1705.02407v2.pdf	Pose Estimation#Leeds Sports Poses#PCK#93.9%$Pose Estimation#MPII Human Pose#PCKh-0.5#91.2
1702.07432v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#92.6%$Pose Estimation#MPII Human Pose#PCKh-0.5#91.5
1811.05419v2.pdf	Pose Estimation#Leeds Sports Poses#PCK#90.8%$Pose Estimation#MPII Human Pose#PCKh-0.5#91.1
1609.01743v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#90.7%$Pose Estimation#MPII Human Pose#PCKh-0.5#89.7
1710.02322v1.pdf	Pose Estimation#Leeds Sports Poses#PCK#90.5%
1605.03170v3.pdf	Pose Estimation#Leeds Sports Poses#PCK#90.1%$Pose Estimation#MPII Human Pose#PCKh-0.5#88.52$Keypoint Detection#MPII Multi-Person#mAP@0.5#59.4%$Multi-Person Pose Estimation#WAF#AOP#88.10%$Multi-Person Pose Estimation#MPII Multi-Person#AP#59.4%
1407.3399v2.pdf	Pose Estimation#Leeds Sports Poses#PCK#73.4%
1712.06316v4.pdf	Pose Estimation#J-HMDB#Mean PCK@0.2#93.6$Pose Estimation#UPenn Action#Mean PCK@0.2#97.7$2D Human Pose Estimation#JHMDB (2D poses only)#PCK#93.6
1612.00137v5.pdf	Pose Estimation#UAV-Human#mAP#56.9$Pose Estimation#OCHuman#Test AP#30.7$Pose Estimation#OCHuman#Validation AP#38.8$Pose Estimation#COCO test-dev#AP#72.3$Pose Estimation#COCO test-dev#AP50#89.2$Pose Estimation#COCO test-dev#AP75#79.1$Pose Estimation#COCO test-dev#APL#78.6$Pose Estimation#COCO test-dev#APM#68.0$Pose Estimation#COCO test-dev#AP#61.8$Pose Estimation#COCO test-dev#AP50#83.7$Pose Estimation#COCO test-dev#AP75#69.8$Pose Estimation#COCO test-dev#APL#67.6$Pose Estimation#COCO test-dev#APM#58.6$Keypoint Detection#MPII Multi-Person#mAP@0.5#82.1%$Keypoint Detection#OCHuman#Test AP#30.7$Keypoint Detection#OCHuman#Validation AP#38.8$Keypoint Detection#COCO#Test AP#73.3$Keypoint Detection#COCO#FPS#23$Keypoint Detection#COCO test-dev#APL#81.5$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#61.0$Multi-Person Pose Estimation#CrowdPose#AP Easy#71.2$Multi-Person Pose Estimation#CrowdPose#AP Medium#61.4$Multi-Person Pose Estimation#CrowdPose#AP Hard#51.1$Multi-Person Pose Estimation#COCO test-dev#AP#61.8$Multi-Person Pose Estimation#COCO test-dev#APL#67.6$Multi-Person Pose Estimation#COCO test-dev#APM#58.6$Multi-Person Pose Estimation#COCO test-dev#AP50#83.7$Multi-Person Pose Estimation#COCO test-dev#AP75#69.8$Multi-Person Pose Estimation#MPII Multi-Person#AP#82.1%$2D Human Pose Estimation#OCHuman#Test AP#30.7$2D Human Pose Estimation#OCHuman#Validation AP#38.8
1908.10357v3.pdf	Pose Estimation#UAV-Human#mAP#56.5$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#67.6$Multi-Person Pose Estimation#CrowdPose#AP Easy#75.8$Multi-Person Pose Estimation#CrowdPose#AP Medium#68.1$Multi-Person Pose Estimation#CrowdPose#AP Hard#58.9$Multi-Person Pose Estimation#CrowdPose#FPS#-$Multi-Person Pose Estimation#COCO test-dev#AP#70.5$Multi-Person Pose Estimation#COCO test-dev#APL#75.8$Multi-Person Pose Estimation#COCO test-dev#APM#66.6$Multi-Person Pose Estimation#COCO test-dev#AP50#89.3$Multi-Person Pose Estimation#COCO test-dev#AP75#77.2
2203.01449v1.pdf	Pose Estimation#Pix3D#Percentage correct#74.55
1703.10898v1.pdf	Pose Estimation#UPenn Action#Mean PCK@0.2#96.5
1603.04037v2.pdf	Pose Estimation#UPenn Action#Mean PCK@0.2#81.1
1803.02276v2.pdf	Pose Estimation#KITTI 2015#Average End-Point Error#10.81
2204.12484v3.pdf	Pose Estimation#CrowdPose#AP#78.3$Pose Estimation#CrowdPose#AP50#85.3$Pose Estimation#CrowdPose#AP75#81.4$Pose Estimation#CrowdPose#APM#86.6$Pose Estimation#CrowdPose#AP Hard#67.9$Pose Estimation#OCHuman#Test AP#93.3$Pose Estimation#OCHuman#Validation AP#92.8$Pose Estimation#MPII Human Pose#PCKh-0.5#94.3$Pose Estimation#COCO test-dev#AP#81.1$Pose Estimation#COCO test-dev#AP50#95.0$Pose Estimation#COCO test-dev#AP75#88.2$Pose Estimation#COCO test-dev#APL#86.0$Pose Estimation#COCO test-dev#APM#77.8$Pose Estimation#COCO test-dev#AR#85.6$Pose Estimation#COCO test-dev#AP#80.9$Pose Estimation#COCO test-dev#AP50#94.8$Pose Estimation#COCO test-dev#AP75#88.1$Pose Estimation#COCO test-dev#APL#85.9$Pose Estimation#COCO test-dev#APM#77.5$Pose Estimation#COCO test-dev#AR#85.4
2111.08557v4.pdf	Pose Estimation#CrowdPose#AP#68.9$Pose Estimation#CrowdPose#AP50#89.4$Pose Estimation#CrowdPose#AP75#75.6$Pose Estimation#CrowdPose#Test#76.6$Pose Estimation#CrowdPose#APM#69.9$Pose Estimation#CrowdPose#AP#67.1$Pose Estimation#CrowdPose#AP50#88.8$Pose Estimation#CrowdPose#AP75#73.4$Pose Estimation#CrowdPose#Test#75.2$Pose Estimation#CrowdPose#APM#68.1$Pose Estimation#CrowdPose#AP#63.8$Pose Estimation#CrowdPose#AP50#87.7$Pose Estimation#CrowdPose#AP75#69.4$Pose Estimation#CrowdPose#Test#72.1$Pose Estimation#CrowdPose#APM#64.8$Pose Estimation#COCO test-dev#AP#70.3$Pose Estimation#COCO test-dev#AP50#91.2$Pose Estimation#COCO test-dev#AP75#77.8$Pose Estimation#COCO test-dev#APL#76.8$Pose Estimation#COCO test-dev#APM#66.3$Pose Estimation#COCO test-dev#AR#77.7$Pose Estimation#COCO test-dev#AP#68.8$Pose Estimation#COCO test-dev#AP50#90.5$Pose Estimation#COCO test-dev#AP75#76.5$Pose Estimation#COCO test-dev#APL#76$Pose Estimation#COCO test-dev#APM#64.3$Pose Estimation#COCO test-dev#AR#76.3$Pose Estimation#COCO test-dev#AP#63.8$Pose Estimation#COCO test-dev#AP50#88.4$Pose Estimation#COCO test-dev#AP75#70.4$Pose Estimation#COCO test-dev#APL#71.7$Pose Estimation#COCO test-dev#APM#58.6$Pose Estimation#COCO test-dev#AR#71.2
2107.03098v2.pdf	Pose Estimation#CrowdPose#AP#65.2$Pose Estimation#CrowdPose#AP50#85.9$Pose Estimation#CrowdPose#AP75#69.5$Pose Estimation#CrowdPose#APM#66.2$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#65.2$Multi-Person Pose Estimation#CrowdPose#AP Easy#73.8$Multi-Person Pose Estimation#CrowdPose#AP Medium#66.2$Multi-Person Pose Estimation#CrowdPose#AP Hard#54.8$Multi-Person Pose Estimation#CrowdPose#FPS#14.7 (21.4)$Multi-Person Pose Estimation#COCO test-dev#AP#65.6$Multi-Person Pose Estimation#COCO test-dev#APL#68.8$Multi-Person Pose Estimation#COCO test-dev#APM#63.3
2101.11223v3.pdf	Pose Estimation#OCHuman#Test AP#42.5$Pose Estimation#OCHuman#Validation AP#42.0$Pose Estimation#OCHuman#Test AP#37.2$Pose Estimation#OCHuman#Validation AP#37.8$Pose Estimation#COCO test-dev#AP#75.7$Pose Estimation#COCO test-dev#AP50#92.4$Pose Estimation#COCO test-dev#AP75#83.3$Pose Estimation#COCO test-dev#APL#81.2$Pose Estimation#COCO test-dev#APM#71.4$Pose Estimation#COCO test-dev#AR#80.5$Keypoint Detection#OCHuman#Test AP#42.5$Keypoint Detection#OCHuman#Validation AP#42.0$Keypoint Detection#OCHuman#Test AP#37.2$Keypoint Detection#OCHuman#Validation AP#37.8$Keypoint Detection#COCO#Validation AP#76.3$Keypoint Detection#COCO#Test AP#75.7$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#70.0$Multi-Person Pose Estimation#CrowdPose#AP Easy#78.1$Multi-Person Pose Estimation#CrowdPose#AP Medium#71.1$Multi-Person Pose Estimation#CrowdPose#AP Hard#59.4$2D Human Pose Estimation#OCHuman#Test AP#42.5$2D Human Pose Estimation#OCHuman#Validation AP#42.0$2D Human Pose Estimation#OCHuman#Test AP#37.2$2D Human Pose Estimation#OCHuman#Validation AP#37.8
2007.11864v1.pdf	Pose Estimation#OCHuman#Test AP#36.0$Pose Estimation#OCHuman#Validation AP#41.8$Keypoint Detection#OCHuman#Test AP#36.0$Keypoint Detection#OCHuman#Validation AP#41.8$2D Human Pose Estimation#OCHuman#Test AP#36.0$2D Human Pose Estimation#OCHuman#Validation AP#41.8
1804.06208v2.pdf	Pose Estimation#OCHuman#Test AP#33.3$Pose Estimation#OCHuman#Validation AP#41.0$Pose Estimation#OCHuman#Test AP#29.5$Pose Estimation#OCHuman#Validation AP#32.1$Pose Estimation#AIC#AP#29.9$Pose Estimation#AIC#AP50#73.8$Pose Estimation#AIC#AP75#18.3$Pose Estimation#AIC#AR#34.3$Pose Estimation#AIC#AR50#76.9$Pose Estimation#AIC#AP#29.4$Pose Estimation#AIC#AP50#73.6$Pose Estimation#AIC#AP75#17.4$Pose Estimation#AIC#AR#33.7$Pose Estimation#AIC#AR50#76.3$Pose Estimation#AIC#AP#28.0$Pose Estimation#AIC#AP50#71.6$Pose Estimation#AIC#AP75#15.8$Pose Estimation#AIC#AR#32.1$Pose Estimation#AIC#AR50#74.1$Pose Estimation#COCO test-dev#AP#73.7$Pose Estimation#COCO test-dev#AP50#91.9$Pose Estimation#COCO test-dev#AP75#81.1$Pose Estimation#COCO test-dev#APL#80$Pose Estimation#COCO test-dev#APM#70.3$Pose Estimation#COCO test-dev#AR#79$Keypoint Detection#OCHuman#Test AP#33.3$Keypoint Detection#OCHuman#Validation AP#41.0$Keypoint Detection#OCHuman#Test AP#29.5$Keypoint Detection#OCHuman#Validation AP#32.1$Keypoint Detection#COCO#Validation AP#72.2$Keypoint Detection#COCO test-dev#APL#82.7$Keypoint Detection#COCO test-dev#APM#73.0$Keypoint Detection#COCO test-dev#AP50#92.4$Keypoint Detection#COCO test-dev#AP75#84.0$Keypoint Detection#COCO test-dev#AR#81.5$Keypoint Detection#COCO test-dev#AR50#95.8$Keypoint Detection#COCO test-dev#AR75#88.2$Keypoint Detection#COCO test-dev#ARL#87.2$Keypoint Detection#COCO test-dev#ARM#77.4$Keypoint Detection#COCO test-dev#APL#80.0$Keypoint Detection#COCO test-dev#APM#70.3$Keypoint Detection#COCO test-dev#AP50#91.9$Keypoint Detection#COCO test-dev#AP75#81.1$Keypoint Detection#COCO test-dev#AR#79.0$Keypoint Detection#COCO test-challenge#AR#80.5$Keypoint Detection#COCO test-challenge#ARM#75.3$Keypoint Detection#COCO test-challenge#AP#74.5$Keypoint Detection#COCO test-challenge#AP50#90.9$Keypoint Detection#COCO test-challenge#AP75#80.8$Keypoint Detection#COCO test-challenge#APL#87.5$Keypoint Detection#COCO test-challenge#AR50#95.1$Keypoint Detection#COCO test-challenge#AR75#86.3$Keypoint Detection#COCO test-challenge#ARL#82.9$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#60.8$Multi-Person Pose Estimation#CrowdPose#AP Easy#71.4$Multi-Person Pose Estimation#CrowdPose#AP Medium#61.2$Multi-Person Pose Estimation#CrowdPose#AP Hard#51.2$Multi-Person Pose Estimation#OCHuman#Validation AP#24.1$Multi-Person Pose Estimation#OCHuman#AP50#37.4$Multi-Person Pose Estimation#OCHuman#AP75#26.8$Pose Tracking#PoseTrack2017#MOTA#57.81$Pose Tracking#PoseTrack2017#mAP#74.57$Pose Tracking#PoseTrack2018#MOTA#61.37$Pose Tracking#PoseTrack2018#mAP#74.03$2D Human Pose Estimation#OCHuman#Test AP#33.3$2D Human Pose Estimation#OCHuman#Validation AP#41.0$2D Human Pose Estimation#OCHuman#Test AP#30.4$2D Human Pose Estimation#OCHuman#Validation AP#37.8$2D Human Pose Estimation#JHMDB (2D poses only)#PCK#94.4
1611.05424v2.pdf	Pose Estimation#OCHuman#Test AP#32.8$Pose Estimation#OCHuman#Validation AP#40.0$Pose Estimation#OCHuman#Test AP#29.5$Pose Estimation#OCHuman#Validation AP#32.1$Keypoint Detection#MPII Multi-Person#mAP@0.5#77.5%$Keypoint Detection#OCHuman#Test AP#32.8$Keypoint Detection#OCHuman#Validation AP#40.0$Keypoint Detection#OCHuman#Test AP#29.5$Keypoint Detection#OCHuman#Validation AP#32.1$Keypoint Detection#COCO#Test AP#62.8$Keypoint Detection#COCO test-dev#APL#72.6$Keypoint Detection#COCO test-dev#APM#60.6$Keypoint Detection#COCO test-dev#AP50#86.8$Keypoint Detection#COCO test-dev#AP75#72.3$Keypoint Detection#COCO test-dev#AR#70.2$Keypoint Detection#COCO test-dev#AR50#89.5$Keypoint Detection#COCO test-dev#AR75#76.0$Keypoint Detection#COCO test-dev#ARL#78.1$Keypoint Detection#COCO test-dev#ARM#64.6$Multi-Person Pose Estimation#COCO#AP#0.655$Multi-Person Pose Estimation#MPII Multi-Person#AP#77.5%$2D Human Pose Estimation#OCHuman#Test AP#32.8$2D Human Pose Estimation#OCHuman#Validation AP#40.0$2D Human Pose Estimation#OCHuman#Test AP#29.5$2D Human Pose Estimation#OCHuman#Validation AP#32.1$2D Human Pose Estimation#COCO-WholeBody#WB#27.4$2D Human Pose Estimation#COCO-WholeBody#body#40.5$2D Human Pose Estimation#COCO-WholeBody#foot#7.7$2D Human Pose Estimation#COCO-WholeBody#face#47.7$2D Human Pose Estimation#COCO-WholeBody#hand#34.1
1803.10683v3.pdf	Pose Estimation#OCHuman#Test AP#23.8$Keypoint Detection#OCHuman#Test AP#23.8$Human Instance Segmentation#OCHuman#AP#0.552$2D Human Pose Estimation#OCHuman#Test AP#23.8
2012.14214v5.pdf	Pose Estimation#OCHuman#Validation AP#62.3$Pose Estimation#MPII Human Pose#PCKh-0.5#93.5$Pose Estimation#COCO test-dev#AP#75$Pose Estimation#COCO test-dev#AP50#92.2$Pose Estimation#COCO test-dev#AP75#82.3$Pose Estimation#COCO test-dev#APL#81.1$Pose Estimation#COCO test-dev#APM#71.3$Keypoint Detection#COCO#Validation AP#75.8$Keypoint Detection#COCO#Test AP#75.0$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#71.8$Multi-Person Pose Estimation#CrowdPose#AP Easy#79.5$Multi-Person Pose Estimation#CrowdPose#AP Medium#72.9$Multi-Person Pose Estimation#CrowdPose#AP Hard#62.2$Multi-Person Pose Estimation#OCHuman#AP50#82.7$Multi-Person Pose Estimation#OCHuman#AP75#67.1
2110.09408v3.pdf	Pose Estimation#AIC#AP#34.4$Pose Estimation#AIC#AP50#78.3$Pose Estimation#AIC#AP75#24.8$Pose Estimation#AIC#AR#38.7$Pose Estimation#AIC#AR50#80.9$Pose Estimation#AIC#AP#31.6$Pose Estimation#AIC#AP75#20.9$Pose Estimation#AIC#AR#35.8$Pose Estimation#AIC#AR50#78.0$Pose Estimation#COCO test-dev#AP#76.2$Pose Estimation#COCO test-dev#AP50#92.7$Pose Estimation#COCO test-dev#AP75#83.8$Pose Estimation#COCO test-dev#APL#82.3$Pose Estimation#COCO test-dev#APM#72.5$Pose Estimation#COCO test-dev#AR#81.2$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#72.4$Multi-Person Pose Estimation#CrowdPose#AP Easy#80.0$Multi-Person Pose Estimation#CrowdPose#AP Medium#73.5$Multi-Person Pose Estimation#CrowdPose#AP Hard#62.4$Multi-Person Pose Estimation#OCHuman#Validation AP#62.1$Multi-Person Pose Estimation#OCHuman#AP50#81.4$Multi-Person Pose Estimation#OCHuman#AP75#67.1$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#50.3M$Image Classification#ImageNet#GFLOPs#13.7$Image Classification#ImageNet#Top 1 Accuracy#78.5%$Image Classification#ImageNet#Number of params#8.0M$Image Classification#ImageNet#GFLOPs#1.8
1902.09212v1.pdf	Pose Estimation#AIC#AP#33.5$Pose Estimation#AIC#AP50#78.0$Pose Estimation#AIC#AP75#23.6$Pose Estimation#AIC#AR#37.9$Pose Estimation#AIC#AR50#80.0$Pose Estimation#AIC#AP#32.3$Pose Estimation#AIC#AP50#76.2$Pose Estimation#AIC#AP75#21.9$Pose Estimation#AIC#AR#36.6$Pose Estimation#AIC#AR50#78.9$Pose Estimation#MPII Human Pose#PCKh-0.5#92.3$Pose Estimation#COCO test-dev#AP#77$Pose Estimation#COCO test-dev#AP50#92.7$Pose Estimation#COCO test-dev#AP75#84.5$Pose Estimation#COCO test-dev#APL#83.1$Pose Estimation#COCO test-dev#APM#73.4$Pose Estimation#COCO test-dev#AR#82$Keypoint Detection#COCO#Validation AP#76.3$Keypoint Detection#COCO#Test AP#75.5$Keypoint Detection#COCO#Validation AP#75.8$Keypoint Detection#COCO test-dev#APL#83.1$Keypoint Detection#COCO test-dev#APM#73.4$Keypoint Detection#COCO test-dev#AP50#92.7$Keypoint Detection#COCO test-dev#AP75#84.5$Keypoint Detection#COCO test-dev#AR#82.0$Keypoint Detection#COCO test-dev#APL#81.5$Keypoint Detection#COCO test-dev#APM#71.9$Keypoint Detection#COCO test-dev#AP50#92.5$Keypoint Detection#COCO test-dev#AP75#83.3$Keypoint Detection#COCO test-dev#AR#80.5$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#72.8$Multi-Person Pose Estimation#CrowdPose#AP Easy#81.3$Multi-Person Pose Estimation#CrowdPose#AP Medium#73.3$Multi-Person Pose Estimation#CrowdPose#AP Hard#65.5$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#71.3$Multi-Person Pose Estimation#CrowdPose#AP Easy#80.5$Multi-Person Pose Estimation#CrowdPose#AP Medium#71.4$Multi-Person Pose Estimation#CrowdPose#AP Hard#62.5$Instance Segmentation#COCO minival#mask AP#41.0$Pose Tracking#PoseTrack2017#MOTA#57.93$Pose Tracking#PoseTrack2017#mAP#74.95$2D Human Pose Estimation#COCO-WholeBody#WB#43.2$2D Human Pose Estimation#COCO-WholeBody#body#65.9$2D Human Pose Estimation#COCO-WholeBody#foot#31.4$2D Human Pose Estimation#COCO-WholeBody#face#52.3$2D Human Pose Estimation#COCO-WholeBody#hand#30.0
1811.12596v1.pdf	Pose Estimation#DensePose-COCO#AP#61.6$Human Part Segmentation#MHP v2.0#Mean IoU#41.8$Human Part Segmentation#CIHP#Mean IoU#61.1
1802.00434v1.pdf	Pose Estimation#DensePose-COCO#AP#55.8
1901.00148v4.pdf	Pose Estimation#COCO minival#AP#75.9$Pose Estimation#MPII Human Pose#PCKh-0.5#92.6$Pose Estimation#COCO test-dev#AP#76.1$Pose Estimation#COCO test-dev#AP50#93.4$Pose Estimation#COCO test-dev#AP75#83.8$Pose Estimation#COCO test-dev#APL#81.5$Pose Estimation#COCO test-dev#APM#72.3$Pose Estimation#COCO test-dev#AR#81.6$Keypoint Detection#COCO#Test AP#76.1$Keypoint Detection#COCO test-dev#APL#81.5$Keypoint Detection#COCO test-dev#APM#72.3$Keypoint Detection#COCO test-dev#AP50#93.4$Keypoint Detection#COCO test-dev#AP75#83.8$Keypoint Detection#COCO test-dev#AR#81.6$Keypoint Detection#COCO test-dev#AR50#96.3$Keypoint Detection#COCO test-dev#AR75#88.1$Keypoint Detection#COCO test-dev#ARL#87.1$Keypoint Detection#COCO test-dev#ARM#77.5$Keypoint Detection#COCO test-dev#AP#76.1$Keypoint Detection#COCO test-challenge#AR#82.2$Keypoint Detection#COCO test-challenge#ARM#77.5$Keypoint Detection#COCO test-challenge#AP#76.4$Keypoint Detection#COCO test-challenge#AP50#92.9$Keypoint Detection#COCO test-challenge#AP75#82.6$Keypoint Detection#COCO test-challenge#APL#88.6$Keypoint Detection#COCO test-challenge#AR50#96$Keypoint Detection#COCO test-challenge#AR75#87.7$Keypoint Detection#COCO test-challenge#ARL#83.2
1603.06937v2.pdf	Pose Estimation#FLIC Elbows#PCK@0.2#99.0%$Pose Estimation#MPII Human Pose#PCKh-0.5#90.9$Pose Estimation#FLIC Wrists#PCK@0.2#97.0%
2108.08557v1.pdf	Pose Estimation#ITOP front-view#Mean mAP#88.75$Pose Estimation#ITOP top-view#Mean mAP#86.92
1603.07076v3.pdf	Pose Estimation#ITOP front-view#Mean mAP#77.4$Pose Estimation#ITOP top-view#Mean mAP#75.5
1902.07837v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#93.9
2003.04030v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#93.0$Pose Estimation#COCO test-dev#AP#79.2$Pose Estimation#COCO test-dev#AP50#94.4$Pose Estimation#COCO test-dev#AP75#87.1$Pose Estimation#COCO test-dev#APL#76.1$Pose Estimation#COCO test-dev#APM#83.8$Pose Estimation#COCO test-dev#AR#84.1$Pose Estimation#COCO test-dev#AP#78.6$Pose Estimation#COCO test-dev#AP50#94.3$Pose Estimation#COCO test-dev#AP75#86.6$Pose Estimation#COCO test-dev#APL#75.5$Pose Estimation#COCO test-dev#APM#83.3$Pose Estimation#COCO test-dev#AR#83.8$Pose Estimation#MPII Single Person#PCKh@0.5#93$Keypoint Detection#COCO#Test AP#78.6$Keypoint Detection#COCO test-challenge#AR#82.6$Keypoint Detection#COCO test-challenge#ARM#78.0$Keypoint Detection#COCO test-challenge#AP#77.1$Keypoint Detection#COCO test-challenge#AP50#93.3$Keypoint Detection#COCO test-challenge#AP75#83.6$Keypoint Detection#COCO test-challenge#APL#82.6$Keypoint Detection#COCO test-challenge#AR50#96.1$Keypoint Detection#COCO test-challenge#AR75#88.2$Keypoint Detection#COCO test-challenge#ARL#88.7$Multi-Person Pose Estimation#COCO#AP#0.792
1901.01760v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#92.5
1803.09894v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#92.1
1705.00389v2.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#91.9
1808.02194v2.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#91.2
2004.12186v2.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#91.2$Pose Estimation#MPII Human Pose#PCKh-0.5#88.8$Pose Estimation#MPII Human Pose#PCKh-0.5#84.8$Pose Estimation#MPII Single Person#PCKh@0.5#91.2$Pose Estimation#MPII Single Person#PCKh@0.1#36.0
1910.06278v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#90.6$Pose Estimation#COCO test-dev#AP#77.4$Pose Estimation#COCO test-dev#AP50#92.6$Pose Estimation#COCO test-dev#AP75#84.6$Pose Estimation#COCO test-dev#APL#83.7$Pose Estimation#COCO test-dev#APM#73.6$Pose Estimation#COCO test-dev#AR#82.3$Keypoint Detection#COCO#Test AP#76.2$Multi-Person Pose Estimation#COCO#AP#0.774
2103.15320v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#90.4$Pose Estimation#COCO test-dev#AP#72.2$Pose Estimation#COCO test-dev#AP50#90.9$Pose Estimation#COCO test-dev#AP75#80.1$Pose Estimation#COCO test-dev#APL#78.8$Pose Estimation#COCO test-dev#APM#69.1
1801.07372v2.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#89.5
1808.06521v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#89.4
2204.10762v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#87.6$Pose Estimation#COCO test-dev#AP#70.6$Pose Estimation#COCO test-dev#AP50#90.8$Pose Estimation#COCO test-dev#AP75#78.2$Pose Estimation#COCO test-dev#APL#76.1$Pose Estimation#COCO test-dev#APM#67.4$Pose Estimation#COCO test-dev#AR#76.4
1904.02698v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#87.5
1603.08212v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#85.0
1904.07852v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#82.5
1511.06645v2.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#82.40$Multi-Person Pose Estimation#WAF#AOP#86.5%
1507.05699v5.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#82.4$Pose Estimation#MPII Human Pose#PCKh-0.5#81.1
1411.4280v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#82.0
1507.06550v3.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#81.3
1904.05868v1.pdf	Pose Estimation#MPII Human Pose#PCKh-0.5#80.9
2002.00537v2.pdf	Pose Estimation#COCO test-dev#AP#78.9$Pose Estimation#COCO test-dev#AP50#93.8$Pose Estimation#COCO test-dev#AP75#86$Pose Estimation#COCO test-dev#APL#84.5$Pose Estimation#COCO test-dev#APM#75$Pose Estimation#COCO test-dev#AR#83.6
2011.08446v2.pdf	Pose Estimation#COCO test-dev#AP#76.8$Pose Estimation#COCO test-dev#AP50#92.5$Pose Estimation#COCO test-dev#AP75#84.3$Pose Estimation#COCO test-dev#APL#82.5$Pose Estimation#COCO test-dev#APM#73.5$Pose Estimation#COCO test-dev#AR#81.7$Keypoint Detection#COCO#Validation AP#77.5$Keypoint Detection#COCO#Test AP#76.8$Multi-Person Pose Estimation#COCO#Validation AP#77.5$Multi-Person Pose Estimation#COCO#Test AP#76.8
1911.07524v2.pdf	Pose Estimation#COCO test-dev#AP#76.5$Pose Estimation#COCO test-dev#AP50#92.7$Pose Estimation#COCO test-dev#AP75#84$Pose Estimation#COCO test-dev#APL#73.0$Pose Estimation#COCO test-dev#APM#82.4$Pose Estimation#COCO test-dev#AR#81.6
2206.07510v2.pdf	Pose Estimation#COCO test-dev#AP#75.7$Pose Estimation#COCO test-dev#AP50#90.3$Pose Estimation#COCO test-dev#AP75#76.3$Pose Estimation#COCO test-dev#APL#79.5$Pose Estimation#COCO test-dev#APM#80.7
1812.03595v3.pdf	Pose Estimation#COCO test-dev#AP#74.7$Pose Estimation#COCO test-dev#AP50#91.2$Pose Estimation#COCO test-dev#AP75#81.9$Pose Estimation#COCO test-dev#APL#81.2$Pose Estimation#COCO test-dev#APM#71.1$Pose Estimation#COCO test-dev#AR#79.9$Keypoint Detection#COCO#Validation AP#77.3$Keypoint Detection#COCO#Test AP#76.7$Multi-Person Pose Estimation#COCO#Validation AP#77.3$Multi-Person Pose Estimation#COCO#Test AP#76.7
2209.02431v1.pdf	Pose Estimation#COCO test-dev#AP#74.6$Pose Estimation#COCO test-dev#AP50#91.9$Pose Estimation#COCO test-dev#AP75#82.1$Pose Estimation#COCO test-dev#APL#80.6$Pose Estimation#COCO test-dev#APM#71.3$Pose Estimation#COCO test-dev#AR#79.9
2105.10154v1.pdf	Pose Estimation#COCO test-dev#AP#73.9$Pose Estimation#COCO test-dev#AP50#91.7$Pose Estimation#COCO test-dev#AP75#82$Pose Estimation#COCO test-dev#APL#79.5$Pose Estimation#COCO test-dev#APM#70.5$Pose Estimation#COCO test-dev#AR#80.4$Pose Estimation#COCO test-dev#AP#70.3$Pose Estimation#COCO test-dev#AP50#90.7$Pose Estimation#COCO test-dev#AP75#78.8$Pose Estimation#COCO test-dev#APL#75.5$Pose Estimation#COCO test-dev#APM#67.3$Pose Estimation#COCO test-dev#AR#77.3
1711.07319v2.pdf	Pose Estimation#COCO test-dev#AP#73.0$Pose Estimation#COCO test-dev#AP50#91.7$Pose Estimation#COCO test-dev#AP75#80.9$Pose Estimation#COCO test-dev#APL#78.1$Pose Estimation#COCO test-dev#AR#79.0$Pose Estimation#COCO test-dev#AP#72.1$Pose Estimation#COCO test-dev#AP50#91.4$Pose Estimation#COCO test-dev#AP75#80.0$Pose Estimation#COCO test-dev#APL#77.2$Pose Estimation#COCO test-dev#AR#78.5$Keypoint Detection#COCO#Test AP#73.0$Keypoint Detection#COCO test-dev#APL#78.1$Keypoint Detection#COCO test-dev#APM#69.5$Keypoint Detection#COCO test-dev#AP50#91.7$Keypoint Detection#COCO test-dev#AP75#80.9$Keypoint Detection#COCO test-dev#AR#79.0$Keypoint Detection#COCO test-dev#AR50#95.1$Keypoint Detection#COCO test-dev#AR75#85.9$Keypoint Detection#COCO test-dev#ARL#84.6$Keypoint Detection#COCO test-dev#ARM#74.8$Keypoint Detection#COCO test-dev#APL#77.2$Keypoint Detection#COCO test-dev#APM#68.7$Keypoint Detection#COCO test-dev#AP50#91.4$Keypoint Detection#COCO test-dev#AP75#80.0$Keypoint Detection#COCO test-dev#AR#78.5$Keypoint Detection#COCO test-dev#AR75#85.3$Keypoint Detection#COCO test-dev#ARL#84.3$Keypoint Detection#COCO test-dev#ARM#74.2$Keypoint Detection#COCO test-challenge#AR#78.7$Keypoint Detection#COCO test-challenge#ARM#74.3$Keypoint Detection#COCO test-challenge#AP#72.1$Keypoint Detection#COCO test-challenge#AP50#90.5$Keypoint Detection#COCO test-challenge#AP75#78.9$Keypoint Detection#COCO test-challenge#APL#84.7$Keypoint Detection#COCO test-challenge#AR50#94.7$Keypoint Detection#COCO test-challenge#AR75#84.8$Keypoint Detection#COCO test-challenge#ARL#78.1$Multi-Person Pose Estimation#COCO#AP#0.730
2104.06403v1.pdf	Pose Estimation#COCO test-dev#AP#69.7$Pose Estimation#COCO test-dev#AP50#90.7$Pose Estimation#COCO test-dev#AP75#77.5$Pose Estimation#COCO test-dev#APL#75.0$Pose Estimation#COCO test-dev#APM#66.9$Pose Estimation#COCO test-dev#AR#75.4$Pose Estimation#COCO test-dev#AP#66.9$Pose Estimation#COCO test-dev#AP50#89.4$Pose Estimation#COCO test-dev#AP75#74.4$Pose Estimation#COCO test-dev#APL#72.2$Pose Estimation#COCO test-dev#APM#64.0$Pose Estimation#COCO test-dev#AR#72.6
1911.10529v1.pdf	Pose Estimation#COCO test-dev#AP#68.1$Pose Estimation#COCO test-dev#APL#70.5$Pose Estimation#COCO test-dev#APM#66.8$Pose Estimation#COCO test-dev#AR#88.2$Keypoint Detection#COCO test-dev#APL#70.5$Keypoint Detection#COCO test-dev#APM#66.8$Keypoint Detection#COCO test-dev#AR#72.1$Keypoint Detection#COCO test-dev#AR50#88.2$Keypoint Detection#COCO test-dev#AP#68.1$Multi-Person Pose Estimation#COCO test-dev#AP#68.1$Multi-Person Pose Estimation#COCO test-dev#APL#70.5$Multi-Person Pose Estimation#COCO test-dev#APM#66.8$Multi-Person Pose Estimation#COCO test-dev#AR#72.1$Multi-Person Pose Estimation#COCO test-dev#AR50#88.2
1701.01779v2.pdf	Pose Estimation#COCO test-dev#AP#64.9$Pose Estimation#COCO test-dev#AP50#85.5$Pose Estimation#COCO test-dev#AP75#71.3$Pose Estimation#COCO test-dev#APL#70.0$Pose Estimation#COCO test-dev#AR#69.7$Keypoint Detection#COCO test-dev#APL#70.0$Keypoint Detection#COCO test-dev#APM#62.3$Keypoint Detection#COCO test-dev#AP50#85.5$Keypoint Detection#COCO test-dev#AP75#71.3$Keypoint Detection#COCO test-dev#AR#69.7$Keypoint Detection#COCO test-dev#AR50#88.7$Keypoint Detection#COCO test-dev#AR75#75.5$Keypoint Detection#COCO test-dev#ARL#77.1$Keypoint Detection#COCO test-dev#ARM#64.4$Keypoint Detection#COCO test-challenge#AR#75.1$Keypoint Detection#COCO test-challenge#ARM#69.7$Keypoint Detection#COCO test-challenge#AP#69.1$Keypoint Detection#COCO test-challenge#AP50#85.9$Keypoint Detection#COCO test-challenge#AP75#75.2$Keypoint Detection#COCO test-challenge#APL#82.4$Keypoint Detection#COCO test-challenge#AR50#90.7$Keypoint Detection#COCO test-challenge#AR75#80.7$Keypoint Detection#COCO test-challenge#ARL#74.5$Multi-Person Pose Estimation#COCO#AP#0.685$Multi-Person Pose Estimation#COCO#AP#0.649$Multi-Person Pose Estimation#COCO test-dev#AP#64.9$Multi-Person Pose Estimation#COCO test-dev#APL#70.0$Multi-Person Pose Estimation#COCO test-dev#APM#62.3$Multi-Person Pose Estimation#COCO test-dev#AP50#85.5$Multi-Person Pose Estimation#COCO test-dev#AP75#71.3
1812.08008v2.pdf	Pose Estimation#COCO test-dev#AP#64.2$Pose Estimation#COCO test-dev#AP50#86.2$Pose Estimation#COCO test-dev#AP75#70.1$Pose Estimation#COCO test-dev#APL#68.8$Pose Estimation#COCO test-dev#APM#61$Pose Estimation#MPII Single Person#PCKh@0.5#88.8$Pose Estimation#MPII Single Person#PCKh@0.1#22.5$Multi-Person Pose Estimation#CrowdPose#AP Easy#62.7$Multi-Person Pose Estimation#CrowdPose#AP Medium#58.7$Multi-Person Pose Estimation#CrowdPose#AP Hard#32.3
1911.07451v2.pdf	Pose Estimation#COCO test-dev#AP#63.3$Pose Estimation#COCO test-dev#AP50#86.7$Pose Estimation#COCO test-dev#AP75#69.4$Pose Estimation#COCO test-dev#APL#71.2$Pose Estimation#COCO test-dev#APM#57.8$Keypoint Detection#COCO test-dev#APL#71.5$Keypoint Detection#COCO test-dev#APM#60.4$Keypoint Detection#COCO test-dev#AP50#87.8$Keypoint Detection#COCO test-dev#AP75#71.1$Keypoint Detection#COCO test-dev#AP#64.8
1611.08050v2.pdf	Pose Estimation#COCO test-dev#AP#61.8$Pose Estimation#COCO test-dev#AP50#84.9$Pose Estimation#COCO test-dev#AP75#67.5$Pose Estimation#COCO test-dev#APL#68.2$Pose Estimation#COCO test-dev#APM#57.1$Pose Estimation#COCO test-dev#AR#66.5$Keypoint Detection#MPII Multi-Person#mAP@0.5#75.6%$Keypoint Detection#COCO#Validation AP#60.5$Keypoint Detection#COCO test-dev#APL#68.2$Keypoint Detection#COCO test-dev#APM#57.1$Keypoint Detection#COCO test-dev#AP50#84.9$Keypoint Detection#COCO test-dev#AP75#67.5$Keypoint Detection#COCO test-dev#AR#66.5$Keypoint Detection#COCO test-dev#AR50#87.2$Keypoint Detection#COCO test-dev#ARL#74.6$Keypoint Detection#COCO test-dev#ARM#60.6$Multi-Person Pose Estimation#COCO#AP#0.618$Multi-Person Pose Estimation#COCO test-dev#AP#61.8$Multi-Person Pose Estimation#COCO test-dev#APL#68.2$Multi-Person Pose Estimation#COCO test-dev#APM#57.1$Multi-Person Pose Estimation#COCO test-dev#AP50#84.9$Multi-Person Pose Estimation#COCO test-dev#AP75#67.5$Multi-Person Pose Estimation#MPII Multi-Person#AP#75.6%$2D Human Pose Estimation#COCO-WholeBody#WB#33.8$2D Human Pose Estimation#COCO-WholeBody#body#56.3$2D Human Pose Estimation#COCO-WholeBody#foot#53.2$2D Human Pose Estimation#COCO-WholeBody#face#48.2$2D Human Pose Estimation#COCO-WholeBody#hand#19.8
1804.07909v1.pdf	Pose Estimation#MPII Single Person#PCKh@0.5#92.1$Keypoint Detection#MPII Multi-Person#mAP@0.5#78%$Multi-Person Pose Estimation#PoseTrack2018#Mean mAP#73.8$Multi-Person Pose Estimation#MPII Multi-Person#AP#78%$Multi-Person Pose Estimation and Tracking#PoseTrack2018#MOTA#58.4
2206.10892v2.pdf	Pose Estimation#COCO#AP#77.3$Pose Estimation#COCO#AR#82.1$Pose Estimation#COCO#AP50#91$Pose Estimation#COCO#AP75#83.6$Pose Estimation#COCO#APM#73$Pose Estimation#COCO#APL#84.5$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#77.4$Multi-Person Pose Estimation#CrowdPose#AP Easy#83.8$Multi-Person Pose Estimation#CrowdPose#AP Medium#78.1$Multi-Person Pose Estimation#CrowdPose#AP Hard#69.3$Multi-Person Pose Estimation#OCHuman#Validation AP#67.8$Multi-Person Pose Estimation#OCHuman#AP50#85$Multi-Person Pose Estimation#OCHuman#AP75#72.8
2112.04981v1.pdf	Pose Estimation#COCO#AP#72.6$Pose Estimation#COCO#AR#79.4
1703.04670v1.pdf	Keypoint Detection#Pascal3D+#Mean PCK#82.5
1803.09331v2.pdf	Keypoint Detection#Pascal3D+#Mean PCK#78.6
1411.6067v2.pdf	Keypoint Detection#Pascal3D+#Mean PCK#68.8
1411.1091v1.pdf	Keypoint Detection#Pascal3D+#Mean PCK#48.5
1705.07422v2.pdf	Keypoint Detection#MPII Multi-Person#mAP@0.5#80.4%$Multi-Person Pose Estimation#WAF#AP#84.8$Multi-Person Pose Estimation#MPII Multi-Person#AP#80.4%
1908.09220v1.pdf	Keypoint Detection#MPII Multi-Person#mAP@0.5#78.5%$Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#63.7$Multi-Person Pose Estimation#CrowdPose#AP Easy#70.3$Multi-Person Pose Estimation#CrowdPose#AP Medium#64.5$Multi-Person Pose Estimation#CrowdPose#AP Hard#55.7$Multi-Person Pose Estimation#OCHuman#Validation AP#47.6$Multi-Person Pose Estimation#OCHuman#AP50#67.5$Multi-Person Pose Estimation#OCHuman#AP75#53.2$Multi-Person Pose Estimation#COCO test-dev#AP#66.9$Multi-Person Pose Estimation#COCO test-dev#APL#73.1$Multi-Person Pose Estimation#COCO test-dev#APM#62.6$Multi-Person Pose Estimation#COCO test-dev#AP50#88.5$Multi-Person Pose Estimation#COCO test-dev#AP75#72.9$Multi-Person Pose Estimation#MPII Multi-Person#AP#78.5%
1612.01465v3.pdf	Keypoint Detection#MPII Multi-Person#mAP@0.5#74.3%$Multi-Person Pose Estimation#MPII Multi-Person#AP#74.3%
1608.08526v2.pdf	Keypoint Detection#MPII Multi-Person#mAP@0.5#62.2%$Multi-Person Pose Estimation#MPII Multi-Person#AP#62.2%
2201.07412v2.pdf	Keypoint Detection#COCO#Validation AP#79.6$Keypoint Detection#COCO#Test AP#78.3
2205.05277v2.pdf	Keypoint Detection#COCO#Validation AP#76.4$Keypoint Detection#COCO#Test AP#75.7
1909.07068v4.pdf	Keypoint Detection#COCO#Test AP#70.9
1803.08225v1.pdf	Keypoint Detection#COCO#Test AP#66.5$Multi-Person Pose Estimation#COCO test-dev#AP#68.7$Multi-Person Pose Estimation#COCO test-dev#APL#75.5$Multi-Person Pose Estimation#COCO test-dev#APM#64.1$Multi-Person Pose Estimation#COCO test-dev#AP50#89.0$Multi-Person Pose Estimation#COCO test-dev#AP75#75.4
1807.04067v1.pdf	Keypoint Detection#COCO#Validation AP#69.6$Multi-Person Pose Estimation#COCO#AP#0.697
2103.02440v2.pdf	Keypoint Detection#COCO test-dev#APL#76.8$Keypoint Detection#COCO test-dev#APM#67.1$Keypoint Detection#COCO test-dev#AP#70.9$Multi-Person Pose Estimation#COCO#AP#0.709$Multi-Person Pose Estimation#COCO#Validation AP#71.0$Multi-Person Pose Estimation#COCO#Test AP#70.9
1903.06593v2.pdf	Keypoint Detection#COCO test-dev#APL#72.1$Keypoint Detection#COCO test-dev#APM#62.6$Keypoint Detection#COCO test-dev#AP#66.4
1712.09184v2.pdf	Keypoint Detection#COCO test-challenge#AR#70.2$Keypoint Detection#COCO test-challenge#ARM#60.7$Pose Tracking#PoseTrack2017#MOTA#51.82$Pose Tracking#PoseTrack2017#mAP#59.56
1802.00977v2.pdf	Keypoint Detection#COCO test-challenge#AR#67.5$Keypoint Detection#COCO test-challenge#ARM#62.5$Pose Tracking#PoseTrack2017#MOTA#50.98$Pose Tracking#PoseTrack2017#mAP#62.95
2006.10204v1.pdf	3D Pose Estimation#Google-AR#PCK@0.2#87.8$3D Pose Estimation#Google-AR#PCK@0.2#84.1$3D Pose Estimation#Google-AR#PCK@0.2#79.6$3D Pose Estimation#Google-Yoga#PCK@0.2#84.5$3D Pose Estimation#Google-Yoga#PCK@0.2#83.4$3D Pose Estimation#Google-Yoga#PCK@0.2#77.6
2009.00348v1.pdf	3D Pose Estimation#Human3.6M#Average MPJPE (mm)#44.8$3D Pose Estimation#Human3.6M#Average MPJPE (mm)#46$3D Pose Estimation#Human3.6M#Average MPJPE (mm)#48.6
2112.09598v1.pdf	6D Pose Estimation#3D-BSLS-6D#eRE#0.197$6D Pose Estimation#3D-BSLS-6D#eTE#3.469
2103.02242v1.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#96.6$6D Pose Estimation#LineMOD#Accuracy (ADD)#99.7
2203.05334v1.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#96.5
1911.04231v2.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#96.1$6D Pose Estimation#LineMOD#Accuracy (ADD)#99.4$6D Pose Estimation using RGBD#YCB-Video#Mean ADD-S#95.5$6D Pose Estimation using RGBD#LineMOD#Mean ADD#99.4
2007.13866v1.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#95.71
1911.07771v2.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#93.3$6D Pose Estimation#LineMOD#Accuracy (ADD)#97.8$6D Pose Estimation using RGBD#YCB-Video#Mean ADD#93.3$6D Pose Estimation using RGBD#YCB-Video#Mean ADD-S#93.3$6D Pose Estimation using RGBD#LineMOD#Mean ADD#97.8
1901.04780v1.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#93.1$6D Pose Estimation#LineMOD#Accuracy (ADD)#94.3$6D Pose Estimation using RGBD#LineMOD#Mean ADD#94.3
1711.00199v3.pdf	6D Pose Estimation#YCB-Video#ADDS AUC#93.0$6D Pose Estimation using RGB#YCB-Video#Accuracy (ADD)#21.3%$6D Pose Estimation using RGB#YCB-Video#Mean ADD#53.7$6D Pose Estimation using RGB#YCB-Video#Mean ADD-S#75.9$6D Pose Estimation using RGBD#YCB-Video#Mean ADD#79.3$6D Pose Estimation using RGBD#YCB-Video#Mean ADD-S#93
2203.07918v2.pdf	6D Pose Estimation#LineMOD#Mean ADD-S#98.2$6D Pose Estimation using RGBD#REAL275#mAP 10, 10cm#74.6$6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#73.3$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#84.2$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#83$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#42.9$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@75#64.4$6D Pose Estimation using RGBD#REAL275#mAP 5, 2cm#32$6D Pose Estimation using RGBD#REAL275#FPS#20
2112.10716v1.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#72.2$Multi-Person Pose Estimation#CrowdPose#AP Easy#79.9$Multi-Person Pose Estimation#CrowdPose#AP Medium#73.4$Multi-Person Pose Estimation#CrowdPose#AP Hard#61.3$Multi-Person Pose Estimation#COCO#AP#0.727$Multi-Person Pose Estimation#COCO#Validation AP#72.7$Multi-Person Pose Estimation#COCO#Test AP#71.2
2207.02425v1.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#71.5$Multi-Person Pose Estimation#CrowdPose#AP Medium#72.2$Multi-Person Pose Estimation#COCO test-dev#AP#79.2$Multi-Person Pose Estimation#COCO test-dev#APL#84.2$Multi-Person Pose Estimation#COCO test-dev#APM#74.1$Multi-Person Pose Estimation#COCO test-dev#AP50#93.5$Multi-Person Pose Estimation#COCO test-dev#AP75#85.8$Multi-Person Pose Estimation#COCO test-dev#AR#81.6
2011.14584v1.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#71.3$Multi-Person Pose Estimation#COCO test-dev#AP#71.6$Multi-Person Pose Estimation#COCO test-dev#APL#77.2$Multi-Person Pose Estimation#COCO test-dev#APM#67.5$Multi-Person Pose Estimation#COCO test-dev#AP50#90.3$Multi-Person Pose Estimation#COCO test-dev#AP75#78.2$Multi-Person Pose Estimation#COCO test-dev#AR#76.0$Multi-Person Pose Estimation#COCO test-dev#AR50#92.3
2110.05132v1.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#69.4$Multi-Person Pose Estimation#CrowdPose#AP Easy#76.6$Multi-Person Pose Estimation#CrowdPose#AP Medium#70.0$Multi-Person Pose Estimation#CrowdPose#AP Hard#61.5$Multi-Person Pose Estimation#COCO#AP#0.714$Multi-Person Pose Estimation#COCO#Test AP#71.4
1812.00324v2.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#66.0$Multi-Person Pose Estimation#CrowdPose#AP Easy#75.5$Multi-Person Pose Estimation#CrowdPose#AP Medium#66.3$Multi-Person Pose Estimation#CrowdPose#AP Hard#57.4$Multi-Person Pose Estimation#CrowdPose#FPS#10.1$Multi-Person Pose Estimation#OCHuman#Validation AP#27.5$Multi-Person Pose Estimation#OCHuman#AP50#40.8$Multi-Person Pose Estimation#OCHuman#AP75#29.9
1907.06922v1.pdf	Multi-Person Pose Estimation#CrowdPose#mAP @0.5:0.95#65.5$Multi-Person Pose Estimation#CrowdPose#AP Easy#75.2$Multi-Person Pose Estimation#CrowdPose#AP Medium#66.6$Multi-Person Pose Estimation#CrowdPose#AP Hard#53.1
2103.07254v3.pdf	Multi-Person Pose Estimation#PoseTrack2018#Mean mAP#79$Multi-Person Pose Estimation#PoseTrack2017#Mean mAP#79.2
1906.04016v3.pdf	Multi-Person Pose Estimation#PoseTrack2018#Mean mAP#78$Multi-Person Pose Estimation#PoseTrack2017#Mean mAP#77.94
1710.10000v2.pdf	Multi-Person Pose Estimation#PoseTrack2017#Mean mAP#59.4$Pose Tracking#PoseTrack2017#MOTA#48.37$Pose Tracking#PoseTrack2017#mAP#59.22
2111.12892v1.pdf	Multi-Person Pose Estimation#COCO#AP#0.665$Multi-Person Pose Estimation#COCO test-dev#AP#66.5
2008.07139v2.pdf	Multi-Person Pose Estimation#COCO test-dev#AP#78.7$Multi-Person Pose Estimation#COCO test-dev#AP#76.2$Multi-Person Pose Estimation#COCO test-dev#AP#73.7$Multi-Person Pose Estimation#COCO minival#AP#79.1$Multi-Person Pose Estimation#COCO minival#AP#77.8$Multi-Person Pose Estimation#COCO minival#AP#75.3
2006.15576v2.pdf	Multi-Person Pose Estimation#COCO test-dev#AP#70.2$Multi-Person Pose Estimation#COCO test-dev#APL#77.2$Multi-Person Pose Estimation#COCO test-dev#APM#65.9$Multi-Person Pose Estimation#COCO test-dev#AP50#89.7$Multi-Person Pose Estimation#COCO test-dev#AP75#77.5
1611.07727v3.pdf	Multi-Person Pose Estimation#Multi-Person PoseTrack#Mean mAP#38.2$Pose Tracking#Multi-Person PoseTrack#MOTA#28.2$Pose Tracking#Multi-Person PoseTrack#MOTP#55.7
2107.08982v3.pdf	Multi-Person Pose Estimation#COCO minival#AP#63.1
2108.11801v4.pdf	Semi-Supervised Human Pose Estimation#COCO 1% labeled data#Person Keypoint AP#38.22$Semi-Supervised Person Instance Segmentation#COCO 1% labeled data#Person Mask AP#36.06
2203.12870v3.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#97.37%$6D Pose Estimation using RGB#LineMOD#Mean ADD#97.37$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#60.65
2011.04307v2.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#97.35%$6D Pose Estimation using RGB#LineMOD#Mean ADD#97.35
2104.00633v2.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#96.1%$6D Pose Estimation using RGB#LineMOD#Mean ADD#96.1$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#51.6
2203.13254v4.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#95.8$3D Object Detection#nuScenes#NDS#0.453$3D Object Detection#nuScenes#mAP#0.373$3D Object Detection#nuScenes#mATE#0.605$3D Object Detection#nuScenes#mASE#0.243$3D Object Detection#nuScenes#mAOE#0.359$3D Object Detection#nuScenes#mAVE#1.067$3D Object Detection#nuScenes#mAAE#0.124
2110.11636v1.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#95.61%$6D Pose Estimation using RGB#LineMOD#Mean ADD#95.61$6D Pose Estimation using RGB#YCB-Video#Mean AUC#79.88$6D Pose Estimation using RGB#YCB-Video#Mean ADD#66.59$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#45.95
1902.11020v3.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#95.15%$6D Pose Estimation using RGB#LineMOD#Mean ADD#95.2$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#47.25
1909.06043v3.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#93.3$6D Pose Estimation using RGB#LineMOD#Accuracy#99.21%$6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#93.27%
2001.01869v4.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#94.5%$6D Pose Estimation using RGB#LineMOD#Mean ADD#91.3$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#47.5
1804.00175v4.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#97.5$6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#88.1%$6D Pose Estimation using RGB#LineMOD#Mean ADD#88.6$6D Pose Estimation using RGB#YCB-Video#Mean ADD#70.1%$6D Pose Estimation using RGB#YCB-Video#Mean ADI#84.2$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#55.5$6D Pose Estimation using RGBD#YCB-Video#Mean ADD#80.6$6D Pose Estimation using RGBD#YCB-Video#Mean ADI#92.4
2011.11078v1.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#86.8$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#47.4
1812.11788v1.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#99%$6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#86.27%$6D Pose Estimation using RGB#LineMOD#Mean ADD#86.27$6D Pose Estimation using RGB#YCB-Video#Mean AUC#73.4%$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#40.77
1909.13476v1.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#97.7%$6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#78.3%$6D Pose Estimation using RGB#LineMOD#Mean ADD#78.3$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#24.48
1711.10006v1.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#76.3$6D Pose Estimation using RGB#LineMOD#Mean IoU#99.4$6D Pose Estimation using RGB#OCCLUSION#MAP#0.38$6D Pose Estimation using RGBD#LineMOD#Mean ADD#90.9$6D Pose Estimation using RGBD#LineMOD#Mean IoU#96.5$6D Pose Estimation using RGBD#Tejani#IoU-2D#0.988$6D Pose Estimation using RGBD#Tejani#IoU-3D#0.963$6D Pose Estimation using RGBD#Tejani#VSS-2D#0.724$6D Pose Estimation using RGBD#Tejani#VSS-3D#0.854
1812.01387v1.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#94.5%$6D Pose Estimation using RGB#LineMOD#Mean ADD#72.6
1711.08848v5.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#90.37%$6D Pose Estimation using RGB#LineMOD#Mean ADD#55.95$6D Pose Estimation using RGB#LineMOD#Mean IoU#99.92$6D Pose Estimation using RGB#OCCLUSION#MAP#0.48
1703.10896v2.pdf	6D Pose Estimation using RGB#LineMOD#Accuracy#83.9%$6D Pose Estimation using RGB#LineMOD#Accuracy (ADD)#43.6%$6D Pose Estimation using RGB#LineMOD#Mean ADD#43.6
1908.07433v1.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#32$6D Pose Estimation using RGB#T-LESS#Recall (VSD)#29.5
1902.01275v2.pdf	6D Pose Estimation using RGB#LineMOD#Mean ADD#28.7$6D Pose Estimation using RGB#T-LESS#Mean Recall#36.8$6D Pose Estimation using RGBD#LineMOD#Mean ADD#64.67$6D Pose Estimation using RGBD#T-LESS#Mean Recall#72.76
1812.02541v3.pdf	6D Pose Estimation using RGB#YCB-Video#Accuracy (ADD)#39.0%$6D Pose Estimation using RGB#YCB-Video#Mean ADD#39$6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#27
2108.08367v1.pdf	6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#62.3
2102.12145v3.pdf	6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#56.1
2005.06262v2.pdf	6D Pose Estimation using RGB#Occlusion LineMOD#Mean ADD#55.33
2202.12555v1.pdf	Head Pose Estimation#BIWI#MAE (trained with BIWI data)#2.66$Head Pose Estimation#BIWI#MAE (trained with other data)#3.47$Head Pose Estimation#AFLW2000#MAE#3.97
2005.10353v2.pdf	Head Pose Estimation#BIWI#MAE (trained with other data)#3.48$Head Pose Estimation#BIWI#MAE (trained with other data)#3.81$Head Pose Estimation#AFLW2000#MAE#4.83$Head Pose Estimation#AFLW2000#MAE#5.42
1702.05085v1.pdf	Head Pose Estimation#BIWI#MAE (trained with other data)#13.852
1901.06778v2.pdf	Head Pose Estimation#BIWI#MAE (trained with BIWI data)#3.0174$Head Pose Estimation#AFLW#MAE#5.09$Head Pose Estimation#AFLW2000#MAE#5.395
1710.00925v5.pdf	Head Pose Estimation#BIWI#MAE (trained with BIWI data)#4.895$Head Pose Estimation#AFLW#MAE#5.324$Head Pose Estimation#AFLW2000#MAE#6.155
1812.00739v1.pdf	Head Pose Estimation#AFLW#MAE#4.06$Head Pose Estimation#AFLW#MAE#5.14
2104.02527v4.pdf	6D Pose Estimation using RGBD#YCB-Video#ADD(S) AUC#96.6$6D Pose Estimation using RGBD#YCB-Video#ADDS AUC#96.6$6D Pose Estimation using RGBD#YCB-Video#ADD(S) AUC#95.9$6D Pose Estimation using RGBD#YCB-Video#ADDS AUC#97.2$6D Pose Estimation using RGBD#LineMOD#Mean ADD#99.7$6D Pose Estimation using RGBD#LineMOD#Mean ADD#99.4$6D Pose Estimation using RGBD#OccludedLINEMOD#Mean ADD#71.1$6D Pose Estimation using RGBD#OccludedLINEMOD#Mean ADD#70.2
1912.11888v2.pdf	6D Pose Estimation using RGBD#LineMOD#Mean ADD-S#98.2
2203.01929v1.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 10cm#70.9$6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#64.3$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#83.5$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#80.2$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#29.1$6D Pose Estimation using RGBD#CAMERA25#mAP 10, 10cm#87.9$6D Pose Estimation using RGBD#CAMERA25#mAP 10, 5cm#81.3$6D Pose Estimation using RGBD#CAMERA25#mAP 3DIou@25#93.2$6D Pose Estimation using RGBD#CAMERA25#mAP 3DIou@50#92.5$6D Pose Estimation using RGBD#CAMERA25#mAP 5, 5cm#66.2
2103.07054v2.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 10cm#64.6$6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#60.8$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#95.1$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#92.2$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#28.2$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@75#63.5$6D Pose Estimation using RGBD#REAL275#FPS#20
1901.02970v2.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 10cm#26.7$6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#26.7$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#84.9$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#80.5$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#9.5$6D Pose Estimation using RGBD#CAMERA25#mAP 10, 10cm#62.2$6D Pose Estimation using RGBD#CAMERA25#mAP 10, 5cm#61.7$6D Pose Estimation using RGBD#CAMERA25#mAP 3DIou@25#91.4$6D Pose Estimation using RGBD#CAMERA25#mAP 3DIou@50#85.3$6D Pose Estimation using RGBD#CAMERA25#mAP 5, 5cm#38.8
2103.06526v3.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#66.8$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#79.8$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#35.9$6D Pose Estimation using RGBD#REAL275#mAP 10, 2cm#50$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@75#62.2$6D Pose Estimation using RGBD#REAL275#mAP 5, 2cm#29.3
2111.12580v2.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#66.0$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#82.6$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#34.8$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@75#62.5$6D Pose Estimation using RGBD#REAL275#mAP 5, 2cm#30.4$6D Pose Estimation using RGBD#REAL275#mAP 10, 2cm#56.9
2203.03089v2.pdf	6D Pose Estimation using RGBD#REAL275#mAP 10, 5cm#44.9$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#78.2$6D Pose Estimation using RGBD#REAL275#mAP 3DIou@50#26.4$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#16.9$6D Pose Estimation using RGBD#REAL275#mAP 15, 5cm#50.8
2108.00516v1.pdf	6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#99.9$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#87.4$6D Pose Estimation using RGBD#REAL275#Rerr#2.4$6D Pose Estimation using RGBD#REAL275#Terr#2.1
1910.10750v1.pdf	6D Pose Estimation using RGBD#REAL275#mAP 3DIou@25#94.2$6D Pose Estimation using RGBD#REAL275#mAP 5, 5cm#33.3$6D Pose Estimation using RGBD#REAL275#Rerr#16.0$6D Pose Estimation using RGBD#REAL275#Terr#3.5
2011.08464v5.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#80.96$Vehicle Pose Estimation#KITTI#Average Orientation Similarity#89.43
1703.07570v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#80.39
1604.04693v3.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#78.68$Object Detection#PASCAL VOC 2007#MAP#68.5%
2001.03398v3.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#78.27$3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#52.18$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#15.55$3D Object Detection From Stereo Images#KITTI Cyclists Moderate#AP50#18.17
2001.03343v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#77.18
1904.12681v2.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#76.85
1612.00496v2.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#76.76
2003.00504v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#76.45$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#9.99
1904.01690v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#72.26
2004.03572v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#67.16$3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#45.78$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#25.80$3D Object Detection From Stereo Images#KITTI Cyclists Moderate#AP50#24.40
1907.06038v2.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#67.08$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#9.71
2008.13748v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#66.90
1912.04799v2.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#63.98$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#11.72
1903.10955v2.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#61.85$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#2.9
2007.09548v1.pdf	Vehicle Pose Estimation#KITTI Cars Hard#Average Orientation Similarity#34.81$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.72
2108.00249v1.pdf	Animal Pose Estimation#StanfordExtra#PCK@0.1#78.65$Animal Pose Estimation#StanfordExtra#PCK@0.1#77.19$Animal Pose Estimation#StanfordExtra#PCK@0.1#50.77
1909.11229v2.pdf	Animal Pose Estimation#Horse-10#PCK@0.3#88.4$Animal Pose Estimation#Horse-10#PCK@0.3#84.3$Animal Pose Estimation#Horse-10#PCK@0.3#77.6
2110.04573v1.pdf	Human Pose Forecasting#AMASS#Average MPJPE (mm) 1000 msec#45.5$Human Pose Forecasting#3DPW#Average MPJPE (mm) 1000 msec#42.3$Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#0.55$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#0.87$Human Pose Forecasting#Human3.6M#Average MPJPE (mm) 1000 msec#75.6
1908.05436v3.pdf	Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#0.56$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#0.67
2207.00499v1.pdf	Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#0.58$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#0.73$Human Pose Forecasting#Human3.6M#Average MPJPE (mm) 1000 msec#71.6
1909.03449v1.pdf	Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#0.59$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#0.69
1810.09676v1.pdf	Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#0.65$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#0.77
1508.00271v2.pdf	Human Pose Forecasting#Human3.6M#MAR, walking, 400ms#1.78$Human Pose Forecasting#Human3.6M#MAR, walking, 1,000ms#2.38
2110.00988v1.pdf	Car Pose Estimation#ApolloCar3D#Detection Rate#91.9$2D Human Pose Estimation#COCO-WholeBody#WB#60.4$2D Human Pose Estimation#COCO-WholeBody#body#69.6$2D Human Pose Estimation#COCO-WholeBody#foot#63.4$2D Human Pose Estimation#COCO-WholeBody#face#85.0$2D Human Pose Estimation#COCO-WholeBody#hand#52.9
2010.13714v1.pdf	Activeness Detection#COCO test-dev#Accuracy (%)#76.67
2011.13205v1.pdf	Intent Classification#SLURP#Accuracy (%)#78.33$Slot Filling#SLURP#F1#0.642
2205.00926v2.pdf	Intent Classification#ORCAS-I#Precision#0.789$Intent Classification#ORCAS-I#Recall#0.764$Intent Classification#ORCAS-I#F1-score#0.774
2204.08582v2.pdf	Intent Classification#MASSIVE#Intent Accuracy#86.1$Intent Classification#MASSIVE#Intent Accuracy#85.3$Intent Classification#MASSIVE#Intent Accuracy#85.1$Slot Filling#MASSIVE#Slot F1 Score#83.6$Slot Filling#MASSIVE#Slot F1 Score#82.2$Slot Filling#MASSIVE#Slot F1 Score#81.3$Zero-shot Slot Filling#MASSIVE#Slot F1 Score#64.2$Zero-shot Slot Filling#MASSIVE#Slot F1 Score#56.9$Zero-shot Slot Filling#MASSIVE#Slot F1 Score#50.6
1908.10063v1.pdf	Sentiment Analysis#FiQA#MSE#0.07$Sentiment Analysis#FiQA#R^2#0.55$Sentiment Analysis#Financial PhraseBank#Accuracy#86$Sentiment Analysis#Financial PhraseBank#F1 score#84
1808.07931v1.pdf	Sentiment Analysis#FiQA#MSE#0.08$Sentiment Analysis#FiQA#R^2#0.40
2001.06286v2.pdf	Sentiment Analysis#DBRD#Accuracy#95.144%$Sentiment Analysis#DBRD#F1#95.144%$Sentiment Analysis#DBRD#Accuracy#94.422%$Sentiment Analysis#DBRD#F1#94.422%
1912.09582v1.pdf	Sentiment Analysis#DBRD#Accuracy#93%
1902.09314v2.pdf	Sentiment Analysis#Twitter#Accuracy#74.71$Sentiment Analysis#Twitter#Accuracy#73.55$Sentiment Analysis#Twitter#Accuracy#72.83$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#84.46$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#78.99$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#81.73$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#83.12$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#79.93$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#81.53$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#80.98$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#73.51$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#77.25
1904.12848v6.pdf	Sentiment Analysis#Amazon Review Polarity#Accuracy#97.37$Sentiment Analysis#Amazon Review Polarity#Accuracy#96.5$Sentiment Analysis#Yelp Fine-grained classification#Error#29.32$Sentiment Analysis#Yelp Fine-grained classification#Error#32.08$Sentiment Analysis#Amazon Review Full#Accuracy#65.83$Sentiment Analysis#Amazon Review Full#Accuracy#62.88$Sentiment Analysis#IMDb#Accuracy#95.8$Sentiment Analysis#IMDb#Accuracy#95.49$Sentiment Analysis#Yelp Binary classification#Error#1.89$Sentiment Analysis#Yelp Binary classification#Error#2.05$Text Classification#Amazon-5#Error#37.12$Text Classification#Yelp-5#Accuracy#67.92%$Text Classification#Yelp-2#Accuracy#97.95%$Text Classification#DBpedia#Error#0.68$Text Classification#DBpedia#Error#1.09$Text Classification#Amazon-2#Error#3.5$Text Classification#IMDb#Accuracy (2 classes)#95.8$Text Classification#IMDb#Accuracy (10 classes)#-$Image Classification#ImageNet#Top 1 Accuracy#79.04%$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#97.54$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#5.27$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#88.52%
1811.09386v1.pdf	Sentiment Analysis#Amazon Review Polarity#Accuracy#95.5$Sentiment Analysis#Amazon Review Full#Accuracy#61.9$Text Classification#DBpedia#Error#1$Text Classification#AG News#Error#7$Text Classification#Yahoo! Answers#Accuracy#74.8
1807.02291v1.pdf	Sentiment Analysis#Amazon Review Polarity#Accuracy#95.26$Sentiment Analysis#Amazon Review Full#Accuracy#61.65$Sentiment Analysis#Yelp Binary classification#Error#3.96
1810.09177v5.pdf	Sentiment Analysis#Amazon Review Polarity#Accuracy#94.96$Sentiment Analysis#Yelp Fine-grained classification#Error#34.15$Sentiment Analysis#Amazon Review Full#Accuracy#60.95$Sentiment Analysis#Yelp Binary classification#Error#3.52$Text Classification#Sogou News#Accuracy#97.25$Text Classification#DBpedia#Error#1.28$Text Classification#AG News#Error#7.61$Text Classification#Yahoo! Answers#Accuracy#73.85
1808.09644v1.pdf	Sentiment Analysis#Amazon Review Polarity#Accuracy#88.1$Sentiment Analysis#Amazon Review Full#Accuracy#49.7$Text Classification#DBpedia#Error#1.2$Text Classification#AG News#Error#7.9
1704.06125v1.pdf	Sentiment Analysis#SemEval#F1-score#0.685$Sentiment Analysis#SemEval 2017 Task 4-A#Average Recall#0.685
2201.08702v1.pdf	Sentiment Analysis#CR#Accuracy#94.39$Sentiment Analysis#SST-2 Binary classification#Accuracy#94.91$Subjectivity Analysis#SUBJ#Accuracy#97.34$Text Classification#TREC-6#Error#2.60
1805.05388v1.pdf	Sentiment Analysis#CR#Accuracy#90.6$Sentiment Analysis#MPQA#Accuracy#88.8$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.7$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#54.6$Sentiment Analysis#MR#Accuracy#86.8$Subjectivity Analysis#SUBJ#Accuracy#94.7$Text Classification#TREC-6#Error#9.6$Text Classification#IMDb#Accuracy (2 classes)#92.2$Text Classification#IMDb#Accuracy (10 classes)#-
1805.07340v2.pdf	Sentiment Analysis#CR#Accuracy#86.5$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.2$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#56.2$Sentiment Analysis#MR#Accuracy#81.6
1804.00538v4.pdf	Sentiment Analysis#CR#Accuracy#85.1$Sentiment Analysis#SST-2 Binary classification#Accuracy#86.8$Sentiment Analysis#MR#Accuracy#82.3$Subjectivity Analysis#SUBJ#Accuracy#93.8$Text Classification#TREC-6#Error#7.2$Text Classification#AG News#Error#7.4
1906.00095v1.pdf	Sentiment Analysis#CR#Accuracy#82.73$Sentiment Analysis#MPQA#Accuracy#89.83$Sentiment Analysis#SST-2 Binary classification#Accuracy#86.95$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#49.14$Sentiment Analysis#MR#Accuracy#80.09$Subjectivity Analysis#SUBJ#Accuracy#92.34$Text Classification#TREC-6#Error#7.04
1908.09590v1.pdf	Sentiment Analysis#User and product information#IMDB (Acc)#56.4$Sentiment Analysis#User and product information#Yelp 2013 (Acc)#67.8$Sentiment Analysis#User and product information#Yelp 2014 (Acc)#69.2
1801.07861v1.pdf	Sentiment Analysis#User and product information#IMDB (Acc)#55.0$Sentiment Analysis#User and product information#Yelp 2013 (Acc)#68.3$Sentiment Analysis#User and product information#Yelp 2014 (Acc)#68.6
1806.05507v1.pdf	Sentiment Analysis#User and product information#IMDB (Acc)#54.2$Sentiment Analysis#User and product information#Yelp 2013 (Acc)#65.7
1809.05807v1.pdf	Sentiment Analysis#User and product information#IMDB (Acc)#53.9$Sentiment Analysis#User and product information#Yelp 2013 (Acc)#66.2$Sentiment Analysis#User and product information#Yelp 2014 (Acc)#67.6
1902.05196v1.pdf	Sentiment Analysis#User and product information#Yelp 2013 (Acc)#67.1
2003.00104v4.pdf	Sentiment Analysis#AJGT#Accuracy#93.8$Sentiment Analysis#HARD#Accuracy#96.1$Sentiment Analysis#LABR (2-class, unbalanced)#Accuracy#86.7
2104.07078v1.pdf	Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#89.78$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#90.63$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#92.78$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#93.77$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#91.74
1810.09311v1.pdf	Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#81.00$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#81.4$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#85,06$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#85.9$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#83.30
1804.09530v1.pdf	Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#78.14$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#74.86$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#81.45$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#82.14$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#79.15
1511.00830v6.pdf	Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#76.57$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#73.40$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#80.53$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#82.93$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#78.36
1702.08400v3.pdf	Sentiment Analysis#Multi-Domain Sentiment Dataset#DVD#76.17$Sentiment Analysis#Multi-Domain Sentiment Dataset#Books#72.97$Sentiment Analysis#Multi-Domain Sentiment Dataset#Electronics#80.47$Sentiment Analysis#Multi-Domain Sentiment Dataset#Kitchen#83.97$Sentiment Analysis#Multi-Domain Sentiment Dataset#Average#78.39
2009.10557v2.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#70.71$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#70.71
1906.03820v1.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#68.06$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#68.06$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Laptop#F1#68.06$Aspect Term Extraction and Sentiment Classification#SemEval#Avg F1#65.74$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2014 (F1)#73.68$Aspect Term Extraction and Sentiment Classification#SemEval#Laptop 2014 (F1)#61.25$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2015 (F1)#62.29
1910.00883v2.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#61.12$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#61.12$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Laptop#F1#61.12
1906.01794v1.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#60.35$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#60.35$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Laptop#F1#60.35
1906.06906v1.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#58.37$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#83.89$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#75.36$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#79.63$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#58.37$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Laptop#F1#58.37$Aspect Term Extraction and Sentiment Classification#SemEval#Avg F1#64.23$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2014 (F1)#70.72$Aspect Term Extraction and Sentiment Classification#SemEval#Laptop 2014 (F1)#61.73$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2015 (F1)#60.22
1811.05082v2.pdf	Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#57.9$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 1+2#F1#57.9$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Laptop#F1#57.9
2007.05194v2.pdf	Sentiment Analysis#Latvian Twitter Eater Sentiment Dataset#Accuracy#61.23
2104.12250v2.pdf	Sentiment Analysis#TweetEval#Emoji#31.4$Sentiment Analysis#TweetEval#Emotion#79.5$Sentiment Analysis#TweetEval#Hate#52.3$Sentiment Analysis#TweetEval#Irony#61.7$Sentiment Analysis#TweetEval#Offensive#80.5$Sentiment Analysis#TweetEval#Sentiment#72.6$Sentiment Analysis#TweetEval#Stance#69.3$Sentiment Analysis#TweetEval#ALL#65.2
2010.12421v2.pdf	Sentiment Analysis#TweetEval#Emoji#30.9$Sentiment Analysis#TweetEval#Emotion#76.1$Sentiment Analysis#TweetEval#Hate#46.6$Sentiment Analysis#TweetEval#Irony#59.7$Sentiment Analysis#TweetEval#Offensive#79.5$Sentiment Analysis#TweetEval#Sentiment#71.3$Sentiment Analysis#TweetEval#Stance#68$Sentiment Analysis#TweetEval#ALL#61.3$Sentiment Analysis#TweetEval#Emoji#29.3$Sentiment Analysis#TweetEval#Emotion#72.0$Sentiment Analysis#TweetEval#Hate#49.9$Sentiment Analysis#TweetEval#Irony#65.4$Sentiment Analysis#TweetEval#Offensive#77.1$Sentiment Analysis#TweetEval#Sentiment#69.1$Sentiment Analysis#TweetEval#Stance#66.7$Sentiment Analysis#TweetEval#ALL#61.0$Sentiment Analysis#TweetEval#Emotion#64.7$Sentiment Analysis#TweetEval#Hate#36.7$Sentiment Analysis#TweetEval#Irony#61.7$Sentiment Analysis#TweetEval#Offensive#52.3$Sentiment Analysis#TweetEval#Sentiment#62.9$Sentiment Analysis#TweetEval#Stance#67.3$Sentiment Analysis#TweetEval#ALL#53.5$Sentiment Analysis#TweetEval#Emoji#25.8$Sentiment Analysis#TweetEval#Emotion#65.2$Sentiment Analysis#TweetEval#Hate#50.6$Sentiment Analysis#TweetEval#Irony#63.1$Sentiment Analysis#TweetEval#Offensive#73.4$Sentiment Analysis#TweetEval#Stance#65.4$Sentiment Analysis#TweetEval#ALL#58.1$Sentiment Analysis#TweetEval#Emoji#24.7$Sentiment Analysis#TweetEval#Emotion#66.0$Sentiment Analysis#TweetEval#Hate#52.6$Sentiment Analysis#TweetEval#Irony#62.8$Sentiment Analysis#TweetEval#Offensive#71.7$Sentiment Analysis#TweetEval#Sentiment#58.3$Sentiment Analysis#TweetEval#Stance#59.4$Sentiment Analysis#TweetEval#ALL#56.5
1911.00792v6.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#95.6$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#58.5$Image Classification#smallNORB#Classification Error#0.90
1903.07785v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#94.6$Named Entity Recognition#CoNLL 2003 (English)#F1#93.5$Constituency Parsing#Penn Treebank#F1 score#95.6
1910.03474v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#93.1$Sentiment Analysis#SST-2 Binary classification#Accuracy#91.2$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#55.5$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#53.2
1704.01444v2.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#91.8$Subjectivity Analysis#SUBJ#Accuracy#94.60
1707.01780v3.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#91.2$Sentiment Analysis#IMDb#Accuracy#88.9$Text Classification#Ohsumed#Accuracy#36.2
1812.01207v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#90.9$Emotion Classification#SemEval 2018 Task 1E-c#Macro-F1#0.561
1903.12136v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#90.7
1808.09315v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#90.0$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#53.4
1611.06639v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#89.5$Text Classification#TREC-6#Error#3.9
1603.06318v6.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#89.3$Named Entity Recognition#CoNLL 2003 (English)#F1#91.18
1506.07285v5.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#88.6
1511.08630v2.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#87.8$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#49.2$Text Classification#TREC-6#Error#5.4
1908.06267v2.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#87.75$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#49.68$Text Classification#TREC-6#Error#6.2$Text Classification#IMDb#Accuracy (2 classes)#91.84$Text Classification#IMDb#Accuracy (10 classes)#-$Document Classification#Reuters-21578#Accuracy#97.44$Document Classification#BBCSport#Accuracy#99.59$Document Classification#MPQA#Accuracy#89.81
1806.01501v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#87.6$Sentiment Analysis#SST-2 Binary classification#Accuracy#87.2$Sentiment Analysis#IMDb#Accuracy#45.1$Sentiment Analysis#IMDb#Accuracy#44.5
1809.04505v1.pdf	Sentiment Analysis#SST-2 Binary classification#Accuracy#82.3$Sentiment Analysis#SST-2 Binary classification#Accuracy#81.2$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#43.6$Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#41.6
1807.04990v1.pdf	Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#51.4$Sentiment Analysis#MR#Accuracy#84.5
1812.01527v2.pdf	Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#50.4
1702.01417v2.pdf	Sentiment Analysis#SST-5 Fine-grained classification#Accuracy#45.02$Sentiment Analysis#MR#Accuracy#78.26$Subjectivity Analysis#SUBJ#Accuracy#91.85$Text Classification#TREC-6#Error#7
1905.05583v3.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#28.62$Sentiment Analysis#Yelp Fine-grained classification#Error#29.42$Sentiment Analysis#IMDb#Accuracy#95.79$Sentiment Analysis#IMDb#Accuracy#95.63$Sentiment Analysis#Yelp Binary classification#Error#1.81$Sentiment Analysis#Yelp Binary classification#Error#1.92$Text Classification#TREC-6#Error#3.2$Text Classification#Yelp-5#Accuracy#70.58%$Text Classification#Yelp-2#Accuracy#98.08%$Text Classification#Sogou News#Accuracy#98.07$Text Classification#DBpedia#Error#0.68$Text Classification#AG News#Error#4.8$Text Classification#Yahoo! Answers#Accuracy#77.62$Text Classification#IMDb#Accuracy (2 classes)#95.63$Text Classification#IMDb#Accuracy (10 classes)#-
1801.06146v5.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#29.98$Sentiment Analysis#IMDb#Accuracy#95.4$Sentiment Analysis#Yelp Binary classification#Error#2.16$Text Classification#TREC-6#Error#3.6$Text Classification#DBpedia#Error#0.80$Text Classification#AG News#Error#5.01
1602.02373v2.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#32.39$Sentiment Analysis#IMDb#Accuracy#94.1$Sentiment Analysis#Yelp Binary classification#Error#2.9$Text Classification#DBpedia#Error#0.84$Text Classification#AG News#Error#6.57$Text Classification#RCV1#Accuracy#92.85
1901.01347v2.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#34.40$Sentiment Analysis#Yelp Binary classification#Error#3.60$Text Classification#AG News#Error#6.10$Text Classification#Yahoo! Answers#Accuracy#74.30$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.1%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#96.3%
1805.04174v1.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#35.91$Sentiment Analysis#Yelp Binary classification#Error#4.69$Text Classification#DBpedia#Error#0.98$Text Classification#AG News#Error#7.55
1509.01626v3.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#37.95$Sentiment Analysis#Yelp Binary classification#Error#4.88$Text Classification#DBpedia#Error#1.55$Text Classification#AG News#Error#9.51
1901.09821v1.pdf	Sentiment Analysis#Yelp Fine-grained classification#Error#46.80$Sentiment Analysis#Yelp Binary classification#Error#4.74$Text Classification#AG News#Error#9.45
1906.08101v3.pdf	Sentiment Analysis#ChnSentiCorp#F1#95.8$Sentiment Analysis#ChnSentiCorp Dev#F1#95.8
1902.08850v3.pdf	Sentiment Analysis#MR#Accuracy#93.3$Subjectivity Analysis#SUBJ#Accuracy#95.0$Multi-Label Text Classification#Reuters-21578#Micro-F1#89.3$Text Classification#TREC-6#Error#5.8$Text Classification#MR#Accuracy#93.3$Document Classification#Reuters-21578#F1#89.3
2104.06901v2.pdf	Sentiment Analysis#MR#Accuracy#77.51$Text Classification#TREC-6#Error#9.96$Text Classification#R52#Accuracy#89.14$Text Classification#R8#Accuracy#97.50
1809.05679v3.pdf	Sentiment Analysis#MR#Accuracy#76.74$Text Classification#20NEWS#Accuracy#86.34$Text Classification#R52#Accuracy#93.56$Text Classification#R8#Accuracy#97.07$Text Classification#Ohsumed#Accuracy#68.36
1708.05891v1.pdf	Sentiment Analysis#DynaSent#10 fold Cross validation#1
2205.13357v1.pdf	Sentiment Analysis#IMDb#Accuracy#95.94$Sentiment Analysis#IMDb#Accuracy#95.92$Sentiment Analysis#IMDb#Accuracy#95.79$Sentiment Analysis#IMDb#Accuracy#93.68
2009.04007v1.pdf	Sentiment Analysis#IMDb#Accuracy#95.68$Text Classification#DBpedia#Error#0.7$Text Classification#AG News#Error#4.95
1705.10301v4.pdf	Sentiment Analysis#IMDb#Accuracy#94.52
1605.07725v4.pdf	Sentiment Analysis#IMDb#Accuracy#94.1
2102.11417v2.pdf	Sentiment Analysis#IMDb#Accuracy#93.20$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.49%
1412.1058v2.pdf	Sentiment Analysis#IMDb#Accuracy#92.33
1811.03873v1.pdf	Sentiment Analysis#IMDb#Accuracy#90.1$Named Entity Recognition#CoNLL 2003 (English)#F1#91.56
2106.13898v2.pdf	Sentiment Analysis#IMDb#Accuracy#88.4
2010.00951v2.pdf	Sentiment Analysis#IMDb#Accuracy#87.4%$Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#59.0$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.4%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#97.34%
2106.12479v4.pdf	Sentiment Analysis#IMDb#Accuracy#87$Sentiment Analysis#IMDb#Accuracy#86$Sentiment Analysis#IMDb#Accuracy#85
2003.11593v2.pdf	Sentiment Analysis#Yelp Binary classification#Error#1.86$Text Classification#Amazon-2#Error#5.7
1709.08294v3.pdf	Sentiment Analysis#Yelp Binary classification#Error#3.89$Text Classification#DBpedia#Error#1.07
2110.08604v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#91.07$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#86.21$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#88.64
1912.07976v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#90.18$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#82.29$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#86.24
2203.07090v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#89.54$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#81.96$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#85.75
2104.04986v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#87.37$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#83.78$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#85.58
2108.02352v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#87.35$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#81.87$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#84.61
1908.11860v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#87.89$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#80.23$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#84.06
2002.09685v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#86.59$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#81.25$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#83.92$Aspect-Based Sentiment Analysis#MAMS#Acc#84.52$Aspect-Based Sentiment Analysis#MAMS#Macro-F1#83.74
2010.11731v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#86.37$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#79.55$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#82.96$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop (F1)#86.09$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Mean F1 (Laptop + Restaurant)#84.215$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant (F1)#82.34
2001.11316v4.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#86.03$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#79.35$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#82.69$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop (F1)#85.57$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Mean F1 (Laptop + Restaurant)#83.54$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant (F1)#81.50
1906.04501v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#83.57$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#81.35$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#82.46
1904.02232v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#84.95$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#78.07$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#81.51$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 1#Laptop (F1)#84.26$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 1#Restaurant (F1)#77.97
2010.02696v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#82.86$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#77.64$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#80.25
1906.01213v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#81.53$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#77.62$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#79.58
1811.10999v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#81.49$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#76.21$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#78.85
1805.01086v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#80.79$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#76.01$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#78.4
1802.00892v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#81.34$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#75.24$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#78.29
1810.10437v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#81.10$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#75.34$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#78.22
1804.06536v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#81.20$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#74.5$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#77.85
1605.08900v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#80.95$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#72.21$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#76.58
1709.00893v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#78.60$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#72.10$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#75.35
1806.04346v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#79.11$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#71.15$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#75.13
1909.06276v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#79.20$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#70.06$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#74.63
1805.07043v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#77.28$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#69.14$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#73.21
1512.01100v2.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#75.63$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Laptop (Acc)#68.13$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Mean Acc (Restaurant + Laptop)#71.88
2011.11673v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 2#Restaurant (Acc)#86.20$Aspect-Based Sentiment Analysis#SemEval-2016 Task 5 Subtask 1#Restaurant (Acc)#88.70
2204.12784v1.pdf	Aspect-Based Sentiment Analysis#Rest16#Acc#93.02$Aspect-Based Sentiment Analysis#Rest16#Acc#89.84$Aspect-Based Sentiment Analysis#Lap14#Acc#81.49$Aspect-Based Sentiment Analysis#Lap14#Acc#78.64$Aspect-Based Sentiment Analysis#Rest14#Acc#87.41$Aspect-Based Sentiment Analysis#Rest14#Acc#84.09$Aspect-Based Sentiment Analysis#Rest15#Acc#85.61$Aspect-Based Sentiment Analysis#Rest15#Acc#82.66
1603.06679v3.pdf	Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 1#Laptop (F1)#78.42$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Sub Task 1#Restaurant (F1)#69.74
1903.09588v1.pdf	Aspect-Based Sentiment Analysis#Sentihood#Aspect#87.9$Aspect-Based Sentiment Analysis#Sentihood#Sentiment#93.3$Aspect-Based Sentiment Analysis#Sentihood#Aspect#86.4$Aspect-Based Sentiment Analysis#Sentihood#Sentiment#93.6$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 4#Accuracy (3-way)#89.9$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 4#Accuracy (4-way)#85.9$Aspect-Based Sentiment Analysis#SemEval 2014 Task 4 Subtask 4#Binary Accuracy#95.6$Aspect Category Detection#SemEval 2014 Task 4 Subtask 3#F1 score#92.18$Aspect Category Detection#SemEval 2014 Task 4 Subtask 3#Precision#93.57$Aspect Category Detection#SemEval 2014 Task 4 Subtask 3#Recall#90.83
1804.11019v1.pdf	Aspect-Based Sentiment Analysis#Sentihood#Aspect#78.5$Aspect-Based Sentiment Analysis#Sentihood#Sentiment#91.0
1610.03771v1.pdf	Aspect-Based Sentiment Analysis#Sentihood#Aspect#69.3$Aspect-Based Sentiment Analysis#Sentihood#Sentiment#81.9
2004.08673v1.pdf	Aspect-Based Sentiment Analysis#SemEval 2015 Task 12#Restaurant (Acc)#81.7$Aspect-Based Sentiment Analysis#SemEval-2016 Task 5 Subtask 1#Restaurant (Acc)#87.0
2012.14541v2.pdf	Aspect Extraction#YASO - YELP#F1#23
2004.03846v3.pdf	Aspect Extraction#SemEval-2016 Task 5 Subtask 1#F1#72.8$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Russian)#F1#71.8$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Dutch)#F1#72.9$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Spanish)#F1#74.3$Aspect Extraction#SemEval-2016 Task 5 Subtask 1 (Turkish)#F1#59.3
1805.04601v1.pdf	Aspect Extraction#SemEval 2015 Task 12#Restaurant (F1)#68.28$Aspect Extraction#SemEval 2014 Task 4 Sub Task 1#Laptop (F1)#81.59$Aspect Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant (F1)#85.20$Aspect Extraction#SemEval 2016 Task 5 Sub Task 1 Slot 2#Restaurant (F1)#74.37
2106.04300v1.pdf	Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2014 (F1)#85.38$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop 2014 (F1)#80.55$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2015 (F1)#80.52$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2016 (F1)#87.92$Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#67.62$Aspect Sentiment Triplet Extraction#SemEval#F1#72.46$Aspect Term Extraction and Sentiment Classification#SemEval#Avg F1#69.18$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2014 (F1)#73.56$Aspect Term Extraction and Sentiment Classification#SemEval#Laptop 2014 (F1)#67.37$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2015 (F1)#66.61
2101.00816v2.pdf	Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2014 (F1)#83.73$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop 2014 (F1)#79.90$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2015 (F1)#74.50$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2016 (F1)#83.33$Aspect Sentiment Triplet Extraction#SemEval#F1#70.32$Aspect Term Extraction and Sentiment Classification#SemEval#Avg F1#68.99$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2014 (F1)#75.95$Aspect Term Extraction and Sentiment Classification#SemEval#Laptop 2014 (F1)#65.94$Aspect Term Extraction and Sentiment Classification#SemEval#Restaurant 2015 (F1)#65.08
2010.13378v1.pdf	Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2014 (F1)#82.33$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop 2014 (F1)#75.77$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2015 (F1)#78.81$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2016 (F1)#86.01
2001.01989v1.pdf	Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2014 (F1)#82.21$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Laptop 2014 (F1)#72.02$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2015 (F1)#73.29$Aspect-oriented  Opinion Extraction#SemEval 2014 Task 4 Sub Task 2#Restaurant 2016 (F1)#83.62
2103.15255v5.pdf	Aspect-Sentiment-Opinion Triplet Extraction#Res14#F1 score#69.2
2010.04640v2.pdf	Aspect-Sentiment-Opinion Triplet Extraction#Res14#Precision#67.3$Aspect Sentiment Triplet Extraction#Res14#F1#70.20$Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#68.17
2102.08092v1.pdf	Multimodal Sentiment Analysis#B-T4SA#Accuracy#95.19$Multimodal Sentiment Analysis#B-T4SA#Accuracy#95.16
2201.09828v1.pdf	Multimodal Sentiment Analysis#CMU-MOSEI#Accuracy#82.4$Multimodal Sentiment Analysis#CMU-MOSEI#MAE#0.7
2006.15955v1.pdf	Multimodal Sentiment Analysis#CMU-MOSEI#Accuracy#82.40
2002.08267v3.pdf	Multimodal Sentiment Analysis#CMU-MOSEI#Accuracy#82.10$Multimodal Sentiment Analysis#CMU-MOSEI#MAE#0.59
2003.01043v1.pdf	Multimodal Sentiment Analysis#CMU-MOSEI#Accuracy#81.14$Multimodal Sentiment Analysis#MOSI#Accuracy#83.91%$Multimodal Sentiment Analysis#MOSI#F1 score#81.17
2110.03007v2.pdf	Multimodal Sentiment Analysis#CMU-MOSEI#Accuracy#78
1906.00295v1.pdf	Multimodal Sentiment Analysis#MOSI#Accuracy#83%$Multimodal Sentiment Analysis#MOSI#F1 score#82.8
1802.00923v1.pdf	Multimodal Sentiment Analysis#MOSI#Accuracy#77.1%
2109.05522v1.pdf	Multimodal Sentiment Analysis#CMU-MOSI#F1#85$Multimodal Sentiment Analysis#CMU-MOSI#MAE#0.64$Multimodal Sentiment Analysis#CMU-MOSI#Corr#0.836$Multimodal Sentiment Analysis#CMU-MOSI#Acc-7#47.52$Multimodal Sentiment Analysis#CMU-MOSI#Acc-2#87.5
2109.00412v2.pdf	Multimodal Sentiment Analysis#CMU-MOSI#F1#84$Multimodal Sentiment Analysis#CMU-MOSI#MAE#0.7$Multimodal Sentiment Analysis#CMU-MOSI#Corr#0.8$Multimodal Sentiment Analysis#CMU-MOSI#Acc-7#46.65$Multimodal Sentiment Analysis#CMU-MOSI#Acc-2#84.14$Multimodal Sentiment Analysis#CMU-MOSI#F1#82.68$Multimodal Sentiment Analysis#CMU-MOSI#MAE#0.712$Multimodal Sentiment Analysis#CMU-MOSI#Corr#0.795$Multimodal Sentiment Analysis#CMU-MOSI#Acc-7#45.79$Multimodal Sentiment Analysis#CMU-MOSI#Acc-2#82.54$Multimodal Sentiment Analysis#CMU-MOSI#F1#82.5$Multimodal Sentiment Analysis#CMU-MOSI#MAE#0.727$Multimodal Sentiment Analysis#CMU-MOSI#Corr#0.781$Multimodal Sentiment Analysis#CMU-MOSI#Acc-7#43.62$Multimodal Sentiment Analysis#CMU-MOSI#Acc-2#82.37
2009.02902v2.pdf	Multimodal Sentiment Analysis#CMU-MOSI#F1-score (Weighted)#82.71
2107.12214v1.pdf	Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#71.85
2108.06107v1.pdf	Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#69.61
2102.08549v3.pdf	Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#68.16
2010.02609v3.pdf	Aspect Sentiment Triplet Extraction#ASTE-Data-V2#F1#63.83$Aspect Sentiment Triplet Extraction#SemEval#F1#62.40
1911.01616v4.pdf	Aspect Sentiment Triplet Extraction#SemEval#F1#50.90
2104.10513v1.pdf	Tweet-Reply Sentiment Analysis#RETWEET#Average F1#73.2$Tweet-Reply Sentiment Analysis#RETWEET#Average F1#71.9
1711.00768v3.pdf	Fine-Grained Opinion Analysis#MPQA#Holder Binary F1#83.80$Fine-Grained Opinion Analysis#MPQA#Target Binary F1#72.06
2111.09296v3.pdf	Language Identification#VoxLingua107#Error rate#5.7$Language Identification#VoxLingua107#Error rate#7.2
2012.06431v1.pdf	Language Identification#nordic_langid#Accuracy#0.9711
2102.06282v1.pdf	Language Identification#Universal Dependencies#Accuracy#86.93$Language Identification#OpenSubtitles#Accuracy#91.37
2109.02363v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.900$Entity Alignment#dbp15k fr-en#Hits@1#0.988$Entity Alignment#dbp15k ja-en#Hits@1#0.956
2108.05278v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.883$Entity Alignment#dbp15k fr-en#Hits@1#0.958$Entity Alignment#dbp15k ja-en#Hits@1#0.908
2103.15452v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.861$Entity Alignment#dbp15k fr-en#Hits@1#0.954$Entity Alignment#dbp15k ja-en#Hits@1#0.892
2008.07962v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.822$Entity Alignment#DBP15k zh-en#Hits@1#0.801
2001.09621v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.8012$Entity Alignment#DBP15k zh-en#Hits@1#0.7075$Entity Alignment#DBP15k zh-en#Hits@1#0.6793$Entity Alignment#DBP15k zh-en#Hits@1#0.6501$Entity Alignment#DBP15k zh-en#Hits@1#0.6294$Entity Alignment#DBP15k zh-en#Hits@1#0.494$Entity Alignment#DBP15k zh-en#Hits@1#0.4125
2009.13603v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.761$Entity Alignment#dbp15k fr-en#Hits@1#0.793$Entity Alignment#dbp15k ja-en#Hits@1#0.762
1909.09317v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.7203$Entity Alignment#DBP15k zh-en#Hits@1#0.6294$Entity Alignment#DBP15k zh-en#Hits@1#0.4125$Entity Alignment#DBP15k zh-en#Hits@1#0.3083
2005.00171v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.719
1908.08210v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.7075
2010.16314v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.6954$Entity Alignment#DBP15k zh-en#Hits@1#0.594$Entity Alignment#dbp15k fr-en#Hits@1#0.8370$Entity Alignment#dbp15k ja-en#Hits@1#0.6564
2010.02162v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.572
1911.08936v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.539
1908.09898v1.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.494$Entity Alignment#DBP15k zh-en#Hits@1#0.472$Entity Alignment#DBP15k zh-en#Hits@1#0.412
1911.08342v2.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.433
1611.03954v3.pdf	Entity Alignment#DBP15k zh-en#Hits@1#0.308
2106.02248v1.pdf	Entity Alignment#DBP2.0 zh-en#dangling entity detection F1#0.767$Entity Alignment#DBP2.0 zh-en#Entity Alignment (Consolidated) F1#0.335$Entity Alignment#DBP2.0 zh-en#dangling entity detection F1#0.643$Entity Alignment#DBP2.0 zh-en#Entity Alignment (Consolidated) F1#0.238
2109.07449v1.pdf	Entity Linking#GUM#F1#26.4
2109.01242v2.pdf	Entity Linking#ZESHEL#Unnormalized Accuracy#50.4$Entity Linking#ZESHEL#Recall@64#85.11$Entity Linking#MedMentions#Accuracy#72.3$Entity Linking#MedMentions#Recall@64#95.62
2204.03905v2.pdf	Entity Linking#MedMentions#Accuracy#71.78$Nested Named Entity Recognition#GENIA#F1#79.93
2010.00904v3.pdf	Entity Linking#KILT: AIDA-YAGO2#KILT-AC#89.85$Entity Linking#KILT: AIDA-YAGO2#R-Prec#89.85$Entity Linking#KILT: AIDA-YAGO2#Recall@5#94.76$Entity Linking#KILT: AIDA-YAGO2#Accuracy#89.85$Entity Linking#AIDA-CoNLL#Micro-F1 strong#83.7$Entity Linking#MSNBC#Micro-F1#73.7$Entity Linking#KILT: WNED-WIKI#KILT-AC#87.44$Entity Linking#KILT: WNED-WIKI#R-Prec#87.44$Entity Linking#KILT: WNED-WIKI#Recall@5#94.91$Entity Linking#KILT: WNED-WIKI#Accuracy#87.44$Entity Linking#Derczynski#Micro-F1#54.1$Entity Linking#KILT: WNED-CWEB#KILT-AC#71.22$Entity Linking#KILT: WNED-CWEB#R-Prec#71.22$Entity Linking#KILT: WNED-CWEB#Recall@5#79.22$Entity Linking#KILT: WNED-CWEB#Accuracy#71.22$Entity Disambiguation#ACE2004#Micro-F1#90.1$Entity Disambiguation#MSNBC#Micro-F1#94.3$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#93.3$Entity Disambiguation#AQUAINT#Micro-F1#89.9$Entity Disambiguation#WNED-CWEB#Micro-F1#77.3$Entity Disambiguation#WNED-WIKI#Micro-F1#87.4
2110.02369v2.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#85.8
2109.03792v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#85.5
2207.04108v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#84.0$Entity Linking#MSNBC#Micro-F1#71.8$Entity Linking#MSNBC#Micro-F1 strong#71.8$Entity Linking#OKE-2015#Micro-F1#65.0$Entity Linking#OKE-2015#Micro-F1 strong#64.4$Entity Linking#KORE50#Micro-F1 strong#64.7$Entity Linking#KORE50#Micro-F1#65.9$Entity Linking#OKE-2016#Micro-F1#59.5$Entity Linking#OKE-2016#Micro-F1 strong#59.1$Entity Linking#Derczynski#Micro-F1#50.7$Entity Linking#Derczynski#Micro-F1 strong#50.7$Entity Linking#N3-Reuters-128#Micro-F1#58.1$Entity Linking#N3-Reuters-128#Micro-F1 strong#58.1$Entity Linking#WebQSP-WD#F1#89.1$Entity Typing#AIDA-CoNLL#Micro-F1#84.0$Entity Disambiguation#ACE2004#Micro-F1#91.6$Entity Disambiguation#MSNBC#Micro-F1#94.4$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#93.9$Entity Disambiguation#AQUAINT#Micro-F1#91.8$Entity Disambiguation#WNED-CWEB#Micro-F1#79.4$Entity Disambiguation#WNED-WIKI#Micro-F1#88.7
2101.09969v2.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#83.1$Entity Linking#MSNBC#Micro-F1#83.4
1808.07699v2.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#82.4$Entity Linking#MSNBC#Micro-F1#72.4$Entity Linking#OKE-2015#Micro-F1#66.9$Entity Linking#OKE-2016#Micro-F1#58.4$Entity Linking#Derczynski#Micro-F1#34.1$Entity Linking#N3-Reuters-128#Micro-F1#54.6
1907.08243v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#81.9$Named Entity Recognition#CoNLL 2003 (English)#F1#92.43
2006.01969v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#80.5$Entity Linking#MSNBC#Micro-F1#72.4$Entity Linking#Derczynski#Micro-F1#41.1
2003.05473v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#79.3
2005.14253v1.pdf	Entity Linking#AIDA-CoNLL#Micro-F1 strong#76.7
2110.09915v1.pdf	Entity Linking#FUNSD#F1#65.96
2205.05656v3.pdf	Entity Linking#Rare Diseases Mentions in MIMIC-III Radiology Reports (Text-to-UMLS)#F1#0.907$Entity Linking#Rare Diseases Mentions in MIMIC-III (Text-to-UMLS)#F1#0.861$Entity Linking#Rare Diseases Mentions in MIMIC-III#F1#0.711
2105.01995v3.pdf	Entity Linking#Rare Diseases Mentions in MIMIC-III (Text-to-UMLS)#F1#0.858$Entity Linking#Rare Diseases Mentions in MIMIC-III#F1#0.702
2001.03765v1.pdf	Entity Linking#CoNLL-Aida#Accuracy#94.9$Entity Linking#TAC-KBP 2010#Accuracy#89.8
1802.01021v1.pdf	Entity Linking#CoNLL-Aida#Accuracy#94.9$Entity Linking#TAC-KBP 2010#Accuracy#90.9$Entity Disambiguation#TAC2010#Micro Precision#90.85$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#94.88
1804.08460v1.pdf	Entity Linking#WebQSP-WD#F1#0.73
2011.06315v1.pdf	Named Entity Recognition#LINNAEUS#F1#86.26$Named Entity Recognition#Species800#F1#80.91$Named Entity Recognition#BC5CDR#F1#89.73$Named Entity Recognition#BC2GM#F1#88.75$Named Entity Recognition#Species-800#F1#82.59$Named Entity Recognition#AnatEM#F1#89.13$Named Entity Recognition#BC4CHEMD#F1#93.72$Named Entity Recognition#BC5CDR-chemical#F1#94.88$Named Entity Recognition#BioNLP13-CG#F1#85.58$Named Entity Recognition#NCBI-disease#F1#90.48$Named Entity Recognition#NCBI-disease#F1#89.13$Named Entity Recognition#JNLPBA#F1#81.29
1908.05760v1.pdf	Named Entity Recognition#LINNAEUS#F1#87.02$Named Entity Recognition#BC5CDR#F1#89.42$Named Entity Recognition#Species-800#F1#82.44$Named Entity Recognition#NCBI-disease#F1#88.85$Named Entity Recognition#JNLPBA#F1#77.03
2104.04052v1.pdf	Named Entity Recognition#NEMO-Corpus (token,test)#F1#84.91$Named Entity Recognition#NEMO-Corpus (morph,test)#F1#80.15$Named Entity Recognition#NEMO-Corpus (morph,test)#F1#79.15
2007.15620v2.pdf	Named Entity Recognition#NEMO-Corpus (token,test)#F1#77.75$Named Entity Recognition#NEMO-Corpus (morph,test)#F1#77.11
2203.10545v1.pdf	Named Entity Recognition#ACE 2004#F1#88.14$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#Ontonotes v5 (English)#F1#90.96$Named Entity Recognition#Few-NERD (SUP)#Precision#70.16$Named Entity Recognition#Few-NERD (SUP)#Recall#69.18$Named Entity Recognition#Few-NERD (SUP)#F1-Measure#69.67$Named Entity Recognition#Few-NERD (SUP)#Precision#67.37$Named Entity Recognition#Few-NERD (SUP)#Recall#69.12$Named Entity Recognition#Few-NERD (SUP)#F1-Measure#68.23$Named Entity Recognition#Few-NERD (SUP)#Precision#64.69$Named Entity Recognition#Few-NERD (SUP)#Recall#70.87$Named Entity Recognition#Few-NERD (SUP)#F1-Measure#67.64$Named Entity Recognition#CoNLL 2003 (English)#F1#92.87$Named Entity Recognition#ACE 2005#F1#87.42$Nested Named Entity Recognition#ACE 2004#F1#88.14$Nested Named Entity Recognition#TAC-KBP 2017#F1#84.5$Nested Named Entity Recognition#GENIA#F1#81.77$Nested Named Entity Recognition#ACE 2005#F1#87.42$Nested Named Entity Recognition#NNE#Micro F1#94.04$Chinese Named Entity Recognition#MSRA#F1#93.48
2204.12031v1.pdf	Named Entity Recognition#ACE 2004#F1#87.98$Named Entity Recognition#Ontonotes v5 (English)#F1#91.74$Named Entity Recognition#CoNLL 2003 (English)#F1#93.65$Named Entity Recognition#ACE 2005#F1#87.15$Chinese Named Entity Recognition#Resume NER#F1#96.66$Chinese Named Entity Recognition#MSRA#F1#96.26$Chinese Named Entity Recognition#OntoNotes 4#F1#82.83$Chinese Named Entity Recognition#Weibo NER#F1#72.66
2005.07150v3.pdf	Named Entity Recognition#ACE 2004#F1#86.7$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#CoNLL 2002 (Dutch)#F1#93.7$Named Entity Recognition#Ontonotes v5 (English)#F1#91.3$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#90.3$Named Entity Recognition#CoNLL 2003 (German) Revised#F1#90.3$Named Entity Recognition#CoNLL 2003 (German)#F1#86.4$Named Entity Recognition#CoNLL 2003 (English)#F1#93.5$Named Entity Recognition#ACE 2005#F1#85.4$Named Entity Recognition#GENIA#F1#80.5
2107.09429v1.pdf	Named Entity Recognition#ACE 2004#F1#86.41$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#ACE 2005#F1#85.46$Nested Named Entity Recognition#ACE 2004#F1#86.41$Nested Named Entity Recognition#ACE 2005#F1#85.46$Nested Named Entity Recognition#NNE#Micro F1#94.24$Nested Mention Recognition#ACE 2005#F1#85.46$Nested Mention Recognition#ACE 2004#F1#86.41
1909.02250v3.pdf	Named Entity Recognition#ACE 2004#F1#85.82$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#ACE 2005#F1#84.34$Named Entity Recognition#GENIA#F1#77.36$Named Entity Recognition#GENIA#F1#77.19$Nested Named Entity Recognition#ACE 2004#F1#85.82$Nested Named Entity Recognition#ACE 2004#F1#84.97$Nested Named Entity Recognition#ACE 2004#F1#77.44$Nested Named Entity Recognition#GENIA#F1#77.36$Nested Named Entity Recognition#GENIA#F1#77.19$Nested Named Entity Recognition#GENIA#F1#77.05$Nested Named Entity Recognition#ACE 2005#F1#84.34$Nested Named Entity Recognition#ACE 2005#F1#83.99$Nested Named Entity Recognition#ACE 2005#F1#76.83$Nested Named Entity Recognition#NNE#Micro F1#93.19$Nested Mention Recognition#ACE 2005#F1#84.34$Nested Mention Recognition#ACE 2004#F1#85.82
1908.06926v1.pdf	Named Entity Recognition#ACE 2004#F1#84.40$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#CoNLL 2002 (Dutch)#F1#92.7$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#88.8$Named Entity Recognition#CoNLL 2003 (German)#F1#85.1$Named Entity Recognition#CoNLL 2003 (English)#F1#93.38$Named Entity Recognition#ACE 2005#F1#84.33$Named Entity Recognition#GENIA#F1#78.31$Nested Named Entity Recognition#ACE 2004#F1#84.40$Nested Named Entity Recognition#GENIA#F1#78.31$Nested Named Entity Recognition#ACE 2005#F1#84.33$Nested Mention Recognition#ACE 2005#F1#84.33$Nested Mention Recognition#ACE 2004#F1#84.40
1906.08449v1.pdf	Named Entity Recognition#ACE 2004#F1#79.5$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#CoNLL 2003 (English)#F1#92.28$Named Entity Recognition#ACE 2005#F1#78.2$Nested Named Entity Recognition#ACE 2004#F1#79.5$Nested Named Entity Recognition#ACE 2005#F1#78.2$Nested Mention Recognition#ACE 2005#F1#78.2$Nested Mention Recognition#ACE 2004#F1#79.5
1810.01817v1.pdf	Named Entity Recognition#ACE 2004#F1#75.1$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#ACE 2005#F1#74.5$Named Entity Recognition#GENIA#F1#75.1$Nested Named Entity Recognition#ACE 2004#F1#75.1$Nested Named Entity Recognition#GENIA#F1#75.1$Nested Named Entity Recognition#ACE 2005#F1#74.5$Nested Named Entity Recognition#NNE#Micro F1#91.4$Nested Mention Recognition#ACE 2005#F1#74.5$Nested Mention Recognition#ACE 2004#F1#75.1
1810.01808v1.pdf	Named Entity Recognition#ACE 2004#F1#73.3$Named Entity Recognition#ACE 2004#Multi-Task Supervision#n$Named Entity Recognition#ACE 2005#F1#73.0$Named Entity Recognition#GENIA#F1#73.9$Nested Named Entity Recognition#ACE 2004#F1#73.3$Nested Named Entity Recognition#GENIA#F1#73.9$Nested Named Entity Recognition#ACE 2005#F1#73.0$Nested Named Entity Recognition#NNE#Micro F1#73.6$Nested Mention Recognition#ACE 2005#F1#73.0$Nested Mention Recognition#ACE 2004#F1#73.1
2011.06993v2.pdf	Named Entity Recognition#CoNLL 2002 (Dutch)#F1#95.21$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#90.14$Named Entity Recognition#CoNLL 2003 (German) Revised#F1#92.23$Named Entity Recognition#CoNLL 2003 (German)#F1#88.34$Named Entity Recognition#CoNLL 2003 (English)#F1#94.09$Named Entity Recognition#FindVehicle#F1 Score#80.9
2006.01563v2.pdf	Named Entity Recognition#CoNLL 2002 (Dutch)#F1#93.49$Named Entity Recognition#CoNLL 2002 (Spanish)#F1#88.32$Named Entity Recognition#CoNLL 2003 (German)#F1#87.31$Named Entity Recognition#CoNLL 2003 (English)#F1#93.74
2205.07177v1.pdf	Named Entity Recognition#OntoNotes 5.0#Average F1#90.92$Named Entity Recognition#Ontonotes v5 (English)#F1#90.92$Named Entity Recognition#BC2GM#F1#85.65$Named Entity Recognition#BC5CDR-chemical#F1#94.59$Named Entity Recognition#BC5CDR-disease#F1#87.86$Named Entity Recognition#WNUT 2017#F1#57.41$Named Entity Recognition#WNUT 2016#F1#59.50
1910.11476v6.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#91.11$Named Entity Recognition#CoNLL 2003 (English)#F1#93.04$Named Entity Recognition#ACE 2005#F1#86.88$Chinese Named Entity Recognition#MSRA#F1#95.75$Chinese Named Entity Recognition#OntoNotes 4#F1#82.11$Nested Mention Recognition#ACE 2004#F1#85.98
2104.05316v1.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#90.85$Named Entity Recognition#Ontonotes v5 (English)#F1#89.04
2112.10070v1.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#90.50$Named Entity Recognition#CoNLL 2003 (English)#F1#93.07$Nested Named Entity Recognition#ACE 2004#F1#87.52$Nested Named Entity Recognition#GENIA#F1#81.39$Nested Named Entity Recognition#ACE 2005#F1#86.79$Chinese Named Entity Recognition#MSRA#F1#96.10$Chinese Named Entity Recognition#OntoNotes 4#F1#83.08
2106.01223v1.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#90.38$Named Entity Recognition#CoNLL 2003 (English)#F1#93.24$Nested Named Entity Recognition#ACE 2004#F1#86.84$Nested Named Entity Recognition#GENIA#F1#79.23$Nested Named Entity Recognition#ACE 2005#F1#84.74
1911.02257v2.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#90.30$Named Entity Recognition#Ontonotes v5 (English)#F1#87.98$Named Entity Recognition#CoNLL 2003 (English)#F1#93.37$Named Entity Recognition#CoNLL 2003 (English)#F1#91.96
1909.10148v1.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#89.88$Named Entity Recognition#Ontonotes v5 (English)#F1#88.52$Named Entity Recognition#CoNLL 2003 (English)#F1#92.4$Chinese Named Entity Recognition#OntoNotes 5.0#F1#79.92
1908.11046v3.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#88.4$Named Entity Recognition#Ontonotes v5 (English)#Precision#88.71$Named Entity Recognition#Ontonotes v5 (English)#Recall#88.11$Named Entity Recognition#WNUT 2017#F1#42.85$Named Entity Recognition#WNUT 2017#Precision#58.28$Named Entity Recognition#WNUT 2017#Recall#33.92
1806.03489v1.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#87.95$Named Entity Recognition#CoNLL 2003 (English)#F1#91.73
1907.05611v2.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#87.67$Named Entity Recognition#CoNLL 2003 (English)#F1#92.34
1702.02098v3.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#86.99$Named Entity Recognition#Ontonotes v5 (English)#F1#86.84
1511.08308v5.pdf	Named Entity Recognition#Ontonotes v5 (English)#F1#86.19$Named Entity Recognition#CoNLL 2003 (English)#F1#91.62
2210.12949v1.pdf	Named Entity Recognition#BC5CDR#F1#91.3$Named Entity Recognition#AnatEM#F1#83.5$Named Entity Recognition#Gellus#F1 (%)#63.4$Named Entity Recognition#NCBI-disease#F1#89.9
2105.03654v2.pdf	Named Entity Recognition#BC5CDR#F1#90.99$Named Entity Recognition#CoNLL++#F1#94.81$Named Entity Recognition#CoNLL 2003 (English)#F1#93.85$Named Entity Recognition#NCBI-disease#F1#88.96$Named Entity Recognition#WNUT 2017#F1#60.45$Named Entity Recognition#WNUT 2016#F1#58.98
2101.00388v1.pdf	Named Entity Recognition#BC5CDR#F1#87.38$Named Entity Recognition#SciERC#F1#68.96$Named Entity Recognition#NCBI-disease#F1#87.89
1809.07950v2.pdf	Named Entity Recognition#BC5CDR#F1#87.12
2111.03837v1.pdf	Named Entity Recognition#BC5CDR#F1#86$Named Entity Recognition#CoNLL 2003 (English)#F1#93.6$Named Entity Recognition#NCBI-disease#F1#84.5
2003.10715v2.pdf	Named Entity Recognition#SoSciSoCi#Precision#0.83$Named Entity Recognition#SoSciSoCi#Recall#0.82$Named Entity Recognition#SoSciSoCi#F1#0.82
2209.03182v1.pdf	Named Entity Recognition#BC2GM#F1#86.97$Named Entity Recognition#BC2GM#F1#86.71$Named Entity Recognition#BC2GM#F1#86.6$Named Entity Recognition#BC2GM#F1#85.26$Named Entity Recognition#BC5CDR-chemical#F1#94.53$Named Entity Recognition#BC5CDR-chemical#F1#94.48$Named Entity Recognition#BC5CDR-chemical#F1#94.31$Named Entity Recognition#BC5CDR-chemical#F1#94.23$Named Entity Recognition#BC5CDR-disease#F1#85.61$Named Entity Recognition#BC5CDR-disease#F1#85.42$Named Entity Recognition#BC5CDR-disease#F1#85.38$Named Entity Recognition#BC5CDR-disease#F1#84.62$Named Entity Recognition#NCBI-disease#F1#88.67$Named Entity Recognition#NCBI-disease#F1#87.93$Named Entity Recognition#NCBI-disease#F1#87.61$Named Entity Recognition#NCBI-disease#F1#87.21$Named Entity Recognition#JNLPBA#F1#80.13$Named Entity Recognition#JNLPBA#F1#79.97$Named Entity Recognition#JNLPBA#F1#79.88$Named Entity Recognition#JNLPBA#F1#79.1
2005.11687v2.pdf	Named Entity Recognition#i2b2 De-identification Dataset#F1#0.97$Named Entity Recognition#i2b2 De-identification Dataset#Precision#96
2204.13743v1.pdf	Named Entity Recognition#HiNER-original#F1-score (Weighted)#88.78$Named Entity Recognition#HiNER-original#F1-score (Weighted)#88.27$Named Entity Recognition#HiNER-collapsed#F1-score (Weighted)#92.22$Named Entity Recognition#HiNER-collapsed#F1-score (Weighted)#92.11
2012.11145v1.pdf	Named Entity Recognition#WNUT 2020#F1#74.91
1909.08504v1.pdf	Named Entity Recognition#Code-Switching English-Spanish NER#F1#69.17
2205.01086v1.pdf	Named Entity Recognition#SLUE#F1 (%)#65.4
1909.01441v1.pdf	Named Entity Recognition#CoNLL++#F1#94.28$Named Entity Recognition#CoNLL++#F1#94.13$Named Entity Recognition#CoNLL 2003 (English)#F1#93.43$Named Entity Recognition#WNUT 2017#F1#50.03
1603.01360v3.pdf	Named Entity Recognition#CoNLL++#F1#91.47$Named Entity Recognition#CoNLL 2003 (English)#F1#90.94
2105.07464v6.pdf	Named Entity Recognition#Few-NERD (SUP)#Precision#65.56$Named Entity Recognition#Few-NERD (SUP)#Recall#68.78$Named Entity Recognition#Few-NERD (SUP)#F1-Measure#67.13$Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#51.88±0.69$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#57.32±0.63$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#43.34±0.10$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#49.57±3.08$Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#47.24±1.00$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#55.64±0.63$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#38.87±0.21$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#49.57±2.73$Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#38.83±1.49$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#58.79±0.44$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#32.45±0.79$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#52.92±0.37$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#30.21±0.90$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#38.00±1.29$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#21.03±1.13$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#26.42±0.60$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#25.78±0.91$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#36.18±0.79$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#18.27±0.41$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#27.38±0.53$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#20.76±0.84$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#42.54±0.94$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#15.05±0.44$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#35.40±0.13
2112.08033v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#93.82$Named Entity Recognition#CoNLL 2003 (English)#F1#93.28$Named Entity Recognition#CoNLL 2003 (English)#F1#88.63
1906.02437v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#93.47$Named Entity Recognition#CoNLL 2003 (English)#F1#91.96
2105.06804v2.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#92.94$Named Entity Recognition#ACE 2005#F1#86.67$Nested Named Entity Recognition#ACE 2004#F1#87.41$Nested Named Entity Recognition#GENIA#F1#80.54$Nested Named Entity Recognition#ACE 2005#F1#86.67$Chinese Named Entity Recognition#Weibo NER#F1#69.16
1911.04474v3.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#92.62$Chinese Named Entity Recognition#Resume NER#F1#95$Chinese Named Entity Recognition#MSRA#F1#92.74$Chinese Named Entity Recognition#Weibo NER#F1#58.17
1808.09075v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#92.29$Named Entity Recognition#CoNLL 2003 (English)#F1#91.87
1804.07827v2.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#92.03
1705.00108v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#91.93
1707.05127v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#91.62
1805.03838v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#91.38
1701.09123v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#91.36
1906.09535v1.pdf	Named Entity Recognition#CoNLL 2003 (English)#F1#84.7
1907.00464v1.pdf	Named Entity Recognition#ACE 2005#F1#82.4$Nested Named Entity Recognition#ACE 2005#F1#82.4$Nested Mention Recognition#ACE 2005#F1#82.4
2005.00436v1.pdf	Named Entity Recognition#ACE 2005#F1#75.1$Named Entity Recognition#GENIA#F1#76.0$Nested Named Entity Recognition#GENIA#F1#76.0$Nested Named Entity Recognition#ACE 2005#F1#75.1$Nested Mention Recognition#ACE 2005#F1#75.1
1906.03783v1.pdf	Named Entity Recognition#ACE 2005#F1#74.9$Named Entity Recognition#GENIA#F1#74.8$Nested Named Entity Recognition#GENIA#F1#74.8$Nested Named Entity Recognition#ACE 2005#F1#75.9$Nested Mention Recognition#ACE 2005#F1#74.9
1904.00585v2.pdf	Named Entity Recognition#WetLab#F1#79.62$Named Entity Recognition#JNLPBA#F1#74.29
2104.07249v2.pdf	Named Entity Recognition#WNUT 2017#F1#58.9$Named Entity Recognition#WNUT 2017#F1#42.3
2209.12616v1.pdf	Named Entity Recognition#WNUT 2017#F1#58.5
2106.00641v2.pdf	Named Entity Recognition#WNUT 2017#F1#52.97
1912.07095v1.pdf	Named Entity Recognition#WNUT 2017#F1#52.3
2010.15458v1.pdf	Named Entity Recognition#WNUT 2017#F1#50.36$Named Entity Recognition#WNUT 2016#F1#55.01$Chinese Named Entity Recognition#Weibo NER#F1#69.8
1906.04129v1.pdf	Named Entity Recognition#WNUT 2017#F1#45.55$Named Entity Recognition#WNUT 2017#F1 (surface form)#40.24
1906.04135v1.pdf	Named Entity Recognition#WNUT 2017#F1#41.86
2207.06991v1.pdf	Named Entity Recognition#MasakhaNER#ENG#92.9$Named Entity Recognition#MasakhaNER#Params#110M$Named Entity Recognition#MasakhaNER#AMH#0$Named Entity Recognition#MasakhaNER#IBO#83.5$Named Entity Recognition#MasakhaNER#HAU#86.6$Named Entity Recognition#MasakhaNER#KIN#72.0$Named Entity Recognition#MasakhaNER#LUG#78.4$Named Entity Recognition#MasakhaNER#LUO#73.2$Named Entity Recognition#MasakhaNER#PCM#87.0$Named Entity Recognition#MasakhaNER#SWA#83.3$Named Entity Recognition#MasakhaNER#WOL#62.2$Named Entity Recognition#MasakhaNER#YOR#73.8$Named Entity Recognition#MasakhaNER#ENG#89.5$Named Entity Recognition#MasakhaNER#Params#86M$Named Entity Recognition#MasakhaNER#AMH#47.7$Named Entity Recognition#MasakhaNER#IBO#79.9$Named Entity Recognition#MasakhaNER#HAU#82.4$Named Entity Recognition#MasakhaNER#KIN#64.2$Named Entity Recognition#MasakhaNER#LUG#76.5$Named Entity Recognition#MasakhaNER#LUO#66.6$Named Entity Recognition#MasakhaNER#PCM#78.7$Named Entity Recognition#MasakhaNER#SWA#79.8$Named Entity Recognition#MasakhaNER#WOL#59.7$Named Entity Recognition#MasakhaNER#YOR#70.7
2201.01405v2.pdf	Named Entity Recognition#Adverse Drug Events (ADE) Corpus#NER Macro F1#91.75$Text Classification#Adverse Drug Events (ADE) Corpus#F1 - macro#85.96
1508.01991v1.pdf	Named Entity Recognition#FindVehicle#F1 Score#49.5
2110.07480v3.pdf	Nested Named Entity Recognition#ACE 2004#F1#88.56$Nested Named Entity Recognition#ACE 2004#F1#87.40$Nested Named Entity Recognition#TAC-KBP 2017#F1#87.27$Nested Named Entity Recognition#TAC-KBP 2017#F1#85.05$Nested Named Entity Recognition#GENIA#F1#81.23$Nested Named Entity Recognition#ACE 2005#F1#88.83$Nested Named Entity Recognition#ACE 2005#F1#86.82
2208.04534v3.pdf	Nested Named Entity Recognition#ACE 2004#F1#88.03$Nested Named Entity Recognition#GENIA#F1#81.40$Nested Named Entity Recognition#ACE 2005#F1#87.42
2105.08901v2.pdf	Nested Named Entity Recognition#ACE 2004#F1#87.26$Nested Named Entity Recognition#GENIA#F1#80.44$Nested Named Entity Recognition#ACE 2005#F1#87.05
2012.08478v1.pdf	Nested Named Entity Recognition#ACE 2004#F1#86.6$Nested Named Entity Recognition#GENIA#F1#78.2$Nested Named Entity Recognition#ACE 2005#F1#85.4
2001.05272v6.pdf	Chinese Named Entity Recognition#Resume NER#F1#96.79$Chinese Named Entity Recognition#MSRA#F1#95.64$Chinese Named Entity Recognition#OntoNotes 4#F1#82.04$Chinese Named Entity Recognition#Weibo NER#F1#71.25
2010.15466v1.pdf	Chinese Named Entity Recognition#Resume NER#F1#96.62$Chinese Named Entity Recognition#OntoNotes 4#F1#81.18$Chinese Named Entity Recognition#Weibo NER#F1#69.78
2004.11795v2.pdf	Chinese Named Entity Recognition#Resume NER#F1#95.86$Chinese Named Entity Recognition#Resume NER#F1#95.45$Chinese Named Entity Recognition#MSRA#F1#96.09$Chinese Named Entity Recognition#MSRA#F1#94.12$Chinese Named Entity Recognition#OntoNotes 4#F1#81.82$Chinese Named Entity Recognition#OntoNotes 4#F1#76.45$Chinese Named Entity Recognition#Weibo NER#F1#68.55$Chinese Named Entity Recognition#Weibo NER#F1#60.32
2007.08416v1.pdf	Chinese Named Entity Recognition#Resume NER#F1#95.8$Chinese Named Entity Recognition#OntoNotes 4#F1#80.2$Chinese Named Entity Recognition#Weibo NER#F1#64
1908.05969v2.pdf	Chinese Named Entity Recognition#Resume NER#F1#95.59$Chinese Named Entity Recognition#MSRA#F1#93.5$Chinese Named Entity Recognition#OntoNotes 4#F1#75.54$Chinese Named Entity Recognition#Weibo NER#F1#61.24
1904.02141v3.pdf	Chinese Named Entity Recognition#Resume NER#F1#94.94$Chinese Named Entity Recognition#Resume NER#Precision#95.05$Chinese Named Entity Recognition#Resume NER#Recall#94.82$Chinese Named Entity Recognition#MSRA#F1#92.97$Chinese Named Entity Recognition#MSRA#Precision#93.53$Chinese Named Entity Recognition#MSRA#Recall#92.42$Chinese Named Entity Recognition#OntoNotes 4#F1#73.64$Chinese Named Entity Recognition#OntoNotes 4#Precision#75.05$Chinese Named Entity Recognition#OntoNotes 4#Recall#72.29$Chinese Named Entity Recognition#Weibo NER#Accuracy-NE#55.38$Chinese Named Entity Recognition#Weibo NER#Accuracy-NM#62.98$Chinese Named Entity Recognition#Weibo NER#Overall#59.31
1805.02023v4.pdf	Chinese Named Entity Recognition#Resume NER#F1#94.46$Chinese Named Entity Recognition#MSRA#F1#93.18$Chinese Named Entity Recognition#OntoNotes 4#F1#73.88$Chinese Named Entity Recognition#Weibo NER#F1#58.79
2204.05751v2.pdf	Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#64.75±0.35$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#71.49±0.47$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#58.65±0.43$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#68.11±0.05$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#49.48±0.85$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#62.92±0.57$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#42.84±0.46$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#57.31±0.25
2109.13023v3.pdf	Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#59.29±1.25$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#69.06±0.80$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#52.16±0.79$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#64.00±0.43$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#36.08±1.60$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#52.14±1.50$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#30.00±0.70$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#42.15±2.60
2109.07589v2.pdf	Few-shot NER#Few-NERD (INTER)#5 way 1~2 shot#55.95$Few-shot NER#Few-NERD (INTER)#5 way 5~10 shot#61.83$Few-shot NER#Few-NERD (INTER)#10 way 1~2 shot#48.35$Few-shot NER#Few-NERD (INTER)#10 way 5~10 shot#57.12$Few-shot NER#Few-NERD (INTRA)#5 way 1~2 shot#40.43$Few-shot NER#Few-NERD (INTRA)#5 way 5~10 shot#53.70$Few-shot NER#Few-NERD (INTRA)#10 way 1~2 shot#33.84$Few-shot NER#Few-NERD (INTRA)#10 way 5~10 shot#47.49
2002.05923v2.pdf	Cross-Domain Named Entity Recognition#CoNLL04#F1#70.04
2205.06457v2.pdf	Named Entity Recognition In Vietnamese#PhoNER COVID19#F1 (%)#94.5$Abstractive Text Summarization#vietnews#Rouge-L#43.55$Abstractive Text Summarization#vietnews#Rouge-1#63.37$Abstractive Text Summarization#vietnews#Rouge-2#34.24$Abstractive Text Summarization#vietnews#Rouge-L#42.75$Abstractive Text Summarization#vietnews#Rouge-1#62.77$Abstractive Text Summarization#vietnews#Rouge-2#33.16
2104.03879v1.pdf	Named Entity Recognition In Vietnamese#PhoNER COVID19#F1 (%)#94.5
2001.03067v1.pdf	Scientific Concept Extraction#STM-corpus#Exact Span F1#66.4$Scientific Concept Extraction#STM-corpus#Exact Span F1#65.5
2109.04053v1.pdf	Table-based Fact Verification#TabFact#Test#82.1$Table-based Fact Verification#TabFact#Val#82.7
2010.00571v2.pdf	Table-based Fact Verification#TabFact#Test#81.0$Table-based Fact Verification#TabFact#Val#81.0
1909.02164v5.pdf	Table-based Fact Verification#TabFact#Test#65.12$Table-based Fact Verification#TabFact#Val#66.1$Table-based Fact Verification#TabFact#Test#50.5$Table-based Fact Verification#TabFact#Val#50.9
1907.10014v2.pdf	Horizon Line Estimation#KITTI Horizon#ATV#4.984$Horizon Line Estimation#KITTI Horizon#AUC#74.55$Horizon Line Estimation#KITTI Horizon#MSE#6.731
1608.05684v1.pdf	Horizon Line Estimation#Eurasian Cities Dataset#AUC (horizon error)#90.80$Horizon Line Estimation#Horizon Lines in the Wild#AUC (horizon error)#58.24$Horizon Line Estimation#York Urban Dataset#AUC (horizon error)#94.78
1707.02427v2.pdf	Horizon Line Estimation#Eurasian Cities Dataset#AUC (horizon error)#86.26$Horizon Line Estimation#Horizon Lines in the Wild#AUC (horizon error)#57.31$Horizon Line Estimation#York Urban Dataset#AUC (horizon error)#94.27
1604.02129v2.pdf	Horizon Line Estimation#Eurasian Cities Dataset#AUC (horizon error)#83.6$Horizon Line Estimation#Horizon Lines in the Wild#AUC (horizon error)#71.16$Horizon Line Estimation#York Urban Dataset#AUC (horizon error)#86.41
1905.04132v2.pdf	Horizon Line Estimation#Horizon Lines in the Wild#AUC (horizon error)#75.2
1803.06589v2.pdf	Mortality Prediction#MIMIC-III#F1 score#0.97$Mortality Prediction#MIMIC-III#Precision#0.97$Mortality Prediction#MIMIC-III#Recall#0.97$Mortality Prediction#MIMIC-III#F1 score#0.96$Mortality Prediction#MIMIC-III#Precision#0.95$Mortality Prediction#MIMIC-III#Recall#0.96$Mortality Prediction#MIMIC-III#F1 score#0.91$Mortality Prediction#MIMIC-III#Precision#0.90$Mortality Prediction#MIMIC-III#Recall#0.92$Mortality Prediction#MIMIC-III#F1 score#0.87$Mortality Prediction#MIMIC-III#Precision#0.91$Mortality Prediction#MIMIC-III#Recall#0.83$Mortality Prediction#MIMIC-III#F1 score#0.82$Mortality Prediction#MIMIC-III#Precision#0.80$Mortality Prediction#MIMIC-III#Recall#0.85$Mortality Prediction#MIMIC-III#F1 score#0.72$Mortality Prediction#MIMIC-III#Precision#0.77$Mortality Prediction#MIMIC-III#Recall#0.67$Mortality Prediction#MIMIC-III#F1 score#0.71$Mortality Prediction#MIMIC-III#Precision#0.78$Mortality Prediction#MIMIC-III#Recall#0.66$Mortality Prediction#MIMIC-III#F1 score#0.70$Mortality Prediction#MIMIC-III#Recall#0.63
2012.13978v1.pdf	Mortality Prediction#MIMIC-III#Accuracy#0.8443$Mortality Prediction#MIMIC-III#Accuracy#0.8325$Mortality Prediction#MIMIC-III#Accuracy#0.8298$Mortality Prediction#MIMIC-III#Accuracy#0.828$Mortality Prediction#MIMIC-III#Accuracy#0.7996
1904.01949v2.pdf	ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (1dAVb)#0.893$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (RBBB)#0.932$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (LBBB)#0.984$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (SB)#0.882$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (AF)#0.857$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (ST)#0.933$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (1dAVb)#0.776$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (RBBB)#0.917$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (LBBB)#0.947$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (AF)#0.769$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (ST)#0.896$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (1dAVb)#0.732$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (RBBB)#0.928$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (LBBB)#0.915$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (SB)#0.750$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (AF)#0.706$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (ST)#0.857$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (1dAVb)#0.719$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (RBBB)#0.852$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (LBBB)#0.912$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (SB)#0.848$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (AF)#0.696$ECG Classification#Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)#F1 (ST)#0.932
2204.08989v1.pdf	Heart rate estimation#BIDMC#MAE [bpm, session-wise]#1.33$Heart rate estimation#MTHS#MAE [bpm, session-wise]#6.96$SpO2 estimation#BIDMC#MAE [bpm, session-wise]#92$SpO2 estimation#MTHS#MAE [bpm, session-wise]#1.34
1705.04524v3.pdf	Blood pressure estimation#Multi-day Continuous BP Prediction#RMSE#3.73$Blood pressure estimation#MIMIC-III#MAE for SBP [mmHg]#8.54$Blood pressure estimation#MIMIC-III#MAE for DBP [mmHg]#6.7
2210.01791v1.pdf	Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAE#1.72$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAPE (%)#2.24%$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#RMSE#4.03$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#Pearson Correlation#0.95$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAE#0.65$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAPE (%)#0.77%$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#RMSE#1.98$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#Pearson Correlation#0.99
2006.03790v2.pdf	Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAE#3.04$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAPE (%)#3.41%$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#Pearson Correlation#0.89$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#RMSE#2.72
2110.04447v2.pdf	Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAE#3.04$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAPE (%)#3.91%$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#RMSE#5.91$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#Pearson Correlation#0.92$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAE#3.48$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#MAPE (%)#4.02%$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#RMSE#7.21$Photoplethysmography (PPG) heart rate estimation#MMSE-HR#Pearson Correlation#0.86$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAE#1.14$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAPE (%)#1.16%$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#RMSE#1.81$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#Pearson Correlation#0.99$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAE#2.08$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#MAPE (%)#2.53%$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#RMSE#4.91$Photoplethysmography (PPG) heart rate estimation#UBFC-rPPG#Pearson Correlation#0.96
1812.07421v1.pdf	Arrhythmia Detection#MIT-BIH AR#Accuracy (Intra-Patient)#99.92%$Arrhythmia Detection#MIT-BIH AR#Accuracy (Inter-Patient)#99.53%
1907.09504v1.pdf	Arrhythmia Detection#MIT-BIH AR#Accuracy (Inter-Patient)#99.11%
1805.00794v2.pdf	Arrhythmia Detection#MIT-BIH AR#Accuracy (Inter-Patient)#93.4%$Myocardial infarction detection#PTB dataset, ECG lead II#Accuracy#95.9%
2207.07089v1.pdf	Arrhythmia Detection#MIT-BIH Arrhythmia Database#Accuracy#98.2$Arrhythmia Detection#MIT-BIH Arrhythmia Database#specificity#98.8$Arrhythmia Detection#MIT-BIH Arrhythmia Database#Precision#91.9$Arrhythmia Detection#MIT-BIH Arrhythmia Database#Recall#93.7$Arrhythmia Detection#MIT-BIH Arrhythmia Database#F1#92.8
1903.12536v1.pdf	ECG Denoising#UnoViS_auto2012#MSE#0.167
1912.07618v3.pdf	Myocardial infarction detection#PTB dataset, ECG lead II#Accuracy#99.43%$Myocardial infarction detection#PTB#Accuracy (%)#99.43%
1809.03393v4.pdf	ECG Wave Delineation#LUDB#F1 score#98.51
1907.05888v1.pdf	Congestive Heart Failure detection#CHF database#Accuracy#98.49$Congestive Heart Failure detection#CHF database#Precision#98.05$Congestive Heart Failure detection#CHF database#Sensitivity#98.3
1707.09423v2.pdf	Visual Relationship Detection#VRD Relationship Detection#R@100#31.89$Visual Relationship Detection#VRD Relationship Detection#R@50#22.68$Visual Relationship Detection#VRD Phrase Detection#R@100#29.43$Visual Relationship Detection#VRD Phrase Detection#R@50#26.32$Visual Relationship Detection#VRD Predicate Detection#R@100#94.65$Visual Relationship Detection#VRD Predicate Detection#R@50#85.64
1704.03114v2.pdf	Visual Relationship Detection#VRD Relationship Detection#R@100#20.88$Visual Relationship Detection#VRD Relationship Detection#R@50#17.73$Visual Relationship Detection#VRD Phrase Detection#R@100#23.45$Visual Relationship Detection#VRD Phrase Detection#R@50#19.93$Visual Relationship Detection#VRD Predicate Detection#R@100#81.90$Visual Relationship Detection#VRD Predicate Detection#R@50#80.78
1703.03054v1.pdf	Visual Relationship Detection#VRD Relationship Detection#R@100#20.79$Visual Relationship Detection#VRD Relationship Detection#R@50#18.19$Visual Relationship Detection#VRD Phrase Detection#R@100#22.60$Visual Relationship Detection#VRD Phrase Detection#R@50#21.37
1707.09472v1.pdf	Visual Relationship Detection#VRD Relationship Detection#R@100#17.1$Visual Relationship Detection#VRD Relationship Detection#R@50#15.8$Visual Relationship Detection#VRD Phrase Detection#R@100#19.5$Visual Relationship Detection#VRD Phrase Detection#R@50#17.9$Visual Relationship Detection#VRD Predicate Detection#R@100#52.6$Visual Relationship Detection#VRD Predicate Detection#R@50#52.6
1702.08319v1.pdf	Visual Relationship Detection#VRD Relationship Detection#R@100#15.20$Visual Relationship Detection#VRD Relationship Detection#R@50#14.07$Visual Relationship Detection#VRD Phrase Detection#R@100#22.42$Visual Relationship Detection#VRD Phrase Detection#R@50#19.42$Visual Relationship Detection#VRD Predicate Detection#R@100#44.76$Visual Relationship Detection#VRD Predicate Detection#R@50#44.76
2107.07154v2.pdf	Video Visual Relation Detection#ImageNet-VidVRD#Recall@50#11.56$Video Visual Relation Detection#ImageNet-VidVRD#Recall@100#14.13$Video Visual Relation Detection#ImageNet-VidVRD#mAP#18.9$Video Visual Relation Detection#VidOR#Recall@50#9.33$Video Visual Relation Detection#VidOR#Recall@100#10.71$Video Visual Relation Detection#VidOR#mAP#7.61
1812.10235v1.pdf	Slot Filling#THU-Bi-Hand#F1-score#0.958$Slot Filling#SNIPS#F1#0.938$Slot Filling#ATIS#F1#98.99$Slot Filling#ATIS#F1#0.982$Intent Detection#ATIS#Accuracy#0.9927
1902.03646v2.pdf	Slot Filling#Polyvore#FITB#96.9$Recommendation Systems#Polyvore#AUC#0.99
1902.10909v1.pdf	Slot Filling#ATIS#F1#0.961$Slot Filling#ATIS#F1#0.96$Intent Detection#ATIS#Accuracy#97.9$Intent Detection#ATIS#Accuracy#97.5
1907.00390v1.pdf	Slot Filling#ATIS#F1#0.958$Intent Detection#ATIS#Accuracy#97.76$Intent Detection#ATIS#F1#95.80$Intent Detection#SNIPS#Intent Accuracy#97.43$Intent Detection#SNIPS#Slot F1 Score#92.23
1812.09471v2.pdf	Slot Filling#ATIS#F1#0.952$Intent Detection#ATIS#Accuracy#95.00$Intent Detection#SNIPS#Intent Accuracy#97.70$Intent Detection#SNIPS#Slot F1 Score#91.80
2106.01925v1.pdf	Slot Filling#MixSNIPS#F1#94.9$Slot Filling#MixATIS#F1#88.3$Intent Detection#MixSNIPS#Accuracy#95.6$Intent Detection#MixATIS#Accuracy#76.3
2108.13934v2.pdf	Zero-shot Slot Filling#T-REx#R-Prec#74.34$Zero-shot Slot Filling#T-REx#R@5#82.89$Zero-shot Slot Filling#T-REx#R-Prec#65.02$Zero-shot Slot Filling#T-REx#R@5#75.52$Zero-shot Slot Filling#T-REx#R-Prec#53.04$Zero-shot Slot Filling#T-REx#R@5#65.54$Zero-shot Slot Filling#T-REx#R-Prec#49.02$Zero-shot Slot Filling#T-REx#R@5#63.34$Zero-shot Slot Filling#T-REx#R-Prec#42.62$Zero-shot Slot Filling#T-REx#R@5#55.09$Zero-shot Slot Filling#T-REx#R-Prec#19.5$Zero-shot Slot Filling#T-REx#R@5#29.8$Zero-shot Slot Filling#zsRE#R-Prec#98.60$Zero-shot Slot Filling#zsRE#R@5#99.70$Zero-shot Slot Filling#zsRE#R-Prec#97.53$Zero-shot Slot Filling#zsRE#R@5#99.3$Zero-shot Slot Filling#zsRE#R-Prec#96.89$Zero-shot Slot Filling#zsRE#R@5#98.01$Zero-shot Slot Filling#zsRE#R-Prec#94.55$Zero-shot Slot Filling#zsRE#R@5#98.17$Zero-shot Slot Filling#zsRE#R-Prec#68.13$Zero-shot Slot Filling#zsRE#R@5#79.19$Zero-shot Slot Filling#zsRE#R-Prec#45.49$Zero-shot Slot Filling#zsRE#R@5#60.77
2012.10052v1.pdf	Extracting COVID-19 Events from Twitter#W-NUT 2020 Shared Task-3#F1#0.66
2201.02861v2.pdf	Camera Localization#Aachen Day-Night benchmark#Acc @ 0.5m, 2°#81.6$Camera Localization#Aachen Day-Night benchmark#Acc @ 1m, 5°#90.8$Camera Localization#Aachen Day-Night benchmark#Acc @ 5m, 10°#100
2204.00154v2.pdf	Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9734$Change detection for remote sensing images#WHU building#F1-Score#0.9236
2202.09745v3.pdf	Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.972
2208.00657v1.pdf	Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9713$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#94.51$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9685$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#94$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9648$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#93.33$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9552$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#91.62$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9278$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#87$Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.9205$Change detection for remote sensing images#CDD Dataset (season-varying)#IoU#85.81$Building change detection for remote sensing images#LEVIR-CD#F1#91.58$Building change detection for remote sensing images#LEVIR-CD#IoU#85.38$Building change detection for remote sensing images#LEVIR-CD#F1#90.70$Building change detection for remote sensing images#LEVIR-CD#IoU#84.05$Building change detection for remote sensing images#LEVIR-CD#F1#90.57$Building change detection for remote sensing images#LEVIR-CD#IoU#83.88$Building change detection for remote sensing images#LEVIR-CD#F1#90.54$Building change detection for remote sensing images#LEVIR-CD#IoU#83.84$Building change detection for remote sensing images#LEVIR-CD#F1#89.47$Building change detection for remote sensing images#LEVIR-CD#IoU#82.29$Building change detection for remote sensing images#LEVIR-CD#F1#89.29$Building change detection for remote sensing images#LEVIR-CD#IoU#82.03$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#96.69$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#93.58$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#96.59$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#93.4$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#96.32$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#92.9$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#96.22$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#92.7$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#96.01$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#92.31$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#F1#95.53$Extracting Buildings In Remote Sensing Images#WHU Building Dataset#IoU#91.43$Extracting Buildings In Remote Sensing Images#xBD#IoU#79.26$Extracting Buildings In Remote Sensing Images#xBD#F1#88.43$Extracting Buildings In Remote Sensing Images#xBD#IoU#79.14$Extracting Buildings In Remote Sensing Images#xBD#F1#88.35$Extracting Buildings In Remote Sensing Images#xBD#IoU#79.06$Extracting Buildings In Remote Sensing Images#xBD#F1#88.3$Extracting Buildings In Remote Sensing Images#xBD#IoU#78.66$Extracting Buildings In Remote Sensing Images#xBD#F1#88.05$Extracting Buildings In Remote Sensing Images#xBD#IoU#77.35$Extracting Buildings In Remote Sensing Images#xBD#F1#87.23$Extracting Buildings In Remote Sensing Images#xBD#IoU#76.43$Extracting Buildings In Remote Sensing Images#xBD#F1#86.46
2003.03608v2.pdf	Change detection for remote sensing images#CDD Dataset (season-varying)#F1-Score#0.919
2209.08290v1.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#92.33$Building change detection for remote sensing images#LEVIR-CD#F1#92.19$Building change detection for remote sensing images#LEVIR-CD#F1#91.77$Change Detection#S2Looking#F1-Score#66.20
2009.02062v2.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#91.79
2108.07002v2.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#91.25$Building change detection for remote sensing images#LEVIR-CD#IoU#83.92$Building change detection for remote sensing images#LEVIR-CD#F1#90.4$Building change detection for remote sensing images#LEVIR-CD#F1#89.7$Building change detection for remote sensing images#LEVIR-CD#F1#87.6$Change Detection#LEVIR-CD#F1#91.25$Change Detection#LEVIR-CD#IoU#83.92$Change Detection#LEVIR-CD#Overall Accuracy#-
2207.13159v1.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#91.05
2201.01293v7.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#90.40$Building change detection for remote sensing images#LEVIR-CD#IoU#82.48$Change Detection#LEVIR-CD#F1#90.4$Change Detection#LEVIR-CD#IoU#82.48$Change Detection#LEVIR-CD#Overall Accuracy#99.04$Change Detection#DSIFN-CD#F1#86.67$Change Detection#DSIFN-CD#IoU#76.48$Change Detection#DSIFN-CD#Overall Accuracy#95.56
2103.00208v3.pdf	Building change detection for remote sensing images#LEVIR-CD#F1#89.31
2201.10953v2.pdf	Extracting Buildings In Remote Sensing Images#xBD#F1#86.86
1609.01454v1.pdf	Intent Detection#ATIS#Accuracy#98.43$Intent Detection#ATIS#F1#95.87
1609.01462v1.pdf	Intent Detection#ATIS#Accuracy#98.40$Intent Detection#ATIS#F1#94.64
1909.02188v1.pdf	Intent Detection#ATIS#Accuracy#97.50$Intent Detection#ATIS#F1#96.10$Intent Detection#SNIPS#Intent Accuracy#99.0$Intent Detection#SNIPS#Slot F1 Score#97.00$Intent Detection#SNIPS#Intent Accuracy#98.00$Intent Detection#SNIPS#Slot F1 Score#94.20
2110.15717v1.pdf	Intent Detection#ATIS#Accuracy#95.97$Intent Detection#ATIS#Intent Accuracy#95.97$Intent Detection#SNIPS#Intent Accuracy#98.0$Intent Detection#SNIPS#model size#0.63 MB$Intent Detection#SNIPS#Latency, ms#18
1911.01680v2.pdf	Intent Detection#ATIS#F1#95.80$Intent Detection#SNIPS#Slot F1 Score#93.60
2012.10209v5.pdf	Open Intent Detection#BANKING-77 (50% known)#1:1 Accuracy#78.86$Open Intent Detection#BANKING-77 (50% known)#F1-score#80.90$Open Intent Detection#BANKING77 (25%known)#1:1 Accuracy#78.85$Open Intent Detection#BANKING77 (25%known)#F1-score#71.62$Open Intent Detection#OOS(75%known)#1:1 Accuracy#86.32$Open Intent Detection#OOS(75%known)#F1-score#88.53$Open Intent Detection#BANKING-77 (75% known)#1:1 Accuracy#81.08$Open Intent Detection#BANKING-77 (75% known)#F1-score#85.96$Open Intent Detection#OOS(25%known)#1:1 Accuracy#87.59$Open Intent Detection#OOS(25%known)#F1-score#77.19$Open Intent Detection#OOS(50%known)#1:1 Accuracy#86.54$Open Intent Detection#OOS(50%known)#F1-score#85.05$Open Intent Detection#StackOverFlow(50%known)#1:1 Accuracy#86.40$Open Intent Detection#StackOverFlow(50%known)#F1-score#85.83$Open Intent Detection#StackOverFlow(75%known)#1:1 Accuracy#82.78$Open Intent Detection#StackOverFlow(75%known)#F1-score#85.99$Open Intent Detection#StackOverFlow(25%known)#1:1 Accuracy#86.72$Open Intent Detection#StackOverFlow(25%known)#F1-score#80.83
1906.00434v1.pdf	Open Intent Detection#ATIS (50% known)#F1#0.396$Open Intent Detection#ATIS (25% known)#F1#0.696$Open Intent Detection#SNIPS (25% known)#F1#0.792$Open Intent Detection#SNIPS (50% known)#F1#0.841$Open Intent Detection#SNIPS (75% known)#F1#0.788
2110.13473v2.pdf	Action Detection#Charades#mAP#27.8$Action Detection#Multi-THUMOS#mAP#51.2
2111.13675v1.pdf	Action Detection#Charades#mAP#26.95
2112.03902v2.pdf	Action Detection#Charades#mAP#25.4$Action Detection#TSU#Frame-mAP#33.7$Action Detection#Multi-THUMOS#mAP#43.1
2103.01302v2.pdf	Action Detection#Charades#mAP#25.1
1905.07385v2.pdf	Action Detection#Charades#mAP#23.7
2103.03027v3.pdf	Action Detection#Charades#mAP#23.7$Action Detection#Multi-THUMOS#mAP#51.5
1803.06316v6.pdf	Action Detection#Charades#mAP#22.3$Action Detection#Multi-THUMOS#mAP#46.4
1712.01938v2.pdf	Action Detection#Charades#mAP#19.41$Action Detection#Multi-THUMOS#mAP#36.4
2102.04308v1.pdf	Action Detection#.#Frame-mAP#1
1507.05738v3.pdf	Action Detection#Multi-THUMOS#mAP#28.1$Action Detection#Multi-THUMOS#mAP#27.6
2001.04608v3.pdf	Action Detection#UCF101-24#Video-mAP 0.2#81.8$Action Detection#UCF101-24#mAP#27.7$Action Detection#UCF101-24#Video-mAP 0.5#53.9$Action Detection#UCF101-24#Video-mAP 0.75#28.5
1904.09288v1.pdf	Action Detection#UCF101-24#Video-mAP 0.2#76.6$Action Detection#UCF101-24#Video-mAP 0.1#83.1
1703.10664v3.pdf	Action Detection#UCF101-24#Video-mAP 0.2#73.1$Action Detection#UCF101-24#Video-mAP 0.1#77.9
2206.04668v1.pdf	Online Action Detection#TVSeries#mCAP#89.6$Online Action Detection#THUMOS'14#mAP#72.5$Online Action Detection#THUMOS'14#mAP#70.7$Online Action Detection#THUMOS'14#mAP#66.5
2107.03377v3.pdf	Online Action Detection#TVSeries#mCAP#89.1$Online Action Detection#THUMOS'14#mAP#69.5
2203.01057v2.pdf	Online Action Detection#TVSeries#mCAP#88.1$Online Action Detection#THUMOS'14#mAP#66.9$Online Action Detection#THUMOS'14#mAP#58.6
2106.11149v1.pdf	Online Action Detection#TVSeries#mCAP#87.2$Online Action Detection#THUMOS'14#mAP#65.2
2011.09158v2.pdf	Online Action Detection#TVSeries#mCAP#86.4
1811.07391v2.pdf	Online Action Detection#TVSeries#mCAP#86.2$Online Action Detection#THUMOS'14#mAP#62.1
1912.04461v3.pdf	Online Action Detection#TVSeries#mCAP#86.1
2006.03732v2.pdf	Online Action Detection#THUMOS'14#mAP#67.1
2207.07783v3.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#94.9%$Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#94.2%
2206.10861v1.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#94.5%
2203.14250v2.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#94.1%
2106.03932v2.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#93.5%
2108.02607v1.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#92.0%
2106.03821v2.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#91.9%
2101.03682v2.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#88.8%$Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#85.1%
1906.10555v1.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#87.8%
2005.09812v1.pdf	Audio-Visual Active Speaker Detection#AVA-ActiveSpeaker#validation mean average precision#87.1%
2110.10552v1.pdf	Few Shot Temporal Action Localization#THUMOS14#mIoU#30.2$Few Shot Temporal Action Localization#ActivityNet#mIoU#38.5
2101.03545v1.pdf	Fake News Detection#COVID-19 Fake News Dataset#F1#0.9883
2101.02359v1.pdf	Fake News Detection#Grover-Mega#Unpaired Accuracy#98.5%$Fake News Detection#Social media#Accuracy#92.4
1905.12616v3.pdf	Fake News Detection#Grover-Mega#Unpaired Accuracy#92.0%$Fake News Detection#Grover-Mega#Unpaired Accuracy#80.8%$Fake News Detection#Grover-Mega#Unpaired Accuracy#73.1%$Fake News Detection#Grover-Mega#Unpaired Accuracy#70.1%
2210.08331v1.pdf	Fake News Detection#FNC-1#Weighted Accuracy#84.60$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#88.47$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#96.00$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#87.70$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#95.04
1712.03935v1.pdf	Fake News Detection#FNC-1#Weighted Accuracy#83.08$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#43.82$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#6.31$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#85.68$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#98.04$Fake News Detection#FNC-1#Weighted Accuracy#76.18$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#31.80$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#0.00$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#81.20$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#91.18$Fake News Detection#FNC-1#Weighted Accuracy#72.78$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#50.70$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#9.61$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#53.38$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#96.05$Fake News Detection#FNC-1#Weighted Accuracy#63.11$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#38.04$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#4.59$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#58.132$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#78.27
1707.03264v2.pdf	Fake News Detection#FNC-1#Weighted Accuracy#81.72$Fake News Detection#FNC-1#Per-class Accuracy (Agree)#44.04$Fake News Detection#FNC-1#Per-class Accuracy (Disagree)#6.60$Fake News Detection#FNC-1#Per-class Accuracy (Discuss)#81.38$Fake News Detection#FNC-1#Per-class Accuracy (Unrelated)#97.90
1804.07581v1.pdf	Fake News Detection#FNC-1#Weighted Accuracy#81.23$Fake News Detection#FNC-1#Weighted Accuracy#78.97
2205.08159v1.pdf	Fake News Detection#Weibo NER#Accuracy#86.83%$Fake News Detection#MediaEval2016#Accuracy#85.80%
1705.00648v1.pdf	Fake News Detection#LIAR#Validation Accuracy#0.247$Fake News Detection#LIAR#Test Accuracy#0.274$Fake News Detection#LIAR#Validation Accuracy#0.26$Fake News Detection#LIAR#Test Accuracy#0.27$Fake News Detection#LIAR#Validation Accuracy#0.277$Fake News Detection#LIAR#Test Accuracy#0.248$Fake News Detection#LIAR#Validation Accuracy#0.223$Fake News Detection#LIAR#Test Accuracy#0.233
2204.08198v5.pdf	Sarcasm Detection#iSarcasm#F1-Score#0.414
2206.02119v1.pdf	Sarcasm Detection#MUStARD++#Precision#70.2$Sarcasm Detection#MUStARD++#Recall#70.2$Sarcasm Detection#MUStARD++#F1#70.2
2006.00850v1.pdf	Sarcasm Detection#FigLang 2020 Reddit Dataset#F1#0.716$Sarcasm Detection#FigLang 2020 Twitter Dataset#F1#0.772
1704.05579v4.pdf	Sarcasm Detection#SARC (pol-bal)#Accuracy#76.5$Sarcasm Detection#SARC (all-bal)#Accuracy#75.8$Sarcasm Detection#SARC (pol-unbal)#Avg F1#27.0
1805.06413v1.pdf	Sarcasm Detection#SARC (pol-bal)#Accuracy#74$Sarcasm Detection#SARC (all-bal)#Accuracy#77
2203.06419v1.pdf	Sarcasm Detection#WITS#R1#36.88
1712.01361v2.pdf	Shadow Detection#SBU#BER#5.37
1712.04142v2.pdf	Shadow Detection#SBU#BER#5.59$RGB Salient Object Detection#SBU#Balanced Error Rate#5.59$RGB Salient Object Detection#ISTD#Balanced Error Rate#8.24$RGB Salient Object Detection#UCF#Balanced Error Rate#8.10
1712.02478v1.pdf	Shadow Detection#SBU#BER#8.14$RGB Salient Object Detection#SBU#Balanced Error Rate#8.14$RGB Salient Object Detection#ISTD#Balanced Error Rate#7.35$RGB Salient Object Detection#UCF#Balanced Error Rate#11.23
1709.09283v2.pdf	Shadow Detection#SBU#BER#11.56
1908.05900v2.pdf	Scene Text Detection#MSRA-TD500#Recall#83.8$Scene Text Detection#MSRA-TD500#F-Measure#84.1$Scene Text Detection#SCUT-CTW1500#F-Measure#83.7$Scene Text Detection#SCUT-CTW1500#Precision#86.4$Scene Text Detection#SCUT-CTW1500#Recall#81.2$Scene Text Detection#ICDAR 2015#F-Measure#82.6$Scene Text Detection#ICDAR 2015#Precision#84.9$Scene Text Detection#ICDAR 2015#Recall#80.4$Scene Text Detection#Total-Text#F-Measure#85%$Scene Text Detection#Total-Text#Precision#89.3$Scene Text Detection#Total-Text#Recall#81
2202.10304v1.pdf	Scene Text Detection#MSRA-TD500#Recall#83.3$Scene Text Detection#MSRA-TD500#Precision#91.5$Scene Text Detection#MSRA-TD500#F-Measure#87.2$Scene Text Detection#MSRA-TD500#FPS#29$Scene Text Detection#MSRA-TD500#Recall#82.5$Scene Text Detection#MSRA-TD500#Precision#87.9$Scene Text Detection#MSRA-TD500#F-Measure#85.1$Scene Text Detection#MSRA-TD500#FPS#55$Scene Text Detection#MSRA-TD500#Recall#76.5$Scene Text Detection#MSRA-TD500#Precision#89.7$Scene Text Detection#MSRA-TD500#F-Measure#82.6$Scene Text Detection#MSRA-TD500#FPS#80$Scene Text Detection#ICDAR 2015#F-Measure#87.3$Scene Text Detection#ICDAR 2015#Precision#90.9$Scene Text Detection#ICDAR 2015#Recall#83.9$Scene Text Detection#ICDAR 2015#FPS#10$Scene Text Detection#ICDAR 2015#F-Measure#83.1$Scene Text Detection#ICDAR 2015#Precision#90.1$Scene Text Detection#ICDAR 2015#Recall#77.2$Scene Text Detection#ICDAR 2015#FPS#44$Scene Text Detection#Total-Text#F-Measure#86%$Scene Text Detection#Total-Text#Precision#88.9$Scene Text Detection#Total-Text#Recall#83.2$Scene Text Detection#Total-Text#FPS#28$Scene Text Detection#Total-Text#F-Measure#83.3%$Scene Text Detection#Total-Text#Precision#87.4$Scene Text Detection#Total-Text#Recall#79.6$Scene Text Detection#Total-Text#FPS#48
2111.02394v1.pdf	Scene Text Detection#MSRA-TD500#Recall#83$Scene Text Detection#MSRA-TD500#Precision#90.9$Scene Text Detection#MSRA-TD500#F-Measure#86.7$Scene Text Detection#MSRA-TD500#FPS#56.8$Scene Text Detection#MSRA-TD500#Recall#82.3$Scene Text Detection#MSRA-TD500#Precision#90.2$Scene Text Detection#MSRA-TD500#F-Measure#86.1$Scene Text Detection#MSRA-TD500#FPS#72$Scene Text Detection#MSRA-TD500#Recall#80.3$Scene Text Detection#MSRA-TD500#F-Measure#85.3$Scene Text Detection#MSRA-TD500#FPS#79.6$Scene Text Detection#MSRA-TD500#Recall#78.9$Scene Text Detection#MSRA-TD500#Precision#90.6$Scene Text Detection#MSRA-TD500#F-Measure#84.4$Scene Text Detection#MSRA-TD500#FPS#137.2$Scene Text Detection#SCUT-CTW1500#F-Measure#83.7$Scene Text Detection#SCUT-CTW1500#Precision#87.2$Scene Text Detection#SCUT-CTW1500#Recall#80.4$Scene Text Detection#SCUT-CTW1500#FPS#66.5$Scene Text Detection#SCUT-CTW1500#F-Measure#82$Scene Text Detection#SCUT-CTW1500#Precision#86.2$Scene Text Detection#SCUT-CTW1500#Recall#78.1$Scene Text Detection#SCUT-CTW1500#FPS#112.9$Scene Text Detection#SCUT-CTW1500#F-Measure#82.8$Scene Text Detection#SCUT-CTW1500#Precision#85.9$Scene Text Detection#SCUT-CTW1500#Recall#79.9$Scene Text Detection#SCUT-CTW1500#FPS#92.6$Scene Text Detection#SCUT-CTW1500#F-Measure#81.5$Scene Text Detection#SCUT-CTW1500#Precision#85.6$Scene Text Detection#SCUT-CTW1500#Recall#77.8$Scene Text Detection#SCUT-CTW1500#FPS#129.1$Scene Text Detection#ICDAR 2015#F-Measure#87$Scene Text Detection#ICDAR 2015#Precision#89.9$Scene Text Detection#ICDAR 2015#Recall#84.4$Scene Text Detection#ICDAR 2015#FPS#15.7$Scene Text Detection#ICDAR 2015#F-Measure#85.3$Scene Text Detection#ICDAR 2015#Precision#88.6$Scene Text Detection#ICDAR 2015#Recall#82.2$Scene Text Detection#ICDAR 2015#FPS#31.8$Scene Text Detection#ICDAR 2015#F-Measure#83.7$Scene Text Detection#ICDAR 2015#Precision#87.5$Scene Text Detection#ICDAR 2015#Recall#80.3$Scene Text Detection#ICDAR 2015#FPS#42.7$Scene Text Detection#ICDAR 2015#F-Measure#81.9$Scene Text Detection#ICDAR 2015#Precision#85.9$Scene Text Detection#ICDAR 2015#Recall#78.3$Scene Text Detection#ICDAR 2015#FPS#60.9$Scene Text Detection#ICDAR 2015#F-Measure#82.7$Scene Text Detection#ICDAR 2015#Precision#85.7$Scene Text Detection#ICDAR 2015#Recall#80$Scene Text Detection#ICDAR 2015#FPS#53.9$Scene Text Detection#Total-Text#F-Measure#86.3%$Scene Text Detection#Total-Text#Precision#90.5$Scene Text Detection#Total-Text#Recall#82.5$Scene Text Detection#Total-Text#FPS#46$Scene Text Detection#Total-Text#F-Measure#85.7%$Scene Text Detection#Total-Text#Recall#81.4$Scene Text Detection#Total-Text#FPS#67.5$Scene Text Detection#Total-Text#F-Measure#85.4%$Scene Text Detection#Total-Text#Precision#89.3$Scene Text Detection#Total-Text#Recall#81.8$Scene Text Detection#Total-Text#FPS#93.2$Scene Text Detection#Total-Text#F-Measure#84.9%$Scene Text Detection#Total-Text#Precision#90.4$Scene Text Detection#Total-Text#Recall#80$Scene Text Detection#Total-Text#FPS#115.5$Scene Text Detection#Total-Text#F-Measure#81.4%$Scene Text Detection#Total-Text#Precision#88.2$Scene Text Detection#Total-Text#Recall#75.5$Scene Text Detection#Total-Text#FPS#152.8
1911.08947v2.pdf	Scene Text Detection#MSRA-TD500#Recall#79.2$Scene Text Detection#MSRA-TD500#Precision#91.5$Scene Text Detection#MSRA-TD500#F-Measure#84.9$Scene Text Detection#SCUT-CTW1500#F-Measure#83.4$Scene Text Detection#ICDAR 2015#F-Measure#87.3$Scene Text Detection#ICDAR 2015#Precision#91.8$Scene Text Detection#ICDAR 2015#Recall#83.2$Scene Text Detection#Total-Text#F-Measure#84.7%
1904.01941v1.pdf	Scene Text Detection#MSRA-TD500#Recall#78.2$Scene Text Detection#MSRA-TD500#Precision#88.2$Scene Text Detection#MSRA-TD500#H-Mean#82.9$Scene Text Detection#SCUT-CTW1500#Precision#86$Scene Text Detection#SCUT-CTW1500#Recall#81.1$Scene Text Detection#SCUT-CTW1500#H-Mean#83.5$Scene Text Detection#ICDAR 2017 MLT#Precision#80.6$Scene Text Detection#ICDAR 2017 MLT#Recall#68.2$Scene Text Detection#ICDAR 2017 MLT#H-Mean#73.9$Scene Text Detection#ICDAR 2015#Precision#89.8$Scene Text Detection#ICDAR 2015#Recall#84.3$Scene Text Detection#ICDAR 2015#H-Mean#86.9$Scene Text Detection#Total-Text#F-Measure#83.6%$Scene Text Detection#Total-Text#Precision#87.6$Scene Text Detection#Total-Text#Recall#79.9$Scene Text Detection#Total-Text#H-Mean#83.6$Scene Text Detection#ICDAR 2013#Precision#97.4$Scene Text Detection#ICDAR 2013#Recall#93.1$Scene Text Detection#ICDAR 2013#H-Mean#95.2
1709.03272v4.pdf	Scene Text Detection#MSRA-TD500#Recall#77.1$Scene Text Detection#MSRA-TD500#Precision#87.6$Scene Text Detection#MSRA-TD500#H-Mean#82$Scene Text Detection#ICDAR 2015#F-Measure#84.1$Scene Text Detection#ICDAR 2015#Precision#88.6$Scene Text Detection#ICDAR 2015#Recall#80$Scene Text Detection#Total-Text#F-Measure#81.3%$Scene Text Detection#Total-Text#Precision#84.7$Scene Text Detection#Total-Text#Recall#78
1802.08948v2.pdf	Scene Text Detection#MSRA-TD500#Recall#76.2$Scene Text Detection#MSRA-TD500#Precision#87.6$Scene Text Detection#MSRA-TD500#F-Measure#81.5$Scene Text Detection#ICDAR 2017 MLT#Precision#83.8$Scene Text Detection#ICDAR 2017 MLT#Recall#55.6$Scene Text Detection#ICDAR 2017 MLT#F-Measure#66.8%$Scene Text Detection#ICDAR 2017 MLT#Precision#74.3$Scene Text Detection#ICDAR 2017 MLT#Recall#70.6$Scene Text Detection#ICDAR 2017 MLT#F-Measure#72.4%$Scene Text Detection#ICDAR 2015#F-Measure#84.3$Scene Text Detection#ICDAR 2015#Precision#89.5$Scene Text Detection#ICDAR 2015#Recall#79.7$Scene Text Detection#ICDAR 2013#F-Measure#88%$Scene Text Detection#ICDAR 2013#Precision#92$Scene Text Detection#ICDAR 2013#Recall#84.4
1807.01544v2.pdf	Scene Text Detection#MSRA-TD500#Recall#73.9$Scene Text Detection#MSRA-TD500#Precision#83.2$Scene Text Detection#MSRA-TD500#F-Measure#78.3$Scene Text Detection#SCUT-CTW1500#F-Measure#75.6$Scene Text Detection#SCUT-CTW1500#Precision#67.9$Scene Text Detection#SCUT-CTW1500#Recall#85.3$Scene Text Detection#ICDAR 2015#F-Measure#83.7$Scene Text Detection#ICDAR 2015#Precision#85.5$Scene Text Detection#ICDAR 2015#Recall#82$Scene Text Detection#Total-Text#F-Measure#78.4%%$Scene Text Detection#Total-Text#Precision#82.7$Scene Text Detection#Total-Text#Recall#74.5$Curved Text Detection#SCUT-CTW1500#F-Measure#75.6%
1801.01315v1.pdf	Scene Text Detection#MSRA-TD500#Recall#73.2$Scene Text Detection#MSRA-TD500#Precision#83$Scene Text Detection#MSRA-TD500#F-Measure#77.8$Scene Text Detection#ICDAR 2015#F-Measure#84.5$Scene Text Detection#ICDAR 2015#Precision#85.5$Scene Text Detection#ICDAR 2015#Recall#83.6$Scene Text Detection#ICDAR 2013#F-Measure#88.1%$Scene Text Detection#ICDAR 2013#Precision#88.6$Scene Text Detection#ICDAR 2013#Recall#87.5
1803.05265v1.pdf	Scene Text Detection#MSRA-TD500#Recall#73$Scene Text Detection#MSRA-TD500#Precision#87$Scene Text Detection#MSRA-TD500#H-Mean#79
1703.06520v3.pdf	Scene Text Detection#MSRA-TD500#Recall#70$Scene Text Detection#MSRA-TD500#Precision#86$Scene Text Detection#MSRA-TD500#F-Measure#77$Scene Text Detection#ICDAR 2015#F-Measure#78.2$Scene Text Detection#ICDAR 2015#Precision#79.3$Scene Text Detection#ICDAR 2015#Recall#77.0$Scene Text Detection#ICDAR 2013#F-Measure#85.3%$Scene Text Detection#ICDAR 2013#Precision#87.7$Scene Text Detection#ICDAR 2013#Recall#83
1704.03155v2.pdf	Scene Text Detection#MSRA-TD500#Recall#67.43$Scene Text Detection#MSRA-TD500#Precision#87.28$Scene Text Detection#MSRA-TD500#F-Measure#76.08$Scene Text Detection#ICDAR 2015#F-Measure#82.9$Scene Text Detection#ICDAR 2015#Precision#84$Scene Text Detection#ICDAR 2015#Recall#81.9$Scene Text Detection#ICDAR 2015#F-Measure#78.2$Scene Text Detection#ICDAR 2015#Precision#83.6$Scene Text Detection#ICDAR 2015#Recall#73.5$Scene Text Detection#Total-Text#F-Measure#42.0%$Scene Text Detection#Total-Text#Precision#50.0$Scene Text Detection#Total-Text#Recall#36.2$Scene Text Detection#COCO-Text#F-Measure#39.45$Scene Text Detection#COCO-Text#Precision#50.39$Scene Text Detection#COCO-Text#Recall#32.4
1906.02371v3.pdf	Scene Text Detection#IC19-ReCTs#F-Measure#93.36
1811.09058v1.pdf	Scene Text Detection#SCUT-CTW1500#TIoU#65.2$Scene Text Detection#SCUT-CTW1500#F-Measure#85$Scene Text Detection#SCUT-CTW1500#Precision#86.8$Scene Text Detection#SCUT-CTW1500#Recall#83.2$Scene Text Detection#ICDAR 2017 MLT#Precision#80$Scene Text Detection#ICDAR 2017 MLT#Recall#69.8$Scene Text Detection#ICDAR 2017 MLT#F-Measure#74.3%$Scene Text Detection#ICDAR 2015#F-Measure#85.9$Scene Text Detection#ICDAR 2015#Precision#90.8$Scene Text Detection#ICDAR 2015#Recall#81.5
2108.01343v3.pdf	Scene Text Detection#SCUT-CTW1500#F-Measure#88.4$Scene Text Detection#SCUT-CTW1500#Precision#86.5$Scene Text Detection#SCUT-CTW1500#Recall#84.6$Scene Text Detection#Total-Text#F-Measure#86.9%$Scene Text Detection#Total-Text#Precision#89.8$Scene Text Detection#Total-Text#Recall#84.2
1903.12473v2.pdf	Scene Text Detection#SCUT-CTW1500#F-Measure#82.2$Scene Text Detection#SCUT-CTW1500#Precision#84.8$Scene Text Detection#SCUT-CTW1500#Recall#79.7$Scene Text Detection#ICDAR 2017 MLT#Precision#75.35$Scene Text Detection#ICDAR 2017 MLT#Recall#69.18$Scene Text Detection#ICDAR 2017 MLT#F-Measure#72.13%$Scene Text Detection#ICDAR 2015#F-Measure#85.7$Scene Text Detection#ICDAR 2015#Precision#86.9$Scene Text Detection#ICDAR 2015#Recall#84.5$Scene Text Detection#Total-Text#F-Measure#79.6%%$Scene Text Detection#Total-Text#Precision#84.5$Scene Text Detection#Total-Text#Recall#75.2
1806.02559v1.pdf	Scene Text Detection#SCUT-CTW1500#F-Measure#81.17$Scene Text Detection#SCUT-CTW1500#Precision#82.5$Scene Text Detection#SCUT-CTW1500#Recall#79.89$Scene Text Detection#ICDAR 2017 MLT#Precision#77.01$Scene Text Detection#ICDAR 2017 MLT#Recall#68.4$Scene Text Detection#ICDAR 2017 MLT#F-Measure#72.45%$Scene Text Detection#ICDAR 2015#F-Measure#87.1$Scene Text Detection#ICDAR 2015#Precision#88.7$Scene Text Detection#ICDAR 2015#Recall#85.5
1801.09969v1.pdf	Scene Text Detection#SCUT-CTW1500#Precision#80.1$Scene Text Detection#SCUT-CTW1500#Recall#70.1$Scene Text Detection#SCUT-CTW1500#H-Mean#74.8
1903.11800v1.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#84.42$Scene Text Detection#ICDAR 2017 MLT#Recall#76.25$Scene Text Detection#ICDAR 2017 MLT#F-Measure#80.13%$Scene Text Detection#ICDAR 2015#F-Measure#89.33$Scene Text Detection#ICDAR 2015#Precision#91.3$Scene Text Detection#ICDAR 2015#Recall#87.43
1912.09629v3.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#82.75$Scene Text Detection#ICDAR 2017 MLT#Recall#76.44$Scene Text Detection#ICDAR 2017 MLT#F-Measure#79.47%$Scene Text Detection#ICDAR 2015#F-Measure#90.1$Scene Text Detection#ICDAR 2015#Precision#92.1$Scene Text Detection#ICDAR 2015#Recall#88.2
1801.01671v2.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#81.86$Scene Text Detection#ICDAR 2017 MLT#Recall#62.3$Scene Text Detection#ICDAR 2017 MLT#F-Measure#70.75%$Scene Text Detection#ICDAR 2017 MLT#Precision#80.95$Scene Text Detection#ICDAR 2017 MLT#Recall#57.51$Scene Text Detection#ICDAR 2017 MLT#F-Measure#67.25%$Scene Text Detection#ICDAR 2015#F-Measure#89.84$Scene Text Detection#ICDAR 2015#Precision#91.85$Scene Text Detection#ICDAR 2015#Recall#87.92$Scene Text Detection#ICDAR 2015#F-Measure#87.99$Scene Text Detection#ICDAR 2015#Precision#91$Scene Text Detection#ICDAR 2015#Recall#85.17
1910.07954v1.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#81.27$Scene Text Detection#ICDAR 2017 MLT#Recall#70.97$Scene Text Detection#ICDAR 2017 MLT#F-Measure#75.77%$Scene Text Detection#ICDAR 2017 MLT#Precision#77.07$Scene Text Detection#ICDAR 2017 MLT#Recall#70.1$Scene Text Detection#ICDAR 2017 MLT#F-Measure#73.42%$Scene Text Detection#ICDAR 2015#F-Measure#91.55$Scene Text Detection#ICDAR 2015#Precision#92.65$Scene Text Detection#ICDAR 2015#Recall#90.47$Scene Text Detection#ICDAR 2015#F-Measure#90.06$Scene Text Detection#ICDAR 2015#Precision#91.43$Scene Text Detection#ICDAR 2015#Recall#88.74$Scene Text Detection#ICDAR 2015#F-Measure#89.7$Scene Text Detection#ICDAR 2015#Precision#91.15$Scene Text Detection#ICDAR 2015#Recall#88.3$Scene Text Detection#ICDAR 2015#F-Measure#90.16$Scene Text Detection#ICDAR 2015#Precision#90.9$Scene Text Detection#ICDAR 2015#Recall#89.44$Scene Text Detection#ICDAR 2015#F-Measure#90.97$Scene Text Detection#ICDAR 2015#Precision#89.99$Scene Text Detection#ICDAR 2015#Recall#91.98$Scene Text Detection#ICDAR 2015#F-Measure#89.66$Scene Text Detection#ICDAR 2015#Precision#88.88$Scene Text Detection#ICDAR 2015#Recall#90.45$Scene Text Detection#Total-Text#F-Measure#86.5%$Scene Text Detection#Total-Text#Precision#88$Scene Text Detection#Total-Text#Recall#85$Scene Text Detection#Total-Text#F-Measure#85.6%$Scene Text Detection#Total-Text#Precision#89.9$Scene Text Detection#Total-Text#Recall#81.7
1811.08605v1.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#80.6$Scene Text Detection#ICDAR 2017 MLT#Recall#68.6$Scene Text Detection#ICDAR 2017 MLT#F-Measure#74.1%$Scene Text Detection#ICDAR 2015#F-Measure#87.2$Scene Text Detection#ICDAR 2015#Precision#88.7$Scene Text Detection#ICDAR 2015#Recall#85.8$Scene Text Detection#Total-Text#F-Measure#82.9%$Scene Text Detection#Total-Text#Precision#83$Scene Text Detection#Total-Text#Recall#82.8$Scene Text Detection#ICDAR 2013#F-Measure#92.1%$Scene Text Detection#ICDAR 2013#Precision#93.8$Scene Text Detection#ICDAR 2013#Recall#90.5
1909.00794v1.pdf	Scene Text Detection#ICDAR 2017 MLT#Precision#79.63$Scene Text Detection#ICDAR 2017 MLT#Recall#70.06$Scene Text Detection#ICDAR 2017 MLT#F-Measure#74.54%$Scene Text Detection#ICDAR 2015#F-Measure#88.52$Scene Text Detection#ICDAR 2015#Precision#90.41$Scene Text Detection#ICDAR 2015#Recall#86.71
1807.02242v2.pdf	Scene Text Detection#ICDAR 2015#F-Measure#86$Scene Text Detection#ICDAR 2015#Precision#91.6$Scene Text Detection#ICDAR 2015#Recall#81$Scene Text Detection#Total-Text#F-Measure#61.3%$Scene Text Detection#Total-Text#Precision#69$Scene Text Detection#Total-Text#Recall#55$Scene Text Detection#ICDAR 2013#F-Measure#91.7%$Scene Text Detection#ICDAR 2013#Precision#95$Scene Text Detection#ICDAR 2013#Recall#88.6
1804.02690v2.pdf	Scene Text Detection#ICDAR 2015#F-Measure#84.5$Scene Text Detection#ICDAR 2015#Precision#88.7$Scene Text Detection#ICDAR 2015#Recall#80.7$Scene Text Detection#COCO-Text#F-Measure#59.1$Scene Text Detection#COCO-Text#Precision#55.5$Scene Text Detection#COCO-Text#Recall#63.3$Scene Text Detection#ICDAR 2013#F-Measure#87.6%%$Scene Text Detection#ICDAR 2013#Precision#91.9$Scene Text Detection#ICDAR 2013#Recall#83.9
1801.02765v3.pdf	Scene Text Detection#ICDAR 2015#F-Measure#82.9$Scene Text Detection#ICDAR 2015#Precision#87.8$Scene Text Detection#ICDAR 2015#Recall#78.5$Scene Text Detection#COCO-Text#F-Measure#58.72$Scene Text Detection#COCO-Text#Precision#60.87$Scene Text Detection#COCO-Text#Recall#56.7$Scene Text Detection#ICDAR 2013#F-Measure#88%%$Scene Text Detection#ICDAR 2013#Precision#91$Scene Text Detection#ICDAR 2013#Recall#84
1908.05498v1.pdf	Scene Text Detection#ICDAR 2015#Precision#86.72$Scene Text Detection#ICDAR 2015#Recall#87.09$Scene Text Detection#ICDAR 2015#H-Mean#86.91
1709.00138v1.pdf	Scene Text Detection#ICDAR 2015#F-Measure#80.7$Scene Text Detection#ICDAR 2015#Precision#83.3$Scene Text Detection#ICDAR 2015#Recall#78.3$Scene Text Detection#COCO-Text#F-Measure#37$Scene Text Detection#COCO-Text#Precision#46$Scene Text Detection#COCO-Text#Recall#31$Scene Text Detection#ICDAR 2013#F-Measure#87%$Scene Text Detection#ICDAR 2013#Precision#88$Scene Text Detection#ICDAR 2013#Recall#86
1708.06720v1.pdf	Scene Text Detection#ICDAR 2015#F-Measure#77$Scene Text Detection#ICDAR 2015#Precision#80$Scene Text Detection#ICDAR 2015#Recall#73$Scene Text Detection#COCO-Text#F-Measure#36.8$Scene Text Detection#COCO-Text#Precision#45.2$Scene Text Detection#COCO-Text#Recall#30.9$Scene Text Detection#ICDAR 2013#F-Measure#90.34%$Scene Text Detection#ICDAR 2013#Precision#93.34$Scene Text Detection#ICDAR 2013#Recall#87.53
1604.04018v2.pdf	Scene Text Detection#ICDAR 2015#F-Measure#75$Scene Text Detection#ICDAR 2015#Precision#73.1$Scene Text Detection#ICDAR 2015#Recall#76.8
2104.05458v1.pdf	Scene Text Detection#ICDAR 2015#F-Measure#53.6$Scene Text Detection#ICDAR 2015#Precision#70.8$Scene Text Detection#ICDAR 2015#Recall#43.0$Scene Text Detection#ICDAR 2015#Accuracy#62.3
1911.07046v3.pdf	Scene Text Detection#Total-Text#F-Measure#85.6%
1904.12640v2.pdf	Scene Text Detection#Total-Text#F-Measure#84.6%$Curved Text Detection#SCUT-CTW1500#F-Measure#86.3%
1812.01393v2.pdf	Scene Text Detection#Total-Text#F-Measure#80.6%$Scene Text Detection#Total-Text#Precision#81.2$Scene Text Detection#Total-Text#Recall#79.9
1710.10400v1.pdf	Scene Text Detection#Total-Text#F-Measure#36.0%$Scene Text Detection#Total-Text#Precision#40.0$Scene Text Detection#Total-Text#Recall#33.0
1606.09002v2.pdf	Scene Text Detection#COCO-Text#F-Measure#33.31$Scene Text Detection#COCO-Text#Precision#43.23$Scene Text Detection#COCO-Text#Recall#27.1
1707.08831v1.pdf	Scene Text Detection#ICDAR 2013#F-Measure#90.3%
1604.06646v1.pdf	Scene Text Detection#ICDAR 2013#F-Measure#83.0%$Scene Text Detection#ICDAR 2013#Precision#92.0$Scene Text Detection#ICDAR 2013#Recall#75.5
1504.03522v1.pdf	Scene Text Detection#ICDAR 2013#F-Measure#77.1%$Scene Text Detection#ICDAR 2013#Precision#81.8$Scene Text Detection#ICDAR 2013#Recall#72.4
1412.1842v1.pdf	Scene Text Detection#ICDAR 2013#F-Measure#76.8%$Scene Text Detection#ICDAR 2013#Precision#88.5$Scene Text Detection#ICDAR 2013#Recall#67.8
1712.02170v1.pdf	Curved Text Detection#SCUT-CTW1500#F-Measure#73.4%
1505.04366v1.pdf	Curved Text Detection#SCUT-CTW1500#F-Measure#73.4%$Curved Text Detection#SCUT-CTW1500#F-Measure#69.5%
2012.04150v2.pdf	Multi-Oriented Scene Text Detection#ICDAR2015#F-Measure#82.4$Object Detection In Aerial Images#DOTA#mAP#76.95%
2203.15296v2.pdf	Sound Event Detection#DESED#event-based F1 score#54.0$Sound Event Detection#DESED#PSDS1#0.452$Sound Event Detection#DESED#PSDS2#0.670
2110.11144v3.pdf	Sound Event Detection#DESED#event-based F1 score#49.62$Sound Event Detection#DESED#PSDS1#0.4395$Sound Event Detection#DESED#PSDS2#0.6711
2107.03649v3.pdf	Sound Event Detection#DESED#event-based F1 score#49.6$Sound Event Detection#DESED#PSDS1#0.4336$Sound Event Detection#DESED#PSDS2#0.8161
2007.03932v1.pdf	Sound Event Detection#DESED#event-based F1 score#40.7
2007.03931v1.pdf	Sound Event Detection#DESED#event-based F1 score#39.0$Sound Event Detection#DESED#PSDS (gtc=dtc=0.5,emax=100,cttc=0.3,ct=1,st=0)#0.552
2110.04176v2.pdf	Sound Event Detection#L3DAS21#F-Score#0.68$Sound Event Detection#L3DAS21#Error Rate#0.389$Sound Event Detection#L3DAS21#SED-score#0.638$Sound Event Detection#L3DAS21#Error Rate#0.453$Sound Event Detection#L3DAS21#SED-score#0.407$Sound Event Detection#L3DAS21#F-Score#0.588$Sound Event Detection#L3DAS21#Error Rate#0.509$Sound Event Detection#L3DAS21#SED-score#0.461$Sound Event Detection#L3DAS21#F-Score#0.58$Sound Event Detection#L3DAS21#Error Rate#0.516$Sound Event Detection#L3DAS21#SED-score#0.468$Sound Event Detection#L3DAS21#F-Score#0.553$Sound Event Detection#L3DAS21#Error Rate#0.56$Sound Event Detection#L3DAS21#SED-score#0.503
2004.04136v4.pdf	Continuous Control#Ball in cup, catch (DMControl500k)#Score#959$Continuous Control#Cheetah, run (DMControl100k)#Score#299$Continuous Control#Finger, spin (DMControl100k)#Score#767$Continuous Control#Cartpole, swingup (DMControl500k)#Score#841$Continuous Control#Cheetah, run (DMControl500k)#Score#518$Continuous Control#Reacher, easy (DMControl500k)#Score#929$Continuous Control#Cartpole, swingup (DMControl100k)#Score#582$Continuous Control#Walker, walk (DMControl100k)#Score#403$Continuous Control#Reacher, easy (DMControl100k)#Score#538$Continuous Control#Walker, walk (DMControl500k)#Score#902$Continuous Control#Ball in cup, catch (DMControl100k)#Score#769$Continuous Control#Finger, spin (DMControl500k)#Score#926$Atari Games#Atari 2600 Demon Attack#Score#834$Atari Games#Atari 2600 Krull#Score#3833.6$Atari Games#Atari 2600 Freeway#Score#27.9$Atari Games#Atari 2600 Kangaroo#Score#345.3$Atari Games#Atari 2600 Kung-Fu Master#Score#14280$Atari Games#Atari 2600 Private Eye#Score#105.2$Atari Games#Atari 2600 Breakout#Score#18.2$Atari Games#Atari 2600 Q*Bert#Score#1225.6$Atari Games#Atari 2600 Assault#Score#543.7$Atari Games#Atari 2600 Gopher#Score#801.4$Atari Games#Atari 2600 Asterix#Score#524.3$Atari Games#Atari 2600 Ms. Pacman#Score#1492.8$Atari Games#Atari 2600 Alien#Score#1148.2$Atari Games#Atari 2600 Boxing#Score#4.8$Atari Games#Atari 2600 Battle Zone#Score#11208$Atari Games#Atari 2600 Chopper Command#Score#1198$Atari Games#Atari 2600 Crazy Climber#Score#27805.6$Atari Games#Atari 2600 Seaquest#Score#408$Atari Games#Atari 2600 Frostbite#Score#924$Atari Games#Atari 2600 Up and Down#Score#2735.2$Atari Games#Atari 2600 Bank Heist#Score#193.7$Atari Games#Atari 2600 James Bond#Medium Human-Normalized Score#400.1$Atari Games#Atari 2600 Road Runner#Score#6786.7$Atari Games#Atari 2600 HERO#Score#6235.1$Atari Games#Atari 2600 Amidar#Score#232.3$Atari Games#Atari 2600 Pong#Score#2.1
2104.06303v1.pdf	Continuous Control#reacher.hard#Return#971.53$Continuous Control#finger.turn_easy#Return#972.53$Continuous Control#hopper.stand#Return#926.5$Continuous Control#quadruped.run#Return#923.54$Continuous Control#hopper.hop#Return#528.24$Continuous Control#reacher.easy#Return#982.26$Continuous Control#cartpole.balance_sparse#Return#998.14$Continuous Control#walker.run#Return#931.06$Continuous Control#cartpole.balance#Return#984.86$Continuous Control#walker.stand#Return#987.79$Continuous Control#ball_in_cup.catch#Return#977.38$Continuous Control#walker.walk#Return#975.46$Continuous Control#quadruped.walk#Return#933.77$Continuous Control#pendulum.swingup#Return#837.76$Continuous Control#cartpole.swingup_sparse#Return#846.91$Continuous Control#cheetah.run#Return#914.39$Continuous Control#finger.spin#Return#986.38$Continuous Control#cartpole.swingup#Return#868.87$Continuous Control#acrobot.swingup#Return#417.52$Continuous Control#finger.turn_hard#Return#963.07
2005.05719v2.pdf	Continuous Control#PyBullet Ant#Return#3459$Continuous Control#PyBullet Ant#Return#3267$Continuous Control#PyBullet Ant#Return#2865$Continuous Control#PyBullet Ant#Return#2859$Continuous Control#PyBullet Ant#Return#2587$Continuous Control#PyBullet Ant#Return#2560$Continuous Control#PyBullet Ant#Return#2160$Continuous Control#PyBullet Ant#Return#1967$Continuous Control#PyBullet HalfCheetah#Return#2883$Continuous Control#PyBullet HalfCheetah#Return#2850$Continuous Control#PyBullet HalfCheetah#Return#2760$Continuous Control#PyBullet HalfCheetah#Return#2687$Continuous Control#PyBullet HalfCheetah#Return#2578$Continuous Control#PyBullet HalfCheetah#Return#2254$Continuous Control#PyBullet HalfCheetah#Return#2028$Continuous Control#PyBullet HalfCheetah#Return#1652$Continuous Control#PyBullet Walker2D#Return#2341$Continuous Control#PyBullet Walker2D#Return#2215$Continuous Control#PyBullet Walker2D#Return#2106$Continuous Control#PyBullet Walker2D#Return#1989$Continuous Control#PyBullet Walker2D#Return#1776$Continuous Control#PyBullet Walker2D#Return#1238$Continuous Control#PyBullet Walker2D#Return#694$Continuous Control#PyBullet Walker2D#Return#443$Continuous Control#PyBullet Hopper#Return#2646$Continuous Control#PyBullet Hopper#Return#2508$Continuous Control#PyBullet Hopper#Return#2477$Continuous Control#PyBullet Hopper#Return#2470$Continuous Control#PyBullet Hopper#Return#2353$Continuous Control#PyBullet Hopper#Return#1622$Continuous Control#PyBullet Hopper#Return#1559$Continuous Control#PyBullet Hopper#Return#1448
2104.06294v1.pdf	Continuous Control#manipulator.insert_peg#Return#556$Continuous Control#fish.swim#Return#681.6$Continuous Control#humanoid.run#Return#643.1$Continuous Control#walker.stand#Return#887.2$Continuous Control#manipulator.insert_ball#Return#659.2$Continuous Control#walker.walk#Return#949.5$Continuous Control#cheetah.run#Return#869.9$Continuous Control#cartpole.swingup#Return#594.3$Continuous Control#finger.turn_hard#Return#759$Atari Games#Atari 2600 Tennis#Score#0$Atari Games#Atari 2600 Double Dunk#Score#23.91$Atari Games#Atari 2600 Phoenix#Score#815728.7$Atari Games#Atari 2600 Yars Revenge#Score#219838.09$Atari Games#Atari 2600 Montezuma's Revenge#Score#2500$Atari Games#Atari 2600 Demon Attack#Score#143838.04$Atari Games#Atari 2600 Krull#Score#72570.5$Atari Games#Atari 2600 Freeway#Score#33.87$Atari Games#Atari 2600 Zaxxon#Score#154131.86$Atari Games#Atari 2600 Gravitar#Score#8006.93$Atari Games#Atari 2600 Kangaroo#Score#13838$Atari Games#Atari 2600 Kung-Fu Master#Score#116726.96$Atari Games#Atari 2600 Ice Hockey#Score#41.66$Atari Games#Atari 2600 Surround#Score#9.9$Atari Games#Atari 2600 Private Eye#Score#100$Atari Games#Atari 2600 Beam Rider#Score#333077.44$Atari Games#Atari 2600 Breakout#Score#758.04$Atari Games#Atari 2600 Q*Bert#Score#94906.25$Atari Games#Atari 2600 Wizard of Wor#Score#100096.6$Atari Games#Atari 2600 Star Gunner#Score#154548.26$Atari Games#Atari 2600 Solaris#Score#5132.95$Atari Games#Atari 2600 Assault#Score#33292.22$Atari Games#Atari 2600 Tutankham#Score#347.99$Atari Games#Atari 2600 Defender#Score#557200.75$Atari Games#Atari 2600 River Raid#Score#171673.78$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#131.65$Atari Games#Atari 2600 Berzerk#Score#2705.82$Atari Games#Atari 2600 Gopher#Score#122882.5$Atari Games#Atari-57#Medium Human-Normalized Score#1331.7%$Atari Games#Atari-57#Medium Human-Normalized Score#1006.4%$Atari Games#Atari 2600 Asterix#Score#862406.65$Atari Games#Atari 2600 Enduro#Score#2365.81$Atari Games#Atari 2600 Fishing Derby#Score#73.94$Atari Games#Atari 2600 Ms. Pacman#Score#70659.76$Atari Games#Atari 2600 Robotank#Score#100.59$Atari Games#Atari 2600 Alien#Score#70192.35$Atari Games#Atari 2600 Video Pinball#Score#865543.44$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Battle Zone#Score#178716.9$Atari Games#Atari 2600 Chopper Command#Score#5989.55$Atari Games#Atari 2600 Crazy Climber#Score#158541.58$Atari Games#Atari 2600 Name This Game#Score#101197.71$Atari Games#Atari 2600 Centipede#Score#874301.64$Atari Games#Atari 2600 Skiing#Score#-30000$Atari Games#Atari 2600 Seaquest#Score#999659.18$Atari Games#Atari 2600 Frostbite#Score#374769.76$Atari Games#Atari 2600 Up and Down#Score#634898.18$Atari Games#Atari 2600 Bank Heist#Score#27219.8$Atari Games#Atari 2600 Venture#Score#1731.47$Atari Games#Atari 2600 Space Invaders#Score#3645.63$Atari Games#Atari 2600 James Bond#Score#28626.23$Atari Games#Atari 2600 Road Runner#Score#531097$Atari Games#Atari 2600 HERO#Score#37234.31$Atari Games#Atari 2600 Amidar#Score#1197.38$Atari Games#Atari 2600 Asteroids#Score#476412$Atari Games#Atari 2600 Atlantis#Score#1137475.12$Atari Games#Atari 2600 Pong#Score#20.95$Atari Games#Atari 2600 Time Pilot#Score#424011.16
1604.06778v3.pdf	Continuous Control#Simple Humanoid#Score#269.7$Continuous Control#Ant + Maze#Score#0$Continuous Control#Mountain Car (noisy observations)#Score#-60.2$Continuous Control#Double Inverted Pendulum#Score#4412.4$Continuous Control#Half-Cheetah#Score#1914$Continuous Control#Inverted Pendulum#Score#247.2$Continuous Control#Inverted Pendulum (noisy observations)#Score#10.4$Continuous Control#Full Humanoid#Score#287$Continuous Control#Cart-Pole Balancing (noisy observations)#Score#606.2$Continuous Control#Ant + Gathering#Score#-0.4$Continuous Control#Mountain Car#Score#-61.7$Continuous Control#Inverted Pendulum (limited sensors)#Score#4.5$Continuous Control#Cart-Pole Balancing (system identifications)#Score#980.3$Continuous Control#2D Walker#Score#1353.8$Continuous Control#Mountain Car (limited sensors)#Score#-64.2$Continuous Control#Acrobot (noisy observations)#Score#-149.6$Continuous Control#Hopper#Score#1183.3$Continuous Control#Mountain Car (system identifications)#Score#-61.6$Continuous Control#Acrobot (limited sensors)#Score#-83.3$Continuous Control#Inverted Pendulum (system identifications)#Score#14.1$Continuous Control#Cart-Pole Balancing#Score#4869.8$Continuous Control#Cart-Pole Balancing (limited sensors)#Score#960.2$Continuous Control#Swimmer + Maze#Score#0$Continuous Control#Swimmer + Gathering#Score#0$Continuous Control#Acrobot (system identifications)#Score#-170.9$Continuous Control#Acrobot#Score#-326$Continuous Control#Swimmer#Score#96$Continuous Control#Ant#Score#730.2
2004.13649v4.pdf	Continuous Control#DeepMind Walker Walk (Images)#Return#921$Continuous Control#DeepMind Cup Catch (Images)#Return#963$Continuous Control#DeepMind Cheetah Run (Images)#Return#660
1811.04551v5.pdf	Continuous Control#DeepMind Walker Walk (Images)#Return#890$Continuous Control#DeepMind Cup Catch (Images)#Return#914$Continuous Control#DeepMind Cheetah Run (Images)#Return#650
1709.00503v2.pdf	Continuous Control#Cart Pole (OpenAI Gym)#Score#178.3$Continuous Control#Lunar Lander (OpenAI Gym)#Score#163.5$Atari Games#Atari 2600 Beam Rider#Score#6072$Atari Games#Atari 2600 Breakout#Score#372.7$Atari Games#Atari 2600 Q*Bert#Score#243.4$Atari Games#Atari 2600 Seaquest#Score#1703.4$Atari Games#Atari 2600 Space Invaders#Score#1173.1$Atari Games#Atari 2600 Pong#Score#10.6
1801.01290v2.pdf	Continuous Control#Lunar Lander (OpenAI Gym)#Score#284.59±0.97
1802.09477v3.pdf	Continuous Control#Lunar Lander (OpenAI Gym)#Score#277.26±4.17
1509.02971v6.pdf	Continuous Control#Lunar Lander (OpenAI Gym)#Score#256.98±14.38
1707.06347v2.pdf	Continuous Control#Lunar Lander (OpenAI Gym)#Score#175.14±44.94
1811.02759v1.pdf	Steering Control#Comma.ai#MAE#0.7048$Steering Control#Udacity#MAE#1.6236$Steering Control#BDD100K#Accuracy#85.03%
2201.12094v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#95.0$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#RE (all)#4.932$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#TE (all)#0.155$Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#92.9$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#71.9
2202.06688v2.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#95$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#99.5$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#74
2110.01269v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#92.4$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#RE (all)#8.9$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#TE (all)#0.23$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#91.3$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#RE (all)#9.8$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#TE (all)#0.24$Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#85.5$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#98$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#0.79$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.12$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#97.4$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#1.04$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.17$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#97.2$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#1.00$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.18$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#96.5$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#1.17$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.22$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#54.9
2004.11540v2.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#91.3$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#RE (all)#9.5$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#TE (all)#0.25$Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#85.3$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#98.2$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#1.43$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.16$Point Cloud Registration#KITTI (FCGF setting)#Recall (0.6m, 5 degrees)#96.9$Point Cloud Registration#KITTI (FCGF setting)#RE (all)#1.62$Point Cloud Registration#KITTI (FCGF setting)#TE (all)#0.34$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#48.7
1605.03344v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#22.9
1801.09847v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#6.59$Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#6.04
1905.03304v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#3.22
1903.05711v2.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - FCGF setting)#Recall (0.3m, 15 degrees)#1.61
2203.14517v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#92$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#64.8
2011.13005v3.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#90.5$Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#89$Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#62.7$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#62.5$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#59.8$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#24
2003.03164v1.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#81.6$Point Cloud Registration#KITTI (trained on 3DMatch)#Success Rate#36.76$Point Cloud Registration#3DMatch (trained on KITTI)#Recall#0.627$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#95.8$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#95.3$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#37.2$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.563$Point Cloud Registration#KITTI#Success Rate#99.81
1811.06879v3.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#78.4$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#94.7$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#33$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.790
2103.00937v5.pdf	Point Cloud Registration#3DMatch (at least 30% overlapped - sample 5k interest points)#Recall ( correspondence RMSE below 0.2)#35.9$Point Cloud Registration#3DLoMatch (10-30% overlap)#Recall ( correspondence RMSE below 0.2)#8.4
2105.10382v3.pdf	Point Cloud Registration#KITTI (trained on 3DMatch)#Success Rate#98.92$Point Cloud Registration#3DMatch (trained on KITTI)#Recall#0.922$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#97.9$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.982$Point Cloud Registration#KITTI#Success Rate#99.82
2009.00258v2.pdf	Point Cloud Registration#KITTI (trained on 3DMatch)#Success Rate#93.51$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#94.8$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.928$Point Cloud Registration#KITTI#Success Rate#97.30
2011.12149v2.pdf	Point Cloud Registration#KITTI (trained on 3DMatch)#Success Rate#81.44$Point Cloud Registration#3DMatch (trained on KITTI)#Recall#0.845$Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#97.6$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.928$Point Cloud Registration#KITTI#Success Rate#99.10
2111.09624v1.pdf	Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#98.6
2003.05855v2.pdf	Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#97.5$Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.616
2204.03957v1.pdf	Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#96.8$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#83.5$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#81.0$3D Point Cloud Classification#ScanObjectNN#Number of params#3.9M$3D Point Cloud Classification#ScanObjectNN#FLOPs#1.19G$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.6$3D Point Cloud Classification#ModelNet40#Number of params#3.9M
1808.10322v1.pdf	Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#71.8
1802.02669v2.pdf	Point Cloud Registration#3DMatch Benchmark#Feature Matching Recall#62.3
1709.05056v1.pdf	Point Cloud Registration#ETH (trained on 3DMatch)#Recall#0.202
1807.09413v1.pdf	Point Cloud Registration#KITTI#Success Rate#95.97
2207.05483v3.pdf	Image to Point Cloud Registration#KITTI#RTE#0.74$Image to Point Cloud Registration#KITTI#RRE#2.07
1906.00139v2.pdf	Image Registration#Osteoarthritis Initiative#Dice#68.18
1903.08811v1.pdf	Image Registration#Osteoarthritis Initiative#Dice#67.59
2106.07608v1.pdf	Image Registration#DIR-LAB COPDgene#landmarks#0.83
2207.07932v1.pdf	Image Registration#FIRE#mAUC#0.755$Image Registration#FIRE#mAUC#0.72$Image Registration#FIRE#mAUC#0.552
1908.06812v3.pdf	Image Registration#FIRE#mAUC#0.622
2112.07891v4.pdf	Audio Tagging#AudioSet#mean average precision#0.467$Audio Source Separation#AudioSet#SDR#10.55
2201.01763v3.pdf	Audio-Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#1.4
1911.04890v1.pdf	Audio-Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#4.5$Lipreading#LRS3-TED#Word Error Rate (WER)#33.6
2005.05592v2.pdf	Audio-Visual Speech Recognition#LRS3-TED#Word Error Rate (WER)#6.8$Lipreading#LRS3-TED#Word Error Rate (WER)#57.8$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#84.80
1706.08474v4.pdf	Image Captioning#Flickr30k Captions test#BLEU-4#21.3$Image Captioning#Flickr30k Captions test#CIDEr#46.4$Image Captioning#Flickr30k Captions test#METEOR#20.0$Image Captioning#Flickr30k Captions test#SPICE#-
1412.2306v2.pdf	Image Captioning#Flickr30k Captions test#BLEU-4#15.7$Image Captioning#Flickr30k Captions test#CIDEr#24.7$Image Captioning#Flickr30k Captions test#METEOR#15.3$Image Captioning#Flickr30k Captions test#SPICE#-$Image Retrieval#Flickr30K 1K test#R@1#15.2$Image Retrieval#Flickr30K 1K test#R@10#50.5$Text-Image Retrieval#COCO (image as query)#Recall@10#74.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#41.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#81.1$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#70.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#25.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#66.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#53.4$Question Generation#COCO Visual Question Answering (VQA) real images 1.0 open ended#BLEU-1#62.5
2110.08484v2.pdf	Image Captioning#Flickr30k Captions test#CIDEr#31.0$Image Captioning#Flickr30k Captions test#SPICE#10.0$Image Captioning#nocaps val#CIDEr#42.2$Image Captioning#nocaps val#SPICE#8.5
2205.14100v4.pdf	Image Captioning#nocaps-XD near-domain#CIDEr#125.51$Image Captioning#nocaps-XD near-domain#B1#88.9$Image Captioning#nocaps-XD near-domain#B2#75.86$Image Captioning#nocaps-XD near-domain#B3#58.9$Image Captioning#nocaps-XD near-domain#B4#38.95$Image Captioning#nocaps-XD near-domain#ROUGE-L#63.66$Image Captioning#nocaps-XD near-domain#METEOR#32.95$Image Captioning#nocaps-XD near-domain#SPICE#16.11$Image Captioning#nocaps-XD near-domain#CIDEr#123.92$Image Captioning#nocaps-XD near-domain#B1#88.56$Image Captioning#nocaps-XD near-domain#B2#75.48$Image Captioning#nocaps-XD near-domain#B3#58.46$Image Captioning#nocaps-XD near-domain#B4#38.44$Image Captioning#nocaps-XD near-domain#ROUGE-L#63.5$Image Captioning#nocaps-XD near-domain#METEOR#32.86$Image Captioning#nocaps-XD near-domain#SPICE#15.96$Image Captioning#nocaps entire#CIDEr#124.77$Image Captioning#nocaps entire#B1#88.43$Image Captioning#nocaps entire#B2#75.02$Image Captioning#nocaps entire#B3#57.87$Image Captioning#nocaps entire#B4#37.65$Image Captioning#nocaps entire#ROUGE-L#63.19$Image Captioning#nocaps entire#METEOR#32.56$Image Captioning#nocaps entire#SPICE#16.05$Image Captioning#nocaps entire#CIDEr#123.39$Image Captioning#nocaps entire#B1#88.1$Image Captioning#nocaps entire#B2#74.81$Image Captioning#nocaps entire#B3#57.68$Image Captioning#nocaps entire#B4#37.35$Image Captioning#nocaps entire#ROUGE-L#63.12$Image Captioning#nocaps entire#METEOR#32.5$Image Captioning#nocaps entire#SPICE#15.94$Image Captioning#nocaps near-domain#CIDEr#125.51$Image Captioning#nocaps near-domain#B1#88.9$Image Captioning#nocaps near-domain#B2#75.86$Image Captioning#nocaps near-domain#B3#58.9$Image Captioning#nocaps near-domain#B4#38.95$Image Captioning#nocaps near-domain#ROUGE-L#63.66$Image Captioning#nocaps near-domain#METEOR#32.95$Image Captioning#nocaps near-domain#SPICE#16.11$Image Captioning#nocaps near-domain#CIDEr#123.92$Image Captioning#nocaps near-domain#B1#88.56$Image Captioning#nocaps near-domain#B2#75.48$Image Captioning#nocaps near-domain#B3#58.46$Image Captioning#nocaps near-domain#B4#38.44$Image Captioning#nocaps near-domain#ROUGE-L#63.5$Image Captioning#nocaps near-domain#METEOR#32.86$Image Captioning#nocaps near-domain#SPICE#15.96$Image Captioning#nocaps-XD entire#CIDEr#124.77$Image Captioning#nocaps-XD entire#B1#88.43$Image Captioning#nocaps-XD entire#B2#75.02$Image Captioning#nocaps-XD entire#B3#57.87$Image Captioning#nocaps-XD entire#B4#37.65$Image Captioning#nocaps-XD entire#ROUGE-L#63.19$Image Captioning#nocaps-XD entire#METEOR#32.56$Image Captioning#nocaps-XD entire#SPICE#16.06$Image Captioning#nocaps-XD entire#CIDEr#123.39$Image Captioning#nocaps-XD entire#B1#88.1$Image Captioning#nocaps-XD entire#B2#74.81$Image Captioning#nocaps-XD entire#B3#57.68$Image Captioning#nocaps-XD entire#B4#37.35$Image Captioning#nocaps-XD entire#ROUGE-L#63.12$Image Captioning#nocaps-XD entire#METEOR#32.5$Image Captioning#nocaps-XD entire#SPICE#15.94$Image Captioning#nocaps in-domain#CIDEr#124.18$Image Captioning#nocaps in-domain#B1#88.86$Image Captioning#nocaps in-domain#B2#75.86$Image Captioning#nocaps in-domain#B3#59.94$Image Captioning#nocaps in-domain#B4#41.1$Image Captioning#nocaps in-domain#ROUGE-L#63.82$Image Captioning#nocaps in-domain#METEOR#33.83$Image Captioning#nocaps in-domain#SPICE#16.36$Image Captioning#nocaps in-domain#CIDEr#122.4$Image Captioning#nocaps in-domain#B1#88.55$Image Captioning#nocaps in-domain#B2#76.1$Image Captioning#nocaps in-domain#B3#60.53$Image Captioning#nocaps in-domain#B4#41.65$Image Captioning#nocaps in-domain#ROUGE-L#64.02$Image Captioning#nocaps in-domain#METEOR#33.41$Image Captioning#nocaps in-domain#SPICE#16.18$Image Captioning#nocaps-XD out-of-domain#CIDEr#122.27$Image Captioning#nocaps-XD out-of-domain#B1#86.28$Image Captioning#nocaps-XD out-of-domain#B2#71.15$Image Captioning#nocaps-XD out-of-domain#B3#52.36$Image Captioning#nocaps-XD out-of-domain#B4#30.15$Image Captioning#nocaps-XD out-of-domain#ROUGE-L#60.91$Image Captioning#nocaps-XD out-of-domain#METEOR#30.15$Image Captioning#nocaps-XD out-of-domain#SPICE#15.62$Image Captioning#nocaps-XD out-of-domain#CIDEr#122.04$Image Captioning#nocaps-XD out-of-domain#B1#85.99$Image Captioning#nocaps-XD out-of-domain#B2#71.28$Image Captioning#nocaps-XD out-of-domain#B3#52.66$Image Captioning#nocaps-XD out-of-domain#B4#30.04$Image Captioning#nocaps-XD out-of-domain#ROUGE-L#60.96$Image Captioning#nocaps-XD out-of-domain#METEOR#30.45$Image Captioning#nocaps-XD out-of-domain#SPICE#15.7$Image Captioning#nocaps-XD in-domain#CIDEr#124.18$Image Captioning#nocaps-XD in-domain#B1#88.86$Image Captioning#nocaps-XD in-domain#B2#75.86$Image Captioning#nocaps-XD in-domain#B3#59.94$Image Captioning#nocaps-XD in-domain#B4#41.1$Image Captioning#nocaps-XD in-domain#ROUGE-L#63.82$Image Captioning#nocaps-XD in-domain#METEOR#33.83$Image Captioning#nocaps-XD in-domain#SPICE#16.36$Image Captioning#nocaps-XD in-domain#CIDEr#122.4$Image Captioning#nocaps-XD in-domain#B1#88.55$Image Captioning#nocaps-XD in-domain#B2#76.1$Image Captioning#nocaps-XD in-domain#B3#60.53$Image Captioning#nocaps-XD in-domain#B4#41.65$Image Captioning#nocaps-XD in-domain#ROUGE-L#64.02$Image Captioning#nocaps-XD in-domain#METEOR#33.41$Image Captioning#nocaps-XD in-domain#SPICE#16.18$Image Captioning#nocaps out-of-domain#CIDEr#122.27$Image Captioning#nocaps out-of-domain#B1#86.28$Image Captioning#nocaps out-of-domain#B2#71.15$Image Captioning#nocaps out-of-domain#B3#52.36$Image Captioning#nocaps out-of-domain#B4#30.15$Image Captioning#nocaps out-of-domain#ROUGE-L#60.91$Image Captioning#nocaps out-of-domain#METEOR#30.15$Image Captioning#nocaps out-of-domain#SPICE#15.62$Image Captioning#nocaps out-of-domain#CIDEr#122.04$Image Captioning#nocaps out-of-domain#B1#85.99$Image Captioning#nocaps out-of-domain#B2#71.28$Image Captioning#nocaps out-of-domain#B3#52.66$Image Captioning#nocaps out-of-domain#B4#30.04$Image Captioning#nocaps out-of-domain#ROUGE-L#60.96$Image Captioning#nocaps out-of-domain#METEOR#30.45$Image Captioning#nocaps out-of-domain#SPICE#15.7
2009.13682v2.pdf	Image Captioning#nocaps-XD near-domain#CIDEr#101.2$Image Captioning#nocaps-XD near-domain#B1#82.88$Image Captioning#nocaps-XD near-domain#B2#67.01$Image Captioning#nocaps-XD near-domain#B3#48.73$Image Captioning#nocaps-XD near-domain#B4#30.21$Image Captioning#nocaps-XD near-domain#ROUGE-L#58.76$Image Captioning#nocaps-XD near-domain#METEOR#30.0$Image Captioning#nocaps-XD near-domain#SPICE#14.27$Image Captioning#nocaps entire#CIDEr#114.25$Image Captioning#nocaps entire#B1#85.62$Image Captioning#nocaps entire#B2#71.36$Image Captioning#nocaps entire#B3#53.62$Image Captioning#nocaps entire#B4#34.65$Image Captioning#nocaps entire#ROUGE-L#61.2$Image Captioning#nocaps entire#METEOR#31.27$Image Captioning#nocaps entire#SPICE#14.85$Image Captioning#nocaps near-domain#CIDEr#115.54$Image Captioning#nocaps near-domain#B1#86.48$Image Captioning#nocaps near-domain#B2#72.6$Image Captioning#nocaps near-domain#B3#55.26$Image Captioning#nocaps near-domain#B4#36.31$Image Captioning#nocaps near-domain#ROUGE-L#61.9$Image Captioning#nocaps near-domain#METEOR#31.8$Image Captioning#nocaps near-domain#SPICE#15.06$Image Captioning#nocaps-XD entire#CIDEr#100.12$Image Captioning#nocaps-XD entire#B1#82.27$Image Captioning#nocaps-XD entire#B2#66.04$Image Captioning#nocaps-XD entire#B3#47.48$Image Captioning#nocaps-XD entire#B4#28.95$Image Captioning#nocaps-XD entire#ROUGE-L#58.26$Image Captioning#nocaps-XD entire#METEOR#29.47$Image Captioning#nocaps-XD entire#SPICE#14.04$Image Captioning#nocaps in-domain#CIDEr#112.82$Image Captioning#nocaps in-domain#B1#86.33$Image Captioning#nocaps in-domain#B2#72.83$Image Captioning#nocaps in-domain#B3#55.94$Image Captioning#nocaps in-domain#B4#37.97$Image Captioning#nocaps in-domain#ROUGE-L#62.48$Image Captioning#nocaps in-domain#METEOR#32.7$Image Captioning#nocaps in-domain#SPICE#15.22$Image Captioning#nocaps-XD out-of-domain#CIDEr#95.5$Image Captioning#nocaps-XD out-of-domain#B1#79.44$Image Captioning#nocaps-XD out-of-domain#B2#61.15$Image Captioning#nocaps-XD out-of-domain#B3#41.03$Image Captioning#nocaps-XD out-of-domain#B4#21.79$Image Captioning#nocaps-XD out-of-domain#ROUGE-L#55.49$Image Captioning#nocaps-XD out-of-domain#METEOR#26.56$Image Captioning#nocaps-XD out-of-domain#SPICE#12.66$Image Captioning#nocaps-XD in-domain#CIDEr#100.62$Image Captioning#nocaps-XD in-domain#B1#82.94$Image Captioning#nocaps-XD in-domain#B2#67.56$Image Captioning#nocaps-XD in-domain#B3#49.66$Image Captioning#nocaps-XD in-domain#B4#32.07$Image Captioning#nocaps-XD in-domain#ROUGE-L#59.43$Image Captioning#nocaps-XD in-domain#METEOR#30.62$Image Captioning#nocaps-XD in-domain#SPICE#14.7$Image Captioning#nocaps out-of-domain#CIDEr#110.14$Image Captioning#nocaps out-of-domain#B1#81.73$Image Captioning#nocaps out-of-domain#B2#65.48$Image Captioning#nocaps out-of-domain#B3#45.58$Image Captioning#nocaps out-of-domain#B4#25.78$Image Captioning#nocaps out-of-domain#ROUGE-L#57.57$Image Captioning#nocaps out-of-domain#METEOR#28.17$Image Captioning#nocaps out-of-domain#SPICE#13.74
2208.06551v3.pdf	Image Captioning#COCO Captions#BLEU-4#42.7$Image Captioning#COCO Captions#METEOR#30.6$Image Captioning#COCO Captions#ROUGE-L#61.1$Image Captioning#COCO Captions#CIDER#143.7$Image Captioning#COCO Captions#SPICE#24.7$Image Captioning#COCO Captions#BLEU-1#83.5$Image Captioning#COCO#CIDEr#143.7
2111.12233v2.pdf	Image Captioning#COCO Captions#BLEU-4#42.6$Image Captioning#COCO Captions#METEOR#31.4$Image Captioning#COCO Captions#CIDER#145.5$Image Captioning#COCO Captions#SPICE#25.5$Image Captioning#nocaps-XD entire#CIDEr#114.25$Image Captioning#nocaps-XD entire#B1#85.62$Image Captioning#nocaps-XD entire#B2#71.36$Image Captioning#nocaps-XD entire#B3#53.62$Image Captioning#nocaps-XD entire#B4#34.65$Image Captioning#nocaps-XD entire#ROUGE-L#61.2$Image Captioning#nocaps-XD entire#METEOR#31.27$Image Captioning#nocaps-XD entire#SPICE#14.85$Image Captioning#nocaps-val-out-domain#CIDEr#111.3$Image Captioning#nocaps-val-out-domain#SPICE#14.0$Image Captioning#nocaps-val-out-domain#Pretrain (#images)#200M$Image Captioning#nocaps-val-overall#CIDEr#113.4$Image Captioning#nocaps-val-overall#SPICE#15.0$Image Captioning#nocaps-val-overall#Pretrain (#images)#200M$Image Captioning#nocaps-val-in-domain#CIDEr#116.9$Image Captioning#nocaps-val-in-domain#SPICE#15.8$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#200M$Image Captioning#nocaps-val-in-domain#CIDEr#107.7$Image Captioning#nocaps-val-in-domain#SPICE#14.7$Image Captioning#nocaps-val-near-domain#CIDEr#113.3$Image Captioning#nocaps-val-near-domain#SPICE#15.1$Image Captioning#nocaps-val-near-domain#Pre-train (#images)#200M
2207.09666v1.pdf	Image Captioning#COCO Captions#BLEU-4#42.4$Image Captioning#COCO Captions#METEOR#30.6$Image Captioning#COCO Captions#ROUGE-L#60.7$Image Captioning#COCO Captions#CIDEr-D#144.2$Image Captioning#COCO Captions#CIDER#144.2$Image Captioning#COCO Captions#SPICE#24.3$Image Captioning#COCO Captions#BLEU-1#84.2$Image Captioning#nocaps in-domain#CIDEr#105.9$Image Captioning#nocaps in-domain#SPICE#13.6$Image Captioning#nocaps out-of-domain#CIDEr#72.6$Image Captioning#nocaps out-of-domain#SPICE#11.1
2205.04363v2.pdf	Image Captioning#COCO Captions#BLEU-4#41.3$Image Captioning#COCO Captions#CIDER#142.2$Image Captioning#COCO Captions#SPICE#24.9$Image Captioning#COCO Captions#BLEU-4#39.7$Image Captioning#COCO Captions#METEOR#30.0$Image Captioning#COCO Captions#ROUGE-L#59.5$Image Captioning#COCO Captions#CIDER#135.9$Image Captioning#COCO Captions#SPICE#23.7$Image Captioning#COCO Captions#BLEU-1#81.5
2003.14080v1.pdf	Image Captioning#COCO Captions#BLEU-4#39.7$Image Captioning#COCO Captions#METEOR#29.5$Image Captioning#COCO Captions#ROUGE-L#59.1$Image Captioning#COCO Captions#CIDEr-D#132.8$Image Captioning#COCO Captions#CIDER#132.8$Image Captioning#COCO Captions#SPICE#23.4$Image Captioning#COCO Captions#BLEU-1#80.9$Image Captioning#COCO Captions#BLEU-2#65.8$Image Captioning#COCO Captions#BLEU-3#51.5
2003.09971v2.pdf	Image Captioning#COCO Captions#BLEU-4#39.4$Image Captioning#COCO Captions#METEOR#28.9$Image Captioning#COCO Captions#ROUGE-L#58.7$Image Captioning#COCO Captions#CIDER#129.6$Image Captioning#COCO Captions#SPICE#22.8$Image Captioning#COCO Captions#BLEU-1#80.7$Image Captioning#COCO Captions#BLEU-2#65.6$Image Captioning#COCO Captions#BLEU-3#51.3
1912.08226v2.pdf	Image Captioning#COCO Captions#BLEU-4#39.1$Image Captioning#COCO Captions#METEOR#29.2$Image Captioning#COCO Captions#ROUGE-L#58.6$Image Captioning#COCO Captions#CIDER#131.2$Image Captioning#COCO Captions#SPICE#22.6$Image Captioning#COCO Captions#BLEU-1#80.8$Image Captioning#COCO#CIDEr#131.2
2109.03529v1.pdf	Image Captioning#COCO Captions#BLEU-4#37.8$Image Captioning#COCO Captions#METEOR#28.3$Image Captioning#COCO Captions#ROUGE-L#58.0$Image Captioning#COCO Captions#CIDEr-D#127.2$Image Captioning#COCO Captions#CIDER#127.2$Image Captioning#COCO Captions#SPICE#22.5$Image Captioning#COCO Captions#BLEU-1#80.2$Image Captioning#COCO Captions#BLEU-2#64.5$Image Captioning#COCO Captions#BLEU-3#49.9
1908.11824v1.pdf	Image Captioning#COCO Captions#BLEU-4#37.3$Image Captioning#COCO Captions#METEOR#28.1$Image Captioning#COCO Captions#ROUGE-L#57.4$Image Captioning#COCO Captions#CIDEr-D#125.2$Image Captioning#COCO Captions#CIDER#125.2$Image Captioning#COCO Captions#BLEU-1#80.2$Image Captioning#COCO#CIDEr#125.2
2111.09734v1.pdf	Image Captioning#COCO Captions#BLEU-4#33.53$Image Captioning#COCO Captions#METEOR#27.45$Image Captioning#COCO Captions#CIDER#113.08$Image Captioning#COCO Captions#SPICE#21.05$Image Captioning#COCO Captions#BLEU-4#32.15$Image Captioning#COCO Captions#METEOR#27.1$Image Captioning#COCO Captions#CIDER#108.35$Image Captioning#COCO Captions#SPICE#20.12$Image Captioning#nocaps entire#CIDEr#65.83$Image Captioning#nocaps entire#SPICE#10.86$Image Captioning#nocaps entire#CIDEr#65.7$Image Captioning#nocaps entire#SPICE#11.1$Image Captioning#nocaps near-domain#CIDEr#67.69$Image Captioning#nocaps near-domain#SPICE#11.26$Image Captioning#nocaps near-domain#CIDEr#66.82$Image Captioning#nocaps near-domain#SPICE#10.92$Image Captioning#nocaps in-domain#CIDEr#84.85$Image Captioning#nocaps in-domain#SPICE#12.14$Image Captioning#nocaps in-domain#CIDEr#79.73$Image Captioning#nocaps in-domain#SPICE#12.2$Image Captioning#Conceptual Captions#ROUGE-L#26.71$Image Captioning#Conceptual Captions#CIDEr#87.26$Image Captioning#Conceptual Captions#SPICE#18.5$Image Captioning#Conceptual Captions#ROUGE-L#25.12$Image Captioning#Conceptual Captions#CIDEr#71.82$Image Captioning#Conceptual Captions#SPICE#16.07$Image Captioning#nocaps out-of-domain#CIDEr#49.35$Image Captioning#nocaps out-of-domain#SPICE#9.7$Image Captioning#nocaps out-of-domain#CIDEr#49.14$Image Captioning#nocaps out-of-domain#SPICE#9.57
1411.4952v3.pdf	Image Captioning#COCO Captions#BLEU-4#25.7$Image Captioning#COCO Captions#METEOR#23.6$Image Captioning#COCO Captions test#BLEU-4#56.7$Image Captioning#COCO Captions test#CIDEr#92.5$Image Captioning#COCO Captions test#METEOR#33.1
2006.06666v3.pdf	Image Captioning#COCO Captions#CIDER#94$Image Captioning#COCO Captions#SPICE#18.5$Object Detection#COCO test-dev#AP50#61.7$Object Detection#COCO test-dev#AP75#44.8$Object Detection#COCO minival#box AP#40.9$Instance Segmentation#COCO test-dev#mask AP#36.9$Instance Segmentation#COCO test-dev#AP50#58.4$Instance Segmentation#COCO test-dev#AP75#39.7
2102.07192v1.pdf	Image Captioning#BanglaLekhaImageCaptions#BLEU-1#65.1$Image Captioning#BanglaLekhaImageCaptions#BLEU-2#42.6$Image Captioning#BanglaLekhaImageCaptions#BLEU-3#27.8$Image Captioning#BanglaLekhaImageCaptions#BLEU-4#17.5$Image Captioning#BanglaLekhaImageCaptions#METEOR#29.7$Image Captioning#BanglaLekhaImageCaptions#ROUGE-L#43.4$Image Captioning#BanglaLekhaImageCaptions#CIDEr#57.2$Image Captioning#BanglaLekhaImageCaptions#SPICE#35.7
2111.14447v2.pdf	Image Captioning#COCO Captions Karpathy Test#BLEU-4#2.6$Image Captioning#COCO Captions Karpathy Test#CIDEr#14.6$Image Captioning#COCO Captions Karpathy Test#METEOR#11.5$Image Captioning#COCO Captions Karpathy Test#SPICE#5.5
2103.06561v6.pdf	Image Captioning#AIC-ICC#BLEU#66.1$Image Captioning#AIC-ICC#METEOR#41.1$Image Captioning#AIC-ICC#ROUGE-L#71.9$Image Captioning#AIC-ICC#CIDEr#220.7
2201.12086v2.pdf	Image Captioning#nocaps-val-out-domain#CIDEr#115.3$Image Captioning#nocaps-val-out-domain#SPICE#14.4$Image Captioning#nocaps-val-out-domain#Pretrain (#images)#129M$Image Captioning#nocaps-val-out-domain#CIDEr#111.5$Image Captioning#nocaps-val-out-domain#SPICE#14.2$Image Captioning#nocaps-val-overall#CIDEr#113.2$Image Captioning#nocaps-val-overall#SPICE#14.8$Image Captioning#nocaps-val-overall#Pretrain (#images)#129M$Image Captioning#nocaps-val-overall#CIDEr#109.6$Image Captioning#nocaps-val-overall#SPICE#14.7$Image Captioning#nocaps-val-in-domain#CIDEr#114.9$Image Captioning#nocaps-val-in-domain#SPICE#15.2$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#129M$Image Captioning#nocaps-val-in-domain#CIDEr#111.8$Image Captioning#nocaps-val-in-domain#SPICE#14.9$Image Captioning#nocaps-val-near-domain#CIDEr#112.1$Image Captioning#nocaps-val-near-domain#SPICE#14.9$Image Captioning#nocaps-val-near-domain#Pre-train (#images)#129M$Image Captioning#nocaps-val-near-domain#CIDEr#108.6$Image Captioning#nocaps-val-near-domain#SPICE#14.8
2102.08981v2.pdf	Image Captioning#nocaps-val-out-domain#CIDEr#94.5$Image Captioning#nocaps-val-out-domain#SPICE#11.9$Image Captioning#nocaps-val-overall#CIDEr#90.2$Image Captioning#nocaps-val-overall#SPICE#12.1$Image Captioning#nocaps-val-in-domain#CIDEr#92.6$Image Captioning#nocaps-val-in-domain#SPICE#12.5$Image Captioning#nocaps-val-in-domain#Pre-train (#images)#15M$Image Captioning#nocaps-val-near-domain#CIDEr#88.3$Image Captioning#nocaps-val-near-domain#SPICE#12.1
1912.03098v4.pdf	Image Captioning#Localized Narratives#CIDEr#106.5
2012.15409v4.pdf	Image Captioning#COCO#BLEU-4#39.6$Image Captioning#COCO#CIDEr#127.7
2208.04202v1.pdf	Image Captioning#COCO#BLEU-4#34.7$Image Captioning#COCO#CIDEr#115$Image Captioning#COCO#ROUGE-L#58
2110.11624v2.pdf	Image Captioning#SCICAP#BLEU-4#0.0219$Image Captioning#SCICAP#BLEU-4#0.0213$Image Captioning#SCICAP#BLEU-4#0.0212$Image Captioning#SCICAP#BLEU-4#0.0207$Image Captioning#SCICAP#BLEU-4#0.0205$Image Captioning#SCICAP#BLEU-4#0.0202$Image Captioning#SCICAP#BLEU-4#0.0172$Image Captioning#SCICAP#BLEU-4#0.0168$Image Captioning#SCICAP#BLEU-4#0.0165
2010.03855v3.pdf	Relational Captioning#relational captioning dataset#Image-Level Recall#45.96
1903.05942v4.pdf	Relational Captioning#relational captioning dataset#Image-Level Recall#34.27
1804.00819v1.pdf	Video Captioning#YouCook2#BLEU-3#7.53$Video Captioning#YouCook2#BLEU-4#4.38$Video Captioning#YouCook2#METEOR#11.55$Video Captioning#YouCook2#ROUGE-L#27.44$Video Captioning#YouCook2#CIDEr#0.38
2011.11760v1.pdf	Video Captioning#YouCook2#BLEU-4#12.04$Video Captioning#YouCook2#METEOR#18.32$Video Captioning#YouCook2#ROUGE-L#39.03$Video Captioning#YouCook2#CIDEr#1.22$Dense Video Captioning#YouCook2#ROUGE-L#39.03
2002.11566v1.pdf	Video Captioning#MSR-VTT#CIDEr#50.9$Video Captioning#MSR-VTT#METEOR#28.8$Video Captioning#MSR-VTT#ROUGE-L#62.1$Video Captioning#MSR-VTT#BLEU-4#43.6$Video Captioning#MSVD#CIDEr#95.2$Video Captioning#MSVD#BLEU-4#54.3$Video Captioning#MSVD#METEOR#36.4$Video Captioning#MSVD#ROUGE-L#73.9$Video Captioning#VATEX#BLEU-4#32.1$Video Captioning#VATEX#CIDEr#49.7$Video Captioning#VATEX#METEOR#22.2$Video Captioning#VATEX#ROUGE-L#48.9
2206.12972v2.pdf	Video Captioning#ActivityNet Captions#ROUGE-L#35.99$Video Captioning#ActivityNet Captions#METEOR#17.48$Video Captioning#ActivityNet Captions#BLEU4#13.38$Video Captioning#ActivityNet Captions#CIDEr#31.29
2005.05402v1.pdf	Video Captioning#ActivityNet Captions#METEOR#15.68$Video Captioning#ActivityNet Captions#BLEU4#10.33$Video Captioning#ActivityNet Captions#CIDEr#23.42
2006.04058v2.pdf	Video Captioning#VATEX#BLEU-4#20.0$Video Captioning#VATEX#CIDEr#24.0$Video Captioning#VATEX#METEOR#18.0$Video Captioning#VATEX#ROUGE-L#42.0
2006.07896v1.pdf	Dense Video Captioning#ActivityNet Captions#METEOR#11.28
2006.11693v2.pdf	Dense Video Captioning#ActivityNet Captions#METEOR#9.71
2108.07781v2.pdf	Dense Video Captioning#ActivityNet Captions#METEOR#9.03$Dense Video Captioning#ActivityNet Captions#BLEU-4#2.17$Dense Video Captioning#ActivityNet Captions#CIDEr#31.14$Dense Video Captioning#ActivityNet Captions#SODA#6.05$Dense Video Captioning#YouCook2#METEOR#4.74$Dense Video Captioning#YouCook2#CIDEr#22.71$Dense Video Captioning#YouCook2#BLEU4#0.8$Dense Video Captioning#YouCook2#SODA#4.42
2003.07758v2.pdf	Dense Video Captioning#ActivityNet Captions#METEOR#7.31$Dense Video Captioning#ActivityNet Captions#BLEU-3#2.6$Dense Video Captioning#ActivityNet Captions#BLEU-4#1.07
2008.09285v2.pdf	Robot Navigation#Habitat 2020 Point Nav test-std#SPL#0.22$Robot Navigation#Habitat 2020 Point Nav test-std#SOFT_SPL#0.473$Robot Navigation#Habitat 2020 Point Nav test-std#DISTANCE_TO_GOAL#2.567$Robot Navigation#Habitat 2020 Point Nav test-std#SUCCESS#0.289
2009.03231v1.pdf	Robot Navigation#Habitat 2020 Point Nav test-std#SPL#0.119$Robot Navigation#Habitat 2020 Point Nav test-std#SOFT_SPL#0.586$Robot Navigation#Habitat 2020 Point Nav test-std#DISTANCE_TO_GOAL#2.232$Robot Navigation#Habitat 2020 Point Nav test-std#SUCCESS#0.157
2104.04112v2.pdf	Robot Navigation#Habitat 2020 Object Nav test-std#SPL#0.08378$Robot Navigation#Habitat 2020 Object Nav test-std#SOFT_SPL#0.1655$Robot Navigation#Habitat 2020 Object Nav test-std#DISTANCE_TO_GOAL#9.14796$Robot Navigation#Habitat 2020 Object Nav test-std#SUCCESS#0.21082
2007.00643v2.pdf	Robot Navigation#Habitat 2020 Object Nav test-std#SPL#0.07073$Robot Navigation#Habitat 2020 Object Nav test-std#SOFT_SPL#0.14506$Robot Navigation#Habitat 2020 Object Nav test-std#DISTANCE_TO_GOAL#8.81774$Robot Navigation#Habitat 2020 Object Nav test-std#SUCCESS#0.17854
1911.00357v2.pdf	Robot Navigation#Habitat 2020 Object Nav test-std#SPL#0.02119$Robot Navigation#Habitat 2020 Object Nav test-std#SOFT_SPL#0.14718$Robot Navigation#Habitat 2020 Object Nav test-std#DISTANCE_TO_GOAL#9.31617$Robot Navigation#Habitat 2020 Object Nav test-std#SUCCESS#0.06165$PointGoal Navigation#Gibson PointGoal Navigation#spl#0.917
1904.01201v2.pdf	PointGoal Navigation#Gibson PointGoal Navigation#spl#0.79
2009.00402v1.pdf	Visual Navigation#AI2-THOR#SPL (All)#17.27$Visual Navigation#AI2-THOR#Success Rate (All)#48.7$Visual Navigation#AI2-THOR#SPL (L≥5)#13.63$Visual Navigation#AI2-THOR#Success Rate (L≥5)#30.9
1812.00971v2.pdf	Visual Navigation#AI2-THOR#SPL (All)#16.15$Visual Navigation#AI2-THOR#Success Rate (All)#40.86$Visual Navigation#AI2-THOR#SPL (L≥5)#13.91$Visual Navigation#AI2-THOR#Success Rate (L≥5)#28.7
2005.04625v2.pdf	Visual Navigation#Cooperative Vision-and-Dialogue Navigation#dist_to_end_reduction#4.46$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#spl#0.23$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#dist_to_end_reduction#3.65$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#spl#0.11
2003.00443v5.pdf	Visual Navigation#Cooperative Vision-and-Dialogue Navigation#dist_to_end_reduction#3.91$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#spl#0.17$Vision and Language Navigation#VLN Challenge#success#0.45$Vision and Language Navigation#VLN Challenge#length#13.35$Vision and Language Navigation#VLN Challenge#error#6.03$Vision and Language Navigation#VLN Challenge#oracle success#0.56$Vision and Language Navigation#VLN Challenge#spl#0.4
1907.04957v3.pdf	Visual Navigation#Cooperative Vision-and-Dialogue Navigation#dist_to_end_reduction#2.35$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#spl#0.16$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#dist_to_end_reduction#1.76$Visual Navigation#Cooperative Vision-and-Dialogue Navigation#spl#0.15
2002.10638v2.pdf	Visual Navigation#Help, Anna! (HANNA)#spl#28.72$Visual Navigation#R2R#spl#0.51
1809.04474v1.pdf	Visual Navigation#Dmlab-30#Medium Human-Normalized Score#72.8%$Atari Games#Atari-57#Medium Human-Normalized Score#110.7%
1811.10092v2.pdf	Visual Navigation#R2R#spl#0.38$Vision-Language Navigation#Room2Room#spl#0.59
1711.07280v3.pdf	Visual Navigation#R2R#spl#0.18
2005.02071v1.pdf	Muscle Tendon Junction Identification#deepMTJ v1#MAE#2.55 +/- 1.0 mm
2202.05199v1.pdf	Muscle Tendon Junction Identification#deepMTJ#RMSE#4.89 mm
1811.10907v2.pdf	Image Retrieval#Oxf105k#MAP#95.2%$Image Retrieval#Par106k#mAP#96.2%$Image Retrieval#Par6k#mAP#97.8%$Image Retrieval#Oxf5k#MAP#96.2%
1612.06321v4.pdf	Image Retrieval#Oxf105k#MAP#88.5%$Image Retrieval#Oxf105k#MAP#82.6%$Image Retrieval#Par106k#mAP#92.8%$Image Retrieval#Par106k#mAP#81.7%$Image Retrieval#Par6k#mAP#95.7%$Image Retrieval#Par6k#mAP#85.0%$Image Retrieval#Oxf5k#MAP#90.0%$Image Retrieval#Oxf5k#MAP#83.8%
1604.01325v2.pdf	Image Retrieval#Oxf105k#MAP#87.8%$Image Retrieval#Par106k#mAP#90.5%$Image Retrieval#Par6k#mAP#93.8%$Image Retrieval#Oxf5k#MAP#89%
1707.09862v2.pdf	Image Retrieval#Oxf105k#MAP#87.2%$Image Retrieval#Oxf105k#MAP#31.3%$Image Retrieval#Paris6k#mAP#96.6$Image Retrieval#INSTRE#MAP#82.4$Image Retrieval#Oxf5k#MAP#92%$Image Retrieval#Oxf5k#MAP#83.5%$Image Retrieval#Oxf5k#MAP#82.6%$Image Retrieval#Oxf5k#MAP#77.9%$Image Retrieval#Oxf5k#MAP#62.2%$Image Retrieval#Oxf5k#MAP#51.7%
1604.02426v3.pdf	Image Retrieval#Oxf105k#MAP#77.9%$Image Retrieval#Par106k#mAP#78.3%$Image Retrieval#Par6k#mAP#85.6%$Image Retrieval#Oxf5k#MAP#82.9%
1511.05879v2.pdf	Image Retrieval#Oxf105k#MAP#73.2%$Image Retrieval#Oxf105k#MAP#61.6%$Image Retrieval#Par106k#mAP#79.8%$Image Retrieval#Par106k#mAP#75.7%$Image Retrieval#Par6k#mAP#86.5%$Image Retrieval#Par6k#mAP#83.0%
1908.09943v1.pdf	Image Retrieval#DeepFashion#Recall@20#84.6
2204.02287v2.pdf	Image Retrieval#AmsterTime#mAP#60$Visual Place Recognition#Pittsburgh-30k-test#Recall@1#90.4$Visual Place Recognition#Pittsburgh-30k-test#Recall@5#95.7$Visual Place Recognition#Pittsburgh-30k-test#Recall@10#96.7$Visual Place Recognition#SF-XL test v1#Recall@1#64.7$Visual Place Recognition#SF-XL test v1#Recall@5#73.3$Visual Place Recognition#SF-XL test v1#Recall@10#76.6$Visual Place Recognition#St Lucia#Recall@1#99.7$Visual Place Recognition#St Lucia#Recall@5#99.9$Visual Place Recognition#St Lucia#Recall@10#99.9$Visual Place Recognition#SF-XL test v2#Recall@1#83.4$Visual Place Recognition#SF-XL test v2#Recall@5#91.6$Visual Place Recognition#SF-XL test v2#Recall@10#94.1$Visual Place Recognition#Mapillary val#Recall@1#86.7$Visual Place Recognition#Mapillary val#Recall@5#92.1$Visual Place Recognition#Mapillary val#Recall@10#93.4$Visual Place Recognition#Tokyo247#Recall@1#88.6$Visual Place Recognition#Tokyo247#Recall@5#95.9$Visual Place Recognition#Tokyo247#Recall@10#96.5$Visual Place Recognition#Pittsburgh-250k-test#Recall@1#91.8$Visual Place Recognition#Pittsburgh-250k-test#Recall@5#97.5$Visual Place Recognition#Pittsburgh-250k-test#Recall@10#98.6$Image Classification#AmsterTime#Accuracy#0.88
2203.16291v2.pdf	Image Retrieval#AmsterTime#mAP#35$Image Classification#AmsterTime#Accuracy#0.84
2004.01804v2.pdf	Image Retrieval#Google Landmarks Dataset v2 (retrieval, validation)#mAP@100#22.2$Image Retrieval#ROxford (Hard)#mAP#51.6$Image Retrieval#RParis (Medium)#mAP#84.9$Image Retrieval#RParis (Hard)#mAP#70.3$Image Retrieval#ROxford (Medium)#mAP#74.2$Image Retrieval#Google Landmarks Dataset v2 (retrieval, testing)#mAP@100#24.15$Landmark Recognition#Google Landmarks Dataset v2 (recognition, testing)#microAP#56.35$Landmark Recognition#Google Landmarks Dataset v2 (recognition, validation)#microAP#55.01
1902.05509v2.pdf	Image Retrieval#INRIA Holidays#Mean mAP#92.5%$Image Retrieval#INRIA Holidays#Mean mAP#91.8%$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Top 5 Accuracy#96.7%$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Top 1 Accuracy#83.0%$Image Classification#ImageNet#Top 5 Accuracy#96.5%$Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Top 1 Accuracy#81.3%$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Top 5 Accuracy#94.8%$Image Classification#ImageNet#Top 1 Accuracy#78.2%$Image Classification#ImageNet#Top 5 Accuracy#93.9%$Image Classification#ImageNet#Top 1 Accuracy#75.1%$Image Classification#ImageNet#Top 5 Accuracy#92.5%
2101.01368v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#58.5$Image Retrieval#Flickr30K 1K test#R@10#88.8$Image Retrieval#Flickr30K 1K test#R@5#83.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#57.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#91.6$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#84.9$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#41.9$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#81.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#70.7$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#77.8$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#97.4$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#94.1$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#58.5$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#88.8$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#83.0
2106.02400v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#57.4$Image Retrieval#Flickr30K 1K test#R@10#90.2$Image Retrieval#Flickr30K 1K test#R@5#84.1
2101.00265v2.pdf	Image Retrieval#Flickr30K 1K test#R@1#57.4$Image Retrieval#Flickr30K 1K test#R@10#88.1$Image Retrieval#Flickr30K 1K test#R@5#82.0$Text-Image Retrieval#Flickr30k#recall@1#57.4$Text-Image Retrieval#Flickr30k#recall@5#82.0$Text-Image Retrieval#Flickr30k#recall@10#88.1$Text-Image Retrieval#Flickr30k#QPS#451.4$Text-Image Retrieval#MSCOCO-1k#recall@1#68.2$Text-Image Retrieval#MSCOCO-1k#recall@5#91.8$Text-Image Retrieval#MSCOCO-1k#recall@10#96.3$Text-Image Retrieval#MSCOCO-1k#QPS#451.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#44.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#82.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#72.8
2008.05231v2.pdf	Image Retrieval#Flickr30K 1K test#R@1#56.5$Image Retrieval#Flickr30K 1K test#R@10#88.2$Image Retrieval#Flickr30K 1K test#R@5#81.2$Image Retrieval#Flickr30K 1K test#R@1#55.7$Image Retrieval#Flickr30K 1K test#R@10#89.3$Image Retrieval#Flickr30K 1K test#R@5#83.1
1909.02701v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#54.7$Image Retrieval#Flickr30K 1K test#R@10#88.2$Image Retrieval#Flickr30K 1K test#R@5#81.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#53.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#89.4$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#81.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#40.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#81.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#70.6
1909.05506v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#51.5$Image Retrieval#Flickr30K 1K test#R@10#85.3$Image Retrieval#Flickr30K 1K test#R@5#77.1
1803.08024v2.pdf	Image Retrieval#Flickr30K 1K test#R@1#44.0$Image Retrieval#Flickr30K 1K test#R@10#82.6$Image Retrieval#Flickr30K 1K test#R@5#74.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#50.4$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#90.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#82.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#38.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#80.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#69.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#67.4$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#95.8$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#90.3$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#48.6$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#85.2$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#77.7
1712.02036v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#41.1$Image Retrieval#Flickr30K 1K test#R@10#80.1$Image Retrieval#Flickr30K 1K test#R@5#70.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#42.8$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#83.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#72.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#33.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#75.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#62.9$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#55.5$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#89.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#82.0$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#41.1$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#80.1$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#70.5
1608.07973v3.pdf	Image Retrieval#Flickr30K 1K test#R@1#36.0
1611.05588v1.pdf	Image Retrieval#Flickr30K 1K test#R@1#30.2$Image Retrieval#Flickr30K 1K test#R@10#72.3
1511.06078v2.pdf	Image Retrieval#Flickr30K 1K test#R@1#29.7$Image Retrieval#Flickr30K 1K test#R@10#72.1$Image Retrieval#Flickr30K 1K test#R@5#60.1
1504.06063v5.pdf	Image Retrieval#Flickr30K 1K test#R@1#26.2$Image Retrieval#Flickr30K 1K test#R@10#69.6$Image Retrieval#Flickr30K 1K test#R@5#56.3
1505.04870v4.pdf	Image Retrieval#Flickr30K 1K test#R@1#24.7$Image Retrieval#Flickr30K 1K test#R@10#66.8$Image Retrieval#Flickr30K 1K test#R@5#53.4
2108.11179v2.pdf	Image Retrieval#iNaturalist#R@1#83.0$Image Retrieval#iNaturalist#R@5#92.1$Image Retrieval#iNaturalist#R@16#95.9$Image Retrieval#iNaturalist#R@32#97.2$Image Retrieval#iNaturalist#R@1#71.8$Image Retrieval#iNaturalist#R@5#84.7$Image Retrieval#iNaturalist#R@16#91.9$Image Retrieval#iNaturalist#R@32#94.3$Vehicle Re-Identification#VehicleID Medium#Rank-1#95.2$Vehicle Re-Identification#VehicleID Medium#Rank-5#97.2$Vehicle Re-Identification#VehicleID Medium#Rank-1#94.6$Vehicle Re-Identification#VehicleID Medium#Rank-5#96.9$Vehicle Re-Identification#VehicleID Small#Rank-1#96.2$Vehicle Re-Identification#VehicleID Small#Rank-5#98.0$Vehicle Re-Identification#VehicleID Small#Rank-1#95.7$Vehicle Re-Identification#VehicleID Small#Rank-5#97.9$Vehicle Re-Identification#VehicleID Large#Rank-1#94.7$Vehicle Re-Identification#VehicleID Large#Rank-5#97.1$Vehicle Re-Identification#VehicleID Large#Rank-1#93.8$Vehicle Re-Identification#VehicleID Large#Rank-5#96.6$Metric Learning#Stanford Online Products#R@1#82.7$Metric Learning#CARS196#R@1#89.5$Metric Learning#CARS196#R@1#88.3
2110.01445v3.pdf	Image Retrieval#iNaturalist#R@1#73.6$Image Retrieval#iNaturalist#R@5#86.2$Image Retrieval#iNaturalist#R@16#93.1$Image Retrieval#iNaturalist#R@32#95.2$Image Retrieval#iNaturalist#R@1#69.1$Image Retrieval#iNaturalist#R@5#83.1$Image Retrieval#iNaturalist#R@16#91.3$Image Retrieval#iNaturalist#R@32#93.9$Image Retrieval#SOP#R@1#86.0$Image Retrieval#SOP#R@1#83.1$Image Retrieval#CUB-200-2011#R@1#77.4$Image Retrieval#CUB-200-2011#R@1#68.5$Metric Learning#Stanford Online Products#R@1#86.0$Metric Learning#Stanford Online Products#R@1#83.1
2007.12163v2.pdf	Image Retrieval#iNaturalist#R@1#67.2$Image Retrieval#iNaturalist#R@5#81.8$Image Retrieval#iNaturalist#R@16#90.3$Image Retrieval#iNaturalist#R@32#93.1$Image Retrieval#SOP#R@1#80.1$Vehicle Re-Identification#VehicleID Medium#Rank-1#93.3$Vehicle Re-Identification#VehicleID Medium#Rank-5#96.4$Vehicle Re-Identification#VehicleID Small#Rank-1#94.9$Vehicle Re-Identification#VehicleID Small#Rank-5#97.6$Vehicle Re-Identification#VehicleID Large#Rank-1#91.9$Vehicle Re-Identification#VehicleID Large#Rank-5#96.2
1903.10663v4.pdf	Image Retrieval#CARS196#R@1#94.8$Image Retrieval#SOP#R@1#84.2$Image Retrieval#CUB-200-2011#R@1#79.2$Image Retrieval#In-Shop#R@1#91.9
2004.01113v2.pdf	Image Retrieval#CARS196#R@1#90.1$Image Retrieval#SOP#R@1#81.4$Image Retrieval#CUB-200-2011#R@1#72.2$Image Retrieval#In-Shop#R@1#90.9$Metric Learning#Stanford Online Products#R@1#80.7$Metric Learning#In-Shop#R@1#90.9$Metric Learning#CARS196#R@1#86.5$Metric Learning#CUB-200-2011#R@1#69.0
1811.12649v2.pdf	Image Retrieval#CARS196#R@1#89.3$Image Retrieval#SOP#R@1#79.5$Image Retrieval#CUB-200-2011#R@1#65.3$Image Retrieval#In-Shop#R@1#89.4
1706.07567v2.pdf	Image Retrieval#CARS196#R@1#86.9$Metric Learning#CARS196#R@1#79.6$Metric Learning#CUB-200-2011#R@1#63.6
1904.06627v3.pdf	Image Retrieval#CARS196#R@1#84.1$Image Retrieval#SOP#R@1#78.2$Image Retrieval#CUB-200-2011#R@1#65.7$Image Retrieval#In-Shop#R@1#89.7
1904.04370v2.pdf	Image Retrieval#CARS196#R@1#82.7$Image Retrieval#SOP#R@1#78.3$Image Retrieval#CUB-200-2011#R@1#64.9$Image Retrieval#In-Shop#R@1#87.8$Metric Learning#Stanford Online Products#R@1#78.3$Metric Learning#In-Shop#R@1#87.8$Metric Learning#CARS196#R@1#82.7$Metric Learning#CARS196#R@1#75.5$Metric Learning#CUB-200-2011#R@1#64.9$Metric Learning#CUB-200-2011#R@1#57.3
1810.06951v1.pdf	Image Retrieval#CARS196#R@1#81.4
1901.03546v1.pdf	Image Retrieval#street2shop - topwear#Accuracy#94.98
1903.00905v2.pdf	Image Retrieval#street2shop - topwear#Accuracy#93.69
1912.06798v3.pdf	Image Retrieval#SOP#R@1#80.6$Image Retrieval#In-Shop#R@1#91.3
1804.00382v2.pdf	Image Retrieval#SOP#R@1#76.3$Image Retrieval#In-Shop#R@1#87.3$Metric Learning#CARS196#R@1#85.2$Metric Learning#CUB-200-2011#R@1#60.6
1801.04815v1.pdf	Image Retrieval#SOP#R@1#74.2
1611.05720v2.pdf	Image Retrieval#SOP#R@1#69.5$Metric Learning#CUB-200-2011#R@1#60.7
1902.00153v1.pdf	Image Retrieval#NUS-WIDE#MAP#0.801$Quantization#CIFAR-10#MAP#0.792
2003.04094v1.pdf	Image Retrieval#Exact Street2Shop#mAP#46.8$Image Retrieval#Exact Street2Shop#Rank-1#53.7$Image Retrieval#Exact Street2Shop#Rank-10#69.8$Image Retrieval#Exact Street2Shop#Rank-20#73.6$Image Retrieval#DeepFashion - Consumer-to-shop#mAP#43.0$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-1#37.8$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-10#71.1$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-20#77.2$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-50#84.1
1908.11754v1.pdf	Image Retrieval#DeepFashion - Consumer-to-shop#Rank-1#25.7$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-20#64.4$Image Retrieval#DeepFashion - Consumer-to-shop#Rank-50#75
2203.15867v1.pdf	Image Retrieval#ImageCoDe#Accuracy#29.9
1709.03409v2.pdf	Sketch-Based Image Retrieval#Handbags#R@1#51.2$Sketch-Based Image Retrieval#Handbags#R@10#85.7$Sketch-Based Image Retrieval#Shoes#R@1#54.8$Sketch-Based Image Retrieval#Shoes#R@10#92.2$Sketch-Based Image Retrieval#Chairs#R@1#85.6$Sketch-Based Image Retrieval#Chairs#R@10#97.9
1705.09888v1.pdf	Sketch-Based Image Retrieval#Chairs#R@1#53.2$Sketch-Based Image Retrieval#Chairs#R@10#90.3
2201.09206v1.pdf	Drone navigation#University-1652#AP#81.53$Drone navigation#University-1652#Recall@1#87.87$Drone-view target localization#University-1652#AP#84.82$Drone-view target localization#University-1652#Recall@1#82.25
2110.02035v2.pdf	Text-Image Retrieval#FooDI-ML (Global)#A-R@1#0.005$Text-Image Retrieval#FooDI-ML (Global)#A-R@5#0.02$Text-Image Retrieval#FooDI-ML (Global)#A-R@10#0.05$Text-Image Retrieval#FooDI-ML (Global)#Re-R@1#0.01$Text-Image Retrieval#FooDI-ML (Global)#Re-R@5#0.03$Text-Image Retrieval#FooDI-ML (Global)#Re-R@10#0.045$Text-Image Retrieval#FooDI-ML (Spain)#A-R@1#0.93$Text-Image Retrieval#FooDI-ML (Spain)#A-R@5#3.33$Text-Image Retrieval#FooDI-ML (Spain)#A-R@10#5.8$Text-Image Retrieval#FooDI-ML (Spain)#Re-R@1#0.73$Text-Image Retrieval#FooDI-ML (Spain)#Re-R@5#2.93$Text-Image Retrieval#FooDI-ML (Spain)#Re-R@10#5.67
2104.03015v3.pdf	Text-Image Retrieval#Fashion IQ#(Recall@10+Recall@50)/2#40.64
2003.12299v2.pdf	Text-Image Retrieval#Fashion IQ#(Recall@10+Recall@50)/2#38.45
2006.11149v3.pdf	Text-Image Retrieval#Fashion IQ#(Recall@10+Recall@50)/2#20.60$Image Retrieval with Multi-Modal Query#MIT-States#Recall@1#13.9$Image Retrieval with Multi-Modal Query#MIT-States#Recall@5#35.5$Image Retrieval with Multi-Modal Query#MIT-States#Recall@10#47.9$Image Retrieval with Multi-Modal Query#FashionIQ#Recall@10#11.8$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#22.8$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#55.3$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#73.4
2108.04024v1.pdf	Text-Image Retrieval#CIRR#(Recall@5+Recall_subset@1)/2#45.88
2203.08101v2.pdf	Text-Image Retrieval#CIRR#(Recall@5+Recall_subset@1)/2#43.05
1908.06066v3.pdf	Text-Image Retrieval#COCO (image as query)#Recall@10#97.2
2103.01913v2.pdf	Text-Image Retrieval#WIT#R@1#0.346$Text-Image Retrieval#WIT#R@5#0.642$Text-Image Retrieval#WIT#R@1#0.048$Text-Image Retrieval#WIT#R@5#0.122
2103.12340v1.pdf	Amodal Instance Segmentation#WALT#AP#73.2$Instance Segmentation#KINS#mAP#28.87$Instance Segmentation#COCO test-dev#mask AP#41.7$Instance Segmentation#COCO test-dev#mask AP#39.8$Instance Segmentation#COCO test-dev#AP50#61.5$Instance Segmentation#COCO test-dev#AP75#43.1$Instance Segmentation#COCO test-dev#APS#22.7$Instance Segmentation#COCO test-dev#APM#42.4$Instance Segmentation#COCO test-dev#APL#51.1$Instance Segmentation#COCO test-dev#mask AP#39.6$Instance Segmentation#COCO test-dev#AP50#61.2$Instance Segmentation#COCO test-dev#AP75#42.7$Instance Segmentation#COCO test-dev#APS#22.3$Instance Segmentation#COCO test-dev#APM#42.3$Instance Segmentation#COCO test-dev#APL#51.0
2110.02627v4.pdf	Video-to-Shop#MovingFashion#Top-1 Accuracy#0.49
2003.06713v1.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.3876$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.5165$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.6091
2008.09093v2.pdf	Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4604$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.5399$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4486$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.5252
1904.07094v3.pdf	Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4667$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.5381$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4042$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.4541
1905.09217v1.pdf	Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.469$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.467$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.444
1809.01682v2.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.271$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.389$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.464$Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.258$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.374$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.445
1810.12936v1.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.2904$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4064$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.4502$Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.2846$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.3926$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.4327$Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.2464$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.3510$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.3989
1711.08611v1.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.279$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.382$Ad-Hoc Information Retrieval#TREC Robust04#nDCG@20#0.431
1903.10972v1.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.3278$Ad-Hoc Information Retrieval#TREC Robust04#P@20#0.4287
1704.08803v2.pdf	Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.2837$Ad-Hoc Information Retrieval#TREC Robust04#MAP#0.2811
2112.01810v1.pdf	Document Ranking#DaReCzech#P@10#46.73$Document Ranking#DaReCzech#P@10#46.30$Document Ranking#DaReCzech#P@10#45.26
2005.00352v2.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#44.15$Text Simplification#ASSET#BLEU#72.98$Text Simplification#ASSET#FKGL#6.05$Text Simplification#ASSET#SARI (EASSE>=0.2.1)#42.65$Text Simplification#ASSET#FKGL#8.23$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#42.53$Text Simplification#TurkCorpus#BLEU#78.17$Text Simplification#TurkCorpus#FKGL#7.60$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#40.85$Text Simplification#TurkCorpus#FKGL#8.79
2103.05070v1.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#43.21$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#41.46$Text Simplification#PWKP / WikiSmall#SARI#44.67$Text Simplification#PWKP / WikiSmall#SARI (EASSE>=0.2.1)#44.67
1910.02677v3.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#40.13$Text Simplification#ASSET#BLEU#75.99*$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#41.38$Text Simplification#TurkCorpus#BLEU#72.53
1810.11193v1.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#38.67$Text Simplification#ASSET#BLEU#71.44*$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#40.45$Text Simplification#Newsela#SARI#27.28
1703.10931v2.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#36.59$Text Simplification#ASSET#BLEU#86.39*$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.27$Text Simplification#TurkCorpus#BLEU#80.12$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.08$Text Simplification#TurkCorpus#BLEU#77.18$Text Simplification#PWKP / WikiSmall#SARI#27.24$Text Simplification#PWKP / WikiSmall#BLEU#36.32$Text Simplification#PWKP / WikiSmall#SARI#27.48$Text Simplification#PWKP / WikiSmall#BLEU#34.53$Text Simplification#Newsela#SARI#27.37$Text Simplification#Newsela#BLEU#23.21$Text Simplification#Newsela#SARI#26.63$Text Simplification#Newsela#BLEU#24.30
1810.07931v6.pdf	Text Simplification#ASSET#SARI (EASSE>=0.2.1)#35.19$Text Simplification#ASSET#BLEU#76.14*$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.20$Text Simplification#TurkCorpus#BLEU#74.02$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.15$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#36.29
1906.08104v1.pdf	Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#38.22$Text Simplification#TurkCorpus#BLEU#86.69$Text Simplification#PWKP / WikiSmall#SARI#32.35$Text Simplification#Newsela#SARI#31.41$Text Simplification#Newsela#BLEU#19.85
2006.09639v1.pdf	Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.85$Text Simplification#TurkCorpus#BLEU#73.62$Text Simplification#Newsela#SARI#30.44$Text Simplification#Newsela#BLEU#17.36
1806.07304v1.pdf	Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#37.45$Text Simplification#TurkCorpus#BLEU#81.49$Text Simplification#PWKP / WikiSmall#SARI#29.58$Text Simplification#PWKP / WikiSmall#BLEU#27.23$Text Simplification#Newsela#SARI#33.22$Text Simplification#Newsela#BLEU#11.14
1804.07445v1.pdf	Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#36.88$Text Simplification#TurkCorpus#BLEU#80.43$Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#33.43$Text Simplification#TurkCorpus#BLEU#92.02$Text Simplification#PWKP / WikiSmall#SARI#17.47$Text Simplification#PWKP / WikiSmall#BLEU#53.42$Text Simplification#PWKP / WikiSmall#SARI#29.75$Text Simplification#PWKP / WikiSmall#BLEU#29.72$Text Simplification#Newsela#SARI#29.58$Text Simplification#Newsela#BLEU#22.62$Text Simplification#Newsela#SARI#27.42$Text Simplification#Newsela#BLEU#26.31
1810.05104v1.pdf	Text Simplification#TurkCorpus#SARI (EASSE>=0.2.1)#36.70$Text Simplification#TurkCorpus#BLEU#74.49
1507.08452v3.pdf	Text Simplification#PWKP / WikiSmall#BLEU#38.47
2005.02324v4.pdf	Text Simplification#Newsela#SARI#36.6
1904.02767v1.pdf	Text Simplification#Newsela#SARI#30.73$Text Simplification#Newsela#BLEU#19.55
2004.12331v1.pdf	Text Clustering#20 Newsgroups#Accuracy#41.25$Text Clustering#20 Newsgroups#Accuracy#35.66
2103.12953v2.pdf	Short Text Clustering#Tweet#Acc#78.2$Short Text Clustering#Searchsnippets#Acc#85.2$Short Text Clustering#Biomedical#Acc#46.2$Short Text Clustering#GoogleNews-S#Acc#83.1$Short Text Clustering#GoogleNews-TS#Acc#89.8$Short Text Clustering#AG News#Acc#88.2$Short Text Clustering#Stackoverflow#Acc#SCCL$Short Text Clustering#GoogleNews-T#Acc#75.8
1701.00185v1.pdf	Short Text Clustering#Searchsnippets#Acc#77.09$Short Text Clustering#Searchsnippets#Acc#77.01$Short Text Clustering#Biomedical#Acc#43.62$Short Text Clustering#Biomedical#Acc#43$Short Text Clustering#Stackoverflow#Acc#STC2-LE$Short Text Clustering#Stackoverflow#Acc#STC2-LPI
2210.11680v1.pdf	Short Text Clustering#Biomedical#Acc#49.8$Short Text Clustering#Biomedical#NMI#42.9$Short Text Clustering#Stackoverflow#Acc#88.2$Short Text Clustering#Stackoverflow#NMI#0.786$Image Clustering#Imagenet-dog-15#Accuracy#0.644$Image Clustering#Imagenet-dog-15#NMI#0.623$Image Clustering#Imagenet-dog-15#ARI#0.516$Image Clustering#ImageNet-10#Accuracy#0.895$Image Clustering#ImageNet-10#NMI#0.875$Image Clustering#ImageNet-10#ARI#0.837$Image Clustering#CIFAR-100#Accuracy#0.531$Image Clustering#CIFAR-100#NMI#0.529$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.357$Image Clustering#STL-10#Accuracy#0.868$Image Clustering#STL-10#NMI#0.799$Image Clustering#STL-10#Train Split#Train$Image Clustering#STL-10#ARI#0.757$Image Clustering#STL-10#Backbone#ResNet-34$Image Clustering#CIFAR-10#Accuracy#0.887$Image Clustering#CIFAR-10#NMI#0.819$Image Clustering#CIFAR-10#Train set#Train$Image Clustering#CIFAR-10#ARI#0.780$Image Clustering#CIFAR-10#Backbone#ResNet-34
2102.00541v1.pdf	Short Text Clustering#Stackoverflow#Acc#Deep ECIC
1911.08891v1.pdf	Open Intent Discovery#Stackoverflow#NMI#69.84$Open Intent Discovery#Stackoverflow#ARI#52.59$Open Intent Discovery#Stackoverflow#ACC#73.48$Open Intent Discovery#SNIPS#NMI#89.3$Open Intent Discovery#SNIPS#ARI#86.82$Open Intent Discovery#SNIPS#ACC#93.63$Open Intent Discovery#ATIS#NMI#94.74$Open Intent Discovery#ATIS#ARI#89.41$Open Intent Discovery#ATIS#ACC#91.66
2012.08987v7.pdf	Open Intent Discovery#BANKING77#NMI#0.7956$Open Intent Discovery#BANKING77#ARI#0.5364$Open Intent Discovery#BANKING77#ACC#64.9$Open Intent Discovery#CLINC150#NMI#0.9389$Open Intent Discovery#CLINC150#ARI#0.7975$Open Intent Discovery#CLINC150#ACC#86.49
2103.15619v1.pdf	Point Cloud Generation#ShapeNet Chair#MMD-CD#2.55$Point Cloud Generation#ShapeNet Chair#1-NNA-CD#58.76$Point Cloud Generation#ShapeNet Airplane#MMD-CD#0.199$Point Cloud Generation#ShapeNet Airplane#1-NNA-CD#75.31$Point Cloud Generation#ShapeNet Car#MMD-CD#0.88$Point Cloud Generation#ShapeNet Car#1-NNA-CD#59.66
2006.04604v4.pdf	Point Cloud Generation#ShapeNet Chair#1-NNA-CD#59.95$Point Cloud Generation#ShapeNet Airplane#1-NNA-CD#70.92$Point Cloud Generation#ShapeNet Car#1-NNA-CD#62.63
1906.12320v3.pdf	Point Cloud Generation#ShapeNet Chair#MMD-CD#2.42$Point Cloud Generation#ShapeNet Chair#1-NNA-CD#60.88$Point Cloud Generation#ShapeNet Airplane#MMD-CD#0.217$Point Cloud Generation#ShapeNet Airplane#1-NNA-CD#75.68$Point Cloud Generation#ShapeNet Car#MMD-CD#0.91$Point Cloud Generation#ShapeNet Car#1-NNA-CD#60.65
2210.06978v1.pdf	Point Cloud Generation#ShapeNet Chair#CD#52.07$Point Cloud Generation#ShapeNet Chair#EMD#48.67$Point Cloud Generation#ShapeNet#CD#51.85$Point Cloud Generation#ShapeNet#EMD#48.95$Point Cloud Generation#ShapeNet Airplane#CD#53.47$Point Cloud Generation#ShapeNet Airplane#EMD#53.84$Point Cloud Generation#ShapeNet Car#CD#54.81$Point Cloud Generation#ShapeNet Car#EMD#50.53
2006.03761v4.pdf	Point Cloud Completion#Completion3D#Chamfer Distance#10.64$Point Cloud Completion#ShapeNet#Chamfer Distance#8.81$Point Cloud Completion#ShapeNet#F-Score@1%#0.708$Point Cloud Completion#ShapeNet#Chamfer Distance L2#2.723
1802.05384v3.pdf	Point Cloud Completion#Completion3D#Chamfer Distance#17.77$3D Shape Reconstruction#Pix3D#CD#0.125$3D Shape Reconstruction#Pix3D#EMD#0.128$3D Shape Reconstruction#Pix3D#IoU#N/A
1808.00671v3.pdf	Point Cloud Completion#Completion3D#Chamfer Distance#18.22$Point Cloud Completion#ShapeNet#Chamfer Distance#9.636$Point Cloud Completion#ShapeNet#F-Score@1%#0.695$Point Cloud Completion#ShapeNet#Chamfer Distance L2#4.016
2209.09552v1.pdf	Point Cloud Completion#ShapeNet-ViPC#Chamfer Distance#1.443
2208.00751v1.pdf	Point Cloud Completion#ShapeNet-ViPC#Chamfer Distance#2.570
2104.05666v2.pdf	Point Cloud Completion#ShapeNet-ViPC#Chamfer Distance#3.308
2108.08839v1.pdf	Point Cloud Completion#ShapeNet#Chamfer Distance#8.38$Point Cloud Completion#ShapeNet#F-Score@1%#0.748
1912.00280v1.pdf	Point Cloud Completion#ShapeNet#Chamfer Distance#9.969$Point Cloud Completion#ShapeNet#F-Score@1%#0.705$Point Cloud Completion#ShapeNet#Chamfer Distance L2#4.758
1506.03134v2.pdf	Point Cloud Completion#ShapeNet#Chamfer Distance#100
2103.02535v3.pdf	Point Cloud Completion#ShapeNet#Earth Mover's Distance#1.862$Point Cloud Completion#ShapeNet#Frechet Point cloud Distance#0.645
1504.05070v2.pdf	Subjectivity Analysis#SUBJ#Accuracy#95.50
1806.05516v1.pdf	Subjectivity Analysis#SUBJ#Accuracy#94.80$Text Classification#TREC-6#Error#4
1602.03483v1.pdf	Subjectivity Analysis#SUBJ#Accuracy#90.8
2204.13915v1.pdf	Subjectivity Analysis#Czech Subjectivity Dataset#Accuracy#93.56$Subjectivity Analysis#Czech Subjectivity Dataset#Accuracy#93.29$Subjectivity Analysis#Czech Subjectivity Dataset#Accuracy#92.85$Subjectivity Analysis#Czech Subjectivity Dataset#Accuracy#91.85$Subjectivity Analysis#Czech Subjectivity Dataset#Accuracy#91.23
2005.05859v2.pdf	Neural Architecture Search#Oxford-IIIT Pet Dataset#Accuracy (%)#94.3$Neural Architecture Search#Oxford-IIIT Pet Dataset#FLOPS#744M$Neural Architecture Search#Oxford-IIIT Pet Dataset#PARAMS#8.5M$Neural Architecture Search#Oxford-IIIT Pet Dataset#Accuracy (%)#94.1$Neural Architecture Search#Oxford-IIIT Pet Dataset#FLOPS#471M$Neural Architecture Search#Oxford-IIIT Pet Dataset#PARAMS#5.7M$Neural Architecture Search#Oxford-IIIT Pet Dataset#Accuracy (%)#93.5$Neural Architecture Search#Oxford-IIIT Pet Dataset#FLOPS#306M$Neural Architecture Search#Oxford-IIIT Pet Dataset#PARAMS#5.5M$Neural Architecture Search#Oxford-IIIT Pet Dataset#Accuracy (%)#91.8$Neural Architecture Search#Oxford-IIIT Pet Dataset#FLOPS#160M$Neural Architecture Search#Oxford-IIIT Pet Dataset#PARAMS#4.0M$Neural Architecture Search#CINIC-10#Accuracy (%)#94.8$Neural Architecture Search#CINIC-10#FLOPS#710M$Neural Architecture Search#CINIC-10#PARAMS#9.1M$Neural Architecture Search#CINIC-10#Accuracy (%)#94.3$Neural Architecture Search#CINIC-10#FLOPS#501M$Neural Architecture Search#CINIC-10#PARAMS#8.1M$Neural Architecture Search#CINIC-10#Accuracy (%)#94.1$Neural Architecture Search#CINIC-10#FLOPS#411M$Neural Architecture Search#CINIC-10#PARAMS#6.2M$Neural Architecture Search#CINIC-10#Accuracy (%)#93.4$Neural Architecture Search#CINIC-10#FLOPS#317M$Neural Architecture Search#CINIC-10#PARAMS#4.6M$Neural Architecture Search#DTD#Accuracy (%)#79.1$Neural Architecture Search#DTD#FLOPS#560M$Neural Architecture Search#DTD#PARAMS#6.3M$Neural Architecture Search#DTD#Accuracy (%)#78.4$Neural Architecture Search#DTD#FLOPS#347M$Neural Architecture Search#DTD#PARAMS#4.1M$Neural Architecture Search#DTD#Accuracy (%)#77.6$Neural Architecture Search#DTD#FLOPS#297M$Neural Architecture Search#DTD#PARAMS#4.0M$Neural Architecture Search#DTD#Accuracy (%)#76.1$Neural Architecture Search#DTD#FLOPS#136M$Neural Architecture Search#DTD#PARAMS#2.2M$Neural Architecture Search#FGVC Aircraft#Accuracy (%)#90.8$Neural Architecture Search#FGVC Aircraft#FLOPS#581M$Neural Architecture Search#FGVC Aircraft#PARAMS#5.3M$Neural Architecture Search#FGVC Aircraft#Accuracy (%)#90.1$Neural Architecture Search#FGVC Aircraft#FLOPS#388M$Neural Architecture Search#FGVC Aircraft#PARAMS#5.1M$Neural Architecture Search#FGVC Aircraft#Accuracy (%)#89.0$Neural Architecture Search#FGVC Aircraft#FLOPS#235M$Neural Architecture Search#FGVC Aircraft#PARAMS#3.4M$Neural Architecture Search#FGVC Aircraft#Accuracy (%)#87.0$Neural Architecture Search#FGVC Aircraft#FLOPS#175M$Neural Architecture Search#FGVC Aircraft#PARAMS#3.2M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#1.6$Neural Architecture Search#CIFAR-10 Image Classification#Params#6.9M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#468M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#1.8$Neural Architecture Search#CIFAR-10 Image Classification#Params#6.2M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#392M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.1$Neural Architecture Search#CIFAR-10 Image Classification#Params#4.6M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#291M$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.6$Neural Architecture Search#CIFAR-10 Image Classification#Params#4.3M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#232M$Neural Architecture Search#Food-101#Accuracy (%)#89.4$Neural Architecture Search#Food-101#FLOPS#361M$Neural Architecture Search#Food-101#PARAMS#4.5M$Neural Architecture Search#Food-101#Accuracy (%)#89.0$Neural Architecture Search#Food-101#FLOPS#299M$Neural Architecture Search#Food-101#PARAMS#3.9M$Neural Architecture Search#Food-101#Accuracy (%)#88.5$Neural Architecture Search#Food-101#FLOPS#266M$Neural Architecture Search#Food-101#PARAMS#4.1M$Neural Architecture Search#Food-101#Accuracy (%)#87.4$Neural Architecture Search#Food-101#FLOPS#198M$Neural Architecture Search#Food-101#PARAMS#3.1M$Neural Architecture Search#ImageNet#Top-1 Error Rate#19.5$Neural Architecture Search#ImageNet#Accuracy#80.5$Neural Architecture Search#ImageNet#Params#9.1M$Neural Architecture Search#ImageNet#MACs#600M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.1$Neural Architecture Search#ImageNet#Accuracy#79.9$Neural Architecture Search#ImageNet#MACs#490M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.4$Neural Architecture Search#ImageNet#Accuracy#78.6$Neural Architecture Search#ImageNet#Params#7.7M$Neural Architecture Search#ImageNet#MACs#312M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.5$Neural Architecture Search#ImageNet#Accuracy#77.5$Neural Architecture Search#ImageNet#Params#6.0M$Neural Architecture Search#ImageNet#MACs#225M$Neural Architecture Search#Stanford Cars#Accuracy (%)#92.9$Neural Architecture Search#Stanford Cars#FLOPS#369M$Neural Architecture Search#Stanford Cars#PARAMS#3.7M$Neural Architecture Search#Stanford Cars#Accuracy (%)#92.6$Neural Architecture Search#Stanford Cars#FLOPS#289M$Neural Architecture Search#Stanford Cars#PARAMS#3.5M$Neural Architecture Search#Stanford Cars#Accuracy (%)#92.2$Neural Architecture Search#Stanford Cars#FLOPS#222M$Neural Architecture Search#Stanford Cars#PARAMS#2.7M$Neural Architecture Search#Stanford Cars#Accuracy (%)#90.0$Neural Architecture Search#Stanford Cars#FLOPS#165M$Neural Architecture Search#Stanford Cars#PARAMS#2.4M$Neural Architecture Search#STL-10#Accuracy (%)#97.9$Neural Architecture Search#STL-10#FLOPS#573M$Neural Architecture Search#STL-10#PARAMS#7.5M$Neural Architecture Search#STL-10#Accuracy (%)#97.8$Neural Architecture Search#STL-10#FLOPS#436M$Neural Architecture Search#STL-10#Accuracy (%)#97.2$Neural Architecture Search#STL-10#FLOPS#303M$Neural Architecture Search#STL-10#PARAMS#5.1M$Neural Architecture Search#STL-10#Accuracy (%)#96.7$Neural Architecture Search#STL-10#FLOPS#240M$Neural Architecture Search#STL-10#PARAMS#4.4M$Neural Architecture Search#CIFAR-100#FLOPS#796M$Neural Architecture Search#CIFAR-100#Percentage Error#11.7$Neural Architecture Search#CIFAR-100#PARAMS#9.0M$Neural Architecture Search#CIFAR-100#FLOPS#492M$Neural Architecture Search#CIFAR-100#Percentage Error#12.3$Neural Architecture Search#CIFAR-100#PARAMS#7.8M$Neural Architecture Search#CIFAR-100#FLOPS#398M$Neural Architecture Search#CIFAR-100#Percentage Error#12.5$Neural Architecture Search#CIFAR-100#PARAMS#6.4M$Neural Architecture Search#CIFAR-100#FLOPS#261M$Neural Architecture Search#CIFAR-100#Percentage Error#14.0$Neural Architecture Search#CIFAR-100#PARAMS#3.8M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#1.6%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#1.0$Neural Architecture Search#CIFAR-10#Parameters#6.9M$Neural Architecture Search#CIFAR-10#FLOPS#468M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#1.8%$Neural Architecture Search#CIFAR-10#Parameters#6.2M$Neural Architecture Search#CIFAR-10#FLOPS#392M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.1%$Neural Architecture Search#CIFAR-10#Parameters#4.6M$Neural Architecture Search#CIFAR-10#FLOPS#291M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.6%$Neural Architecture Search#CIFAR-10#Parameters#4.3M$Neural Architecture Search#CIFAR-10#FLOPS#232M$Neural Architecture Search#Oxford 102 Flowers#Accuracy (%)#98.3$Neural Architecture Search#Oxford 102 Flowers#FLOPS#400M$Neural Architecture Search#Oxford 102 Flowers#PARAMS#4.2M$Neural Architecture Search#Oxford 102 Flowers#Accuracy (%)#98.1$Neural Architecture Search#Oxford 102 Flowers#FLOPS#250M$Neural Architecture Search#Oxford 102 Flowers#PARAMS#3.7M$Neural Architecture Search#Oxford 102 Flowers#Accuracy (%)#97.9$Neural Architecture Search#Oxford 102 Flowers#FLOPS#195M$Neural Architecture Search#Oxford 102 Flowers#PARAMS#3.4M$Neural Architecture Search#Oxford 102 Flowers#Accuracy (%)#97.5$Neural Architecture Search#Oxford 102 Flowers#FLOPS#152M$Neural Architecture Search#Oxford 102 Flowers#PARAMS#3.3M$Image Classification#CIFAR-100#Percentage correct#88.3$Image Classification#CIFAR-100#PARAMS#9.0M$Image Classification#CIFAR-100#Percentage correct#87.7$Image Classification#CIFAR-100#PARAMS#7.8M$Image Classification#CIFAR-100#Percentage correct#87.5$Image Classification#CIFAR-100#PARAMS#6.4M$Image Classification#CIFAR-100#Percentage correct#86.0$Image Classification#CIFAR-100#PARAMS#3.8M$Image Classification#ImageNet#Top 1 Accuracy#80.5%$Image Classification#ImageNet#Top 5 Accuracy#95.2%$Image Classification#ImageNet#Number of params#9.1M$Image Classification#STL-10#Percentage correct#97.9$Image Classification#STL-10#FLOPS#573M$Image Classification#STL-10#PARAMS#7.5M$Image Classification#STL-10#Percentage correct#97.8$Image Classification#STL-10#FLOPS#436M$Image Classification#STL-10#Percentage correct#97.2$Image Classification#STL-10#FLOPS#303M$Image Classification#STL-10#PARAMS#5.1M$Image Classification#STL-10#Percentage correct#96.7$Image Classification#STL-10#FLOPS#240M$Image Classification#STL-10#PARAMS#4.4M$Image Classification#Flowers-102#Accuracy#98.3%$Image Classification#Flowers-102#FLOPS#400M$Image Classification#Flowers-102#PARAMS#4.2M$Image Classification#Flowers-102#Accuracy#98.1%$Image Classification#Flowers-102#FLOPS#250M$Image Classification#Flowers-102#PARAMS#3.7M$Image Classification#Flowers-102#Accuracy#97.9%$Image Classification#Flowers-102#FLOPS#195M$Image Classification#Flowers-102#PARAMS#3.4M$Image Classification#Flowers-102#FLOPS#152M$Image Classification#Flowers-102#PARAMS#3.3M$Image Classification#CINIC-10#Accuracy#94.3$Image Classification#CINIC-10#FLOPS#501M$Image Classification#CINIC-10#PARAMS#8.1M$Image Classification#CINIC-10#Accuracy#94.1$Image Classification#CINIC-10#FLOPS#411M$Image Classification#CINIC-10#PARAMS#6.2M$Image Classification#CINIC-10#Accuracy#93.4$Image Classification#CINIC-10#FLOPS#317M$Image Classification#CINIC-10#PARAMS#4.6M$Image Classification#CIFAR-10#Percentage correct#98.4$Image Classification#CIFAR-10#PARAMS#6.9M$Image Classification#CIFAR-10#Percentage correct#98.2$Image Classification#CIFAR-10#PARAMS#6.2M$Image Classification#CIFAR-10#Percentage correct#97.9$Image Classification#CIFAR-10#PARAMS#4.6M$Image Classification#CIFAR-10#Percentage correct#97.4$Image Classification#CIFAR-10#PARAMS#4.3M$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.9%$Fine-Grained Image Classification#Stanford Cars#FLOPS#369M$Fine-Grained Image Classification#Stanford Cars#PARAMS#3.7M$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.6%$Fine-Grained Image Classification#Stanford Cars#FLOPS#289M$Fine-Grained Image Classification#Stanford Cars#PARAMS#3.5M$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.2%$Fine-Grained Image Classification#Stanford Cars#FLOPS#222M$Fine-Grained Image Classification#Stanford Cars#PARAMS#2.7M$Fine-Grained Image Classification#Stanford Cars#Accuracy#90.9%$Fine-Grained Image Classification#Stanford Cars#FLOPS#165M$Fine-Grained Image Classification#Stanford Cars#PARAMS#2.4M$Fine-Grained Image Classification#Food-101#Accuracy#89.4$Fine-Grained Image Classification#Food-101#FLOPS#361M$Fine-Grained Image Classification#Food-101#PARAMS#4.5M$Fine-Grained Image Classification#Food-101#Accuracy#89.0$Fine-Grained Image Classification#Food-101#FLOPS#299M$Fine-Grained Image Classification#Food-101#PARAMS#3.9M$Fine-Grained Image Classification#Food-101#Accuracy#88.5$Fine-Grained Image Classification#Food-101#FLOPS#266M$Fine-Grained Image Classification#Food-101#PARAMS#4.1M$Fine-Grained Image Classification#Food-101#Accuracy#87.4$Fine-Grained Image Classification#Food-101#FLOPS#198M$Fine-Grained Image Classification#Food-101#PARAMS#3.1M$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#90.8%$Fine-Grained Image Classification#FGVC Aircraft#FLOPS#581M$Fine-Grained Image Classification#FGVC Aircraft#PARAMS#5.3M$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#90.1%$Fine-Grained Image Classification#FGVC Aircraft#FLOPS#388M$Fine-Grained Image Classification#FGVC Aircraft#PARAMS#5.1M$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#89.0%$Fine-Grained Image Classification#FGVC Aircraft#FLOPS#235M$Fine-Grained Image Classification#FGVC Aircraft#PARAMS#3.4M$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#87.0%$Fine-Grained Image Classification#FGVC Aircraft#FLOPS#175M$Fine-Grained Image Classification#FGVC Aircraft#PARAMS#3.2M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#5.7%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.3%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#FLOPS#744M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#8.5M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#5.9%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.1%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#FLOPS#471M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#5.7M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#6.5%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#93.5%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#FLOPS#306M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#5.5M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#FLOPS#160M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#4.0M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.3%$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#400M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#4.2M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.1%$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#250M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#3.7M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#97.9%$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#195M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#3.4M$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#152M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#3.3M
1910.07225v1.pdf	Neural Architecture Search#MNIST#R2#0.9314
2108.01899v2.pdf	Neural Architecture Search#NAS-Bench-101#Spearman Correlation#0.87$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#72.56$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#1080$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.59$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#1080$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.18$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#-$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#1080
2203.01665v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.51$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#73.49$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.9$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.71$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.34$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.37$Neural Architecture Search#CIFAR-100#Percentage Error#16.52$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.53%$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.36$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.55
2206.09811v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.51$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#73.49$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.9$Neural Architecture Search#ImageNet#Params#5.4M$Neural Architecture Search#ImageNet#MACs#582M$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.85$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.57$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.43%$Neural Architecture Search#CIFAR-10#Parameters#3.6M$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.37$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.61
2006.10355v4.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.51$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#73.49$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.7$Neural Architecture Search#ImageNet#Params#5.7M$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.34$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.37$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.46%$Neural Architecture Search#CIFAR-10#Parameters#4.1M$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.36$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.55
2203.08734v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.51$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#73.49$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.42$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.73$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.37$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.61
2004.07802v5.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.43$Neural Architecture Search#ImageNet#Top-1 Error Rate#24$Neural Architecture Search#ImageNet#Params#5.6$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.36$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.1
2006.06936v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.37$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#73.35$Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.56$Neural Architecture Search#CIFAR-10 Image Classification#Params#3.6$Neural Architecture Search#CIFAR-10 Image Classification#Search Time (GPU days)#10.5$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.27$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.34$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.56%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#10.5$Neural Architecture Search#CIFAR-10#Parameters#3.6M$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.18$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.41$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#12000
2204.04918v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#73.02$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.31$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.35
2111.13204v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#72.95$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#72.67$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.54$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.14$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.33$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.52
2208.08835v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#72.94$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#72.95$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.1$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#53.6$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.27$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.3
2208.06475v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#72.36$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#72.62$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.04$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#45.97$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#93.99$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.26
2204.12726v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#72.02$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#71.95$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.34$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#45.16$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.04$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.37
2006.10724v4.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#71.92$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#72.12$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.51$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#45.09$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#94.02$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.12
2102.11382v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#71.56$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.85
2009.01027v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#71.53$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#71.36$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.12$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#44.87$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#93.80$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#91.03$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#11520
1907.01845v5.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#71.00$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#70.94$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#9845$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.7$Neural Architecture Search#ImageNet#Accuracy#75.34$Neural Architecture Search#ImageNet#Params#4.6M$Neural Architecture Search#ImageNet#MACs#388M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.9$Neural Architecture Search#ImageNet#Accuracy#75.1$Neural Architecture Search#ImageNet#Params#4.5M$Neural Architecture Search#ImageNet#MACs#345M$Neural Architecture Search#ImageNet#Top-1 Error Rate#25.4$Neural Architecture Search#ImageNet#Accuracy#74.69$Neural Architecture Search#ImageNet#Params#4.4M$Neural Architecture Search#ImageNet#MACs#321M$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#42.19$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#41.90$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#9845$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#1.8%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#8$Neural Architecture Search#CIFAR-10#Parameters#3$Neural Architecture Search#CIFAR-10#FLOPS#391$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#93.23$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#90.07$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#9845$Image Classification#ImageNet#Top 1 Accuracy#75.34%$Image Classification#ImageNet#Top 5 Accuracy#92.38$Image Classification#ImageNet#Number of params#4.6M$Image Classification#ImageNet#GFLOPs#0.776$Image Classification#ImageNet#Top 1 Accuracy#75.10%$Image Classification#ImageNet#Top 5 Accuracy#92.30$Image Classification#ImageNet#Number of params#4.5M$Image Classification#ImageNet#GFLOPs#0.690$Image Classification#ImageNet#Top 1 Accuracy#74.69%$Image Classification#ImageNet#Top 5 Accuracy#92.12$Image Classification#ImageNet#Number of params#4.4M$Image Classification#ImageNet#GFLOPs#0.642
2106.10784v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#70.83$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#70.57$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#40.89$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#40.38$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#93.58$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#89.86
1910.04465v2.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#70.61$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#71.14$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#28926$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#41.84$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#41.70$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#28926$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.5%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.17$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#3.4%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.21$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#93.51$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#90.00$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#28926
2102.08099v1.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#70.10$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#69.78$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#2.3$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#69.58$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#69.44$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#206.2$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#69.33$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#69.23$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#105.8$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#67.19$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#67.28$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#20.5$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#42.05$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#41.93$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#105.8$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#41.92$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#41.73$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#2.3$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#41.84$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#41.86$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#206.2$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#38.80$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#38.66$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#20.5$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#92.63$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#89.90$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#2.3$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#92.27$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#88.17$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#105.8$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#91.59$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#88.74$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#20.5$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#91.31$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#87.87$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#206.2
1812.09926v3.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#69.34$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#69.69$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#43.16$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#42.84$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#92.77$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#90.10
1902.07638v3.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#58.33$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#59.00$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#7587$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#31.14$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#31.56$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#7587$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (Test)#87.66$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Accuracy (val)#84.16$Neural Architecture Search#NAS-Bench-201, CIFAR-10#Search time (s)#7587
1910.05733v4.pdf	Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Test)#56.87$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Accuracy (Val)#56.86$Neural Architecture Search#NAS-Bench-201, CIFAR-100#Search time (s)#31010$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.69%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#1.8
1808.07233v5.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#1.93$Neural Architecture Search#CIFAR-10 Image Classification#Params#144.6M
1903.09900v1.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#1.98$Neural Architecture Search#CIFAR-10 Image Classification#Params#3.6M$Neural Architecture Search#CIFAR-10 Image Classification#FLOPS#579M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.0$Neural Architecture Search#ImageNet#Accuracy#76.0$Neural Architecture Search#ImageNet#Params#8.3M$Neural Architecture Search#ImageNet#MACs#950M$Neural Architecture Search#ImageNet#Top-1 Error Rate#25.1$Neural Architecture Search#ImageNet#Accuracy#74.1$Neural Architecture Search#ImageNet#Params#4.9M$Neural Architecture Search#ImageNet#MACs#573M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#1.98%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.8$Neural Architecture Search#CIFAR-10#Parameters#3.6M$Neural Architecture Search#CIFAR-10#FLOPS#579M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.29%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#1.8$Neural Architecture Search#CIFAR-10#Parameters#1.98M$Neural Architecture Search#CIFAR-10#FLOPS#357M
1812.00332v2.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.08$Neural Architecture Search#CIFAR-10 Image Classification#Params#5.7M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.9$Neural Architecture Search#ImageNet#Accuracy#75.1$Neural Architecture Search#ImageNet#Params#5.1M$Neural Architecture Search#ImageNet#MACs#581M$Image Classification#ImageNet#Top 1 Accuracy#74.6%$Image Classification#ImageNet#Number of params#4.0M$Image Classification#CIFAR-10#Percentage correct#97.92$Image Classification#CIFAR-10#PARAMS#5.7M
1802.01548v7.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.13$Neural Architecture Search#CIFAR-10 Image Classification#Params#34.9M$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#45.54$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#45.15$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#12000$Image Classification#ImageNet#Top 1 Accuracy#83.9%$Image Classification#ImageNet#Top 5 Accuracy#96.6$Image Classification#ImageNet#Number of params#469M$Image Classification#ImageNet#GFLOPs#208
1806.02639v1.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.30$Neural Architecture Search#CIFAR-10 Image Classification#Params#14.3M
2102.07108v2.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.46$Neural Architecture Search#CIFAR-10 Image Classification#Params#4.1$Neural Architecture Search#CIFAR-10 Image Classification#Search Time (GPU days)#10.3$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.46%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#10.3$Neural Architecture Search#CIFAR-10#Parameters#4.1
1902.09701v2.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.53$Neural Architecture Search#CIFAR-10 Image Classification#Params#33.5$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.53%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.7$Image Classification#CIFAR-100#Percentage correct#82.57$Image Classification#CIFAR-10#Percentage correct#97.47$Image Classification#CIFAR-10#PARAMS#33.5M
2004.01899v3.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Percentage error#2.58$Neural Architecture Search#CIFAR-10 Image Classification#Params#4.1M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.1$Neural Architecture Search#ImageNet#Accuracy#75.9$Neural Architecture Search#ImageNet#Params#5.6M
1903.11059v2.pdf	Neural Architecture Search#CIFAR-10 Image Classification#Params#3.59M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.5$Neural Architecture Search#ImageNet#Accuracy#75.5$Neural Architecture Search#ImageNet#Params#5.4M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.82%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#224
2102.01063v4.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#16.4$Neural Architecture Search#ImageNet#Accuracy#83.6$Neural Architecture Search#ImageNet#FLOPs#22G$Neural Architecture Search#ImageNet#Params#180M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.2$Neural Architecture Search#ImageNet#Accuracy#77.8$Neural Architecture Search#ImageNet#FLOPs#1.7G$Neural Architecture Search#ImageNet#Params#30.1$Neural Architecture Search#CIFAR-100#FLOPS#487M$Neural Architecture Search#CIFAR-100#Percentage Error#15.6$Neural Architecture Search#CIFAR-100#PARAMS#2.0M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.5%$Neural Architecture Search#CIFAR-10#Parameters#2.0M$Neural Architecture Search#CIFAR-10#FLOPS#487M$Image Classification#ImageNet#Top 1 Accuracy#83.0%$Image Classification#ImageNet#Number of params#183M$Image Classification#ImageNet#GFLOPs#13.9$Image Classification#ImageNet#Top 1 Accuracy#78%$Image Classification#ImageNet#Number of params#5.7M$Image Classification#ImageNet#GFLOPs#0.820
2205.00841v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#16.4$Neural Architecture Search#ImageNet#FLOPs#15.6G$Neural Architecture Search#ImageNet#Params#19M$Neural Architecture Search#ImageNet#Top-1 Error Rate#17.5$Neural Architecture Search#ImageNet#FLOPs#3.66G$Neural Architecture Search#ImageNet#Params#10.6M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.3$Neural Architecture Search#ImageNet#FLOPs#720M$Neural Architecture Search#ImageNet#Params#6.2M
2006.02049v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#17.7$Neural Architecture Search#ImageNet#Accuracy#82.3$Neural Architecture Search#ImageNet#MACs#2.0G$Neural Architecture Search#ImageNet#Top-1 Error Rate#19.6$Neural Architecture Search#ImageNet#Accuracy#80.4$Neural Architecture Search#ImageNet#MACs#752M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.4$Neural Architecture Search#ImageNet#Accuracy#79.6$Neural Architecture Search#ImageNet#MACs#544M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.0$Neural Architecture Search#ImageNet#Accuracy#78.0$Neural Architecture Search#ImageNet#MACs#343M
2103.12424v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#17.8$Neural Architecture Search#ImageNet#Accuracy#82.2$Neural Architecture Search#ImageNet#MACs#10.5G$Neural Architecture Search#ImageNet#Top 5 Accuracy#95.8$Neural Architecture Search#NATS-Bench Size, CIFAR-10#Kendall's Tau#0.53$Neural Architecture Search#NATS-Bench Size, CIFAR-10#Spearman's Rho#0.73$Neural Architecture Search#NATS-Bench Size, CIFAR-10#Pearson R#0.72$Neural Architecture Search#NATS-Bench Size, CIFAR-10#Acc. (test)#93.29$Neural Architecture Search#NATS-Bench Size, CIFAR-100#Kendall's Tau#0.59$Neural Architecture Search#NATS-Bench Size, CIFAR-100#Spearman's Rho#0.76$Neural Architecture Search#NATS-Bench Size, CIFAR-100#Pearson R#0.79$Neural Architecture Search#NATS-Bench Size, CIFAR-100#Acc. (test)#70.86$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#GFLOPs#15.8
2102.07954v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.2$Neural Architecture Search#ImageNet#Accuracy#80.8$Neural Architecture Search#ImageNet#FLOPs#709M$Neural Architecture Search#ImageNet#Top-1 Error Rate#19.4$Neural Architecture Search#ImageNet#Accuracy#80.6$Neural Architecture Search#ImageNet#FLOPs#596M$Neural Architecture Search#ImageNet#Top-1 Error Rate#19.7$Neural Architecture Search#ImageNet#Accuracy#80.3$Neural Architecture Search#ImageNet#FLOPs#491M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.0$Neural Architecture Search#ImageNet#Accuracy#80.0$Neural Architecture Search#ImageNet#FLOPs#444M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.6$Neural Architecture Search#ImageNet#Accuracy#79.4$Neural Architecture Search#ImageNet#FLOPs#357M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.8$Neural Architecture Search#ImageNet#Accuracy#79.2$Neural Architecture Search#ImageNet#FLOPs#317M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.0$Neural Architecture Search#ImageNet#Accuracy#79.0$Neural Architecture Search#ImageNet#FLOPs#279M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.1$Neural Architecture Search#ImageNet#Accuracy#77.9$Neural Architecture Search#ImageNet#FLOPs#203M$Image Classification#ImageNet#Top 1 Accuracy#80.8%$Image Classification#ImageNet#GFLOPs#0.709$Image Classification#ImageNet#Top 1 Accuracy#80.3%$Image Classification#ImageNet#GFLOPs#0.491$Image Classification#ImageNet#Top 1 Accuracy#80.0%$Image Classification#ImageNet#GFLOPs#0.444$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#GFLOPs#0.357$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#GFLOPs#0.317$Image Classification#ImageNet#Top 1 Accuracy#78.9%$Image Classification#ImageNet#GFLOPs#0.279$Image Classification#ImageNet#Top 1 Accuracy#77.8%$Image Classification#ImageNet#GFLOPs#0.203
2207.05420v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.2$Neural Architecture Search#ImageNet#FLOPs#555M$Neural Architecture Search#ImageNet#Params#11.5M$Image Classification#ImageNet#Top 1 Accuracy#87.4%$Image Classification#ImageNet#Number of params#117M$Image Classification#ImageNet#GFLOPs#51$Image Classification#ImageNet#Top 1 Accuracy#87%$Image Classification#ImageNet#Number of params#72.9M$Image Classification#ImageNet#GFLOPs#20.4$Image Classification#ImageNet#Top 1 Accuracy#80.8%$Image Classification#ImageNet#Number of params#11.5M$Image Classification#ImageNet#GFLOPs#0.555
2007.10396v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.6$Neural Architecture Search#ImageNet#Accuracy#80.4$Neural Architecture Search#ImageNet#Params#8.7M$Neural Architecture Search#ImageNet#MACs#593M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.9$Neural Architecture Search#ImageNet#Accuracy#79.1$Neural Architecture Search#ImageNet#Params#8.0M$Neural Architecture Search#ImageNet#MACs#400M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.7$Neural Architecture Search#ImageNet#Accuracy#78.3$Neural Architecture Search#ImageNet#Params#7.7M$Neural Architecture Search#ImageNet#MACs#312M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.6$Neural Architecture Search#ImageNet#Accuracy#77.4$Neural Architecture Search#ImageNet#Params#6.1M$Neural Architecture Search#ImageNet#MACs#225M$Image Classification#STL-10#Percentage correct#92.0
2109.01932v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.84$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.59$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.45$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.15$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.7$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.16$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.55
2102.11646v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.9$Neural Architecture Search#ImageNet#Accuracy#80.1$Neural Architecture Search#ImageNet#MACs#330M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.5$Neural Architecture Search#ImageNet#Accuracy#79.5$Neural Architecture Search#ImageNet#MACs#290M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.1$Neural Architecture Search#ImageNet#Accuracy#78.9$Neural Architecture Search#ImageNet#MACs#270M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.2$Neural Architecture Search#ImageNet#Accuracy#78.8$Neural Architecture Search#ImageNet#MACs#250M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.7$Neural Architecture Search#ImageNet#Accuracy#78.3$Neural Architecture Search#ImageNet#MACs#220M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.9$Neural Architecture Search#ImageNet#Accuracy#78.1$Neural Architecture Search#ImageNet#MACs#340M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.1$Neural Architecture Search#ImageNet#Accuracy#77.9$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.6$Neural Architecture Search#ImageNet#Accuracy#77.4$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.9$Neural Architecture Search#ImageNet#Accuracy#77.1$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.5$Neural Architecture Search#ImageNet#Accuracy#76.5$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.1$Neural Architecture Search#ImageNet#Accuracy#75.9
2011.09011v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#19.9$Neural Architecture Search#ImageNet#Accuracy#80.1$Neural Architecture Search#ImageNet#MACs#491M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.2$Neural Architecture Search#ImageNet#Accuracy#79.8$Neural Architecture Search#ImageNet#MACs#444M$Neural Architecture Search#ImageNet#Top-1 Error Rate#20.9$Neural Architecture Search#ImageNet#Accuracy#79.1$Neural Architecture Search#ImageNet#MACs#357M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.2$Neural Architecture Search#ImageNet#Accuracy#78.8$Neural Architecture Search#ImageNet#MACs#317M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.6$Neural Architecture Search#ImageNet#Accuracy#78.4$Neural Architecture Search#ImageNet#MACs#279M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.7$Neural Architecture Search#ImageNet#Accuracy#77.3$Neural Architecture Search#ImageNet#MACs#203M
2003.11142v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#20.5$Neural Architecture Search#ImageNet#Accuracy#79.5$Neural Architecture Search#ImageNet#Params#6.4M$Neural Architecture Search#ImageNet#MACs#586M$Neural Architecture Search#ImageNet#Top-1 Error Rate#21.1$Neural Architecture Search#ImageNet#Accuracy#78.9$Neural Architecture Search#ImageNet#Params#5.5M$Neural Architecture Search#ImageNet#MACs#418M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.5$Neural Architecture Search#ImageNet#Accuracy#76.5$Neural Architecture Search#ImageNet#Params#4.5M$Neural Architecture Search#ImageNet#MACs#242M
2107.11500v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#21.24$Neural Architecture Search#ImageNet#Accuracy#78.76$Neural Architecture Search#ImageNet#Params#602M$Neural Architecture Search#CIFAR-100#Percentage Error#19.39$Neural Architecture Search#CIFAR-100#PARAMS#602M$Neural Architecture Search#CIFAR-100#Search Time (GPU days)#1.57$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#3.277%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.1$Neural Architecture Search#CIFAR-10#FLOPS#602M
1911.13053v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#21.6$Neural Architecture Search#ImageNet#Accuracy#78.4$Neural Architecture Search#ImageNet#FLOPs#611M$Neural Architecture Search#ImageNet#Params#6.4M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.2$Neural Architecture Search#ImageNet#Accuracy#77.8$Neural Architecture Search#ImageNet#FLOPs#466M$Neural Architecture Search#ImageNet#Params#5.3M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.5$Neural Architecture Search#ImageNet#Accuracy#77.5$Neural Architecture Search#ImageNet#FLOPs#406M$Neural Architecture Search#ImageNet#Params#4.9M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.9$Neural Architecture Search#ImageNet#Accuracy#77.1$Neural Architecture Search#ImageNet#FLOPs#348M$Neural Architecture Search#ImageNet#Params#4.2M$Neural Architecture Search#CIFAR-100#Percentage Error#11.7$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#1.7%
2005.03566v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.1$Neural Architecture Search#ImageNet#Accuracy#77.9$Neural Architecture Search#ImageNet#Params#5.5M$Neural Architecture Search#ImageNet#MACs#449M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.39%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.25$Neural Architecture Search#CIFAR-10#Parameters#3.25M$Neural Architecture Search#CIFAR-10#FLOPS#534M$Image Classification#CIFAR-10#Percentage correct#98.28$Image Classification#CIFAR-10#Percentage correct#97.61$Image Classification#CIFAR-10#PARAMS#5.5M
2004.01961v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.3$Neural Architecture Search#ImageNet#Accuracy#77.7$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.5$Neural Architecture Search#ImageNet#Accuracy#76.5
1912.09640v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.4$Neural Architecture Search#ImageNet#Accuracy#77.6$Neural Architecture Search#ImageNet#Params#5.9M$Neural Architecture Search#ImageNet#MACs#363M$Neural Architecture Search#ImageNet#Top-1 Error Rate#22.8$Neural Architecture Search#ImageNet#Accuracy#77.2$Neural Architecture Search#ImageNet#Params#5.5M$Neural Architecture Search#ImageNet#MACs#329M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.7$Neural Architecture Search#ImageNet#Accuracy#76.3$Neural Architecture Search#ImageNet#Params#4.7M$Neural Architecture Search#ImageNet#MACs#260M
2004.05565v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.8$Neural Architecture Search#ImageNet#Accuracy#77.2$Neural Architecture Search#ImageNet#MACs#325M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.0$Neural Architecture Search#ImageNet#Accuracy#76.0$Neural Architecture Search#ImageNet#MACs#238M$Neural Architecture Search#ImageNet#Top-1 Error Rate#26.8$Neural Architecture Search#ImageNet#Accuracy#73.2$Neural Architecture Search#ImageNet#MACs#126M$Neural Architecture Search#ImageNet#Top-1 Error Rate#31.7$Neural Architecture Search#ImageNet#Accuracy#68.3$Neural Architecture Search#ImageNet#MACs#56M
1911.12126v4.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.8$Neural Architecture Search#ImageNet#MACs#386M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.54%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.25$Neural Architecture Search#CIFAR-10#Parameters#2.8M$Neural Architecture Search#CIFAR-10#FLOPS#746M
2003.11236v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#22.9$Neural Architecture Search#ImageNet#Accuracy#77.1$Neural Architecture Search#ImageNet#Params#6.5M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.2$Neural Architecture Search#ImageNet#Accuracy#76.8$Neural Architecture Search#ImageNet#Params#5.2M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.8$Neural Architecture Search#ImageNet#Accuracy#76.2$Neural Architecture Search#ImageNet#Params#4.7M$Image Classification#ImageNet#Top 1 Accuracy#77.1%$Image Classification#ImageNet#Top 5 Accuracy#93.3$Image Classification#ImageNet#Number of params#6.5M$Image Classification#ImageNet#GFLOPs#0.366$Image Classification#ImageNet#Top 1 Accuracy#76.8%$Image Classification#ImageNet#Top 5 Accuracy#93$Image Classification#ImageNet#Number of params#5.2M$Image Classification#ImageNet#GFLOPs#0.324$Image Classification#ImageNet#Top 1 Accuracy#76.2%$Image Classification#ImageNet#Top 5 Accuracy#92.5$Image Classification#ImageNet#Number of params#4.7M$Image Classification#ImageNet#GFLOPs#0.284
1908.06022v6.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.1$Neural Architecture Search#ImageNet#Accuracy#76.9$Neural Architecture Search#ImageNet#Params#6.7M$Neural Architecture Search#ImageNet#MACs#365M$Neural Architecture Search#ImageNet#Top-1 Error Rate#23.7$Neural Architecture Search#ImageNet#Accuracy#76.3$Neural Architecture Search#ImageNet#Params#6.5M$Neural Architecture Search#ImageNet#MACs#329M$Neural Architecture Search#ImageNet#Top-1 Error Rate#24.4$Neural Architecture Search#ImageNet#Accuracy#75.6$Neural Architecture Search#ImageNet#Params#6.0M$Neural Architecture Search#ImageNet#MACs#280M$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#Top 5 Accuracy#96$Image Classification#ImageNet#Number of params#27.8M$Image Classification#ImageNet#Hardware Burden#12G$Image Classification#ImageNet#Operations per network pass#0.42G$Image Classification#ImageNet#GFLOPs#8.4$Image Classification#ImageNet#Top 1 Accuracy#76.9%$Image Classification#ImageNet#Top 5 Accuracy#93.4$Image Classification#ImageNet#Number of params#6.7M$Image Classification#ImageNet#GFLOPs#0.730$Image Classification#ImageNet#Top 1 Accuracy#76.3%$Image Classification#ImageNet#Top 5 Accuracy#93$Image Classification#ImageNet#Number of params#6.5M$Image Classification#ImageNet#GFLOPs#0.658$Image Classification#ImageNet#Top 1 Accuracy#75.6%$Image Classification#ImageNet#Top 5 Accuracy#92.6$Image Classification#ImageNet#Number of params#6M$Image Classification#ImageNet#GFLOPs#0.560
1908.09791v5.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.1$Neural Architecture Search#ImageNet#Accuracy#76.9$Neural Architecture Search#ImageNet#MACs#230M
2007.04785v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.5$Neural Architecture Search#ImageNet#Accuracy#76.5$Neural Architecture Search#ImageNet#Params#6.4M$Neural Architecture Search#ImageNet#MACs#577M
2002.10389v4.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.5$Neural Architecture Search#ImageNet#Accuracy#76.5
2009.09209v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.9$Neural Architecture Search#ImageNet#Accuracy#76.1$Neural Architecture Search#ImageNet#Params#5.6M$Neural Architecture Search#ImageNet#MACs#632M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.54%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.3$Neural Architecture Search#CIFAR-10#Parameters#4.0M
1906.09607v3.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#23.9$Neural Architecture Search#ImageNet#FLOPs#479M$Image Classification#ImageNet#Top 1 Accuracy#75.9%$Image Classification#ImageNet#Top 5 Accuracy#92.6
1912.00195v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#24.1$Neural Architecture Search#ImageNet#Accuracy#75.9$Neural Architecture Search#ImageNet#Params#5.4M$Neural Architecture Search#ImageNet#MACs#598M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.39%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.25$Neural Architecture Search#CIFAR-10#Parameters#3.8M$Node Classification#PPI#F1#99.46
1907.05737v4.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#24.2$Neural Architecture Search#ImageNet#Accuracy#75.8$Neural Architecture Search#ImageNet#Params#5.3M$Neural Architecture Search#ImageNet#MACs#597M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.51%$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.57%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.1$Neural Architecture Search#CIFAR-10#Parameters#3.6M
2012.12540v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#24.4$Neural Architecture Search#ImageNet#Accuracy#75.6$Neural Architecture Search#ImageNet#Params#5.3$Neural Architecture Search#ImageNet#MACs#599$Neural Architecture Search#ImageNet#Params#5.1$Neural Architecture Search#ImageNet#MACs#570$Neural Architecture Search#ImageNet#Top-1 Error Rate#25.1$Neural Architecture Search#ImageNet#Accuracy#74.9$Neural Architecture Search#ImageNet#Params#4.9$Neural Architecture Search#ImageNet#MACs#547
2108.11014v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#24.7$Neural Architecture Search#ImageNet#Params#5.1M$Neural Architecture Search#ImageNet#MACs#568M$Neural Architecture Search#ImageNet#Top-1 Error Rate#25.2$Neural Architecture Search#ImageNet#MACs#578M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.25%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.4$Neural Architecture Search#CIFAR-10#Parameters#3.6M
1904.01569v2.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#25.3$Neural Architecture Search#ImageNet#FLOPs#583M$Neural Architecture Search#ImageNet#Params#5.6M$Image Classification#ImageNet#Top 1 Accuracy#80.1%$Image Classification#ImageNet#Top 5 Accuracy#94.8$Image Classification#ImageNet#Number of params#61.5M$Image Classification#ImageNet#GFLOPs#7.9$Image Classification#ImageNet#Top 1 Accuracy#74.7%$Image Classification#ImageNet#Top 5 Accuracy#92.2$Image Classification#ImageNet#Number of params#5.6M$Image Classification#ImageNet#GFLOPs#0.583
2005.07669v1.pdf	Neural Architecture Search#ImageNet#Top-1 Error Rate#29.51$Neural Architecture Search#ImageNet#Accuracy#70.49$Neural Architecture Search#CIFAR-100#Percentage Error#18.83$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.82%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#1
1904.00420v4.pdf	Neural Architecture Search#ImageNet#Accuracy#75.3$Neural Architecture Search#ImageNet#MACs#465M$Neural Architecture Search#ImageNet#Accuracy#75.1$Neural Architecture Search#ImageNet#MACs#375M$Neural Architecture Search#ImageNet#Accuracy#74.7$Neural Architecture Search#ImageNet#MACs#328M
2005.02960v3.pdf	Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.38$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#151200
1802.07191v3.pdf	Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.37$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#75600
1910.11858v3.pdf	Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#46.3$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#100800
2006.04647v3.pdf	Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#38.33$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#38.33$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#1.7$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (Test)#36.37$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#36.56$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#17.4
2007.09380v3.pdf	Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Accuracy (val)#46.07$Neural Architecture Search#NAS-Bench-201, ImageNet-16-120#Search time (s)#18000
2106.11655v3.pdf	Neural Architecture Search#CIFAR-100#Percentage Error#17.44$Neural Architecture Search#CIFAR-100#PARAMS#3.16M$Neural Architecture Search#CIFAR-10#Top-1 Error Rate#2.62%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.5$Neural Architecture Search#CIFAR-10#Parameters#3.7M
2101.07429v1.pdf	Neural Architecture Search#LIDC-IDRI#Specificity (VEB+)#95.04$Neural Architecture Search#LIDC-IDRI#F1 score#0.8929$Lung Nodule Classification#LIDC-IDRI#Accuracy#90.77
2006.09264v3.pdf	Neural Architecture Search#CIFAR-10#Top-1 Error Rate#3.35%$Neural Architecture Search#CIFAR-10#Search Time (GPU days)#0.10$Neural Architecture Search#CIFAR-10#Parameters#2.9M
1802.03997v1.pdf	Community Detection#Facebook Celebrities#Modularity#0.649$Community Detection#Facebook Companies#Modularity#0.684$Community Detection#Facebook Athletes#Modularity#0.692$Community Detection#Facebook Artists#Modularity#0.562$Community Detection#Facebook Government#Modularity#0.712$Community Detection#Facebook TV Show#Modularity#0.847$Community Detection#Facebook Politicians#Modularity#0.859$Community Detection#Facebook Media#Modularity#0.571$Node Classification#Deezer Hungary#Micro-F1#0.409$Node Classification#Deezer Croatia#Micro-F1#0.381$Node Classification#Deezer Romania#Micro-F1#0.378
1906.04560v1.pdf	Community Detection#Cora#NMI#0.4226
1901.06631v3.pdf	Community Detection#DBLP#F1-Score#0.153$Community Detection#Amazon#F1-score#0.091
1705.08415v6.pdf	Community Detection#Amazon#Accuracy-NE#2
2206.06291v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#66.0$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#74$Human-Object Interaction Detection#V-COCO#AP(S2)#70.7$Human-Object Interaction Detection#HICO-DET#mAP#32.22$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#74
2202.00259v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#65.3$Human-Object Interaction Detection#V-COCO#AP(S2)#67.1$Human-Object Interaction Detection#V-COCO#AP(S1)#64.2$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#43$Human-Object Interaction Detection#V-COCO#AP(S2)#66.3$Human-Object Interaction Detection#HICO-DET#mAP#31.43
2108.05077v2.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#63.91$Human-Object Interaction Detection#V-COCO#AP(S2)#65.89$Human-Object Interaction Detection#HICO-DET#mAP#32.07
2112.01838v2.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#61.3$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#131$Human-Object Interaction Detection#V-COCO#AP(S2)#67.1$Human-Object Interaction Detection#V-COCO#AP(S1)#60.7$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#64$Human-Object Interaction Detection#V-COCO#AP(S2)#66.2$Human-Object Interaction Detection#V-COCO#AP(S1)#59.0$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#43$Human-Object Interaction Detection#V-COCO#AP(S2)#64.5$Human-Object Interaction Detection#HICO-DET#mAP#32.62$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#124$Human-Object Interaction Detection#HICO-DET#mAP#32.31$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#61$Human-Object Interaction Detection#HICO-DET#mAP#31.66$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#42
2103.05399v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#58.8$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#46$Human-Object Interaction Detection#V-COCO#AP(S2)#61.0$Human-Object Interaction Detection#V-COCO#AP(S1)#58.3$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#63$Human-Object Interaction Detection#V-COCO#AP(S2)#60.7$Human-Object Interaction Detection#HICO-DET#mAP#29.90$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#63$Human-Object Interaction Detection#HICO-DET#mAP#29.07$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#46$Human-Object Interaction Concept Discovery#HICO-DET#Unknown (AP)#27.42
2010.01005v2.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#56.1$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#68$Human-Object Interaction Detection#HICO-DET#mAP#21.81$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#68
2104.13682v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#55.2$Human-Object Interaction Detection#V-COCO#AP(S2)#64.4$Human-Object Interaction Detection#HICO-DET#mAP#23.46
2104.05269v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#54.7
2012.06060v3.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#54.2$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#500$Human-Object Interaction Detection#V-COCO#AP(S2)#60.9$Human-Object Interaction Detection#HICO-DET#mAP#29.26
2008.02918v3.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#53.34$Human-Object Interaction Detection#HICO-DET#mAP#22.37
2010.16219v2.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#53.3$Human-Object Interaction Detection#V-COCO#AP(S2)#60.3$Human-Object Interaction Detection#HICO-DET#mAP#26.29$Human-Object Interaction Detection#HICO-DET#mAP#23.36
2003.05541v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#51.76$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#312$Human-Object Interaction Detection#V-COCO#AP(S2)#57.0$Human-Object Interaction Detection#HICO-DET#mAP#19.8
1912.12898v3.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#51.1$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#71$Human-Object Interaction Detection#HICO-DET#mAP#21.92$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#71
2004.00945v2.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#51.0$Human-Object Interaction Detection#HICO#mAP#46.3$Human-Object Interaction Detection#HICO-DET#mAP#22.65
1811.08264v4.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#49.0$Human-Object Interaction Detection#V-COCO#Time Per Frame(ms)#513$Human-Object Interaction Detection#Ambiguious-HOI#mAP#8.22$Human-Object Interaction Detection#HICO-DET#mAP#17.84$Human-Object Interaction Detection#HICO-DET#mAP#17.54$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#512
1808.10437v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#44.7$Human-Object Interaction Detection#Ambiguious-HOI#mAP#8.14$Human-Object Interaction Detection#HICO-DET#mAP#14.84
1808.07962v1.pdf	Human-Object Interaction Detection#V-COCO#AP(S1)#44.0$Human-Object Interaction Detection#HICO-DET#mAP#13.11
2112.06392v2.pdf	Human-Object Interaction Detection#HICO#mAP#65.6$Human-Object Interaction Detection#HICO-DET#mAP#32.35
1904.06539v5.pdf	Human-Object Interaction Detection#HICO#mAP#47.1
1807.10889v1.pdf	Human-Object Interaction Detection#HICO#mAP#39.9
1604.04808v2.pdf	Human-Object Interaction Detection#HICO#mAP#36.1
1711.01467v3.pdf	Human-Object Interaction Detection#HICO#mAP#34.6
1505.01197v3.pdf	Human-Object Interaction Detection#HICO#mAP#28.5$Weakly Supervised Object Detection#HICO-DET#MAP#2.15$Weakly Supervised Object Detection#Charades#MAP#0.99
2004.08154v2.pdf	Human-Object Interaction Detection#Ambiguious-HOI#mAP#10.37$Human-Object Interaction Detection#HICO-DET#mAP#21.34
2112.08647v1.pdf	Human-Object Interaction Detection#HICO-DET#mAP#35.78
2203.13954v2.pdf	Human-Object Interaction Detection#HICO-DET#mAP#34.95
2103.05983v2.pdf	Human-Object Interaction Detection#HICO-DET#mAP#28.87$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#71
2103.04503v1.pdf	Human-Object Interaction Detection#HICO-DET#mAP#26.61$Human-Object Interaction Detection#HICO-DET#mAP#23.46
2008.06254v4.pdf	Human-Object Interaction Detection#HICO-DET#mAP#25.94$Human-Object Interaction Detection#HICO-DET#mAP#22.15
2109.04047v1.pdf	Human-Object Interaction Detection#HICO-DET#mAP#22.11
1704.07333v3.pdf	Human-Object Interaction Detection#HICO-DET#mAP#9.94$Human-Object Interaction Detection#HICO-DET#Time Per Frame (ms)#145
2203.14272v2.pdf	Affordance Recognition#HICO-DET#HICO#82.47$Affordance Recognition#HICO-DET#COCO-Val2017#72.08$Affordance Recognition#HICO-DET#Object365#57.53$Affordance Recognition#HICO-DET#Novel classes#18.55$Affordance Recognition#HICO-DET(Unknown Concepts)#COCO-Val2017#56.19$Affordance Recognition#HICO-DET(Unknown Concepts)#Obj365#46.32$Affordance Recognition#HICO-DET(Unknown Concepts)#HICO#64.50$Affordance Recognition#HICO-DET(Unknown Concepts)#Novel Classes#18.55$Human-Object Interaction Concept Discovery#HICO-DET#Unknown (AP)#33.58
2104.02867v2.pdf	Affordance Recognition#HICO-DET#HICO#59.44$Affordance Recognition#HICO-DET#COCO-Val2017#52.01$Affordance Recognition#HICO-DET#Object365#50.94$Affordance Recognition#HICO-DET#Novel classes#15.64$Affordance Recognition#HICO-DET(Unknown Concepts)#COCO-Val2017#36.80$Affordance Recognition#HICO-DET(Unknown Concepts)#Obj365#34.38$Affordance Recognition#HICO-DET(Unknown Concepts)#HICO#42.00$Affordance Recognition#HICO-DET(Unknown Concepts)#Novel Classes#15.64$Human-Object Interaction Concept Discovery#HICO-DET#Unknown (AP)#24.38
2007.12407v2.pdf	Affordance Recognition#HICO-DET#HICO#43.15$Affordance Recognition#HICO-DET#COCO-Val2017#36.74$Affordance Recognition#HICO-DET#Object365#35.73$Affordance Recognition#HICO-DET#Novel classes#12.05$Affordance Recognition#HICO-DET(Unknown Concepts)#COCO-Val2017#28.71$Affordance Recognition#HICO-DET(Unknown Concepts)#Obj365#27.58$Affordance Recognition#HICO-DET(Unknown Concepts)#HICO#32.76$Affordance Recognition#HICO-DET(Unknown Concepts)#Novel Classes#12.05
2103.08214v2.pdf	Affordance Recognition#HICO-DET#HICO#37.32$Affordance Recognition#HICO-DET#COCO-Val2017#25.11$Affordance Recognition#HICO-DET#Object365#25.21$Affordance Recognition#HICO-DET#Novel classes#6.80
2005.10636v2.pdf	Program Synthesis#SPoC TestW#Success rate @budget 100#57.0$Program Synthesis#SPoC TestP#Success rate @budget 100#38.5$Program Repair#DeepFix#Average Success Rate#68.2
1906.04908v1.pdf	Program Synthesis#SPoC TestW#Success rate @budget 100#53.7$Program Synthesis#SPoC TestP#Success rate @budget 100#34.2
2203.13474v4.pdf	Program Synthesis#HumanEval#Pass@1#29.28
2007.04973v4.pdf	Type prediction#DeepTyper#Accuracy@5#84.60$Source Code Summarization#CodeSearchNet#F1#17.24$Method name prediction#CodeSearchNet#F1#17.24
2009.08366v4.pdf	Type prediction#ManyTypes4TypeScript#Average Accuracy#62.51$Type prediction#ManyTypes4TypeScript#Average Precision#60.06$Type prediction#ManyTypes4TypeScript#Average Recall#61.08$Type prediction#ManyTypes4TypeScript#Average F1#60.57$Code Search#CodeSearchNet#Overall#77.4$Code Search#CodeSearchNet#Go#84.1$Code Search#CodeSearchNet#Ruby#73.2$Code Search#CodeSearchNet#Python#87.9$Code Search#CodeSearchNet#Java#75.7$Code Search#CodeSearchNet#JS#71.1$Code Search#CodeSearchNet#PHP#72.5
2112.02043v4.pdf	Type prediction#ManyTypes4TypeScript#Average Accuracy#61.29$Type prediction#ManyTypes4TypeScript#Average Precision#58.81$Type prediction#ManyTypes4TypeScript#Average Recall#58.91$Type prediction#ManyTypes4TypeScript#Average F1#58.86$Type prediction#ManyTypes4TypeScript#Average Accuracy#61.00$Type prediction#ManyTypes4TypeScript#Average Precision#58.36$Type prediction#ManyTypes4TypeScript#Average F1#58.63
2003.13848v1.pdf	Type prediction#Py150#MRR#98.7$Value prediction#Py150#MRR#73.6
2106.06600v2.pdf	Program Repair#DeepFix#Average Success Rate#71.7$Program Repair#GitHub-Python#Accuracy (%)#90.5$Program Repair#GitHub-Python#Accuracy (%)#62.0
1906.10502v3.pdf	Program Repair#DeepFix#Average Success Rate#45.3
1801.10467v1.pdf	Program Repair#DeepFix#Average Success Rate#26.6
2007.06225v3.pdf	Protein Secondary Structure Prediction#CASP12#Q3#0.81$Protein Secondary Structure Prediction#CASP12#Q8#0.70$Protein Secondary Structure Prediction#CASP12#Q3#0.77$Protein Secondary Structure Prediction#CASP12#Q8#0.66$Protein Secondary Structure Prediction#CASP12#Q3#0.76$Protein Secondary Structure Prediction#CASP12#Q8#0.65$Protein Secondary Structure Prediction#TS115#Q3#0.87$Protein Secondary Structure Prediction#TS115#Q8#0.77$Protein Secondary Structure Prediction#TS115#Q3#0.85$Protein Secondary Structure Prediction#TS115#Q8#0.74$Protein Secondary Structure Prediction#TS115#Q3#0.84$Protein Secondary Structure Prediction#TS115#Q8#0.73$Protein Secondary Structure Prediction#CB513#Q8#0.74$Protein Secondary Structure Prediction#CB513#Q3#0.86$Protein Secondary Structure Prediction#CB513#Q8#0.71$Protein Secondary Structure Prediction#CB513#Q3#0.84$Protein Secondary Structure Prediction#CB513#Q8#0.7$Protein Secondary Structure Prediction#CB513#Q3#0.83
1512.00843v3.pdf	Protein Secondary Structure Prediction#CullPDB#Q8#0.721522$Protein Secondary Structure Prediction#CB513#Q8#0.697$Protein Secondary Structure Prediction#CB513#Q8#0.684
2002.09116v3.pdf	Two-sample testing#HIGGS Data Set#Avg accuracy#57.9$Two-sample testing#HDGM (d=10, N=4000)#Avg accuracy#65.9$Two-sample testing#CIFAR-10 vs CIFAR-10.1 (1000 samples)#Avg accuracy#74.4$Two-sample testing#Blob (9 modes, 40 for each)#Avg accuracy#98.5$Two-sample testing#MNIST vs Fake MNIST#Avg accuracy#91
1712.10136v1.pdf	Gesture Recognition#Chalearn 2014#Accuracy#93.2
1811.07081v2.pdf	Gesture Recognition#ChaLearn 2013#Accuracy#92.08$Gesture Recognition#MSRC-12#Accuracy#99.01$Gesture Recognition#ChaLearn 2016#Accuracy#39.95
1901.06958v2.pdf	Gesture Recognition#CapgMyo DB-c#Accuracy#96.8$Gesture Recognition#Ninapro DB-1 12 gestures#Accuracy#84.7$Gesture Recognition#Ninapro DB-1 8 gestures#Accuracy#90.7$Gesture Recognition#CapgMyo DB-b#Accuracy#97.1$Gesture Recognition#CapgMyo DB-a#Accuracy#97.1
2010.08946v1.pdf	Gesture Recognition#DVS128 Gesture#Accuracy (%)#97.73
2005.02183v1.pdf	Gesture Recognition#DVS128 Gesture#Accuracy (%)#86.81
1506.01911v3.pdf	Gesture Recognition#Montalbano#Error rate#2.77$Gesture Recognition#Montalbano#Jaccard (Mean)#90.6$Gesture Recognition#Montalbano#Precision#94.49$Gesture Recognition#Montalbano#Recall#94.57
2007.04571v3.pdf	Personality Trait Recognition#Essays#Precision#60.48$Personality Trait Recognition#Essays#Recall#61.66$Personality Trait Recognition#Essays#F-Measure#61.04$Personality Trait Recognition#Essays#Accuracy#60.24$Personality Trait Recognition#Essays#Precision#51.42$Personality Trait Recognition#Essays#Recall#100$Personality Trait Recognition#Essays#F-Measure#67.91$Personality Trait Recognition#Essays#Accuracy#51.42
2008.01515v1.pdf	Multi-Label Classification Of Biomedical Texts#MIMIC-III#Micro F1#0.537
1905.10070v2.pdf	Multi-Label Text Classification#Amazon-12K#P@1#94.87$Multi-Label Text Classification#Amazon-12K#P@3#79.16$Multi-Label Text Classification#Amazon-12K#P@5#63.16$Multi-Label Text Classification#Amazon-12K#nDCG@3#89.13$Multi-Label Text Classification#Amazon-12K#nDCG@5#87.57$Multi-Label Text Classification#EUR-Lex#nDCG@5#59.28$Multi-Label Text Classification#EUR-Lex#P@1#74.95$Multi-Label Text Classification#EUR-Lex#P@3#61.48$Multi-Label Text Classification#EUR-Lex#P@5#50.71$Multi-Label Text Classification#EUR-Lex#nDCG@3#64.89$Multi-Label Text Classification#Kan-Shan Cup#P@1#54.38$Multi-Label Text Classification#Kan-Shan Cup#P@3#34.6$Multi-Label Text Classification#Kan-Shan Cup#P@5#25.88$Multi-Label Text Classification#Kan-Shan Cup#nDCG@3#51.7$Multi-Label Text Classification#Kan-Shan Cup#nDCG@5#54.65$Multi-Label Text Classification#Wiki-30K#P@1#84.18$Multi-Label Text Classification#Wiki-30K#P@3#73.14$Multi-Label Text Classification#Wiki-30K#P@5#62.87$Multi-Label Text Classification#Wiki-30K#nDCG@3#75.64$Multi-Label Text Classification#Wiki-30K#nDCG@5#67.82$Multi-Label Text Classification#AAPD#P@1#84.48$Multi-Label Text Classification#AAPD#P@3#60.72$Multi-Label Text Classification#AAPD#P@5#41.19$Multi-Label Text Classification#AAPD#nDCG@3#80.11$Multi-Label Text Classification#AAPD#nDCG@5#83.7
2010.04971v1.pdf	Multi-Label Text Classification#Freecode#F1-score#46$Multi-Label Text Classification#Freecode#F1-score#45.3$Multi-Label Text Classification#Freecode#F1-score#36.4$Multi-Label Text Classification#Freecode#F1-score#36$Multi-Label Text Classification#Freecode#F1-score#33.2
1906.02192v1.pdf	Multi-Label Text Classification#EUR-Lex#nDCG@5#82.3$Multi-Label Text Classification#EUR-Lex#P@5#68.7$Multi-Label Text Classification#EUR-Lex#Micro F1#73.2$Multi-Label Text Classification#EUR-Lex#RP@5#79.6
2106.07932v4.pdf	Multi-Label Text Classification#MIMIC-III-50#Micro-F1#68.555
2106.07544v1.pdf	Multi-Label Text Classification#Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China#Micro F1#0.85431$Multi-Label Text Classification#Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China#1:1 Accuracy#0.80352$Multi-Label Text Classification#Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China#F1 - macro#0.20803
2108.00261v1.pdf	Multi-Label Text Classification#LF-AmazonTitles-131K#Precision@1#38.4$Multi-Label Text Classification#LF-AmzonTitles-131K#Precision@1#40.74
1906.02124v2.pdf	Multi-Label Text Classification#USPTO-3M#F1#66.83%
2109.04712v2.pdf	Multi-Label Text Classification#Reuters-21578#Micro-F1#90.74$Multi-Label Text Classification#Reuters-21578#Micro-F1#90.70$Multi-Label Text Classification#Reuters-21578#Micro-F1#90.62
1802.02311v2.pdf	Multi-Label Text Classification#MIMIC-III#Precision#0.249$Multi-Label Text Classification#MIMIC-III#Recall#0.1138
2008.06695v1.pdf	Multi-Label Text Classification#AAPD#Micro F1#72.8
2101.04997v1.pdf	Multi-Label Text Classification#RCV1#Micro-F1#79.3$Multi-Label Text Classification#RCV1#Macro-F1#47.3
2206.13188v2.pdf	Multi-Label Image Classification#BigEarthNet#mean average precision#89.3$Multi-Label Image Classification#BigEarthNet#mean average precision#84.4$Image Classification#EuroSAT#Accuracy (%)#98.9$Image Classification#EuroSAT#Accuracy (%)#94.4
2111.09451v3.pdf	Multi-Label Image Classification#BigEarthNet#FScore#79$Multi-Label Image Classification#BigEarthNet#FScore#77.1$Multi-Label Image Classification#BigEarthNet#FScore#76.8$Multi-Label Image Classification#BigEarthNet#FScore#75.2
2108.02456v2.pdf	Multi-Label Image Classification#VOC2007#MAP#96.8
1812.07119v1.pdf	Image Retrieval with Multi-Modal Query#MIT-States#Recall@1#12.2$Image Retrieval with Multi-Modal Query#MIT-States#Recall@5#31.9$Image Retrieval with Multi-Modal Query#MIT-States#Recall@10#43.1$Image Retrieval with Multi-Modal Query#FashionIQ#Recall@10#3.34$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#14.1$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#42.5$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#63.8
1411.4555v2.pdf	Image Retrieval with Multi-Modal Query#MIT-States#Recall@1#11.9$Image Retrieval with Multi-Modal Query#MIT-States#Recall@5#31.0$Image Retrieval with Multi-Modal Query#MIT-States#Recall@10#42.0$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#12.3$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#40.2$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#61.8
1803.09851v2.pdf	Image Retrieval with Multi-Modal Query#MIT-States#Recall@1#8.8$Image Retrieval with Multi-Modal Query#MIT-States#Recall@5#27.3$Image Retrieval with Multi-Modal Query#MIT-States#Recall@10#39.1
1511.05756v1.pdf	Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#12.2$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#40$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#61.7
1708.01311v1.pdf	Image Retrieval with Multi-Modal Query#Fashion200k#Recall@1#6.3$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@10#19.9$Image Retrieval with Multi-Modal Query#Fashion200k#Recall@50#38.3
1711.05535v4.pdf	Cross-Modal Retrieval#CUHK-PEDES#Text-to-image Medr#2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#65.6$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#95.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#89.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#47.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#90$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#79.9$Cross-Modal Retrieval#COCO 2014#Image-to-text Medr#1$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#55.6$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#81.9$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#89.5$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#39.1$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#80.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#69.2$Text based Person Retrieval#CUHK-PEDES#R@1#44.4$Text based Person Retrieval#CUHK-PEDES#R@10#75.07$Text based Person Retrieval#CUHK-PEDES#R@5#66.26
2102.05918v2.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#77$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#96.9$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#93.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#59.9$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#89.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#83.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#95.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#100$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#99.8$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#84.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#98.6$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#97.4$Image Classification#ImageNet#Top 1 Accuracy#88.64%$Image Classification#ImageNet#Top 5 Accuracy#98.67%$Image Classification#ImageNet#Number of params#480M$Image Classification#VTAB-1k#Top-1 Accuracy#79.99$Image Classification#Flowers-102#Accuracy#99.65%$Fine-Grained Image Classification#Stanford Cars#Accuracy#96.13%$Fine-Grained Image Classification#Food-101#Accuracy#95.88$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#96.19%$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#70.1$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#76.4$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#92.2$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Public)#-$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#75.8$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Public)#-
2202.10401v4.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#75.6$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#96.7$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#92.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#59.0$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#89.9$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#83.2
2111.02387v3.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#76.16$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#96.82$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#93.16$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#57.08$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#90.07$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#82.66
2203.16778v1.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#68.9$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#95.4$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#90.1$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#52.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#87.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#79.6$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#89.5$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#99.6$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#98.4$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#75.8$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#96.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#94.2
2207.14757v1.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#64.9$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#94.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#88.6$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#51.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#87.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#79.2
2203.01445v2.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#55.6$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#91.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#82.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#41.5$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#82.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#72.1
2003.03772v1.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#53.7$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#91.0$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#83.2$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#39.7$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#79.8$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#69.1$Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#74.1$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#96.6$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#93.0$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#53.9$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#87.2$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#79.4
1906.04402v2.pdf	Cross-Modal Retrieval#COCO 2014#Image-to-text R@1#45.2$Cross-Modal Retrieval#COCO 2014#Image-to-text R@10#84.5$Cross-Modal Retrieval#COCO 2014#Image-to-text R@5#74.3$Cross-Modal Retrieval#COCO 2014#Text-to-image R@1#32.4$Cross-Modal Retrieval#COCO 2014#Text-to-image R@10#75.0$Cross-Modal Retrieval#COCO 2014#Text-to-image R@5#63.0
2204.09730v1.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#72.3$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#72.6$Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#68.2$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#68.3
2012.01345v3.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#64$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#63.9
2103.13061v1.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#60.0$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#60.3
2003.03955v3.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#54.0$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#54.9
1905.01273v1.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#51.8$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#52.8
1804.11146v1.pdf	Cross-Modal Retrieval#Recipe1M#Image-to-text R@1#39.8$Cross-Modal Retrieval#Recipe1M#Text-to-image R@1#40.2
2004.00277v1.pdf	Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#76.4$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#97.3$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#94.3$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#57.4$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#89.0$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#82.3
1707.05612v4.pdf	Cross-Modal Retrieval#Flickr30k#Image-to-text R@1#52.9$Cross-Modal Retrieval#Flickr30k#Image-to-text R@10#87.2$Cross-Modal Retrieval#Flickr30k#Image-to-text R@5#80.5$Cross-Modal Retrieval#Flickr30k#Text-to-image R@1#39.6$Cross-Modal Retrieval#Flickr30k#Text-to-image R@10#79.5$Cross-Modal Retrieval#Flickr30k#Text-to-image R@5#70.1
1809.03544v1.pdf	Medical Report Generation#10,000 People - Re-ID Data in Real Surveillance Scenes#10 steps MAE#12$2D Human Pose Estimation#hoanghuy#0..5sec#1
2005.00333v2.pdf	Cross-Lingual Transfer#XCOPA#Accuracy#76.05
2005.00052v3.pdf	Cross-Lingual Transfer#XCOPA#Accuracy#60.94
2109.13238v2.pdf	Zero-Shot Cross-Lingual Transfer#MaRVL#Accuracy (%)#56.1$Zero-Shot Cross-Lingual Transfer#MaRVL#Accuracy (%)#54.0
2106.16138v2.pdf	Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#91.0$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#83.8$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#77.1$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#94.4$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#85.5$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#90.3$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#81.7$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#76.3$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#93.7$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#84.5
2012.15674v4.pdf	Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#87.9$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#75.6$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#72.3$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#91.9$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#80.9
2007.07834v2.pdf	Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#88.8$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#75.4$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#72.9$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#89.3$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#80.7
2009.05166v3.pdf	Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#87.5$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#71.9$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#68.5$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#84.4$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#77.0
2005.13013v2.pdf	Zero-Shot Cross-Lingual Transfer#XTREME#Sentence-pair Classification#83.9$Zero-Shot Cross-Lingual Transfer#XTREME#Structured Prediction#69.4$Zero-Shot Cross-Lingual Transfer#XTREME#Question Answering#67.2$Zero-Shot Cross-Lingual Transfer#XTREME#Sentence Retrieval#76.5$Zero-Shot Cross-Lingual Transfer#XTREME#Avg#73.5
2007.07683v1.pdf	Cross-Lingual NER#CoNLL Spanish#F1#79.31$Cross-Lingual NER#CoNLL German#F1#74.82$Cross-Lingual NER#CoNLL Dutch#F1#82.9$Cross-Lingual NER#NoDaLiDa Norwegian Bokmål#F1#81.17
2004.12440v2.pdf	Cross-Lingual NER#CoNLL Spanish#F1#78$Cross-Lingual NER#CoNLL Spanish#F1#77.75$Cross-Lingual NER#CoNLL Spanish#F1#76.94$Cross-Lingual NER#CoNLL German#F1#75.33$Cross-Lingual NER#CoNLL German#F1#74.97$Cross-Lingual NER#CoNLL German#F1#73.22$Cross-Lingual NER#CoNLL Dutch#F1#81.33$Cross-Lingual NER#CoNLL Dutch#F1#80.89$Cross-Lingual NER#CoNLL Dutch#F1#80.7
1911.06161v2.pdf	Cross-Lingual NER#CoNLL Spanish#F1#76.75$Cross-Lingual NER#CoNLL Spanish#F1#74.59$Cross-Lingual NER#CoNLL German#F1#73.16$Cross-Lingual NER#CoNLL German#F1#70.79$Cross-Lingual NER#CoNLL Dutch#F1#80.44$Cross-Lingual NER#CoNLL Dutch#F1#79.57$Cross-Lingual NER#MSRA#F1#77.89$Cross-Lingual NER#MSRA#F1#76.42$Cross-Lingual NER#Europeana French#F1#55.3$Cross-Lingual NER#Europeana French#F1#50.89
1912.01389v2.pdf	Cross-Lingual NER#CoNLL Spanish#F1#76.53$Cross-Lingual NER#CoNLL German#F1#72.44$Cross-Lingual NER#CoNLL Dutch#F1#83.35
1904.09077v2.pdf	Cross-Lingual NER#CoNLL Spanish#F1#74.96$Cross-Lingual NER#CoNLL German#F1#69.56$Cross-Lingual NER#CoNLL Dutch#F1#77.57
1810.03552v3.pdf	Cross-Lingual NER#CoNLL Spanish#F1#73.5$Cross-Lingual NER#CoNLL German#F1#56$Cross-Lingual NER#CoNLL Dutch#F1#72.4
1412.6334v4.pdf	Cross-Lingual Document Classification#Reuters RCV1/RCV2 English-to-German#Accuracy#92.7$Cross-Lingual Document Classification#Reuters RCV1/RCV2 German-to-English#Accuracy#84.4
1404.4641v1.pdf	Cross-Lingual Document Classification#Reuters RCV1/RCV2 English-to-German#Accuracy#88.1$Cross-Lingual Document Classification#Reuters RCV1/RCV2 German-to-English#Accuracy#79.2
1312.6173v4.pdf	Cross-Lingual Document Classification#Reuters RCV1/RCV2 English-to-German#Accuracy#86.2$Cross-Lingual Document Classification#Reuters RCV1/RCV2 German-to-English#Accuracy#76.9
1909.07009v2.pdf	Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Chinese#Accuracy#93.32$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#96.8$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#96.05$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Russian#Accuracy#89.7$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-German#Accuracy#96.95%
1909.04761v2.pdf	Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Chinese#Accuracy#82.48$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Italian#Accuracy#76.02$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#79.1$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#89.42$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Russian#Accuracy#67.83$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-German#Accuracy#91.62%$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Japanese#Accuracy#69.57
1805.09821v1.pdf	Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Chinese#Accuracy#74.73$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Chinese#Accuracy#71.97$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Italian#Accuracy#69.38$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Italian#Accuracy#60.73$Cross-Lingual Document Classification#MLDoc Zero-Shot German-to-French#Accuracy#75.45$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#72.5$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#69.5$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#66.65$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#74.52$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#72.83$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#72.38$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Russian#Accuracy#61.42$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Russian#Accuracy#60.8$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-German#Accuracy#81.2%$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-German#Accuracy#71.83%$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Japanese#Accuracy#67.63
1812.10464v2.pdf	Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Chinese#Accuracy#71.93$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Italian#Accuracy#69.43$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Spanish#Accuracy#77.33$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-French#Accuracy#77.95$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Russian#Accuracy#67.78$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-German#Accuracy#84.78%$Cross-Lingual Document Classification#MLDoc Zero-Shot English-to-Japanese#Accuracy#60.3$Cross-Lingual Bitext Mining#BUCC German-to-English#F1 score#96.19$Cross-Lingual Bitext Mining#BUCC French-to-English#F1 score#93.91$Cross-Lingual Bitext Mining#BUCC Russian-to-English#F1 score#93.3$Cross-Lingual Bitext Mining#BUCC Chinese-to-English#F1 score#92.27
2108.13327v4.pdf	News Classification#N15News#Accuracy#0.9249$News Classification#N15News#Accuracy#0.9203$News Classification#N15News#Accuracy#0.8610$News Classification#N15News#Accuracy#0.8471$News Classification#N15News#Accuracy#0.8202$News Classification#N15News#Accuracy#0.7951$News Classification#N15News#Accuracy#0.7792$News Classification#N15News#Accuracy#0.7727$News Classification#N15News#Accuracy#0.6065
2209.09062v1.pdf	Variable Disambiguation#SV-Ident#mAP@10#18.93$Variable Disambiguation#SV-Ident#mAP@10#13.59$Variable Disambiguation#SV-Ident#mAP@10#11.27$Variable Disambiguation#SV-Ident#mAP@10#9.43$Variable Detection#SV-Ident#F1#66.1$Variable Detection#SV-Ident#F1#60.17
2109.14573v1.pdf	JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#PSNR#34.35$JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#SSIM#0.907$JPEG Artifact Correction#BSDS500 (Quality 10 Color)#PSNR#27.85$JPEG Artifact Correction#BSDS500 (Quality 10 Color)#PSNR-B#27.52$JPEG Artifact Correction#BSDS500 (Quality 10 Color)#SSIM#0.799$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#32.13$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.57$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.889$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#30.11$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.70$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.868$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#PSNR#29.67$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#PSNR-B#29.22$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#SSIM#0.821$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR#35.41$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR-B#35.35$JPEG Artifact Correction#ICB (Quality 30 Color)#SSIM#0.857$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.75$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.40$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.827$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#PSNR#31.43$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#PSNR-B#30.92$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#SSIM#0.897$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#PSNR#34.53$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#SSIM#0.931$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#34.38$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#34.34$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.844$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#32.18$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#32.15$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.815$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR#33.54$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR-B#32.83$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#SSIM#0.916$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#PSNR#30.14$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#PSNR-B#29.56$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#SSIM#0.867$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#PSNR#31.45$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#PSNR-B#30.72$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#SSIM#0.897$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR#33.54$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR-B#32.78$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#SSIM#0.894$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR#32.31$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR-B#31.74$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#SSIM#0.872$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#30.12$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR-B#29.80$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#SSIM#0.822$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#PSNR#32.00$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#PSNR-B#31.19$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#SSIM#0.885$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#PSNR#33.37$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#PSNR-B#32.32$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#SSIM#0.913$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.77$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.51$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.803
1812.10477v2.pdf	JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#PSNR#34.29$JPEG Artifact Correction#Classic5 (Quality 40 Grayscale)#SSIM#0.9063$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#32.1$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8886$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.7$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8252$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#PSNR#34.54$JPEG Artifact Correction#LIVE1 (Quality 40 Grayscale)#SSIM#0.9304$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR#33.54$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#SSIM#0.9156$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR#33.46$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#SSIM#0.8932$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR#32.19$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#SSIM#0.8704$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#30.03$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#SSIM#0.8194$Color Image Denoising#BSD68 sigma70#PSNR#26.88$Color Image Denoising#BSD68 sigma30#PSNR#30.7$Color Image Denoising#Urban100 sigma30#PSNR#31.78$Color Image Denoising#Kodak24 sigma10#PSNR#37.33$Color Image Denoising#Urban100 sigma70#PSNR#27.74$Color Image Denoising#Kodak24 sigma50#PSNR#29.7$Color Image Denoising#Kodak24 sigma70#PSNR#28.24$Color Image Denoising#Urban100 sigma10#PSNR#36.75$Color Image Denoising#Kodak24 sigma30#PSNR#31.98$Color Image Denoising#BSD68 sigma10#PSNR#36.49$Color Image Denoising#Urban100 sigma50#PSNR#29.38$Grayscale Image Denoising#Kodak24 sigma70#PSNR#26.57$Grayscale Image Denoising#Kodak24 sigma10#PSNR#35.19$Grayscale Image Denoising#Kodak24 sigma50#PSNR#27.88$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.43$Grayscale Image Denoising#BSD68 sigma70#PSNR#25.12$Grayscale Image Denoising#Kodak24 sigma30#PSNR#30.02$Grayscale Image Denoising#Urban100 sigma70#PSNR#25.71$Grayscale Image Denoising#BSD68 sigma30#PSNR#28.58$Grayscale Image Denoising#BSD68 sigma10#PSNR#34.01$Grayscale Image Denoising#Urban100 sigma10#PSNR#35.45$Grayscale Image Denoising#Urban100 sigma30#PSNR#30.08$Grayscale Image Denoising#Urban100 sigma50#PSNR#27.47
2004.09320v2.pdf	JPEG Artifact Correction#BSDS500 (Quality 10 Color)#PSNR#27.69$JPEG Artifact Correction#BSDS500 (Quality 10 Color)#PSNR-B#27.36$JPEG Artifact Correction#BSDS500 (Quality 10 Color)#SSIM#0.810$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.86$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.27$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.901$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.92$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.51$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.882$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#PSNR#29.54$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#PSNR-B#29.04$JPEG Artifact Correction#BSDS500 (Quality 10 Grayscale)#SSIM#0.833$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR#35.20$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR-B#35.67$JPEG Artifact Correction#ICB (Quality 30 Color)#SSIM#0.860$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.53$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.15$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.840$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#PSNR#31.21$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#PSNR-B#30.71$JPEG Artifact Correction#LIVE1 (Quality 30 Color)#SSIM#0.908$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR#34.73$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR-B#34.58$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#SSIM#0.896$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#34.23$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#34.67$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.845$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#32.11$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#32.47$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.815$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR#37.12$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR-B#36.88$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#SSIM#0.924$JPEG Artifact Correction#ICB (Quality 30 Grayscale)#PSNR#38.43$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR#33.23$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#PSNR-B#32.50$JPEG Artifact Correction#LIVE1 (Quality 30 Grayscale)#SSIM#0.925$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#PSNR#29.89$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#PSNR-B#29.29$JPEG Artifact Correction#BSDS500 (Quality 20 Color)#SSIM#0.876$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#PSNR#31.15$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#PSNR-B#30.37$JPEG Artifact Correction#BSDS500 (Quality 30 Color)#SSIM#0.903$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR#33.22$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#PSNR-B#32.42$JPEG Artifact Correction#Classic5 (Quality 30 Grayscale)#SSIM#0.907$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR#31.98$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#PSNR-B#31.37$JPEG Artifact Correction#Classic5 (Quality 20 Grayscale)#SSIM#0.885$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR#29.84$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#PSNR-B#29.43$JPEG Artifact Correction#Classic5 (Quality 10 Grayscale)#SSIM#0.837$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#PSNR#31.79$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#PSNR-B#30.96$JPEG Artifact Correction#BSDS500 (Quality 20 Grayscale)#SSIM#0.894$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#PSNR#33.12$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#PSNR-B#32.42$JPEG Artifact Correction#BSDS500 (Quality 30 Grayscale)#SSIM#0.907$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.65$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.40$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.819
1810.08042v3.pdf	JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#32.09$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#32.00$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.9006$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#30.04$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#30.01$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.882$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.71$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.66$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.838$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR#32.50$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR-B#32.42$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#SSIM#0.826$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#33.99$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#34.37$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.838$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#31.71$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#32.02$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.809$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR#34.30$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR-B#34.18$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#SSIM#0.851$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.63$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.63$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.816
1810.07960v1.pdf	JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.83$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.76$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8975$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.81$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.79$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.878$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.44$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.39$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8325$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.35$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.36$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.809
1805.10558v1.pdf	JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.69$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.60$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8891$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.59$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.55$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.874$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.40$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.34$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8235$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#27.26$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#27.28$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.803
1504.06993v1.pdf	JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR#31.29$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#PSNR-B#31.37$JPEG Artifact Correction#LIVE1 (Quality 20 Grayscale)#SSIM#0.8891$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR#29.23$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#PSNR-B#29.24$JPEG Artifact Correction#LIVE1 (Quality 20 Color)#SSIM#0.865$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR#33.31$JPEG Artifact Correction#ICB (Quality 30 Color)#PSNR-B#33.72$JPEG Artifact Correction#ICB (Quality 30 Color)#SSIM#0.807$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR#29.11$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#PSNR-B#29.07$JPEG Artifact Correction#Live1 (Quality 10 Grayscale)#SSIM#0.8235$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR#31.13$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR-B#30.97$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#SSIM#0.794$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#32.24$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#32.53$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.778$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#30.06$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#31.21$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.779$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR#35.04$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR-B#32.72$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#SSIM#0.905$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR#26.91$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#PSNR-B#26.92$JPEG Artifact Correction#LIVE1 (Quality 10 Color)#SSIM#0.795
1806.03275v2.pdf	JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR#34.18$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#PSNR-B#34.15$JPEG Artifact Correction#ICB (Quality 10 Grayscale)#SSIM#0.874$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR#32.77$JPEG Artifact Correction#ICB (Quality 20 Color)#PSNR-B#33.26$JPEG Artifact Correction#ICB (Quality 20 Color)#SSIM#0.830$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR#30.85$JPEG Artifact Correction#ICB (Quality 10 Color)#PSNR-B#31.31$JPEG Artifact Correction#ICB (Quality 10 Color)#SSIM#0.796$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR#35.93$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#PSNR-B#35.79$JPEG Artifact Correction#ICB (Quality 20 Grayscale)#SSIM#0.918
2111.11843v6.pdf	Underwater Image Restoration#LSUI#PSNR#24.16
2104.13015v1.pdf	Underwater Image Restoration#LSUI#PSNR#22.91
1801.04011v1.pdf	Underwater Image Restoration#LSUI#PSNR#19.79
1903.09766v3.pdf	Underwater Image Restoration#LSUI#PSNR#19.37
1901.05495v2.pdf	Underwater Image Restoration#LSUI#PSNR#17.73
1903.10146v1.pdf	Image Reconstruction#Edge-to-Handbags#FID#0.069$Image Reconstruction#Edge-to-Handbags#LPIPS#0.168$Image Reconstruction#Edge-to-Handbags#HP#57.10$Image Reconstruction#Edge-to-Handbags#MMD#0.112$Image Reconstruction#Edge-to-Shoes#FID#0.015$Image Reconstruction#Edge-to-Shoes#LPIPS#0.085$Image Reconstruction#Edge-to-Shoes#HP#62.30$Image Reconstruction#Edge-to-Shoes#MMD#0.081
1706.02823v3.pdf	Image Reconstruction#Edge-to-Handbags#FID#60.848$Image Reconstruction#Edge-to-Handbags#LPIPS#0.171$Image Reconstruction#Edge-to-Shoes#FID#44.762$Image Reconstruction#Edge-to-Shoes#LPIPS#0.124
2004.06688v2.pdf	MRI Reconstruction#fastMRI Brain 8x#SSIM#0.943$MRI Reconstruction#fastMRI Brain 8x#PSNR#38$MRI Reconstruction#fastMRI Brain 4x#SSIM#0.959$MRI Reconstruction#fastMRI Brain 4x#PSNR#41$MRI Reconstruction#fastMRI Knee 4x#SSIM#0.930$MRI Reconstruction#fastMRI Knee 4x#PSNR#40$MRI Reconstruction#fastMRI Knee 8x#SSIM#0.890$MRI Reconstruction#fastMRI Knee 8x#PSNR#37
2010.07290v2.pdf	MRI Reconstruction#fastMRI Brain 8x#SSIM#0.9408$MRI Reconstruction#fastMRI Brain 8x#PSNR#38.1$MRI Reconstruction#fastMRI Brain 4x#SSIM#0.9581$MRI Reconstruction#fastMRI Brain 4x#PSNR#41.3$MRI Reconstruction#fastMRI Knee 4x#SSIM#0.9287$MRI Reconstruction#fastMRI Knee 4x#PSNR#40.2$MRI Reconstruction#fastMRI Knee 8x#SSIM#0.8893$MRI Reconstruction#fastMRI Knee 8x#PSNR#37.2
2203.08213v1.pdf	MRI Reconstruction#fastMRI Knee 8x#SSIM#0.8945$MRI Reconstruction#fastMRI Knee 8x#PSNR#37.3$MRI Reconstruction#fastMRI Knee 8x#SSIM#0.8936$MRI Reconstruction#fastMRI Knee 8x#PSNR#37.0
2104.15042v2.pdf	Image/Document Clustering#pendigits#Accuracy (%)#81.55$Image/Document Clustering#pendigits#runtime (s)#0.77$Image/Document Clustering#pendigits#NMI#79.15$Image/Document Clustering#pendigits#Accuracy (%)#74.02$Image/Document Clustering#pendigits#runtime (s)#1.20$Image/Document Clustering#pendigits#NMI#81.37$Image/Document Clustering#pendigits#Accuracy (%)#81.68$Image/Document Clustering#pendigits#runtime (s)#2.07$Image/Document Clustering#pendigits#NMI#81.68
1903.01057v2.pdf	Image/Document Clustering#pendigits#runtime (s)#1.01$Image/Document Clustering#pendigits#NMI#0.803
1805.11048v3.pdf	Image/Document Clustering#pendigits#runtime (s)#1.8
1604.03628v3.pdf	Image Clustering#Coil-20#NMI#1$Image Clustering#Stanford Cars#Accuracy#0.046$Image Clustering#Stanford Cars#NMI#0.232$Image Clustering#MNIST-full#NMI#0.917$Image Clustering#MNIST-full#Accuracy#0.964$Image Clustering#Stanford Dogs#Accuracy#0.043$Image Clustering#Stanford Dogs#NMI#0.142$Image Clustering#MNIST-test#NMI#0.915$Image Clustering#coil-100#NMI#0.985$Image Clustering#Imagenet-dog-15#Accuracy#0.138$Image Clustering#Imagenet-dog-15#NMI#0.054$Image Clustering#FRGC#NMI#0.574$Image Clustering#ImageNet-10#Accuracy#0.300$Image Clustering#ImageNet-10#NMI#0.175$Image Clustering#CIFAR-100#Accuracy#0.137$Image Clustering#CIFAR-100#NMI#0.103$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#CUB Birds#Accuracy#0.044$Image Clustering#CUB Birds#NMI#0.203$Image Clustering#Tiny-ImageNet#Accuracy#0.033$Image Clustering#Tiny-ImageNet#NMI#0.102$Image Clustering#STL-10#Accuracy#0.277$Image Clustering#STL-10#NMI#0.182$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#UMist#NMI#0.877$Image Clustering#CIFAR-10#Accuracy#0.272$Image Clustering#CIFAR-10#NMI#0.192$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.138$Image Clustering#YouTube Faces DB#NMI#0.848$Image Clustering#CMU-PIE#NMI#1.000$Image Clustering#USPS#NMI#0.913
2002.05687v1.pdf	Image Clustering#Coil-20#NMI#.958$Image Clustering#MNIST-full#NMI#0.864$Image Clustering#coil-100#NMI#0.926$Image Clustering#USPS#NMI#0.885
1208.5092v1.pdf	Image Clustering#Coil-20#NMI#0.937$Image Clustering#Coil-20#Accuracy#0.858$Image Clustering#Coil-20#NMI#0.746$Image Clustering#MNIST-full#NMI#0.913$Image Clustering#MNIST-full#Accuracy#0.965$Image Clustering#Extended Yale-B#NMI#0.91$Image Clustering#MNIST-test#NMI#0.91$Image Clustering#MNIST-test#NMI#0.844$Image Clustering#coil-100#NMI#0.929$Image Clustering#coil-100#Accuracy#0.731$Image Clustering#Fashion-MNIST#Accuracy#0.627$Image Clustering#Fashion-MNIST#NMI#0.66$Image Clustering#USPS#NMI#0.824
1703.07980v1.pdf	Image Clustering#Coil-20#NMI#0.895$Image Clustering#Coil-20#Accuracy#0.793$Image Clustering#MNIST-full#NMI#0.937$Image Clustering#MNIST-full#Accuracy#0.976$Image Clustering#coil-100#NMI#0.905$Image Clustering#coil-100#Accuracy#0.775$Image Clustering#USPS#NMI#0.724$Image Clustering#USPS#Accuracy#0.743
1704.06327v3.pdf	Image Clustering#Stanford Cars#Accuracy#0.063$Image Clustering#Stanford Cars#NMI#0.329$Image Clustering#Stanford Cars#Accuracy#0.062$Image Clustering#Stanford Cars#NMI#0.330$Image Clustering#Stanford Dogs#Accuracy#0.054$Image Clustering#Stanford Dogs#NMI#0.183$Image Clustering#Stanford Dogs#Accuracy#0.052$Image Clustering#Stanford Dogs#NMI#0.182$Image Clustering#FRGC#NMI#0.583$Image Clustering#FRGC#Accuracy#0.432$Image Clustering#CUB Birds#Accuracy#0.061$Image Clustering#CUB Birds#NMI#0.297$Image Clustering#CUB Birds#NMI#0.290$Image Clustering#YouTube Faces DB#NMI#0.802$Image Clustering#YouTube Faces DB#Accuracy#0.611$Image Clustering#CMU-PIE#NMI#0.964$Image Clustering#CMU-PIE#Accuracy#0.850
2107.10692v1.pdf	Image Clustering#MNIST-full#NMI#0.975$Image Clustering#MNIST-full#Accuracy#0.992$Image Clustering#Fashion-MNIST#Accuracy#0.679$Image Clustering#Fashion-MNIST#NMI#0.735$Image Clustering#USPS#NMI#0.954$Image Clustering#USPS#Accuracy#0.984
1909.11832v1.pdf	Image Clustering#MNIST-full#NMI#0.971$Image Clustering#MNIST-full#Accuracy#0.990
1908.05968v6.pdf	Image Clustering#MNIST-full#NMI#0.964$Image Clustering#MNIST-full#Accuracy#0.987$Image Clustering#MNIST-test#NMI#0.882$Image Clustering#MNIST-test#Accuracy#0.948$Image Clustering#HAR#Accuracy#0.801$Image Clustering#HAR#NMI#0.683$Image Clustering#pendigits#Accuracy#0.885$Image Clustering#pendigits#NMI#0.863$Image Clustering#Fashion-MNIST#Accuracy#0.672$Image Clustering#Fashion-MNIST#NMI#0.684$Image Clustering#USPS#NMI#0.901$Image Clustering#USPS#Accuracy#0.958
1901.07752v5.pdf	Image Clustering#MNIST-full#NMI#0.964$Image Clustering#MNIST-full#Accuracy#0.987$Image Clustering#MNIST-test#NMI#0.963$Image Clustering#MNIST-test#Accuracy#0.987$Image Clustering#Fashion-MNIST#Accuracy#0.591$Image Clustering#Fashion-MNIST#NMI#0.642$Image Clustering#USPS#NMI#0.948$Image Clustering#USPS#Accuracy#0.981
1812.04287v1.pdf	Image Clustering#MNIST-full#NMI#0.961$Image Clustering#MNIST-full#Accuracy#0.986$Image Clustering#MNIST-test#NMI#0.927$Image Clustering#MNIST-test#Accuracy#0.97$Image Clustering#MNIST-test#NMI#0.916$Image Clustering#MNIST-test#Accuracy#0.965$Image Clustering#Fashion-MNIST#Accuracy#0.619$Image Clustering#Fashion-MNIST#NMI#0.682$Image Clustering#Fashion-MNIST#Accuracy#0.609$Image Clustering#Fashion-MNIST#NMI#0.661$Image Clustering#LetterA-J#Accuracy#0.691$Image Clustering#LetterA-J#NMI#0.629$Image Clustering#LetterA-J#Accuracy#0.573$Image Clustering#LetterA-J#NMI#0.546$Image Clustering#USPS#NMI#0.939$Image Clustering#USPS#Accuracy#0.977$Image Clustering#USPS#NMI#0.918$Image Clustering#USPS#Accuracy#0.967
2006.06640v1.pdf	Image Clustering#MNIST-full#NMI#0.956$Image Clustering#MNIST-full#Accuracy#0.984$Image Clustering#Fashion-MNIST#Accuracy#0.635$Image Clustering#Fashion-MNIST#NMI#0.71$Image Clustering#USPS#NMI#0.944$Image Clustering#USPS#Accuracy#0.979
2006.11132v2.pdf	Image Clustering#MNIST-full#NMI#0.942$Image Clustering#MNIST-full#Accuracy#0.979$Image Clustering#MNIST-test#NMI#0.947$Image Clustering#MNIST-test#Accuracy#0.978$Image Clustering#Fashion-MNIST#Accuracy#0.612$Image Clustering#Fashion-MNIST#NMI#0.637$Image Clustering#USPS#NMI#0.882$Image Clustering#USPS#Accuracy#0.864$Unsupervised Image Classification#MNIST#Accuracy#97.3$Unsupervised Image Classification#SVHN#Acc#57.4$Unsupervised Image Classification#SVHN## of clusters (k)#10
1605.02633v1.pdf	Image Clustering#MNIST-full#NMI#0.941$Image Clustering#MNIST-full#Accuracy#0.969$Image Clustering#coil-100#Accuracy#0.6924
2011.11586v2.pdf	Image Clustering#MNIST-full#NMI#0.921$Image Clustering#MNIST-full#Accuracy#0.964$Image Clustering#MNIST-test#NMI#0.919$Image Clustering#MNIST-test#Accuracy#0.967$Image Clustering#Fashion-MNIST#Accuracy#0.628$Image Clustering#Fashion-MNIST#NMI#0.644$Image Clustering#USPS#NMI#0.898$Image Clustering#USPS#Accuracy#0.957
1810.04246v2.pdf	Image Clustering#MNIST-full#NMI#0.913$Image Clustering#MNIST-test#NMI#0.873$Image Clustering#MNIST-test#Accuracy#0.863$Image Clustering#FRGC#NMI#0.487$Image Clustering#FRGC#Accuracy#0.413$Image Clustering#YouTube Faces DB#NMI#0.806$Image Clustering#YouTube Faces DB#Accuracy#0.605$Image Clustering#CMU-PIE#NMI#0.945$Image Clustering#CMU-PIE#Accuracy#0.902$Image Clustering#USPS#NMI#0.936$Image Clustering#USPS#Accuracy#0.974
1804.06498v3.pdf	Image Clustering#Extended Yale-B#Accuracy#0.992$Image Clustering#Extended Yale-B#NMI#0.988$Image Clustering#ARL Polarimetric Thermal Face Dataset#Accuracy#0.983$Image Clustering#USPS#NMI#0.929$Image Clustering#USPS#Accuracy#0.951$Multi-view Subspace Clustering#ORL#Accuracy#0.833$Multi-view Subspace Clustering#ARL Polarimetric Thermal Face Dataset#Accuracy#0.988
1905.00149v1.pdf	Image Clustering#Extended Yale-B#Accuracy#0.984
1709.02508v1.pdf	Image Clustering#Extended Yale-B#Accuracy#0.973$Image Clustering#Extended Yale-B#NMI#0.970
2011.14859v2.pdf	Image Clustering#Extended Yale-B#Accuracy#0.924$Image Clustering#Extended Yale-B#NMI#0.952$Image Clustering#Extended Yale-B#Accuracy#0.917$Image Clustering#Extended Yale-B#NMI#0.947$Image Clustering#coil-100#NMI#0.997$Image Clustering#coil-100#Accuracy#0.984$Image Clustering#coil-100#NMI#0.992$Image Clustering#coil-100#Accuracy#0.961$Image Clustering#coil-100#NMI#0.946$Image Clustering#coil-100#Accuracy#0.824$Image Clustering#coil-100#NMI#0.943$Image Clustering#coil-100#Accuracy#0.796$Image Clustering#UMist#NMI#0.939$Image Clustering#UMist#NMI#0.935$Image Clustering#coil-40#Accuracy#1$Image Clustering#coil-40#NMI#1
1507.01238v3.pdf	Image Clustering#Extended Yale-B#Accuracy#0.776
1203.1005v3.pdf	Image Clustering#Extended Yale-B#Accuracy#0.706$Motion Segmentation#Hopkins155#Classification Error#2.18
2006.04535v1.pdf	Image Clustering#MNIST-test#NMI#0.903$Image Clustering#MNIST-test#Accuracy#0.962$Image Clustering#EMNIST-Balanced#NMI#0.783$Image Clustering#EMNIST-Balanced#Accuracy#0.792$Image Clustering#Fashion-MNIST#Accuracy#0.856$Image Clustering#Fashion-MNIST#NMI#0.767
2005.12320v2.pdf	Image Clustering#ImageNet#NMI#72.0$Image Clustering#ImageNet#Accuracy#39.9$Image Clustering#ImageNet#Comment#1% training label (semi-supervised)$Image Clustering#ImageNet-50#NMI#0.805$Image Clustering#ImageNet-50#ACCURACY#0.751$Image Clustering#ImageNet-50#ARI#0.635$Image Clustering#CIFAR-100#Accuracy#0.507$Image Clustering#CIFAR-100#NMI#0.486$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.333$Image Clustering#CIFAR-100#Accuracy#0.459$Image Clustering#CIFAR-100#NMI#0.468$Image Clustering#CIFAR-100#ARI#0.301$Image Clustering#ImageNet-100#NMI#0.787$Image Clustering#ImageNet-100#ACCURACY#0.662$Image Clustering#ImageNet-100#ARI#0.544$Image Clustering#STL-10#Accuracy#0.809$Image Clustering#STL-10#NMI#0.698$Image Clustering#STL-10#Train Split#Train$Image Clustering#STL-10#Backbone#ResNet-18$Image Clustering#STL-10#Accuracy#0.767$Image Clustering#STL-10#NMI#0.680$Image Clustering#CIFAR-10#Accuracy#0.883$Image Clustering#CIFAR-10#NMI#0.797$Image Clustering#CIFAR-10#Train set#Train$Image Clustering#CIFAR-10#ARI#0.772$Image Clustering#CIFAR-10#Backbone#ResNet-18$Image Clustering#CIFAR-10#Accuracy#0.876$Image Clustering#CIFAR-10#NMI#0.787$Image Clustering#CIFAR-10#ARI#0.758$Image Clustering#ImageNet-200#NMI#0.757$Image Clustering#ImageNet-200#ACCURACY#0.563$Image Clustering#ImageNet-200#ARI#0.441$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#60.0%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#39.90%$Unsupervised Image Classification#ImageNet#Accuracy (%)#39.9$Unsupervised Image Classification#ImageNet#ARI#27.5$Unsupervised Image Classification#CIFAR-20#Accuracy#50.7$Unsupervised Image Classification#CIFAR-10#Accuracy#88.3$Unsupervised Image Classification#STL-10#Accuracy#80.90
1911.05371v3.pdf	Image Clustering#ImageNet#NMI#66.4$Image Clustering#ImageNet#Accuracy#-$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#61.5%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#84.0%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#48.4%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#61.5
2104.03952v2.pdf	Image Clustering#ImageNet-50#NMI#0.847$Image Clustering#ImageNet-50#ACCURACY#0.827$Image Clustering#ImageNet-50#ARI#0.744$Image Clustering#ImageNet-100#NMI#0.805$Image Clustering#ImageNet-100#ACCURACY#0.731$Image Clustering#ImageNet-100#ARI#0.628$Image Clustering#CIFAR-10#Accuracy#0.853$Image Clustering#CIFAR-10#NMI#0.731$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.702$Image Clustering#CIFAR-10#Backbone#ViT-B-32$Image Clustering#ImageNet-200#NMI#0.749$Image Clustering#ImageNet-200#ACCURACY#0.598$Image Clustering#ImageNet-200#ARI#0.486
2111.11821v2.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.775$Image Clustering#Imagenet-dog-15#NMI#0.737$Image Clustering#Imagenet-dog-15#ARI#0.675$Image Clustering#Imagenet-dog-15#Backbone#ResNet-34$Image Clustering#Imagenet-dog-15#Image Size#224$Image Clustering#Imagenet-dog-15#Accuracy#0.745$Image Clustering#Imagenet-dog-15#NMI#0.692$Image Clustering#Imagenet-dog-15#ARI#0.627$Image Clustering#Imagenet-dog-15#Image Size#96$Image Clustering#ImageNet-10#Accuracy#0.962$Image Clustering#ImageNet-10#NMI#0.908$Image Clustering#ImageNet-10#ARI#0.918$Image Clustering#ImageNet-10#Backbone#ResNet-34$Image Clustering#ImageNet-10#Image Size#224$Image Clustering#ImageNet-10#Accuracy#0.956$Image Clustering#ImageNet-10#NMI#0.896$Image Clustering#ImageNet-10#ARI#0.906$Image Clustering#ImageNet-10#Image Size#96
2105.01289v2.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.695$Image Clustering#Imagenet-dog-15#NMI#0.63$Image Clustering#Imagenet-dog-15#ARI#0.531$Image Clustering#ImageNet-10#Accuracy#0.958$Image Clustering#ImageNet-10#NMI#0.907$Image Clustering#ImageNet-10#ARI#0.909$Image Clustering#CIFAR-100#Accuracy#0.479$Image Clustering#CIFAR-100#NMI#0.468$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.303$Image Clustering#STL-10#Accuracy#0.749$Image Clustering#STL-10#NMI#0.636$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#CIFAR-10#Accuracy#0.846$Image Clustering#CIFAR-10#NMI#0.762$Image Clustering#CIFAR-10#Train set#Train$Image Clustering#CIFAR-10#ARI#0.715
2103.09382v3.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.675$Image Clustering#Imagenet-dog-15#NMI#0.627$Image Clustering#Imagenet-dog-15#ARI#0.526$Image Clustering#ImageNet-10#Accuracy#0.969$Image Clustering#ImageNet-10#NMI#0.927$Image Clustering#ImageNet-10#ARI#0.933$Image Clustering#CIFAR-100#Accuracy#0.584$Image Clustering#CIFAR-100#NMI#0.583$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.422$Image Clustering#Tiny-ImageNet#Accuracy#0.305$Image Clustering#Tiny-ImageNet#NMI#0.449$Image Clustering#Tiny-ImageNet#ARI#0.161$Image Clustering#STL-10#Accuracy#0.929$Image Clustering#STL-10#NMI#0.860$Image Clustering#STL-10#Train Split#Train$Image Clustering#STL-10#Backbone#ResNet-34$Image Clustering#CIFAR-10#Accuracy#0.918$Image Clustering#CIFAR-10#NMI#0.850$Image Clustering#CIFAR-10#Train set#Train$Image Clustering#CIFAR-10#ARI#0.836$Image Clustering#CIFAR-10#Backbone#ResNet-18
2106.00131v1.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.591$Image Clustering#Imagenet-dog-15#NMI#0.546$Image Clustering#Imagenet-dog-15#ARI#0.413$Image Clustering#Imagenet-dog-15#Image Size#96$Image Clustering#ImageNet-10#Accuracy#0.954$Image Clustering#ImageNet-10#NMI#0.898$Image Clustering#ImageNet-10#ARI#0.901$Image Clustering#ImageNet-10#Image Size#96$Image Clustering#CIFAR-100#Accuracy#0.425$Image Clustering#CIFAR-100#NMI#0.426$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.264$Image Clustering#STL-10#Accuracy#0.756$Image Clustering#STL-10#NMI#0.643$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#STL-10#Backbone#ResNet-18$Image Clustering#CIFAR-10#Accuracy#0.815$Image Clustering#CIFAR-10#NMI#0.711$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.663$Image Clustering#CIFAR-10#Backbone#ResNet-18
2105.01899v1.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.439$Image Clustering#Imagenet-dog-15#NMI#0.423$Image Clustering#Imagenet-dog-15#ARI#0.286$Image Clustering#Imagenet-dog-15#Image Size#96$Image Clustering#STL-10#Accuracy#0.752$Image Clustering#STL-10#NMI#0.635$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#STL-10#Backbone#ResNet-34
2009.09687v1.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.429$Image Clustering#Imagenet-dog-15#NMI#0.445$Image Clustering#Imagenet-dog-15#ARI#0.274$Image Clustering#Imagenet-dog-15#Image Size#224$Image Clustering#ImageNet-10#Accuracy#0.893$Image Clustering#ImageNet-10#NMI#0.859$Image Clustering#ImageNet-10#ARI#0.822$Image Clustering#ImageNet-10#Image Size#224$Image Clustering#CIFAR-100#Accuracy#0.429$Image Clustering#CIFAR-100#NMI#0.431$Image Clustering#CIFAR-100#ARI#0.266$Image Clustering#Tiny-ImageNet#Accuracy#0.14$Image Clustering#Tiny-ImageNet#NMI#0.34$Image Clustering#Tiny-ImageNet#ARI#0.071$Image Clustering#STL-10#Accuracy#0.85$Image Clustering#STL-10#NMI#0.764$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#STL-10#Backbone#ResNet34$Image Clustering#CIFAR-10#Accuracy#0.79$Image Clustering#CIFAR-10#NMI#0.705$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.637$Image Clustering#CIFAR-10#Backbone#ResNet34
1904.06925v3.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.383$Image Clustering#Imagenet-dog-15#NMI#0.321$Image Clustering#ImageNet-10#Accuracy#0.71$Image Clustering#ImageNet-10#NMI#0.608$Image Clustering#CIFAR-100#Accuracy#0.327$Image Clustering#CIFAR-100#NMI#0.285$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#Tiny-ImageNet#Accuracy#0.108$Image Clustering#Tiny-ImageNet#NMI#0.224$Image Clustering#STL-10#Accuracy#0.482$Image Clustering#STL-10#NMI#0.376$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#STL-10#Backbone#AlexNet$Image Clustering#CIFAR-10#Accuracy#0.623$Image Clustering#CIFAR-10#NMI#0.496$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.408$Image Clustering#CIFAR-10#Backbone#AlexNet
1511.06335v2.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.195$Image Clustering#Imagenet-dog-15#NMI#0.122$Image Clustering#ImageNet-10#Accuracy#0.381$Image Clustering#ImageNet-10#NMI#0.282$Image Clustering#CIFAR-100#Accuracy#0.185$Image Clustering#CIFAR-100#NMI#0.136$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#Tiny-ImageNet#Accuracy#0.037$Image Clustering#Tiny-ImageNet#NMI#0.115$Image Clustering#STL-10#Accuracy#0.359$Image Clustering#STL-10#NMI#0.276$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#CIFAR-10#Accuracy#0.301$Image Clustering#CIFAR-10#NMI#0.25$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.161$Image Clustering#CIFAR-10#Backbone#Custom$Image Clustering#YouTube Faces DB#NMI#0.446$Image Clustering#YouTube Faces DB#Accuracy#0.371$Image Clustering#CMU-PIE#NMI#0.924$Image Clustering#CMU-PIE#Accuracy#0.801$Unsupervised Image Classification#SVHN#Acc#11.90$Unsupervised Image Classification#SVHN## of clusters (k)#10
1312.6114v10.pdf	Image Clustering#Imagenet-dog-15#Accuracy#0.179$Image Clustering#Imagenet-dog-15#NMI#0.107$Image Clustering#ImageNet-10#Accuracy#0.334$Image Clustering#ImageNet-10#NMI#0.193$Image Clustering#CIFAR-100#Accuracy#0.152$Image Clustering#CIFAR-100#NMI#0.108$Image Clustering#CIFAR-100#Train Set#Train+Test$Image Clustering#Tiny-ImageNet#Accuracy#0.036$Image Clustering#Tiny-ImageNet#NMI#0.113$Image Clustering#STL-10#Accuracy#0.282$Image Clustering#STL-10#NMI#0.200$Image Clustering#STL-10#Train Split#Train+Test$Image Clustering#CIFAR-10#Accuracy#0.291$Image Clustering#CIFAR-10#NMI#0.245$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.168$Image Clustering#CIFAR-10#Backbone#VAE
1912.02678v3.pdf	Image Clustering#ImageNet-10#Accuracy#0.811$Image Clustering#ImageNet-10#NMI#0.719$Image Clustering#CIFAR-100#Accuracy#0.446$Image Clustering#CIFAR-100#NMI#0.418$Image Clustering#Tiny-ImageNet#Accuracy#0.119$Image Clustering#Tiny-ImageNet#NMI#0.274$Image Clustering#STL-10#Accuracy#0.694$Image Clustering#STL-10#NMI#0.593$Image Clustering#STL-10#Backbone#ResNet18$Image Clustering#CIFAR-10#Accuracy#0.820$Image Clustering#CIFAR-10#NMI#0.703$Image Clustering#CIFAR-10#Backbone#ResNet18
2103.07368v2.pdf	Image Clustering#CIFAR-100#Accuracy#0.519$Image Clustering#CIFAR-100#NMI#0.527$Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#CIFAR-100#ARI#0.361$Image Clustering#CIFAR-100#Accuracy#0.49$Image Clustering#CIFAR-100#NMI#0.503$Image Clustering#CIFAR-100#ARI#0.337$Image Clustering#Tiny-ImageNet#Accuracy#0.282$Image Clustering#Tiny-ImageNet#NMI#0.526$Image Clustering#Tiny-ImageNet#ARI#0.146$Image Clustering#Tiny-ImageNet#Accuracy#0.279$Image Clustering#Tiny-ImageNet#NMI#0.485$Image Clustering#Tiny-ImageNet#ARI#0.143$Image Clustering#STL-10#Accuracy#0.853$Image Clustering#STL-10#NMI#0.747$Image Clustering#STL-10#Train Split#Train$Image Clustering#STL-10#ARI#0.716$Image Clustering#STL-10#Backbone#ResNet-18$Image Clustering#STL-10#Accuracy#0.831$Image Clustering#STL-10#NMI#0.729$Image Clustering#STL-10#ARI#0.685$Image Clustering#CIFAR-10#Accuracy#0.897$Image Clustering#CIFAR-10#NMI#0.818$Image Clustering#CIFAR-10#Train set#Train$Image Clustering#CIFAR-10#ARI#0.8$Image Clustering#CIFAR-10#Backbone#ResNet-18$Image Clustering#CIFAR-10#Accuracy#0.891$Image Clustering#CIFAR-10#NMI#0.811$Image Clustering#CIFAR-10#ARI#0.79
2012.11150v2.pdf	Image Clustering#CIFAR-100#Train Set#Train$Image Clustering#STL-10#Accuracy#0.867$Image Clustering#STL-10#Backbone#ResNet-18$Image Clustering#CIFAR-10#Accuracy#0.903$Image Clustering#CIFAR-10#Backbone#ResNet-18$Unsupervised Image Classification#CIFAR-20#Accuracy#54.3$Unsupervised Image Classification#CIFAR-10#Accuracy#90.3$Unsupervised Image Classification#STL-10#Accuracy#86.7
2006.08558v1.pdf	Image Clustering#STL-10#Accuracy#0.491$Image Clustering#STL-10#NMI#0.446
2003.08821v1.pdf	Image Clustering#CIFAR-10#Accuracy#0.666$Image Clustering#CIFAR-10#NMI#0.585$Image Clustering#CIFAR-10#Train set#Train+Test$Image Clustering#CIFAR-10#ARI#0.492$Image Clustering#CIFAR-10#Backbone#ResNet-18
2203.13166v2.pdf	Face Clustering#EasyCom#NMI#87.44
1908.01978v1.pdf	Multi-view Subspace Clustering#ORL#Accuracy#0.870
2110.10955v1.pdf	Multi-Label Classification#OpenImages-v6#mAP#87.34$Multi-Label Classification#OpenImages-v6#mAP#86.72
2009.14119v4.pdf	Multi-Label Classification#OpenImages-v6#mAP#86.3$Multi-Label Classification#MS-COCO#mAP#88.4$Multi-Label Classification#MS-COCO#mAP#86.6$Multi-Label Classification#PASCAL VOC 2007#mAP#95.8$Multi-Label Classification#PASCAL VOC 2007#mAP#94.6$Multi-Label Classification#NUS-WIDE#MAP#65.2
2107.10834v1.pdf	Multi-Label Classification#MS-COCO#mAP#91.3$Multi-Label Classification#MS-COCO#mAP#90.5$Multi-Label Classification#MS-COCO#mAP#90.3$Multi-Label Classification#MS-COCO#mAP#84.9$Multi-Label Classification#PASCAL VOC 2007#mAP#97.3$Multi-Label Classification#PASCAL VOC 2007#mAP#96.9$Multi-Label Classification#PASCAL VOC 2007#mAP#96.1$Multi-Label Classification#PASCAL VOC 2012#mAP#96.6$Multi-Label Classification#NUS-WIDE#MAP#70.1$Multi-Label Classification#NUS-WIDE#MAP#66.3$Multi-Label Classification#NUS-WIDE#MAP#65.0
2209.06585v1.pdf	Multi-Label Classification#MS-COCO#mAP#91.30$Multi-Label Classification#PASCAL VOC 2007#mAP#96.70$Multi-Label Classification#NUS-WIDE#MAP#68.30
2106.06195v1.pdf	Multi-Label Classification#MS-COCO#mAP#90.0$Multi-Label Classification#MS-COCO#mAP#88.5
2104.10972v4.pdf	Multi-Label Classification#MS-COCO#mAP#89.8$Multi-Label Classification#MS-COCO#mAP#88.4$Multi-Label Classification#PASCAL VOC 2007#mAP#93.1$Image Classification#CIFAR-100#Percentage correct#94.2$Image Classification#Stanford Cars#Accuracy#96.32
2007.01755v3.pdf	Multi-Label Classification#MS-COCO#mAP#84.5$Multi-Label Classification#MS-COCO#mAP#83.8$Multi-Label Classification#PASCAL VOC 2007#mAP#94.8$Multi-Label Classification#PASCAL VOC 2012#mAP#94.3
1912.07872v2.pdf	Multi-Label Classification#MS-COCO#mAP#83.8$Multi-Label Classification#NUS-WIDE#MAP#61.4
1911.09243v1.pdf	Multi-Label Classification#MS-COCO#mAP#83.7
2106.11596v1.pdf	Multi-Label Classification#MS-COCO#mAP#83.4$Multi-Label Classification#PASCAL VOC 2007#mAP#96.0$Multi-Label Classification#NUS-WIDE#MAP#61.5
1912.11757v1.pdf	Multi-Label Classification#MS-COCO#mAP#83.0
1702.05891v2.pdf	Multi-Label Classification#MS-COCO#mAP#77.1$Multi-Label Classification#NUS-WIDE#MAP#62.0
1908.07325v1.pdf	Multi-Label Classification#PASCAL VOC 2007#mAP#95.0$Multi-Label Classification#PASCAL VOC 2007#mAP#93.4
1904.03582v1.pdf	Multi-Label Classification#PASCAL VOC 2007#mAP#94.0
1504.05843v2.pdf	Multi-Label Classification#PASCAL VOC 2007#mAP#92.0
2111.03690v3.pdf	Multi-Label Classification#MLRSNet#F1-score#92.41$Multi-Label Classification#MLRSNet#F1-score#91.83
2003.00827v2.pdf	Multi-Label Classification#ChestX-ray14#Average AUC on 14 label#84.9$Multi-Label Classification#MIMIC-CXR#Average AUC on 14 label#0.8340000000000001$Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.805
1809.05884v2.pdf	Multi-Label Classification#NUS-WIDE#MAP#60.1
2012.03173v2.pdf	Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.930$Multi-Label Classification#CheXpert#NUM RADS BELOW CURVE#2.800$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8352 ± 0.0054$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8238 ± 0.0061$Graph Property Prediction#ogbg-molhiv#Number of params#3444509$Graph Property Prediction#ogbg-molhiv#Ext. data#No
1911.06475v3.pdf	Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.930$Multi-Label Classification#CheXpert#NUM RADS BELOW CURVE#2.600$Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.929
2106.05915v3.pdf	Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.926$Multi-Label Classification#CheXpert#NUM RADS BELOW CURVE#2.600$Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.917
1901.07031v1.pdf	Multi-Label Classification#CheXpert#AVERAGE AUC ON 14 LABEL#0.907$Multi-Label Classification#CheXpert#NUM RADS BELOW CURVE#1.800
2010.10151v1.pdf	Hierarchical Multi-label Classification#Seq Funcat#AU(PRC)#0.292$Hierarchical Multi-label Classification#Derisi Funcat#AU(PRC)#0.195$Hierarchical Multi-label Classification#Spo Funcat#AU(PRC)#0.215$Hierarchical Multi-label Classification#Gasch2 Funcat#AU(PRC)#0.258$Hierarchical Multi-label Classification#Gasch2 GO#AU(PRC)#0.414$Hierarchical Multi-label Classification#Spo GO#AU(PRC)#0.382$Hierarchical Multi-label Classification#Expr GO#AU(PRC)#0.447$Hierarchical Multi-label Classification#Derisi GO#AU(PRC)#0.37$Hierarchical Multi-label Classification#Cellcycle GO#AU(PRC)#0.413$Hierarchical Multi-label Classification#Gasch1 GO#AU(PRC)#0.436$Hierarchical Multi-label Classification#Eisen Funcat#AU(PRC)#0.306$Hierarchical Multi-label Classification#Gasch1 Funcat#AU(PRC)#0.286$Hierarchical Multi-label Classification#Cellcycle Funcat#AU(PRC)#0.255$Hierarchical Multi-label Classification#Seq GO#AU(PRC)#0.446$Hierarchical Multi-label Classification#Eisen GO#AU(PRC)#0.455$Hierarchical Multi-label Classification#Expr Funcat#AU(PRC)#0.302
2107.00382v2.pdf	Visual Place Recognition#KITTI#Average F1#0.932
2103.06638v3.pdf	Visual Place Recognition#Pittsburgh-30k-test#Recall@1#81.94$Visual Place Recognition#Pittsburgh-30k-test#Recall@5#94.56$Visual Place Recognition#Pittsburgh-30k-test#Recall@10#92.19$Visual Place Recognition#Mapillary test#Recall@1#57.9$Visual Place Recognition#Mapillary test#Recall@5#70.7$Visual Place Recognition#Mapillary test#Recall@10#75.7$Visual Place Recognition#Mapillary test#Recall@1#45.7$Visual Place Recognition#Mapillary test#Recall@5#62.3$Visual Place Recognition#Mapillary test#Recall@10#67.9$Visual Place Recognition#Mapillary val#Recall@1#79.9$Visual Place Recognition#Mapillary val#Recall@5#88.2$Visual Place Recognition#Mapillary val#Recall@10#90$Visual Place Recognition#Mapillary val#Recall@1#70.3$Visual Place Recognition#Mapillary val#Recall@5#82$Visual Place Recognition#Mapillary val#Recall@10#84.9$Visual Place Recognition#Tokyo247#Recall@1#69.84$Visual Place Recognition#Tokyo247#Recall@5#84.76$Visual Place Recognition#Tokyo247#Recall@10#80.63
2107.02440v1.pdf	Visual Place Recognition#Nordland#Recall@1#29.34$Visual Place Recognition#Berlin Kudamm#Recall@1#61.07
2104.05327v2.pdf	Visual Place Recognition#Oxford RobotCar (LiDAR 4096 points+RGB)#recall@top1%#99.1$Visual Place Recognition#Oxford RobotCar (LiDAR 4096 points+RGB)#recall@top1#96.7
1911.11763v2.pdf	Visual Place Recognition#Berlin Kudamm#Recall@1#59.64$Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.65248
1812.03506v2.pdf	Visual Place Recognition#Berlin Kudamm#Recall@1#46.78
1511.07247v3.pdf	Visual Place Recognition#Berlin Kudamm#Recall@1#38.21
1908.08987v1.pdf	Document Image Classification#Noisy MNIST#Accuracy#98.43$Document Image Classification#Noisy Bangla Numeral#Accuracy#96.68$Document Image Classification#Noisy Bangla Characters#Accuracy#89.54$Image Classification#Noisy MNIST (AWGN)#Accuracy#98.43$Image Classification#Noisy MNIST (Contrast)#Accuracy#97.25$Image Classification#Noisy MNIST (Motion)#Accuracy#99.20
2106.13802v1.pdf	Document Image Classification#Tobacco-3482#Accuracy#91.95$Document Image Classification#Tobacco-3482#Accuracy#91$Document Image Classification#Tobacco-3482#Accuracy#82.3$Document Image Classification#Tobacco-3482#Accuracy#81.5$Document Image Classification#Tobacco-3482#Accuracy#79$Document Image Classification#Tobacco-3482#Accuracy#77.5$Document Image Classification#Tobacco-3482#Accuracy#73.5$Document Image Classification#Tobacco-3482#Memory#7.08
2106.11539v2.pdf	Document Image Classification#RVL-CDIP#Accuracy#96.17%$Document Image Classification#RVL-CDIP#Parameters#183M$Document Image Classification#RVL-CDIP#Accuracy#95.50%$Document Image Classification#RVL-CDIP#Parameters#536M
2204.08387v3.pdf	Document Image Classification#RVL-CDIP#Accuracy#95.93%$Document Image Classification#RVL-CDIP#Parameters#368M$Document Image Classification#RVL-CDIP#Accuracy#95.44%$Document Image Classification#RVL-CDIP#Parameters#133M$Document Layout Analysis#PubLayNet val#Text#0.945$Document Layout Analysis#PubLayNet val#Title#0.906$Document Layout Analysis#PubLayNet val#List#0.955$Document Layout Analysis#PubLayNet val#Table#0.979$Document Layout Analysis#PubLayNet val#Figure#0.970$Document Layout Analysis#PubLayNet val#Overall#0.951$Document AI#EPHOIE#Average F1#99.21
2202.13669v1.pdf	Document Image Classification#RVL-CDIP#Accuracy#95.68%
2104.08836v3.pdf	Document Image Classification#RVL-CDIP#Accuracy#95.21%
1912.13318v5.pdf	Document Image Classification#RVL-CDIP#Accuracy#94.42%$Document Image Classification#RVL-CDIP#Parameters#160M
2203.02378v3.pdf	Document Image Classification#RVL-CDIP#Accuracy#92.69%$Document Image Classification#RVL-CDIP#Parameters#304M$Document Image Classification#RVL-CDIP#Accuracy#92.11%$Document Image Classification#RVL-CDIP#Parameters#87M$Document Layout Analysis#PubLayNet val#Text#0.944$Document Layout Analysis#PubLayNet val#Title#0.893$Document Layout Analysis#PubLayNet val#List#0.960$Document Layout Analysis#PubLayNet val#Table#0.978$Document Layout Analysis#PubLayNet val#Figure#0.972$Document Layout Analysis#PubLayNet val#Overall#0.949$Table Detection#cTDaR#Weighted Average F1-score#96.55$Table Detection#cTDaR#Weighted Average F1-score#96.14
2006.09141v1.pdf	Document Image Classification#RVL-CDIP#Accuracy#92.31%
1801.09321v3.pdf	Document Image Classification#RVL-CDIP#Accuracy#92.21%
1704.03557v1.pdf	Document Image Classification#RVL-CDIP#Accuracy#90.97%
1708.03273v1.pdf	Document Image Classification#RVL-CDIP#Accuracy#90.94%
2012.12877v2.pdf	Document Image Classification#RVL-CDIP#Accuracy#90.32%$Document Image Classification#RVL-CDIP#Parameters#87M$Image Classification#CIFAR-100#Percentage correct#90.8$Image Classification#CIFAR-100#PARAMS#86M$Image Classification#iNaturalist 2018#Top-1 Accuracy#79.5%$Image Classification#ImageNet#Top 1 Accuracy#85.2%$Image Classification#ImageNet#Number of params#87M$Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#Number of params#86M$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Number of params#22M$Image Classification#ImageNet#Top 1 Accuracy#76.6%$Image Classification#ImageNet#Number of params#5M$Image Classification#ImageNet ReaL#Accuracy#89.3%$Image Classification#ImageNet ReaL#Params#86M$Image Classification#ImageNet ReaL#Accuracy#88.7%$Image Classification#ImageNet ReaL#Accuracy#86.8%$Image Classification#ImageNet ReaL#Params#22M$Image Classification#ImageNet ReaL#Accuracy#82.1%$Image Classification#ImageNet ReaL#Params#5M$Image Classification#Flowers-102#Accuracy#98.8%$Image Classification#Flowers-102#PARAMS#86M$Image Classification#CIFAR-10#Percentage correct#99.1$Image Classification#CIFAR-10#PARAMS#86M$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.3%$Fine-Grained Image Classification#Stanford Cars#PARAMS#86M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.8%$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#86M$Document Layout Analysis#PubLayNet val#Text#0.934$Document Layout Analysis#PubLayNet val#Title#0.874$Document Layout Analysis#PubLayNet val#List#0.921$Document Layout Analysis#PubLayNet val#Table#0.972$Document Layout Analysis#PubLayNet val#Figure#0.957$Document Layout Analysis#PubLayNet val#Overall#0.932
1806.08037v1.pdf	Document Image Classification#Noisy Bangla Numeral#Accuracy#95.46$Document Image Classification#n-MNIST#Accuracy#97.62$Document Image Classification#Noisy Bangla Characters#Accuracy#77.22$Image Classification#Noisy MNIST (AWGN)#Accuracy#97.62$Image Classification#Noisy MNIST (Contrast)#Accuracy#95.04$Image Classification#Noisy MNIST (Motion)#Accuracy#97.20
2103.07579v1.pdf	Document Image Classification#AIP#Top 1 Accuracy - Verb#83.4$Image Classification#ImageNet#Top 1 Accuracy#84.4%$Image Classification#ImageNet#Number of params#192M$Image Classification#ImageNet#GFLOPs#4.6$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#GFLOPs#54$Image Classification#PRImA#Percentage correct#89.3
2008.03897v1.pdf	Image Stitching#HPatches#0..5sec#10000
2109.04127v1.pdf	Coreference Resolution#OntoNotes#F1#81$Coreference Resolution#CoNLL 2012#Avg F1#81.0
2010.02807v3.pdf	Coreference Resolution#OntoNotes#F1#79.6$Coreference Resolution#CoNLL 2012#Avg F1#79.6
1908.09091v4.pdf	Coreference Resolution#OntoNotes#F1#76.9$Coreference Resolution#OntoNotes#F1#73.9$Coreference Resolution#CoNLL 2012#Avg F1#76.9
1804.05392v1.pdf	Coreference Resolution#OntoNotes#F1#73.0$Coreference Resolution#OntoNotes#F1#72.3$Coreference Resolution#CoNLL 2012#Avg F1#73.0
1707.07045v2.pdf	Coreference Resolution#OntoNotes#F1#67.2$Coreference Resolution#CoNLL 2012#Avg F1#70.4$Coreference Resolution#CoNLL 2012#Avg F1#68.8$Coreference Resolution#CoNLL 2012#Avg F1#67.2
1609.08667v3.pdf	Coreference Resolution#OntoNotes#F1#65.73
1606.01323v2.pdf	Coreference Resolution#OntoNotes#F1#65.29
1604.03035v1.pdf	Coreference Resolution#OntoNotes#F1#64.21
1906.03695v1.pdf	Coreference Resolution#GAP#Overall F1#90.2$Coreference Resolution#GAP#Masculine F1 (M)#90.9$Coreference Resolution#GAP#Feminine F1 (F)#89.5$Coreference Resolution#GAP#Bias (F/M)#0.98
2005.02990v1.pdf	Coreference Resolution#GAP#F1#85.3
1911.09532v2.pdf	Coreference Resolution#The ARRAU Corpus#Avg F1#77.9$Coreference Resolution#CoNLL 2012#Avg F1#76.4
2101.00884v1.pdf	Coreference Resolution#STM-coref#CoNLL F1#61.4$Coreference Resolution#STM-coref#CoNLL F1#50.4
2106.00933v2.pdf	Coreference Resolution#OntoGUM#Avg F1#64.6
2101.00434v2.pdf	Coreference Resolution#CoNLL 2012#Avg F1#80.3$Coreference Resolution#CoNLL 2012#Avg F1#80.2
2009.12013v2.pdf	Coreference Resolution#CoNLL 2012#Avg F1#80.2
2004.00584v3.pdf	Entity Resolution#WDC Watches-xlarge#F1 (%)#96.53$Entity Resolution#WDC Computers-xlarge#F1 (%)#95.45$Entity Resolution#WDC Watches-small#F1 (%)#85.12$Entity Resolution#Abt-Buy#F1 (%)#89.33$Entity Resolution#WDC Computers-small#F1 (%)#80.76$Entity Resolution#Amazon-Google#F1 (%)#75.58
2202.02098v2.pdf	Entity Resolution#WDC Computers-xlarge#F1 (%)#98.33$Entity Resolution#Abt-Buy#F1 (%)#94.29$Entity Resolution#WDC Computers-small#F1 (%)#95.21$Entity Resolution#Amazon-Google#F1 (%)#79.28
2009.07203v3.pdf	Entity Resolution#Amazon-Google#F1 (%)#70.2
2106.10800v5.pdf	Image Compression#ImageNet#Bit rate#1350$Image Compression#PCam#Bit rate#1490$Image Compression#Caltech101#Bit rate#1340$Image Compression#Cars-196#Bit rate#1470$Image Compression#STL-10#Bit rate#1340$Image Compression#Food-101#Bit rate#1270$Image Compression#CIFAR-10#Bit rate#1410$Image Compression#Oxford-IIIT Pet Dataset#Bit rate#1210
2111.00965v1.pdf	Image Compression#ImageNet32#bpsp#3.88
1811.12817v3.pdf	Image Compression#ImageNet32#bpsp#4.76$Image Compression#ImageNet32#bpsp#6.35$Image Compression#ImageNet32#bpsp#6.42
1901.09124v2.pdf	Neural Network Compression#ImageNet#All#0.1
2001.04850v1.pdf	Neural Network Compression#CIFAR-10#Size (MB)#1.9$Neural Network Compression#CIFAR-10#Size (MB)#2.9$Neural Network Compression#CIFAR-10#Size (MB)#54.6$Network Pruning#CIFAR-10#Inference Time (ms)#4.74$Network Pruning#CIFAR-10#Inference Time (ms)#5.23$Network Pruning#CIFAR-10#Inference Time (ms)#23.15
1903.12483v4.pdf	Neural Network Compression#CIFAR-10#Size (MB)#993.5337$Neural Network Compression#CIFAR-10#Size (MB)#1005.1122
2012.00212v2.pdf	Optical Flow Estimation#KITTI 2015 unsupervised#Average End-Point Error#9.38$Optical Flow Estimation#KITTI 2012 unsupervised#Average End-Point Error#1.4$Optical Flow Estimation#Sintel Clean unsupervised#Average End-Point Error#4.68$Optical Flow Estimation#Sintel Final unsupervised#Average End-Point Error#5.32
2003.13045v2.pdf	Optical Flow Estimation#KITTI 2015 unsupervised#Fl-all#11.79$Optical Flow Estimation#KITTI 2012 unsupervised#Average End-Point Error#1.5$Optical Flow Estimation#Sintel Clean unsupervised#Average End-Point Error#4.49$Optical Flow Estimation#Sintel Final unsupervised#Average End-Point Error#5.67
2204.08442v1.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#13.0$Optical Flow Estimation#KITTI 2015 (train)#EPE#3.76$Optical Flow Estimation#Sintel-clean#Average End-Point Error#1.519$Optical Flow Estimation#KITTI 2015#Fl-all#4.91$Optical Flow Estimation#Sintel-final#Average End-Point Error#2.886
2203.16194v4.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#14.7$Optical Flow Estimation#KITTI 2015 (train)#EPE#4.09$Optical Flow Estimation#Sintel-clean#Average End-Point Error#1.16$Optical Flow Estimation#Sintel-final#Average End-Point Error#2.09
2203.11335v1.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#15.4$Optical Flow Estimation#KITTI 2015 (train)#EPE#4.24
2104.02409v3.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#17.1$Optical Flow Estimation#KITTI 2015 (train)#EPE#4.69$Optical Flow Estimation#Sintel-clean#Average End-Point Error#1.388$Optical Flow Estimation#Sintel-final#Average End-Point Error#2.470
2003.12039v3.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#17.4$Optical Flow Estimation#KITTI 2015 (train)#EPE#5.04$Optical Flow Estimation#Sintel-clean#Average End-Point Error#1.609$Optical Flow Estimation#Sintel-final#Average End-Point Error#2.855
2203.16896v1.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#17.5$Optical Flow Estimation#KITTI 2015 (train)#EPE#4.88
2104.02166v1.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#19.3$Optical Flow Estimation#KITTI 2015 (train)#EPE#6.80
2003.10955v2.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#23.1$Optical Flow Estimation#Sintel-clean#Average End-Point Error#2.52$Optical Flow Estimation#Sintel-clean#Average End-Point Error#2.77$Optical Flow Estimation#KITTI 2015#Fl-all#6.11$Optical Flow Estimation#KITTI 2015#Fl-all#6.81$Optical Flow Estimation#KITTI 2012#Average End-Point Error#1.1$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.17$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.38
1812.06264v3.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#24.0$Optical Flow Estimation#KITTI 2015 (train)#EPE#13.17
1903.07414v3.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#25.9$Optical Flow Estimation#KITTI 2015 (train)#EPE#8.97
1709.02371v3.pdf	Optical Flow Estimation#KITTI 2015 (train)#F1-all#33.7$Optical Flow Estimation#KITTI 2015 (train)#EPE#10.35$Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#4.43$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#11.44$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#15.47$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#20.17$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#28.30
2107.14795v3.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#1.81$Optical Flow Estimation#KITTI 2015#Average End-Point Error#4.98$Optical Flow Estimation#Sintel-final#Average End-Point Error#2.42
1705.01352v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#2.53$Optical Flow Estimation#Sintel-final#Average End-Point Error#5.38
1806.00800v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#2.82
1809.05571v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.45$Optical Flow Estimation#KITTI 2015#Fl-all#7.72$Optical Flow Estimation#KITTI 2012#Average End-Point Error#1.5$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.6
2002.10770v2.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.592$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.098
2006.12263v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.71$Optical Flow Estimation#KITTI 2012#Average End-Point Error#1.5$Optical Flow Estimation#Sintel-final#Average End-Point Error#5.11
1904.09117v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.74$Optical Flow Estimation#KITTI 2015#Fl-all#8.42$Optical Flow Estimation#KITTI 2012#Average End-Point Error#1.5$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.26
1904.05290v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#3.84$Optical Flow Estimation#KITTI 2015#Fl-all#7.65$Optical Flow Estimation#KITTI 2012#Average End-Point Error#1.6$Optical Flow Estimation#Sintel-final#Average End-Point Error#4.579
1805.07036v1.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#4.54$Optical Flow Estimation#Sintel-final#Average End-Point Error#5.38
2011.14814v2.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#4.69$Optical Flow Estimation#KITTI 2015#Fl-all#10.81$Optical Flow Estimation#Sintel-final#Average End-Point Error#5.8
1611.00850v2.pdf	Optical Flow Estimation#Sintel-clean#Average End-Point Error#6.64$Optical Flow Estimation#Sintel-final#Average End-Point Error#8.36$Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#36.94$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#50.92$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#54.29$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#62.60$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#72.57
2006.04902v2.pdf	Optical Flow Estimation#Sintel Clean unsupervised#Average End-Point Error#5.21$Optical Flow Estimation#Sintel Final unsupervised#Average End-Point Error#6.50
1811.01602v1.pdf	Optical Flow Estimation#Sintel-final#Average End-Point Error#4.52
2203.06172v2.pdf	Data Augmentation#ImageNet#Accuracy (%)#81.32$Data Augmentation#ImageNet#Accuracy (%)#78.30
1905.00397v2.pdf	Data Augmentation#ImageNet#Accuracy (%)#80.6$Data Augmentation#ImageNet#Accuracy (%)#77.6$Image Classification#CIFAR-100#Percentage correct#88.3$Image Classification#ImageNet#Top 1 Accuracy#80.6%$Image Classification#ImageNet#Top 5 Accuracy#95.3%$Image Classification#ImageNet#Top 1 Accuracy#77.6%$Image Classification#SVHN#Percentage error#1.1$Image Classification#CIFAR-10#Percentage correct#98.3$Image Classification#CIFAR-10#PARAMS#26.21M
2003.14348v1.pdf	Data Augmentation#ImageNet#Accuracy (%)#80.4$Data Augmentation#ImageNet#Accuracy (%)#77.63
1805.09501v3.pdf	Data Augmentation#ImageNet#Accuracy (%)#80.0$Data Augmentation#ImageNet#Accuracy (%)#77.6$Image Classification#CIFAR-100#Percentage correct#89.3$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.8%$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#13.07%$Fine-Grained Image Classification#FGVC Aircraft#Top-1 Error Rate#7.33$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.67%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#11.02%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#88.98%$Fine-Grained Image Classification#Oxford 102 Flowers#Top-1 Error Rate#4.64%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#95.36%
2103.10158v2.pdf	Data Augmentation#ImageNet#Accuracy (%)#78.07
1909.13719v2.pdf	Data Augmentation#ImageNet#Accuracy (%)#77.6$Image Classification#ImageNet#Top 1 Accuracy#85.4%$Image Classification#ImageNet#Top 1 Accuracy#85%$Image Classification#ImageNet#Number of params#66M
2003.03780v3.pdf	Data Augmentation#ImageNet#Accuracy (%)#77.5
1911.06987v1.pdf	Data Augmentation#ImageNet#Accuracy (%)#76.5
2004.11883v3.pdf	Object Counting#TallyQA-Simple#Accuracy#74.9$Object Counting#TallyQA-Simple#RMSE#1$Object Counting#TallyQA-Simple#Accuracy#70.8$Object Counting#TallyQA-Simple#RMSE#1.09$Object Counting#TallyQA-Complex#Accuracy#56.8$Object Counting#TallyQA-Complex#RMSE#1.43$Object Counting#TallyQA-Complex#Accuracy#54.1$Object Counting#TallyQA-Complex#RMSE#1.52$Object Counting#HowMany-QA#Accuracy#64$Object Counting#HowMany-QA#RMSE#2.3$Object Counting#HowMany-QA#Accuracy#61.2$Object Counting#HowMany-QA#RMSE#2.36
1810.12440v2.pdf	Object Counting#TallyQA-Simple#Accuracy#71.8$Object Counting#TallyQA-Simple#RMSE#1.13$Object Counting#TallyQA-Complex#Accuracy#56.2$Object Counting#TallyQA-Complex#RMSE#1.43$Object Counting#HowMany-QA#Accuracy#60.3$Object Counting#HowMany-QA#RMSE#2.35
2208.13721v2.pdf	Object Counting#CARPK#MAE#5.75$Object Counting#CARPK#RMSE#7.45$Object Counting#FSC147#MAE(val)#13.13$Object Counting#FSC147#RMSE(val)#49.83$Object Counting#FSC147#MAE(test)#11.95$Object Counting#FSC147#RMSE(test)#91.23
2203.08354v1.pdf	Object Counting#CARPK#MAE#5.76$Object Counting#CARPK#RMSE#7.83$Object Counting#FSC147#MAE(val)#15.74$Object Counting#FSC147#RMSE(val)#58.53$Object Counting#FSC147#MAE(test)#14.62$Object Counting#FSC147#RMSE(test)#91.83
1904.00853v3.pdf	Object Counting#CARPK#MAE#6.77$Object Counting#CARPK#RMSE#8.52$Dense Object Detection#SKU-110K#AP#49.2
1707.05972v3.pdf	Object Counting#CARPK#MAE#16.62$Object Counting#CARPK#RMSE#22.30$Object Counting#CARPK#MAE#22.76$Object Counting#CARPK#RMSE#34.46
1609.04453v1.pdf	Object Counting#CARPK#MAE#21.88$Object Counting#CARPK#RMSE#36.73
1612.08242v1.pdf	Object Counting#CARPK#MAE#130.40$Object Counting#CARPK#RMSE#172.46$Object Detection#PASCAL VOC 2007#MAP#78.6%$Object Detection#UA-DETRAC#mAP#57.72
1604.03505v3.pdf	Object Counting#COCO count-test#m-reIRMSE#0.18$Object Counting#COCO count-test#m-reIRMSE-nz#0.81$Object Counting#COCO count-test#mRMSE#0.36$Object Counting#COCO count-test#mRMSE-nz#1.98$Object Counting#COCO count-test#m-reIRMSE-nz#0.82$Object Counting#COCO count-test#mRMSE#0.35$Object Counting#COCO count-test#mRMSE-nz#1.96$Object Counting#COCO count-test#m-reIRMSE#0.20$Object Counting#COCO count-test#m-reIRMSE-nz#1.13$Object Counting#COCO count-test#mRMSE#0.49$Object Counting#COCO count-test#mRMSE-nz#2.78$Object Counting#COCO count-test#m-reIRMSE#0.23$Object Counting#COCO count-test#m-reIRMSE-nz#0.91$Object Counting#COCO count-test#mRMSE#0.42$Object Counting#COCO count-test#mRMSE-nz#2.25$Object Counting#COCO count-test#m-reIRMSE#0.24$Object Counting#COCO count-test#m-reIRMSE-nz#0.87$Object Counting#COCO count-test#mRMSE#0.38$Object Counting#COCO count-test#mRMSE-nz#2.08$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.65$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.20$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.42$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.68$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.68$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.22$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.43$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.65$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.73$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.27$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.50$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.83$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.85$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.26$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.92
1903.02494v2.pdf	Object Counting#COCO count-test#m-reIRMSE#0.18$Object Counting#COCO count-test#m-reIRMSE-nz#0.84$Object Counting#COCO count-test#mRMSE#0.34$Object Counting#COCO count-test#mRMSE-nz#1.89$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.61$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.17$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.29$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.14
1807.09856v1.pdf	Object Counting#COCO count-test#m-reIRMSE#0.19$Object Counting#COCO count-test#m-reIRMSE-nz#0.99$Object Counting#COCO count-test#mRMSE#0.38$Object Counting#COCO count-test#mRMSE-nz#2.20$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.61$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.17$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.31$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.20$Object Counting#Pascal VOC 2007 count-test#m-reIRMSE-nz#0.70$Object Counting#Pascal VOC 2007 count-test#m-relRMSE#0.20$Object Counting#Pascal VOC 2007 count-test#mRMSE#0.35$Object Counting#Pascal VOC 2007 count-test#mRMSE-nz#1.32
2112.05993v1.pdf	Object Counting#FSC147#MAE(val)#17.11$Object Counting#FSC147#RMSE(val)#56.81$Object Counting#FSC147#MAE(test)#15.78$Object Counting#FSC147#RMSE(test)#97.15
2207.10988v2.pdf	Object Counting#FSC147#MAE(test)#16.79$Object Counting#FSC147#RMSE(test)#123.56
2205.10203v2.pdf	Object Counting#FSC147#MAE(val)#17.49$Object Counting#FSC147#RMSE(val)#58.81$Object Counting#FSC147#MAE(test)#17.12$Object Counting#FSC147#RMSE(test)#104.53
2104.08391v1.pdf	Object Counting#FSC147#MAE(val)#23.75$Object Counting#FSC147#RMSE(val)#69.07$Object Counting#FSC147#MAE(test)#22.08$Object Counting#FSC147#RMSE(test)#99.54
2006.12250v2.pdf	3D Object Reconstruction#Data3D−R2N2#3DIoU#0.67$3D Object Reconstruction#Data3D−R2N2#3DIoU#0.645
1901.11153v2.pdf	3D Object Reconstruction#Data3D−R2N2#3DIoU#0.661$3D Object Reconstruction#Data3D−R2N2#3DIoU#0.634
1804.10975v1.pdf	3D Object Reconstruction#Data3D−R2N2#3DIoU#0.640
1901.11461v1.pdf	3D Object Reconstruction#Data3D−R2N2#Avg F1#67.37
1802.09987v3.pdf	3D Object Reconstruction#Data3D−R2N2#Avg F1#66.39
1804.01654v2.pdf	3D Object Reconstruction#Data3D−R2N2#Avg F1#59.72
1711.07566v1.pdf	3D Object Reconstruction#Data3D−R2N2#Avg F1#33.80
2108.07845v4.pdf	3D Object Reconstruction From A Single Image#BUFF#Point-to-surface distance (cm)#0.58$3D Object Reconstruction From A Single Image#BUFF#Chamfer (cm)#0.61$3D Object Reconstruction From A Single Image#BUFF#Surface normal consistency#0.03$3D Object Reconstruction From A Single Image#RenderPeople#Point-to-surface distance (cm)#0.5$3D Object Reconstruction From A Single Image#RenderPeople#Chamfer (cm)#0.61$3D Object Reconstruction From A Single Image#RenderPeople#Surface normal consistency#0.03
2004.04572v2.pdf	3D Object Reconstruction From A Single Image#BUFF#Point-to-surface distance (cm)#0.82$3D Object Reconstruction From A Single Image#BUFF#Chamfer (cm)#0.87$3D Object Reconstruction From A Single Image#BUFF#Surface normal consistency#0.04
1303.3997v2.pdf	3D Object Reconstruction From A Single Image#RenderPeople#Point-to-surface distance (cm)#002$3D Object Reconstruction From A Single Image#RenderPeople#Chamfer (cm)#202$3D Object Reconstruction From A Single Image#RenderPeople#Surface normal consistency#0.2
2204.02569v1.pdf	Gait Recognition#Gait3D#Rank-1#46.30$Gait Recognition#Gait3D#Rank-5#64.50$Gait Recognition#Gait3D#mAP#37.16$Gait Recognition#Gait3D#mINP#22.23$Gait Recognition in the Wild#Gait3D#Rank-1#46.30$Gait Recognition in the Wild#Gait3D#Rank-5#64.50$Gait Recognition in the Wild#Gait3D#mAP#37.16$Gait Recognition in the Wild#Gait3D#mINP#22.23
2204.03270v2.pdf	Gait Recognition#OUMVLP#Averaged rank-1 acc(%)#91.0$Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#94.5$Multiview Gait Recognition#CASIA-B#NM#5-6#98.7$Multiview Gait Recognition#CASIA-B#BG#1-2#94.8$Multiview Gait Recognition#CASIA-B#CL#1-2#88.7
2203.04038v1.pdf	Gait Recognition#OUMVLP#Averaged rank-1 acc(%)#90.9$Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#93.0$Multiview Gait Recognition#CASIA-B#NM#5-6#97.7$Multiview Gait Recognition#CASIA-B#BG#1-2#95.3$Multiview Gait Recognition#CASIA-B#CL#1-2#86.0
1811.06186v4.pdf	Gait Recognition#OUMVLP#Averaged rank-1 acc(%)#87.1$Multiview Gait Recognition#OU-MVLP#Accuracy (Cross-View)#87.1$Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#84.2$Multiview Gait Recognition#CASIA-B#NM#5-6#95.0$Multiview Gait Recognition#CASIA-B#BG#1-2#87.2$Multiview Gait Recognition#CASIA-B#CL#1-2#70.4
2210.15491v2.pdf	Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#88.3$Multiview Gait Recognition#CASIA-B#NM#5-6#94.9$Multiview Gait Recognition#CASIA-B#BG#1-2#85.6$Multiview Gait Recognition#CASIA-B#CL#1-2#84.5$Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#83.4$Multiview Gait Recognition#CASIA-B#NM#5-6#91.5$Multiview Gait Recognition#CASIA-B#BG#1-2#81.4$Multiview Gait Recognition#CASIA-B#CL#1-2#77.2
2101.11228v2.pdf	Multiview Gait Recognition#CASIA-B#Accuracy (Cross-View, Avg)#76.3$Multiview Gait Recognition#CASIA-B#NM#5-6#87.7$Multiview Gait Recognition#CASIA-B#BG#1-2#74.8$Multiview Gait Recognition#CASIA-B#CL#1-2#66.3
1804.02142v1.pdf	Motion Segmentation#KT3DMoSeg#Error#7.92$Motion Segmentation#MTPV62#Classification Error#0.65$Motion Segmentation#Hopkins155#Classification Error#0.31
2005.04437v5.pdf	Motion Segmentation#ApolloScape#Accuracy#90$Motion Segmentation#ApolloScape#Accuracy#89$Motion Segmentation#ApolloScape#Accuracy#86$Motion Segmentation#ApolloScape#Accuracy#72$Motion Segmentation#ApolloScape#Accuracy#63
1509.02649v2.pdf	Motion Segmentation#Hopkins155#Classification Error#1.01
1708.00111v2.pdf	Motion Segmentation#Hopkins155#Classification Error#1.97
2203.11693v1.pdf	Motion Detection#nuScenes#F1 (%)#92.9$Motion Detection#nuScenes#F1 (%)#89.5
1904.03485v2.pdf	Denoising#Darmstadt Noise Dataset#PSNR#38.4
1807.04364v1.pdf	Denoising#Darmstadt Noise Dataset#PSNR#37.93$Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#37.94$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.9403
1807.04686v2.pdf	Denoising#Darmstadt Noise Dataset#PSNR#37.57$Image Denoising#SIDD#PSNR (sRGB)#30.78$Image Denoising#SIDD#SSIM (sRGB)#0.801$Image Denoising#DND#PSNR (sRGB)#38.06$Image Denoising#DND#SSIM (sRGB)#0.942$Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#38.06$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.9421
1705.09912v2.pdf	Denoising#Darmstadt Noise Dataset#PSNR#37.38
1805.03779v3.pdf	Denoising#Darmstadt Noise Dataset#PSNR#35.95
1710.04026v2.pdf	Denoising#Darmstadt Noise Dataset#PSNR#34.40$Color Image Denoising#CBSD68 sigma35#PSNR#29.58$Color Image Denoising#CBSD68 sigma25#PSNR#31.21$Color Image Denoising#CBSD68 sigma50#PSNR#27.96$Color Image Denoising#McMaster sigma35#PSNR#30.81$Color Image Denoising#CBSD68 sigma15#PSNR#33.87$Color Image Denoising#McMaster sigma15#PSNR#34.66$Color Image Denoising#McMaster sigma75#PSNR#27.33$Color Image Denoising#Kodak25 sigma50#PSNR#28.98$Color Image Denoising#CBSD68 sigma75#PSNR#26.24$Color Image Denoising#Kodak25 sigma25#PSNR#32.13$Color Image Denoising#McMaster sigma50#PSNR#29.18$Color Image Denoising#Kodak25 sigma75#PSNR#27.27$Color Image Denoising#McMaster sigma25#PSNR#32.35$Color Image Denoising#Kodak25 sigma35#PSNR#30.57$Color Image Denoising#Kodak25 sigma15#PSNR#34.63$Grayscale Image Denoising#Set12 sigma15#PSNR#25.49$Grayscale Image Denoising#Clip300 sigma60#PSNR#25.51$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.29$Grayscale Image Denoising#BSD68 sigma35#PSNR#27.73$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.19$Grayscale Image Denoising#BSD68 sigma75#PSNR#24.79$Grayscale Image Denoising#Clip300 sigma35#PSNR#27.75$Grayscale Image Denoising#Clip300 sigma15#PSNR#31.68$Grayscale Image Denoising#Clip300 sigma25#PSNR#29.25$Grayscale Image Denoising#Clip300 sigma50#PSNR#26.25$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.63
2011.00139v1.pdf	Denoising#AAPM#PSNR#0.0061±0.0014$Denoising#AAPM#SSIM#0.9866±0.0031
2003.06792v2.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.72$Image Denoising#SIDD#SSIM (sRGB)#0.959$Image Denoising#DND#PSNR (sRGB)#39.88$Image Denoising#DND#SSIM (sRGB)#0.956
2203.01645v1.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.72$Image Denoising#SIDD#SSIM (sRGB)#0.959
2003.07761v1.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.52$Image Denoising#SIDD#SSIM (sRGB)#0.957$Image Denoising#DND#PSNR (sRGB)#39.56$Image Denoising#DND#SSIM (sRGB)#0.956
2007.05946v1.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.47$Image Denoising#SIDD#SSIM (sRGB)#0.957$Image Denoising#DND#PSNR (sRGB)#39.58$Image Denoising#DND#SSIM (sRGB)#0.955
2001.10291v2.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.46$Image Denoising#SIDD#SSIM (sRGB)#0.957$Image Denoising#DND#PSNR (sRGB)#39.59$Image Denoising#DND#SSIM (sRGB)#0.952
1908.11314v4.pdf	Image Denoising#SIDD#PSNR (sRGB)#39.28$Image Denoising#SIDD#SSIM (sRGB)#0.956$Image Denoising#DND#PSNR (sRGB)#39.38$Image Denoising#DND#SSIM (sRGB)#0.952
2002.11244v2.pdf	Image Denoising#SIDD#PSNR (sRGB)#38.95$Image Denoising#SIDD#SSIM (sRGB)#0.952$Image Denoising#DND#PSNR (sRGB)#39.37$Image Denoising#DND#SSIM (sRGB)#0.951
1904.07396v2.pdf	Image Denoising#SIDD#PSNR (sRGB)#38.71$Image Denoising#SIDD#SSIM (sRGB)#0.951$Image Denoising#DND#PSNR (sRGB)#39.26$Image Denoising#DND#SSIM (sRGB)#0.953$Color Image Denoising#BSD68 sigma25#PSNR#31.37$Color Image Denoising#CBSD68 sigma50#PSNR#28.14$Color Image Denoising#BSD68 sigma15#PSNR#34.01$Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#39.23$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.9526$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.4$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.34$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.81
2012.15028v2.pdf	Image Denoising#SIDD#SSIM (sRGB)#0.973$Image Denoising#DND#PSNR (sRGB)#39.89$Image Denoising#DND#SSIM (sRGB)#0.955
2003.12751v2.pdf	Image Denoising#ELD SonyA7S2 x100#PSNR (Raw)#45.44$Image Denoising#ELD SonyA7S2 x100#SSIM#0.975$Image Denoising#ELD SonyA7S2 x200#PSNR (Raw)#43.42$Image Denoising#ELD SonyA7S2 x200#SSIM#0.954
1805.01934v1.pdf	Image Denoising#ELD SonyA7S2 x100#PSNR (Raw)#44.50$Image Denoising#ELD SonyA7S2 x100#SSIM#0.971$Image Denoising#SID x300#PSNR (Raw)#36.85$Image Denoising#SID x300#SSIM#0.923$Image Denoising#SID x100#PSNR (Raw)#42.06$Image Denoising#SID x100#SSIM#39.60$Image Denoising#ELD SonyA7S2 x200#PSNR (Raw)#42.45$Image Denoising#ELD SonyA7S2 x200#SSIM#0.945
2008.02320v1.pdf	Image Denoising#FMD#PSNR#8-10dB
2107.05318v1.pdf	Image Denoising#BSD68 sigma30#PSNR#27.67
2108.02158v1.pdf	Image Denoising#SID x300#PSNR (Raw)#36.36$Image Denoising#SID x300#SSIM#0.911$Image Denoising#SID x100#PSNR (Raw)#41.95$Image Denoising#SID x100#SSIM#39.44
2003.01643v2.pdf	Image Denoising#ultracold fermions Technion system, pixelfly#ODRMSE#0.0711
2006.13801v1.pdf	intensity image denoising#FMD#PSNR#7.5dB improvement
2204.14100v1.pdf	Color Image Denoising#CBSD68 sigma35#PSNR#30.24$Color Image Denoising#CBSD68 sigma25#PSNR#31.78$Color Image Denoising#CBSD68 sigma50#PSNR#29.02$Color Image Denoising#CBSD68 sigma15#PSNR#34.61$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.87$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.50$Grayscale Image Denoising#BSD68 sigma15#PSNR#32.11
1904.10898v1.pdf	Color Image Denoising#CBSD68 sigma35#PSNR#29.34$Color Image Denoising#CBSD68 sigma25#PSNR#30.99$Color Image Denoising#CBSD68 sigma50#PSNR#27.63$Color Image Denoising#CBSD68 sigma10#PSNR#35.92$Color Image Denoising#CBSD68 sigma15#PSNR#33.66$Color Image Denoising#CBSD68 sigma5#PSNR#39.73
1907.03029v2.pdf	Color Image Denoising#CBSD68 sigma35#PSNR#28.81$Color Image Denoising#CBSD68 sigma25#PSNR#30.76$Color Image Denoising#CBSD68 sigma50#PSNR#26.60$Color Image Denoising#CBSD68 sigma70#PSNR#24.18$Color Image Denoising#CBSD68 sigma60#PSNR#25.34$Color Image Denoising#CBSD68 sigma10#PSNR#35.98$Color Image Denoising#CBSD68 sigma40#PSNR#28.01$Color Image Denoising#CBSD68 sigma20#PSNR#32.02$Color Image Denoising#CBSD68 sigma15#PSNR#33.66$Color Image Denoising#CBSD68 sigma75#PSNR#23.63$Color Image Denoising#CBSD68 sigma45#PSNR#27.28$Color Image Denoising#CBSD68 sigma55#PSNR#25.95$Color Image Denoising#CBSD68 sigma5#PSNR#40.05$Color Image Denoising#CBSD68 sigma65#PSNR#24.75$Color Image Denoising#CBSD68 sigma30#PSNR#29.71$Grayscale Image Denoising#BSD68 sigma45#PSNR#25.67$Grayscale Image Denoising#BSD68 sigma5#PSNR#37.25$Grayscale Image Denoising#BSD68 sigma20#PSNR#29.88$Grayscale Image Denoising#BSD68 sigma50#PSNR#25.1$Grayscale Image Denoising#BSD68 sigma35#PSNR#27.03$Grayscale Image Denoising#BSD68 sigma65#PSNR#23.56$Grayscale Image Denoising#BSD68 sigma25#PSNR#28.75$Grayscale Image Denoising#BSD68 sigma75#PSNR#22.67$Grayscale Image Denoising#BSD68 sigma70#PSNR#23.1$Grayscale Image Denoising#BSD68 sigma30#PSNR#27.82$Grayscale Image Denoising#BSD68 sigma55#PSNR#24.55$Grayscale Image Denoising#BSD68 sigma10#PSNR#33.47$Grayscale Image Denoising#BSD68 sigma60#PSNR#24.05$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.35$Grayscale Image Denoising#BSD68 sigma40#PSNR#26.31
1909.05742v1.pdf	Color Image Denoising#BSD68 sigma25#PSNR#31.18$Color Image Denoising#CBSD68 sigma50#PSNR#28.00$Color Image Denoising#BSD68 sigma75#PSNR#26.32$Color Image Denoising#BSD68 sigma15#PSNR#33.83
1409.8230v9.pdf	Color Image Denoising#RENOIR#Average PSNR#36.355$Color Image Denoising#RENOIR#Average PSNR#33.755
1905.11172v1.pdf	Color Image Denoising#NTIRE 2019 Real Image Denoising Challenge (sRGB)#PSNR#39.931743$Color Image Denoising#NTIRE 2019 Real Image Denoising Challenge (sRGB)#SSIM#0.973589
1901.11365v2.pdf	Color Image Denoising#ImageNet#PSNR#22$Color Image Denoising#CellNet#PSNR#34.4$Color Image Denoising#Hanzi#PSNR#13.9
1811.11127v1.pdf	Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#40.35$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.9641$Color Image Denoising#Darmstadt Noise Dataset#PSNR (Raw)#48.88$Color Image Denoising#Darmstadt Noise Dataset#SSIM (Raw)#0.9821
1908.00273v2.pdf	Color Image Denoising#Darmstadt Noise Dataset#PSNR (sRGB)#39.4$Color Image Denoising#Darmstadt Noise Dataset#SSIM (sRGB)#0.9528$Color Image Denoising#Darmstadt Noise Dataset#PSNR (Raw)#48.5$Color Image Denoising#Darmstadt Noise Dataset#SSIM (Raw)#0.9806
1907.08448v1.pdf	Grayscale Image Denoising#Set12 sigma15#PSNR#33.14$Grayscale Image Denoising#Urban100 sigma25#PSNR#30.95$Grayscale Image Denoising#Set12 sigma50#PSNR#27.6$Grayscale Image Denoising#BSD68 sigma50#PSNR#26.38$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.35$Grayscale Image Denoising#Set12 sigma25#PSNR#30.78$Grayscale Image Denoising#Urban100 sigma15#PSNR#33.47$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.83$Grayscale Image Denoising#Urban100 sigma50#PSNR#27.41
2103.04779v1.pdf	Grayscale Image Denoising#BSD68 sigma50#PSNR#26.35$Grayscale Image Denoising#BSD68 sigma25#PSNR#29.26$Grayscale Image Denoising#BSD68 sigma15#PSNR#31.74
1908.06452v1.pdf	Salt-And-Pepper Noise Removal#Kodak24 Noise Level 50%#PSNR#34.35$Salt-And-Pepper Noise Removal#Kodak24 Noise Level 70%#PSNR#31.56$Salt-And-Pepper Noise Removal#Kodak24 Noise Level 30%#PSNR#36.39$Salt-And-Pepper Noise Removal#BSD300 Noise Level 70%#PSNR#32.4$Salt-And-Pepper Noise Removal#BSD300 Noise Level 50%#PSNR#37.28$Salt-And-Pepper Noise Removal#BSD300 Noise Level 30%#PSNR#40.90
1803.04189v3.pdf	Salt-And-Pepper Noise Removal#Kodak24 Noise Level 50%#PSNR#32.27$Salt-And-Pepper Noise Removal#Kodak24 Noise Level 70%#PSNR#30.49$Salt-And-Pepper Noise Removal#Kodak24 Noise Level 30%#PSNR#34.95$Salt-And-Pepper Noise Removal#BSD300 Noise Level 70%#PSNR#31.42$Salt-And-Pepper Noise Removal#BSD300 Noise Level 50%#PSNR#35.92$Salt-And-Pepper Noise Removal#BSD300 Noise Level 30%#PSNR#39.83
2105.14327v1.pdf	Hyperspectral Image Classification#CASI University of Houston#Overall Accuracy#95.36$Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.63%$Hyperspectral Image Classification#Indian Pines#Kappa#0.9958$Hyperspectral Image Classification#Pavia University#Overall Accuracy#99.97%$Hyperspectral Image Classification#Pavia University#Kappa@1%#0.9996
2011.05670v1.pdf	Hyperspectral Image Classification#CASI University of Houston#Overall Accuracy#86.61$Hyperspectral Image Classification#CASI University of Houston#Average Accuracy#88.44$Hyperspectral Image Classification#CASI University of Houston#Kappa#0.8555$Hyperspectral Image Classification#Salinas#OA@200#99.92$Hyperspectral Image Classification#Salinas#AA@200#99.91$Hyperspectral Image Classification#Salinas#Kappa@200#0.9991$Hyperspectral Image Classification#Pavia University#Overall Accuracy#99.81%$Hyperspectral Image Classification#Pavia University#OA@200#99.81$Hyperspectral Image Classification#Pavia University#AA@200#99.83$Hyperspectral Image Classification#Pavia University#Kappa@200#0.9974
2104.00341v1.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.86%$Hyperspectral Image Classification#Salinas Scene#Overall Accuracy#100%$Hyperspectral Image Classification#Pavia University#Overall Accuracy#99.99%
2202.06458v1.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.83%$Hyperspectral Image Classification#Botswana#Overall Accuracy#1$Hyperspectral Image Classification#Salinas#Overall Accuracy#99.98%$Hyperspectral Image Classification#Pavia University#Overall Accuracy#99.96%
1902.06701v3.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.81%$Hyperspectral Image Classification#Salinas Scene#Overall Accuracy#100%
2206.02327v2.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.74$Hyperspectral Image Classification#Salinas#OA@200#100.00$Hyperspectral Image Classification#Pavia University#Overall Accuracy#100.00
1903.06258v2.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#99.50%
1612.00144v2.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#96.77%$Hyperspectral Image Classification#Pavia University#Overall Accuracy#97.48%
1705.00727v2.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#96.12%$Hyperspectral Image Classification#Pavia University#Overall Accuracy#96.18
1810.12563v1.pdf	Hyperspectral Image Classification#Indian Pines#Overall Accuracy#90.35%$Hyperspectral Image Classification#Pavia University#Overall Accuracy#98.44%
1904.10674v1.pdf	Hyperspectral Image Classification#Pavia University#Overall Accuracy#96.71
2002.01145v2.pdf	Sentence Compression#Google Dataset#F1#0.855$Sentence Compression#Google Dataset#CR#0.407
1604.03357v1.pdf	Sentence Compression#Google Dataset#F1#0.81$Sentence Compression#Google Dataset#CR#-
1810.09302v6.pdf	Sentence Embeddings For Biomedical Texts#MedSTS#Pearson Correlation#0.767$Sentence Embeddings For Biomedical Texts#MedSTS#Pearson Correlation#0.759$Sentence Embeddings For Biomedical Texts#MedSTS#Pearson Correlation#0.750$Sentence Embeddings For Biomedical Texts#MedSTS#Pearson Correlation#0.714$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.817$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.795$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.350$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.345
2110.15708v1.pdf	Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.871$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.846$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.819$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.804$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.798$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.766$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.723$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.485$Sentence Embeddings For Biomedical Texts#BIOSSES#Pearson Correlation#0.253
2009.08330v3.pdf	Chunking#CoNLL 2003 (German)#F1#94.4$Chunking#CoNLL 2003 (English)#F1#92.0
2009.08229v2.pdf	Chunking#CoNLL 2003 (German)#F1#94.04$Chunking#CoNLL 2003 (English)#F1#91.71
1611.01587v5.pdf	Chunking#Penn Treebank#F1 score#95.77
2010.14568v1.pdf	Constituency Parsing#Penn Treebank#F1 score#96.34$Constituency Parsing#CTB5#F1 score#93.52
2008.03736v1.pdf	Constituency Parsing#Penn Treebank#F1 score#96.32$Constituency Parsing#Penn Treebank#F1 score#95.69$Constituency Parsing#Penn Treebank#F1 score#94.12$Constituency Parsing#CTB7#F1 score#91.92$Constituency Parsing#CTB7#F1 score#91.55$Constituency Parsing#CTB7#F1 score#88.60$Constituency Parsing#CTB5#F1 score#92.27$Constituency Parsing#CTB5#F1 score#89.80
2109.12814v2.pdf	Constituency Parsing#Penn Treebank#F1 score#95.92
1805.01052v1.pdf	Constituency Parsing#Penn Treebank#F1 score#95.13$Constituency Parsing#CTB5#F1 score#87.43
1707.03058v1.pdf	Constituency Parsing#Penn Treebank#F1 score#94.66
1707.05000v1.pdf	Constituency Parsing#Penn Treebank#F1 score#94.2
1611.05774v2.pdf	Constituency Parsing#Penn Treebank#F1 score#93.6
1412.7449v3.pdf	Constituency Parsing#Penn Treebank#F1 score#92.1
1602.07776v4.pdf	Constituency Parsing#Penn Treebank#F1 score#﻿93.3
1812.11760v2.pdf	Constituency Parsing#CTB5#F1 score#91.75
2205.00484v1.pdf	Constituency Grammar Induction#PTB#Mean F1 (WSJ)#64.1
2110.02283v2.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#66.8$Constituency Grammar Induction#PTB#Mean F1 (WSJ10)#74.2$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#63.1
2105.15021v1.pdf	Constituency Grammar Induction#PTB#Mean F1 (WSJ)#60.4
2104.13727v1.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#61.4$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#57.7
1906.10225v9.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#60.1$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#55.2$Constituency Grammar Induction#PTB#Max F1 (WSJ)#52.6$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#50.8
1810.09536v6.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#50.0$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#48.1$Constituency Grammar Induction#PTB#Max F1 (WSJ)#49.4$Constituency Grammar Induction#PTB#Mean F1 (WSJ10)#65.1$Constituency Grammar Induction#PTB#Max F1 (WSJ10)#66.8$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#47.7
1808.09111v1.pdf	Constituency Grammar Induction#PTB#Mean F1 (WSJ10)#60.2$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#47.9
1711.02013v2.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#47.9$Constituency Grammar Induction#PTB#Mean F1 (WSJ)#47.3$Constituency Grammar Induction#PTB#Max F1 (WSJ)#38.1
1904.03746v6.pdf	Constituency Grammar Induction#PTB#Max F1 (WSJ)#52.4
2205.12615v1.pdf	Automated Theorem Proving#miniF2F-test#Pass@1#35.2
2205.10893v1.pdf	Automated Theorem Proving#miniF2F-test#Pass@1#29.9
2202.01344v1.pdf	Automated Theorem Proving#miniF2F-test#Pass@1#29.6$Automated Theorem Proving#miniF2F-test#Pass@8#34.5$Automated Theorem Proving#miniF2F-test#Pass@64#36.6
2109.00110v2.pdf	Automated Theorem Proving#miniF2F-test#Pass@1#24.6$Automated Theorem Proving#miniF2F-test#Pass@8#29.2$Automated Theorem Proving#miniF2F-test#Pass@1#18$Automated Theorem Proving#miniF2F-test#Pass@1#1.3$Automated Theorem Proving#miniF2F-test#Pass@8#1.6$Automated Theorem Proving#miniF2F-valid#Pass@8#29.3$Automated Theorem Proving#miniF2F-valid#Pass@1#23.9$Automated Theorem Proving#miniF2F-valid#Pass@8#2$Automated Theorem Proving#miniF2F-valid#Pass@1#1$Automated Theorem Proving#miniF2F-valid#Pass@1#16.8
2205.11491v1.pdf	Automated Theorem Proving#miniF2F-test#Pass@64#41$Automated Theorem Proving#Metamath set.mm#Percentage correct#72.4
1709.09994v1.pdf	Automated Theorem Proving#HolStep (Unconditional)#Classification Accuracy#0.900$Automated Theorem Proving#HolStep (Unconditional)#Classification Accuracy#0.890$Automated Theorem Proving#HolStep (Conditional)#Classification Accuracy#0.903$Automated Theorem Proving#HolStep (Conditional)#Classification Accuracy#0.891
1703.00426v1.pdf	Automated Theorem Proving#HolStep (Unconditional)#Classification Accuracy#0.83$Automated Theorem Proving#HolStep (Conditional)#Classification Accuracy#0.83$Automated Theorem Proving#HolStep (Conditional)#Classification Accuracy#0.82
1905.10006v2.pdf	Automated Theorem Proving#HOList benchmark#Percentage correct#49.95
1904.03241v3.pdf	Automated Theorem Proving#HOList benchmark#Percentage correct#38.88$Automated Theorem Proving#HOList benchmark#Percentage correct#32.65
1905.10501v3.pdf	Automated Theorem Proving#HOList benchmark#Percentage correct#36.55
1907.07794v4.pdf	Automated Theorem Proving#CompCert#Percentage correct#19.36$Automated Theorem Proving#CompCert#Percentage correct#4.99
2009.03393v1.pdf	Automated Theorem Proving#Metamath set.mm#Percentage correct#56.2
2002.07019v2.pdf	Automated Theorem Proving#Metamath set.mm#Percentage correct#22.1
1608.02644v2.pdf	Automated Theorem Proving#Metamath set.mm#Percentage correct#14.3
1911.06904v3.pdf	Automated Theorem Proving#HolStep (Conditional)#Classification Accuracy#0.916
1905.09381v1.pdf	Automated Theorem Proving#CoqGym#Percentage correct#12.2
2003.11657v2.pdf	Graph Matching#SPair-71k#matching accuracy#0.8215$Graph Matching#PASCAL VOC#matching accuracy#0.7899$Graph Matching#Willow Object Class#matching accuracy#0.9718
1911.11308v3.pdf	Graph Matching#SPair-71k#matching accuracy#0.8067$Graph Matching#SPair-71k#matching accuracy#0.6887$Graph Matching#PASCAL VOC#matching accuracy#0.8040$Graph Matching#PASCAL VOC#matching accuracy#0.6458$Graph Matching#PASCAL VOC#matching accuracy#0.6413$Graph Matching#Willow Object Class#matching accuracy#0.9754$Graph Matching#Willow Object Class#matching accuracy#0.8530
2103.06643v2.pdf	Graph Matching#PASCAL VOC#matching accuracy#0.703$Graph Matching#PASCAL VOC#matching accuracy#0.693$Graph Matching#Willow Object Class#matching accuracy#0.977$Graph Matching#Willow Object Class#matching accuracy#0.960
1911.07681v1.pdf	Graph Matching#PASCAL VOC#matching accuracy#0.675$Graph Matching#Willow Object Class#matching accuracy#0.924
2104.08869v2.pdf	Graph Ranking#ogbg-mollipo#Kendall's Tau#0.318$Graph Ranking#ogbg-mollipo#Kendall's Tau#0.332$Graph Ranking#ogbg-mollipo#Kendall's Tau#0.503$Graph Ranking#ogbg-mollipo#Kendall's Tau#0.505$Graph Ranking#ogbg-molesol#Kendall's Tau#0.718$Graph Ranking#ogbg-molesol#Kendall's Tau#0.720$Graph Ranking#ogbg-molesol#Kendall's Tau#0.745$Graph Ranking#ogbg-molesol#Kendall's Tau#0.747$Graph Ranking#ogbg-molfreesolv#Kendall's Tau#0.379$Graph Ranking#ogbg-molfreesolv#Kendall's Tau#0.524$Graph Ranking#ogbg-molfreesolv#Kendall's Tau#0.525$Graph Ranking#ogbg-molfreesolv#Kendall's Tau#0.527$Graph Ranking#ZINC#Kendall's Tau#0.894$Graph Ranking#ZINC#Kendall's Tau#0.873$Graph Ranking#ZINC#Kendall's Tau#0.810$Graph Ranking#ZINC#Kendall's Tau#0.803
2006.04159v2.pdf	Graph Embedding#Barabasi-Albert#Entropy Difference#0.0001261
2010.12121v2.pdf	Knowledge Graph Embedding#FB15k#MRR#0.815
1808.05689v4.pdf	Graph Similarity#IMDb#mse (10^-3)#1.264
2107.08562v3.pdf	Graph Clustering#Pubmed#NMI#33.4$Graph Clustering#Pubmed#ARI#37.9$Graph Clustering#Pubmed#ACC#74.0$Graph Clustering#Pubmed#NMI#34.4$Graph Clustering#Pubmed#ARI#34.6$Graph Clustering#Pubmed#ACC#71.4$Graph Clustering#Citeseer#ARI#47.1$Graph Clustering#Citeseer#NMI#45.0$Graph Clustering#Citeseer#ACC#70.5$Graph Clustering#Citeseer#ARI#43.9$Graph Clustering#Citeseer#NMI#42.0$Graph Clustering#Citeseer#ACC#68.9$Graph Clustering#Cora#ARI#57.9$Graph Clustering#Cora#NMI#57.3$Graph Clustering#Cora#ACC#76.7$Graph Clustering#Cora#ARI#54.1$Graph Clustering#Cora#NMI#56.0$Graph Clustering#Cora#ACC#73.7
1908.04003v1.pdf	Graph Clustering#Pubmed#NMI#34.6$Graph Clustering#Pubmed#ACC#73.6$Graph Clustering#Pubmed#NMI#35.5$Graph Clustering#Pubmed#ACC#72.6$Graph Clustering#Citeseer#NMI#35.4$Graph Clustering#Citeseer#ACC#61.6$Graph Clustering#Citeseer#NMI#33.8$Graph Clustering#Citeseer#ACC#61.3$Graph Clustering#Cora#NMI#45.5$Graph Clustering#Cora#ACC#68.5$Graph Clustering#Cora#NMI#48.1$Graph Clustering#Cora#ACC#66.9
1906.01210v1.pdf	Graph Clustering#Pubmed#NMI#31.59$Graph Clustering#Pubmed#ACC#69.78$Graph Clustering#Citeseer#NMI#41.13$Graph Clustering#Citeseer#ACC#67.0$Graph Clustering#Cora#NMI#53.68$Graph Clustering#Cora#ACC#68.92
1805.03064v3.pdf	Gaze Estimation#EYEDIAP (screen target)#Angular Error#3.38$Gaze Estimation#EYEDIAP (screen target)#Angular Error#3.4$Gaze Estimation#EYEDIAP (floating target)#Angular Error#5.19$Gaze Estimation#EYEDIAP (floating target)#Angular Error#5.43
1905.01941v2.pdf	Gaze Estimation#MPII Gaze#Angular Error#3.14
2203.03339v1.pdf	Gaze Estimation#MPII Gaze#Angular Error#3.92$Gaze Estimation#Gaze360#Angular Error#10.41
2105.09803v1.pdf	Gaze Estimation#Gaze360#Angular Error#12.94
1910.10088v1.pdf	Gaze Estimation#Gaze360#Angular Error#13.5
2007.15837v1.pdf	Gaze Estimation#MPSGaze#Angular Error#8.1
2012.03021v2.pdf	Disparity Estimation#Sintel 4D LFV - bamboo3#MSE*100#21.59$Disparity Estimation#Sintel 4D LFV - bamboo3#BadPix(0.07)#8.9475$Disparity Estimation#Sintel 4D LFV - bamboo3#BadPix(0.03)#21.8162$Disparity Estimation#Sintel 4D LFV - bamboo3#BadPix(0.01)#53.2985$Disparity Estimation#Sintel 4D LFV - thebigfight2#MSE*100#3.67$Disparity Estimation#Sintel 4D LFV - thebigfight2#BadPix(0.05)#1.0688$Disparity Estimation#Sintel 4D LFV - thebigfight2#BadPix(0.03)#3.6084$Disparity Estimation#Sintel 4D LFV - thebigfight2#BadPix(0.01)#17.7493$Disparity Estimation#Sintel 4D LFV - shaman2#MSE*100#2.4421$Disparity Estimation#Sintel 4D LFV - shaman2#BadPix(0.07)#32.7585$Disparity Estimation#Sintel 4D LFV - shaman2#BadPix(0.03)#50.6706$Disparity Estimation#Sintel 4D LFV - shaman2#BadPix(0.01)#74.7733$Disparity Estimation#Sintel 4D LFV - ambushfight5#MSE*100#21.67$Disparity Estimation#Sintel 4D LFV - ambushfight5#BadPix(0.07)#8.3404$Disparity Estimation#Sintel 4D LFV - ambushfight5#BadPix(0.03)#22.8762$Disparity Estimation#Sintel 4D LFV - ambushfight5#BadPix(0.01)#62.0493
2201.05222v2.pdf	Source Code Summarization#Hybrid-DeepCom-Java#METEOR#25.59%$Source Code Summarization#Hybrid-DeepCom-Java#BLEU-4#37.64$Source Code Summarization#DeepCom-Java#METEOR#28.25%$Source Code Summarization#DeepCom-Java#BLEU-4#45.35$Source Code Summarization#DeepCom-Java#METEOR#28.19%$Source Code Summarization#DeepCom-Java#BLEU-4#45.3$Source Code Summarization#CodeSearchNet - Python#METEOR#12.51%$Source Code Summarization#CodeSearchNet - Python#BLEU-4#16.46$Source Code Summarization#ParallelCorpus-Python#METEOR#21.92%$Source Code Summarization#ParallelCorpus-Python#BLEU-4#34.05$Source Code Summarization#ParallelCorpus-Python#METEOR#21.68%$Source Code Summarization#ParallelCorpus-Python#BLEU-4#33.85
2105.14220v1.pdf	Source Code Summarization#CoDesc#BLEU-4#45.89$Code Search#CoDesc#Test MRR#0.839$Code Search#CoDesc#Test MRR#0.812$Code Search#CoDesc#Test MRR#0.766
1805.07799v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#42.3$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#17.8$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#37.6
1804.07036v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#41.25$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#18.87$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#37.75
1808.07913v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#40.02$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#15.53$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#37.44$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.19$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.38$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.52
1711.09357v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#39.92$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#17.65$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#36.71
1705.04304v3.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#39.87$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#15.82$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#36.90$Document Summarization#CNN / Daily Mail#ROUGE-1#39.87$Document Summarization#CNN / Daily Mail#ROUGE-2#15.82$Document Summarization#CNN / Daily Mail#ROUGE-L#36.90$Document Summarization#CNN / Daily Mail#ROUGE-1#38.30$Document Summarization#CNN / Daily Mail#ROUGE-2#14.81$Document Summarization#CNN / Daily Mail#ROUGE-L#35.49
1805.11080v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#39.66$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#15.85$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#37.34$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.47$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.72$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.76$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.88$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.80$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.54
1611.04230v1.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#39.6$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#16.2$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#35.3$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#39.2$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#15.7$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#35.5
2108.09084v6.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#38.54$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#16.22$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#36.21$Text Summarization#Pubmed#ROUGE-1#38.09$Text Summarization#Pubmed#ROUGE-2#15.44$Text Summarization#Pubmed#ROUGE-L#34.81
1602.06023v5.pdf	Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-1#35.46$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-2#13.30$Text Summarization#CNN / Daily Mail (Anonymized)#ROUGE-L#32.65$Text Summarization#GigaWord#ROUGE-1#36.4$Text Summarization#GigaWord#ROUGE-2#17.7$Text Summarization#GigaWord#ROUGE-L#33.71$Text Summarization#DUC 2004 Task 1#ROUGE-1#28.61$Text Summarization#DUC 2004 Task 1#ROUGE-2#9.42$Text Summarization#DUC 2004 Task 1#ROUGE-L#25.24$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.42$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.62$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.67
2008.09676.pdf	Text Summarization#WikiHow#ROUGE-1#35.91$Text Summarization#WikiHow#ROUGE-2#13.9$Text Summarization#WikiHow#ROUGE-L#34.82$Text Summarization#WikiHow#Content F1#29.8$Text Summarization#How2#ROUGE-L#44.02$Text Summarization#How2#Content F1#36.4$Text Summarization#How2#ROUGE-1#48.26$Abstractive Text Summarization#WikiHow#ROUGE-1#35.91$Abstractive Text Summarization#WikiHow#ROUGE-L#34.82$Abstractive Text Summarization#WikiHow#ROUGE-2#13.9$Abstractive Text Summarization#WikiHow#Content F1#29.8
2004.08795v1.pdf	Text Summarization#WikiHow#ROUGE-1#31.85$Text Summarization#WikiHow#ROUGE-2#8.98$Text Summarization#WikiHow#ROUGE-L#29.58$Text Summarization#BBC XSum#ROUGE-1#24.86$Text Summarization#BBC XSum#ROUGE-2#4.66$Text Summarization#BBC XSum#ROUGE-L#18.41$Text Summarization#Reddit TIFU#ROUGE-1#25.09$Text Summarization#Reddit TIFU#ROUGE-2#6.17$Text Summarization#Reddit TIFU#ROUGE-L#20.13$Text Summarization#Pubmed#ROUGE-1#41.21$Text Summarization#Pubmed#ROUGE-2#14.91$Text Summarization#Pubmed#ROUGE-L#36.75$Document Summarization#CNN / Daily Mail#ROUGE-1#44.41$Document Summarization#CNN / Daily Mail#ROUGE-2#20.86$Document Summarization#CNN / Daily Mail#ROUGE-L#40.55$Document Summarization#CNN / Daily Mail#ROUGE-1#44.22$Document Summarization#CNN / Daily Mail#ROUGE-2#20.62$Document Summarization#CNN / Daily Mail#ROUGE-L#40.38$Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#20.86$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.41$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#40.55
1810.09305v1.pdf	Text Summarization#WikiHow#ROUGE-1#28.53$Text Summarization#WikiHow#ROUGE-2#9.23$Text Summarization#WikiHow#ROUGE-L#26.54
2205.12486v2.pdf	Text Summarization#GovReport#ROUGE-1#60.1$Text Summarization#GovReport#ROUGE-2#25.28$Text Summarization#GovReport#ROUGE-L#56.65$Text Summarization#arXiv#ROUGE-1#49.32$Text Summarization#arXiv#ROUGE-2#20.27$Text Summarization#arXiv#ROUGE-L#44.76$Text Summarization#Pubmed#ROUGE-1#47.5$Text Summarization#Pubmed#ROUGE-2#20.33$Text Summarization#Pubmed#ROUGE-L#43.76
2001.04063v3.pdf	Text Summarization#GigaWord#ROUGE-1#39.51$Text Summarization#GigaWord#ROUGE-2#20.42$Text Summarization#GigaWord#ROUGE-L#36.69$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.20$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.17$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.30$Question Generation#SQuAD1.1#BLEU-4#23.91
1912.08777v2.pdf	Text Summarization#GigaWord#ROUGE-1#39.12$Text Summarization#GigaWord#ROUGE-2#19.86$Text Summarization#GigaWord#ROUGE-L#36.24$Text Summarization#arXiv#ROUGE-1#44.67$Text Summarization#X-Sum#ROUGE-1#47.21$Text Summarization#X-Sum#ROUGE-2#24.56$Text Summarization#Pubmed#ROUGE-1#45.09$Abstractive Text Summarization#AESLC#ROUGE-1#37.68$Abstractive Text Summarization#AESLC#ROUGE-2#21.25$Abstractive Text Summarization#AESLC#ROUGE-L#36.51$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#44.17$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#21.47$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#41.11
1906.05012v1.pdf	Text Summarization#GigaWord#ROUGE-1#39.11$Text Summarization#GigaWord#ROUGE-2#19.78$Text Summarization#GigaWord#ROUGE-L#36.87
1911.10390v1.pdf	Text Summarization#GigaWord#ROUGE-1#39.08$Text Summarization#GigaWord#ROUGE-2#20.47$Text Summarization#GigaWord#ROUGE-L#36.69
1711.04434v1.pdf	Text Summarization#GigaWord#ROUGE-1#37.27$Text Summarization#GigaWord#ROUGE-2#17.65$Text Summarization#GigaWord#ROUGE-L#34.24
1806.05504v1.pdf	Text Summarization#GigaWord#ROUGE-1#37.04$Text Summarization#GigaWord#ROUGE-2#16.66$Text Summarization#GigaWord#ROUGE-L#34.93
1910.08486v1.pdf	Text Summarization#GigaWord#ROUGE-1#37.01$Text Summarization#GigaWord#ROUGE-2#17.10$Text Summarization#GigaWord#ROUGE-L#34.87
1805.03616v3.pdf	Text Summarization#GigaWord#ROUGE-1#36.92$Text Summarization#GigaWord#ROUGE-2#18.29$Text Summarization#GigaWord#ROUGE-L#34.58$Text Summarization#DUC 2004 Task 1#ROUGE-1#31.15$Text Summarization#DUC 2004 Task 1#ROUGE-2#10.85$Text Summarization#DUC 2004 Task 1#ROUGE-L#27.68
1911.10389v1.pdf	Text Summarization#GigaWord#ROUGE-1#36.61$Text Summarization#GigaWord#ROUGE-2#18.85$Text Summarization#GigaWord#ROUGE-L#34.33
1805.03989v2.pdf	Text Summarization#GigaWord#ROUGE-1#36.3$Text Summarization#GigaWord#ROUGE-2#18.0$Text Summarization#GigaWord#ROUGE-L#33.8
1701.00138v2.pdf	Text Summarization#GigaWord#ROUGE-1#36.30$Text Summarization#GigaWord#ROUGE-2#17.31$Text Summarization#GigaWord#ROUGE-L#33.88$Text Summarization#DUC 2004 Task 1#ROUGE-1#32.28$Text Summarization#DUC 2004 Task 1#ROUGE-2#10.54$Text Summarization#DUC 2004 Task 1#ROUGE-L#27.8
1708.00625v1.pdf	Text Summarization#GigaWord#ROUGE-1#36.27$Text Summarization#GigaWord#ROUGE-2#17.57$Text Summarization#GigaWord#ROUGE-L#33.62$Text Summarization#DUC 2004 Task 1#ROUGE-1#31.79$Text Summarization#DUC 2004 Task 1#ROUGE-2#10.75$Text Summarization#DUC 2004 Task 1#ROUGE-L#27.48
1704.07073v1.pdf	Text Summarization#GigaWord#ROUGE-1#36.15$Text Summarization#GigaWord#ROUGE-2#17.54$Text Summarization#GigaWord#ROUGE-L#33.63$Text Summarization#DUC 2004 Task 1#ROUGE-1#29.21$Text Summarization#DUC 2004 Task 1#ROUGE-2#9.56$Text Summarization#DUC 2004 Task 1#ROUGE-L#25.51
1805.11004v1.pdf	Text Summarization#GigaWord#ROUGE-1#35.98$Text Summarization#GigaWord#ROUGE-2#17.76$Text Summarization#GigaWord#ROUGE-L#33.63$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#39.81$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.64$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.54
1806.05658v2.pdf	Text Summarization#GigaWord#ROUGE-1#35.47$Text Summarization#GigaWord#ROUGE-2#17.66$Text Summarization#GigaWord#ROUGE-L#33.52
1509.00685v2.pdf	Text Summarization#GigaWord#ROUGE-1#31$Text Summarization#GigaWord#ROUGE-1#30.88$Text Summarization#DUC 2004 Task 1#ROUGE-1#28.18$Text Summarization#DUC 2004 Task 1#ROUGE-2#8.49$Text Summarization#DUC 2004 Task 1#ROUGE-L#23.81$Text Summarization#DUC 2004 Task 1#ROUGE-L#22.05$Extractive Text Summarization#DUC 2004 Task 1#ROUGE-1#26.55$Extractive Text Summarization#DUC 2004 Task 1#ROUGE-2#7.06$Extractive Text Summarization#DUC 2004 Task 1#ROUGE-L#22.05
1907.13337v1.pdf	Text Summarization#GigaWord#ROUGE-1#26.48$Text Summarization#GigaWord#ROUGE-2#10.05$Text Summarization#GigaWord#ROUGE-L#24.41
2206.00856v1.pdf	Text Summarization#MentSum#Rouge-1#29.13$Text Summarization#MentSum#Rouge-2#7.98$Text Summarization#MentSum#Rouge-L#20.27
2203.07586v1.pdf	Text Summarization#arXiv#ROUGE-1#50.95$Text Summarization#arXiv#ROUGE-2#21.93$Text Summarization#arXiv#ROUGE-L#45.61$Text Summarization#Pubmed#ROUGE-1#51.05$Text Summarization#Pubmed#ROUGE-2#23.26$Text Summarization#Pubmed#ROUGE-L#46.47$Text Summarization#BookSum#ROUGE#38.3
2107.08929v2.pdf	Text Summarization#arXiv#ROUGE-1#48.42$Text Summarization#arXiv#ROUGE-2#20.30$Text Summarization#arXiv#ROUGE-L#42.54$Text Summarization#Pubmed#ROUGE-1#49.25$Text Summarization#Pubmed#ROUGE-2#22.94$Text Summarization#Pubmed#ROUGE-L#44.42$Extractive Text Summarization#GovReport#Avg. Test Rouge1#59.43$Extractive Text Summarization#GovReport#Avg. Test Rouge2#28.60$Extractive Text Summarization#GovReport#Avg. Test RougeLsum#56.69
2203.09629v1.pdf	Text Summarization#arXiv#ROUGE-1#45.22$Text Summarization#arXiv#ROUGE-2#17.67$Text Summarization#arXiv#ROUGE-L#40.16$Text Summarization#Pubmed#ROUGE-1#46.59$Text Summarization#Pubmed#ROUGE-2#20.39$Text Summarization#Pubmed#ROUGE-L#42.11
2004.06190v3.pdf	Text Summarization#arXiv#ROUGE-1#45.01$Text Summarization#arXiv#ROUGE-2#17.6$Text Summarization#arXiv#ROUGE-L#40.56$Text Summarization#arXiv#ROUGE-1#42.7$Text Summarization#arXiv#ROUGE-2#16.54$Text Summarization#arXiv#ROUGE-L#38.44$Text Summarization#arXiv#ROUGE-1#41.87$Text Summarization#arXiv#ROUGE-2#15.92$Text Summarization#arXiv#ROUGE-L#37.61$Text Summarization#Pubmed#ROUGE-1#46.34$Text Summarization#Pubmed#ROUGE-2#19.97$Text Summarization#Pubmed#ROUGE-L#42.42$Text Summarization#Pubmed#ROUGE-1#44.09$Text Summarization#Pubmed#ROUGE-2#17.69$Text Summarization#Pubmed#ROUGE-L#40.27$Text Summarization#Pubmed#ROUGE-1#43.98$Text Summarization#Pubmed#ROUGE-2#17.65$Text Summarization#Pubmed#ROUGE-L#40.25
2012.00052v1.pdf	Text Summarization#arXiv#ROUGE-1#44.01$Text Summarization#arXiv#ROUGE-2#17.79$Text Summarization#arXiv#ROUGE-L#39.09$Text Summarization#arXiv#ROUGE-1#43.87$Text Summarization#arXiv#ROUGE-2#17.5$Text Summarization#arXiv#ROUGE-L#38.97$Text Summarization#Pubmed#ROUGE-1#45.39$Text Summarization#Pubmed#ROUGE-2#20.37$Text Summarization#Pubmed#ROUGE-L#40.99$Text Summarization#Pubmed#ROUGE-1#45.3$Text Summarization#Pubmed#ROUGE-2#20.42$Text Summarization#Pubmed#ROUGE-L#40.95
1909.08089v1.pdf	Text Summarization#arXiv#ROUGE-1#43.58$Text Summarization#arXiv#ROUGE-2#17.37$Text Summarization#Pubmed#ROUGE-1#44.81$Text Summarization#Pubmed#ROUGE-2#19.74
1909.03186v2.pdf	Text Summarization#arXiv#ROUGE-1#42.43$Text Summarization#arXiv#ROUGE-1#42.32$Text Summarization#arXiv#ROUGE-1#34.01$Text Summarization#Pubmed#ROUGE-1#45.01$Text Summarization#Pubmed#ROUGE-1#43.3$Text Summarization#Pubmed#ROUGE-1#41.43
1704.04368v2.pdf	Text Summarization#arXiv#ROUGE-1#32.06$Text Summarization#Pubmed#ROUGE-1#35.86$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#39.53$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.28$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.38$Document Summarization#CNN / Daily Mail#ROUGE-1#40.34$Document Summarization#CNN / Daily Mail#ROUGE-2#17.70$Document Summarization#CNN / Daily Mail#ROUGE-L#36.57$Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.70$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.34$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.57
1910.00523v2.pdf	Text Summarization#BillSum#rouge1#38.650
1909.01716v3.pdf	Text Summarization#CL-SciSumm#ROUGE-2#33.88$Scientific Document Summarization#CL-SciSumm#ROUGE-2#33.88
2010.12321v2.pdf	Text Summarization#OrangeSum#ROUGE-1#32.67$Text Summarization#OrangeSum#ROUGE-1#31.44
2006.11063v4.pdf	Text Summarization#Gazeta#ROUGE-1#32.1$Text Summarization#Gazeta#ROUGE-2#14.2$Text Summarization#Gazeta#ROUGE-L#27.9$Text Summarization#Gazeta#BLEU#12.4$Text Summarization#Gazeta#Meteor#25.7
2210.00045v1.pdf	Text Summarization#X-Sum#ROUGE-1#49.77$Text Summarization#X-Sum#ROUGE-2#27.09$Text Summarization#X-Sum#ROUGE-3#42.08$Text Summarization#Reddit TIFU#ROUGE-1#32.03$Text Summarization#Reddit TIFU#ROUGE-2#11.13$Text Summarization#Reddit TIFU#ROUGE-L#25.51$Text Summarization#SAMSum Corpus#ROUGE-1#54.37$Text Summarization#SAMSum Corpus#ROUGE-2#29.88$Text Summarization#SAMSum Corpus#ROUGE-L#45.89$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#47.97$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#24.18$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#44.88
2203.16804v1.pdf	Text Summarization#X-Sum#ROUGE-1#49.07$Text Summarization#X-Sum#ROUGE-2#25.59$Text Summarization#X-Sum#ROUGE-3#40.40$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#47.78$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#23.55$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#44.57
2203.06569v1.pdf	Text Summarization#X-Sum#ROUGE-1#48.12$Text Summarization#X-Sum#ROUGE-2#24.95$Text Summarization#X-Sum#ROUGE-L#40.00$Text Summarization#Reddit TIFU#ROUGE-1#29.83$Text Summarization#Reddit TIFU#ROUGE-2#9.5$Text Summarization#Reddit TIFU#ROUGE-L#23.47$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#47.16$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#22.61$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#43.87$Document Summarization#CNN / Daily Mail#ROUGE-1#47.16$Document Summarization#CNN / Daily Mail#ROUGE-2#22.55$Document Summarization#CNN / Daily Mail#ROUGE-L#43.87
2106.01890v1.pdf	Text Summarization#X-Sum#ROUGE-1#47.61$Text Summarization#X-Sum#ROUGE-2#24.57$Text Summarization#X-Sum#ROUGE-L#39.44$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#46.67$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#22.15$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#43.54
1908.08345v2.pdf	Text Summarization#X-Sum#ROUGE-1#38.81$Text Summarization#X-Sum#ROUGE-2#16.50$Text Summarization#X-Sum#ROUGE-3#31.27$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#42.13$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.6$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#39.18$Document Summarization#CNN / Daily Mail#ROUGE-1#43.85$Document Summarization#CNN / Daily Mail#ROUGE-2#20.34$Document Summarization#CNN / Daily Mail#ROUGE-L#39.9
1808.08745v1.pdf	Text Summarization#X-Sum#ROUGE-1#31.89$Text Summarization#X-Sum#ROUGE-2#11.54$Text Summarization#X-Sum#ROUGE-3#25.75$Text Summarization#X-Sum#ROUGE-1#29.79$Text Summarization#X-Sum#ROUGE-2#8.81$Text Summarization#X-Sum#ROUGE-3#22.66$Text Summarization#X-Sum#ROUGE-1#29.70$Text Summarization#X-Sum#ROUGE-2#9.21$Text Summarization#X-Sum#ROUGE-3#23.24$Text Summarization#X-Sum#ROUGE-1#28.42$Text Summarization#X-Sum#ROUGE-2#8.77$Text Summarization#X-Sum#ROUGE-3#22.48$Text Summarization#X-Sum#ROUGE-1#28.10$Text Summarization#X-Sum#ROUGE-2#8.02$Text Summarization#X-Sum#ROUGE-3#21.72$Text Summarization#X-Sum#ROUGE-1#16.30$Text Summarization#X-Sum#ROUGE-2#1.60$Text Summarization#X-Sum#ROUGE-3#11.95$Text Summarization#X-Sum#ROUGE-1#15.16$Text Summarization#X-Sum#ROUGE-2#1.78$Text Summarization#X-Sum#ROUGE-3#11.27
2201.07198v2.pdf	Text Summarization#Klexikon#ROUGE-1#32.00$Text Summarization#Klexikon#ROUGE-2#5.63$Text Summarization#Klexikon#ROUGE-L#11.68$Text Summarization#Klexikon#ROUGE-1#25.00$Text Summarization#Klexikon#ROUGE-2#5.16$Text Summarization#Klexikon#ROUGE-L#12.10$Text Summarization#Klexikon#ROUGE-1#17.50$Text Summarization#Klexikon#ROUGE-2#3.94$Text Summarization#Klexikon#ROUGE-L#9.99$Text Summarization#Klexikon#ROUGE-1#16.98$Text Summarization#Klexikon#ROUGE-2#4.30$Text Summarization#Klexikon#ROUGE-L#7.09
2009.05169v4.pdf	Text Summarization#arXiv Summarization Dataset#ROUGE-1#47.15$Text Summarization#arXiv Summarization Dataset#ROUGE-2#19.99$Text Summarization#arXiv Summarization Dataset#ROUGE-1#46.85$Text Summarization#arXiv Summarization Dataset#ROUGE-2#19.39$Text Summarization#Pubmed#ROUGE-1#47.81$Text Summarization#Pubmed#ROUGE-2#21.14
2208.09982v1.pdf	Text Summarization#Pubmed#ROUGE-1#48.20$Text Summarization#Pubmed#ROUGE-2#21.20$Text Summarization#Pubmed#ROUGE-L#43.16
2002.10782v2.pdf	Text Summarization#Webis-Snippet-20 Corpus#Rouge-1#25.7$Text Summarization#Webis-Snippet-20 Corpus#Rouge-2#5.2$Text Summarization#Webis-Snippet-20 Corpus#Rouge-L#20.1
2109.04994v1.pdf	Text Summarization#SAMSum Corpus#ROUGE-1#54.3$Text Summarization#SAMSum Corpus#ROUGE-2#29.3$Text Summarization#SAMSum Corpus#ROUGE-L#45.2$Text Summarization#SAMSum Corpus#BertScoreF1#54$Text Summarization#SAMSum Corpus#ROUGE-1#52.6$Text Summarization#SAMSum Corpus#ROUGE-2#27$Text Summarization#SAMSum Corpus#ROUGE-L#42.1$Text Summarization#SAMSum Corpus#BertScoreF1#52.1
1904.07418v1.pdf	Text Summarization#DUC 2004 Task 1#ROUGE-1#32.85$Text Summarization#DUC 2004 Task 1#ROUGE-2#11.78$Text Summarization#DUC 2004 Task 1#ROUGE-L#28.52
2004.12073v3.pdf	Text Summarization#DUC 2004 Task 1#ROUGE-1#32.57$Text Summarization#DUC 2004 Task 1#ROUGE-2#11.63$Text Summarization#DUC 2004 Task 1#ROUGE-L#28.24
1905.08836v1.pdf	Text Summarization#DUC 2004 Task 1#ROUGE-2#17.74
1906.07901v1.pdf	Text Summarization#How2#ROUGE-L#54.9$Text Summarization#How2#Content F1#48.9
2109.09701v3.pdf	Abstractive Text Summarization#vietnews#Rouge-L#40.15$Abstractive Text Summarization#vietnews#Rouge-1#61.14$Abstractive Text Summarization#vietnews#Rouge-2#30.31
1906.03497v1.pdf	Abstractive Text Summarization#AESLC#ROUGE-1#23.67$Abstractive Text Summarization#AESLC#ROUGE-2#10.29$Abstractive Text Summarization#AESLC#ROUGE-L#23.44
2002.12804v1.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#43.16$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#20.42$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#40.14$Question Generation#SQuAD1.1#BLEU-4#24.43
1909.08752v3.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.90$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.08$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#39.64$Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.87$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#42.76$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#39.11
1909.01953v1.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.72$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.74$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.79$Document Summarization#CNN / Daily Mail#ROUGE-1#41.72$Document Summarization#CNN / Daily Mail#ROUGE-2#18.74$Document Summarization#CNN / Daily Mail#ROUGE-L#38.79$Question Generation#SQuAD1.1#BLEU-4#15.874
1902.09243v2.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.71$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.49$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.79
1803.10357v3.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.69$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.47$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.92
1902.10360v1.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.42$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.03$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.36
1805.06266v2.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.68$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.97$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.13
1809.04585v1.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.66$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#17.87$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.06
1804.06451v2.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.43$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.00$Abstractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.10
2105.05361v1.pdf	Abstractive Text Summarization#CNN / Daily Mail#ROUGE-1#37.7
2010.08021v1.pdf	Multimodal Abstractive Text Summarization#How2 300h#ROUGE-L#43.23
1812.05407v1.pdf	Reader-Aware Summarization#RASG#ROUGE-1#30.33
2112.08709v2.pdf	Document Summarization#WikiLingua (tr->en)#Rouge-L#31.37
2110.03179v2.pdf	Document Summarization#HowSumm-Method#ROUGE-1#53.5$Document Summarization#HowSumm-Method#ROUGE-1#52.2$Document Summarization#HowSumm-Method#ROUGE-1#48.6$Document Summarization#HowSumm-Method#ROUGE-1#48.4$Document Summarization#HowSumm-Method#ROUGE-1#48.3$Document Summarization#HowSumm-Method#ROUGE-1#47.7$Document Summarization#HowSumm-Method#ROUGE-1#47.1$Document Summarization#HowSumm-Method#ROUGE-1#43.4$Document Summarization#HowSumm-Method#ROUGE-1#42.3$Document Summarization#HowSumm-Step#ROUGE-1#39.6$Document Summarization#HowSumm-Step#ROUGE-1#39.3$Document Summarization#HowSumm-Step#ROUGE-1#38.3$Document Summarization#HowSumm-Step#ROUGE-1#38.2$Document Summarization#HowSumm-Step#ROUGE-1#37.0$Document Summarization#HowSumm-Step#ROUGE-1#36.3$Document Summarization#HowSumm-Step#ROUGE-1#30.3$Document Summarization#HowSumm-Step#ROUGE-1#30.1$Document Summarization#HowSumm-Step#ROUGE-1#23.0$Document Summarization#HowSumm-Step#ROUGE-1#22.3$Document Summarization#HowSumm-Step#ROUGE-1#21.9
1903.10318v2.pdf	Document Summarization#CNN / Daily Mail#ROUGE-1#43.25$Document Summarization#CNN / Daily Mail#ROUGE-2#20.24$Document Summarization#CNN / Daily Mail#ROUGE-L#39.63
2107.14691v1.pdf	Email Thread Summarization#EmailSum (long)#ROUGE-1#44.08$Email Thread Summarization#EmailSum (long)#ROUGE-2#14.06$Email Thread Summarization#EmailSum (long)#ROUGE-L#31.17$Email Thread Summarization#EmailSum (long)#RLsum#40.67$Email Thread Summarization#EmailSum (long)#BertS#32.3$Email Thread Summarization#EmailSum (long)#ROUGE-1#43.81$Email Thread Summarization#EmailSum (long)#ROUGE-2#14.08$Email Thread Summarization#EmailSum (long)#ROUGE-L#30.47$Email Thread Summarization#EmailSum (long)#RLsum#39.88$Email Thread Summarization#EmailSum (long)#BertS#32.09$Email Thread Summarization#EmailSum (long)#ROUGE-1#45.98$Email Thread Summarization#EmailSum (long)#ROUGE-2#15.49$Email Thread Summarization#EmailSum (long)#ROUGE-L#32.4$Email Thread Summarization#EmailSum (long)#RLsum#42.14$Email Thread Summarization#EmailSum (long)#BertS#26.31$Email Thread Summarization#EmailSum (short)#ROUGE-1#36.98$Email Thread Summarization#EmailSum (short)#ROUGE-2#11.21$Email Thread Summarization#EmailSum (short)#ROUGE-L#28.76$Email Thread Summarization#EmailSum (short)#RLsum#33.7$Email Thread Summarization#EmailSum (short)#BertS#33.91$Email Thread Summarization#EmailSum (short)#ROUGE-1#36.57$Email Thread Summarization#EmailSum (short)#ROUGE-2#10.56$Email Thread Summarization#EmailSum (short)#ROUGE-L#28.3$Email Thread Summarization#EmailSum (short)#RLsum#32.76$Email Thread Summarization#EmailSum (short)#BertS#33.9$Email Thread Summarization#EmailSum (short)#ROUGE-1#39.04$Email Thread Summarization#EmailSum (short)#ROUGE-2#12.47$Email Thread Summarization#EmailSum (short)#ROUGE-L#30.17$Email Thread Summarization#EmailSum (short)#RLsum#35.61$Email Thread Summarization#EmailSum (short)#BertS#22.32
1812.01243v9.pdf	Extractive Text Summarization#GovReport#Avg. Test Rouge1#56.86$Extractive Text Summarization#GovReport#Avg. Test Rouge2#22.62$Extractive Text Summarization#GovReport#Avg. Test RougeLsum#53.82
1907.03491v1.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.60$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#42.69$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.85
1905.06566v1.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.95$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#42.37$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#38.83
1807.02305v1.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#19.01$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.59$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.98
1809.09672v3.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.7$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.5$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.6
1808.07187v2.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.77$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#41.05$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#37.54
1802.08636v2.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#18.2$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#40.0$Extractive Text Summarization#CNN / Daily Mail#ROUGE-L#36.6
1809.10324v2.pdf	Extractive Text Summarization#CNN / Daily Mail#ROUGE-2#12.6$Extractive Text Summarization#CNN / Daily Mail#ROUGE-1#30.80
2011.07251v1.pdf	Extractive Text Summarization#DebateSum#ROUGE-L#57.21$Extractive Text Summarization#DebateSum#ROUGE-L#53.23$Extractive Text Summarization#DebateSum#ROUGE-L#49.98
2210.09932v1.pdf	Lay Summarization#eLife#ROUGE-1#46.57$Lay Summarization#eLife#ROUGE-2#11.65$Lay Summarization#eLife#ROUGE-L#43.70$Lay Summarization#PLOS#ROUGE-1#42.35$Lay Summarization#PLOS#ROUGE-2#12.96$Lay Summarization#PLOS#ROUGE-L#38.57
2104.01371v3.pdf	Unsupervised Opinion Summarization#Yelp#ROUGE-1#35.37$Unsupervised Opinion Summarization#Yelp#ROUGE-2#7.35$Unsupervised Opinion Summarization#Yelp#ROUGE-L#19.94$Unsupervised Opinion Summarization#Yelp#ROUGE-1#33.68$Unsupervised Opinion Summarization#Yelp#ROUGE-2#7$Unsupervised Opinion Summarization#Yelp#ROUGE-L#18.95$Unsupervised Opinion Summarization#Yelp#ROUGE-1#32.87$Unsupervised Opinion Summarization#Yelp#ROUGE-2#6.93$Unsupervised Opinion Summarization#Yelp#ROUGE-L#19.89$Unsupervised Opinion Summarization#Yelp#ROUGE-1#31.23$Unsupervised Opinion Summarization#Yelp#ROUGE-2#6.48$Unsupervised Opinion Summarization#Yelp#ROUGE-L#18.27$Unsupervised Opinion Summarization#Amazon#ROUGE-1#36.57$Unsupervised Opinion Summarization#Amazon#ROUGE-2#7.23$Unsupervised Opinion Summarization#Amazon#ROUGE-L#21.24$Unsupervised Opinion Summarization#Amazon#ROUGE-1#35.32$Unsupervised Opinion Summarization#Amazon#ROUGE-2#6.22$Unsupervised Opinion Summarization#Amazon#ROUGE-L#19.84$Unsupervised Opinion Summarization#Amazon#ROUGE-1#33.6$Unsupervised Opinion Summarization#Amazon#ROUGE-2#6.64$Unsupervised Opinion Summarization#Amazon#ROUGE-L#20.87$Unsupervised Opinion Summarization#Amazon#ROUGE-1#33.54$Unsupervised Opinion Summarization#Amazon#ROUGE-2#6.18$Unsupervised Opinion Summarization#Amazon#ROUGE-L#19.34
1801.07704v2.pdf	Query-Based Extractive Summarization#Debatepedia#ROUGE-1#53.09
1704.08300v2.pdf	Query-Based Extractive Summarization#Debatepedia#ROUGE-1#41.26
1907.05193v2.pdf	Human Part Segmentation#PASCAL-Part#mIoU#72.82$Human Part Segmentation#PASCAL-Part#mIoU#65.02
1805.04310v1.pdf	Human Part Segmentation#PASCAL-Part#mIoU#67.60
1708.03383v1.pdf	Human Part Segmentation#PASCAL-Part#mIoU#64.39$Human Part Segmentation#PASCAL-Part#mIoU#58.06
1511.06881v5.pdf	Human Part Segmentation#PASCAL-Part#mIoU#57.54
1808.00157v1.pdf	Human Part Segmentation#CIHP#Mean IoU#55.8
2102.04432v2.pdf	Colorization#ImageNet val#FID-5K#19.37
1705.07208v2.pdf	Colorization#ImageNet val#FID-5K#24.32
2207.06831v4.pdf	Point-interactive Image Colorization#CUB-200-2011#PSNR@1#27.986$Point-interactive Image Colorization#CUB-200-2011#PSNR@10#30.595$Point-interactive Image Colorization#CUB-200-2011#PSNR@100#33.543$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@1#22.925$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@10#27.37$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@100#30.731$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@10#30.626$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@1#27.474$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@100#33.787
2005.10825v1.pdf	Point-interactive Image Colorization#CUB-200-2011#PSNR@1#27.69$Point-interactive Image Colorization#CUB-200-2011#PSNR@10#29.45$Point-interactive Image Colorization#CUB-200-2011#PSNR@100#31.45$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@1#22.97$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@10#25.130$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@100#27.35$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@10#29.108$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@1#27.275$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@100#31.37
1705.02999v1.pdf	Point-interactive Image Colorization#CUB-200-2011#PSNR@1#27.45$Point-interactive Image Colorization#CUB-200-2011#PSNR@10#29.32$Point-interactive Image Colorization#CUB-200-2011#PSNR@100#31.57$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@1#22.72$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@10#25.13$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@100#27.826$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@10#29.009$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@1#26.937$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@100#31.58
1905.07177v1.pdf	Point-interactive Image Colorization#CUB-200-2011#PSNR@1#23.547$Point-interactive Image Colorization#CUB-200-2011#PSNR@10#25.097$Point-interactive Image Colorization#CUB-200-2011#PSNR@100#27.623$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@1#18.452$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@10#19.445$Point-interactive Image Colorization#Oxford 102 Flowers#PSNR@100#22.362$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@10#24.232$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@1#23.119$Point-interactive Image Colorization#ImageNet ctest10k#PSNR@100#27.099
2202.13084v2.pdf	Lipreading#CMLR#CER#9.1%$Lipreading#LRS3-TED#Word Error Rate (WER)#31.5$Lipreading#LRS2#Word Error Rate (WER)#25.5%$Lipreading#LRS2#Word Error Rate (WER)#32.9%$Lipreading#GRID corpus (mixed-speech)#Word Error Rate (WER)#1.2
1911.11502v1.pdf	Lipreading#CMLR#CER#31.27%$Lipreading#LRS2#Word Error Rate (WER)#65.29%
1908.04917v2.pdf	Lipreading#CMLR#CER#32.48%$Lipreading#CMLR#CER#34.07%$Lipreading#CMLR#CER#38.93%
2011.07557v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#55.7%$Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#48.3%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#88.4$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#85.5
2204.01725v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#53.8$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#88.5$Lipreading#LRS2#Word Error Rate (WER)#44.5%
2204.01265v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#50.82%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#85.4
2003.03206v2.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#45.24%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#85.02$Lipreading#GRID corpus (mixed-speech)#Word Error Rate (WER)#2.9
2003.05709v2.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#41.93%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#84.13
2001.08702v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#41.4%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#85.30
2003.06439v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#38.79%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#84.41
2003.03983v1.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#38.7%$Lipreading#Lip Reading in the Wild#Top-1 Accuracy#83.5
1810.06990v6.pdf	Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#38.19%$Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#34.76%$Lipreading#CAS-VSR-W1k (LRW-1000)#Top-1 Accuracy#25.76%
2201.02184v2.pdf	Lipreading#LRS3-TED#Word Error Rate (WER)#26.9
1807.05162v3.pdf	Lipreading#LRS3-TED#Word Error Rate (WER)#55.1
1911.12747v2.pdf	Lipreading#LRS3-TED#Word Error Rate (WER)#59.8$Lipreading#LRS2#Word Error Rate (WER)#53.2%
2209.01383v3.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#94.1
2007.06504v3.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#88.5
2005.10903v1.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#84.4
1802.06424v2.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#83.39
1908.11618v2.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#83.34
1703.04105v4.pdf	Lipreading#Lip Reading in the Wild#Top-1 Accuracy#83.00
1803.04988v1.pdf	Lipreading#GRID corpus (mixed-speech)#Word Error Rate (WER)#2.9
1611.05358v2.pdf	Lipreading#GRID corpus (mixed-speech)#Word Error Rate (WER)#3
1611.01599v2.pdf	Lipreading#GRID corpus (mixed-speech)#Word Error Rate (WER)#4.6
2106.06232v6.pdf	Atari Games#Atari 2600 Tennis#Score#24$Atari Games#Atari 2600 Double Dunk#Score#24$Atari Games#Atari 2600 Phoenix#Score#894460$Atari Games#Atari 2600 Montezuma's Revenge#Score#3000$Atari Games#Atari 2600 Demon Attack#Score#675530$Atari Games#Atari 2600 Krull#Score#97575$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Gravitar#Score#5905$Atari Games#Atari 2600 Kangaroo#Score#14500$Atari Games#Atari 2600 Ice Hockey#Score#44.94$Atari Games#Atari 2600 Surround#Score#-7.8$Atari Games#Atari 2600 Private Eye#Score#15100$Atari Games#Atari 2600 Beam Rider#Score#162100$Atari Games#Atari 2600 Q*Bert#Score#27800$Atari Games#Atari 2600 Star Gunner#Score#465750$Atari Games#Atari 2600 Solaris#Score#11074$Atari Games#Atari 2600 Tutankham#Score#423.9$Atari Games#Atari 2600 Defender#Score#893110$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#201.9$Atari Games#Atari 2600 Berzerk#Score#7607$Atari Games#Atari 2600 Enduro#Score#14330$Atari Games#Atari 2600 Fishing Derby#Score#59$Atari Games#Atari 2600 Ms. Pacman#Score#11536$Atari Games#Atari 2600 Robotank#Score#108.2$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Chopper Command#Score#999999$Atari Games#Atari 2600 Crazy Climber#Score#201000$Atari Games#Atari 2600 Name This Game#Score#34434$Atari Games#Atari 2600 Centipede#Score#155830$Atari Games#Atari 2600 Skiing#Score#-6774$Atari Games#Atari 2600 Seaquest#Score#943910$Atari Games#Atari 2600 Frostbite#Score#10485$Atari Games#Atari 2600 Up and Down#Score#986440$Atari Games#Atari 2600 Space Invaders#Score#140460$Atari Games#Atari 2600 James Bond#Score#594500$Atari Games#Atari 2600 Road Runner#Score#878600$Atari Games#Atari 2600 HERO#Score#38330$Atari Games#Atari 2600 Time Pilot#Score#216770
2206.03192v4.pdf	Atari Games#Atari 2600 Tennis#Score#24$Atari Games#Atari 2600 Double Dunk#Score#24$Atari Games#Atari games#Mean Human Normalized Score#9620.33%$Atari Games#Atari games#Medium Human-Normalized Score#1146.39%$Atari Games#Atari games#Mean Human Normalized Score#7810.1%$Atari Games#Atari games#Medium Human-Normalized Score#832.5%$Atari Games#Atari 2600 Phoenix#Score#959580$Atari Games#Atari 2600 Phoenix#Score#894460$Atari Games#Atari 2600 Yars Revenge#Score#972000$Atari Games#Atari 2600 Yars Revenge#Score#968090$Atari Games#Atari 2600 Montezuma's Revenge#Score#3000$Atari Games#Atari 2600 Montezuma's Revenge#Score#2500$Atari Games#Atari 2600 Demon Attack#Score#787985$Atari Games#Atari 2600 Demon Attack#Score#675530$Atari Games#Atari 2600 Krull#Score#594540$Atari Games#Atari 2600 Krull#Score#97575$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Zaxxon#Score#216020$Atari Games#Atari 2600 Zaxxon#Score#109140$Atari Games#Atari 2600 Gravitar#Score#5915$Atari Games#Atari 2600 Gravitar#Score#5905$Atari Games#Atari 2600 Kangaroo#Score#14636$Atari Games#Atari 2600 Kangaroo#Score#14500$Atari Games#Atari 2600 Kung-Fu Master#Score#1666665$Atari Games#Atari 2600 Kung-Fu Master#Score#140440$Atari Games#Atari 2600 Ice Hockey#Score#481.9$Atari Games#Atari 2600 Ice Hockey#Score#44.94$Atari Games#Atari 2600 Surround#Score#2.606$Atari Games#Atari 2600 Surround#Score#-7.8$Atari Games#Atari 2600 Private Eye#Score#15100$Atari Games#Atari 2600 Beam Rider#Score#422890$Atari Games#Atari 2600 Beam Rider#Score#162100$Atari Games#Atari 2600 Breakout#Score#864.00$Atari Games#Atari 2600 Breakout#Score#864$Atari Games#atari game#Human World Record Breakthrough#22$Atari Games#atari game#Human World Record Breakthrough#17$Atari Games#Atari 2600 Q*Bert#Score#28657$Atari Games#Atari 2600 Q*Bert#Score#27800$Atari Games#Atari 2600 Wizard of Wor#Score#64239$Atari Games#Atari 2600 Wizard of Wor#Score#63735$Atari Games#Atari 2600 Star Gunner#Score#677590$Atari Games#Atari 2600 Star Gunner#Score#465750$Atari Games#Atari 2600 Solaris#Score#11074$Atari Games#Atari 2600 Solaris#Score#9105$Atari Games#Atari 2600 Assault#Score#97155$Atari Games#Atari 2600 Assault#Score#63876$Atari Games#Atari 2600 Tutankham#Score#423.9$Atari Games#Atari 2600 Tutankham#Score#418.2$Atari Games#Atari 2600 Defender#Score#970540$Atari Games#Atari 2600 Defender#Score#893110$Atari Games#Atari 2600 River Raid#Score#28349$Atari Games#Atari 2600 River Raid#Score#28075$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Pitfall!#Score#-4.345$Atari Games#Atari 2600 Bowling#Score#205.2$Atari Games#Atari 2600 Bowling#Score#201.9$Atari Games#Atari 2600 Berzerk#Score#14649$Atari Games#Atari 2600 Berzerk#Score#7607$Atari Games#Atari 2600 Gopher#Score#488830$Atari Games#Atari 2600 Gopher#Score#473560$Atari Games#Atari-57#Medium Human-Normalized Score#1146.39$Atari Games#Atari-57#Human World Record Breakthrough#22$Atari Games#Atari-57#Mean Human Normalized Score#9620.33%$Atari Games#Atari-57#Medium Human-Normalized Score#832.5$Atari Games#Atari-57#Human World Record Breakthrough#17$Atari Games#Atari-57#Mean Human Normalized Score#7810.1%$Atari Games#Atari 2600 Asterix#Score#999999$Atari Games#Atari 2600 Asterix#Score#759910$Atari Games#Atari 2600 Enduro#Score#14330$Atari Games#Atari 2600 Enduro#Score#14300$Atari Games#Atari 2600 Fishing Derby#Score#65$Atari Games#Atari 2600 Fishing Derby#Score#59$Atari Games#Atari 2600 Ms. Pacman#Score#11573$Atari Games#Atari 2600 Ms. Pacman#Score#11536$Atari Games#Atari 2600 Robotank#Score#113.4$Atari Games#Atari 2600 Robotank#Score#108.2$Atari Games#Atari 2600 Alien#Score#48735$Atari Games#Atari 2600 Alien#Score#43384$Atari Games#Atari 2600 Video Pinball#Score#978190$Atari Games#Atari 2600 Video Pinball#Score#925830$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Battle Zone#Score#824360$Atari Games#Atari 2600 Battle Zone#Score#478830$Atari Games#Atari 2600 Chopper Command#Score#999999$Atari Games#Atari 2600 Crazy Climber#Score#241170$Atari Games#Atari 2600 Crazy Climber#Score#201000$Atari Games#Atari 2600 Name This Game#Score#36296$Atari Games#Atari 2600 Name This Game#Score#34434$Atari Games#Atari 2600 Centipede#Score#195630$Atari Games#Atari 2600 Centipede#Score#155830$Atari Games#Atari 2600 Skiing#Score#-6774$Atari Games#Atari 2600 Skiing#Score#-6025$Atari Games#Atari 2600 Seaquest#Score#1000000$Atari Games#Atari 2600 Seaquest#Score#943910$Atari Games#Atari 2600 Frostbite#Score#11330$Atari Games#Atari 2600 Frostbite#Score#10485$Atari Games#Atari 2600 Up and Down#Score#986440$Atari Games#Atari 2600 Up and Down#Score#966590$Atari Games#Atari 2600 Bank Heist#Score#1401$Atari Games#Atari 2600 Bank Heist#Score#1380$Atari Games#Atari 2600 Venture#Score#2035$Atari Games#Atari 2600 Venture#Score#2000$Atari Games#Atari 2600 Space Invaders#Score#154380$Atari Games#Atari 2600 Space Invaders#Score#140460$Atari Games#Atari 2600 James Bond#Score#620780$Atari Games#Atari 2600 James Bond#Score#594500$Atari Games#Atari 2600 Road Runner#Score#999999$Atari Games#Atari 2600 Road Runner#Score#878600$Atari Games#Atari 2600 HERO#Score#38330$Atari Games#Atari 2600 HERO#Score#38225$Atari Games#Atari 2600 Amidar#Score#1442$Atari Games#Atari 2600 Amidar#Score#1065$Atari Games#Atari 2600 Asteroids#Score#760005$Atari Games#Atari 2600 Asteroids#Score#751970$Atari Games#Atari 2600 Atlantis#Score#3837300$Atari Games#Atari 2600 Atlantis#Score#3803000$Atari Games#Atari 2600 Pong#Score#21.0$Atari Games#Atari 2600 Pong#Score#21$Atari Games#Atari 2600 Time Pilot#Score#450810$Atari Games#Atari 2600 Time Pilot#Score#216770
1803.00933v1.pdf	Atari Games#Atari 2600 Tennis#Score#23.9$Atari Games#Atari 2600 Double Dunk#Score#23.5$Atari Games#Atari 2600 Phoenix#Score#224491.1$Atari Games#Atari 2600 Yars Revenge#Score#148594.8$Atari Games#Atari 2600 Montezuma's Revenge#Score#2500.0$Atari Games#Atari 2600 Demon Attack#Score#133086.4$Atari Games#Atari 2600 Krull#Score#11741.4$Atari Games#Atari 2600 Freeway#Score#33.7$Atari Games#Atari 2600 Zaxxon#Score#42285.5$Atari Games#Atari 2600 Gravitar#Score#1598.5$Atari Games#Atari 2600 Kangaroo#Score#1416$Atari Games#Atari 2600 Kung-Fu Master#Score#97829.5$Atari Games#Atari 2600 Ice Hockey#Score#33$Atari Games#Atari 2600 Surround#Score#7.1$Atari Games#Atari 2600 Private Eye#Score#49.8$Atari Games#Atari 2600 Beam Rider#Score#63305.2$Atari Games#Atari 2600 Breakout#Score#800.9$Atari Games#Atari 2600 Q*Bert#Score#302391.3$Atari Games#Atari 2600 Wizard of Wor#Score#46204$Atari Games#Atari 2600 Star Gunner#Score#434342.5$Atari Games#Atari 2600 Solaris#Score#2892.9$Atari Games#Atari 2600 Assault#Score#24559.4$Atari Games#Atari 2600 Tutankham#Score#272.6$Atari Games#Atari 2600 Defender#Score#411943.5$Atari Games#Atari 2600 River Raid#Score#63864.4$Atari Games#Atari 2600 Pitfall!#Score#-0.6$Atari Games#Atari 2600 Bowling#Score#17.6$Atari Games#Atari 2600 Berzerk#Score#57196.7$Atari Games#Atari 2600 Gopher#Score#120500.9$Atari Games#Atari-57#Medium Human-Normalized Score#434.1%$Atari Games#Atari 2600 Asterix#Score#313305$Atari Games#Atari 2600 Enduro#Score#2177.4$Atari Games#Atari 2600 Fishing Derby#Score#44.4$Atari Games#Atari 2600 Ms. Pacman#Score#11255.2$Atari Games#Atari 2600 Robotank#Score#73.8$Atari Games#Atari 2600 Alien#Score#40804.9$Atari Games#Atari 2600 Video Pinball#Score#565163.2$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Battle Zone#Score#98895$Atari Games#Atari 2600 Chopper Command#Score#721851$Atari Games#Atari 2600 Crazy Climber#Score#320426$Atari Games#Atari 2600 Name This Game#Score#25783.3$Atari Games#Atari 2600 Centipede#Score#12974$Atari Games#Atari 2600 Skiing#Score#-10789.9$Atari Games#Atari 2600 Seaquest#Score#392952.3$Atari Games#Atari 2600 Frostbite#Score#9328.6$Atari Games#Atari 2600 Up and Down#Score#401884.3$Atari Games#Atari 2600 Bank Heist#Score#1716.4$Atari Games#Atari 2600 Venture#Score#1813$Atari Games#Atari 2600 Space Invaders#Score#54681$Atari Games#Atari 2600 James Bond#Score#21322.5$Atari Games#Atari 2600 Road Runner#Score#222234.5$Atari Games#Atari 2600 HERO#Score#31655.9$Atari Games#Atari 2600 Amidar#Score#8659.2$Atari Games#Atari 2600 Asteroids#Score#155495.1$Atari Games#Atari 2600 Atlantis#Score#944497.5$Atari Games#Atari 2600 Pong#Score#20.9$Atari Games#Atari 2600 Time Pilot#Score#87085
2003.13350v1.pdf	Atari Games#Atari 2600 Tennis#Score#23.84$Atari Games#Atari 2600 Double Dunk#Score#23.93$Atari Games#Atari games#Mean Human Normalized Score#4763.69%$Atari Games#Atari 2600 Phoenix#Score#908264.15$Atari Games#Atari 2600 Yars Revenge#Score#998532.37$Atari Games#Atari 2600 Montezuma's Revenge#Score#9352.01$Atari Games#Atari 2600 Demon Attack#Score#143161.44$Atari Games#Atari 2600 Krull#Score#251997.31$Atari Games#Atari 2600 Freeway#Score#32.59$Atari Games#Atari 2600 Zaxxon#Score#249808.9$Atari Games#Atari 2600 Gravitar#Score#19213.96$Atari Games#Atari 2600 Kangaroo#Score#24034.16$Atari Games#Atari 2600 Kung-Fu Master#Score#206845.82$Atari Games#Atari 2600 Ice Hockey#Score#63.64$Atari Games#Atari 2600 Surround#Score#9.5$Atari Games#Atari 2600 Private Eye#Score#79716.46$Atari Games#Atari 2600 Beam Rider#Score#300509.8$Atari Games#Atari 2600 Breakout#Score#790.4$Atari Games#atari game#Human World Record Breakthrough#18$Atari Games#Atari 2600 Q*Bert#Score#580328.14$Atari Games#Atari 2600 Wizard of Wor#Score#157306.41$Atari Games#Atari 2600 Star Gunner#Score#839573.53$Atari Games#Atari 2600 Solaris#Score#44199.93$Atari Games#Atari 2600 Assault#Score#67212.67$Atari Games#Atari 2600 Tutankham#Score#2354.91$Atari Games#Atari 2600 Defender#Score#677642.78$Atari Games#Atari 2600 River Raid#Score#63318.67$Atari Games#Atari 2600 Pitfall!#Score#18756.01$Atari Games#Atari 2600 Bowling#Score#251.18$Atari Games#Atari 2600 Berzerk#Score#61507.83$Atari Games#Atari 2600 Gopher#Score#117777.08$Atari Games#Atari 2600 Asterix#Score#991384.42$Atari Games#Atari 2600 Enduro#Score#2367.71$Atari Games#Atari 2600 Fishing Derby#Score#86.97$Atari Games#Atari 2600 Ms. Pacman#Score#63994.44$Atari Games#Atari 2600 Robotank#Score#127.32$Atari Games#Atari 2600 Alien#Score#297638.17$Atari Games#Atari 2600 Video Pinball#Score#992340.74$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Battle Zone#Score#934134.88$Atari Games#Atari 2600 Chopper Command#Score#999900$Atari Games#Atari 2600 Crazy Climber#Score#565909.85$Atari Games#Atari 2600 Name This Game#Score#54386.77$Atari Games#Atari 2600 Centipede#Score#412847.86$Atari Games#Atari 2600 Skiing#Score#-4202.6$Atari Games#Atari 2600 Seaquest#Score#999997.63$Atari Games#Atari 2600 Frostbite#Score#541280.88$Atari Games#Atari 2600 Up and Down#Score#623805.73$Atari Games#Atari 2600 Bank Heist#Score#23071.5$Atari Games#Atari 2600 Venture#Score#2623.71$Atari Games#Atari 2600 Space Invaders#Score#48680.86$Atari Games#Atari 2600 James Bond#Score#135784.96$Atari Games#Atari 2600 Road Runner#Score#243025.8$Atari Games#Atari 2600 HERO#Score#114736.26$Atari Games#Atari 2600 Amidar#Score#29660.08$Atari Games#Atari 2600 Asteroids#Score#150854.61$Atari Games#Atari 2600 Atlantis#Score#1528841.76$Atari Games#Atari 2600 Pong#Score#20.67$Atari Games#Atari 2600 Time Pilot#Score#405425.31
1806.06923v1.pdf	Atari Games#Atari 2600 Tennis#Score#23.6$Atari Games#Atari 2600 Double Dunk#Score#5.6$Atari Games#Atari 2600 Phoenix#Score#56599$Atari Games#Atari 2600 Yars Revenge#Score#28379$Atari Games#Atari 2600 Montezuma's Revenge#Score#0$Atari Games#Atari 2600 Demon Attack#Score#128580$Atari Games#Atari 2600 Krull#Score#10707$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Zaxxon#Score#21772$Atari Games#Atari 2600 Gravitar#Score#911$Atari Games#Atari 2600 Kangaroo#Score#15487$Atari Games#Atari 2600 Kung-Fu Master#Score#73512$Atari Games#Atari 2600 Ice Hockey#Score#0.2$Atari Games#Atari 2600 Surround#Score#9.4$Atari Games#Atari 2600 Private Eye#Score#200$Atari Games#Atari 2600 Beam Rider#Score#42776$Atari Games#Atari 2600 Breakout#Score#734$Atari Games#Atari 2600 Q*Bert#Score#25750$Atari Games#Atari 2600 Wizard of Wor#Score#31190$Atari Games#Atari 2600 Star Gunner#Score#74677$Atari Games#Atari 2600 Solaris#Score#8007$Atari Games#Atari 2600 Assault#Score#29091$Atari Games#Atari 2600 Tutankham#Score#293$Atari Games#Atari 2600 Defender#Score#53537$Atari Games#Atari 2600 River Raid#Score#17765$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#86.5$Atari Games#Atari 2600 Berzerk#Score#1053$Atari Games#Atari 2600 Gopher#Score#118365$Atari Games#Atari 2600 Asterix#Score#342016$Atari Games#Atari 2600 Enduro#Score#2359$Atari Games#Atari 2600 Fishing Derby#Score#33.8$Atari Games#Atari 2600 Ms. Pacman#Score#6349$Atari Games#Atari 2600 Robotank#Score#62.5$Atari Games#Atari 2600 Alien#Score#7022$Atari Games#Atari 2600 Video Pinball#Score#698045$Atari Games#Atari 2600 Boxing#Score#99.8$Atari Games#Atari 2600 Battle Zone#Score#42244$Atari Games#Atari 2600 Chopper Command#Score#16836$Atari Games#Atari 2600 Crazy Climber#Score#179082$Atari Games#Atari 2600 Name This Game#Score#22682$Atari Games#Atari 2600 Centipede#Score#11561$Atari Games#Atari 2600 Skiing#Score#-9289$Atari Games#Atari 2600 Seaquest#Score#30140$Atari Games#Atari 2600 Frostbite#Score#4324$Atari Games#Atari 2600 Up and Down#Score#88148$Atari Games#Atari 2600 Bank Heist#Score#1416$Atari Games#Atari 2600 Venture#Score#1318$Atari Games#Atari 2600 Space Invaders#Score#28888$Atari Games#Atari 2600 James Bond#Score#35108$Atari Games#Atari 2600 Road Runner#Score#57900$Atari Games#Atari 2600 HERO#Score#28386$Atari Games#Atari 2600 Amidar#Score#2946$Atari Games#Atari 2600 Asteroids#Score#2898$Atari Games#Atari 2600 Atlantis#Score#978200$Atari Games#Atari 2600 Pong#Score#21$Atari Games#Atari 2600 Time Pilot#Score#12236
1710.10044v1.pdf	Atari Games#Atari 2600 Tennis#Score#23.6$Atari Games#Atari 2600 Double Dunk#Score#21.9$Atari Games#Atari 2600 Phoenix#Score#16585$Atari Games#Atari 2600 Yars Revenge#Score#26447$Atari Games#Atari 2600 Montezuma's Revenge#Score#0$Atari Games#Atari 2600 Demon Attack#Score#121551$Atari Games#Atari 2600 Krull#Score#11447$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Zaxxon#Score#13112$Atari Games#Atari 2600 Gravitar#Score#995$Atari Games#Atari 2600 Kangaroo#Score#15356$Atari Games#Atari 2600 Kung-Fu Master#Score#76642$Atari Games#Atari 2600 Ice Hockey#Score#-1.7$Atari Games#Atari 2600 Surround#Score#8.2$Atari Games#Atari 2600 Private Eye#Score#350$Atari Games#Atari 2600 Beam Rider#Score#34821$Atari Games#Atari 2600 Breakout#Score#742$Atari Games#Atari 2600 Q*Bert#Score#572510$Atari Games#Atari 2600 Wizard of Wor#Score#25061$Atari Games#Atari 2600 Star Gunner#Score#77495$Atari Games#Atari 2600 Solaris#Score#6740$Atari Games#Atari 2600 Assault#Score#22012$Atari Games#Atari 2600 Tutankham#Score#297$Atari Games#Atari 2600 Defender#Score#47887$Atari Games#Atari 2600 River Raid#Score#17571$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#77.2$Atari Games#Atari 2600 Berzerk#Score#3117$Atari Games#Atari 2600 Gopher#Score#113585$Atari Games#Atari-57#Medium Human-Normalized Score#211%$Atari Games#Atari 2600 Asterix#Score#261025$Atari Games#Atari 2600 Enduro#Score#2355$Atari Games#Atari 2600 Fishing Derby#Score#39$Atari Games#Atari 2600 Ms. Pacman#Score#5821$Atari Games#Atari 2600 Robotank#Score#59.4$Atari Games#Atari 2600 Alien#Score#4871$Atari Games#Atari 2600 Video Pinball#Score#705662$Atari Games#Atari 2600 Boxing#Score#99.9$Atari Games#Atari 2600 Battle Zone#Score#39268$Atari Games#Atari 2600 Chopper Command#Score#14667$Atari Games#Atari 2600 Crazy Climber#Score#161196$Atari Games#Atari 2600 Name This Game#Score#21890$Atari Games#Atari 2600 Centipede#Score#12447$Atari Games#Atari 2600 Skiing#Score#-9324$Atari Games#Atari 2600 Seaquest#Score#8268$Atari Games#Atari 2600 Frostbite#Score#4384$Atari Games#Atari 2600 Up and Down#Score#71260$Atari Games#Atari 2600 Bank Heist#Score#1249$Atari Games#Atari 2600 Venture#Score#43.9$Atari Games#Atari 2600 Space Invaders#Score#20972$Atari Games#Atari 2600 James Bond#Score#4703$Atari Games#Atari 2600 Road Runner#Score#64262$Atari Games#Atari 2600 HERO#Score#21395$Atari Games#Atari 2600 Amidar#Score#1641$Atari Games#Atari 2600 Asteroids#Score#4226$Atari Games#Atari 2600 Atlantis#Score#971850$Atari Games#Atari 2600 Pong#Score#21$Atari Games#Atari 2600 Time Pilot#Score#10345
1707.06887v1.pdf	Atari Games#Atari 2600 Tennis#Score#23.1$Atari Games#Atari 2600 Double Dunk#Score#2.5$Atari Games#Atari 2600 Demon Attack#Score#130955.0$Atari Games#Atari 2600 Krull#Score#9735.0$Atari Games#Atari 2600 Freeway#Score#33.9$Atari Games#Atari 2600 Zaxxon#Score#10513.0$Atari Games#Atari 2600 Gravitar#Score#440.0$Atari Games#Atari 2600 Kangaroo#Score#12853.0$Atari Games#Atari 2600 Kung-Fu Master#Score#48192.0$Atari Games#Atari 2600 Ice Hockey#Score#-3.5$Atari Games#Atari 2600 Private Eye#Score#15095.0$Atari Games#Atari 2600 Beam Rider#Score#14074.0$Atari Games#Atari 2600 Breakout#Score#748.0$Atari Games#Atari 2600 Q*Bert#Score#23784$Atari Games#Atari 2600 Wizard of Wor#Score#9300.0$Atari Games#Atari 2600 Star Gunner#Score#49095.0$Atari Games#Atari 2600 Assault#Score#7203.0$Atari Games#Atari 2600 Tutankham#Score#280.0$Atari Games#Atari 2600 River Raid#Score#17322.0$Atari Games#Atari 2600 Bowling#Score#81.8$Atari Games#Atari 2600 Berzerk#Score#1645.0$Atari Games#Atari 2600 Gopher#Score#33641.0$Atari Games#Atari-57#Medium Human-Normalized Score#178%$Atari Games#Atari 2600 Asterix#Score#406211$Atari Games#Atari 2600 Enduro#Score#3454.0$Atari Games#Atari 2600 Fishing Derby#Score#8.9$Atari Games#Atari 2600 Ms. Pacman#Score#3415.0$Atari Games#Atari 2600 Robotank#Score#52.3$Atari Games#Atari 2600 Alien#Score#3166.0$Atari Games#Atari 2600 Video Pinball#Score#949604.0$Atari Games#Atari 2600 Boxing#Score#97.8$Atari Games#Atari 2600 Battle Zone#Score#28742.0$Atari Games#Atari 2600 Chopper Command#Score#15600.0$Atari Games#Atari 2600 Crazy Climber#Score#179877.0$Atari Games#Atari 2600 Name This Game#Score#12542.0$Atari Games#Atari 2600 Centipede#Score#9646.0$Atari Games#Atari 2600 Seaquest#Score#266434.0$Atari Games#Atari 2600 Frostbite#Score#3965.0$Atari Games#Atari 2600 Up and Down#Score#15612.0$Atari Games#Atari 2600 Bank Heist#Score#976.0$Atari Games#Atari 2600 Venture#Score#1520.0$Atari Games#Atari 2600 Space Invaders#Score#5747.0$Atari Games#Atari 2600 James Bond#Score#1909.0$Atari Games#Atari 2600 Road Runner#Score#55839.0$Atari Games#Atari 2600 HERO#Score#38874$Atari Games#Atari 2600 Amidar#Score#1735.0$Atari Games#Atari 2600 Asteroids#Score#1516.0$Atari Games#Atari 2600 Atlantis#Score#841075.0$Atari Games#Atari 2600 Pong#Score#20.9$Atari Games#Atari 2600 Time Pilot#Score#8329.0
2102.09407v3.pdf	Atari Games#Atari 2600 Tennis#Score#20.6$Atari Games#Atari 2600 Tennis#Score#20.5$Atari Games#Atari 2600 Kangaroo#Score#5266$Atari Games#Atari 2600 Kangaroo#Score#2941$Atari Games#Atari 2600 Breakout#Score#336$Atari Games#Atari 2600 Breakout#Score#316$Atari Games#Atari 2600 Q*Bert#Score#14436$Atari Games#Atari 2600 Q*Bert#Score#14080$Atari Games#Atari 2600 Tutankham#Score#184$Atari Games#Atari 2600 Tutankham#Score#179$Atari Games#Atari 2600 Asterix#Score#18109$Atari Games#Atari 2600 Asterix#Score#12621$Atari Games#Atari 2600 Enduro#Score#1043$Atari Games#Atari 2600 Enduro#Score#957$Atari Games#Atari 2600 Video Pinball#Score#149712$Atari Games#Atari 2600 Video Pinball#Score#86942$Atari Games#Atari 2600 Battle Zone#Score#25749$Atari Games#Atari 2600 Battle Zone#Score#23403$Atari Games#Atari 2600 Skiing#Score#-23582$Atari Games#Atari 2600 Skiing#Score#-23487$Atari Games#Atari 2600 Seaquest#Score#7460$Atari Games#Atari 2600 Seaquest#Score#6603$Atari Games#Atari 2600 Space Invaders#Score#1395$Atari Games#Atari 2600 Space Invaders#Score#650$Atari Games#Atari 2600 James Bond#Score#1137$Atari Games#Atari 2600 James Bond#Score#1122$Atari Games#Atari 2600 Pong#Score#18.13$Atari Games#Atari 2600 Pong#Score#18.04$Atari Games#Atari 2600 Time Pilot#Score#17632$Atari Games#Atari 2600 Time Pilot#Score#13261
2010.02193v4.pdf	Atari Games#Atari 2600 Tennis#Score#14$Atari Games#Atari 2600 Double Dunk#Score#17$Atari Games#Atari games#Mean Human Normalized Score#631.17%$Atari Games#Atari 2600 Phoenix#Score#49375$Atari Games#Atari 2600 Yars Revenge#Score#156748$Atari Games#Atari 2600 Montezuma's Revenge#Score#81$Atari Games#Atari 2600 Demon Attack#Score#82263$Atari Games#Atari 2600 Krull#Score#50061$Atari Games#Atari 2600 Freeway#Score#33$Atari Games#Atari 2600 Zaxxon#Score#50699$Atari Games#Atari 2600 Gravitar#Score#3789$Atari Games#Atari 2600 Kangaroo#Score#14064$Atari Games#Atari 2600 Kung-Fu Master#Score#62741$Atari Games#Atari 2600 Ice Hockey#Score#26$Atari Games#Atari 2600 Private Eye#Score#2198$Atari Games#Atari 2600 Beam Rider#Score#18646$Atari Games#Atari 2600 Breakout#Score#312$Atari Games#Atari 2600 Q*Bert#Score#94688$Atari Games#Atari 2600 Wizard of Wor#Score#12851$Atari Games#Atari 2600 Star Gunner#Score#7800$Atari Games#Atari 2600 Solaris#Score#922$Atari Games#Atari 2600 Assault#Score#23625$Atari Games#Atari 2600 Tutankham#Score#264$Atari Games#Atari 2600 River Raid#Score#16351$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#49$Atari Games#Atari 2600 Berzerk#Score#810$Atari Games#Atari 2600 Gopher#Score#92282$Atari Games#Atari 2600 Asterix#Score#72311$Atari Games#Atari 2600 Enduro#Score#1656$Atari Games#Atari 2600 Fishing Derby#Score#65$Atari Games#Atari 2600 Ms. Pacman#Score#5652$Atari Games#Atari 2600 Robotank#Score#78$Atari Games#Atari 2600 Alien#Score#3967$Atari Games#Atari 2600 Video Pinball#Score#41860$Atari Games#Atari 2600 Boxing#Score#92$Atari Games#Atari 2600 Battle Zone#Score#40325$Atari Games#Atari 2600 Chopper Command#Score#2861$Atari Games#Atari 2600 Crazy Climber#Score#161839$Atari Games#Atari 2600 Name This Game#Score#14649$Atari Games#Atari 2600 Centipede#Score#11883$Atari Games#Atari 2600 Skiing#Score#-9299$Atari Games#Atari 2600 Seaquest#Score#7480$Atari Games#Atari 2600 Frostbite#Score#11384$Atari Games#Atari 2600 Up and Down#Score#653662$Atari Games#Atari 2600 Bank Heist#Score#1126$Atari Games#Atari 2600 Venture#Score#2$Atari Games#Atari 2600 Space Invaders#Score#2474$Atari Games#Atari 2600 James Bond#Score#40445$Atari Games#Atari 2600 Road Runner#Score#203576$Atari Games#Atari 2600 HERO#Score#21868$Atari Games#Atari 2600 Amidar#Score#2577$Atari Games#Atari 2600 Asteroids#Score#41526$Atari Games#Atari 2600 Atlantis#Score#978778$Atari Games#Atari 2600 Pong#Score#20$Atari Games#Atari 2600 Time Pilot#Score#37945
1509.06461v3.pdf	Atari Games#Atari 2600 Tennis#Score#12.2$Atari Games#Atari 2600 Tennis#Score#11.1$Atari Games#Atari 2600 Tennis#Score#-7.8$Atari Games#Atari 2600 Tennis#Score#-13.2$Atari Games#Atari 2600 Double Dunk#Score#-6.0$Atari Games#Atari 2600 Double Dunk#Score#-6.6$Atari Games#Atari 2600 Double Dunk#Score#-0.3$Atari Games#Atari 2600 Double Dunk#Score#-10.7$Atari Games#Atari 2600 Montezuma's Revenge#Score#47$Atari Games#Atari 2600 Montezuma's Revenge#Score#42$Atari Games#Atari 2600 Montezuma's Revenge#Score#24$Atari Games#Atari 2600 Demon Attack#Score#73371.3$Atari Games#Atari 2600 Demon Attack#Score#69803.4$Atari Games#Atari 2600 Demon Attack#Score#12550.7$Atari Games#Atari 2600 Demon Attack#Score#12149.4$Atari Games#Atari 2600 Krull#Score#8422.3$Atari Games#Atari 2600 Krull#Score#7658.6$Atari Games#Atari 2600 Krull#Score#6796.1$Atari Games#Atari 2600 Krull#Score#6206.0$Atari Games#Atari 2600 Freeway#Score#30.8$Atari Games#Atari 2600 Freeway#Score#28.8$Atari Games#Atari 2600 Freeway#Score#28.2$Atari Games#Atari 2600 Freeway#Score#26.9$Atari Games#Atari 2600 Zaxxon#Score#11320.0$Atari Games#Atari 2600 Zaxxon#Score#8593.0$Atari Games#Atari 2600 Zaxxon#Score#5363.0$Atari Games#Atari 2600 Zaxxon#Score#4412.0$Atari Games#Atari 2600 Gravitar#Score#473.0$Atari Games#Atari 2600 Gravitar#Score#298.0$Atari Games#Atari 2600 Gravitar#Score#200.5$Atari Games#Atari 2600 Gravitar#Score#167.0$Atari Games#Atari 2600 Kangaroo#Score#11204.0$Atari Games#Atari 2600 Kangaroo#Score#7259.0$Atari Games#Atari 2600 Kangaroo#Score#4496.0$Atari Games#Atari 2600 Kangaroo#Score#861.0$Atari Games#Atari 2600 Kung-Fu Master#Score#37484.0$Atari Games#Atari 2600 Kung-Fu Master#Score#30207.0$Atari Games#Atari 2600 Kung-Fu Master#Score#26059.0$Atari Games#Atari 2600 Kung-Fu Master#Score#20882.0$Atari Games#Atari 2600 Ice Hockey#Score#0.5$Atari Games#Atari 2600 Ice Hockey#Score#-1.6$Atari Games#Atari 2600 Ice Hockey#Score#-1.9$Atari Games#Atari 2600 Ice Hockey#Score#-2.5$Atari Games#Atari 2600 Private Eye#Score#1277.6$Atari Games#Atari 2600 Private Eye#Score#207.9$Atari Games#Atari 2600 Private Eye#Score#146.7$Atari Games#Atari 2600 Private Eye#Score#-575.5$Atari Games#Atari 2600 Beam Rider#Score#37412.2$Atari Games#Atari 2600 Beam Rider#Score#17417.2$Atari Games#Atari 2600 Beam Rider#Score#9743.2$Atari Games#Atari 2600 Beam Rider#Score#8627.5$Atari Games#Atari 2600 Breakout#Score#385.5$Atari Games#Atari 2600 Breakout#Score#368.9$Atari Games#Atari 2600 Breakout#Score#354.6$Atari Games#Atari 2600 Breakout#Score#354.5$Atari Games#Atari 2600 Q*Bert#Score#14063$Atari Games#Atari 2600 Q*Bert#Score#13117.3$Atari Games#Atari 2600 Q*Bert#Score#11020.8$Atari Games#Atari 2600 Q*Bert#Score#9271.5$Atari Games#Atari 2600 Wizard of Wor#Score#10471.0$Atari Games#Atari 2600 Wizard of Wor#Score#6201.0$Atari Games#Atari 2600 Wizard of Wor#Score#2704.0$Atari Games#Atari 2600 Wizard of Wor#Score#1609.0$Atari Games#Atari 2600 Star Gunner#Score#127073.0$Atari Games#Atari 2600 Star Gunner#Score#58365.0$Atari Games#Atari 2600 Star Gunner#Score#54282.0$Atari Games#Atari 2600 Star Gunner#Score#52970.0$Atari Games#Atari 2600 Assault#Score#10950.6$Atari Games#Atari 2600 Assault#Score#6060.8$Atari Games#Atari 2600 Assault#Score#4280.4$Atari Games#Atari 2600 Assault#Score#3489.3$Atari Games#Atari 2600 Tutankham#Score#108.6$Atari Games#Atari 2600 Tutankham#Score#92.2$Atari Games#Atari 2600 Tutankham#Score#68.1$Atari Games#Atari 2600 Tutankham#Score#45.6$Atari Games#Atari 2600 River Raid#Score#16496.8$Atari Games#Atari 2600 River Raid#Score#10838.4$Atari Games#Atari 2600 River Raid#Score#7377.6$Atari Games#Atari 2600 River Raid#Score#4748.5$Atari Games#Atari 2600 Bowling#Score#69.6$Atari Games#Atari 2600 Bowling#Score#56.5$Atari Games#Atari 2600 Bowling#Score#50.4$Atari Games#Atari 2600 Berzerk#Score#2178.6$Atari Games#Atari 2600 Berzerk#Score#1011.1$Atari Games#Atari 2600 Berzerk#Score#585.6$Atari Games#Atari 2600 Berzerk#Score#493.4$Atari Games#Atari 2600 Gopher#Score#105148.4$Atari Games#Atari 2600 Gopher#Score#15253.0$Atari Games#Atari 2600 Gopher#Score#8777.4$Atari Games#Atari 2600 Gopher#Score#8190.4$Atari Games#Atari 2600 Asterix#Score#364200$Atari Games#Atari 2600 Asterix#Score#16837$Atari Games#Atari 2600 Asterix#Score#4359$Atari Games#Atari 2600 Asterix#Score#3170.5$Atari Games#Atari 2600 Enduro#Score#2223.9$Atari Games#Atari 2600 Enduro#Score#1216.6$Atari Games#Atari 2600 Enduro#Score#729.0$Atari Games#Atari 2600 Enduro#Score#626.7$Atari Games#Atari 2600 Fishing Derby#Score#17.0$Atari Games#Atari 2600 Fishing Derby#Score#3.2$Atari Games#Atari 2600 Fishing Derby#Score#-1.6$Atari Games#Atari 2600 Fishing Derby#Score#-4.9$Atari Games#Atari 2600 Ms. Pacman#Score#3085.6$Atari Games#Atari 2600 Ms. Pacman#Score#1241.3$Atari Games#Atari 2600 Ms. Pacman#Score#1092.3$Atari Games#Atari 2600 Ms. Pacman#Score#1007.8$Atari Games#Atari 2600 Robotank#Score#63.9$Atari Games#Atari 2600 Robotank#Score#59.1$Atari Games#Atari 2600 Robotank#Score#58.7$Atari Games#Atari 2600 Robotank#Score#24.7$Atari Games#Atari 2600 Alien#Score#1620.0$Atari Games#Atari 2600 Alien#Score#1033.4$Atari Games#Atari 2600 Alien#Score#823.7$Atari Games#Atari 2600 Alien#Score#634.0$Atari Games#Atari 2600 Video Pinball#Score#447408.6$Atari Games#Atari 2600 Video Pinball#Score#367823.7$Atari Games#Atari 2600 Video Pinball#Score#196760.4$Atari Games#Atari 2600 Video Pinball#Score#154414.1$Atari Games#Atari 2600 Boxing#Score#88.0$Atari Games#Atari 2600 Boxing#Score#79.2$Atari Games#Atari 2600 Boxing#Score#73.5$Atari Games#Atari 2600 Boxing#Score#70.3$Atari Games#Atari 2600 Battle Zone#Score#30650.0$Atari Games#Atari 2600 Battle Zone#Score#29900.0$Atari Games#Atari 2600 Battle Zone#Score#24740.0$Atari Games#Atari 2600 Battle Zone#Score#23750.0$Atari Games#Atari 2600 Chopper Command#Score#8058.0$Atari Games#Atari 2600 Chopper Command#Score#6126.0$Atari Games#Atari 2600 Chopper Command#Score#5017.0$Atari Games#Atari 2600 Chopper Command#Score#3495.0$Atari Games#Atari 2600 Crazy Climber#Score#127853.0$Atari Games#Atari 2600 Crazy Climber#Score#113782.0$Atari Games#Atari 2600 Crazy Climber#Score#110763.0$Atari Games#Atari 2600 Crazy Climber#Score#98128.0$Atari Games#Atari 2600 Name This Game#Score#13637.9$Atari Games#Atari 2600 Name This Game#Score#8960.3$Atari Games#Atari 2600 Name This Game#Score#8207.8$Atari Games#Atari 2600 Name This Game#Score#6738.8$Atari Games#Atari 2600 Centipede#Score#5570.2$Atari Games#Atari 2600 Centipede#Score#4657.7$Atari Games#Atari 2600 Centipede#Score#3973.9$Atari Games#Atari 2600 Centipede#Score#3853.5$Atari Games#Atari 2600 Seaquest#Score#14498.0$Atari Games#Atari 2600 Seaquest#Score#5860.6$Atari Games#Atari 2600 Seaquest#Score#4216.7$Atari Games#Atari 2600 Seaquest#Score#1431.2$Atari Games#Atari 2600 Frostbite#Score#4038.4$Atari Games#Atari 2600 Frostbite#Score#1448.1$Atari Games#Atari 2600 Frostbite#Score#797.4$Atari Games#Atari 2600 Frostbite#Score#496.1$Atari Games#Atari 2600 Up and Down#Score#22681.3$Atari Games#Atari 2600 Up and Down#Score#19086.9$Atari Games#Atari 2600 Up and Down#Score#9989.9$Atari Games#Atari 2600 Up and Down#Score#8038.5$Atari Games#Atari 2600 Bank Heist#Score#1004.6$Atari Games#Atari 2600 Bank Heist#Score#886.0$Atari Games#Atari 2600 Bank Heist#Score#455.0$Atari Games#Atari 2600 Bank Heist#Score#312.7$Atari Games#Atari 2600 Venture#Score#163.0$Atari Games#Atari 2600 Venture#Score#136.0$Atari Games#Atari 2600 Venture#Score#29.0$Atari Games#Atari 2600 Venture#Score#21.0$Atari Games#Atari 2600 Space Invaders#Score#8978.0$Atari Games#Atari 2600 Space Invaders#Score#2628.7$Atari Games#Atari 2600 Space Invaders#Score#1692.3$Atari Games#Atari 2600 Space Invaders#Score#1293.8$Atari Games#Atari 2600 James Bond#Score#768.5$Atari Games#Atari 2600 James Bond#Score#697.5$Atari Games#Atari 2600 James Bond#Score#585.0$Atari Games#Atari 2600 James Bond#Score#573.0$Atari Games#Atari 2600 Road Runner#Score#54630.0$Atari Games#Atari 2600 Road Runner#Score#43156.0$Atari Games#Atari 2600 Road Runner#Score#39544.0$Atari Games#Atari 2600 Road Runner#Score#35215.0$Atari Games#Atari 2600 HERO#Score#20437.8$Atari Games#Atari 2600 HERO#Score#15459.2$Atari Games#Atari 2600 HERO#Score#14992.9$Atari Games#Atari 2600 HERO#Score#14892.5$Atari Games#Atari 2600 Amidar#Score#978.0$Atari Games#Atari 2600 Amidar#Score#238.4$Atari Games#Atari 2600 Amidar#Score#178.4$Atari Games#Atari 2600 Amidar#Score#169.1$Atari Games#Atari 2600 Asteroids#Score#1458.7$Atari Games#Atari 2600 Asteroids#Score#1364.5$Atari Games#Atari 2600 Asteroids#Score#1193.2$Atari Games#Atari 2600 Asteroids#Score#1021.9$Atari Games#Atari 2600 Atlantis#Score#423252.0$Atari Games#Atari 2600 Atlantis#Score#319688.0$Atari Games#Atari 2600 Atlantis#Score#292491.0$Atari Games#Atari 2600 Atlantis#Score#279987.0$Atari Games#Atari 2600 Pong#Score#19.5$Atari Games#Atari 2600 Pong#Score#19.1$Atari Games#Atari 2600 Pong#Score#18.4$Atari Games#Atari 2600 Pong#Score#18.0$Atari Games#Atari 2600 Time Pilot#Score#6608.0$Atari Games#Atari 2600 Time Pilot#Score#4871.0$Atari Games#Atari 2600 Time Pilot#Score#4870.0$Atari Games#Atari 2600 Time Pilot#Score#4786.0
1602.07714v2.pdf	Atari Games#Atari 2600 Tennis#Score#12.1$Atari Games#Atari 2600 Double Dunk#Score#-11.5$Atari Games#Atari 2600 Demon Attack#Score#63644.9$Atari Games#Atari 2600 Krull#Score#9745.1$Atari Games#Atari 2600 Freeway#Score#33.4$Atari Games#Atari 2600 Zaxxon#Score#14402.0$Atari Games#Atari 2600 Gravitar#Score#483.5$Atari Games#Atari 2600 Kangaroo#Score#13150.0$Atari Games#Atari 2600 Kung-Fu Master#Score#34393.0$Atari Games#Atari 2600 Ice Hockey#Score#-4.1$Atari Games#Atari 2600 Private Eye#Score#286.7$Atari Games#Atari 2600 Beam Rider#Score#8299.4$Atari Games#Atari 2600 Breakout#Score#344.1$Atari Games#Atari 2600 Q*Bert#Score#5236.8$Atari Games#Atari 2600 Wizard of Wor#Score#483.0$Atari Games#Atari 2600 Star Gunner#Score#589.0$Atari Games#Atari 2600 Assault#Score#9011.6$Atari Games#Atari 2600 Tutankham#Score#183.9$Atari Games#Atari 2600 River Raid#Score#12530.8$Atari Games#Atari 2600 Bowling#Score#102.1$Atari Games#Atari 2600 Berzerk#Score#1199.6$Atari Games#Atari 2600 Gopher#Score#56218.2$Atari Games#Atari 2600 Asterix#Score#18919.5$Atari Games#Atari 2600 Enduro#Score#2002.1$Atari Games#Atari 2600 Fishing Derby#Score#45.1$Atari Games#Atari 2600 Ms. Pacman#Score#4963.8$Atari Games#Atari 2600 Robotank#Score#64.3$Atari Games#Atari 2600 Alien#Score#3213.5$Atari Games#Atari 2600 Video Pinball#Score#56287.0$Atari Games#Atari 2600 Boxing#Score#99.3$Atari Games#Atari 2600 Battle Zone#Score#8220.0$Atari Games#Atari 2600 Chopper Command#Score#775.0$Atari Games#Atari 2600 Crazy Climber#Score#119679.0$Atari Games#Atari 2600 Name This Game#Score#15851.2$Atari Games#Atari 2600 Centipede#Score#49065.8$Atari Games#Atari 2600 Seaquest#Score#10932.3$Atari Games#Atari 2600 Frostbite#Score#3469.6$Atari Games#Atari 2600 Up and Down#Score#22474.4$Atari Games#Atari 2600 Bank Heist#Score#1103.3$Atari Games#Atari 2600 Venture#Score#1172.0$Atari Games#Atari 2600 Space Invaders#Score#2589.7$Atari Games#Atari 2600 James Bond#Score#507.5$Atari Games#Atari 2600 Road Runner#Score#47770.0$Atari Games#Atari 2600 HERO#Score#14225.2$Atari Games#Atari 2600 Amidar#Score#782.5$Atari Games#Atari 2600 Asteroids#Score#2869.3$Atari Games#Atari 2600 Atlantis#Score#340076.0$Atari Games#Atari 2600 Pong#Score#20.6$Atari Games#Atari 2600 Time Pilot#Score#4870.0
1511.06581v3.pdf	Atari Games#Atari 2600 Tennis#Score#5.1$Atari Games#Atari 2600 Tennis#Score#4.4$Atari Games#Atari 2600 Tennis#Score#0.0$Atari Games#Atari 2600 Tennis#Score#-22.8$Atari Games#Atari 2600 Double Dunk#Score#0.1$Atari Games#Atari 2600 Double Dunk#Score#-0.8$Atari Games#Atari 2600 Double Dunk#Score#-5.5$Atari Games#Atari 2600 Double Dunk#Score#-12.5$Atari Games#Atari 2600 Phoenix#Score#63597.0$Atari Games#Atari 2600 Montezuma's Revenge#Score#22.0$Atari Games#Atari 2600 Demon Attack#Score#72878.6$Atari Games#Atari 2600 Demon Attack#Score#60813.3$Atari Games#Atari 2600 Demon Attack#Score#58044.2$Atari Games#Atari 2600 Demon Attack#Score#56322.8$Atari Games#Atari 2600 Krull#Score#11451.9$Atari Games#Atari 2600 Krull#Score#10374.4$Atari Games#Atari 2600 Krull#Score#8051.6$Atari Games#Atari 2600 Krull#Score#7920.5$Atari Games#Atari 2600 Freeway#Score#33.3$Atari Games#Atari 2600 Freeway#Score#33.0$Atari Games#Atari 2600 Freeway#Score#0.2$Atari Games#Atari 2600 Freeway#Score#0.0$Atari Games#Atari 2600 Zaxxon#Score#13886.0$Atari Games#Atari 2600 Zaxxon#Score#12944.0$Atari Games#Atari 2600 Zaxxon#Score#10164.0$Atari Games#Atari 2600 Zaxxon#Score#10163.0$Atari Games#Atari 2600 Gravitar#Score#588.0$Atari Games#Atari 2600 Gravitar#Score#412.0$Atari Games#Atari 2600 Gravitar#Score#297.0$Atari Games#Atari 2600 Gravitar#Score#238.0$Atari Games#Atari 2600 Kangaroo#Score#14854.0$Atari Games#Atari 2600 Kangaroo#Score#12992.0$Atari Games#Atari 2600 Kangaroo#Score#10334.0$Atari Games#Atari 2600 Kangaroo#Score#1792.0$Atari Games#Atari 2600 Kung-Fu Master#Score#48375.0$Atari Games#Atari 2600 Kung-Fu Master#Score#34294.0$Atari Games#Atari 2600 Kung-Fu Master#Score#29710.0$Atari Games#Atari 2600 Kung-Fu Master#Score#24288.0$Atari Games#Atari 2600 Ice Hockey#Score#0.5$Atari Games#Atari 2600 Ice Hockey#Score#-1.3$Atari Games#Atari 2600 Ice Hockey#Score#-2.7$Atari Games#Atari 2600 Ice Hockey#Score#-0.4$Atari Games#Atari 2600 Private Eye#Score#292.6$Atari Games#Atari 2600 Private Eye#Score#206.0$Atari Games#Atari 2600 Private Eye#Score#129.7$Atari Games#Atari 2600 Private Eye#Score#103.0$Atari Games#Atari 2600 Beam Rider#Score#30276.5$Atari Games#Atari 2600 Beam Rider#Score#14591.3$Atari Games#Atari 2600 Beam Rider#Score#13772.8$Atari Games#Atari 2600 Beam Rider#Score#12164.0$Atari Games#Atari 2600 Breakout#Score#418.5$Atari Games#Atari 2600 Breakout#Score#411.6$Atari Games#Atari 2600 Breakout#Score#366.0$Atari Games#Atari 2600 Breakout#Score#345.3$Atari Games#Atari 2600 Q*Bert#Score#19220.3$Atari Games#Atari 2600 Q*Bert#Score#18760.3$Atari Games#Atari 2600 Q*Bert#Score#15088.5$Atari Games#Atari 2600 Q*Bert#Score#14175.8$Atari Games#Atari 2600 Wizard of Wor#Score#12352.0$Atari Games#Atari 2600 Wizard of Wor#Score#7855.0$Atari Games#Atari 2600 Wizard of Wor#Score#7492.0$Atari Games#Atari 2600 Wizard of Wor#Score#7054.0$Atari Games#Atari 2600 Star Gunner#Score#125117.0$Atari Games#Atari 2600 Star Gunner#Score#90804.0$Atari Games#Atari 2600 Star Gunner#Score#89238.0$Atari Games#Atari 2600 Star Gunner#Score#60142.0$Atari Games#Atari 2600 Assault#Score#11477.0$Atari Games#Atari 2600 Assault#Score#10950.6$Atari Games#Atari 2600 Assault#Score#5393.2$Atari Games#Atari 2600 Assault#Score#4621.0$Atari Games#Atari 2600 Assault#Score#3994.8$Atari Games#Atari 2600 Tutankham#Score#245.9$Atari Games#Atari 2600 Tutankham#Score#218.4$Atari Games#Atari 2600 Tutankham#Score#211.4$Atari Games#Atari 2600 Tutankham#Score#48.0$Atari Games#Atari 2600 Defender#Score#42214.0$Atari Games#Atari 2600 Defender#Score#41324.5$Atari Games#Atari 2600 Defender#Score#34415.0$Atari Games#Atari 2600 River Raid#Score#21162.6$Atari Games#Atari 2600 River Raid#Score#20607.6$Atari Games#Atari 2600 River Raid#Score#16569.4$Atari Games#Atari 2600 River Raid#Score#14884.5$Atari Games#Atari 2600 Bowling#Score#68.1$Atari Games#Atari 2600 Bowling#Score#65.7$Atari Games#Atari 2600 Bowling#Score#65.5$Atari Games#Atari 2600 Bowling#Score#46.7$Atari Games#Atari 2600 Berzerk#Score#3409.0$Atari Games#Atari 2600 Berzerk#Score#1472.6$Atari Games#Atari 2600 Berzerk#Score#1225.4$Atari Games#Atari 2600 Berzerk#Score#910.6$Atari Games#Atari 2600 Gopher#Score#104368.2$Atari Games#Atari 2600 Gopher#Score#20051.4$Atari Games#Atari 2600 Gopher#Score#15718.4$Atari Games#Atari 2600 Gopher#Score#14840.8$Atari Games#Atari 2600 Asterix#Score#375080.0$Atari Games#Atari 2600 Asterix#Score#364200.0$Atari Games#Atari 2600 Asterix#Score#28188.0$Atari Games#Atari 2600 Asterix#Score#17356.5$Atari Games#Atari 2600 Asterix#Score#15840.0$Atari Games#Atari 2600 Enduro#Score#2306.4$Atari Games#Atari 2600 Enduro#Score#2258.2$Atari Games#Atari 2600 Enduro#Score#2077.4$Atari Games#Atari 2600 Enduro#Score#1211.8$Atari Games#Atari 2600 Fishing Derby#Score#46.4$Atari Games#Atari 2600 Fishing Derby#Score#41.3$Atari Games#Atari 2600 Fishing Derby#Score#15.5$Atari Games#Atari 2600 Fishing Derby#Score#-4.1$Atari Games#Atari 2600 Ms. Pacman#Score#6283.5$Atari Games#Atari 2600 Ms. Pacman#Score#3327.3$Atari Games#Atari 2600 Ms. Pacman#Score#2711.4$Atari Games#Atari 2600 Ms. Pacman#Score#2250.6$Atari Games#Atari 2600 Robotank#Score#65.3$Atari Games#Atari 2600 Robotank#Score#65.1$Atari Games#Atari 2600 Robotank#Score#62.0$Atari Games#Atari 2600 Robotank#Score#27.5$Atari Games#Atari 2600 Alien#Score#4461.4$Atari Games#Atari 2600 Alien#Score#3941.0$Atari Games#Atari 2600 Alien#Score#3747.7$Atari Games#Atari 2600 Alien#Score#1486.5$Atari Games#Atari 2600 Alien#Score#823.7$Atari Games#Atari 2600 Video Pinball#Score#479197.0$Atari Games#Atari 2600 Video Pinball#Score#309941.9$Atari Games#Atari 2600 Video Pinball#Score#110976.2$Atari Games#Atari 2600 Video Pinball#Score#98209.5$Atari Games#Atari 2600 Boxing#Score#99.4$Atari Games#Atari 2600 Boxing#Score#98.9$Atari Games#Atari 2600 Boxing#Score#91.6$Atari Games#Atari 2600 Boxing#Score#77.3$Atari Games#Atari 2600 Battle Zone#Score#37150.0$Atari Games#Atari 2600 Battle Zone#Score#35520.0$Atari Games#Atari 2600 Battle Zone#Score#31700.0$Atari Games#Atari 2600 Battle Zone#Score#31320.0$Atari Games#Atari 2600 Chopper Command#Score#13185.0$Atari Games#Atari 2600 Chopper Command#Score#11215.0$Atari Games#Atari 2600 Chopper Command#Score#5809.0$Atari Games#Atari 2600 Chopper Command#Score#3784.0$Atari Games#Atari 2600 Crazy Climber#Score#162224.0$Atari Games#Atari 2600 Crazy Climber#Score#143570.0$Atari Games#Atari 2600 Crazy Climber#Score#124566.0$Atari Games#Atari 2600 Crazy Climber#Score#117282.0$Atari Games#Atari 2600 Name This Game#Score#15572.5$Atari Games#Atari 2600 Name This Game#Score#11971.1$Atari Games#Atari 2600 Name This Game#Score#11185.1$Atari Games#Atari 2600 Name This Game#Score#10616.0$Atari Games#Atari 2600 Centipede#Score#7687.5$Atari Games#Atari 2600 Centipede#Score#7561.4$Atari Games#Atari 2600 Centipede#Score#5409.4$Atari Games#Atari 2600 Centipede#Score#4881.0$Atari Games#Atari 2600 Seaquest#Score#50254.2$Atari Games#Atari 2600 Seaquest#Score#37361.6$Atari Games#Atari 2600 Seaquest#Score#16452.7$Atari Games#Atari 2600 Seaquest#Score#931.6$Atari Games#Atari 2600 Frostbite#Score#7413.0$Atari Games#Atari 2600 Frostbite#Score#4672.8$Atari Games#Atari 2600 Frostbite#Score#2332.4$Atari Games#Atari 2600 Frostbite#Score#1683.3$Atari Games#Atari 2600 Up and Down#Score#44939.6$Atari Games#Atari 2600 Up and Down#Score#33879.1$Atari Games#Atari 2600 Up and Down#Score#24759.2$Atari Games#Atari 2600 Up and Down#Score#22972.2$Atari Games#Atari 2600 Bank Heist#Score#1611.9$Atari Games#Atari 2600 Bank Heist#Score#1503.1$Atari Games#Atari 2600 Bank Heist#Score#1129.3$Atari Games#Atari 2600 Bank Heist#Score#1030.6$Atari Games#Atari 2600 Venture#Score#497.0$Atari Games#Atari 2600 Venture#Score#200.0$Atari Games#Atari 2600 Venture#Score#98.0$Atari Games#Atari 2600 Venture#Score#48.0$Atari Games#Atari 2600 Space Invaders#Score#15311.5$Atari Games#Atari 2600 Space Invaders#Score#6427.3$Atari Games#Atari 2600 Space Invaders#Score#5993.1$Atari Games#Atari 2600 Space Invaders#Score#2525.5$Atari Games#Atari 2600 James Bond#Score#1358.0$Atari Games#Atari 2600 James Bond#Score#1312.5$Atari Games#Atari 2600 James Bond#Score#835.5$Atari Games#Atari 2600 James Bond#Score#812.0$Atari Games#Atari 2600 Road Runner#Score#69524.0$Atari Games#Atari 2600 Road Runner#Score#62151.0$Atari Games#Atari 2600 Road Runner#Score#58549.0$Atari Games#Atari 2600 Road Runner#Score#44127.0$Atari Games#Atari 2600 HERO#Score#21036.5$Atari Games#Atari 2600 HERO#Score#20818.2$Atari Games#Atari 2600 HERO#Score#20130.2$Atari Games#Atari 2600 HERO#Score#15207.9$Atari Games#Atari 2600 Amidar#Score#2354.5$Atari Games#Atari 2600 Amidar#Score#2296.8$Atari Games#Atari 2600 Amidar#Score#1793.3$Atari Games#Atari 2600 Amidar#Score#238.4$Atari Games#Atari 2600 Amidar#Score#172.7$Atari Games#Atari 2600 Asteroids#Score#2837.7$Atari Games#Atari 2600 Asteroids#Score#2035.4$Atari Games#Atari 2600 Asteroids#Score#1192.7$Atari Games#Atari 2600 Asteroids#Score#734.7$Atari Games#Atari 2600 Atlantis#Score#445360.0$Atari Games#Atari 2600 Atlantis#Score#395762.0$Atari Games#Atari 2600 Atlantis#Score#382572.0$Atari Games#Atari 2600 Atlantis#Score#106056.0$Atari Games#Atari 2600 Pong#Score#21.0$Atari Games#Atari 2600 Pong#Score#20.9$Atari Games#Atari 2600 Pong#Score#18.8$Atari Games#Atari 2600 Time Pilot#Score#11666.0$Atari Games#Atari 2600 Time Pilot#Score#8339.0$Atari Games#Atari 2600 Time Pilot#Score#7553.0$Atari Games#Atari 2600 Time Pilot#Score#6601.0
1207.4708v2.pdf	Atari Games#Atari 2600 Tennis#Score#2.8$Atari Games#Atari 2600 Tennis#Score#-0.1$Atari Games#Atari 2600 Double Dunk#Score#24$Atari Games#Atari 2600 Double Dunk#Score#-13.1$Atari Games#Atari 2600 Montezuma's Revenge#Score#10.7$Atari Games#Atari 2600 Demon Attack#Score#28158.8$Atari Games#Atari 2600 Demon Attack#Score#520.5$Atari Games#Atari 2600 Krull#Score#5037$Atari Games#Atari 2600 Krull#Score#3371.5$Atari Games#Atari 2600 Elevator Action#Score#18100.0$Atari Games#Atari 2600 Freeway#Score#22.5$Atari Games#Atari 2600 Freeway#Score#19.1$Atari Games#Atari 2600 Freeway#Score#0.4$Atari Games#Atari 2600 Zaxxon#Score#22610$Atari Games#Atari 2600 Zaxxon#Score#3365.1$Atari Games#Atari 2600 Gravitar#Score#2850$Atari Games#Atari 2600 Gravitar#Score#387.7$Atari Games#Atari 2600 Kangaroo#Score#1990$Atari Games#Atari 2600 Kangaroo#Score#1622.1$Atari Games#Atari 2600 Kung-Fu Master#Score#48854.5$Atari Games#Atari 2600 Kung-Fu Master#Score#19544$Atari Games#Atari 2600 Carnival#Score#5132.0$Atari Games#Atari 2600 Ice Hockey#Score#39.4$Atari Games#Atari 2600 Ice Hockey#Score#-9.5$Atari Games#Atari 2600 Private Eye#Score#1947.3$Atari Games#Atari 2600 Private Eye#Score#684.3$Atari Games#Atari 2600 Beam Rider#Score#6624.6$Atari Games#Atari 2600 Beam Rider#Score#929.4$Atari Games#Atari 2600 Breakout#Score#364.4$Atari Games#Atari 2600 Breakout#Score#5.2$Atari Games#Atari 2600 Journey Escape#Score#7683.3$Atari Games#Atari 2600 Q*Bert#Score#17343.4$Atari Games#Atari 2600 Q*Bert#Score#613.5$Atari Games#Atari 2600 Wizard of Wor#Score#105500$Atari Games#Atari 2600 Wizard of Wor#Score#1981.3$Atari Games#Atari 2600 Star Gunner#Score#1345$Atari Games#Atari 2600 Star Gunner#Score#1069.5$Atari Games#Atari 2600 Assault#Score#1512.2$Atari Games#Atari 2600 Assault#Score#628$Atari Games#Atari 2600 Tutankham#Score#225.5$Atari Games#Atari 2600 Tutankham#Score#114.3$Atari Games#Atari 2600 River Raid#Score#4449$Atari Games#Atari 2600 River Raid#Score#1904.3$Atari Games#Atari 2600 Bowling#Score#43.9$Atari Games#Atari 2600 Berzerk#Score#670$Atari Games#Atari 2600 Berzerk#Score#501.3$Atari Games#Atari 2600 Gopher#Score#20560$Atari Games#Atari 2600 Gopher#Score#1288.3$Atari Games#Atari 2600 Pooyan#Score#17763.4$Atari Games#Atari 2600 Pooyan#Score#1225.3$Atari Games#Atari 2600 Asterix#Score#290700$Atari Games#Atari 2600 Asterix#Score#987.3$Atari Games#Atari 2600 Enduro#Score#286.3$Atari Games#Atari 2600 Enduro#Score#129.1$Atari Games#Atari 2600 Fishing Derby#Score#37.8$Atari Games#Atari 2600 Fishing Derby#Score#-89.5$Atari Games#Atari 2600 Ms. Pacman#Score#22336$Atari Games#Atari 2600 Ms. Pacman#Score#1691.8$Atari Games#Atari 2600 Robotank#Score#50.4$Atari Games#Atari 2600 Robotank#Score#28.7$Atari Games#Atari 2600 Alien#Score#7785$Atari Games#Atari 2600 Alien#Score#939.2$Atari Games#Atari 2600 Video Pinball#Score#254748$Atari Games#Atari 2600 Video Pinball#Score#16871.3$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Boxing#Score#44$Atari Games#Atari 2600 Battle Zone#Score#70333.3$Atari Games#Atari 2600 Battle Zone#Score#15819.7$Atari Games#Atari 2600 Chopper Command#Score#34018.8$Atari Games#Atari 2600 Chopper Command#Score#1581.5$Atari Games#Atari 2600 Crazy Climber#Score#98172.2$Atari Games#Atari 2600 Crazy Climber#Score#23410.6$Atari Games#Atari 2600 Name This Game#Score#15410$Atari Games#Atari 2600 Name This Game#Score#2500.1$Atari Games#Atari 2600 Centipede#Score#125123$Atari Games#Atari 2600 Centipede#Score#8803.8$Atari Games#Atari 2600 Skiing#Score#0$Atari Games#Atari 2600 Seaquest#Score#5132.4$Atari Games#Atari 2600 Seaquest#Score#664.8$Atari Games#Atari 2600 Frostbite#Score#270.5$Atari Games#Atari 2600 Frostbite#Score#216.9$Atari Games#Atari 2600 Up and Down#Score#74473.6$Atari Games#Atari 2600 Up and Down#Score#3532.7$Atari Games#Atari 2600 Bank Heist#Score#497.8$Atari Games#Atari 2600 Bank Heist#Score#190.8$Atari Games#Atari 2600 Venture#Score#66$Atari Games#Atari 2600 Space Invaders#Score#2718$Atari Games#Atari 2600 Space Invaders#Score#250.1$Atari Games#Atari 2600 James Bond#Score#330$Atari Games#Atari 2600 James Bond#Score#202.8$Atari Games#Atari 2600 Road Runner#Score#38725$Atari Games#Atari 2600 Road Runner#Score#67.7$Atari Games#Atari 2600 HERO#Score#12859.5$Atari Games#Atari 2600 HERO#Score#6459$Atari Games#Atari 2600 HERO#Score#6458.8$Atari Games#Atari 2600 Amidar#Score#180.3$Atari Games#Atari 2600 Amidar#Score#103.4$Atari Games#Atari 2600 Asteroids#Score#4660.6$Atari Games#Atari 2600 Asteroids#Score#907.3$Atari Games#Atari 2600 Atlantis#Score#193858$Atari Games#Atari 2600 Atlantis#Score#62687$Atari Games#Atari 2600 Pong#Score#21$Atari Games#Atari 2600 Pong#Score#-19$Atari Games#Atari 2600 Time Pilot#Score#63854.5$Atari Games#Atari 2600 Time Pilot#Score#3741.2
1802.01561v3.pdf	Atari Games#Atari 2600 Tennis#Score#0.55$Atari Games#Atari 2600 Double Dunk#Score#-0.33$Atari Games#Atari games#Mean Human Normalized Score#957.34%$Atari Games#Atari 2600 Phoenix#Score#210996.45$Atari Games#Atari 2600 Yars Revenge#Score#84231.14$Atari Games#Atari 2600 Montezuma's Revenge#Score#0.00$Atari Games#Atari 2600 Demon Attack#Score#132826.98$Atari Games#Atari 2600 Krull#Score#8147.40$Atari Games#Atari 2600 Freeway#Score#0.00$Atari Games#Atari 2600 Zaxxon#Score#32935.50$Atari Games#Atari 2600 Gravitar#Score#359.50$Atari Games#Atari 2600 Kangaroo#Score#1632.00$Atari Games#Atari 2600 Kung-Fu Master#Score#43375.50$Atari Games#Atari 2600 Ice Hockey#Score#3.48$Atari Games#Atari 2600 Surround#Score#7.56$Atari Games#Atari 2600 Private Eye#Score#98.50$Atari Games#Atari 2600 Beam Rider#Score#32463.47$Atari Games#Atari 2600 Breakout#Score#787.34$Atari Games#Atari 2600 Q*Bert#Score#351200.12$Atari Games#Atari 2600 Wizard of Wor#Score#9157.50$Atari Games#Atari 2600 Star Gunner#Score#200625.00$Atari Games#Atari 2600 Solaris#Score#2365.00$Atari Games#Atari 2600 Assault#Score#19148.47$Atari Games#Atari 2600 Tutankham#Score#292.11$Atari Games#Atari 2600 Defender#Score#185203.00$Atari Games#Atari 2600 River Raid#Score#29608.05$Atari Games#Atari 2600 Pitfall!#Score#-1.66$Atari Games#Atari 2600 Bowling#Score#59.92$Atari Games#Atari 2600 Berzerk#Score#1852.70$Atari Games#Atari 2600 Gopher#Score#66782.30$Atari Games#Atari-57#Medium Human-Normalized Score#191.8%$Atari Games#Atari-57#Human World Record Breakthrough#3$Atari Games#Atari-57#Mean Human Normalized Score#957.34%$Atari Games#Atari 2600 Asterix#Score#300732.00$Atari Games#Atari 2600 Enduro#Score#0.00$Atari Games#Atari 2600 Fishing Derby#Score#44.85$Atari Games#Atari 2600 Ms. Pacman#Score#7342.32$Atari Games#Atari 2600 Robotank#Score#12.96$Atari Games#Atari 2600 Alien#Score#15962.10$Atari Games#Atari 2600 Video Pinball#Score#572898.27$Atari Games#Atari 2600 Boxing#Score#99.96$Atari Games#Atari 2600 Battle Zone#Score#20885.00$Atari Games#Atari 2600 Chopper Command#Score#28255.00$Atari Games#Atari 2600 Crazy Climber#Score#136950.00$Atari Games#Atari 2600 Name This Game#Score#21537.20$Atari Games#Atari 2600 Centipede#Score#11049.75$Atari Games#Atari 2600 Skiing#Score#-10180.38$Atari Games#Atari 2600 Seaquest#Score#1753.20$Atari Games#Atari 2600 Frostbite#Score#317.75$Atari Games#Atari 2600 Up and Down#Score#332546.75$Atari Games#Atari 2600 Bank Heist#Score#1223.15$Atari Games#Atari 2600 Venture#Score#0.00$Atari Games#Atari 2600 Space Invaders#Score#43595.78$Atari Games#Atari 2600 James Bond#Score#601.50$Atari Games#Atari 2600 Road Runner#Score#57121.00$Atari Games#Atari 2600 HERO#Score#33730.55$Atari Games#Atari 2600 Amidar#Score#1554.79$Atari Games#Atari 2600 Asteroids#Score#108590.05$Atari Games#Atari 2600 Atlantis#Score#849967.50$Atari Games#Atari 2600 Pong#Score#20.98$Atari Games#Atari 2600 Time Pilot#Score#48481.50
1511.05952v4.pdf	Atari Games#Atari 2600 Tennis#Score#0.0$Atari Games#Atari 2600 Tennis#Score#-5.3$Atari Games#Atari 2600 Double Dunk#Score#18.5$Atari Games#Atari 2600 Double Dunk#Score#16.0$Atari Games#Atari 2600 Montezuma's Revenge#Score#51$Atari Games#Atari 2600 Demon Attack#Score#71846.4$Atari Games#Atari 2600 Demon Attack#Score#61277.5$Atari Games#Atari 2600 Krull#Score#9728.0$Atari Games#Atari 2600 Krull#Score#6872.8$Atari Games#Atari 2600 Freeway#Score#33.7$Atari Games#Atari 2600 Freeway#Score#28.9$Atari Games#Atari 2600 Zaxxon#Score#10469.0$Atari Games#Atari 2600 Zaxxon#Score#9474.0$Atari Games#Atari 2600 Gravitar#Score#548.5$Atari Games#Atari 2600 Gravitar#Score#269.5$Atari Games#Atari 2600 Kangaroo#Score#16200.0$Atari Games#Atari 2600 Kangaroo#Score#12185.0$Atari Games#Atari 2600 Kung-Fu Master#Score#39581.0$Atari Games#Atari 2600 Kung-Fu Master#Score#31676.0$Atari Games#Atari 2600 Ice Hockey#Score#1.3$Atari Games#Atari 2600 Ice Hockey#Score#-0.2$Atari Games#Atari 2600 Private Eye#Score#670.7$Atari Games#Atari 2600 Private Eye#Score#200.0$Atari Games#Atari 2600 Beam Rider#Score#31181.3$Atari Games#Atari 2600 Beam Rider#Score#23384.2$Atari Games#Atari 2600 Breakout#Score#373.9$Atari Games#Atari 2600 Breakout#Score#343.0$Atari Games#Atari 2600 Q*Bert#Score#16256.5$Atari Games#Atari 2600 Q*Bert#Score#9944$Atari Games#Atari 2600 Wizard of Wor#Score#5727.0$Atari Games#Atari 2600 Wizard of Wor#Score#4802.0$Atari Games#Atari 2600 Star Gunner#Score#63302.0$Atari Games#Atari 2600 Star Gunner#Score#61582.0$Atari Games#Atari 2600 Assault#Score#7672.1$Atari Games#Atari 2600 Assault#Score#6548.9$Atari Games#Atari 2600 Tutankham#Score#204.6$Atari Games#Atari 2600 Tutankham#Score#56.9$Atari Games#Atari 2600 River Raid#Score#14522.3$Atari Games#Atari 2600 River Raid#Score#11807.2$Atari Games#Atari 2600 Bowling#Score#52$Atari Games#Atari 2600 Bowling#Score#47.9$Atari Games#Atari 2600 Berzerk#Score#1305.6$Atari Games#Atari 2600 Berzerk#Score#865.9$Atari Games#Atari 2600 Gopher#Score#34858.8$Atari Games#Atari 2600 Gopher#Score#32487.2$Atari Games#Atari-57#Medium Human-Normalized Score#128%$Atari Games#Atari 2600 Asterix#Score#31527$Atari Games#Atari 2600 Asterix#Score#22484.5$Atari Games#Atari 2600 Enduro#Score#2093.0$Atari Games#Atari 2600 Enduro#Score#1831.0$Atari Games#Atari 2600 Fishing Derby#Score#39.5$Atari Games#Atari 2600 Fishing Derby#Score#9.8$Atari Games#Atari 2600 Ms. Pacman#Score#6518.7$Atari Games#Atari 2600 Ms. Pacman#Score#1865.9$Atari Games#Atari 2600 Robotank#Score#62.6$Atari Games#Atari 2600 Robotank#Score#56.2$Atari Games#Atari 2600 Alien#Score#4203.8$Atari Games#Atari 2600 Alien#Score#1334.7$Atari Games#Atari 2600 Video Pinball#Score#295972.8$Atari Games#Atari 2600 Video Pinball#Score#282007.3$Atari Games#Atari 2600 Boxing#Score#95.6$Atari Games#Atari 2600 Boxing#Score#72.3$Atari Games#Atari 2600 Battle Zone#Score#31530.0$Atari Games#Atari 2600 Battle Zone#Score#25520.0$Atari Games#Atari 2600 Chopper Command#Score#8600.0$Atari Games#Atari 2600 Chopper Command#Score#4635.0$Atari Games#Atari 2600 Crazy Climber#Score#141161.0$Atari Games#Atari 2600 Crazy Climber#Score#127512.0$Atari Games#Atari 2600 Name This Game#Score#12270.5$Atari Games#Atari 2600 Name This Game#Score#10497.6$Atari Games#Atari 2600 Centipede#Score#4463.2$Atari Games#Atari 2600 Centipede#Score#3489.1$Atari Games#Atari 2600 Seaquest#Score#26357.8$Atari Games#Atari 2600 Seaquest#Score#25463.7$Atari Games#Atari 2600 Frostbite#Score#4380.1$Atari Games#Atari 2600 Frostbite#Score#3510.0$Atari Games#Atari 2600 Up and Down#Score#16154.1$Atari Games#Atari 2600 Up and Down#Score#12157.4$Atari Games#Atari 2600 Bank Heist#Score#1054.6$Atari Games#Atari 2600 Bank Heist#Score#876.6$Atari Games#Atari 2600 Venture#Score#94.0$Atari Games#Atari 2600 Venture#Score#54.0$Atari Games#Atari 2600 Space Invaders#Score#3912.1$Atari Games#Atari 2600 Space Invaders#Score#2865.8$Atari Games#Atari 2600 James Bond#Score#5148.0$Atari Games#Atari 2600 James Bond#Score#3961.0$Atari Games#Atari 2600 Road Runner#Score#57608.0$Atari Games#Atari 2600 Road Runner#Score#52264.0$Atari Games#Atari 2600 HERO#Score#23037.7$Atari Games#Atari 2600 HERO#Score#20889.9$Atari Games#Atari 2600 Amidar#Score#1838.9$Atari Games#Atari 2600 Amidar#Score#129.1$Atari Games#Atari 2600 Asteroids#Score#2654.3$Atari Games#Atari 2600 Asteroids#Score#1745.1$Atari Games#Atari 2600 Atlantis#Score#357324.0$Atari Games#Atari 2600 Atlantis#Score#330647.0$Atari Games#Atari 2600 Pong#Score#20.6$Atari Games#Atari 2600 Pong#Score#18.9$Atari Games#Atari 2600 Time Pilot#Score#9197.0$Atari Games#Atari 2600 Time Pilot#Score#5963.0
1602.04621v3.pdf	Atari Games#Atari 2600 Tennis#Score#0$Atari Games#Atari 2600 Double Dunk#Score#3$Atari Games#Atari 2600 Montezuma's Revenge#Score#100$Atari Games#Atari 2600 Demon Attack#Score#82610$Atari Games#Atari 2600 Krull#Score#8627.9$Atari Games#Atari 2600 Freeway#Score#33.9$Atari Games#Atari 2600 Zaxxon#Score#11491.7$Atari Games#Atari 2600 Gravitar#Score#286.1$Atari Games#Atari 2600 Kangaroo#Score#14862.5$Atari Games#Atari 2600 Kung-Fu Master#Score#36733.3$Atari Games#Atari 2600 Ice Hockey#Score#-1.3$Atari Games#Atari 2600 Private Eye#Score#1812.5$Atari Games#Atari 2600 Beam Rider#Score#23429.8$Atari Games#Atari 2600 Breakout#Score#855$Atari Games#Atari 2600 Q*Bert#Score#15092.7$Atari Games#Atari 2600 Wizard of Wor#Score#6804.7$Atari Games#Atari 2600 Star Gunner#Score#55725$Atari Games#Atari 2600 Assault#Score#8047.1$Atari Games#Atari 2600 Tutankham#Score#214.8$Atari Games#Atari 2600 River Raid#Score#12845$Atari Games#Atari 2600 Bowling#Score#60.2$Atari Games#Atari 2600 Gopher#Score#17438.4$Atari Games#Atari 2600 Asterix#Score#19713.2$Atari Games#Atari 2600 Enduro#Score#1591$Atari Games#Atari 2600 Fishing Derby#Score#26$Atari Games#Atari 2600 Ms. Pacman#Score#2983.3$Atari Games#Atari 2600 Robotank#Score#66.6$Atari Games#Atari 2600 Alien#Score#2436.6$Atari Games#Atari 2600 Video Pinball#Score#811610$Atari Games#Atari 2600 Boxing#Score#93.2$Atari Games#Atari 2600 Battle Zone#Score#38666.7$Atari Games#Atari 2600 Chopper Command#Score#4100$Atari Games#Atari 2600 Crazy Climber#Score#137925.9$Atari Games#Atari 2600 Name This Game#Score#11501.1$Atari Games#Atari 2600 Centipede#Score#4553.5$Atari Games#Atari 2600 Seaquest#Score#9083.1$Atari Games#Atari 2600 Frostbite#Score#2181.4$Atari Games#Atari 2600 Up and Down#Score#26231$Atari Games#Atari 2600 Bank Heist#Score#1208$Atari Games#Atari 2600 Venture#Score#212.5$Atari Games#Atari 2600 Space Invaders#Score#2893$Atari Games#Atari 2600 James Bond#Score#1663.5$Atari Games#Atari 2600 Road Runner#Score#51500$Atari Games#Atari 2600 HERO#Score#21021.3$Atari Games#Atari 2600 Amidar#Score#1272.5$Atari Games#Atari 2600 Asteroids#Score#1032$Atari Games#Atari 2600 Atlantis#Score#994500$Atari Games#Atari 2600 Pong#Score#20.9$Atari Games#Atari 2600 Time Pilot#Score#9079.4
1911.08265v2.pdf	Atari Games#Atari 2600 Tennis#Score#0.00$Atari Games#Atari 2600 Double Dunk#Score#23.94$Atari Games#Atari games#Mean Human Normalized Score#4996.20%$Atari Games#Atari 2600 Phoenix#Score#955137.84$Atari Games#Atari 2600 Yars Revenge#Score#553311.46$Atari Games#Atari 2600 Montezuma's Revenge#Score#0.00$Atari Games#Atari 2600 Demon Attack#Score#143964.26$Atari Games#Atari 2600 Krull#Score#269358.27$Atari Games#Atari 2600 Freeway#Score#33.03$Atari Games#Atari 2600 Zaxxon#Score#725853.90$Atari Games#Atari 2600 Gravitar#Score#6682.70$Atari Games#Atari 2600 Kangaroo#Score#16763.60$Atari Games#Atari 2600 Kung-Fu Master#Score#204824.00$Atari Games#Atari 2600 Ice Hockey#Score#67.04$Atari Games#Atari 2600 Surround#Score#9.99$Atari Games#Atari 2600 Private Eye#Score#15299.98$Atari Games#Atari 2600 Beam Rider#Score#454993.53$Atari Games#atari game#Human World Record Breakthrough#19$Atari Games#Atari 2600 Q*Bert#Score#72276.00$Atari Games#Atari 2600 Wizard of Wor#Score#197126.00$Atari Games#Atari 2600 Star Gunner#Score#549271.70$Atari Games#Atari 2600 Solaris#Score#56.62$Atari Games#Atari 2600 Assault#Score#143972.03$Atari Games#Atari 2600 Tutankham#Score#491.48$Atari Games#Atari 2600 Defender#Score#839642.95$Atari Games#Atari 2600 River Raid#Score#323417.18$Atari Games#Atari 2600 Pitfall!#Score#0.00$Atari Games#Atari 2600 Bowling#Score#260.13$Atari Games#Atari 2600 Berzerk#Score#85932.60$Atari Games#Atari 2600 Gopher#Score#130345.58$Atari Games#Atari-57#Medium Human-Normalized Score#2041.1%$Atari Games#Atari-57#Human World Record Breakthrough#19$Atari Games#Atari-57#Mean Human Normalized Score#4996.20%$Atari Games#Atari-57#Medium Human-Normalized Score#731.1%$Atari Games#Atari 2600 Asterix#Score#998425.00$Atari Games#Atari 2600 Enduro#Score#2382.44$Atari Games#Atari 2600 Fishing Derby#Score#91.16$Atari Games#Atari 2600 Ms. Pacman#Score#243401.10$Atari Games#Atari 2600 Robotank#Score#131.13$Atari Games#Atari 2600 Alien#Score#741812.63$Atari Games#Atari 2600 Video Pinball#Score#981791.88$Atari Games#Atari 2600 Boxing#Score#100.00$Atari Games#Atari 2600 Battle Zone#Score#848623.00$Atari Games#Atari 2600 Chopper Command#Score#991039.70$Atari Games#Atari 2600 Crazy Climber#Score#458315.40$Atari Games#Atari 2600 Name This Game#Score#157177.85$Atari Games#Atari 2600 Centipede#Score#1159049.27$Atari Games#Atari 2600 Skiing#Score#-29968.36$Atari Games#Atari 2600 Seaquest#Score#999976.52$Atari Games#Atari 2600 Frostbite#Score#631378.53$Atari Games#Atari 2600 Up and Down#Score#715545.61$Atari Games#Atari 2600 Bank Heist#Score#1278.98$Atari Games#Atari 2600 Venture#Score#0.40$Atari Games#Atari 2600 Space Invaders#Score#74335.30$Atari Games#Atari 2600 James Bond#Score#41063.25$Atari Games#Atari 2600 Road Runner#Score#613411.80$Atari Games#Atari 2600 HERO#Score#49244.11$Atari Games#Atari 2600 Amidar#Score#28634.39$Atari Games#Atari 2600 Asteroids#Score#678558.64$Atari Games#Atari 2600 Atlantis#Score#1674767.20$Atari Games#Atari 2600 Pong#Score#21.00$Atari Games#Atari 2600 Time Pilot#Score#476763.90
1806.05695v1.pdf	Atari Games#Atari 2600 Tennis#Score#0$Atari Games#Atari 2600 Double Dunk#Score#2$Atari Games#Atari 2600 Phoenix#Score#7520$Atari Games#Atari 2600 Yars Revenge#Score#28838.2$Atari Games#Atari 2600 Montezuma's Revenge#Score#0$Atari Games#Atari 2600 Demon Attack#Score#2387$Atari Games#Atari 2600 Krull#Score#9086.8$Atari Games#Atari 2600 Freeway#Score#28.2$Atari Games#Atari 2600 Zaxxon#Score#2980$Atari Games#Atari 2600 Gravitar#Score#2350$Atari Games#Atari 2600 Kangaroo#Score#1400$Atari Games#Atari 2600 Kung-Fu Master#Score#57400$Atari Games#Atari 2600 Ice Hockey#Score#4$Atari Games#Atari 2600 Private Eye#Score#12702.2$Atari Games#Atari 2600 Beam Rider#Score#1341.6$Atari Games#Atari 2600 Breakout#Score#13.2$Atari Games#Atari 2600 Q*Bert#Score#770$Atari Games#Atari 2600 Wizard of Wor#Score#3820$Atari Games#Atari 2600 Star Gunner#Score#2320$Atari Games#Atari 2600 Solaris#Score#8324$Atari Games#Atari 2600 Assault#Score#890.4$Atari Games#Atari 2600 Tutankham#Score#0$Atari Games#Atari 2600 Defender#Score#993010$Atari Games#Atari 2600 River Raid#Score#2914$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#85.8$Atari Games#Atari 2600 Berzerk#Score#1138$Atari Games#Atari 2600 Gopher#Score#1696$Atari Games#Atari 2600 Asterix#Score#1880$Atari Games#Atari 2600 Enduro#Score#56.8$Atari Games#Atari 2600 Fishing Derby#Score#-51$Atari Games#Atari 2600 Ms. Pacman#Score#2568$Atari Games#Atari 2600 Robotank#Score#24.2$Atari Games#Atari 2600 Alien#Score#1978$Atari Games#Atari 2600 Video Pinball#Score#33752.4$Atari Games#Atari 2600 Boxing#Score#38.4$Atari Games#Atari 2600 Battle Zone#Score#34200$Atari Games#Atari 2600 Chopper Command#Score#3580$Atari Games#Atari 2600 Crazy Climber#Score#12900$Atari Games#Atari 2600 Name This Game#Score#3696$Atari Games#Atari 2600 Centipede#Score#24708$Atari Games#Atari 2600 Skiing#Score#-9011$Atari Games#Atari 2600 Seaquest#Score#724$Atari Games#Atari 2600 Frostbite#Score#782$Atari Games#Atari 2600 Up and Down#Score#14524$Atari Games#Atari 2600 Bank Heist#Score#148$Atari Games#Atari 2600 Venture#Score#0$Atari Games#Atari 2600 Space Invaders#Score#1001$Atari Games#Atari 2600 James Bond#Score#6130$Atari Games#Atari 2600 Road Runner#Score#8960$Atari Games#Atari 2600 HERO#Score#2974$Atari Games#Atari 2600 Amidar#Score#199$Atari Games#Atari 2600 Asteroids#Score#9412$Atari Games#Atari 2600 Atlantis#Score#99240$Atari Games#Atari 2600 Pong#Score#20$Atari Games#Atari 2600 Time Pilot#Score#12040
1706.10295v3.pdf	Atari Games#Atari 2600 Tennis#Score#0$Atari Games#Atari 2600 Double Dunk#Score#1$Atari Games#Atari 2600 Phoenix#Score#10379$Atari Games#Atari 2600 Yars Revenge#Score#86101$Atari Games#Atari 2600 Montezuma's Revenge#Score#57$Atari Games#Atari 2600 Demon Attack#Score#69311$Atari Games#Atari 2600 Krull#Score#10754$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Zaxxon#Score#14874$Atari Games#Atari 2600 Gravitar#Score#2209$Atari Games#Atari 2600 Kangaroo#Score#15227$Atari Games#Atari 2600 Kung-Fu Master#Score#41672$Atari Games#Atari 2600 Ice Hockey#Score#3$Atari Games#Atari 2600 Surround#Score#10$Atari Games#Atari 2600 Private Eye#Score#279$Atari Games#Atari 2600 Beam Rider#Score#23134$Atari Games#Atari 2600 Breakout#Score#263$Atari Games#Atari 2600 Q*Bert#Score#27121$Atari Games#Atari 2600 Wizard of Wor#Score#9149$Atari Games#Atari 2600 Star Gunner#Score#75867$Atari Games#Atari 2600 Solaris#Score#6522$Atari Games#Atari 2600 Assault#Score#11231$Atari Games#Atari 2600 Tutankham#Score#269$Atari Games#Atari 2600 Defender#Score#42253$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Berzerk#Score#1896$Atari Games#Atari 2600 Gopher#Score#38909$Atari Games#Atari 2600 Asterix#Score#28350$Atari Games#Atari 2600 Enduro#Score#2013$Atari Games#Atari 2600 Fishing Derby#Score#57$Atari Games#Atari 2600 Ms. Pacman#Score#5546$Atari Games#Atari 2600 Robotank#Score#64$Atari Games#Atari 2600 Alien#Score#5778$Atari Games#Atari 2600 Video Pinball#Score#870954$Atari Games#Atari 2600 Boxing#Score#100$Atari Games#Atari 2600 Battle Zone#Score#52262$Atari Games#Atari 2600 Chopper Command#Score#11477$Atari Games#Atari 2600 Crazy Climber#Score#171171$Atari Games#Atari 2600 Name This Game#Score#12211$Atari Games#Atari 2600 Centipede#Score#7596$Atari Games#Atari 2600 Skiing#Score#-7550$Atari Games#Atari 2600 Seaquest#Score#16754$Atari Games#Atari 2600 Frostbite#Score#2923$Atari Games#Atari 2600 Up and Down#Score#61326$Atari Games#Atari 2600 Bank Heist#Score#1318$Atari Games#Atari 2600 Venture#Score#815$Atari Games#Atari 2600 Space Invaders#Score#5909$Atari Games#Atari 2600 Road Runner#Score#234352$Atari Games#Atari 2600 HERO#Score#31533$Atari Games#Atari 2600 Amidar#Score#3537$Atari Games#Atari 2600 Asteroids#Score#86700$Atari Games#Atari 2600 Atlantis#Score#972175$Atari Games#Atari 2600 Pong#Score#21$Atari Games#Atari 2600 Time Pilot#Score#17301
1512.04860v1.pdf	Atari Games#Atari 2600 Tennis#Score#0$Atari Games#Atari 2600 Double Dunk#Score#-0.15$Atari Games#Atari 2600 Double Dunk#Score#-2.51$Atari Games#Atari 2600 Phoenix#Score#22038.27$Atari Games#Atari 2600 Phoenix#Score#14495.56$Atari Games#Atari 2600 Yars Revenge#Score#24240.03$Atari Games#Atari 2600 Montezuma's Revenge#Score#1.72$Atari Games#Atari 2600 Montezuma's Revenge#Score#0.42$Atari Games#Atari 2600 Demon Attack#Score#70908.17$Atari Games#Atari 2600 Demon Attack#Score#27153.48$Atari Games#Atari 2600 Krull#Score#9548.92$Atari Games#Atari 2600 Krull#Score#8689.81$Atari Games#Atari 2600 Elevator Action#Score#29100$Atari Games#Atari 2600 Elevator Action#Score#27088.89$Atari Games#Atari 2600 Freeway#Score#32.3$Atari Games#Atari 2600 Freeway#Score#31.72$Atari Games#Atari 2600 Zaxxon#Score#9129.61$Atari Games#Atari 2600 Gravitar#Score#446.92$Atari Games#Atari 2600 Gravitar#Score#417.65$Atari Games#Atari 2600 Kangaroo#Score#11478.46$Atari Games#Atari 2600 Kangaroo#Score#10809.16$Atari Games#Atari 2600 Kung-Fu Master#Score#34650.91$Atari Games#Atari 2600 Kung-Fu Master#Score#32182.99$Atari Games#Atari 2600 Ice Hockey#Score#-0.25$Atari Games#Atari 2600 Ice Hockey#Score#-1.24$Atari Games#Atari 2600 Surround#Score#0.72$Atari Games#Atari 2600 Private Eye#Score#5276.16$Atari Games#Atari 2600 Beam Rider#Score#13145.34$Atari Games#Atari 2600 Beam Rider#Score#10054.58$Atari Games#Atari 2600 Breakout#Score#431.89$Atari Games#Atari 2600 Breakout#Score#425.32$Atari Games#Atari 2600 Q*Bert#Score#14368.03$Atari Games#Atari 2600 Wizard of Wor#Score#9541.14$Atari Games#Atari 2600 Star Gunner#Score#61353.59$Atari Games#Atari 2600 Solaris#Score#4785.16$Atari Games#Atari 2600 Assault#Score#3661.51$Atari Games#Atari 2600 Assault#Score#3304.33$Atari Games#Atari 2600 Tutankham#Score#245.22$Atari Games#Atari 2600 Defender#Score#32038.93$Atari Games#Atari 2600 Defender#Score#30643.59$Atari Games#Atari 2600 River Raid#Score#10585.12$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#71.59$Atari Games#Atari 2600 Bowling#Score#57.41$Atari Games#Atari 2600 Berzerk#Score#1328.25$Atari Games#Atari 2600 Berzerk#Score#747.26$Atari Games#Atari 2600 Gopher#Score#11912.68$Atari Games#Atari 2600 Gopher#Score#10611.81$Atari Games#Atari 2600 Pooyan#Score#4801.27$Atari Games#Atari 2600 Asterix#Score#19564.9$Atari Games#Atari 2600 Asterix#Score#12852.08$Atari Games#Atari 2600 Enduro#Score#1343.1$Atari Games#Atari 2600 Enduro#Score#1252.7$Atari Games#Atari 2600 Fishing Derby#Score#28.13$Atari Games#Atari 2600 Fishing Derby#Score#21.32$Atari Games#Atari 2600 Ms. Pacman#Score#4065.8$Atari Games#Atari 2600 Ms. Pacman#Score#3917.55$Atari Games#Atari 2600 Robotank#Score#69.31$Atari Games#Atari 2600 Alien#Score#5699.81$Atari Games#Atari 2600 Alien#Score#4990.91$Atari Games#Atari 2600 Video Pinball#Score#543504$Atari Games#Atari 2600 Boxing#Score#94.3$Atari Games#Atari 2600 Boxing#Score#93.94$Atari Games#Atari 2600 Battle Zone#Score#34583.07$Atari Games#Atari 2600 Battle Zone#Score#28789.29$Atari Games#Atari 2600 Chopper Command#Score#5734.93$Atari Games#Atari 2600 Chopper Command#Score#5431.36$Atari Games#Atari 2600 Crazy Climber#Score#130002.71$Atari Games#Atari 2600 Crazy Climber#Score#123410.71$Atari Games#Atari 2600 Name This Game#Score#11025.26$Atari Games#Atari 2600 Name This Game#Score#10431.33$Atari Games#Atari 2600 Centipede#Score#4539.55$Atari Games#Atari 2600 Centipede#Score#4225.18$Atari Games#Atari 2600 Skiing#Score#-13264.51$Atari Games#Atari 2600 Seaquest#Score#13230.74$Atari Games#Atari 2600 Seaquest#Score#8670.5$Atari Games#Atari 2600 Frostbite#Score#3248.96$Atari Games#Atari 2600 Frostbite#Score#2305.82$Atari Games#Atari 2600 Up and Down#Score#13909.74$Atari Games#Atari 2600 Bank Heist#Score#874.99$Atari Games#Atari 2600 Bank Heist#Score#633.63$Atari Games#Atari 2600 Venture#Score#198.69$Atari Games#Atari 2600 Space Invaders#Score#3460.79$Atari Games#Atari 2600 Space Invaders#Score#3277.59$Atari Games#Atari 2600 James Bond#Score#848.46$Atari Games#Atari 2600 James Bond#Score#772.09$Atari Games#Atari 2600 Road Runner#Score#52351.23$Atari Games#Atari 2600 HERO#Score#24788.86$Atari Games#Atari 2600 HERO#Score#24175.79$Atari Games#Atari 2600 Amidar#Score#1557.43$Atari Games#Atari 2600 Amidar#Score#1451.65$Atari Games#Atari 2600 Asteroids#Score#1924.42$Atari Games#Atari 2600 Asteroids#Score#1673.52$Atari Games#Atari 2600 Atlantis#Score#1465250$Atari Games#Atari 2600 Atlantis#Score#553591.67$Atari Games#Atari 2600 Pong#Score#19.76$Atari Games#Atari 2600 Pong#Score#19.66$Atari Games#Atari 2600 Time Pilot#Score#8969.12
1507.04296v2.pdf	Atari Games#Atari 2600 Tennis#Score#-0.7$Atari Games#Atari 2600 Double Dunk#Score#-11.3$Atari Games#Atari 2600 Montezuma's Revenge#Score#84$Atari Games#Atari 2600 Demon Attack#Score#14880.1$Atari Games#Atari 2600 Krull#Score#6363.1$Atari Games#Atari 2600 Freeway#Score#10.2$Atari Games#Atari 2600 Zaxxon#Score#6159.4$Atari Games#Atari 2600 Gravitar#Score#538.4$Atari Games#Atari 2600 Kangaroo#Score#1431.0$Atari Games#Atari 2600 Kung-Fu Master#Score#20620.0$Atari Games#Atari 2600 Ice Hockey#Score#-1.7$Atari Games#Atari 2600 Private Eye#Score#2598.6$Atari Games#Atari 2600 Beam Rider#Score#3822.1$Atari Games#Atari 2600 Breakout#Score#313.0$Atari Games#Atari 2600 Q*Bert#Score#7089.8$Atari Games#Atari 2600 Wizard of Wor#Score#10431.0$Atari Games#Atari 2600 Star Gunner#Score#14919.2$Atari Games#Atari 2600 Assault#Score#1195.8$Atari Games#Atari 2600 Tutankham#Score#118.5$Atari Games#Atari 2600 River Raid#Score#5310.3$Atari Games#Atari 2600 Bowling#Score#54$Atari Games#Atari 2600 Gopher#Score#4373.0$Atari Games#Atari 2600 Asterix#Score#3324.7$Atari Games#Atari 2600 Enduro#Score#71.0$Atari Games#Atari 2600 Fishing Derby#Score#4.6$Atari Games#Atari 2600 Ms. Pacman#Score#1263.0$Atari Games#Atari 2600 Robotank#Score#61.8$Atari Games#Atari 2600 Alien#Score#813.5$Atari Games#Atari 2600 Video Pinball#Score#112093.4$Atari Games#Atari 2600 Boxing#Score#74.2$Atari Games#Atari 2600 Battle Zone#Score#19938.0$Atari Games#Atari 2600 Chopper Command#Score#3191.8$Atari Games#Atari 2600 Crazy Climber#Score#65451.0$Atari Games#Atari 2600 Name This Game#Score#9238.5$Atari Games#Atari 2600 Centipede#Score#6296.9$Atari Games#Atari 2600 Seaquest#Score#10145.9$Atari Games#Atari 2600 Frostbite#Score#426.6$Atari Games#Atari 2600 Up and Down#Score#8747.7$Atari Games#Atari 2600 Bank Heist#Score#399.4$Atari Games#Atari 2600 Venture#Score#523.4$Atari Games#Atari 2600 Space Invaders#Score#1183.3$Atari Games#Atari 2600 James Bond#Score#444.0$Atari Games#Atari 2600 Road Runner#Score#43079.8$Atari Games#Atari 2600 HERO#Score#8963.4$Atari Games#Atari 2600 Amidar#Score#189.2$Atari Games#Atari 2600 Asteroids#Score#933.6$Atari Games#Atari 2600 Atlantis#Score#629166.5$Atari Games#Atari 2600 Pong#Score#16.7$Atari Games#Atari 2600 Time Pilot#Score#8267.8
1602.01783v2.pdf	Atari Games#Atari 2600 Tennis#Score#-6.3$Atari Games#Atari 2600 Tennis#Score#-6.4$Atari Games#Atari 2600 Tennis#Score#-10.2$Atari Games#Atari 2600 Double Dunk#Score#0.1$Atari Games#Atari 2600 Double Dunk#Score#-0.1$Atari Games#Atari 2600 Montezuma's Revenge#Score#67$Atari Games#Atari 2600 Montezuma's Revenge#Score#53$Atari Games#Atari 2600 Montezuma's Revenge#Score#41$Atari Games#Atari 2600 Demon Attack#Score#115201.9$Atari Games#Atari 2600 Demon Attack#Score#113308.4$Atari Games#Atari 2600 Demon Attack#Score#84997.5$Atari Games#Atari 2600 Krull#Score#8066.6$Atari Games#Atari 2600 Krull#Score#5911.4$Atari Games#Atari 2600 Krull#Score#5560.0$Atari Games#Atari 2600 Freeway#Score#0.1$Atari Games#Atari 2600 Zaxxon#Score#24622.0$Atari Games#Atari 2600 Zaxxon#Score#23519.0$Atari Games#Atari 2600 Zaxxon#Score#2659.0$Atari Games#Atari 2600 Gravitar#Score#320.0$Atari Games#Atari 2600 Gravitar#Score#303.5$Atari Games#Atari 2600 Gravitar#Score#269.5$Atari Games#Atari 2600 Kangaroo#Score#125.0$Atari Games#Atari 2600 Kangaroo#Score#106.0$Atari Games#Atari 2600 Kangaroo#Score#94.0$Atari Games#Atari 2600 Kung-Fu Master#Score#40835.0$Atari Games#Atari 2600 Kung-Fu Master#Score#28819.0$Atari Games#Atari 2600 Kung-Fu Master#Score#3046.0$Atari Games#Atari 2600 Ice Hockey#Score#-1.7$Atari Games#Atari 2600 Ice Hockey#Score#-2.8$Atari Games#Atari 2600 Ice Hockey#Score#-4.7$Atari Games#Atari 2600 Private Eye#Score#421.1$Atari Games#Atari 2600 Private Eye#Score#206.9$Atari Games#Atari 2600 Private Eye#Score#194.4$Atari Games#Atari 2600 Beam Rider#Score#24622.2$Atari Games#Atari 2600 Beam Rider#Score#22707.9$Atari Games#Atari 2600 Beam Rider#Score#13235.9$Atari Games#Atari 2600 Breakout#Score#766.8$Atari Games#Atari 2600 Breakout#Score#681.9$Atari Games#Atari 2600 Breakout#Score#551.6$Atari Games#Atari 2600 Q*Bert#Score#21307.5$Atari Games#Atari 2600 Q*Bert#Score#15148.8$Atari Games#Atari 2600 Q*Bert#Score#13752.3$Atari Games#Atari 2600 Wizard of Wor#Score#18082.0$Atari Games#Atari 2600 Wizard of Wor#Score#17244.0$Atari Games#Atari 2600 Wizard of Wor#Score#5278.0$Atari Games#Atari 2600 Star Gunner#Score#164766.0$Atari Games#Atari 2600 Star Gunner#Score#138218.0$Atari Games#Atari 2600 Star Gunner#Score#64393.0$Atari Games#Atari 2600 Assault#Score#14497.9$Atari Games#Atari 2600 Assault#Score#5474.9$Atari Games#Atari 2600 Assault#Score#3746.1$Atari Games#Atari 2600 Tutankham#Score#156.3$Atari Games#Atari 2600 Tutankham#Score#144.2$Atari Games#Atari 2600 Tutankham#Score#26.1$Atari Games#Atari 2600 River Raid#Score#12201.8$Atari Games#Atari 2600 River Raid#Score#10001.2$Atari Games#Atari 2600 River Raid#Score#6591.9$Atari Games#Atari 2600 Bowling#Score#41.8$Atari Games#Atari 2600 Bowling#Score#36.2$Atari Games#Atari 2600 Bowling#Score#35.1$Atari Games#Atari 2600 Berzerk#Score#1433.4$Atari Games#Atari 2600 Berzerk#Score#862.2$Atari Games#Atari 2600 Berzerk#Score#817.9$Atari Games#Atari 2600 Gopher#Score#17106.8$Atari Games#Atari 2600 Gopher#Score#10022.8$Atari Games#Atari 2600 Gopher#Score#8442.8$Atari Games#Atari 2600 Asterix#Score#22140.5$Atari Games#Atari 2600 Asterix#Score#17244.5$Atari Games#Atari 2600 Asterix#Score#6723$Atari Games#Atari 2600 Enduro#Score#-82.2$Atari Games#Atari 2600 Enduro#Score#-82.5$Atari Games#Atari 2600 Fishing Derby#Score#22.6$Atari Games#Atari 2600 Fishing Derby#Score#18.8$Atari Games#Atari 2600 Fishing Derby#Score#13.6$Atari Games#Atari 2600 Ms. Pacman#Score#850.7$Atari Games#Atari 2600 Ms. Pacman#Score#653.7$Atari Games#Atari 2600 Ms. Pacman#Score#594.4$Atari Games#Atari 2600 Robotank#Score#32.8$Atari Games#Atari 2600 Robotank#Score#2.6$Atari Games#Atari 2600 Robotank#Score#2.3$Atari Games#Atari 2600 Alien#Score#945.3$Atari Games#Atari 2600 Alien#Score#518.4$Atari Games#Atari 2600 Alien#Score#182.1$Atari Games#Atari 2600 Video Pinball#Score#470310.5$Atari Games#Atari 2600 Video Pinball#Score#331628.1$Atari Games#Atari 2600 Video Pinball#Score#185852.6$Atari Games#Atari 2600 Boxing#Score#59.8$Atari Games#Atari 2600 Boxing#Score#37.3$Atari Games#Atari 2600 Boxing#Score#33.7$Atari Games#Atari 2600 Battle Zone#Score#20760.0$Atari Games#Atari 2600 Battle Zone#Score#12950.0$Atari Games#Atari 2600 Battle Zone#Score#11340.0$Atari Games#Atari 2600 Chopper Command#Score#10150.0$Atari Games#Atari 2600 Chopper Command#Score#7021.0$Atari Games#Atari 2600 Chopper Command#Score#4669.0$Atari Games#Atari 2600 Crazy Climber#Score#138518.0$Atari Games#Atari 2600 Crazy Climber#Score#112646.0$Atari Games#Atari 2600 Crazy Climber#Score#101624.0$Atari Games#Atari 2600 Name This Game#Score#12093.7$Atari Games#Atari 2600 Name This Game#Score#10476.1$Atari Games#Atari 2600 Name This Game#Score#5614.0$Atari Games#Atari 2600 Centipede#Score#3755.8$Atari Games#Atari 2600 Centipede#Score#3306.5$Atari Games#Atari 2600 Centipede#Score#1997.0$Atari Games#Atari 2600 Seaquest#Score#2355.4$Atari Games#Atari 2600 Seaquest#Score#2300.2$Atari Games#Atari 2600 Seaquest#Score#1326.1$Atari Games#Atari 2600 Frostbite#Score#197.6$Atari Games#Atari 2600 Frostbite#Score#190.5$Atari Games#Atari 2600 Frostbite#Score#180.1$Atari Games#Atari 2600 Up and Down#Score#105728.7$Atari Games#Atari 2600 Up and Down#Score#74705.7$Atari Games#Atari 2600 Up and Down#Score#54525.4$Atari Games#Atari 2600 Bank Heist#Score#970.1$Atari Games#Atari 2600 Bank Heist#Score#946.0$Atari Games#Atari 2600 Bank Heist#Score#932.8$Atari Games#Atari 2600 Venture#Score#25.0$Atari Games#Atari 2600 Venture#Score#23.0$Atari Games#Atari 2600 Venture#Score#19.0$Atari Games#Atari 2600 Space Invaders#Score#23846.0$Atari Games#Atari 2600 Space Invaders#Score#15730.5$Atari Games#Atari 2600 Space Invaders#Score#2214.7$Atari Games#Atari 2600 James Bond#Score#613.0$Atari Games#Atari 2600 James Bond#Score#541.0$Atari Games#Atari 2600 James Bond#Score#351.5$Atari Games#Atari 2600 Road Runner#Score#73949.0$Atari Games#Atari 2600 Road Runner#Score#34216.0$Atari Games#Atari 2600 Road Runner#Score#31769.0$Atari Games#Atari 2600 HERO#Score#32464.1$Atari Games#Atari 2600 HERO#Score#28889.5$Atari Games#Atari 2600 HERO#Score#28765.8$Atari Games#Atari 2600 Amidar#Score#283.9$Atari Games#Atari 2600 Amidar#Score#263.9$Atari Games#Atari 2600 Amidar#Score#173.0$Atari Games#Atari 2600 Asteroids#Score#5093.1$Atari Games#Atari 2600 Asteroids#Score#4474.5$Atari Games#Atari 2600 Asteroids#Score#3009.4$Atari Games#Atari 2600 Atlantis#Score#911091.0$Atari Games#Atari 2600 Atlantis#Score#875822.0$Atari Games#Atari 2600 Atlantis#Score#772392.0$Atari Games#Atari 2600 Pong#Score#11.4$Atari Games#Atari 2600 Pong#Score#10.7$Atari Games#Atari 2600 Pong#Score#5.6$Atari Games#Atari 2600 Time Pilot#Score#27202.0$Atari Games#Atari 2600 Time Pilot#Score#12679.0$Atari Games#Atari 2600 Time Pilot#Score#5825.0
1703.03864v2.pdf	Atari Games#Atari 2600 Tennis#Score#-4.5$Atari Games#Atari 2600 Double Dunk#Score#0.2$Atari Games#Atari 2600 Demon Attack#Score#1166.5$Atari Games#Atari 2600 Krull#Score#8647.2$Atari Games#Atari 2600 Freeway#Score#31.0$Atari Games#Atari 2600 Zaxxon#Score#6380.0$Atari Games#Atari 2600 Gravitar#Score#805.0$Atari Games#Atari 2600 Kangaroo#Score#11200.0$Atari Games#Atari 2600 Ice Hockey#Score#-4.1$Atari Games#Atari 2600 Private Eye#Score#100.0$Atari Games#Atari 2600 Beam Rider#Score#744.0$Atari Games#Atari 2600 Breakout#Score#9.5$Atari Games#Atari 2600 Q*Bert#Score#147.5$Atari Games#Atari 2600 Wizard of Wor#Score#3480.0$Atari Games#Atari 2600 Star Gunner#Score#1470.0$Atari Games#Atari 2600 Assault#Score#1673.9$Atari Games#Atari 2600 Tutankham#Score#130.3$Atari Games#Atari 2600 River Raid#Score#5009.0$Atari Games#Atari 2600 Bowling#Score#30$Atari Games#Atari 2600 Berzerk#Score#686.0$Atari Games#Atari 2600 Gopher#Score#582.0$Atari Games#Atari 2600 Asterix#Score#1440$Atari Games#Atari 2600 Enduro#Score#95.0$Atari Games#Atari 2600 Fishing Derby#Score#-49.0$Atari Games#Atari 2600 Robotank#Score#11.9$Atari Games#Atari 2600 Alien#Score#994.0$Atari Games#Atari 2600 Video Pinball#Score#22834.8$Atari Games#Atari 2600 Boxing#Score#49.8$Atari Games#Atari 2600 Battle Zone#Score#16600.0$Atari Games#Atari 2600 Chopper Command#Score#3710.0$Atari Games#Atari 2600 Crazy Climber#Score#26430.0$Atari Games#Atari 2600 Name This Game#Score#4503.0$Atari Games#Atari 2600 Centipede#Score#7783.9$Atari Games#Atari 2600 Seaquest#Score#1390.0$Atari Games#Atari 2600 Frostbite#Score#370.0$Atari Games#Atari 2600 Up and Down#Score#67974.0$Atari Games#Atari 2600 Bank Heist#Score#225.0$Atari Games#Atari 2600 Venture#Score#760.0$Atari Games#Atari 2600 Space Invaders#Score#678.5$Atari Games#Atari 2600 Road Runner#Score#16590.0$Atari Games#Atari 2600 Amidar#Score#112.0$Atari Games#Atari 2600 Asteroids#Score#1562.0$Atari Games#Atari 2600 Atlantis#Score#1267410.0$Atari Games#Atari 2600 Pong#Score#21.0$Atari Games#Atari 2600 Time Pilot#Score#4970.0
1807.00442v4.pdf	Atari Games#Atari 2600 Tennis#Score#-8.32$Atari Games#Atari 2600 Double Dunk#Score#-7.89$Atari Games#Atari 2600 Montezuma's Revenge#Score#0$Atari Games#Atari 2600 Demon Attack#Score#61147.33$Atari Games#Atari 2600 Krull#Score#7715.68$Atari Games#Atari 2600 Freeway#Score#21.21$Atari Games#Atari 2600 Zaxxon#Score#9472$Atari Games#Atari 2600 Gravitar#Score#557.17$Atari Games#Atari 2600 Kangaroo#Score#3891.67$Atari Games#Atari 2600 Kung-Fu Master#Score#33728$Atari Games#Atari 2600 Ice Hockey#Score#-4.12$Atari Games#Atari 2600 Private Eye#Score#79.67$Atari Games#Atari 2600 Beam Rider#Score#4549$Atari Games#Atari 2600 Breakout#Score#458.41$Atari Games#Atari 2600 Q*Bert#Score#15396.67$Atari Games#Atari 2600 Wizard of Wor#Score#4704$Atari Games#Atari 2600 Star Gunner#Score#48984$Atari Games#Atari 2600 Assault#Score#5400.13$Atari Games#Atari 2600 Tutankham#Score#241.21$Atari Games#Atari 2600 River Raid#Score#8052.23$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#38.99$Atari Games#Atari 2600 Gopher#Score#6207$Atari Games#Atari 2600 Asterix#Score#4310.67$Atari Games#Atari 2600 Enduro#Score#459.85$Atari Games#Atari 2600 Fishing Derby#Score#28.99$Atari Games#Atari 2600 Ms. Pacman#Score#1683.87$Atari Games#Atari 2600 Robotank#Score#4.6$Atari Games#Atari 2600 Alien#Score#1510.8$Atari Games#Atari 2600 Video Pinball#Score#37780.7$Atari Games#Atari 2600 Boxing#Score#97.23$Atari Games#Atari 2600 Battle Zone#Score#15466.67$Atari Games#Atari 2600 Chopper Command#Score#6308.33$Atari Games#Atari 2600 Crazy Climber#Score#120247.33$Atari Games#Atari 2600 Name This Game#Score#6065.63$Atari Games#Atari 2600 Centipede#Score#3315.44$Atari Games#Atari 2600 Seaquest#Score#1807.47$Atari Games#Atari 2600 Frostbite#Score#316.87$Atari Games#Atari 2600 Up and Down#Score#242701.51$Atari Games#Atari 2600 Bank Heist#Score#1212.23$Atari Games#Atari 2600 Venture#Score#36.33$Atari Games#Atari 2600 Space Invaders#Score#1216.15$Atari Games#Atari 2600 James Bond#Score#358.54$Atari Games#Atari 2600 Road Runner#Score#44679.67$Atari Games#Atari 2600 Amidar#Score#729.15$Atari Games#Atari 2600 Asteroids#Score#2488.1$Atari Games#Atari 2600 Atlantis#Score#2193605.67$Atari Games#Atari 2600 Pong#Score#20.5$Atari Games#Atari 2600 Time Pilot#Score#3770.33$MuJoCo Games#InvertedDoublePendulum#Mean#4907.64$MuJoCo Games#Walker2d#Mean#3966.01$MuJoCo Games#Swimmer#Mean#111.08$MuJoCo Games#InvertedPendulum#Mean#741.94$MuJoCo Games#Reacher#Mean#-4.29$MuJoCo Games#HalfCheetah#Mean#3184.54$MuJoCo Games#Hopper#Mean#1452.09
1806.05635v1.pdf	Atari Games#Atari 2600 Tennis#Score#-17.3$Atari Games#Atari 2600 Double Dunk#Score#21.5$Atari Games#Atari 2600 Montezuma's Revenge#Score#1100$Atari Games#Atari 2600 Demon Attack#Score#10140.5$Atari Games#Atari 2600 Krull#Score#10614.6$Atari Games#Atari 2600 Freeway#Score#32.2$Atari Games#Atari 2600 Zaxxon#Score#9164.2$Atari Games#Atari 2600 Gravitar#Score#1874.2$Atari Games#Atari 2600 Kangaroo#Score#2888.3$Atari Games#Atari 2600 Kung-Fu Master#Score#34449.2$Atari Games#Atari 2600 Ice Hockey#Score#-2.4$Atari Games#Atari 2600 Private Eye#Score#661.2$Atari Games#Atari 2600 Beam Rider#Score#2366.2$Atari Games#Atari 2600 Breakout#Score#452$Atari Games#Atari 2600 Q*Bert#Score#104975.6$Atari Games#Atari 2600 Wizard of Wor#Score#7088.3$Atari Games#Atari 2600 Star Gunner#Score#31309.2$Atari Games#Atari 2600 Assault#Score#1812$Atari Games#Atari 2600 Tutankham#Score#340.5$Atari Games#Atari 2600 River Raid#Score#14306.1$Atari Games#Atari 2600 Bowling#Score#31.1$Atari Games#Atari 2600 Gopher#Score#23304.2$Atari Games#Atari 2600 Asterix#Score#17984.2$Atari Games#Atari 2600 Enduro#Score#1205.1$Atari Games#Atari 2600 Fishing Derby#Score#55.8$Atari Games#Atari 2600 Ms. Pacman#Score#4025.1$Atari Games#Atari 2600 Robotank#Score#10.5$Atari Games#Atari 2600 Alien#Score#2242.2$Atari Games#Atari 2600 Video Pinball#Score#461522.4$Atari Games#Atari 2600 Boxing#Score#99.6$Atari Games#Atari 2600 Battle Zone#Score#25075$Atari Games#Atari 2600 Chopper Command#Score#6710$Atari Games#Atari 2600 Crazy Climber#Score#130185.8$Atari Games#Atari 2600 Name This Game#Score#14958.2$Atari Games#Atari 2600 Centipede#Score#7559.5$Atari Games#Atari 2600 Seaquest#Score#2456.5$Atari Games#Atari 2600 Frostbite#Score#6289.8$Atari Games#Atari 2600 Up and Down#Score#53314.6$Atari Games#Atari 2600 Bank Heist#Score#1137.8$Atari Games#Atari 2600 Venture#Score#0$Atari Games#Atari 2600 Space Invaders#Score#2951.7$Atari Games#Atari 2600 James Bond#Score#310.8$Atari Games#Atari 2600 Road Runner#Score#57071.7$Atari Games#Atari 2600 HERO#Score#33156.7$Atari Games#Atari 2600 Amidar#Score#1362$Atari Games#Atari 2600 Asteroids#Score#2259.4$Atari Games#Atari 2600 Atlantis#Score#3084781.7$Atari Games#Atari 2600 Pong#Score#20.9$Atari Games#Atari 2600 Time Pilot#Score#10811.7
2206.10027v1.pdf	Atari Games#Atari 2600 Tennis#Score#-10.9$Atari Games#Atari 2600 Double Dunk#Score#-1.3$Atari Games#Atari 2600 Phoenix#Score#391085$Atari Games#Atari 2600 Yars Revenge#Score#564513$Atari Games#Atari 2600 Montezuma's Revenge#Score#0$Atari Games#Atari 2600 Demon Attack#Score#97909$Atari Games#Atari 2600 Krull#Score#10956$Atari Games#Atari 2600 Freeway#Score#33$Atari Games#Atari 2600 Zaxxon#Score#22588$Atari Games#Atari 2600 Gravitar#Score#2190$Atari Games#Atari 2600 Kangaroo#Score#14373$Atari Games#Atari 2600 Kung-Fu Master#Score#110962$Atari Games#Atari 2600 Ice Hockey#Score#7.2$Atari Games#Atari 2600 Surround#Score#5.3$Atari Games#Atari 2600 Private Eye#Score#100$Atari Games#Atari 2600 Beam Rider#Score#20393$Atari Games#Atari 2600 Breakout#Score#626$Atari Games#Atari 2600 Q*Bert#Score#52398$Atari Games#Atari 2600 Wizard of Wor#Score#20851$Atari Games#Atari 2600 Star Gunner#Score#104125$Atari Games#Atari 2600 Solaris#Score#2225$Atari Games#Atari 2600 Assault#Score#16293$Atari Games#Atari 2600 Tutankham#Score#127$Atari Games#Atari 2600 Defender#Score#152768$Atari Games#Atari 2600 River Raid#Score#16789$Atari Games#Atari 2600 Pitfall!#Score#0$Atari Games#Atari 2600 Bowling#Score#181$Atari Games#Atari 2600 Berzerk#Score#19789$Atari Games#Atari 2600 Gopher#Score#80104$Atari Games#Atari-57#Medium Human-Normalized Score#311$Atari Games#Atari 2600 Asterix#Score#323965$Atari Games#Atari 2600 Enduro#Score#2059$Atari Games#Atari 2600 Fishing Derby#Score#57.4$Atari Games#Atari 2600 Ms. Pacman#Score#5894$Atari Games#Atari 2600 Robotank#Score#64.8$Atari Games#Atari 2600 Alien#Score#5021$Atari Games#Atari 2600 Video Pinball#Score#505392$Atari Games#Atari 2600 Boxing#Score#99.9$Atari Games#Atari 2600 Battle Zone#Score#71003$Atari Games#Atari 2600 Chopper Command#Score#31181$Atari Games#Atari 2600 Crazy Climber#Score#131623$Atari Games#Atari 2600 Name This Game#Score#20226$Atari Games#Atari 2600 Centipede#Score#100194$Atari Games#Atari 2600 Skiing#Score#-29974$Atari Games#Atari 2600 Seaquest#Score#4146$Atari Games#Atari 2600 Frostbite#Score#320$Atari Games#Atari 2600 Up and Down#Score#291934$Atari Games#Atari 2600 Bank Heist#Score#1286$Atari Games#Atari 2600 Venture#Score#0$Atari Games#Atari 2600 Space Invaders#Score#2731$Atari Games#Atari 2600 James Bond#Score#14102$Atari Games#Atari 2600 Road Runner#Score#61713$Atari Games#Atari 2600 HERO#Score#24904$Atari Games#Atari 2600 Amidar#Score#1025$Atari Games#Atari 2600 Asteroids#Score#165973$Atari Games#Atari 2600 Atlantis#Score#932559$Atari Games#Atari 2600 Pong#Score#19.7$Atari Games#Atari 2600 Time Pilot#Score#12774
1704.04651v2.pdf	Atari Games#Atari 2600 Double Dunk#Score#23.0$Atari Games#Atari 2600 Demon Attack#Score#115154.0$Atari Games#Atari 2600 Beam Rider#Score#11033.4$Atari Games#Atari 2600 Breakout#Score#514.8$Atari Games#Atari 2600 Assault#Score#8323.3$Atari Games#Atari 2600 Defender#Score#223025.0$Atari Games#Atari 2600 Bowling#Score#81.0$Atari Games#Atari 2600 Berzerk#Score#2303.1$Atari Games#Atari-57#Medium Human-Normalized Score#187.0%$Atari Games#Atari 2600 Asterix#Score#205914.0$Atari Games#Atari 2600 Enduro#Score#2224.2$Atari Games#Atari 2600 Alien#Score#12689.1$Atari Games#Atari 2600 Boxing#Score#99.4$Atari Games#Atari 2600 Battle Zone#Score#64070.0$Atari Games#Atari 2600 Chopper Command#Score#107779.0$Atari Games#Atari 2600 Crazy Climber#Score#236422.0$Atari Games#Atari 2600 Centipede#Score#3422.0$Atari Games#Atari 2600 Bank Heist#Score#1259.7$Atari Games#Atari 2600 Amidar#Score#1015.8$Atari Games#Atari 2600 Asteroids#Score#3726.1$Atari Games#Atari 2600 Atlantis#Score#302831.0
2004.12919v6.pdf	Atari Games#Atari games#Mean Human Normalized Score#4989.94%$Atari Games#Atari 2600 Montezuma's Revenge#Score#43791$Atari Games#Atari 2600 Freeway#Score#34$Atari Games#Atari 2600 Gravitar#Score#7588$Atari Games#Atari 2600 Private Eye#Score#95756$Atari Games#Atari 2600 Solaris#Score#19671$Atari Games#Atari 2600 Pitfall!#Score#6954$Atari Games#Atari 2600 Bowling#Score#260$Atari Games#Atari 2600 Berzerk#Score#197376$Atari Games#Atari 2600 Centipede#Score#1422628$Atari Games#Atari 2600 Skiing#Score#-3660$Atari Games#Atari 2600 Venture#Score#2281
2002.06038v1.pdf	Atari Games#Atari games#Mean Human Normalized Score#3169.90%$Atari Games#atari game#Human World Record Breakthrough#8
1909.11583v2.pdf	Atari Games#Atari games#Mean Human Normalized Score#1741.36%$Atari Games#Atari-57#Medium Human-Normalized Score#431%$Atari Games#Atari-57#Human World Record Breakthrough#7$Atari Games#Atari-57#Mean Human Normalized Score#1741.36%
1710.02298v1.pdf	Atari Games#Atari games#Mean Human Normalized Score#873.97%$Atari Games#atari game#Human World Record Breakthrough#4$Atari Games#Atari-57#Medium Human-Normalized Score#223.0%$Atari Games#Atari-57#Human World Record Breakthrough#4$Atari Games#Atari-57#Mean Human Normalized Score#873.97%$Atari Games#Atari 2600 Ms. Pacman#Score#2,570.2$Atari Games#Atari 2600 Space Invaders#Score#12,629.0$Montezuma's Revenge#Atari 2600 Montezuma's Revenge#Average Return (NoOp)#384
1903.00374v4.pdf	Atari Games#Atari games#Mean Human Normalized Score#25.3%
1911.02140v3.pdf	Atari Games#Atari 2600 Phoenix#Score#174077.5$Atari Games#Atari 2600 Gravitar#Score#1406.0$Atari Games#Atari 2600 Kung-Fu Master#Score#111138.5$Atari Games#Atari 2600 Ice Hockey#Score#17.3$Atari Games#Atari 2600 Breakout#Score#854.2$Atari Games#Atari 2600 Wizard of Wor#Score#44782.6$Atari Games#Atari 2600 Star Gunner#Score#131981.2$Atari Games#Atari 2600 River Raid#Score#23560.7$Atari Games#Atari 2600 Bowling#Score#102.3$Atari Games#Atari 2600 Berzerk#Score#12422.2$Atari Games#Atari 2600 Asterix#Score#578388.5$Atari Games#Atari 2600 Fishing Derby#Score#52.7$Atari Games#Atari 2600 Ms. Pacman#Score#7631.9$Atari Games#Atari 2600 Robotank#Score#75.7$Atari Games#Atari 2600 Alien#Score#16754.6$Atari Games#Atari 2600 Battle Zone#Score#87928.6$Atari Games#Atari 2600 Chopper Command#Score#876460.0$Atari Games#Atari 2600 Crazy Climber#Score#223470.6$Atari Games#Atari 2600 Skiing#Score#-9085.3$Atari Games#Atari 2600 Frostbite#Score#214060$Atari Games#Atari 2600 Space Invaders#Score#46498.3$Atari Games#Atari 2600 James Bond#Score#87291.7$Atari Games#Atari 2600 HERO#Score#30926.2$Atari Games#Atari 2600 Amidar#Score#3165.3$Atari Games#Atari 2600 Asteroids#Score#4553.0
1806.01363v2.pdf	Atari Games#Atari 2600 Phoenix#Score#4600$Atari Games#Atari 2600 Demon Attack#Score#325$Atari Games#Atari 2600 Kangaroo#Score#1200$Atari Games#Atari 2600 Q*Bert#Score#1250$Atari Games#Atari 2600 Fishing Derby#Score#-10$Atari Games#Atari 2600 Name This Game#Score#920$Atari Games#Atari 2600 Seaquest#Score#320$Atari Games#Atari 2600 Frostbite#Score#300$Atari Games#Atari 2600 Space Invaders#Score#830$Atari Games#Atari 2600 Time Pilot#Score#4600
1806.07857v3.pdf	Atari Games#Atari 2600 Yars Revenge#Score#60577$Atari Games#Atari 2600 Bowling#Score#179$Atari Games#Atari 2600 Venture#Score#1350
1901.10995v4.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#43763$Atari Games#atari game#Human World Record Breakthrough#17$Atari Games#Atari 2600 Pitfall!#Score#107363
1810.12894v1.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#8152$Atari Games#Atari 2600 Gravitar#Score#3906$Atari Games#Atari 2600 Private Eye#Score#8666$Atari Games#Atari 2600 Solaris#Score#3282$Atari Games#Atari 2600 Pitfall!#Score#-3$Atari Games#Atari 2600 Venture#Score#1859
1811.01483v3.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#6635
1703.01310v2.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#3705.5$Atari Games#Atari 2600 Freeway#Score#33.0$Atari Games#Atari 2600 Freeway#Score#31.7$Atari Games#Atari 2600 Gravitar#Score#498.3$Atari Games#Atari 2600 Gravitar#Score#238.0$Atari Games#Atari 2600 Private Eye#Score#8358.7$Atari Games#Atari 2600 Private Eye#Score#206.0$Atari Games#Atari 2600 Venture#Score#82.2$Atari Games#Atari 2600 Venture#Score#48.0
1606.01868v2.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#3459$Atari Games#Atari 2600 Montezuma's Revenge#Score#273.7$Atari Games#Atari 2600 Freeway#Score#30.48$Atari Games#Atari 2600 Gravitar#Score#238.68$Atari Games#Atari 2600 Private Eye#Score#99.32$Atari Games#Atari 2600 Venture#Score#0.0
1706.08090v1.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#2745.4$Atari Games#Atari 2600 Montezuma's Revenge#Score#399.5$Atari Games#Atari 2600 Freeway#Score#29.9$Atari Games#Atari 2600 Freeway#Score#0.0$Atari Games#Atari 2600 Q*Bert#Score#4111.8$Atari Games#Atari 2600 Q*Bert#Score#3895.3$Atari Games#Atari 2600 Frostbite#Score#2770.1$Atari Games#Atari 2600 Frostbite#Score#1394.3$Atari Games#Atari 2600 Venture#Score#1169.2$Atari Games#Atari 2600 Venture#Score#0.0
1808.04355v1.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#2504.6$Atari Games#Atari 2600 Freeway#Score#32.8$Atari Games#Atari 2600 Gravitar#Score#1165.1$Atari Games#Atari 2600 Private Eye#Score#3036.5$Atari Games#Atari 2600 Venture#Score#416
1807.11622v4.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#1778.8$Atari Games#Atari 2600 Montezuma's Revenge#Score#1778.6$Atari Games#Atari 2600 Freeway#Score#29.5$Atari Games#Atari 2600 Gravitar#Score#1078.3$Atari Games#Atari 2600 Private Eye#Score#99.1$Atari Games#Atari 2600 Solaris#Score#2244.6$Atari Games#Atari 2600 Venture#Score#1241.8
1507.00814v3.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#142$Atari Games#Atari 2600 Freeway#Score#27.0$Atari Games#Atari 2600 Q*Bert#Score#15805$Atari Games#Atari 2600 Frostbite#Score#507.0$Atari Games#Atari 2600 Venture#Score#0.0
1611.04717v3.pdf	Atari Games#Atari 2600 Montezuma's Revenge#Score#75$Atari Games#Atari 2600 Freeway#Score#34.0$Atari Games#Atari 2600 Frostbite#Score#5214.0$Atari Games#Atari 2600 Venture#Score#445.0
1707.03497v2.pdf	Atari Games#Atari 2600 Krull#Score#15930$Atari Games#Atari 2600 Q*Bert#Score#14517$Atari Games#Atari 2600 Enduro#Score#382$Atari Games#Atari 2600 Ms. Pacman#Score#2689$Atari Games#Atari 2600 Alien#Score#1429$Atari Games#Atari 2600 Crazy Climber#Score#54119$Atari Games#Atari 2600 Seaquest#Score#5628$Atari Games#Atari 2600 Frostbite#Score#3811$Atari Games#Atari 2600 Amidar#Score#641
2103.02886v2.pdf	Atari Games#Atari 2600 Krull#Score#3277.5$Atari Games#Atari 2600 Q*Bert#Score#4123.5$Atari Games#Atari 2600 Alien#Score#1172.6$Atari Games#Atari 2600 Crazy Climber#Score#28066$Atari Games#Atari 2600 Seaquest#Score#561.2$Atari Games#Atari 2600 Bank Heist#Score#276.6$Atari Games#Atari 2600 Road Runner#Score#11794$Atari Games#Atari 2600 Amidar#Score#250.5
2010.05767v2.pdf	Atari Games#Atari 2600 Freeway#Score#29$Atari Games#Atari 2600 Breakout#Score#11.6$Atari Games#Atari 2600 Crazy Climber#Score#59609.4$Atari Games#Atari 2600 Seaquest#Score#635$Atari Games#Atari 2600 Bank Heist#Score#121.6$Atari Games#Atari 2600 Pong#Score#20.2
2011.14632v3.pdf	Atari Games#Atari 2600 Freeway#Score#22$Atari Games#Atari 2600 Breakout#Score#180.6$Atari Games#Atari 2600 Breakout#Score#161.1$Atari Games#Atari 2600 Breakout#Score#144.4$Atari Games#Atari 2600 Breakout#Score#91.4
1910.07207v2.pdf	Atari Games#Atari 2600 Freeway#Score#4.4$Atari Games#Atari 2600 Kangaroo#Score#29.3$Atari Games#Atari 2600 Beam Rider#Score#432.1$Atari Games#Atari 2600 Breakout#Score#0.7$Atari Games#Atari 2600 Q*Bert#Score#280.5$Atari Games#Atari 2600 Assault#Score#350$Atari Games#Atari 2600 Asterix#Score#272$Atari Games#Atari 2600 Enduro#Score#0.8$Atari Games#Atari 2600 Ms. Pacman#Score#690.9$Atari Games#Atari 2600 Alien#Score#216.9$Atari Games#Atari 2600 Battle Zone#Score#4386.7$Atari Games#Atari 2600 Crazy Climber#Score#3668.7$Atari Games#Atari 2600 Seaquest#Score#211.6$Atari Games#Atari 2600 Frostbite#Score#59.4$Atari Games#Atari 2600 Up and Down#Score#250.7$Atari Games#Atari 2600 Space Invaders#Score#160.8$Atari Games#Atari 2600 James Bond#Score#68.3$Atari Games#Atari 2600 Road Runner#Score#305.3$Atari Games#Atari 2600 Amidar#Score#7.9$Atari Games#Atari 2600 Pong#Score#-20.98
1801.02852v2.pdf	Atari Games#Atari 2600 Beam Rider#Score#14900$Atari Games#Atari 2600 Breakout#Score#350$Atari Games#Atari 2600 Boxing#Score#98$Atari Games#Atari 2600 Seaquest#Score#1832$Atari Games#Atari 2600 Space Invaders#Score#650$Atari Games#Atari 2600 Pong#Score#20
1312.5602v1.pdf	Atari Games#Atari 2600 Beam Rider#Score#5184$Atari Games#Atari 2600 Breakout#Score#225$Atari Games#Atari 2600 Q*Bert#Score#4500$Atari Games#Atari 2600 Enduro#Score#661$Atari Games#Atari 2600 Seaquest#Score#1740$Atari Games#Atari 2600 Space Invaders#Score#1075$Atari Games#Atari 2600 Pong#Score#21
2106.12142v4.pdf	Atari Games#Atari 2600 Beam Rider#Return#3025$Atari Games#Atari 2600 Q*Bert#Return#12940$Atari Games#Atari 2600 Seaquest#Return#2349$Atari Games#Atari 2600 Space Invaders#Return#507$MuJoCo Games#Walker2d#Mean#5134$MuJoCo Games#Ant#Average Return#4362.9$MuJoCo Games#Humanoid-v2#Return#5227.1
2106.01345v2.pdf	Atari Games#Atari 2600 Breakout#Score#267.5$Atari Games#Atari 2600 Q*Bert#Score#25.1$Atari Games#Atari 2600 Seaquest#Score#2.4$Atari Games#Atari 2600 Pong#Score#106.1
1512.01693v1.pdf	Atari Games#Atari 2600 Breakout#Score#20$Atari Games#Atari 2600 Tutankham#Score#197$Atari Games#Atari 2600 Gopher#Score#5356$Atari Games#Atari 2600 Seaquest#Score#7263$Atari Games#Atari 2600 Space Invaders#Score#650
2104.06159v2.pdf	Atari Games#atari game#Human World Record Breakthrough#5
2008.09685v1.pdf	Atari Games#Atari 2600 Q*Bert#Score#14135$Atari Games#Atari 2600 Q*Bert#Best Score#19750$Atari Games#Atari 2600 River Raid#Score#3868$Atari Games#Atari 2600 River Raid#Best Score#5080$Atari Games#Atari 2600 Ms. Pacman#Score#8530.4004$Atari Games#Atari 2600 Ms. Pacman#Best Score#11301$Atari Games#Atari 2600 Frostbite#Score#2394$Atari Games#Atari 2600 Frostbite#Best Score#4020$Atari Games#Atari 2600 Space Invaders#Score#1990$Atari Games#Atari 2600 Space Invaders#Best Score#2490$Atari Games#Atari 2600 HERO#Score#11732$Atari Games#Atari 2600 HERO#Best Score#13190
2007.14430v3.pdf	Atari Games#Atari-57#Medium Human-Normalized Score#155%$Atari Games#Atari-57#Mean Human Normalized Score#504%
2101.01857v1.pdf	Montezuma's Revenge#Atari 2600 Montezuma's Revenge#Average Return (NoOp)#1668$Montezuma's Revenge#Atari 2600 Montezuma's Revenge#Average Return (NoOp)#900
2002.07563v5.pdf	Rumour Detection#Sepehr_RumTel01#F-Measure#0.828
1901.03904v4.pdf	Rumour Detection#Sepehr_RumTel01#F-Measure#0.791
1803.11485v2.pdf	Starcraft II#SMAC+#Median Win Rate#%$SMAC+#Off_Distant_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_sequential#Median Win Rate#0.0$SMAC+#Off_Complicated_parallel#Median Win Rate#0.0$SMAC+#Off_Superhard_sequential#Median Win Rate#0.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Off_Hard_sequential#Median Win Rate#96.9$SMAC+#Def_Infantry_sequential#Median Win Rate#96.9$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#75.0$SMAC+#Def_Infantry_parallel#Median Win Rate#95.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#0.0$SMAC+#Off_Complicated_sequential#Median Win Rate#87.5$SMAC+#Def_Outnumbered_parallel#Median Win Rate#30.0$SMAC+#Off_Near_parallel#Median Win Rate#95.0$SMAC+#Off_Near_sequential#Median Win Rate#90.6$SMAC+#Off_Distant_sequential#Median Win Rate#93.8
1708.04782v1.pdf	Starcraft II#CollectMineralShards#Max Score#137$Starcraft II#MoveToBeacon#Max Score#35
1605.02097v2.pdf	Game of Doom#ViZDoom Basic Scenario#Average Score#82.2
1611.02205v2.pdf	SNES Games#F-Zero#Score#5161$SNES Games#F-Zero#Score#3636$SNES Games#F-Zero#Score#3116$SNES Games#Super Mario#Score#20030$SNES Games#Super Mario#Score#16946$SNES Games#Super Mario#Score#11765$SNES Games#Wolfenstein#Score#100$SNES Games#Wolfenstein#Score#83$SNES Games#Wolfenstein#Score#40$SNES Games#Mortal Kombat#Score#169300$SNES Games#Mortal Kombat#Score#83733$SNES Games#Mortal Kombat#Score#56200$SNES Games#Gradius III#Score#16929$SNES Games#Gradius III#Score#12343$SNES Games#Gradius III#Score#7583
1901.00109v3.pdf	Representation Learning#Circle Data#Accuracy#97.3
2204.01108v2.pdf	Representation Learning#Animals-10#1:1 Accuracy#0.745896
2103.15375v2.pdf	Representation Learning#CIFAR10#Accuracy (%)#97.05
2106.10060v1.pdf	Representation Learning#Sports10#Silhouette Score#0.56$Image Classification#Sports10#Validation Accuracy#93.42
2202.06671v2.pdf	Representation Learning#SciDocs#Avg.#81.8$Representation Learning#SciDocs#Avg.#66.6$Representation Learning#SciDocs#Avg.#58.8$Document Classification#SciDocs (MAG)#F1 (micro)#81.4$Document Classification#SciDocs (MeSH)#F1 (micro)#88.7
2004.07180v4.pdf	Representation Learning#SciDocs#Avg.#80.0$Representation Learning#SciDocs#Avg.#76.0$Representation Learning#SciDocs#Avg.#59.6$Document Classification#SciDocs (MAG)#F1 (micro)#82.0$Document Classification#SciDocs (MeSH)#F1 (micro)#86.4
2102.08850v4.pdf	Disentanglement#KITTI-Masks#MCC#80.9$Disentanglement#3DIdent#MCC#98.31
2007.10930v2.pdf	Disentanglement#KITTI-Masks#MCC#79.6$Disentanglement#Natural Sprites#MCC#52.6
1606.07659v3.pdf	Recommendation Systems#Douban#RMSE#0.6911$Recommendation Systems#Douban#RMSE#0.7049$Recommendation Systems#MovieLens 10M#RMSE#0.7767$Recommendation Systems#MovieLens 10M#RMSE#0.7954$Recommendation Systems#MovieLens 1M#RMSE#0.8321$Recommendation Systems#MovieLens 1M#RMSE#0.8574
1902.09362v2.pdf	Recommendation Systems#Douban#NDCG#0.195$Recommendation Systems#Douban#Recall@20#0.1861$Recommendation Systems#Yelp#NDCG#0.1427$Recommendation Systems#Yelp#Recall@20#0.0842$Recommendation Systems#Delicious#NDCG#0.2944$Recommendation Systems#Delicious#Recall@20#0.4066
2206.02626v3.pdf	Recommendation Systems#Douban#AUC#0.9523$Recommendation Systems#Douban#HR@10#0.2356$Recommendation Systems#Douban#HR@100#0.2837$Recommendation Systems#Douban#nDCG@10#0.2494$Recommendation Systems#Douban#nDCG@100#0.2326$Recommendation Systems#Douban#PSP@10#0.0128$Recommendation Systems#Netflix#nDCG@10#0.3059$Recommendation Systems#Netflix#nDCG@100#0.3659$Recommendation Systems#Netflix#Recall@10#0.2969$Recommendation Systems#Netflix#AUC#0.9728$Recommendation Systems#Netflix#PSP@10#0.0375$Recommendation Systems#Netflix#Recall@100#0.5088$Recommendation Systems#MovieLens 1M#HR@10#0.3151$Recommendation Systems#MovieLens 1M#nDCG@10#0.3282$Recommendation Systems#MovieLens 1M#nDCG@100#0.4253$Recommendation Systems#MovieLens 1M#AUC#0.9457$Recommendation Systems#MovieLens 1M#HR@100#0.6005$Recommendation Systems#MovieLens 1M#PSP@10#0.0322
2111.11293v2.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.887$Recommendation Systems#MovieLens 100K#Precision#0.771$Recommendation Systems#MovieLens 100K#Recall#0.799$Recommendation Systems#MovieLens 1M#RMSE#0.833$Recommendation Systems#MovieLens 1M#Precision#0.792$Recommendation Systems#MovieLens 1M#Recall#0.838
2108.12184v1.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.8889$Recommendation Systems#Douban Monti#RMSE#0.7208$Recommendation Systems#MovieLens 1M#RMSE#0.8227
1904.12058v3.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.905$Recommendation Systems#YahooMusic Monti#RMSE#19.1$Recommendation Systems#Douban Monti#RMSE#0.721$Recommendation Systems#Flixster Monti#RMSE#0.872$Recommendation Systems#MovieLens 1M#RMSE#0.857
1706.02263v2.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.905$Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.910$Recommendation Systems#YahooMusic Monti#RMSE#20.5$Recommendation Systems#Douban Monti#RMSE#0.734$Recommendation Systems#MovieLens 10M#RMSE#0.777$Recommendation Systems#Flixster Monti#RMSE#0.917$Recommendation Systems#MovieLens 1M#RMSE#0.832
1803.02879v2.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.91$Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.920$Recommendation Systems#YahooMusic Monti#RMSE#20.0$Recommendation Systems#Douban Monti#RMSE#0.738$Recommendation Systems#Flixster Monti#RMSE#0.908$Recommendation Systems#MovieLens 1M#RMSE#0.860
1908.09393v2.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.9174$Recommendation Systems#Douban Monti#RMSE#0.7323$Recommendation Systems#Flixster Monti#RMSE#0.8857$Recommendation Systems#YahooMusic#RMSE#22.760$Recommendation Systems#YahooMusic#RMSE#22.795
1704.06803v1.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.929$Recommendation Systems#YahooMusic Monti#RMSE#22.4149$Recommendation Systems#Douban Monti#RMSE#0.8012$Recommendation Systems#Flixster Monti#RMSE#0.9258
1408.1717v3.pdf	Recommendation Systems#MovieLens 100K#RMSE (u1 Splits)#0.996
1906.09217v1.pdf	Recommendation Systems#GoodReads-Children#Recall@10#0.1263$Recommendation Systems#GoodReads-Children#nDCG@10#0.113$Recommendation Systems#MovieLens 20M#nDCG@10#0.1195$Recommendation Systems#MovieLens 20M#Recall@10#0.1255$Recommendation Systems#Amazon-Book#Recall@10#0.0429$Recommendation Systems#Amazon-Book#nDCG@10#0.0298$Recommendation Systems#GoodReads-Comics#Recall@10#0.1743$Recommendation Systems#GoodReads-Comics#nDCG@10#0.1927$Recommendation Systems#Amazon-CDs#Recall@10#0.0426$Recommendation Systems#Amazon-CDs#nDCG@10#0.0233
1906.01637v1.pdf	Recommendation Systems#Amazon C&A#Hits@10#0.3436$Recommendation Systems#Amazon C&A#Hits@20#0.4658$Recommendation Systems#Amazon C&A#nDCG@10#0.2019$Recommendation Systems#Amazon C&A#nDCG@20#0.2323$Recommendation Systems#Flixster#Hits@10#0.7309$Recommendation Systems#Flixster#Hits@20#0.8374$Recommendation Systems#Flixster#nDCG@10#0.4986$Recommendation Systems#Flixster#nDCG@20#0.5257$Recommendation Systems#Book-Crossing#Hits@10#0.3329$Recommendation Systems#Book-Crossing#Hits@20#0.4744$Recommendation Systems#Book-Crossing#nDCG@10#0.1865$Recommendation Systems#Book-Crossing#nDCG@20#0.2221$Recommendation Systems#Tradesy#Hits@10#0.3198$Recommendation Systems#Tradesy#Hits@20#0.4505$Recommendation Systems#Tradesy#nDCG@10#0.1767$Recommendation Systems#Tradesy#nDCG@20#0.2095$Recommendation Systems#Declicious#Hits@10#0.2586$Recommendation Systems#Declicious#Hits@20#0.3786$Recommendation Systems#Declicious#nDCG@10#0.1475$Recommendation Systems#Declicious#nDCG@20#0.1781$Recommendation Systems#Pinterest#nDCG@10#0.258$Recommendation Systems#Pinterest#Hits@10#0.5504$Recommendation Systems#Pinterest#Hits@20#0.8108$Recommendation Systems#Pinterest#nDCG@20#0.3242$Recommendation Systems#Ciao#Hits@10#0.2292$Recommendation Systems#Ciao#Hits@20#0.374$Recommendation Systems#Ciao#nDCG@10#0.1167$Recommendation Systems#Ciao#nDCG@20#0.1525
1808.09781v1.pdf	Recommendation Systems#Steam#Hit@10#0.8729$Recommendation Systems#Steam#nDCG@10#0.6306$Recommendation Systems#Amazon Games#Hit@10#0.741$Recommendation Systems#Amazon Games#nDCG@10#0.536$Recommendation Systems#Amazon Beauty#Hit@10#0.4854$Recommendation Systems#Amazon Beauty#nDCG@10#0.3219$Recommendation Systems#MovieLens 1M#HR@10#0.8245$Recommendation Systems#MovieLens 1M#nDCG@10#0.5905
2102.05774v1.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.414$Recommendation Systems#MovieLens 20M#Recall@50#0.552$Recommendation Systems#MovieLens 20M#nDCG@100#0.448
1911.00936v1.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.41308$Recommendation Systems#MovieLens 20M#Recall@50#0.55109$Recommendation Systems#MovieLens 20M#nDCG@100#0.44522$Recommendation Systems#Netflix#Recall@20#0.37678$Recommendation Systems#Netflix#Recall@50#0.46252$Recommendation Systems#Netflix#nDCG@100#0.40861
1912.11160v1.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.414$Recommendation Systems#MovieLens 20M#Recall@50#0.553$Recommendation Systems#MovieLens 20M#nDCG@100#0.442$Recommendation Systems#Netflix#Recall@20#0.361$Recommendation Systems#Netflix#Recall@50#0.452$Recommendation Systems#Netflix#nDCG@100#0.394$Recommendation Systems#Million Song Dataset#Recall@20#0.276$Recommendation Systems#Million Song Dataset#Recall@50#0.374$Recommendation Systems#Million Song Dataset#nDCG@100#0.326
1906.04281v2.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.403$Recommendation Systems#MovieLens 20M#Recall@50#0.543$Recommendation Systems#MovieLens 20M#nDCG@100#0.434$Recommendation Systems#Netflix#Recall@20#0.357$Recommendation Systems#Netflix#Recall@50#0.450$Recommendation Systems#Netflix#nDCG@100#0.392$Recommendation Systems#Million Song Dataset#Recall@20#0.268$Recommendation Systems#Million Song Dataset#Recall@50#0.364$Recommendation Systems#Million Song Dataset#nDCG@100#0.319
1802.05814v1.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.395$Recommendation Systems#MovieLens 20M#Recall@50#0.537$Recommendation Systems#MovieLens 20M#nDCG@100#0.426$Recommendation Systems#MovieLens 20M#Recall@20#0.387$Recommendation Systems#MovieLens 20M#Recall@50#0.524$Recommendation Systems#MovieLens 20M#nDCG@100#0.419$Recommendation Systems#Netflix#Recall@20#0.351$Recommendation Systems#Netflix#Recall@50#0.444$Recommendation Systems#Netflix#nDCG@100#0.386$Recommendation Systems#Netflix#Recall@20#0.344$Recommendation Systems#Netflix#Recall@50#0.438$Recommendation Systems#Netflix#nDCG@100#0.380$Recommendation Systems#Million Song Dataset#Recall@20#0.266$Recommendation Systems#Million Song Dataset#Recall@50#0.364$Recommendation Systems#Million Song Dataset#nDCG@100#0.316$Recommendation Systems#Million Song Dataset#Recall@50#0.363$Recommendation Systems#Million Song Dataset#nDCG@100#0.313
1905.03375v1.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.391$Recommendation Systems#MovieLens 20M#Recall@50#0.521$Recommendation Systems#MovieLens 20M#nDCG@100#0.420$Recommendation Systems#Netflix#Recall@20#0.362$Recommendation Systems#Netflix#Recall@50#0.445$Recommendation Systems#Netflix#nDCG@100#0.393$Recommendation Systems#Million Song Dataset#Recall@20#0.333$Recommendation Systems#Million Song Dataset#Recall@50#0.428$Recommendation Systems#Million Song Dataset#nDCG@100#0.389
1809.01703v3.pdf	Recommendation Systems#MovieLens 20M#HR@10#0.8736$Recommendation Systems#MovieLens 20M#nDCG@10#0.6404$Recommendation Systems#MovieLens 1M#HR@10#0.7563$Recommendation Systems#MovieLens 1M#nDCG@10#0.5620
1707.05176v3.pdf	Recommendation Systems#MovieLens 20M#HR@10#0.8447$Recommendation Systems#MovieLens 20M#nDCG@10#0.6152$Recommendation Systems#Netflix#nDCG@10#0.3578$Recommendation Systems#Netflix#Recall@10#0.5371$Recommendation Systems#MovieLens 1M#HR@10#0.7397$Recommendation Systems#MovieLens 1M#nDCG@10#0.5453
2001.00846v3.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.418$Recommendation Systems#Amazon Books#Recall@20#0.285
2101.00870v2.pdf	Recommendation Systems#MovieLens 20M#Recall@20#0.375$Recommendation Systems#MovieLens 20M#Recall@50#0.516
1905.04413v3.pdf	Recommendation Systems#MovieLens 20M#Recall@50#0.321$Recommendation Systems#MovieLens 20M#Recall@100#0.458$Recommendation Systems#MovieLens 20M#Recall@10#0.155$Recommendation Systems#MovieLens 20M#Recall@2#0.043$Recommendation Systems#Dianping-Food#Recall@10#0.17$Recommendation Systems#Dianping-Food#Recall@100#0.487$Recommendation Systems#Dianping-Food#Recall@2#0.047$Recommendation Systems#Dianping-Food#Recall@50#0.34$Recommendation Systems#Last.FM#Recall@10#0.122$Recommendation Systems#Last.FM#Recall@100#0.370$Recommendation Systems#Last.FM#Recall@2#0.044$Recommendation Systems#Last.FM#Recall@50#0.277$Recommendation Systems#Book-Crossing#Recall@10#0.082$Recommendation Systems#Book-Crossing#Recall@100#0.149$Recommendation Systems#Book-Crossing#Recall@2#0.045$Recommendation Systems#Book-Crossing#Recall@50#0.117
2108.06208v3.pdf	Recommendation Systems#Gowalla#Recall@20#0.1875$Recommendation Systems#Gowalla#nDCG@20#0.1574$Recommendation Systems#Amazon-Book#Recall@20#0.0442$Recommendation Systems#Amazon-Book#nDCG@20#0.0341$Recommendation Systems#Yelp2018#Recall@20#0.0671$Recommendation Systems#Yelp2018#NDCG@20#0.0549
2002.02126v4.pdf	Recommendation Systems#Gowalla#Recall@20#0.1830$Recommendation Systems#Gowalla#nDCG@20#0.1554
1902.06188v2.pdf	Recommendation Systems#MovieLens-Latest#Recall@10#0.3225$Recommendation Systems#MovieLens-Latest#mAP@10#0.199$Recommendation Systems#Epinions-Extend#Recall@10#0.1767$Recommendation Systems#Epinions-Extend#mAP@10#0.0921$Recommendation Systems#Last.FM-360k#Recall@10#0.1762$Recommendation Systems#Last.FM-360k#mAP@10#0.097$Recommendation Systems#CiteULike#Recall@10#0.2362$Recommendation Systems#CiteULike#mAP@10#0.1452$Recommendation Systems#Netflix#Recall@10#0.2014$Recommendation Systems#Netflix#mAP@10#0.1039$Recommendation Systems#Frappe#Recall@10#33.47$Recommendation Systems#Frappe#mAP@10#0.2047$Recommendation Systems#Amazon-Book#Recall@10#0.0625$Recommendation Systems#Amazon-Book#mAP@10#0.0274$Recommendation Systems#Echonest#Recall@10#0.1358$Recommendation Systems#Echonest#mAP@10#0.0679
1906.09506v3.pdf	Recommendation Systems#Last.FM#HR@10#0.2483$Recommendation Systems#Last.FM#nDCG@10#0.1766$Recommendation Systems#MovieLens 1M#HR@10#0.1994$Recommendation Systems#MovieLens 1M#nDCG@10#0.3699$Recommendation Systems#DBbook2014#HR@10#0.1874$Recommendation Systems#DBbook2014#nDCG@10#0.1371
2204.04959v1.pdf	Recommendation Systems#Last.FM#Recall@20#0.1008$Recommendation Systems#Last.FM#NDCG@20#0.0931$Recommendation Systems#Alibaba-iFashion#Recall@20#0.1319$Recommendation Systems#Alibaba-iFashion#NDCG@20#0.0848$Recommendation Systems#Yelp2018#Recall@20#0.0778$Recommendation Systems#Yelp2018#NDCG@20#0.0501
2103.08971v1.pdf	Recommendation Systems#Amazon Product Data#AUC#0.9773$Recommendation Systems#Amazon Games#AUC#0.9459$Recommendation Systems#Amazon Beauty#AUC#0.9368
2204.06519v1.pdf	Recommendation Systems#Amazon Games#Hit@10#0.782$Recommendation Systems#Amazon Games#nDCG@10#0573$Recommendation Systems#Amazon Fashion#nDCG@10 (500 Neg. Samples)#0.184$Recommendation Systems#Amazon Fashion#AUC#0.841$Recommendation Systems#Amazon Fashion#nDCG@10 (100 Neg. Samples)#0.381$Recommendation Systems#Amazon Fashion#HitRatio@ 10 (100 Neg. Samples)#0.591$Recommendation Systems#Amazon Beauty#Hit@10#0.579$Recommendation Systems#Amazon Beauty#nDCG@10#0.396$Sequential Recommendation#Amazon Men#Hit@10#0.550$Sequential Recommendation#Amazon Men#nDCG@10#0.349
1905.12862v2.pdf	Recommendation Systems#Amazon Fashion#nDCG@10 (500 Neg. Samples)#0.171$Recommendation Systems#Amazon Fashion#AUC#0.816
1905.01395v1.pdf	Recommendation Systems#MovieLens 10M#RMSE#0.7485$Recommendation Systems#MovieLens 10M#RMSE#0.7523$Recommendation Systems#MovieLens 10M#RMSE#0.7563$Recommendation Systems#MovieLens 10M#RMSE#0.772$Recommendation Systems#MovieLens 10M#RMSE#0.823
1605.09477v1.pdf	Recommendation Systems#MovieLens 10M#RMSE#0.771$Recommendation Systems#MovieLens 1M#RMSE#0.829
1605.00937v2.pdf	Recommendation Systems#MovieLens 10M#RMSE#0.799$Recommendation Systems#MovieLens 1M#RMSE#0.866
2011.10834v2.pdf	Recommendation Systems#MovieLens 10M#MAP@5#0.1536$Recommendation Systems#MovieLens 10M#NDCG@5#0.1846$Recommendation Systems#MovieLens 10M#MAP@15#0.1568$Recommendation Systems#MovieLens 10M#NDCG@15#0.2546$Recommendation Systems#MovieLens 10M#MAP@30#0.1671$Recommendation Systems#MovieLens 10M#NDCG@30#0.2971
1902.09757v1.pdf	Recommendation Systems#Frappe#RMSE#0.3071
2112.08140v1.pdf	Recommendation Systems#ReDial#Recall@1#0.056$Recommendation Systems#ReDial#Recall@10#0.256$Recommendation Systems#ReDial#Recall@50#0.455
2204.09263v2.pdf	Recommendation Systems#ReDial#Recall@10#0.2161$Recommendation Systems#ReDial#Recall@50#0.4258
2010.10333v2.pdf	Recommendation Systems#ReDial#Recall@1#0.04$Recommendation Systems#ReDial#Recall@10#0.187$Recommendation Systems#ReDial#Recall@50#0.376
1903.10433v1.pdf	Recommendation Systems#Epinions#MAE#0.7781$Recommendation Systems#Epinions#RMSE#1.0268$Recommendation Systems#WeChat#AUC#0.8165$Recommendation Systems#WeChat#P@10#0.0823
1706.03205v1.pdf	Recommendation Systems#Epinions#MAE#0.8044$Recommendation Systems#Epinions#RMSE#1.0425$Recommendation Systems#WeChat#AUC#0.7727$Recommendation Systems#WeChat#P@10#0.0736
1902.07243v2.pdf	Recommendation Systems#Epinions#MAE#0.8168$Recommendation Systems#Epinions#RMSE#1.0631
2109.08052v1.pdf	Recommendation Systems#Polyvore#AUC#0.86
1902.08009v1.pdf	Recommendation Systems#Polyvore#Accuracy#0.7813
1708.05031v2.pdf	Recommendation Systems#Pinterest#nDCG@10#0.5550$Recommendation Systems#Pinterest#HR@10#0.8790$Recommendation Systems#MovieLens 1M#HR@10#0.7260$Recommendation Systems#MovieLens 1M#nDCG@10#0.4450
2108.11124v1.pdf	Recommendation Systems#MovieLens 1M#RMSE#0.829
1905.06874v1.pdf	Recommendation Systems#MovieLens 1M#RMSE#0.8401
1511.06443v2.pdf	Recommendation Systems#MovieLens 1M#RMSE#0.843
1811.09975v1.pdf	Recommendation Systems#MovieLens 1M#nDCG@100#29.93
1909.04276v4.pdf	Session-Based Recommendations#yoochoose1/4#MRR@20#32.04$Session-Based Recommendations#yoochoose1/4#HR@20#72.90$Session-Based Recommendations#Last.FM#HR@20#24.76$Session-Based Recommendations#Last.FM#MRR@20#9.02$Session-Based Recommendations#Diginetica#MRR@20#18.72$Session-Based Recommendations#Diginetica#Hit@20#53.39$Session-Based Recommendations#yoochoose1/64#MRR@20#31.61$Session-Based Recommendations#yoochoose1/64#HR@20#71.27
1811.00855v4.pdf	Session-Based Recommendations#yoochoose1/4#MRR@20#31.89$Session-Based Recommendations#yoochoose1/4#HR@20#71.36$Session-Based Recommendations#Last.FM#HR@20#22.33$Session-Based Recommendations#Last.FM#MRR@20#8.23$Session-Based Recommendations#Diginetica#MRR@20#17.59$Session-Based Recommendations#Diginetica#Hit@20#50.73$Session-Based Recommendations#yoochoose1/64#MRR@20#30.94$Session-Based Recommendations#yoochoose1/64#HR@20#70.57$Session-Based Recommendations#yoochoose1#MRR@20#30.94$Session-Based Recommendations#yoochoose1#Precision@20#70.57$Session-Based Recommendations#Gowalla#HR@20#50.32$Session-Based Recommendations#Gowalla#MRR@20#24.25
2106.09306v1.pdf	Session-Based Recommendations#Last.FM#HR@20#28.82$Session-Based Recommendations#Last.FM#MRR@20#11.33$Session-Based Recommendations#Diginetica#MRR@20#18.56$Session-Based Recommendations#Diginetica#Hit@20#52.50$Session-Based Recommendations#yoochoose1/64#MRR@20#31.71$Session-Based Recommendations#yoochoose1/64#HR@20#71.53
2009.10002v1.pdf	Session-Based Recommendations#Diginetica#MRR@20#18.07$Session-Based Recommendations#Diginetica#Hit@20#53.05$Session-Based Recommendations#yoochoose1/64#MRR@20#31.35$Session-Based Recommendations#yoochoose1/64#HR@20#71.18
2005.02844v1.pdf	Session-Based Recommendations#Diginetica#MRR@20#18.03$Session-Based Recommendations#Diginetica#Hit@20#51.31$Session-Based Recommendations#yoochoose1/64#MRR@20#31.12$Session-Based Recommendations#yoochoose1/64#HR@20#71.02$Session-Based Recommendations#yoochoose1#MRR@20#31.12$Session-Based Recommendations#yoochoose1#Precision@20#71.02
2107.01516v3.pdf	Session-Based Recommendations#Diginetica#MRR@20#17.93$Session-Based Recommendations#Diginetica#Hit@20#51.86$Session-Based Recommendations#yoochoose1/64#MRR@20#31.57$Session-Based Recommendations#yoochoose1/64#HR@20#71.91
2006.01894v4.pdf	Session-Based Recommendations#Diginetica#MRR@20#17.31$Session-Based Recommendations#Diginetica#Hit@20#38.49$Session-Based Recommendations#Diginetica#MRR@20#17.24$Session-Based Recommendations#Diginetica#Hit@20#37.52$Session-Based Recommendations#Retailrocket#MRR@20#0.3664$Session-Based Recommendations#Retailrocket#Hit@20#0.5073$Session-Based Recommendations#Retailrocket#MRR@20#0.3524$Session-Based Recommendations#Retailrocket#Hit@20#0.4704$Session-Based Recommendations#yoochoose1#MRR@20#31.16$Session-Based Recommendations#yoochoose1#Precision@20#74.3$Session-Based Recommendations#yoochoose1#MRR@20#31.04$Session-Based Recommendations#yoochoose1#Precision@20#73.0
1711.04725v1.pdf	Session-Based Recommendations#Diginetica#MRR@20#16.17$Session-Based Recommendations#Diginetica#Hit@20#49.70$Session-Based Recommendations#yoochoose1/64#MRR@20#28.63$Session-Based Recommendations#yoochoose1/64#HR@20#68.32
1511.06939v4.pdf	Session-Based Recommendations#Diginetica#MRR@20#8$Session-Based Recommendations#Diginetica#Hit@20#29.45$Session-Based Recommendations#yoochoose1/64#MRR@20#22.89$Session-Based Recommendations#yoochoose1/64#HR@20#60.64
1811.11683v2.pdf	Phrase Grounding#Flickr30k#Pointing Game Accuracy#69.19$Phrase Grounding#Visual Genome#Pointing Game Accuracy#55.16$Phrase Grounding#ReferIt#Pointing Game Accuracy#62.76
2206.07643v1.pdf	Phrase Grounding#Flickr30k Entities Dev#R@1#87.1$Phrase Grounding#Flickr30k Entities Dev#R@10#97.4$Phrase Grounding#Flickr30k Entities Dev#R@5#96.1$Phrase Grounding#Flickr30k Entities Test#R@1#87.4$Phrase Grounding#Flickr30k Entities Test#R@10#97.6$Phrase Grounding#Flickr30k Entities Test#R@5#96.4
2206.05836v2.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#87.7$Object Detection#COCO test-dev#box AP#62.4$Referring Expression Segmentation#PhraseCut#Mean IoU#61.3
2112.03857v2.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#87.1$Phrase Grounding#Flickr30k Entities Test#R@10#98.1$Phrase Grounding#Flickr30k Entities Test#R@5#96.9$Object Detection#COCO test-dev#box AP#61.5$Object Detection#COCO test-dev#AP50#79.5$Object Detection#COCO test-dev#AP75#67.7$Object Detection#COCO test-dev#APS#45.3$Object Detection#COCO test-dev#APM#64.9$Object Detection#COCO test-dev#APL#75.0$Object Detection#COCO minival#box AP#60.8
2104.06008v1.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#78.73
1911.09042.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#76.74
1909.00301v1.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#74.69
1805.03508v1.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#73.3
1511.03745v4.pdf	Phrase Grounding#Flickr30k Entities Test#R@1#48.38
2005.05708v2.pdf	Object Detection#WiderPerson#AP#91.95$Object Detection#WiderPerson#mMR#40.78$Object Detection#WiderPerson#AP#89.49$Object Detection#WiderPerson#mMR#40.35$Object Detection#CrowdHuman (full body)#AP#88.08$Object Detection#CrowdHuman (full body)#mMR#49.44$Object Detection#CrowdHuman (full body)#AP#84.43$Object Detection#CrowdHuman (full body)#mMR#49.12
2003.07080v1.pdf	Object Detection#WiderPerson#AP#89.96$Object Detection#CrowdHuman (full body)#AP#87.94$Object Detection#CrowdHuman (full body)#AP#86.05
1909.12118v1.pdf	Object Detection#WiderPerson#mMR#46.06
2105.06808v1.pdf	Object Detection#UAVVaste#AP50#74.1$Object Detection#Extended TACO-1#AP50#56.8$Object Detection#MJU-Waste#AP50#97.9$Object Detection#Extended TACO-7#mAP50#16.2$Object Detection#Drinking Waste Classification#AP50#99.4
2008.13642v1.pdf	Object Detection#nuScenes#AP50#88.9$Object Detection#nuScenes#AP75#84.3$Object Detection#nuScenes#AR#75.3$Object Detection#nuScenes#MAP#72.3$Object Detection#nuScenes#AP85#65.7$Object Detection#nuScenes#AP(s)#53.5$Object Detection#nuScenes#AP(m)#70.1$Object Detection#nuScenes#AP(l)#76.9$Object Detection#nuScenes#AR(s)#56.2$Object Detection#nuScenes#AR(m)#73.2$Object Detection#nuScenes#AR(l)#79.8$Object Detection#nuScenes#AP50#83.9$Object Detection#nuScenes#AP75#80.1$Object Detection#nuScenes#AR#71.9$Object Detection#nuScenes#MAP#69$Object Detection#nuScenes#AP85#64.4$Object Detection#nuScenes#AP(s)#44.8$Object Detection#nuScenes#AP(m)#67.8$Object Detection#nuScenes#AP(l)#73.3$Object Detection#nuScenes#AR(s)#47.3$Object Detection#nuScenes#AR(m)#70.9$Object Detection#nuScenes#AR(l)#76.2
2111.00902v1.pdf	Object Detection#MSCOCO#mAP @0.5:0.95#40.9
2106.07770v3.pdf	Object Detection#A Dataset of Multispectral Potato Plants Images#Dice Score#0.74$Object Detection#A Dataset of Multispectral Potato Plants Images#Average IOU#0.589
1910.04093v1.pdf	Object Detection#KITTI Cars Hard#AP#68.91$Object Detection#KITTI Cars Easy#AP#87.87$Object Detection#KITTI Cars Moderate#AP#77.16$Birds Eye View Object Detection#KITTI Cars Easy#AP#89.78$Birds Eye View Object Detection#KITTI Cars Moderate#AP#86.55%$Birds Eye View Object Detection#KITTI Cars Hard#AP#79.22
1812.04244v2.pdf	Object Detection#KITTI Cars Hard#AP#68.32$Object Detection#KITTI Cars Easy#AP#85.94$Object Detection#KITTI Cars Moderate#AP#75.76$3D Object Detection#KITTI Cyclists Easy#AP#73.93%$3D Object Detection#KITTI Cars Moderate#AP#75.42%$3D Object Detection#KITTI Cyclists Moderate#AP#59.60%$3D Object Detection#KITTI Cars Easy#AP#84.32%$3D Object Detection#KITTI Cars Hard#AP#67.86%$3D Object Detection#KITTI Cyclists Hard#AP#53.59%
1609.06666v2.pdf	Object Detection#KITTI Cars Hard#AP#63.23$Object Detection#KITTI Cars Easy#AP#76.79$Object Detection#KITTI Cyclists Easy#AP#79.92$Object Detection#KITTI Cyclists Moderate#AP#67.88$Object Detection#KITTI Cars Moderate#AP#68.24$Object Detection#KITTI Pedestrians Easy#AP#68.39$Object Detection#KITTI Cyclists Hard#AP#62.98$Object Detection#KITTI Pedestrians Moderate#AP#55.37$Object Detection#KITTI Pedestrians Hard#AP#52.59
1608.07916v1.pdf	Object Detection#KITTI Cars Hard#AP#42.74$Object Detection#KITTI Cars Easy#AP#60.34$Object Detection#KITTI Cars Moderate#AP#47.51
1807.01232v3.pdf	Object Detection#SpaceNet 2#F1 Score (Avg. over Cities)#0.60$Object Detection#SpaceNet 2#F1 Score (Avg. over Cities)#0.57$Object Detection#SpaceNet 1#F1 Score#0.21
2203.11926v2.pdf	Object Detection#COCO test-dev#box AP#64.3$Object Detection#COCO minival#box AP#64.2$Object Detection#COCO minival#box AP#51.5$Object Detection#COCO minival#AP50#70.3$Object Detection#COCO minival#AP75#56.0$Object Detection#COCO minival#AP50#70.1$Object Detection#COCO minival#AP75#55.8
2106.09018v3.pdf	Object Detection#COCO test-dev#box AP#61.3$Object Detection#COCO minival#box AP#60.7$Object Detection#COCO minival#box AP#60.1$Instance Segmentation#COCO test-dev#mask AP#53.0$Instance Segmentation#COCO minival#mask AP#52.5$Instance Segmentation#COCO minival#mask AP#51.9$Semi-Supervised Object Detection#COCO 100% labeled data#mAP#44.9$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#30.74$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#20.46$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#34.04
2106.08322v1.pdf	Object Detection#COCO test-dev#box AP#60.6$Object Detection#COCO test-dev#AP50#78.5$Object Detection#COCO test-dev#AP75#66.6$Object Detection#COCO test-dev#APM#64.0$Object Detection#COCO test-dev#APL#74.2$Object Detection#COCO test-dev#box AP#58.7$Object Detection#COCO test-dev#AP50#77.1$Object Detection#COCO test-dev#AP75#64.5$Object Detection#COCO test-dev#APM#62.0$Object Detection#COCO test-dev#APL#72.8$Object Detection#COCO test-dev#box AP#54$Object Detection#COCO test-dev#AP50#72.1$Object Detection#COCO test-dev#AP75#59.3$Object Detection#COCO test-dev#box AP#47.7$Object Detection#COCO test-dev#AP50#65.7$Object Detection#COCO test-dev#AP75#51.9$Object Detection#COCO test-dev#box AP#43$Object Detection#COCO test-dev#AP50#60.7$Object Detection#COCO test-dev#AP75#46.8$Object Detection#COCO test-dev#AP50#64.5$Object Detection#COCO test-dev#AP75#50.7$Object Detection#COCO 2017 val#AP50#68$Object Detection#COCO 2017 val#AP75#54.3$Object Detection#COCO 2017 val#APL#64.2$Object Detection#COCO 2017 val#box AP#49.7$Object Detection#COCO minival#box AP#60.3$Object Detection#COCO minival#AP50#78.2$Object Detection#COCO minival#APL#74.2$Object Detection#COCO minival#box AP#58.4$Object Detection#COCO minival#AP50#76.8$Object Detection#COCO minival#APS#44.5$Object Detection#COCO minival#APM#62.2$Object Detection#COCO minival#APL#73.2$Object Detection#COCO minival#box AP#46.5$Object Detection#COCO minival#APL#66.3
2204.08394v1.pdf	Object Detection#COCO test-dev#box AP#57.1$Object Detection#COCO test-dev#AP50#73.7$Object Detection#COCO test-dev#AP75#62.4$Object Detection#COCO test-dev#APS#38.7$Object Detection#COCO test-dev#APM#59.2$Object Detection#COCO test-dev#APL#71.3
2106.02351v3.pdf	Object Detection#COCO test-dev#box AP#56.5$Object Detection#COCO test-dev#AP50#74.6$Object Detection#COCO test-dev#AP75#60.5$Object Detection#COCO test-dev#APS#37.6$Object Detection#COCO test-dev#APM#60$Object Detection#COCO test-dev#APL#70.6$Object Detection#COCO test-dev#box AP#48.7$Object Detection#COCO test-dev#box AP#47.8$Object Detection#COCO minival#AP50#74.9$Object Detection#COCO minival#AP75#61.3$Object Detection#COCO minival#APL#71.9$Instance Segmentation#COCO test-dev#mask AP#46.7$Instance Segmentation#COCO test-dev#mask AP#40.9$Instance Segmentation#COCO test-dev#mask AP#39.7
2103.07461v1.pdf	Object Detection#COCO test-dev#box AP#56.4$Object Detection#COCO test-dev#AP50#74.0$Object Detection#COCO test-dev#AP75#61.6$Object Detection#COCO test-dev#APS#38.7$Object Detection#COCO test-dev#APM#59.7$Object Detection#COCO test-dev#APL#68.6
2105.01928v3.pdf	Object Detection#COCO test-dev#box AP#56.1$Object Detection#COCO test-dev#AP50#75.9$Object Detection#COCO test-dev#AP75#61.9$Object Detection#COCO test-dev#APS#37.4$Object Detection#COCO test-dev#APM#58.9$Object Detection#COCO test-dev#APL#70.3$Object Detection#COCO test-dev#Hardware Burden#17G$Object Detection#COCO minival#box AP#56.1$Object Detection#COCO minival#AP50#75.8$Object Detection#COCO minival#AP75#61.7$Object Detection#COCO minival#APS#40.2$Object Detection#COCO minival#APM#59.8$Object Detection#COCO minival#APL#71.5$Instance Segmentation#COCO test-dev#mask AP#49.1$Instance Segmentation#COCO test-dev#AP50#74.2$Instance Segmentation#COCO test-dev#AP75#53.8$Instance Segmentation#COCO test-dev#APS#31.5$Instance Segmentation#COCO test-dev#APM#51.8$Instance Segmentation#COCO test-dev#APL#63.2$Instance Segmentation#COCO minival#mask AP#48.9$Instance Segmentation#COCO minival#AP50#74.0$Instance Segmentation#COCO minival#AP75#53.9$Instance Segmentation#COCO minival#APL#68.3$Instance Segmentation#COCO minival#APM#52.6$Instance Segmentation#COCO minival#APS#30.8
2011.08036v2.pdf	Object Detection#COCO test-dev#box AP#55.8$Object Detection#COCO test-dev#AP50#73.2$Object Detection#COCO test-dev#AP75#61.2$Object Detection#COCO test-dev#box AP#55.4$Object Detection#COCO test-dev#AP50#73.3$Object Detection#COCO test-dev#AP75#60.7$Object Detection#COCO test-dev#APS#38.1$Object Detection#COCO test-dev#APM#59.5$Object Detection#COCO test-dev#APL#67.4$Object Detection#COCO test-dev#box AP#54.9$Object Detection#COCO test-dev#AP50#72.6$Object Detection#COCO test-dev#AP75#60.2$Object Detection#COCO test-dev#box AP#54.3$Object Detection#COCO test-dev#AP50#72.3$Object Detection#COCO test-dev#AP75#59.5$Object Detection#COCO test-dev#APS#36.6$Object Detection#COCO test-dev#APM#58.2$Object Detection#COCO test-dev#APL#65.5$Object Detection#COCO test-dev#box AP#52.5$Object Detection#COCO test-dev#AP50#70.3$Object Detection#COCO test-dev#AP75#58$Object Detection#COCO test-dev#box AP#45.5$Object Detection#COCO test-dev#AP50#64.1$Object Detection#COCO test-dev#AP75#49.5$Object Detection#COCO test-dev#APS#27$Object Detection#COCO test-dev#APM#49$Object Detection#COCO test-dev#APL#56.7
1911.09070v7.pdf	Object Detection#COCO test-dev#box AP#55.1$Object Detection#COCO test-dev#AP50#74.3$Object Detection#COCO test-dev#AP75#59.9$Object Detection#COCO test-dev#APS#37.2$Object Detection#COCO test-dev#APL#68.0$Object Detection#COCO test-dev#box AP#53.7$Object Detection#COCO test-dev#AP50#72.4$Object Detection#COCO test-dev#APM#57.0$Object Detection#COCO test-dev#APL#66.3$Object Detection#COCO test-dev#box AP#52.6$Object Detection#COCO test-dev#AP50#71.6$Object Detection#COCO test-dev#AP75#56.9$Object Detection#COCO minival#box AP#52.1$Object Detection#COCO minival#AP50#73.4$Object Detection#COCO minival#AP75#59.0$Object Detection#COCO minival#APS#40.0$Object Detection#COCO minival#APM#58.0$Object Detection#COCO minival#APL#67.9
2103.14027v3.pdf	Object Detection#COCO test-dev#box AP#54.1$Object Detection#COCO test-dev#AP50#71.6$Object Detection#COCO test-dev#AP75#59.9$Object Detection#COCO test-dev#APS#35.8$Object Detection#COCO test-dev#APM#57.2$Object Detection#COCO test-dev#APL#67.4$Object Detection#COCO test-dev#box AP#51.3$Object Detection#COCO test-dev#AP50#70.0$Object Detection#COCO test-dev#AP75#55.8$Object Detection#COCO test-dev#APS#31.7$Object Detection#COCO test-dev#APM#55.3$Object Detection#COCO test-dev#APL#64.9$Object Detection#COCO test-dev#box AP#48.8$Object Detection#COCO test-dev#AP50#67.5$Object Detection#COCO test-dev#AP75#53.0$Object Detection#COCO test-dev#APS#30.1$Object Detection#COCO test-dev#APM#52.3$Object Detection#COCO test-dev#APL#61.1$Object Detection#Waymo 2D detection all_ns test#AP/L2#67.42$Object Detection#COCO minival#box AP#53.5$Object Detection#COCO minival#AP50#70.8$Object Detection#COCO minival#AP75#58.9$Object Detection#COCO minival#APS#36.9$Object Detection#COCO minival#APM#57.5$Object Detection#COCO minival#APL#68.1$Object Detection#COCO minival#box AP#50.9$Object Detection#COCO minival#AP50#69.5$Object Detection#COCO minival#AP75#55.4$Object Detection#COCO minival#APS#33.5$Object Detection#COCO minival#APM#55.5$Object Detection#COCO minival#APL#65.8$Object Detection#COCO minival#box AP#48.5$Object Detection#COCO minival#AP50#67.0$Object Detection#COCO minival#AP75#52.6$Object Detection#COCO minival#APS#30.6$Object Detection#COCO minival#APM#52.7$Object Detection#COCO minival#APL#62.7$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#52.1$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#51.4$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#50.4$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#49.6$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#49.4$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#49.0$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#48.1$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#47.7$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#47.1$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#45.9$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#44.8$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#44.6$Object Detection#USB (Standard USB 1.0 protocol)#mCAP#23.7$Object Detection#Manga109-s 15test#COCO-style AP#70.2$Object Detection#Manga109-s 15test#COCO-style AP#69.9$Object Detection#Manga109-s 15test#COCO-style AP#68.9$Object Detection#Manga109-s 15test#COCO-style AP#67.9$Object Detection#Manga109-s 15test#COCO-style AP#67.6$Object Detection#Manga109-s 15test#COCO-style AP#67.4$Object Detection#Manga109-s 15test#COCO-style AP#67.3$Object Detection#Manga109-s 15test#COCO-style AP#67.1$Object Detection#Manga109-s 15test#COCO-style AP#66.5$Object Detection#Manga109-s 15test#COCO-style AP#66.2$Object Detection#Manga109-s 15test#COCO-style AP#65.8$Object Detection#Manga109-s 15test#COCO-style AP#65.3$Object Detection#Manga109-s 15test#COCO-style AP#64.1$Object Detection#Manga109-s 15test#COCO-style AP#63.1$Object Detection#Manga109-s 15test#COCO-style AP#31.2$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#41.6$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#39.0$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#38.6$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#38.3$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#37.2$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#37.1$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#36.4$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#35.7$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#35.4$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#35.0$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#34.5$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#32.8$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#32.7$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#32.5$Object Detection#Waymo 2D detection all_ns f0val#COCO-style AP#17.8
2007.08103v2.pdf	Object Detection#COCO test-dev#box AP#53.5$Object Detection#COCO test-dev#AP50#71.6$Object Detection#COCO test-dev#AP75#59.1$Object Detection#COCO test-dev#APS#36.0$Object Detection#COCO test-dev#APM#56.3$Object Detection#COCO test-dev#APL#66.9
2104.04899v1.pdf	Object Detection#COCO test-dev#box AP#53.5$Object Detection#COCO test-dev#AP50#71.1$Object Detection#COCO test-dev#AP75#59.2$Object Detection#COCO test-dev#APS#35.2$Object Detection#COCO test-dev#APM#56.4$Object Detection#COCO test-dev#APL#65.8
1909.03625v1.pdf	Object Detection#COCO test-dev#box AP#53.3$Object Detection#COCO test-dev#AP50#71.9$Object Detection#COCO test-dev#AP75#58.5$Object Detection#COCO test-dev#APS#35.5$Object Detection#COCO test-dev#APM#55.8$Object Detection#COCO test-dev#APL#66.7$Instance Segmentation#COCO test-dev#mask AP#43.3
2011.12885v1.pdf	Object Detection#COCO test-dev#box AP#53.3$Object Detection#COCO test-dev#AP50#70.9$Object Detection#COCO test-dev#AP75#59.2$Object Detection#COCO test-dev#APS#35.7$Object Detection#COCO test-dev#APM#56.1$Object Detection#COCO test-dev#APL#65.6$Object Detection#COCO test-dev#box AP#50.6$Object Detection#COCO test-dev#AP50#69$Object Detection#COCO test-dev#AP75#55.3$Object Detection#COCO test-dev#APS#31.3$Object Detection#COCO test-dev#APM#54.3$Object Detection#COCO test-dev#APL#63.5$Object Detection#COCO test-dev#box AP#49$Object Detection#COCO test-dev#AP50#67.6$Object Detection#COCO test-dev#AP75#53.5$Object Detection#COCO test-dev#APS#29.7$Object Detection#COCO test-dev#APM#52.4$Object Detection#COCO test-dev#APL#61.4$Object Detection#COCO test-dev#Hardware Burden#3G$Object Detection#COCO test-dev#box AP#48.3$Object Detection#COCO test-dev#AP50#66.5$Object Detection#COCO test-dev#AP75#52.8$Object Detection#COCO test-dev#APS#28.8$Object Detection#COCO test-dev#APM#51.9$Object Detection#COCO test-dev#APL#60.7$Object Detection#COCO test-dev#box AP#46.2$Object Detection#COCO test-dev#AP50#64.3$Object Detection#COCO test-dev#AP75#50.5$Object Detection#COCO test-dev#APS#27.8$Object Detection#COCO test-dev#APM#49.9$Object Detection#COCO test-dev#APL#57$Object Detection#COCO test-dev#box AP#44.3$Object Detection#COCO test-dev#AP50#62.3$Object Detection#COCO test-dev#AP75#48.5$Object Detection#COCO test-dev#APS#26.8$Object Detection#COCO test-dev#APM#47.7$Object Detection#COCO test-dev#APL#54.1
2010.15831v1.pdf	Object Detection#COCO test-dev#box AP#52.7
2012.01724v3.pdf	Object Detection#COCO test-dev#box AP#52.5$Object Detection#COCO test-dev#AP50#70.4$Object Detection#COCO test-dev#AP75#57.2$Object Detection#COCO test-dev#APS#33.4$Object Detection#COCO test-dev#APM#56.2$Object Detection#COCO test-dev#APL#65.8$Object Detection#UAVDT#mAP#76.55
2012.13375v1.pdf	Object Detection#COCO test-dev#box AP#52.3$Object Detection#COCO test-dev#AP50#70.9$Object Detection#COCO test-dev#AP75#56.9$Object Detection#COCO minival#box AP#51.8$Object Detection#COCO minival#AP50#70.4$Object Detection#COCO minival#AP75#56.1$Instance Segmentation#COCO test-dev#mask AP#45.4$Instance Segmentation#COCO test-dev#AP50#68.9$Instance Segmentation#COCO test-dev#AP75#49.6$Instance Segmentation#COCO minival#mask AP#44.7$Instance Segmentation#COCO minival#AP50#67.9$Instance Segmentation#COCO minival#AP75#48.4
1912.05027v3.pdf	Object Detection#COCO test-dev#box AP#52.1$Object Detection#COCO test-dev#AP50#71.8$Object Detection#COCO test-dev#AP75#56.5$Object Detection#COCO test-dev#APS#35.4$Object Detection#COCO test-dev#APM#55$Object Detection#COCO test-dev#APL#63.6$Object Detection#COCO test-dev#box AP#50.7$Object Detection#COCO test-dev#AP50#70.4$Object Detection#COCO test-dev#AP75#54.9$Object Detection#COCO test-dev#APS#33.6$Object Detection#COCO test-dev#APM#53.9$Object Detection#COCO test-dev#APL#62.1$Object Detection#COCO test-dev#box AP#48.6$Object Detection#COCO test-dev#AP50#68.4$Object Detection#COCO test-dev#AP75#52.5$Object Detection#COCO test-dev#APS#32$Object Detection#COCO test-dev#APM#52.3$Object Detection#COCO test-dev#APL#62$Object Detection#COCO test-dev#box AP#46.7$Object Detection#COCO test-dev#AP50#66.3$Object Detection#COCO test-dev#AP75#50.6$Object Detection#COCO test-dev#APS#29.1$Object Detection#COCO test-dev#APM#50.1$Object Detection#COCO test-dev#APL#61.7$Object Detection#COCO test-dev#box AP#44.3$Object Detection#COCO test-dev#AP50#63.8$Object Detection#COCO test-dev#AP75#47.6$Object Detection#COCO test-dev#APS#25.9$Object Detection#COCO test-dev#APM#47.7$Object Detection#COCO test-dev#APL#61.1$Object Detection#COCO test-dev#box AP#42.8$Object Detection#COCO test-dev#AP50#62.3$Object Detection#COCO test-dev#AP75#46.1$Object Detection#COCO test-dev#APS#23.7$Object Detection#COCO test-dev#APM#45.2$Object Detection#COCO test-dev#APL#57.3$Object Detection#COCO test-dev#box AP#41.5$Object Detection#COCO test-dev#AP50#60.5$Object Detection#COCO test-dev#AP75#44.6$Object Detection#COCO test-dev#APS#23.3$Object Detection#COCO test-dev#APM#45$Object Detection#COCO test-dev#APL#58$Object Detection#COCO minival#box AP#52.2$Image Classification#ImageNet#Top 1 Accuracy#79%$Image Classification#ImageNet#Top 5 Accuracy#94.4$Image Classification#ImageNet#Number of params#60.5M$Image Classification#ImageNet#GFLOPs#9.1$Image Classification#iNaturalist#Top 1 Accuracy#63.6%$Image Classification#iNaturalist#Top 5 Accuracy#84.8%$Instance Segmentation#COCO test-dev#mask AP#46.1$Instance Segmentation#COCO minival#mask AP#46.1
2007.08508v1.pdf	Object Detection#COCO test-dev#box AP#52.1$Object Detection#COCO test-dev#AP50#70.1$Object Detection#COCO test-dev#AP75#57.5$Object Detection#COCO test-dev#APS#34.5$Object Detection#COCO test-dev#APM#54.6$Object Detection#COCO test-dev#APL#63.6$Object Detection#COCO test-dev#box AP#49.4$Object Detection#COCO test-dev#AP50#68.9$Object Detection#COCO test-dev#AP75#53.4$Object Detection#COCO test-dev#APS#30.3$Object Detection#COCO test-dev#APM#52.1$Object Detection#COCO test-dev#APL#62.3
2005.11475v1.pdf	Object Detection#COCO test-dev#box AP#51.9$Object Detection#COCO test-dev#AP50#70.4$Object Detection#COCO test-dev#AP75#57$Object Detection#COCO test-dev#APS#34.2$Object Detection#COCO test-dev#APM#54.8$Object Detection#COCO test-dev#APL#64.7$Object Detection#COCO test-dev#box AP#45$Object Detection#COCO test-dev#AP50#64.4$Object Detection#COCO test-dev#AP75#49$Object Detection#COCO test-dev#APS#26.9$Object Detection#COCO test-dev#APM#47.7$Object Detection#COCO test-dev#APL#56.6
2103.14259v1.pdf	Object Detection#COCO test-dev#box AP#51.5$Object Detection#COCO test-dev#AP50#68.6$Object Detection#COCO test-dev#AP75#57.1$Object Detection#COCO test-dev#APS#34.1$Object Detection#COCO test-dev#APM#53.7$Object Detection#COCO test-dev#APL#64.1
2003.07540v1.pdf	Object Detection#COCO test-dev#box AP#51.2$Object Detection#COCO test-dev#AP50#71.9$Object Detection#COCO test-dev#AP75#56.0$Object Detection#COCO test-dev#APS#33.8$Object Detection#COCO test-dev#APM#54.8$Object Detection#COCO test-dev#APL#64.2$Object Detection#COCO test-dev#box AP#49.4$Object Detection#COCO test-dev#AP50#69.6$Object Detection#COCO test-dev#AP75#54.4$Object Detection#COCO test-dev#APS#32.7$Object Detection#COCO test-dev#APM#52.5$Object Detection#COCO test-dev#APL#61.0
1912.02424v4.pdf	Object Detection#COCO test-dev#box AP#50.7$Object Detection#COCO test-dev#AP50#68.9$Object Detection#COCO test-dev#AP75#56.3$Object Detection#COCO test-dev#APS#33.2$Object Detection#COCO test-dev#APM#52.9$Object Detection#COCO test-dev#APL#62.4
1906.11172v1.pdf	Object Detection#COCO test-dev#box AP#50.7$Object Detection#COCO test-dev#APS#34.2$Object Detection#COCO test-dev#APM#55.5$Object Detection#COCO test-dev#APL#64.5
2206.13728v3.pdf	Object Detection#COCO test-dev#box AP#50.7
2009.13592v4.pdf	Object Detection#COCO test-dev#box AP#50.2$Object Detection#COCO test-dev#AP50#70.3$Object Detection#COCO test-dev#AP75#53.9$Object Detection#COCO test-dev#APS#32.0$Object Detection#COCO test-dev#APM#53.1$Object Detection#COCO test-dev#APL#63.0$Object Detection#COCO test-dev#box AP#48.9$Object Detection#COCO test-dev#AP50#69.3$Object Detection#COCO test-dev#AP75#52.5$Object Detection#COCO test-dev#APS#30.8$Object Detection#COCO test-dev#APM#51.5$Object Detection#COCO test-dev#APL#62.1$Object Detection#COCO test-dev#box AP#47.8$Object Detection#COCO test-dev#AP50#68.4$Object Detection#COCO test-dev#AP75#51.1$Object Detection#COCO test-dev#APS#30.2$Object Detection#COCO test-dev#APM#50.8$Object Detection#COCO test-dev#APL#59.1$Object Detection#COCO test-dev#box AP#44.6$Object Detection#COCO test-dev#AP50#65.0$Object Detection#COCO test-dev#AP75#47.5$Object Detection#COCO test-dev#APS#24.6$Object Detection#COCO test-dev#APM#48.1$Object Detection#COCO test-dev#APL#58.3$Object Detection#COCO minival#box AP#40.7$Object Detection#COCO minival#AP50#60.7$Object Detection#COCO minival#AP75#43.3$Object Detection#COCO minival#box AP#40.2$Object Detection#COCO minival#AP50#60.3$Object Detection#COCO minival#AP75#42.3$Object Detection#COCO minival#box AP#39.7$Object Detection#COCO minival#AP50#58.8$Object Detection#COCO minival#AP75#41.5
2005.03101v1.pdf	Object Detection#COCO test-dev#box AP#50.1$Object Detection#COCO test-dev#AP50#69.8$Object Detection#COCO test-dev#AP75#54.3$Object Detection#COCO test-dev#APS#31.3$Object Detection#COCO test-dev#APM#53.3$Object Detection#COCO test-dev#APL#63.7
2004.06002v2.pdf	Object Detection#COCO test-dev#box AP#50.1$Object Detection#COCO test-dev#AP50#68.3$Object Detection#COCO test-dev#AP75#55.6$Object Detection#COCO test-dev#APS#32.8$Object Detection#COCO test-dev#APM#53.0$Object Detection#COCO test-dev#APL#61.2
2007.13816v1.pdf	Object Detection#COCO test-dev#box AP#49.2$Object Detection#COCO test-dev#AP50#67.3$Object Detection#COCO test-dev#AP75#53.7$Object Detection#COCO test-dev#APS#31.0$Object Detection#COCO test-dev#APM#51.9$Object Detection#COCO test-dev#APL#62.4
1901.01892v2.pdf	Object Detection#COCO test-dev#box AP#48.4$Object Detection#COCO test-dev#AP50#69.7$Object Detection#COCO test-dev#AP75#53.5$Object Detection#COCO test-dev#APS#31.8$Object Detection#COCO test-dev#APM#51.3$Object Detection#COCO test-dev#APL#60.3$Object Detection#COCO test-dev#box AP#42.7$Object Detection#COCO test-dev#AP50#63.6$Object Detection#COCO test-dev#AP75#46.5$Object Detection#COCO test-dev#APS#23.9$Object Detection#COCO test-dev#APM#46.6$Object Detection#COCO test-dev#APL#56.6$Object Detection#COCO minival#box AP#42$Object Detection#COCO minival#AP50#63.5$Object Detection#COCO minival#AP75#45.5$Object Detection#COCO minival#APS#24.9$Object Detection#COCO minival#APM#47$Object Detection#COCO minival#APL#56.9
1904.11492v1.pdf	Object Detection#COCO test-dev#box AP#48.4$Object Detection#COCO test-dev#AP50#67.6$Object Detection#COCO test-dev#AP75#52.7$Object Detection#COCO test-dev#Operations per network pass#54.8G$Object Detection#COCO minival#box AP#47.9$Object Detection#COCO minival#AP50#66.9$Object Detection#COCO minival#AP75#52.2$Object Detection#COCO minival#box AP#40.3$Object Detection#COCO minival#AP50#62.4$Object Detection#COCO minival#AP75#44$Object Detection#COCO minival#APS#24.2$Object Detection#COCO minival#APM#44.4$Object Detection#COCO minival#APL#52.5$Instance Segmentation#COCO test-dev#mask AP#41.5%$Instance Segmentation#COCO minival#mask AP#40.9
2006.04388v1.pdf	Object Detection#COCO test-dev#box AP#48.2$Object Detection#COCO test-dev#AP50#67.4$Object Detection#COCO test-dev#AP75#52.6$Object Detection#COCO test-dev#APS#29.2$Object Detection#COCO test-dev#APM#51.7$Object Detection#COCO test-dev#APL#60.2
2105.00637v2.pdf	Object Detection#COCO test-dev#box AP#48.1$Object Detection#COCO test-dev#APS#28.7$Object Detection#COCO test-dev#APM#50.4$Object Detection#COCO test-dev#APL#61.5$Object Detection#COCO test-dev#box AP#46.8$Object Detection#COCO test-dev#APS#27.8$Object Detection#COCO test-dev#APM#48.7$Object Detection#COCO test-dev#APL#59.9$Instance Segmentation#COCO test-dev#mask AP#49.7$Instance Segmentation#COCO test-dev#mask AP#39.9%$Instance Segmentation#COCO test-dev#APS#22.8$Instance Segmentation#COCO test-dev#APM#41.9$Instance Segmentation#COCO test-dev#APL#52.3$Instance Segmentation#COCO test-dev#mask AP#38.6%$Instance Segmentation#COCO test-dev#APS#22.1$Instance Segmentation#COCO test-dev#APM#40.4$Instance Segmentation#COCO test-dev#APL#50.6
1908.04646v2.pdf	Object Detection#COCO test-dev#box AP#47.8$Object Detection#COCO test-dev#AP50#66.2$Object Detection#COCO test-dev#AP75#52.3$Object Detection#COCO test-dev#APS#29.7$Object Detection#COCO test-dev#APM#50.4$Object Detection#COCO test-dev#APL#60.7
1911.12448v2.pdf	Object Detection#COCO test-dev#box AP#47.4$Object Detection#COCO test-dev#AP50#67.4$Object Detection#COCO test-dev#AP75#51.1$Object Detection#COCO test-dev#APS#28.1$Object Detection#COCO test-dev#APM#50.3$Object Detection#COCO test-dev#APL#61.5$Dense Object Detection#SKU-110K#AP#55.7
1803.01534v4.pdf	Object Detection#COCO test-dev#box AP#47.4$Object Detection#COCO test-dev#AP50#67.2$Object Detection#COCO test-dev#AP75#51.8$Object Detection#COCO test-dev#APS#30.1$Object Detection#COCO test-dev#APM#51.7$Object Detection#COCO test-dev#APL#60.0$Object Detection#iSAID#Average Precision#41.66$Instance Segmentation#COCO test-dev#mask AP#42.0$Instance Segmentation#iSAID#Average Precision#34.17$Instance Segmentation#COCO minival#mask AP#37.8
1901.07518v2.pdf	Object Detection#COCO test-dev#box AP#47.1$Object Detection#COCO test-dev#AP50#63.9$Object Detection#COCO test-dev#AP75#44.7$Object Detection#COCO test-dev#APS#22.8$Object Detection#COCO test-dev#APM#43.9$Object Detection#COCO test-dev#APL#54.6$Object Detection#COCO minival#box AP#43.2$Object Detection#COCO minival#AP50#59.4$Object Detection#COCO minival#AP75#40.7$Object Detection#COCO minival#APS#20.3$Object Detection#COCO minival#APM#40.9$Object Detection#COCO minival#APL#52.3$Instance Segmentation#COCO test-dev#mask AP#41.2$Instance Segmentation#COCO test-dev#mask AP#41.2%$Instance Segmentation#COCO minival#mask AP#38.2
1904.08189v3.pdf	Object Detection#COCO test-dev#box AP#47.0$Object Detection#COCO test-dev#AP50#64.5$Object Detection#COCO test-dev#AP75#50.7$Object Detection#COCO test-dev#APS#28.9$Object Detection#COCO test-dev#APM#49.9$Object Detection#COCO test-dev#APL#58.9$Object Detection#COCO minival#box AP#41.3$Object Detection#COCO minival#AP50#59.2$Object Detection#COCO minival#AP75#43.9$Object Detection#COCO minival#APS#23.6$Object Detection#COCO minival#APM#43.8$Object Detection#COCO minival#APL#55.8
1912.02252v1.pdf	Object Detection#COCO test-dev#box AP#47.0$Object Detection#COCO test-dev#box AP#45.9$Object Detection#COCO test-dev#box AP#39.2
1904.11490v2.pdf	Object Detection#COCO test-dev#box AP#46.5$Object Detection#COCO test-dev#AP50#67.4$Object Detection#COCO test-dev#AP75#50.9$Object Detection#COCO test-dev#APS#30.3$Object Detection#COCO test-dev#APM#49.7$Object Detection#COCO test-dev#APL#57.1$Object Detection#COCO test-dev#box AP#42.8$Object Detection#COCO test-dev#AP50#65.0$Object Detection#COCO test-dev#AP75#46.3$Object Detection#COCO test-dev#APS#24.9$Object Detection#COCO test-dev#APM#46.2$Object Detection#COCO test-dev#APL#54.7$Object Detection#COCO test-dev#box AP#41$Object Detection#COCO test-dev#AP50#62.9$Object Detection#COCO test-dev#AP75#44.3$Object Detection#COCO test-dev#APS#23.6$Object Detection#COCO test-dev#APM#44.1$Object Detection#COCO test-dev#APL#51.7$Object Detection#COCO minival#box AP#46.8$Object Detection#COCO minival#box AP#46.4$Object Detection#COCO minival#box AP#44.8$Object Detection#COCO minival#box AP#44.5$Object Detection#COCO minival#box AP#40.8$Object Detection#COCO minival#box AP#40.3$Object Detection#COCO minival#box AP#38.6
2007.02355v3.pdf	Object Detection#COCO test-dev#box AP#46.4$Object Detection#COCO test-dev#AP50#65.1$Object Detection#COCO test-dev#AP75#50.7$Object Detection#COCO test-dev#APS#29.1$Object Detection#COCO test-dev#APM#48.5$Object Detection#COCO test-dev#APL#58.1$Object Detection#COCO minival#box AP#46.1$Object Detection#COCO minival#AP50#64.6$Object Detection#COCO minival#AP75#50.3$Object Detection#COCO minival#APS#30.0$Object Detection#COCO minival#APM#48.8$Object Detection#COCO minival#APL#59.7$Object Detection#COCO minival#box AP#43.0$Object Detection#COCO minival#AP50#62.2$Object Detection#COCO minival#AP75#46.9$Object Detection#COCO minival#APS#25.5$Object Detection#COCO minival#APM#47.6$Object Detection#COCO minival#APL#55.8
2008.01167v2.pdf	Object Detection#COCO test-dev#box AP#46.3$Object Detection#COCO test-dev#AP50#64.8$Object Detection#COCO test-dev#AP75#51.6$Object Detection#COCO test-dev#APS#31.4$Object Detection#COCO test-dev#APM#49.9$Object Detection#COCO test-dev#APL#56.4$Object Detection#COCO minival#box AP#40.5$Object Detection#COCO minival#AP50#59.5$Object Detection#COCO minival#AP75#44.2$Object Detection#COCO minival#APS#25.4$Object Detection#COCO minival#APM#44.7$Object Detection#COCO minival#APL#52.3
1805.09300v3.pdf	Object Detection#COCO test-dev#box AP#46.1$Object Detection#COCO test-dev#AP50#67.0$Object Detection#COCO test-dev#AP75#51.6$Object Detection#COCO test-dev#APS#29.6$Object Detection#COCO test-dev#APM#48.9$Object Detection#COCO test-dev#APL#58.1$Object Detection#COCO test-dev#Hardware Burden#29G$Object Detection#COCO test-dev#box AP#43.5$Object Detection#COCO test-dev#AP50#65.0$Object Detection#COCO test-dev#AP75#48.6$Object Detection#COCO test-dev#APS#26.1$Object Detection#COCO test-dev#APM#46.3$Object Detection#COCO test-dev#APL#56.0
1906.04423v4.pdf	Object Detection#COCO test-dev#box AP#46.1$Object Detection#COCO test-dev#box AP#39.8$Object Detection#COCO test-dev#box AP#34.7$Object Detection#COCO test-dev#Params (M)#16.1
1811.11168v2.pdf	Object Detection#COCO test-dev#box AP#46.0$Object Detection#COCO test-dev#AP50#67.9$Object Detection#COCO test-dev#AP75#50.8$Object Detection#COCO test-dev#APS#27.8$Object Detection#COCO test-dev#APM#49.1$Object Detection#COCO test-dev#APL#59.5$Object Detection#COCO minival#box AP#43.1$Object Detection#COCO minival#box AP#41.7$Object Detection#COCO minival#APS#22.2$Object Detection#COCO minival#APM#45.8$Object Detection#COCO minival#APL#58.7
2006.15607v6.pdf	Object Detection#COCO test-dev#box AP#46
1908.07801v1.pdf	Object Detection#COCO test-dev#box AP#45.9$Object Detection#COCO test-dev#AP50#64.2$Object Detection#COCO test-dev#AP75#50$Object Detection#COCO test-dev#APS#26.3$Object Detection#COCO test-dev#APM#49$Object Detection#COCO test-dev#APL#58.6$Instance Segmentation#COCO test-dev#mask AP#39.5%$Instance Segmentation#COCO test-dev#AP50#61.4%$Instance Segmentation#COCO test-dev#AP75#42.9%$Instance Segmentation#COCO test-dev#APS#21.2%$Instance Segmentation#COCO test-dev#APM#42.5%$Instance Segmentation#COCO test-dev#APL#52.1%
1911.06667v6.pdf	Object Detection#COCO test-dev#box AP#45.8$Object Detection#COCO test-dev#AP50#64.5$Object Detection#COCO test-dev#APS#27.8$Object Detection#COCO test-dev#APM#48.3$Object Detection#COCO test-dev#APL#57.6$Object Detection#COCO test-dev#box AP#44.7$Object Detection#COCO test-dev#AP50#63.1$Object Detection#COCO test-dev#AP75#48.6$Object Detection#COCO test-dev#APS#27.1$Object Detection#COCO test-dev#APL#55.9$Object Detection#COCO test-dev#box AP#44.6$Object Detection#COCO test-dev#AP50#63.4$Object Detection#COCO test-dev#AP75#48.4$Object Detection#COCO test-dev#APM#47.2$Object Detection#COCO test-dev#AP50#68.3$Object Detection#COCO test-dev#AP75#53.2$Object Detection#COCO test-dev#APS#32.4$Object Detection#COCO test-dev#APL#60.0$Object Detection#COCO test-dev#AP50#61.6$Object Detection#COCO test-dev#AP75#46.9$Object Detection#COCO minival#box AP#48.6$Object Detection#COCO minival#AP50#67.8$Object Detection#COCO minival#box AP#45.6$Object Detection#COCO minival#APS#29.2$Object Detection#COCO minival#APL#58.8$Object Detection#COCO minival#box AP#44.9$Object Detection#COCO minival#APS#28.5$Object Detection#COCO minival#APL#57.7$Object Detection#COCO minival#box AP#44.6$Object Detection#COCO minival#APS#27.7$Object Detection#COCO minival#APM#48.3$Object Detection#COCO minival#box AP#44.4$Object Detection#COCO minival#APS#26.7$Object Detection#COCO minival#APL#57.1$Instance Segmentation#COCO test-dev#mask AP#41.8$Instance Segmentation#COCO test-dev#APS#24.4$Instance Segmentation#COCO test-dev#APM#44.4$Instance Segmentation#COCO test-dev#APL#54.3$Instance Segmentation#COCO test-dev#mask AP#40.6$Instance Segmentation#COCO test-dev#AP50#62.3$Instance Segmentation#COCO test-dev#AP75#44.1$Instance Segmentation#COCO test-dev#APS#20.1$Instance Segmentation#COCO test-dev#APM#42.8$Instance Segmentation#COCO test-dev#APL#57.0$Instance Segmentation#COCO test-dev#mask AP#39.6$Instance Segmentation#COCO test-dev#AP50#61.2$Instance Segmentation#COCO test-dev#AP75#42.9$Instance Segmentation#COCO test-dev#APS#19.7$Instance Segmentation#COCO test-dev#mask AP#38.3$Instance Segmentation#COCO test-dev#AP50#66.2$Instance Segmentation#COCO test-dev#AP75#47.4$Instance Segmentation#COCO test-dev#APS#27.2$Instance Segmentation#COCO test-dev#AP50#60.8$Instance Segmentation#COCO test-dev#APS#19.4$Instance Segmentation#COCO test-dev#APM#41.7$Instance Segmentation#COCO minival#mask AP#42.5$Instance Segmentation#COCO minival#mask AP#40.2$Real-time Instance Segmentation#MSCOCO#mask AP#32.9$Real-time Instance Segmentation#MSCOCO#APS#12.9$Real-time Instance Segmentation#MSCOCO#APM#34.7$Real-time Instance Segmentation#MSCOCO#APL#48.7
1711.08189v2.pdf	Object Detection#COCO test-dev#box AP#45.7$Object Detection#COCO test-dev#AP50#67.3$Object Detection#COCO test-dev#AP75#51.1$Object Detection#COCO test-dev#APS#29.3$Object Detection#COCO test-dev#APM#48.8$Object Detection#COCO test-dev#APL#57.1$Object Detection#COCO test-dev#box AP#43.4$Object Detection#COCO test-dev#AP50#65.5$Object Detection#COCO test-dev#AP75#48.4$Object Detection#COCO test-dev#APS#27.2$Object Detection#COCO test-dev#APM#46.5$Object Detection#COCO test-dev#APL#54.9
2007.12099v3.pdf	Object Detection#COCO test-dev#box AP#45.2$Object Detection#COCO test-dev#AP50#65.2$Object Detection#COCO test-dev#AP75#49.9$Object Detection#COCO test-dev#APS#26.3$Object Detection#COCO test-dev#APM#47.8$Object Detection#COCO test-dev#APL#57.2$Object Detection#COCO test-dev#box AP#39.3$Object Detection#COCO test-dev#AP50#59.3$Object Detection#COCO test-dev#AP75#42.7$Object Detection#COCO test-dev#APS#16.7$Object Detection#COCO test-dev#APM#41.4$Object Detection#COCO test-dev#APL#57.8
1909.02466v2.pdf	Object Detection#COCO test-dev#box AP#44.8$Object Detection#COCO test-dev#AP50#64.3$Object Detection#COCO test-dev#AP75#48.4$Object Detection#COCO test-dev#APS#27$Object Detection#COCO test-dev#APM#47.9$Object Detection#COCO test-dev#APL#56
1903.00621v1.pdf	Object Detection#COCO test-dev#box AP#44.6$Object Detection#COCO test-dev#AP50#65.2$Object Detection#COCO test-dev#AP75#48.6$Object Detection#COCO test-dev#APS#29.7$Object Detection#COCO test-dev#APM#47.1$Object Detection#COCO test-dev#APL#54.6$Object Detection#COCO test-dev#box AP#40.9$Object Detection#COCO test-dev#AP50#61.5$Object Detection#COCO test-dev#AP75#44$Object Detection#COCO test-dev#APS#24$Object Detection#COCO test-dev#APM#44.2$Object Detection#COCO test-dev#APL#51.3$Object Detection#COCO test-dev#Hardware Burden#38G$Object Detection#COCO minival#box AP#41.6$Object Detection#COCO minival#AP50#62.4$Object Detection#COCO minival#box AP#39.3$Object Detection#COCO minival#AP50#59.2$Object Detection#COCO minival#box AP#37.9$Object Detection#COCO minival#AP50#58.0$Object Detection#COCO minival#box AP#35.9$Object Detection#COCO minival#AP50#55.0$Object Detection#COCO minival#AP75#37.9$Object Detection#COCO minival#APS#19.8$Object Detection#COCO minival#APM#39.6$Object Detection#COCO minival#APL#48.2
2103.09460v1.pdf	Object Detection#COCO test-dev#box AP#44.3$Object Detection#COCO test-dev#AP50#62.9$Object Detection#COCO test-dev#AP75#47.5$Object Detection#COCO test-dev#APS#24.0$Object Detection#COCO test-dev#APM#48.5$Object Detection#COCO test-dev#APL#60.4
1903.11851v1.pdf	Object Detection#COCO test-dev#box AP#44.2$Object Detection#COCO test-dev#AP50#67.5$Object Detection#COCO test-dev#AP75#51.1$Object Detection#COCO test-dev#APS#27.2$Object Detection#COCO test-dev#APM#50.3$Object Detection#COCO test-dev#APL#57.7
1811.04533v3.pdf	Object Detection#COCO test-dev#box AP#44.2$Object Detection#COCO test-dev#AP50#64.6$Object Detection#COCO test-dev#AP75#49.3$Object Detection#COCO test-dev#APS#29.2$Object Detection#COCO test-dev#APM#47.9$Object Detection#COCO test-dev#APL#55.1$Object Detection#COCO test-dev#Hardware Burden#34G$Object Detection#COCO test-dev#box AP#43.9$Object Detection#COCO test-dev#AP50#64.4$Object Detection#COCO test-dev#AP75#48$Object Detection#COCO test-dev#APS#29.6$Object Detection#COCO test-dev#APM#49.6$Object Detection#COCO test-dev#APL#54.3$Object Detection#COCO test-dev#Hardware Burden#27G$Object Detection#COCO test-dev#box AP#41.0$Object Detection#COCO test-dev#AP50#59.7$Object Detection#COCO test-dev#AP75#45$Object Detection#COCO test-dev#APS#22.1$Object Detection#COCO test-dev#APM#46.5$Object Detection#COCO test-dev#APL#53.8$Object Detection#COCO test-dev#box AP#38.8$Object Detection#COCO test-dev#AP50#59.4$Object Detection#COCO test-dev#AP75#41.7$Object Detection#COCO test-dev#APS#20.5$Object Detection#COCO test-dev#APM#43.9$Object Detection#COCO test-dev#APL#53.4$Object Detection#COCO minival#box AP#34.1$Object Detection#COCO minival#AP50#53.7$Object Detection#COCO minival#APS#15.9$Object Detection#COCO minival#APM#39.5$Object Detection#COCO minival#APL#49.3$Object Detection#COCO minival#box AP#33.2$Object Detection#COCO minival#AP50#52.2$Object Detection#COCO minival#APS#15$Object Detection#COCO minival#APM#38.2$Object Detection#COCO minival#APL#49.1
1908.04156v3.pdf	Object Detection#COCO test-dev#box AP#43.9$Object Detection#COCO test-dev#AP50#65.7$Object Detection#COCO test-dev#AP75#48.1$Object Detection#COCO test-dev#APS#25.4$Object Detection#COCO test-dev#APM#46.7$Object Detection#COCO test-dev#APL#56.3$Object Detection#COCO minival#box AP#41.7$Object Detection#COCO minival#AP50#63.6$Object Detection#COCO minival#AP75#45.6$Object Detection#COCO minival#APS#25.2$Object Detection#COCO minival#APM#45.8$Image Classification#ImageNet#Top 1 Accuracy#79.33%$Image Classification#ImageNet#Top 5 Accuracy#94.6%$Image Classification#ImageNet#Number of params#42.9M$Image Classification#ImageNet#Top 1 Accuracy#78.15%$Image Classification#ImageNet#Top 5 Accuracy#94.02%$Image Classification#ImageNet#Number of params#25.8M$Image Classification#ImageNet#Top 1 Accuracy#76.64%$Image Classification#ImageNet#Top 5 Accuracy#93.16%$Image Classification#ImageNet#Number of params#8.7M
1911.09516v2.pdf	Object Detection#COCO test-dev#box AP#43.9$Object Detection#COCO test-dev#AP50#64.1$Object Detection#COCO test-dev#AP75#49.2$Object Detection#COCO test-dev#APS#27.0$Object Detection#COCO test-dev#APM#46.6$Object Detection#COCO test-dev#APL#53.4
1904.03797v2.pdf	Object Detection#COCO test-dev#box AP#43.9$Object Detection#COCO test-dev#AP50#63.5$Object Detection#COCO test-dev#AP75#47.7$Object Detection#COCO test-dev#APS#26.8$Object Detection#COCO test-dev#APM#46.9$Object Detection#COCO test-dev#APL#55.6$Object Detection#COCO test-dev#box AP#42.1$Object Detection#COCO test-dev#AP50#61.9$Object Detection#COCO test-dev#AP75#45.2$Object Detection#COCO test-dev#APM#46.8$Object Detection#COCO test-dev#APS#24.9$Object Detection#COCO minival#box AP#38.9$Object Detection#COCO minival#AP50#58.4$Object Detection#COCO minival#AP75#41.5$Object Detection#COCO minival#APS#22.3$Object Detection#COCO minival#APM#43.5$Object Detection#COCO minival#APL#51.7$Object Detection#COCO minival#box AP#38.1$Object Detection#COCO minival#AP50#57.8$Object Detection#COCO minival#AP75#40.5$Object Detection#COCO minival#box AP#38$Object Detection#COCO minival#AP75#40.2$Object Detection#COCO minival#APS#19.5$Object Detection#COCO minival#APM#42.2$Object Detection#COCO minival#APL#52.7$Object Detection#COCO minival#box AP#36.0$Object Detection#COCO minival#AP50#55.2$Object Detection#COCO minival#AP75#37.9$Object Detection#COCO minival#APS#18.6$Object Detection#COCO minival#APM#39.4$Object Detection#COCO minival#APL#50.5
1901.08043v3.pdf	Object Detection#COCO test-dev#box AP#43.7$Object Detection#COCO test-dev#AP50#60.5$Object Detection#COCO test-dev#AP75#47.0$Object Detection#COCO test-dev#APS#24.1$Object Detection#COCO test-dev#APM#46.9$Object Detection#COCO test-dev#APL#57.6$Object Detection#COCO test-dev#Hardware Burden#180G$Object Detection#COCO test-dev#box AP#40.2$Object Detection#COCO test-dev#AP50#55.5$Object Detection#COCO test-dev#AP75#43.2$Object Detection#COCO test-dev#APS#20.4$Object Detection#COCO test-dev#APM#43.2$Object Detection#COCO test-dev#APL#53.1$Object Detection#COCO minival#box AP#43.3$Object Detection#COCO minival#AP50#59.6$Object Detection#COCO minival#AP75#46.8$Object Detection#COCO minival#APS#25.7$Object Detection#COCO minival#APM#46.6$Object Detection#COCO minival#APL#59.4$Object Detection#COCO minival#box AP#40.3$Object Detection#COCO minival#AP50#55.1$Object Detection#COCO minival#AP75#43.7$Object Detection#COCO minival#APS#21.6$Object Detection#COCO minival#APM#44.0$Object Detection#COCO minival#APL#56.1
2004.10934v1.pdf	Object Detection#COCO test-dev#box AP#43.5$Object Detection#COCO test-dev#AP50#65.7$Object Detection#COCO test-dev#AP75#47.3$Object Detection#COCO test-dev#APS#26.7$Object Detection#COCO test-dev#APM#46.7$Object Detection#COCO test-dev#APL#53.3
1811.12030v1.pdf	Object Detection#COCO test-dev#box AP#43.2$Object Detection#COCO test-dev#AP50#63.0$Object Detection#COCO test-dev#AP75#46.6$Object Detection#COCO test-dev#APS#25.1$Object Detection#COCO test-dev#APM#46.5$Object Detection#COCO test-dev#APL#55.2$Object Detection#COCO minival#box AP#41.3$Object Detection#COCO minival#AP50#60.3$Object Detection#COCO minival#AP75#44.4$Object Detection#COCO minival#APS#23.4$Object Detection#COCO minival#APM#45.8$Object Detection#COCO minival#APL#54.1$Object Detection#COCO minival#box AP#39.6$Object Detection#COCO minival#AP50#58.3$Object Detection#COCO minival#AP75#42.4$Object Detection#COCO minival#APS#22.6$Object Detection#COCO minival#APM#43.8$Object Detection#COCO minival#APL#51.5
1904.08900v2.pdf	Object Detection#COCO test-dev#box AP#43.2$Object Detection#COCO test-dev#APS#24.4$Object Detection#COCO test-dev#APM#44.6$Object Detection#COCO test-dev#APL#57.3$Object Detection#COCO test-dev#box AP#34.4$Object Detection#COCO minival#box AP#42.6$Object Detection#COCO minival#APS#25.5$Object Detection#COCO minival#APM#44.3$Object Detection#COCO minival#APL#58.4$Object Detection#COCO minival#box AP#41.4$Object Detection#COCO minival#APS#23.8$Object Detection#COCO minival#APM#43.5$Object Detection#COCO minival#APL#57.1
1904.02701v1.pdf	Object Detection#COCO test-dev#box AP#43.0$Object Detection#COCO test-dev#AP50#64$Object Detection#COCO test-dev#AP75#47$Object Detection#COCO test-dev#APS#25.3$Object Detection#COCO test-dev#APM#45.6$Object Detection#COCO test-dev#APL#54.6$Object Detection#COCO minival#box AP#38.5$Object Detection#COCO minival#AP50#59.3$Object Detection#COCO minival#AP75#42.0$Object Detection#COCO minival#APS#22.9$Object Detection#COCO minival#APM#42.1$Object Detection#COCO minival#APL#50.5
1712.00726v1.pdf	Object Detection#COCO test-dev#box AP#42.8$Object Detection#COCO test-dev#AP50#62.1$Object Detection#COCO test-dev#AP75#46.3$Object Detection#COCO test-dev#APS#23.7$Object Detection#COCO test-dev#APM#45.5$Object Detection#COCO test-dev#APL#55.2$Object Detection#COCO test-dev#box AP#40.6$Object Detection#COCO test-dev#AP50#59.9$Object Detection#COCO test-dev#AP75#44$Object Detection#COCO test-dev#APS#22.6$Object Detection#COCO test-dev#APM#42.7$Object Detection#COCO test-dev#APL#52.1$Object Detection#COCO test-dev#Hardware Burden#12G$Object Detection#COCO test-dev#box AP#38.8$Object Detection#COCO test-dev#AP50#61.1$Object Detection#COCO test-dev#AP75#41.9$Object Detection#COCO test-dev#APS#21.3$Object Detection#COCO test-dev#APM#41.8$Object Detection#COCO test-dev#APL#49.8$Object Detection#COCO test-dev#Hardware Burden#3G$Object Detection#COCO test-dev#box AP#36.5$Object Detection#COCO test-dev#AP50#59$Object Detection#COCO test-dev#AP75#39.2$Object Detection#COCO test-dev#APS#20.3$Object Detection#COCO test-dev#APM#38.8$Object Detection#COCO test-dev#APL#46.4$Object Detection#COCO minival#box AP#42.7$Object Detection#COCO minival#AP50#61.6$Object Detection#COCO minival#AP75#46.6$Object Detection#COCO minival#APS#23.8$Object Detection#COCO minival#APM#46.2$Object Detection#COCO minival#APL#57.4$Object Detection#COCO minival#box AP#40.3$Object Detection#COCO minival#AP50#59.4$Object Detection#COCO minival#AP75#43.7$Object Detection#COCO minival#APS#22.9$Object Detection#COCO minival#APM#43.7$Object Detection#COCO minival#APL#54.1$Object Detection#AI-TOD#AP#13.8$Object Detection#AI-TOD#AP50#30.8$Object Detection#AI-TOD#AP75#10.5$Object Detection#AI-TOD#APvt#0.0$Object Detection#AI-TOD#APt#10.6$Object Detection#AI-TOD#APs#25.5$Object Detection#AI-TOD#APm#26.6
1906.09756v1.pdf	Object Detection#COCO test-dev#box AP#42.8$Object Detection#COCO test-dev#AP50#62.1$Object Detection#COCO test-dev#AP75#46.3$Object Detection#COCO test-dev#APS#23.7$Object Detection#COCO test-dev#APM#45.5$Object Detection#COCO test-dev#APL#55.2$Object Detection#COCO test-dev#Hardware Burden#15G$Instance Segmentation#BDD100K#AP#19.8$Instance Segmentation#BDD100K val#AP#19.8
1901.03353v1.pdf	Object Detection#COCO test-dev#box AP#42.6$Object Detection#COCO test-dev#AP50#62.5$Object Detection#COCO test-dev#AP75#46.0$Object Detection#COCO test-dev#APS#24.8$Object Detection#COCO test-dev#APM#45.6$Object Detection#COCO test-dev#APL#53.8$Object Detection#COCO test-dev#Hardware Burden#12G$Object Detection#COCO test-dev#box AP#39.4$Object Detection#COCO test-dev#AP50#58.6$Object Detection#COCO test-dev#AP75#42.3$Object Detection#COCO test-dev#APS#21.9$Object Detection#COCO test-dev#APM#42.0$Object Detection#COCO test-dev#APL#51.0$Object Detection#COCO test-dev#Hardware Burden#9G$Object Detection#COCO minival#box AP#41.1$Object Detection#COCO minival#AP50#60.2$Object Detection#COCO minival#AP75#44.1
2108.07755v3.pdf	Object Detection#COCO test-dev#box AP#42.5$Object Detection#COCO test-dev#AP50#60.3$Object Detection#COCO test-dev#AP75#46.4
1808.01244v2.pdf	Object Detection#COCO test-dev#box AP#42.1$Object Detection#COCO test-dev#AP50#57.8$Object Detection#COCO test-dev#AP75#45.3$Object Detection#COCO test-dev#APS#20.8$Object Detection#COCO test-dev#APM#44.8$Object Detection#COCO test-dev#APL#56.7$Object Detection#COCO test-dev#box AP#37.8$Object Detection#COCO test-dev#AP50#53.7$Object Detection#COCO test-dev#AP75#40.1$Object Detection#COCO test-dev#APS#17.0$Object Detection#COCO test-dev#APM#39.0$Object Detection#COCO test-dev#APL#50.5$Object Detection#COCO minival#box AP#38.4$Object Detection#COCO minival#AP50#53.8$Object Detection#COCO minival#AP75#40.9$Object Detection#COCO minival#APS#18.6$Object Detection#COCO minival#APM#40.5$Object Detection#COCO minival#APL#51.8
1711.06897v3.pdf	Object Detection#COCO test-dev#box AP#41.8$Object Detection#COCO test-dev#AP50#62.9$Object Detection#COCO test-dev#AP75#45.7$Object Detection#COCO test-dev#APS#25.6$Object Detection#COCO test-dev#APM#45.1$Object Detection#COCO test-dev#APL#54.1$Object Detection#COCO test-dev#box AP#37.6$Object Detection#COCO test-dev#AP50#58.7$Object Detection#COCO test-dev#AP75#40.8$Object Detection#COCO test-dev#APS#22.7$Object Detection#COCO test-dev#APM#40.3$Object Detection#COCO test-dev#APL#48.3$Object Detection#COCO test-dev#box AP#36.4$Object Detection#COCO test-dev#AP50#57.5$Object Detection#COCO test-dev#AP75#39.5$Object Detection#COCO test-dev#APS#16.6$Object Detection#COCO test-dev#APM#39.9$Object Detection#COCO test-dev#APL#51.4$Object Detection#COCO test-dev#box AP#33$Object Detection#COCO test-dev#AP50#54.5$Object Detection#COCO test-dev#AP75#35.5$Object Detection#COCO test-dev#APS#16.3$Object Detection#COCO test-dev#APM#36.3$Object Detection#COCO test-dev#APL#44.3
1811.05181v1.pdf	Object Detection#COCO test-dev#box AP#41.6$Object Detection#COCO test-dev#AP50#62.8$Object Detection#COCO test-dev#AP75#44.2$Object Detection#COCO test-dev#APS#22.3$Object Detection#COCO test-dev#APM#45.1$Object Detection#COCO test-dev#APL#55.3$Object Detection#COCO minival#box AP#35.8$Object Detection#COCO minival#AP50#55.5$Object Detection#COCO minival#AP75#38.1$Object Detection#COCO minival#APS#19.6$Object Detection#COCO minival#APM#39.6$Object Detection#COCO minival#APL#46.7
1904.07850v2.pdf	Object Detection#COCO test-dev#box AP#41.6$Object Detection#COCO test-dev#APS#21.5$Object Detection#COCO test-dev#APM#43.9$Object Detection#COCO test-dev#APL#56.0$Object Detection#COCO test-dev#Hardware Burden#26G$Object Detection#PASCAL VOC 2007#MAP#80.7%$Object Detection#UA-DETRAC#mAP#83.48
1909.06720v2.pdf	Object Detection#COCO test-dev#box AP#40.6$Object Detection#COCO test-dev#AP50#58.9$Object Detection#COCO test-dev#AP75#44.5$Object Detection#COCO test-dev#APS#22.0$Object Detection#COCO test-dev#APM#42.8$Object Detection#COCO test-dev#APL#52.6$Object Detection#COCO test-dev#Hardware Burden#5G$Object Detection#COCO test-dev#box AP#40.1$Object Detection#COCO test-dev#AP50#59.4$Object Detection#COCO test-dev#AP75#43.8$Object Detection#COCO test-dev#APS#22.1$Object Detection#COCO test-dev#APM#42.4$Object Detection#COCO test-dev#APL#51.6
1910.02940v2.pdf	Object Detection#COCO test-dev#box AP#40.6$Object Detection#COCO test-dev#APS#24.6$Object Detection#COCO test-dev#APM#43.9$Object Detection#COCO test-dev#APL#53.3$Image Classification#ImageNet#Top 1 Accuracy#78.5%
1807.11590v1.pdf	Object Detection#COCO test-dev#box AP#40.6
1809.08545v3.pdf	Object Detection#COCO test-dev#box AP#40.4$Object Detection#PASCAL VOC 2007#MAP#71.6%
1912.05070v1.pdf	Object Detection#COCO test-dev#box AP#40.3$Object Detection#COCO test-dev#AP50#60.1$Object Detection#COCO test-dev#AP75#43$Object Detection#COCO test-dev#APS#22.1$Object Detection#COCO test-dev#APM#43.5$Object Detection#COCO test-dev#APL#51.5$Instance Segmentation#COCO test-dev#mask AP#36.4%$Instance Segmentation#COCO test-dev#AP50#57.9%$Instance Segmentation#COCO test-dev#AP75#39.0%$Instance Segmentation#COCO test-dev#APS#16.4%$Instance Segmentation#COCO test-dev#APM#39.5%$Instance Segmentation#COCO test-dev#APL#51.6%
2002.05712v3.pdf	Object Detection#COCO test-dev#box AP#40.1$Object Detection#COCO test-dev#AP50#60.5$Object Detection#COCO test-dev#AP75#44.1$Object Detection#COCO test-dev#APS#35.8$Object Detection#COCO test-dev#APM#57.3$Object Detection#COCO test-dev#APL#38.5
1901.03278v2.pdf	Object Detection#COCO test-dev#box AP#39.8$Object Detection#COCO test-dev#AP50#59.2$Object Detection#COCO test-dev#AP75#43.5$Object Detection#COCO test-dev#APS#21.8$Object Detection#COCO test-dev#APM#42.6$Object Detection#COCO test-dev#APL#50.7
1708.08169v1.pdf	Object Detection#COCO test-dev#box AP#39.5
1904.09925v5.pdf	Object Detection#COCO test-dev#box AP#39.2$Object Detection#COCO test-dev#Operations per network pass#24.5G$Image Classification#CIFAR-100#Percentage correct#81.6$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Top 5 Accuracy#94.6%
2003.12125v1.pdf	Object Detection#COCO test-dev#box AP#38.5$Object Detection#COCO test-dev#AP50#55.6$Object Detection#COCO test-dev#AP75#41.4$Object Detection#COCO test-dev#APS#19.2$Object Detection#COCO test-dev#APM#42.1$Object Detection#COCO test-dev#APL#50.6$Object Detection#COCO test-dev#Hardware Burden#46G
1907.09665v10.pdf	Object Detection#COCO test-dev#box AP#37.9$Object Detection#COCO test-dev#box AP#21.4$Image Classification#ImageNet#Top 1 Accuracy#72.56%$Image Classification#ImageNet#Top 5 Accuracy#90.92$Image Classification#ImageNet#Number of params#4.26M$Image Classification#ImageNet#GFLOPs#1.198
1703.06211v3.pdf	Object Detection#COCO test-dev#box AP#37.5$Object Detection#COCO test-dev#AP50#58.0$Object Detection#COCO test-dev#APS#19.4$Object Detection#COCO test-dev#APM#40.1$Object Detection#COCO test-dev#APL#52.5
2011.12913v2.pdf	Object Detection#COCO test-dev#box AP#36.9$Object Detection#COCO test-dev#box AP#35.9$Image Classification#ImageNet#Top 1 Accuracy#71.71%$Image Classification#ImageNet#Top 1 Accuracy#71.56%$Image Classification#ImageNet#Top 1 Accuracy#71.37%$Image Classification#ImageNet#Top 1 Accuracy#71.08%$Image Classification#ImageNet#Top 1 Accuracy#70.93%$Image Classification#ImageNet#Top 1 Accuracy#70.52%$Image Classification#ImageNet#Top 1 Accuracy#70.09%$Instance Segmentation#COCO test-dev#mask AP#33.6
1612.06851v2.pdf	Object Detection#COCO test-dev#box AP#36.8
1611.10012v3.pdf	Object Detection#COCO test-dev#box AP#34.7
1604.02135v2.pdf	Object Detection#COCO test-dev#box AP#33.2$Object Detection#COCO test-dev#Hardware Burden#11G$Instance Segmentation#COCO test-dev#mask AP#25.0%
1512.04143v1.pdf	Object Detection#COCO test-dev#box AP#33.1$Object Detection#COCO test-dev#AP50#55.7$Object Detection#COCO test-dev#AP75#34.6$Object Detection#COCO test-dev#APS#14.5$Object Detection#COCO test-dev#APM#35.2$Object Detection#COCO test-dev#APL#47.2
1804.02767v1.pdf	Object Detection#COCO test-dev#box AP#33.0$Object Detection#COCO test-dev#Hardware Burden#0G$Object Detection#COCO test-dev#Operations per network pass#146.0G
1512.02325v5.pdf	Object Detection#COCO test-dev#box AP#28.8$Object Detection#COCO test-dev#AP50#48.5$Object Detection#COCO test-dev#AP75#30.3$Object Detection#PASCAL VOC 2007#MAP#81.6%$Object Detection#PASCAL VOC 2012#MAP#80
1912.01106v2.pdf	Object Detection#COCO test-dev#box AP#26.1$Object Detection#COCO test-dev#box AP#25.5$Object Detection#COCO test-dev#box AP#24.6$Object Detection#COCO test-dev#box AP#23.8
1504.08083v2.pdf	Object Detection#COCO test-dev#box AP#19.7$Object Detection#PASCAL VOC 2007#MAP#70.0%
1704.04861v1.pdf	Object Detection#COCO test-dev#box AP#19.3$Image Classification#ImageNet#Top 1 Accuracy#70.6%$Image Classification#ImageNet#Number of params#4.2M$Image Classification#ImageNet#GFLOPs#1.138
2104.13534v1.pdf	Object Detection#COCO test-dev#AP50#59.8$Object Detection#COCO test-dev#AP75#45.3$Object Detection#COCO test-dev#APS#22.8$Object Detection#COCO test-dev#APM#45.8$Object Detection#COCO test-dev#APL#59.2
1811.03818v1.pdf	Object Detection#KITTI Cars Easy#AP#83.71$3D Object Detection#KITTI Cars Moderate#AP#73.04%$3D Object Detection#KITTI Cars Easy#AP#83.71%$3D Object Detection#KITTI Cars Hard#AP#59.16%
1812.05784v2.pdf	Object Detection#KITTI Cars Easy#AP#79.05$Object Detection#KITTI Cars Moderate#AP#74.99$3D Object Detection#KITTI Cyclists Easy#AP#75.78%$3D Object Detection#KITTI Cars Moderate#AP#74.99%$3D Object Detection#KITTI Cyclists Moderate#AP#59.07%$3D Object Detection#KITTI Pedestrians Moderate#AP#41.92%$3D Object Detection#KITTI Cyclists Hard#AP#52.92%$Birds Eye View Object Detection#KITTI Cars Easy#AP#88.35$Birds Eye View Object Detection#KITTI Cars Moderate#AP#86.10%$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#62.25%$Birds Eye View Object Detection#KITTI Pedestrians Moderate#AP#50.23%$Birds Eye View Object Detection#KITTI Cars Hard#AP#79.83
2204.01697v4.pdf	Object Detection#COCO 2017#AP#53.4$Object Detection#COCO 2017#AP50#72.9$Object Detection#COCO 2017#AP75#58.1$Object Detection#COCO 2017#APM#45.7$Object Detection#COCO 2017#APM50#70.3$Object Detection#COCO 2017#APM75#50$Object Detection#COCO 2017#AP#53.1$Object Detection#COCO 2017#AP50#72.5$Object Detection#COCO 2017#APM#45.4$Object Detection#COCO 2017#APM50#69.8$Object Detection#COCO 2017#APM75#49.5$Object Detection#COCO 2017#AP#52.1$Object Detection#COCO 2017#AP50#71.9$Object Detection#COCO 2017#AP75#56.8$Object Detection#COCO 2017#APM#44.6$Object Detection#COCO 2017#APM50#69.1$Object Detection#COCO 2017#APM75#48.4$Image Classification#ImageNet#Top 1 Accuracy#89.53%$Image Classification#ImageNet#Top 1 Accuracy#89.41%$Image Classification#ImageNet#Top 1 Accuracy#89.12%$Image Classification#ImageNet#Top 1 Accuracy#88.82%$Image Classification#ImageNet#Top 1 Accuracy#88.7%$Image Classification#ImageNet#Top 1 Accuracy#88.69%$Image Classification#ImageNet#Top 1 Accuracy#88.51%$Image Classification#ImageNet#Top 1 Accuracy#88.46%$Image Classification#ImageNet#Top 1 Accuracy#88.38%$Image Classification#ImageNet#Top 1 Accuracy#88.32%$Image Classification#ImageNet#Top 1 Accuracy#88.24%$Image Classification#ImageNet#Top 1 Accuracy#86.7%$Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Top 1 Accuracy#86.34%$Image Classification#ImageNet#Top 1 Accuracy#86.19%$Image Classification#ImageNet#Top 1 Accuracy#85.72%$Image Classification#ImageNet#Top 1 Accuracy#85.24%$Image Classification#ImageNet#Top 1 Accuracy#84.95%$Image Classification#ImageNet#Top 1 Accuracy#84.45%$Image Classification#ImageNet#Top 1 Accuracy#83.62%
1912.09476v2.pdf	Object Detection#COCO 2017#Mean mAP#3153
2108.03798v2.pdf	Object Detection#COCO 2017#Mean mAP#4.2$Object Detection#A2D#Mean IoU#5.8$Object Detection#SIXray#1 in 10 R@5#0.073
2112.09569v1.pdf	Object Detection#CPPE-5#box AP#52.9$Object Detection#CPPE-5#AP50#85.1$Object Detection#CPPE-5#AP75#58.3$Object Detection#CPPE-5#APS#42.6$Object Detection#CPPE-5#APM#41.3$Object Detection#CPPE-5#APL#62.6$Object Detection#CPPE-5#box AP#52.5$Object Detection#CPPE-5#AP50#86.5$Object Detection#CPPE-5#AP75#54.1$Object Detection#CPPE-5#APS#38.7$Object Detection#CPPE-5#APM#43.4$Object Detection#CPPE-5#APL#61.0$Object Detection#CPPE-5#box AP#52.0$Object Detection#CPPE-5#AP50#87.3$Object Detection#CPPE-5#AP75#55.2$Object Detection#CPPE-5#APS#38.6$Object Detection#CPPE-5#APM#41.0$Object Detection#CPPE-5#APL#60.8$Object Detection#CPPE-5#box AP#51.6$Object Detection#CPPE-5#AP50#87.1$Object Detection#CPPE-5#AP75#55.9$Object Detection#CPPE-5#APS#36.3$Object Detection#CPPE-5#APM#41.4$Object Detection#CPPE-5#APL#61.3$Object Detection#CPPE-5#box AP#51.3$Object Detection#CPPE-5#AP50#85.3$Object Detection#CPPE-5#AP75#51.8$Object Detection#CPPE-5#APS#35.7$Object Detection#CPPE-5#APM#41.1$Object Detection#CPPE-5#APL#60.5$Object Detection#CPPE-5#box AP#51.0$Object Detection#CPPE-5#AP50#82.6$Object Detection#CPPE-5#AP75#56.7$Object Detection#CPPE-5#APS#39.0$Object Detection#CPPE-5#APM#42.1$Object Detection#CPPE-5#APL#58.8$Object Detection#CPPE-5#box AP#50.9$Object Detection#CPPE-5#AP50#76.5$Object Detection#CPPE-5#AP75#58.8$Object Detection#CPPE-5#APS#45.8$Object Detection#CPPE-5#APM#43.0$Object Detection#CPPE-5#APL#59.4$Object Detection#CPPE-5#box AP#49.2$Object Detection#CPPE-5#AP50#84.7$Object Detection#CPPE-5#AP75#48.2$Object Detection#CPPE-5#APS#45.3$Object Detection#CPPE-5#APM#39.6$Object Detection#CPPE-5#APL#56.7$Object Detection#CPPE-5#box AP#48.0$Object Detection#CPPE-5#AP50#76.9$Object Detection#CPPE-5#AP75#52.8$Object Detection#CPPE-5#APS#36.4$Object Detection#CPPE-5#APM#35.2$Object Detection#CPPE-5#APL#53.9$Object Detection#CPPE-5#box AP#47.5$Object Detection#CPPE-5#AP50#77.9$Object Detection#CPPE-5#AP75#50.6$Object Detection#CPPE-5#APS#43.4$Object Detection#CPPE-5#APM#37.2$Object Detection#CPPE-5#APL#54.4$Object Detection#CPPE-5#box AP#44.4$Object Detection#CPPE-5#AP50#79.5$Object Detection#CPPE-5#AP75#45.9$Object Detection#CPPE-5#APS#36.7$Object Detection#CPPE-5#APM#39.2$Object Detection#CPPE-5#APL#51.7$Object Detection#CPPE-5#box AP#44.0$Object Detection#CPPE-5#AP50#73.8$Object Detection#CPPE-5#AP75#47.8$Object Detection#CPPE-5#APS#30.0$Object Detection#CPPE-5#APM#34.7$Object Detection#CPPE-5#APL#52.5$Object Detection#CPPE-5#AP50#69.6$Object Detection#CPPE-5#AP75#44.6$Object Detection#CPPE-5#APM#30.6$Object Detection#CPPE-5#APL#54.7$Object Detection#CPPE-5#box AP#43.0$Object Detection#CPPE-5#AP50#75.9$Object Detection#CPPE-5#AP75#40.1$Object Detection#CPPE-5#APS#27.3$Object Detection#CPPE-5#APM#36.7$Object Detection#CPPE-5#APL#48.0$Object Detection#CPPE-5#box AP#38.5$Object Detection#CPPE-5#AP50#79.4$Object Detection#CPPE-5#AP75#35.3$Object Detection#CPPE-5#APS#23.1$Object Detection#CPPE-5#APM#28.4$Object Detection#CPPE-5#APL#49.0$Object Detection#CPPE-5#box AP#29.50$Object Detection#CPPE-5#AP50#57.0$Object Detection#CPPE-5#AP75#24.9$Object Detection#CPPE-5#APS#32.1$Object Detection#CPPE-5#APM#23.1$Object Detection#CPPE-5#APL#34.6
2112.12252v1.pdf	Object Detection#SeaDronesSee#mAP@0.5#59.20$Object Detection#SeaDronesSee#mAP@0.5#59.08$Object Detection#SeaDronesSee#mAP@0.5#54.74$Object Detection#SeaDronesSee#mAP@0.5#38.74
1511.07571v1.pdf	Object Detection#Visual Genome#MAP#5.39
2110.03921v2.pdf	Object Detection#COCO 2017 val#AP#49.2$Object Detection#COCO 2017 val#AP50#69.4$Object Detection#COCO 2017 val#AP75#53.1$Object Detection#COCO 2017 val#APS#30.6$Object Detection#COCO 2017 val#APM#52.6$Object Detection#COCO 2017 val#APL#66.9$Object Detection#COCO 2017 val#Param.#0.1B$Object Detection#COCO 2017 val#AP#47.5$Object Detection#COCO 2017 val#AP50#67.7$Object Detection#COCO 2017 val#AP75#51.4$Object Detection#COCO 2017 val#APS#29.2$Object Detection#COCO 2017 val#APM#50.7$Object Detection#COCO 2017 val#APL#64.8$Object Detection#COCO 2017 val#Param.#61M$Object Detection#COCO 2017 val#AP#44.8$Object Detection#COCO 2017 val#AP50#64.5$Object Detection#COCO 2017 val#AP75#48.7$Object Detection#COCO 2017 val#APS#25.9$Object Detection#COCO 2017 val#APM#47.6$Object Detection#COCO 2017 val#APL#62.1$Object Detection#COCO 2017 val#Param.#38M$Object Detection#COCO 2017 val#AP#40.4$Object Detection#COCO 2017 val#AP50#59.6$Object Detection#COCO 2017 val#AP75#43.3$Object Detection#COCO 2017 val#APS#23.2$Object Detection#COCO 2017 val#APM#42.5$Object Detection#COCO 2017 val#APL#55.8$Object Detection#COCO 2017 val#Param.#16M
2108.07944v3.pdf	Object Detection#STN PLAD#mAP#89.2%
1909.13080v1.pdf	Object Detection#India Driving Dataset#mAP@0.5#31.57$Object Detection#BDD100K#mAP@0.5#45.7
2111.12389v5.pdf	Object Detection#Drone vs Bird#AP50#79.4$Object Detection#Drone vs Bird#AP50s#86.2$Object Detection#Drone vs Bird#AP50m#72.7$Object Detection#Drone vs Bird#AP50l#70.3$Object Detection#Drone vs Bird#AP50#76.1$Object Detection#Drone vs Bird#AP50s#86.6$Object Detection#Drone vs Bird#AP50m#67.6$Object Detection#Drone vs Bird#AP50l#43
2105.01882v4.pdf	Object Detection#DeepTrash#mAP#0.856
2203.16527v2.pdf	Object Detection#COCO minival#box AP#61.3$Object Detection#COCO minival#box AP#60.4$Instance Segmentation#COCO minival#mask AP#53.1$Instance Segmentation#COCO minival#mask AP#52
2205.10063v1.pdf	Object Detection#COCO minival#box AP#57.4
2107.00057v1.pdf	Object Detection#COCO minival#box AP#53.6$Object Detection#COCO minival#APS#34.5$Object Detection#COCO minival#APM#56.7$Object Detection#COCO minival#APL#70.6$Object Detection#COCO minival#box AP#53.1$Object Detection#COCO minival#APS#33.9$Object Detection#COCO minival#APM#56.2$Object Detection#COCO minival#APL#70.3
2106.13797v6.pdf	Object Detection#COCO minival#box AP#50.1$Object Detection#COCO minival#AP50#69.5$Object Detection#COCO minival#AP75#54.9$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Number of params#82M$Image Classification#ImageNet#GFLOPs#11.8$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#45.2M$Image Classification#ImageNet#GFLOPs#6.9$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Number of params#25.4M$Image Classification#ImageNet#GFLOPs#4$Image Classification#ImageNet#Top 1 Accuracy#78.7%$Image Classification#ImageNet#Number of params#13.1M$Image Classification#ImageNet#GFLOPs#2.1$Image Classification#ImageNet#Top 1 Accuracy#70.5%$Image Classification#ImageNet#Number of params#3.4M$Image Classification#ImageNet#GFLOPs#0.6
2109.10852v2.pdf	Object Detection#COCO minival#box AP#50.0$Object Detection#COCO minival#box AP#47.3$Object Detection#COCO minival#box AP#47.1$Object Detection#COCO minival#box AP#45.0$Object Detection#COCO minival#AP50#63.2$Object Detection#COCO minival#AP75#48.6$Object Detection#COCO minival#APS#28.2$Object Detection#COCO minival#APM#48.9$Object Detection#COCO minival#APL#60.4$Object Detection#COCO minival#box AP#43.2$Object Detection#COCO minival#AP50#61.0$Object Detection#COCO minival#AP75#46.1$Object Detection#COCO minival#APS#26.6$Object Detection#COCO minival#APM#47$Object Detection#COCO minival#APL#58.6$Object Detection#COCO minival#box AP#42.6
2101.11605v2.pdf	Object Detection#COCO minival#box AP#49.7$Object Detection#COCO minival#AP50#71.3$Object Detection#COCO minival#AP75#54.6$Object Detection#COCO minival#box AP#49.5$Object Detection#COCO minival#AP50#71$Object Detection#COCO minival#AP75#54.2$Object Detection#COCO minival#box AP#45.9$Image Classification#ImageNet#Top 1 Accuracy#84.7%$Image Classification#ImageNet#Top 5 Accuracy#97%$Image Classification#ImageNet#Number of params#75.1M$Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#Top 5 Accuracy#96.9%$Image Classification#ImageNet#Top 1 Accuracy#84%$Image Classification#ImageNet#Top 5 Accuracy#96.7%$Image Classification#ImageNet#Number of params#53.9M$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Top 5 Accuracy#96.6%$Image Classification#ImageNet#Top 1 Accuracy#83.5%$Image Classification#ImageNet#Top 5 Accuracy#96.5%$Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Top 5 Accuracy#96.3%$Image Classification#ImageNet#Number of params#54.7M$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Top 5 Accuracy#95.9%$Image Classification#ImageNet#Number of params#66.6M$Image Classification#ImageNet#Top 1 Accuracy#81.7%$Image Classification#ImageNet#Top 5 Accuracy#95.8%$Image Classification#ImageNet#Number of params#33.5M$Image Classification#ImageNet#Top 1 Accuracy#81.4%$Image Classification#ImageNet#Top 5 Accuracy#95.7%$Image Classification#ImageNet#Number of params#49.2M$Image Classification#ImageNet#Top 1 Accuracy#80%$Image Classification#ImageNet#Top 5 Accuracy#95%$Image Classification#ImageNet#Number of params#44.4M$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Top 5 Accuracy#94.6%$Image Classification#ImageNet#Number of params#28.02M$Image Classification#ImageNet#Top 1 Accuracy#78.8%$Image Classification#ImageNet#Top 5 Accuracy#94.5%$Image Classification#ImageNet#Number of params#25.5M$Instance Segmentation#COCO minival#mask AP#44.4$Instance Segmentation#COCO minival#mask AP#43.7$Instance Segmentation#COCO minival#mask AP#40.7
2112.04632v2.pdf	Object Detection#COCO minival#box AP#49.1$Object Detection#COCO minival#AP50#67.5$Object Detection#COCO minival#AP75#53.1$Object Detection#COCO minival#APS#30$Object Detection#COCO minival#APM#52.6$Object Detection#COCO minival#APL#65$Object Detection#COCO#GFlops#434$Object Detection#COCO#Params (M)#119
1811.08883v1.pdf	Object Detection#COCO minival#box AP#48.6$Object Detection#COCO minival#AP50#66.8$Object Detection#COCO minival#AP75#52.9$Object Detection#COCO minival#box AP#47.4$Object Detection#COCO minival#box AP#46.4$Object Detection#COCO minival#AP50#67.1$Object Detection#COCO minival#AP75#51.1
2111.13336v5.pdf	Object Detection#COCO minival#box AP#47.8$Object Detection#COCO minival#AP50#65.5$Object Detection#COCO minival#AP75#52.2$Object Detection#COCO minival#APS#30.3$Object Detection#COCO minival#APM#51.9$Object Detection#COCO minival#APL#61.1
2011.12450v2.pdf	Object Detection#COCO minival#box AP#45.6$Object Detection#COCO minival#AP50#64.6$Object Detection#COCO minival#AP75#49.5$Object Detection#COCO minival#APS#28.3$Object Detection#COCO minival#APM#48.3$Object Detection#COCO minival#APL#61.6$Object Detection#COCO minival#box AP#44.5$Object Detection#COCO minival#AP50#63.4$Object Detection#COCO minival#AP75#48.2$Object Detection#COCO minival#APS#26.9$Object Detection#COCO minival#APM#47.2$Object Detection#COCO minival#APL#59.5$Object Detection#COCO minival#box AP#43.5$Object Detection#COCO minival#AP50#62.1$Object Detection#COCO minival#AP75#47.2$Object Detection#COCO minival#APS#26.1$Object Detection#COCO minival#APM#46.3$Object Detection#COCO minival#APL#59.7$Object Detection#COCO minival#box AP#42.3$Object Detection#COCO minival#AP50#61.2$Object Detection#COCO minival#AP75#45.7$Object Detection#COCO minival#APS#26.7$Object Detection#COCO minival#APM#44.6$Object Detection#COCO minival#APL#57.6
1908.01259v3.pdf	Object Detection#COCO minival#box AP#44.9$Object Detection#COCO minival#AP50#66.2$Object Detection#COCO minival#AP75#49.1$Image Classification#ImageNet#Top 1 Accuracy#81.87%$Image Classification#ImageNet#Top 5 Accuracy#95.74$Image Classification#ImageNet#GFLOPs#7.51$Instance Segmentation#COCO minival#mask AP#40.2$Instance Segmentation#COCO minival#AP50#63.2$Instance Segmentation#COCO minival#AP75#43.3
2104.01329v2.pdf	Object Detection#COCO minival#box AP#44.8$Object Detection#COCO minival#AP50#64.3$Object Detection#COCO minival#AP75#48.9$Object Detection#COCO minival#APS#26.6$Object Detection#COCO minival#APM#48.3$Object Detection#COCO minival#APL#59.6$Object Detection#COCO minival#box AP#44.3$Object Detection#COCO minival#AP50#64.1$Object Detection#COCO minival#AP75#48.4$Object Detection#COCO minival#APS#27$Object Detection#COCO minival#APM#47.1$Object Detection#COCO minival#APL#58.9$Object Detection#COCO minival#box AP#42$Object Detection#COCO minival#AP50#61$Object Detection#COCO minival#AP75#46.3$Object Detection#COCO minival#APS#24.5$Object Detection#COCO minival#APM#45.2$Object Detection#COCO minival#APL#55.7$Object Detection#COCO minival#AP50#61.2$Object Detection#COCO minival#AP75#45.6$Object Detection#COCO minival#APS#24.4$Instance Segmentation#coco minval#APL#56$Instance Segmentation#COCO minival#mask AP#40.4$Instance Segmentation#COCO minival#AP50#61.3$Instance Segmentation#COCO minival#AP75#44$Instance Segmentation#COCO minival#APL#56.1$Instance Segmentation#COCO minival#APM#43.6$Instance Segmentation#COCO minival#APS#22.3$Instance Segmentation#COCO minival#mask AP#40.2$Instance Segmentation#COCO minival#AP50#61.1$Instance Segmentation#COCO minival#AP75#43.5$Instance Segmentation#COCO minival#APM#42.8$Instance Segmentation#COCO minival#APS#22.6$Instance Segmentation#COCO minival#mask AP#39.1$Instance Segmentation#COCO minival#AP50#58.8$Instance Segmentation#COCO minival#AP75#42.3$Instance Segmentation#COCO minival#APL#54.3$Instance Segmentation#COCO minival#APM#42.1$Instance Segmentation#COCO minival#APS#20.7$Instance Segmentation#COCO minival#mask AP#38.2$Instance Segmentation#COCO minival#AP50#58$Instance Segmentation#COCO minival#AP75#41.4$Instance Segmentation#COCO minival#APL#52.8$Instance Segmentation#COCO minival#APM#41$Instance Segmentation#COCO minival#APS#20.4
2103.15358v2.pdf	Object Detection#COCO minival#box AP#44.7$Object Detection#COCO minival#AP75#47.6$Object Detection#COCO minival#APS#29.9$Object Detection#COCO minival#APM#48$Object Detection#COCO minival#APL#58.1$Object Detection#COCO minival#box AP#44.3$Object Detection#COCO minival#AP50#65.5$Object Detection#COCO minival#AP75#47.1$Object Detection#COCO minival#APS#28.9$Object Detection#COCO minival#APM#47.9$Object Detection#COCO minival#APL#58.3$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#39.7M$Image Classification#ImageNet#GFLOPs#8.7$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#55.7M$Image Classification#ImageNet#GFLOPs#13.4$Image Classification#ImageNet#Top 1 Accuracy#82.9%$Image Classification#ImageNet#Number of params#39.8M$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Number of params#24.6M$Image Classification#ImageNet#GFLOPs#4.86$Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#Number of params#79M$Image Classification#ImageNet#GFLOPs#6.74$Image Classification#ImageNet#Top 1 Accuracy#76.7%$Image Classification#ImageNet#Number of params#6.7$Image Classification#ImageNet#GFLOPs#1.3$Image Classification#ImageNet#Number of params#6.7M$Instance Segmentation#COCO minival#mask AP#45.7$Instance Segmentation#COCO minival#AP75#49.9$Instance Segmentation#COCO minival#APL#44.5$Instance Segmentation#COCO minival#APM#64.4$Instance Segmentation#COCO minival#APS#41.3$Instance Segmentation#COCO minival#mask AP#45.1$Instance Segmentation#COCO minival#AP50#67.2$Instance Segmentation#COCO minival#AP75#49.3$Instance Segmentation#COCO minival#APL#44.2$Instance Segmentation#COCO minival#APM#64.3$Instance Segmentation#COCO minival#APS#41
1903.10520v2.pdf	Object Detection#COCO minival#box AP#43.12$Object Detection#COCO minival#AP50#64.15$Object Detection#COCO minival#AP75#47.11$Object Detection#COCO minival#APS#25.49$Object Detection#COCO minival#APM#47.19$Object Detection#COCO minival#APL#56.39$Instance Segmentation#COCO minival#mask AP#38.34$Instance Segmentation#COCO minival#AP50#61.07$Instance Segmentation#COCO minival#AP75#40.82$Instance Segmentation#COCO minival#APL#56.08$Instance Segmentation#COCO minival#APM#41.73$Instance Segmentation#COCO minival#APS#18.32
2106.02253v2.pdf	Object Detection#COCO minival#box AP#42.8$Object Detection#COCO minival#AP50#64$Object Detection#COCO minival#AP75#46.4$Object Detection#COCO minival#APS#26.9$Object Detection#COCO minival#APM#46$Object Detection#COCO minival#APL#55$Image Classification#ImageNet#Top 1 Accuracy#76.6%$Image Classification#ImageNet#Top 5 Accuracy#93.3%$Image Classification#ImageNet#Top 1 Accuracy#75%$Image Classification#ImageNet#Top 5 Accuracy#92.4%$Instance Segmentation#COCO minival#mask AP#37.2$Instance Segmentation#COCO minival#APL#53.1$Instance Segmentation#COCO minival#APM#40$Instance Segmentation#COCO minival#APS#19.2
1803.08494v3.pdf	Object Detection#COCO minival#box AP#42.3$Object Detection#COCO minival#AP50#62.8$Object Detection#COCO minival#AP75#46.2$Object Detection#COCO minival#box AP#40.8$Object Detection#COCO minival#AP50#61.6$Object Detection#COCO minival#AP75#44.4$Object Detection#COCO minival#box AP#40.3$Object Detection#COCO minival#AP50#61$Object Detection#COCO minival#AP75#44
2107.14222v1.pdf	Object Detection#COCO minival#box AP#42.3$Object Detection#COCO minival#box AP#40.8$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Number of params#87M$Image Classification#ImageNet#GFLOPs#35.368$Image Classification#ImageNet#Top 1 Accuracy#81.4%$Image Classification#ImageNet#Top 5 Accuracy#95.6$Image Classification#ImageNet#GFLOPs#9.770$Image Classification#ImageNet#Top 1 Accuracy#81.1%$Image Classification#ImageNet#Top 5 Accuracy#95.4$Image Classification#ImageNet#GFLOPs#9.412$Image Classification#ImageNet#Top 1 Accuracy#80.9%$Image Classification#ImageNet#Number of params#22M$Image Classification#ImageNet#GFLOPs#9.318$Image Classification#ImageNet#Top 1 Accuracy#73.7%$Image Classification#ImageNet#Number of params#6M$Image Classification#ImageNet#GFLOPs#2.568
2004.13665v2.pdf	Object Detection#COCO minival#box AP#38.4$Object Detection#COCO minival#AP50#59.9$Object Detection#COCO minival#AP75#41.7$Object Detection#COCO minival#APS#22.9$Object Detection#COCO minival#APM#42.1$Object Detection#COCO minival#APL#49.7$Object Detection#COCO minival#box AP#37.5$Object Detection#COCO minival#AP50#59.2$Object Detection#COCO minival#AP75#40.6$Object Detection#COCO minival#APS#22.3$Object Detection#COCO minival#APM#41.5$Object Detection#COCO minival#APL#47.8$Instance Segmentation#COCO minival#mask AP#37.2$Instance Segmentation#COCO minival#AP50#59.3$Instance Segmentation#COCO minival#AP75#39.8$Instance Segmentation#COCO minival#APL#51.2$Instance Segmentation#COCO minival#APM#41$Instance Segmentation#COCO minival#APS#20.2$Instance Segmentation#COCO minival#mask AP#35.8$Instance Segmentation#COCO minival#AP50#57.1$Instance Segmentation#COCO minival#AP75#38.0$Instance Segmentation#COCO minival#APL#48.7$Instance Segmentation#COCO minival#APM#39$Instance Segmentation#COCO minival#APS#19.1
1909.09777v3.pdf	Object Detection#COCO minival#box AP#35.6$Object Detection#COCO minival#AP50#55.3
2102.06529v2.pdf	Object Detection#PeopleArt#MAP#36$Object Detection#PeopleArt#mAP@0.5#68$Object Detection#PeopleArt#mAP@0.75#33
1610.08871v1.pdf	Object Detection#PeopleArt#mAP@0.5#59.0
2203.07669v3.pdf	Object Detection#CrowdHuman (full body)#AP#94.1$Object Detection#CrowdHuman (full body)#mMR#37.7
2206.01232v1.pdf	Object Detection#CrowdHuman (full body)#AP#93.2$Object Detection#CrowdHuman (full body)#mMR#40.5
1904.03629v1.pdf	Object Detection#CrowdHuman (full body)#AP#84.71$Object Detection#CrowdHuman (full body)#mMR#49.73
2108.07507v2.pdf	Object Detection#LVIS v1.0 val#box AP#29$Object Detection#LVIS v1.0 val#box AP#27.4$Instance Segmentation#LVIS v1.0 val#mask AP#28$Instance Segmentation#LVIS v1.0 val#mask AP#26.6
2106.08713v1.pdf	Object Detection#Waymo Open Dataset#AP/L2#70.41$Object Detection#Waymo Open Dataset#Latency, ms#6.16$Object Detection#Waymo Open Dataset#AP/L2#69.72$Object Detection#Waymo Open Dataset#Latency, ms#4.58$Object Detection#Waymo Open Dataset#AP/L2#69.56$Object Detection#Waymo Open Dataset#Latency, ms#3.74$Object Detection#Waymo Open Dataset#AP/L2#65.65$Object Detection#Waymo Open Dataset#Latency, ms#6.87$Object Detection#Waymo Open Dataset#AP/L2#64.14$Object Detection#Waymo Open Dataset#Latency, ms#3.81
1905.12886v2.pdf	Object Detection#iSAID#Average Precision#47.0$Object Detection#iSAID#Average Precision#46.31$Instance Segmentation#iSAID#Average Precision#40.00$Instance Segmentation#iSAID#Average Precision#39.54
2111.11430v6.pdf	Object Detection#PASCAL VOC 2007#MAP#84.16%$Object Detection#PASCAL VOC 2007#AP50#84.16$Object Detection#PASCAL VOC 2007#AP#64.51$Object Detection#PASCAL VOC 2007#AP75#71.29$Object Detection#PASCAL VOC 10%#AP#58.78$Object Detection#PASCAL VOC 10%#AP50#80.46$Object Detection#PASCAL VOC 10%#AP75#65.65$Object Proposal Generation#COCO#Average Recall#0.6503$Object Proposal Generation#PASCAL VOC 2012, 60 proposals per image#Average Recall#0.9126$Object Proposal Generation#Comic2k#Average Recall#0.8982 (Off-the-shelf evaluation)$Object Proposal Generation#KITTI#Average Recall#0.6353 (Off-the-shelf evaluation)$Open World Object Detection#COCO 2017 (Electronic, Indoor, Kitchen, Furniture)#MAP#31.66$Open World Object Detection#PASCAL VOC 2007#WI#0.0474$Open World Object Detection#PASCAL VOC 2007#A-OSE#7322$Open World Object Detection#PASCAL VOC 2007#MAP#64.03$Open World Object Detection#PASCAL VOC 2007#Unknown Recall#50.13$Open World Object Detection#COCO 2017 (Sports, Food)#WI#0.0179$Open World Object Detection#COCO 2017 (Sports, Food)#A-OSE#4117$Open World Object Detection#COCO 2017 (Sports, Food)#MAP#36.75$Open World Object Detection#COCO 2017 (Sports, Food)#Unknown Recall#50.89$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#A-OSE#5212$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#WI#0.0251$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#MAP#46.19$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#Unknown Recall#49.54$Class-agnostic Object Detection#Kitchen Scenes#AP50#45.43 (Kitchen Dataset is not included in training)$Class-agnostic Object Detection#Comic2k#AP50#57.72 (Comic Dataset is not included in training)$Class-agnostic Object Detection#KITTI#AP50#48.22 (KITTI Dataset is not included in training)$Class-agnostic Object Detection#PASCAL VOC#AP50#68.59 (VOC Dataset is not included in training)$Class-agnostic Object Detection#COCO#AP50#43.64 (COCO dataset is not included in training)
1708.02863v1.pdf	Object Detection#PASCAL VOC 2007#MAP#82.7%
2009.14085v1.pdf	Object Detection#PASCAL VOC 2007#MAP#81.5%
1903.11752v3.pdf	Object Detection#PASCAL VOC 2007#MAP#78.6%
1703.10295v3.pdf	Object Detection#PASCAL VOC 2007#MAP#77.1%
2011.01901v2.pdf	Object Detection#PASCAL VOC 2007#MAP#74.37%$Image Classification#ImageNet#Top 1 Accuracy#76.71%
1704.03414v1.pdf	Object Detection#PASCAL VOC 2007#MAP#74.2%
1406.4729v4.pdf	Object Detection#PASCAL VOC 2007#MAP#60.9%$Image Classification#ImageNet#Top 1 Accuracy#70.32%$Image Classification#ImageNet#Top 5 Accuracy#89.05
1311.2524v5.pdf	Object Detection#PASCAL VOC 2007#MAP#58.5%
1409.5403v2.pdf	Object Detection#PASCAL VOC 2007#MAP#45.2%
2106.04550v4.pdf	Object Detection#PASCAL VOC 2007#AP50#83.3%$Object Detection#PASCAL VOC 2007#AP#63.5%$Object Detection#PASCAL VOC 2007#AP75#70.3%$Object Detection#PASCAL VOC 10%#AP#51.4$Object Detection#PASCAL VOC 10%#AP50#72.2$Object Detection#PASCAL VOC 10%#AP75#56.6$Few-Shot Object Detection#COCO 2017#AP#30$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#24.80±0.2$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#18.69±0.2$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#14.58 ± 0.3$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#29.12±0.2
2109.07298v1.pdf	Object Detection#UAVDT#mAP#53.76$Object Detection#UA-DETRAC#mAP#88.10
2002.05540v2.pdf	Object Detection#UAVDT#mAP#52.8$Object Detection#UA-DETRAC#mAP#86.8
2003.10898v2.pdf	Object Detection#UAVDT#mAP#39.43$Object Detection#UA-DETRAC#mAP#70.57
1804.00518v1.pdf	Object Detection#UAVDT#mAP#34.35$Object Detection#UAVDT#mAP#33.62$Object Detection#UAVDT#mAP#22.32$Object Detection#UAVDT#mAP#21.59
2110.13389v2.pdf	Object Detection#AI-TOD#AP#20.8$Object Detection#AI-TOD#AP50#49.3$Object Detection#AI-TOD#AP75#14.3$Object Detection#AI-TOD#APvt#6.4$Object Detection#AI-TOD#APt#19.7$Object Detection#AI-TOD#APs#29.6$Object Detection#AI-TOD#APm#38.3$Object Detection#VisDrone-DET2019#AP50#40.3$Object Detection#VisDrone-DET2019#APvt#2.9$Object Detection#VisDrone-DET2019#APt#11.1$Object Detection#VisDrone-DET2019#APs#22.2
2007.02419v1.pdf	Object Detection#PASCAL Part 2010 - Animals#mAP@0.5#87.5$Semantic Part Detection#PASCAL Part 2010 - Animals#mAP@0.5#52.0
2111.04204v1.pdf	Object Detection#NAO#mAP#15.2$Object Detection#NAO#mAP w/o OOD#24.6$Object Detection#NAO#mAR#43.8$Object Detection#NAO#mAP#15.0$Object Detection#NAO#mAP w/o OOD#29.6$Object Detection#NAO#mAR#42.7$Object Detection#NAO#mAP#13.6$Object Detection#NAO#mAP w/o OOD#26.6$Object Detection#NAO#mAR#40.8$Object Detection#NAO#mAP#13.5$Object Detection#NAO#mAP w/o OOD#22.8$Object Detection#NAO#mAR#41.4$Object Detection#NAO#mAP#12.8$Object Detection#NAO#mAP w/o OOD#25.4$Object Detection#NAO#mAR#40.2$Object Detection#NAO#mAP#11.1$Object Detection#NAO#mAP w/o OOD#19.5$Object Detection#NAO#mAR#37.2$Object Detection#NAO#mAP#10.0$Object Detection#NAO#mAP w/o OOD#17.5$Object Detection#NAO#mAR#28.4
2203.13249v1.pdf	Object Detection#BigDetection val#AP#24.1$Object Detection#BigDetection val#AP50#33.0$Object Detection#BigDetection val#AP75#25.8$Object Detection#BigDetection val#AP#23.1$Object Detection#BigDetection val#AP50#30.2$Object Detection#BigDetection val#AP75#24.9$Object Detection#BigDetection val#AP#19.4$Object Detection#BigDetection val#AP50#29.3$Object Detection#BigDetection val#AP75#21.3$Object Detection#BigDetection val#AP#18.9$Object Detection#BigDetection val#AP50#28.8$Object Detection#BigDetection val#AP75#20.5$Object Detection#BigDetection val#AP#13.1$Object Detection#BigDetection val#AP50#19.3$Object Detection#BigDetection val#AP75#14.2$Object Detection#BigDetection val#AP#9.7$Object Detection#BigDetection val#AP50#17.4$Object Detection#BigDetection val#AP75#9.7
1910.09840v3.pdf	Object Detection#PASCAL VOC 2012#MAP#42.1$Object Detection#PASCAL VOC 2012#MAP#34.66$Object Detection#SIXray#1 in 10 R@5#0.01347
1806.10787v1.pdf	Object Detection#SUN-RGBD val#MAP#7
2011.08529v4.pdf	Object Detection#COCO+#mAR (COCO+ XS)#28.4
2205.04339v1.pdf	Object Detection#GEN1 Detection#mAP#18.9$Object Detection#GEN1 Detection#mAP#17.4$Object Detection#GEN1 Detection#mAP#14.7$Classification#N-CARS#Accuracy#92.4$Classification#N-CARS#Accuracy#91.7$Classification#N-CARS#Accuracy#90.4
2008.07043v2.pdf	Object Detection#DOTA#mAP#72.32$Object Detection In Aerial Images#DOTA#mAP#75.36%
2111.07355v3.pdf	Object Detection#Gazi University Wrist Bone X-ray Images#AP50#0.8639$Medical Object Detection#Gazi University Wrist Bone X-ray Images#AP50#0.8639
2008.05359v1.pdf	Object Detection#FlickrLogos-32#MAP#76.11
1510.02131v1.pdf	Object Detection#FlickrLogos-32#MAP#74.4$Object Detection#FlickrLogos-32#MAP#73.5$Image Classification#FlickrLogos-32#Accuracy#89.6
2003.10456v2.pdf	Object Detection#Extragalactic Planetary Nebulae#Number of sources#161
1801.01769v2.pdf	Object Detection#UA-DETRAC#mAP#53.30
2110.02531v1.pdf	3D Object Detection#KITTI Cyclists Easy#AP#89.15%$3D Object Detection#KITTI Cars Moderate#AP#72.79%$3D Object Detection#KITTI Cyclists Moderate#AP#75.86%$3D Object Detection#KITTI Pedestrians Moderate#AP#58.4%
2104.11896v3.pdf	3D Object Detection#KITTI Cyclists Easy#AP#83.83%$3D Object Detection#KITTI Pedestrians Easy#AP#47.05%$3D Object Detection#KITTI Cars Hard val#AP#82.85$3D Object Detection#KITTI Cars Moderate#AP#81.73%$3D Object Detection#KITTI Pedestrian Moderate val#AP#60.63$3D Object Detection#KITTI Cyclists Moderate#AP#66.74%$3D Object Detection#KITTI Cyclist Easy val#AP#89.13$3D Object Detection#KITTI Pedestrians Moderate#AP#41.02%$3D Object Detection#KITTI Cyclist Moderate val#AP#71.70$3D Object Detection#waymo cyclist#APH/L2#67.28$3D Object Detection#KITTI Cars Easy val#AP#92.29$3D Object Detection#KITTI Cars Moderate val#AP#85.41$3D Object Detection#KITTI Cars Easy#AP#90.28%$3D Object Detection#KITTI Pedestrians Hard#AP#38.75%$3D Object Detection#waymo vehicle#APH/L2#70.54$3D Object Detection#waymo vehicle#L1 mAP#77.66$3D Object Detection#waymo vehicle#AP#77.09$3D Object Detection#KITTI Cars Hard#AP#76.96%$3D Object Detection#waymo pedestrian#APH/L2#68.20$3D Object Detection#KITTI Pedestrian Easy val#AP#67.64$3D Object Detection#KITTI Cyclist Hard val#AP#68.29$3D Object Detection#KITTI Cyclists Hard#AP#59.03%$3D Object Detection#KITTI Pedestrian Hard val#AP#56.49
1903.01864v2.pdf	3D Object Detection#KITTI Cyclists Easy#AP#79.58%$3D Object Detection#KITTI Pedestrians Easy#AP#52.37%$3D Object Detection#KITTI Cars Moderate#AP#76.51%$3D Object Detection#KITTI Cyclists Moderate#AP#64.68%$3D Object Detection#KITTI Pedestrians Moderate#AP#43.38%$3D Object Detection#KITTI Cars Easy#AP#85.88%$3D Object Detection#KITTI Pedestrians Hard#AP#41.49%$3D Object Detection#KITTI Cars Hard#AP#68.08%$3D Object Detection#KITTI Cyclists Hard#AP#57.03%
2006.04043v2.pdf	3D Object Detection#KITTI Cyclists Easy#AP#79.22%$3D Object Detection#KITTI Pedestrians Easy#AP#55.21%$3D Object Detection#KITTI Cars Hard val#AP#79.15$3D Object Detection#KITTI Cars Moderate#AP#80.82 %$3D Object Detection#KITTI Cyclists Moderate#AP#66.13%$3D Object Detection#KITTI Pedestrians Moderate#AP#47.71%$3D Object Detection#KITTI Cars Easy val#AP#90.59$3D Object Detection#KITTI Cars Moderate val#AP#80.23$3D Object Detection#KITTI Cars Easy#AP#87.33%$3D Object Detection#KITTI Pedestrians Hard#AP#44.56%$3D Object Detection#KITTI Cars Hard#AP#74.63%$3D Object Detection#KITTI Cyclists Hard#AP#57.64%
1907.10471v1.pdf	3D Object Detection#KITTI Cyclists Easy#AP#78.89%$3D Object Detection#KITTI Pedestrians Easy#AP#53.08%$3D Object Detection#KITTI Cars Moderate#AP#77.63%$3D Object Detection#KITTI Cyclists Moderate#AP#62.53%$3D Object Detection#KITTI Pedestrians Moderate#AP#44.24%$3D Object Detection#KITTI Cars Easy#AP#86.61%$3D Object Detection#KITTI Pedestrians Hard#AP#41.97%$3D Object Detection#KITTI Cars Hard#AP#76.06%$3D Object Detection#KITTI Cyclists Hard#AP#55.77%$Birds Eye View Object Detection#KITTI Cars Easy#AP#89.66$Birds Eye View Object Detection#KITTI Pedestrians Hard#AP#45.89$Birds Eye View Object Detection#KITTI Cars Moderate#AP#87.76%$Birds Eye View Object Detection#KITTI Cyclists Hard#AP#57.85$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#65.32%$Birds Eye View Object Detection#KITTI Pedestrians Moderate#AP#51.39%$Birds Eye View Object Detection#KITTI Cyclists Easy#AP#81.04$Birds Eye View Object Detection#KITTI Pedestrians Easy#AP#60.99$Birds Eye View Object Detection#KITTI Cars Hard#AP#86.89
1912.13192v2.pdf	3D Object Detection#KITTI Cyclists Easy#AP#78.60%$3D Object Detection#KITTI Cars Moderate#AP#81.43%$3D Object Detection#KITTI Cyclists Moderate#AP#63.71%$3D Object Detection#waymo all_ns#APH/L2#71.52$3D Object Detection#waymo cyclist#APH/L2#71.16$3D Object Detection#KITTI Cars Easy#AP#90.25%$3D Object Detection#waymo vehicle#APH/L2#73.23$3D Object Detection#KITTI Cars Hard#AP#76.82%$3D Object Detection#waymo pedestrian#APH/L2#70.16$3D Object Detection#KITTI Cyclists Hard#AP#57.65%$Birds Eye View Object Detection#KITTI Cars Easy#AP#94.98$Birds Eye View Object Detection#KITTI Cars Moderate#AP#90.65%$Birds Eye View Object Detection#KITTI Cyclists Hard#AP#62.41$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#68.89%$Birds Eye View Object Detection#KITTI Cyclists Easy#AP#82.49$Birds Eye View Object Detection#KITTI Cars Hard#AP#86.14
1812.05276v1.pdf	3D Object Detection#KITTI Cyclists Easy#AP#71.40%$3D Object Detection#KITTI Pedestrians Easy#AP#56.92%$3D Object Detection#KITTI Cars Moderate#AP#72.57%$3D Object Detection#KITTI Cyclists Moderate#AP#53.46%$3D Object Detection#KITTI Pedestrians Moderate#AP#44.68%$3D Object Detection#KITTI Cars Easy#AP#79.75%$3D Object Detection#KITTI Pedestrians Hard#AP#42.39%$3D Object Detection#KITTI Cars Hard#AP#66.33%$3D Object Detection#KITTI Cyclists Hard#AP#48.34%
1712.02294v4.pdf	3D Object Detection#KITTI Cyclists Easy#AP#64.0%$3D Object Detection#KITTI Pedestrians Easy#AP#50.8%$3D Object Detection#KITTI Cars Moderate#AP#71.88%$3D Object Detection#KITTI Cyclists Moderate#AP#52.18%$3D Object Detection#KITTI Pedestrians Moderate#AP#42.81%$3D Object Detection#KITTI Cars Easy#AP#81.94%$3D Object Detection#KITTI Pedestrians Hard#AP#40.88%$3D Object Detection#KITTI Cars Hard#AP#66.38%$3D Object Detection#KITTI Cyclists Hard#AP#46.61%$Birds Eye View Object Detection#KITTI Cars Easy#AP#88.53$Birds Eye View Object Detection#KITTI Cars Moderate#AP#83.79%$Birds Eye View Object Detection#KITTI Cyclists Moderate#AP#57.48%$Birds Eye View Object Detection#KITTI Pedestrians Moderate#AP#51.05%
1905.00526v2.pdf	3D Object Detection#nuScenes-F#AP#43$3D Object Detection#nuScenes-F#AP50#64.9$3D Object Detection#nuScenes-F#AP75#48.5$3D Object Detection#nuScenes-F#AR#48.6$3D Object Detection#nuScenes-F#ARI#58.2$3D Object Detection#nuScenes-F#ARm#41.2$3D Object Detection#nuScenes-F#ARs#4$3D Object Detection#nuScenes-FB#AP#35.5$3D Object Detection#nuScenes-FB#AP50#59$3D Object Detection#nuScenes-FB#AP75#37$3D Object Detection#nuScenes-FB#AR#42.1$3D Object Detection#nuScenes-FB#ARI#51.4$3D Object Detection#nuScenes-FB#ARm#39.1$3D Object Detection#nuScenes-FB#ARs#21.1
2102.00463v2.pdf	3D Object Detection#KITTI Cars Hard val#AP#82.69$3D Object Detection#KITTI Cars Moderate#AP#81.88%$3D Object Detection#KITTI Cars Easy val#AP#92.57$3D Object Detection#KITTI Cars Moderate val#AP#84.83$3D Object Detection#KITTI Cars Easy#AP#90.14%$3D Object Detection#KITTI Cars Hard#AP#77.15%
2012.04634v1.pdf	3D Object Detection#KITTI Cars Hard val#AP#82.23$3D Object Detection#KITTI Cars Moderate#AP#80.12%$3D Object Detection#KITTI Cars Easy val#AP#95.45$3D Object Detection#KITTI Cars Moderate val#AP#86.83$3D Object Detection#KITTI Cars Easy#AP#91.05%$3D Object Detection#KITTI Cars Hard#AP#72.78%
2012.10412v3.pdf	3D Object Detection#KITTI Cars Hard val#AP#80.45$3D Object Detection#KITTI Cars Moderate#AP#79.9%$3D Object Detection#KITTI Cars Easy val#AP#90.94$3D Object Detection#KITTI Cars Moderate val#AP#81.43$3D Object Detection#KITTI Cars Easy#AP#89.13%$3D Object Detection#KITTI Cars Hard#AP#75.54%
2012.15712v2.pdf	3D Object Detection#KITTI Cars Hard val#AP#78.93$3D Object Detection#KITTI Cars Moderate#AP#81.62%$3D Object Detection#KITTI Cars Easy val#AP#89.41$3D Object Detection#KITTI Cars Moderate val#AP#84.52$3D Object Detection#KITTI Cars Hard#AP#77.06
1611.07759v3.pdf	3D Object Detection#KITTI Cars Hard val#AP#56.56$3D Object Detection#KITTI Cars Easy val#AP#71.29$3D Object Detection#KITTI Cars Easy val#AP#71.19$3D Object Detection#KITTI Cars Moderate val#AP#62.68$Birds Eye View Object Detection#KITTI Cars Hard val#AP#76.33$Birds Eye View Object Detection#KITTI Cars Moderate val#AP#77.32$Birds Eye View Object Detection#KITTI Cars Easy val#AP#86.18
2107.14160v3.pdf	3D Object Detection#KITTI Cars Hard val#AP#16.9$3D Object Detection#KITTI Cars Moderate#AP#11.77%$3D Object Detection#nuScenes#NDS#0.45$3D Object Detection#nuScenes#mAP#0.39$3D Object Detection#KITTI Cars Easy val#AP#24.35$3D Object Detection#KITTI Cars Moderate val#AP#18.34$3D Object Detection#KITTI Cars Easy#AP#19.05%$3D Object Detection#KITTI Cars Hard#AP#9.39%$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#11.76
2207.02466v2.pdf	3D Object Detection#KITTI Cars Moderate#AP#83.23%$3D Object Detection#KITTI Cars Easy#AP#91.67%$3D Object Detection#KITTI Cars Hard#AP#78.43%
2112.02205v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#82.86%
2104.09804v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#82.54%$3D Object Detection#KITTI Cars Easy#AP#91.49%$3D Object Detection#KITTI Cars Hard#AP#77.15%$Birds Eye View Object Detection#KITTI Cars Easy#AP#95.68%$Birds Eye View Object Detection#KITTI Cars Moderate#AP#91.84%$Birds Eye View Object Detection#KITTI Cars Hard#AP#86.72%
2108.06709v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#82.13 %$3D Object Detection#KITTI Cars Easy#AP#90.5%$3D Object Detection#KITTI Cars Hard#AP#78.90 %
2109.02497v2.pdf	3D Object Detection#KITTI Cars Moderate#AP#82.09%$3D Object Detection#waymo vehicle#L1 mAP#74.95
2109.02499v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#82.08%$3D Object Detection#waymo vehicle#AP#76.3
2012.03015v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#80.28%$3D Object Detection#KITTI Cars Easy#AP#89.59%$3D Object Detection#KITTI Cars Hard#AP#72.87$Birds Eye View Object Detection#KITTI Cars Easy#AP#93.74 %$Birds Eye View Object Detection#KITTI Cars Moderate#AP#89.84 %$Birds Eye View Object Detection#KITTI Cars Hard#AP#82.39 %
2012.12397v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#76.75%$3D Object Detection#KITTI Cars Easy#AP#86.81%$3D Object Detection#KITTI Cars Hard#AP#68.41%
1911.12236v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#75.73%$3D Object Detection#KITTI Cars Easy#AP#85.97%$3D Object Detection#KITTI Cars Hard#AP#70.60%
1803.00387v1.pdf	3D Object Detection#KITTI Cars Moderate#AP#73.80%$3D Object Detection#KITTI Cars Easy#AP#84.33%$3D Object Detection#KITTI Cars Hard#AP#64.83%
2203.15118v2.pdf	3D Object Detection#Heavy Snowfall#mod. Car AP@.7IoU#41.79$3D Object Detection#Light Snowfall#mod. Car AP@.7IoU#41.79$3D Object Detection#Clear Weather#mod. Car AP@.7IoU#45.71
2112.15458v2.pdf	3D Object Detection#KITTI Pedestrian Hard#Average Precision#0.4271$3D Object Detection#KITTI Pedestrian Easy#Average Precision#0.5639$3D Object Detection#KITTI Pedestrian#mAP#0.486$3D Object Detection#KITTI Pedestrian Moderate#Average Precision#0.4671$Birds Eye View Object Detection#KITTI Pedestrian Easy#Average Precision#0.6325$Birds Eye View Object Detection#KITTI Pedestrian Hard#Average Precision#0.5053$Birds Eye View Object Detection#KITTI Pedestrian Moderate#Average Precision#0.5392$Birds Eye View Object Detection#KITTI Pedestrian#mAP#0.559
2008.07519v1.pdf	3D Object Detection#OPV2V#AP@0.7@Default#0.822$3D Object Detection#OPV2V#AP@0.7@CulverCity#0.734$3D Object Detection#V2XSet#AP0.5 (Perfect)#0.845$3D Object Detection#V2XSet#AP0.7 (Perfect)#0.677$3D Object Detection#V2XSet#AP0.5 (Noisy)#0.791$3D Object Detection#V2XSet#AP0.7 (Noisy)#0.493
2109.07644v5.pdf	3D Object Detection#OPV2V#AP@0.7@Default#0.815$3D Object Detection#OPV2V#AP@0.7@CulverCity#0.735$3D Object Detection#OPV2V#AP@0.7@Default#0.781$3D Object Detection#OPV2V#AP@0.7@CulverCity#0.669$3D Object Detection#V2XSet#AP0.5 (Perfect)#0.807$3D Object Detection#V2XSet#AP0.7 (Perfect)#0.664$3D Object Detection#V2XSet#AP0.5 (Noisy)#0.709$3D Object Detection#V2XSet#AP0.7 (Noisy)#0.487
1905.05265v1.pdf	3D Object Detection#OPV2V#AP@0.7@Default#0.800$3D Object Detection#OPV2V#AP@0.7@CulverCity#0.696
1909.06459v1.pdf	3D Object Detection#OPV2V#AP@0.7@Default#0.790$3D Object Detection#OPV2V#AP@0.7@CulverCity#0.728$3D Object Detection#V2XSet#AP0.5 (Perfect)#0.840$3D Object Detection#V2XSet#AP0.7 (Perfect)#0.680$3D Object Detection#V2XSet#AP0.5 (Noisy)#0.715$3D Object Detection#V2XSet#AP0.7 (Noisy)#0.469
1912.12791v3.pdf	3D Object Detection#KITTI Pedestrians Moderate#AP#44.81%
2209.05588v1.pdf	3D Object Detection#waymo cyclist#APH/L2#73.3$3D Object Detection#waymo vehicle#APH/L2#73.8$3D Object Detection#waymo pedestrian#APH/L2#75.0
2112.06375v1.pdf	3D Object Detection#waymo cyclist#APH/L2#72.17$3D Object Detection#waymo vehicle#APH/L2#72.74$3D Object Detection#waymo pedestrian#APH/L2#73.51
2111.06881v1.pdf	3D Object Detection#nuScenes#NDS#0.71$3D Object Detection#nuScenes#mAP#0.66$3D Object Detection#nuScenes#mATE#0.26$3D Object Detection#nuScenes#mASE#0.24$3D Object Detection#nuScenes#mAOE#0.32$3D Object Detection#nuScenes#mAVE#0.31$3D Object Detection#nuScenes#mAAE#0.13
2008.01550v1.pdf	3D Object Detection#nuScenes#NDS#0.59$3D Object Detection#nuScenes#mAP#0.49$3D Object Detection#nuScenes#mATE#0.33$3D Object Detection#nuScenes#mASE#0.24$3D Object Detection#nuScenes#mAOE#0.44$3D Object Detection#nuScenes#mAVE#0.27$3D Object Detection#nuScenes#mAAE#0.24$LIDAR Semantic Segmentation#nuScenes#mIOU#0.78
2203.17270v2.pdf	3D Object Detection#nuScenes#NDS#0.57$3D Object Detection#nuScenes#mAP#0.48$3D Object Detection#nuScenes#mATE#0.58$3D Object Detection#nuScenes#mASE#0.26$3D Object Detection#nuScenes#mAOE#0.38$3D Object Detection#nuScenes#mAVE#0.38$3D Object Detection#nuScenes#mAAE#0.13
2203.17054v3.pdf	3D Object Detection#nuScenes#NDS#0.569$3D Object Detection#nuScenes#mAP#0.451$3D Object Detection#nuScenes#mATE#0.511$3D Object Detection#nuScenes#mASE#0.241$3D Object Detection#nuScenes#mAOE#0.386$3D Object Detection#nuScenes#mAVE#0.301$3D Object Detection#nuScenes#mAAE#0.121
2011.04841v1.pdf	3D Object Detection#nuScenes#NDS#0.449$3D Object Detection#nuScenes#mAP#0.326
1903.11027v5.pdf	3D Object Detection#nuScenes#NDS#0.449$3D Object Detection#nuScenes#NDS#0.448$3D Object Detection#nuScenes#NDS#0.442
2104.10956v3.pdf	3D Object Detection#nuScenes#NDS#0.428$3D Object Detection#nuScenes#mAP#0.358$3D Object Detection#nuScenes#mATE#0.690$3D Object Detection#nuScenes#mASE#0.249$3D Object Detection#nuScenes#mAOE#0.452$3D Object Detection#nuScenes#mAVE#1.434$3D Object Detection#nuScenes#mAAE#0.124
1908.09492v1.pdf	3D Object Detection#nuScenes#NDS#0.63.3$3D Object Detection#nuScenes#mAP#0.528
2108.05249v3.pdf	3D Object Detection#Dense Fog#mod. Car AP@.5IoU#47.38$3D Object Detection#Dense Fog#mod. Cyclist AP@.25IoU#27.89$3D Object Detection#Dense Fog#mod. Pedestrian AP@.25IoU#40.65$3D Object Detection#Dense Fog#mod. mAP#38.64
2112.00322v2.pdf	3D Object Detection#S3DIS#mAP@0.5#45.9$3D Object Detection#S3DIS#mAP@0.25#66.7$3D Object Detection#ScanNetV2#mAP@0.25#71.5$3D Object Detection#ScanNetV2#mAP@0.5#57.3$3D Object Detection#SUN-RGBD val#mAP@0.25#64.2$3D Object Detection#SUN-RGBD val#mAP@0.5#48.9
2006.12356v1.pdf	3D Object Detection#S3DIS#mAP@0.5#25.1$3D Object Detection#S3DIS#mAP@0.25#47.8$3D Object Detection#ScanNetV2#mAP@0.25#62.8$3D Object Detection#ScanNetV2#mAP@0.5#34.8
2008.08766v1.pdf	3D Object Detection#KITTI Cars Moderate val#AP#83.3$3D Object Detection#KITTI Cyclists Moderate val#AP#73.46$3D Object Detection#KITTI Pedestrians Moderate val#AP#58.33
2203.10638v3.pdf	3D Object Detection#V2XSet#AP0.5 (Perfect)#0.882$3D Object Detection#V2XSet#AP0.7 (Perfect)#0.712$3D Object Detection#V2XSet#AP0.5 (Noisy)#0.836$3D Object Detection#V2XSet#AP0.7 (Noisy)#0.614
2111.00643v2.pdf	3D Object Detection#V2XSet#AP0.5 (Perfect)#0.844$3D Object Detection#V2XSet#AP0.7 (Perfect)#0.695$3D Object Detection#V2XSet#AP0.5 (Noisy)#0.798$3D Object Detection#V2XSet#AP0.7 (Noisy)#0.541
2101.02672v5.pdf	3D Object Detection#KITTI Cyclists Hard#AP#61.33%
2210.04264v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#75.1$3D Object Detection#ScanNetV2#mAP@0.5#61.3$3D Object Detection#SUN-RGBD#mAP@0.25#66.8$3D Object Detection#SUN-RGBD#mAP@0.5#50.2$3D Object Detection#SUN-RGBD val#mAP@0.25#66.8$3D Object Detection#SUN-RGBD val#mAP@0.5#50.2
2203.01509v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#71.6$3D Object Detection#ScanNetV2#mAP@0.5#59.4$3D Instance Segmentation#STPLS3D#AP50#61.8$3D Instance Segmentation#STPLS3D#AP25#69.4$3D Instance Segmentation#STPLS3D#AP#46.2$3D Instance Segmentation#S3DIS#mRec#69.8$3D Instance Segmentation#S3DIS#mPrec#75.3$3D Instance Segmentation#S3DIS#mCov#69.3$3D Instance Segmentation#S3DIS#mWCov#71.7$3D Instance Segmentation#S3DIS#AP@50#68.9$3D Instance Segmentation#S3DIS#mAP#54.4$3D Instance Segmentation#ScanNet(v2)#mAP#50.4$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#76.1
2204.02251v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#70.6$3D Object Detection#ScanNetV2#mAP@0.5#55.2$3D Object Detection#SUN-RGBD val#mAP@0.25#64.1$3D Object Detection#SUN-RGBD val#mAP@0.5#47.2
2104.00678v2.pdf	3D Object Detection#ScanNetV2#mAP@0.25#69.1$3D Object Detection#ScanNetV2#mAP@0.5#52.8$3D Object Detection#SUN-RGBD#mAP@0.25#63.0$3D Object Detection#SUN-RGBD#mAP@0.5#45.2$3D Object Detection#SUN-RGBD val#mAP@0.25#63.0$3D Object Detection#SUN-RGBD val#mAP@0.5#45.2
2006.05682v3.pdf	3D Object Detection#ScanNetV2#mAP@0.25#67.2$3D Object Detection#ScanNetV2#mAP@0.5#48.1$3D Object Detection#SUN-RGBD val#mAP@0.25#60.1$3D Object Detection#SUN-RGBD val#mAP@0.5#39.0
2104.06114v2.pdf	3D Object Detection#ScanNetV2#mAP@0.25#66.1$3D Object Detection#ScanNetV2#mAP@0.5#50.9$3D Object Detection#SUN-RGBD val#mAP@0.25#61.1$3D Object Detection#SUN-RGBD val#mAP@0.5#43.7
2109.08141v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#65.0$3D Object Detection#ScanNetV2#mAP@0.5#47.0$3D Object Detection#SUN-RGBD val#mAP@0.25#59.1$3D Object Detection#SUN-RGBD val#mAP@0.5#32.7
2003.13867v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#64.2$3D Object Detection#ScanNetV2#mAP@0.5#49.2$3D Instance Segmentation#S3DIS#mRec#64.1$3D Instance Segmentation#S3DIS#mPrec#66.7$3D Instance Segmentation#ScanNet(v2)#mRec#61.1$3D Instance Segmentation#ScanNet(v2)#mAP#35.3$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#59.1$3D Semantic Instance Segmentation#ScanNetV2#mAP@0.50#61.1
1904.09664v2.pdf	3D Object Detection#ScanNetV2#mAP@0.25#58.6$3D Object Detection#ScanNetV2#mAP@0.5#33.5$3D Object Detection#SUN-RGBD val#mAP@0.25#59.1$3D Object Detection#SUN-RGBD val#mAP@0.5#35.8
2106.01178v3.pdf	3D Object Detection#ScanNetV2#mAP@0.25#48.1$3D Object Detection#ScanNetV2#mAP@0.5#22.7$Monocular 3D Object Detection#SUN RGB-D#AP@0.15#48.74
1812.07003v3.pdf	3D Object Detection#ScanNetV2#mAP@0.25#40.2$3D Object Detection#ScanNetV2#mAP@0.5#22.5$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#38.2$3D Semantic Instance Segmentation#ScanNetV2#mAP@0.50#38.2
1812.03320v1.pdf	3D Object Detection#ScanNetV2#mAP@0.25#30.6$3D Object Detection#ScanNetV2#mAP@0.5#17.7
2001.10692v1.pdf	3D Object Detection#SUN-RGBD#mAP@0.25#63.4
2109.00179v1.pdf	3D Object Detection#SUN-RGBD#mAP@0.25#59.2$3D Object Detection#SUN-RGBD#mAP@0.25#58.2$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.1$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.9
2207.10589v1.pdf	3D Object Detection#SUN-RGBD val#mAP@0.25#67.4$3D Object Detection#SUN-RGBD val#mAP@0.5#51.2
1906.04725v1.pdf	3D Object Detection#SUN-RGBD val#mAP@0.25#54.3
1511.02300v2.pdf	3D Object Detection#SUN-RGBD val#Inference Speed (s)#19.55
2103.01100v2.pdf	Monocular 3D Object Detection#KITTI Cyclist Hard#AP Hard#3.30$Monocular 3D Object Detection#KITTI Cars Hard#AP Hard#11.46$Monocular 3D Object Detection#KITTI Cyclist Moderate#AP Medium#3.41$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#13.41$Monocular 3D Object Detection#KITTI Pedestrian Moderate#AP Medium#8.14$Monocular 3D Object Detection#KITTI Cars Easy#AP Easy#19.17$Monocular 3D Object Detection#KITTI Pedestrian Hard#AP Hard#6.76$Monocular 3D Object Detection#KITTI Pedestrian Easy#AP Easy#12.87$Monocular 3D Object Detection#KITTI Cyclist Easy#AP Easy#7.00
2108.06417v1.pdf	Monocular 3D Object Detection#KITTI Cars Hard#AP Hard#14.20$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#16.34$Monocular 3D Object Detection#KITTI Pedestrian Moderate#AP Medium#9.30$Monocular 3D Object Detection#KITTI Cars Easy#AP Easy#23.22$Monocular 3D Object Detection#KITTI Pedestrian Hard#AP Hard#8.05$Monocular 3D Object Detection#KITTI Pedestrian Easy#AP Easy#13.91
2102.00690v1.pdf	Monocular 3D Object Detection#KITTI Cars Hard#AP Hard#9.94$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#13.17
2006.04080v2.pdf	Monocular 3D Object Detection#KITTI Cars Hard#AP Hard#6.42$Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#7.94$Monocular 3D Object Detection#Virtual KITTI 2#mAP@0.3#86.6$Monocular 3D Object Detection#Virtual KITTI 2#mAP@0.5#66.7$Monocular 3D Object Detection#KITTI Pedestrian Hard#AP Hard#4.82$Monocular 3D Object Detection#KITTI Pedestrians Moderate val#AP Medium#5.43
2103.06422v3.pdf	Monocular 3D Object Detection#SUN RGB-D#AP@0.15#45.21$3D Shape Reconstruction#Pix3D#CD#0.0672$3D Shape Reconstruction#Pix3D#EMD#N/A$3D Shape Reconstruction#Pix3D#IoU#N/A
1912.07744v1.pdf	Monocular 3D Object Detection#SUN RGB-D#AP@0.15#39.09
2002.12212v1.pdf	Monocular 3D Object Detection#SUN RGB-D#AP@0.15#26.38$Monocular 3D Object Detection#SUN RGB-D#AP@0.15#23.32$3D Shape Reconstruction#Pix3D#CD#0.0836$3D Shape Reconstruction#Pix3D#EMD#N/A$3D Shape Reconstruction#Pix3D#IoU#N/A
1810.13049v2.pdf	Monocular 3D Object Detection#SUN RGB-D#AP@0.15#23.65
1808.02201v1.pdf	Monocular 3D Object Detection#SUN RGB-D#AP@0.15#14.01
2112.04628v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#16.46
2104.02323v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#13.89
2106.15796v2.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#13.87
2107.13931v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#13.81
2103.16470v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.78
2104.03775v3.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.65
2103.17202v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.32
2103.12605v2.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.30
2103.16237v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.26
2103.03480v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#12.01
2002.10111v1.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#9.76
1811.10247v2.pdf	Monocular 3D Object Detection#KITTI Cars Moderate#AP Medium#5.74
2012.09988v1.pdf	Monocular 3D Object Detection#Google Objectron#Average Precision at 0.5 3D IoU#0.6512$Monocular 3D Object Detection#Google Objectron#MPE#0.0467$Monocular 3D Object Detection#Google Objectron#AP at 15' Azimuth error#0.7844$Monocular 3D Object Detection#Google Objectron#AP at 10' Elevation error#0.8584
2003.03522v1.pdf	Monocular 3D Object Detection#Google Objectron#Average Precision at 0.5 3D IoU#0.4624$Monocular 3D Object Detection#Google Objectron#MPE#0.1001$Monocular 3D Object Detection#Google Objectron#AP at 15' Azimuth error#0.5088$Monocular 3D Object Detection#Google Objectron#AP at 10' Elevation error#0.6658
2204.03039v3.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#67.37$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#32.74$3D Object Detection From Stereo Images#KITTI Cyclists Moderate#AP50#43.90
2108.08258v1.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#64.66$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#30.00$3D Object Detection From Stereo Images#KITTI Cyclists Moderate#AP50#36.86
2003.05505v1.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#53.58$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#24.31
1906.06310v3.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#42.43
2103.09422v1.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#41.25$3D Object Detection From Stereo Images#KITTI Pedestrians Moderate#AP50#19.75
1909.07566v2.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#37.60$3D Object Detection From Stereo Images#KITTI Cyclists Moderate#AP50#16.63
1812.07179v6.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#34.05
1902.09738v2.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#30.23
1906.01193v1.pdf	3D Object Detection From Stereo Images#KITTI Cars Moderate#AP75#4.37
2209.09475v2.pdf	RGB Salient Object Detection#HRSOD#S-Measure#0.960$RGB Salient Object Detection#HRSOD#F-Measure#0.957$RGB Salient Object Detection#HRSOD#MAE#0.014$RGB Salient Object Detection#HRSOD#mBA#0.766$RGB Salient Object Detection#HRSOD#S-Measure#0.956$RGB Salient Object Detection#HRSOD#F-Measure#0.956$RGB Salient Object Detection#HRSOD#MAE#0.018$RGB Salient Object Detection#HRSOD#mBA#0.771$RGB Salient Object Detection#HRSOD#S-Measure#0.952$RGB Salient Object Detection#HRSOD#F-Measure#0.949$RGB Salient Object Detection#HRSOD#MAE#0.016$RGB Salient Object Detection#HRSOD#mBA#0.738$RGB Salient Object Detection#HKU-IS#MAE#0.021$RGB Salient Object Detection#HKU-IS#F-measure#0.955$RGB Salient Object Detection#HKU-IS#S-Measure#0.944$RGB Salient Object Detection#HKU-IS#MAE#0.028$RGB Salient Object Detection#HKU-IS#F-measure#0.938$RGB Salient Object Detection#HKU-IS#S-Measure#0.929$RGB Salient Object Detection#DUTS-TE#MAE#0.024$RGB Salient Object Detection#DUTS-TE#F-measure#0.927$RGB Salient Object Detection#DUTS-TE#S-Measure#0.931$RGB Salient Object Detection#DUTS-TE#MAE#0.035$RGB Salient Object Detection#DUTS-TE#F-measure#0.892$RGB Salient Object Detection#DUTS-TE#S-Measure#0.904$RGB Salient Object Detection#PASCAL-S#MAE#0.048$RGB Salient Object Detection#PASCAL-S#F-measure#0.893$RGB Salient Object Detection#PASCAL-S#S-Measure#0.893$RGB Salient Object Detection#PASCAL-S#MAE#0.056$RGB Salient Object Detection#PASCAL-S#F-measure#0.869$RGB Salient Object Detection#PASCAL-S#S-Measure#0.876$RGB Salient Object Detection#DUT-OMRON#MAE#0.045$RGB Salient Object Detection#DUT-OMRON#F-measure#0.832$RGB Salient Object Detection#DUT-OMRON#S-Measure#0.875$RGB Salient Object Detection#DUT-OMRON#MAE#0.059$RGB Salient Object Detection#DUT-OMRON#F-measure#0.791$RGB Salient Object Detection#DUT-OMRON#S-Measure#0.845$RGB Salient Object Detection#UHRSD#S-Measure#0.953$RGB Salient Object Detection#UHRSD#F-Measure#0.957$RGB Salient Object Detection#UHRSD#MAE#0.020$RGB Salient Object Detection#UHRSD#mBA#0.812$RGB Salient Object Detection#UHRSD#S-Measure#0.936$RGB Salient Object Detection#UHRSD#F-Measure#0.938$RGB Salient Object Detection#UHRSD#MAE#0.028$RGB Salient Object Detection#UHRSD#mBA#0.785$RGB Salient Object Detection#UHRSD#S-Measure#0.932$RGB Salient Object Detection#UHRSD#MAE#0.029$RGB Salient Object Detection#UHRSD#mBA#0.741$RGB Salient Object Detection#DAVIS-S#S-measure#0.973$RGB Salient Object Detection#DAVIS-S#F-measure#0.977$RGB Salient Object Detection#DAVIS-S#mBA#0.770$RGB Salient Object Detection#DAVIS-S#MAE#0.007$RGB Salient Object Detection#DAVIS-S#S-measure#0.972$RGB Salient Object Detection#DAVIS-S#F-measure#0.976$RGB Salient Object Detection#DAVIS-S#S-measure#0.962$RGB Salient Object Detection#DAVIS-S#F-measure#0.959$RGB Salient Object Detection#DAVIS-S#mBA#0.743$RGB Salient Object Detection#DAVIS-S#MAE#0.009$RGB Salient Object Detection#ECSSD#MAE#0.023$RGB Salient Object Detection#ECSSD#F-measure#0.96$RGB Salient Object Detection#ECSSD#S-Measure#0.949$RGB Salient Object Detection#ECSSD#MAE#0.031$RGB Salient Object Detection#ECSSD#F-measure#0.949$RGB Salient Object Detection#ECSSD#S-Measure#0.936$Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.834$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.777$Dichotomous Image Segmentation#DIS-TE1#MAE#0.045$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.862$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.895$Dichotomous Image Segmentation#DIS-TE1#HCE#148$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.881$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.834$Dichotomous Image Segmentation#DIS-TE2#MAE#0.038$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.893$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.925$Dichotomous Image Segmentation#DIS-TE2#HCE#316$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.904$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.856$Dichotomous Image Segmentation#DIS-TE3#MAE#0.038$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.902$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.938$Dichotomous Image Segmentation#DIS-TE3#HCE#582$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.892$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.840$Dichotomous Image Segmentation#DIS-TE4#MAE#0.046$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.891$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.926$Dichotomous Image Segmentation#DIS-TE4#HCE#2243$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.876$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.826$Dichotomous Image Segmentation#DIS-VD#MAE#0.043$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.887$Dichotomous Image Segmentation#DIS-VD#E-measure#0.921$Dichotomous Image Segmentation#DIS-VD#HCE#905
2204.05041v2.pdf	RGB Salient Object Detection#HRSOD#S-Measure#0.938$RGB Salient Object Detection#HRSOD#F-Measure#0.939$RGB Salient Object Detection#HRSOD#MAE#0.020$RGB Salient Object Detection#HRSOD#mBA#0.727$RGB Salient Object Detection#HRSOD#S-Measure#0.935$RGB Salient Object Detection#HRSOD#F-Measure#0.929$RGB Salient Object Detection#HRSOD#mBA#0.714$RGB Salient Object Detection#HRSOD#S-Measure#0.930$RGB Salient Object Detection#HRSOD#F-Measure#0.922$RGB Salient Object Detection#HRSOD#MAE#0.021$RGB Salient Object Detection#HRSOD#mBA#0.693$RGB Salient Object Detection#UHRSD#S-Measure#0.935$RGB Salient Object Detection#UHRSD#F-Measure#0.930$RGB Salient Object Detection#UHRSD#MAE#0.026$RGB Salient Object Detection#UHRSD#mBA#0.765$RGB Salient Object Detection#UHRSD#S-Measure#0.912$RGB Salient Object Detection#UHRSD#F-Measure#0.915$RGB Salient Object Detection#UHRSD#MAE#0.036$RGB Salient Object Detection#UHRSD#mBA#0.735$RGB Salient Object Detection#UHRSD#F-Measure#0.914$RGB Salient Object Detection#UHRSD#MAE#0.037$RGB Salient Object Detection#UHRSD#mBA#0.715$RGB Salient Object Detection#DAVIS-S#S-measure#0.954$RGB Salient Object Detection#DAVIS-S#F-measure#0.956$RGB Salient Object Detection#DAVIS-S#mBA#0.730$RGB Salient Object Detection#DAVIS-S#MAE#0.010$RGB Salient Object Detection#DAVIS-S#S-measure#0.947$RGB Salient Object Detection#DAVIS-S#F-measure#0.948$RGB Salient Object Detection#DAVIS-S#mBA#0.716$RGB Salient Object Detection#DAVIS-S#MAE#0.012$RGB Salient Object Detection#DAVIS-S#S-measure#0.935$RGB Salient Object Detection#DAVIS-S#F-measure#0.931$RGB Salient Object Detection#DAVIS-S#mBA#0.707$RGB Salient Object Detection#DAVIS-S#MAE#0.015
2108.03551v2.pdf	RGB Salient Object Detection#HRSOD#S-Measure#0.920$RGB Salient Object Detection#HRSOD#F-Measure#0.915$RGB Salient Object Detection#HRSOD#MAE#0.022$RGB Salient Object Detection#HRSOD#mBA#0.693$RGB Salient Object Detection#DAVIS-S#S-measure#0.920$RGB Salient Object Detection#DAVIS-S#F-measure#0.935$RGB Salient Object Detection#DAVIS-S#mBA#0.716$RGB Salient Object Detection#DAVIS-S#MAE#0.012
1908.07274v1.pdf	RGB Salient Object Detection#HRSOD#S-Measure#0.892$RGB Salient Object Detection#HRSOD#F-Measure#0.892$RGB Salient Object Detection#HRSOD#MAE#0.030$RGB Salient Object Detection#HRSOD#mBA#0.693$RGB Salient Object Detection#DAVIS-S#S-measure#0.876$RGB Salient Object Detection#DAVIS-S#F-measure#0.889$RGB Salient Object Detection#DAVIS-S#mBA#0.618$RGB Salient Object Detection#DAVIS-S#MAE#0.026
2112.07380v2.pdf	RGB Salient Object Detection#HKU-IS#MAE#0.020$RGB Salient Object Detection#HKU-IS#F-measure#0.954$RGB Salient Object Detection#HKU-IS#S-Measure#0.932$RGB Salient Object Detection#HKU-IS#mean F-Measure#0.934$RGB Salient Object Detection#HKU-IS#MAE#0.028$RGB Salient Object Detection#DUTS-TE#MAE#0.022$RGB Salient Object Detection#DUTS-TE#F-measure#0.932$RGB Salient Object Detection#DUTS-TE#S-Measure#0.919$RGB Salient Object Detection#DUTS-TE#mean F-Measure#0.904$RGB Salient Object Detection#DUTS-TE#MAE#0.035$RGB Salient Object Detection#PASCAL-S#MAE#0.047$RGB Salient Object Detection#PASCAL-S#F-measure#0.909$RGB Salient Object Detection#PASCAL-S#mean F-Measure#0.874$RGB Salient Object Detection#PASCAL-S#S-Measure#0.882$RGB Salient Object Detection#DUT-OMRON#MAE#0.045$RGB Salient Object Detection#DUT-OMRON#F-measure#0.849$RGB Salient Object Detection#DUT-OMRON#S-Measure#0.855$RGB Salient Object Detection#DUT-OMRON#mean F-Measure#0.798$RGB Salient Object Detection#DUT-OMRON#MAE#0.050$RGB Salient Object Detection#ECSSD#MAE#0.026$RGB Salient Object Detection#ECSSD#F-measure#0.961$RGB Salient Object Detection#ECSSD#S-Measure#0.935$RGB Salient Object Detection#ECSSD#mean F-Measure#0.940$RGB Salient Object Detection#ECSSD#MAE#0.033
2110.11887v1.pdf	RGB Salient Object Detection#HKU-IS#MAE#0.025$RGB Salient Object Detection#HKU-IS#mean F-Measure#0.931$RGB Salient Object Detection#HKU-IS#mean E-Measure#0.961$RGB Salient Object Detection#DUTS-TE#MAE#0.029$RGB Salient Object Detection#DUTS-TE#mean E-Measure#0.937$RGB Salient Object Detection#DUTS-TE#mean F-Measure#0.886$RGB Salient Object Detection#PASCAL-S#MAE#0.055$RGB Salient Object Detection#PASCAL-S#mean F-Measure#0.861$RGB Salient Object Detection#PASCAL-S#mean E-Measure#0.904$RGB Salient Object Detection#DUT-OMRON#MAE#0.047$RGB Salient Object Detection#DUT-OMRON#mean F-Measure#0.788$RGB Salient Object Detection#DUT-OMRON#mean E-Measure#0.865$RGB Salient Object Detection#ECSSD#MAE#0.029$RGB Salient Object Detection#ECSSD#mean F-Measure#0.939$RGB Salient Object Detection#ECSSD#mean E-Measure#0.957
2009.03075v1.pdf	RGB Salient Object Detection#HKU-IS#MAE#0.026$RGB Salient Object Detection#HKU-IS#S-Measure#0.921$RGB Salient Object Detection#HKU-IS#MAE#0.027$RGB Salient Object Detection#HKU-IS#S-Measure#0.917$RGB Salient Object Detection#DUTS-TE#MAE#0.034$RGB Salient Object Detection#DUTS-TE#S-Measure#0.890$RGB Salient Object Detection#DUTS-TE#mean E-Measure#0.931$RGB Salient Object Detection#DUTS-TE#mean F-Measure#0.864$RGB Salient Object Detection#DUTS-TE#S-Measure#0.888$RGB Salient Object Detection#DUTS-TE#mean E-Measure#0.927$RGB Salient Object Detection#DUTS-TE#mean F-Measure#0.860$RGB Salient Object Detection#DUTS-test#MAE#0.034$RGB Salient Object Detection#DUTS-test#mean F-Measure#0.773$RGB Salient Object Detection#SOC#S-Measure#0.849$RGB Salient Object Detection#SOC#mean E-Measure#0.872$RGB Salient Object Detection#SOC#Average MAE#0.089$RGB Salient Object Detection#SOC#S-Measure#0.842$RGB Salient Object Detection#SOC#mean E-Measure#0.868$RGB Salient Object Detection#SOC#Average MAE#0.091$RGB Salient Object Detection#DUT-OMRON#MAE#0.050$RGB Salient Object Detection#DUT-OMRON#S-Measure#0.843$RGB Salient Object Detection#DUT-OMRON#MAE#0.051$RGB Salient Object Detection#DUT-OMRON#S-Measure#0.839$RGB Salient Object Detection#ECSSD#MAE#0.035$RGB Salient Object Detection#ECSSD#S-Measure#0.921$RGB-D Salient Object Detection#SIP#S-Measure#88.3$RGB-D Salient Object Detection#SIP#Average MAE#0.045$RGB-D Salient Object Detection#SIP#S-Measure#87.6$RGB-D Salient Object Detection#SIP#Average MAE#0.049$RGB-D Salient Object Detection#STERE#S-Measure#90.4$RGB-D Salient Object Detection#STERE#Average MAE#0.037$RGB-D Salient Object Detection#STERE#S-Measure#89.8$RGB-D Salient Object Detection#STERE#Average MAE#0.039$RGB-D Salient Object Detection#LFSD#S-Measure#86.8$RGB-D Salient Object Detection#LFSD#Average MAE#0.065$RGB-D Salient Object Detection#LFSD#S-Measure#86.6$RGB-D Salient Object Detection#NJU2K#S-Measure#90.2$RGB-D Salient Object Detection#NJU2K#Average MAE#0.039$RGB-D Salient Object Detection#NJU2K#S-Measure#90.0$RGB-D Salient Object Detection#NLPR#S-Measure#91.9$RGB-D Salient Object Detection#NLPR#Average MAE#0.024$RGB-D Salient Object Detection#NLPR#S-Measure#91.7$RGB-D Salient Object Detection#NLPR#Average MAE#0.025$RGB-D Salient Object Detection#DES#S-Measure#94.0$RGB-D Salient Object Detection#DES#Average MAE#0.016$RGB-D Salient Object Detection#DES#S-Measure#93.7
1904.09569v1.pdf	RGB Salient Object Detection#HKU-IS#MAE#0.03$RGB Salient Object Detection#HKU-IS#F-measure#0.935$RGB Salient Object Detection#DUTS-TE#MAE#0.036$RGB Salient Object Detection#DUTS-TE#F-measure#0.892$RGB Salient Object Detection#PASCAL-S#MAE#0.065$RGB Salient Object Detection#PASCAL-S#F-measure#0.88$RGB Salient Object Detection#SOD#MAE#0.102$RGB Salient Object Detection#SOD#F-measure#0.882$RGB Salient Object Detection#DUT-OMRON#MAE#0.053$RGB Salient Object Detection#DUT-OMRON#F-measure#0.833$RGB Salient Object Detection#ECSSD#MAE#0.038$RGB Salient Object Detection#ECSSD#F-measure#0.945
1904.08739v1.pdf	RGB Salient Object Detection#HKU-IS#MAE#0.034$RGB Salient Object Detection#HKU-IS#F-measure#0.891$RGB Salient Object Detection#SBU#Balanced Error Rate#4.19$RGB Salient Object Detection#ISTD#Balanced Error Rate#6.76$RGB Salient Object Detection#PASCAL-S#MAE#0.072$RGB Salient Object Detection#PASCAL-S#F-measure#0.824$RGB Salient Object Detection#DUTS-test#F-measure#80.5$RGB Salient Object Detection#DUTS-test#MAE#0.043$RGB Salient Object Detection#DUT-OMRON#MAE#0.056$RGB Salient Object Detection#DUT-OMRON#F-measure#0.747$RGB Salient Object Detection#UCF#Balanced Error Rate#7.21$RGB Salient Object Detection#ECSSD#MAE#0.037$RGB Salient Object Detection#ECSSD#F-measure#0.917$Camouflaged Object Segmentation#COD#MAE#0.059$Camouflaged Object Segmentation#COD#Weighted F-Measure#50.8$Camouflaged Object Segmentation#COD#S-Measure#74.7$Camouflaged Object Segmentation#COD#E-Measure#77.0
2106.12011v6.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.029$RGB Salient Object Detection#DUTS-TE#F-measure#0.912$RGB Salient Object Detection#DUTS-TE#MAE#0.033$RGB Salient Object Detection#DUTS-TE#F-measure#0.895
1708.06433v2.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.050$RGB Salient Object Detection#DUTS-TE#F-measure#0.863$RGB Salient Object Detection#DUTS-TE#S-Measure#0.842$RGB Salient Object Detection#DUTS-TE#mean E-Measure#0.853$RGB Salient Object Detection#DUTS-TE#mean F-Measure#0.757$RGB Salient Object Detection#SOC#S-Measure#0.801$RGB Salient Object Detection#SOC#mean E-Measure#0.810$RGB Salient Object Detection#SOC#Average MAE#0.133
1704.03604v1.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.062$RGB Salient Object Detection#DUTS-TE#F-measure#0.824
1611.04849v4.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.065$RGB Salient Object Detection#DUTS-TE#F-measure#0.813$RGB Salient Object Detection#SBU#Balanced Error Rate#7.00$RGB Salient Object Detection#ISTD#Balanced Error Rate#10.48$RGB Salient Object Detection#UCF#Balanced Error Rate#10.56
1708.02001v1.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.075$RGB Salient Object Detection#DUTS-TE#F-measure#0.773
1603.01976v1.pdf	RGB Salient Object Detection#DUTS-TE#MAE#0.081$RGB Salient Object Detection#DUTS-TE#F-measure#0.786
2203.03041v4.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.74$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.662$Dichotomous Image Segmentation#DIS-TE1#MAE#0.074$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.787$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.82$Dichotomous Image Segmentation#DIS-TE1#HCE#149$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.799$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.728$Dichotomous Image Segmentation#DIS-TE2#MAE#0.07$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.823$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.858$Dichotomous Image Segmentation#DIS-TE2#HCE#340$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.830$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.758$Dichotomous Image Segmentation#DIS-TE3#MAE#0.064$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.836$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.883$Dichotomous Image Segmentation#DIS-TE3#HCE#687$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.827$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.753$Dichotomous Image Segmentation#DIS-TE4#MAE#0.072$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.83$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.87$Dichotomous Image Segmentation#DIS-TE4#HCE#2888$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.791$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.717$Dichotomous Image Segmentation#DIS-VD#MAE#0.074$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.813$Dichotomous Image Segmentation#DIS-VD#E-measure#0.856$Dichotomous Image Segmentation#DIS-VD#HCE#1116
2102.10274v2.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.644$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.558$Dichotomous Image Segmentation#DIS-TE1#MAE#0.094$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.727$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.791$Dichotomous Image Segmentation#DIS-TE1#HCE#274$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.700$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.618$Dichotomous Image Segmentation#DIS-TE2#MAE#0.099$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.753$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.823$Dichotomous Image Segmentation#DIS-TE2#HCE#593$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.730$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.641$Dichotomous Image Segmentation#DIS-TE3#MAE#0.096$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.766$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.849$Dichotomous Image Segmentation#DIS-TE3#HCE#1096$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.699$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.616$Dichotomous Image Segmentation#DIS-TE4#MAE#0.113$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.744$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.824$Dichotomous Image Segmentation#DIS-TE4#HCE#3683$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.665$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.584$Dichotomous Image Segmentation#DIS-VD#MAE#0.110$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.727$Dichotomous Image Segmentation#DIS-VD#E-measure#0.798$Dichotomous Image Segmentation#DIS-VD#HCE#1568$Camouflaged Object Segmentation#CAMO#MAE#0.070$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#74.3$Camouflaged Object Segmentation#CAMO#S-Measure#82.0$Camouflaged Object Segmentation#CAMO#E-Measure#88.2$Camouflaged Object Segmentation#COD#MAE#0.037$Camouflaged Object Segmentation#COD#Weighted F-Measure#68.0$Camouflaged Object Segmentation#COD#S-Measure#81.5$Camouflaged Object Segmentation#COD#E-Measure#88.7
2104.10475v1.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.646$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.552$Dichotomous Image Segmentation#DIS-TE1#MAE#0.094$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.722$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.786$Dichotomous Image Segmentation#DIS-TE1#HCE#253$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.720$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.633$Dichotomous Image Segmentation#DIS-TE2#MAE#0.096$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.761$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.829$Dichotomous Image Segmentation#DIS-TE2#HCE#567$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.751$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.664$Dichotomous Image Segmentation#DIS-TE3#MAE#0.092$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.777$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.854$Dichotomous Image Segmentation#DIS-TE3#HCE#1082$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.731$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.647$Dichotomous Image Segmentation#DIS-TE4#MAE#0.107$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.763$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.838$Dichotomous Image Segmentation#DIS-TE4#HCE#3803$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.691$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.604$Dichotomous Image Segmentation#DIS-VD#MAE#0.106$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.740$Dichotomous Image Segmentation#DIS-VD#E-measure#0.811$Dichotomous Image Segmentation#DIS-VD#HCE#1606$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#69.5$Camouflaged Object Segmentation#CAMO#S-Measure#78.2$Camouflaged Object Segmentation#CAMO#E-Measure#85.2
1911.11445v1.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.640$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.549$Dichotomous Image Segmentation#DIS-TE1#MAE#0.095$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.721$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.783$Dichotomous Image Segmentation#DIS-TE1#HCE#244$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.712$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.620$Dichotomous Image Segmentation#DIS-TE2#MAE#0.097$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.755$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.820$Dichotomous Image Segmentation#DIS-TE2#HCE#542$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.743$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.656$Dichotomous Image Segmentation#DIS-TE3#MAE#0.092$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.773$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.848$Dichotomous Image Segmentation#DIS-TE3#HCE#1059$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.721$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.633$Dichotomous Image Segmentation#DIS-TE4#MAE#0.107$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.752$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.825$Dichotomous Image Segmentation#DIS-TE4#HCE#3760$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.685$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.595$Dichotomous Image Segmentation#DIS-VD#MAE#0.107$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.733$Dichotomous Image Segmentation#DIS-VD#E-measure#0.800$Dichotomous Image Segmentation#DIS-VD#HCE#1567$Salient Object Detection#HKU-IS#MAE#0.028$Salient Object Detection#HKU-IS#E-measure#0.952$Salient Object Detection#HKU-IS#max_F1#0.936$Salient Object Detection#HKU-IS#S-measure#0.917$Salient Object Detection#ECSSD#MAE#0.033$Salient Object Detection#ECSSD#max_F1#0.945$Salient Object Detection#ECSSD#S-measure#0.924$Salient Object Detection#ECSSD#E-measure#0.927$Salient Object Detection#DUTS-TE#MAE#0.035$Salient Object Detection#DUTS-TE#max_F1#0.891$Salient Object Detection#DUTS-TE#E-measure#0.901$Salient Object Detection#DUTS-TE#S-measure#0.888$Salient Object Detection#PASCAL-S#MAE#0.061$Salient Object Detection#PASCAL-S#max_F1#0.871$Salient Object Detection#PASCAL-S#S-measure#0.854$Salient Object Detection#PASCAL-S#E-measure#0.858$Salient Object Detection#DUT-OMRON#max_F1#0.813$Salient Object Detection#DUT-OMRON#MAE#0.052$Salient Object Detection#DUT-OMRON#E-measure#0.869$Salient Object Detection#DUT-OMRON#S-measure#0.838
2007.08074v3.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.620$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.517$Dichotomous Image Segmentation#DIS-TE1#MAE#0.099$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.701$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.766$Dichotomous Image Segmentation#DIS-TE1#HCE#230$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.702$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.598$Dichotomous Image Segmentation#DIS-TE2#MAE#0.102$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.737$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.804$Dichotomous Image Segmentation#DIS-TE2#HCE#501$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.726$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.620$Dichotomous Image Segmentation#DIS-TE3#MAE#0.103$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.747$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.815$Dichotomous Image Segmentation#DIS-TE3#HCE#972$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.729$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.625$Dichotomous Image Segmentation#DIS-TE4#MAE#0.109$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.743$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.803$Dichotomous Image Segmentation#DIS-TE4#HCE#3654$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.678$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.574$Dichotomous Image Segmentation#DIS-VD#MAE#0.110$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.723$Dichotomous Image Segmentation#DIS-VD#E-measure#0.783$Dichotomous Image Segmentation#DIS-VD#HCE#1493
2003.00651v1.pdf	Dichotomous Image Segmentation#DIS-TE1#max F-Measure#0.598$Dichotomous Image Segmentation#DIS-TE1#weighted F-measure#0.495$Dichotomous Image Segmentation#DIS-TE1#MAE#0.103$Dichotomous Image Segmentation#DIS-TE1#S-Measure#0.705$Dichotomous Image Segmentation#DIS-TE1#E-measure#0.750$Dichotomous Image Segmentation#DIS-TE1#HCE#271$Dichotomous Image Segmentation#DIS-TE2#max F-Measure#0.673$Dichotomous Image Segmentation#DIS-TE2#weighted F-measure#0.570$Dichotomous Image Segmentation#DIS-TE2#MAE#0.109$Dichotomous Image Segmentation#DIS-TE2#S-Measure#0.735$Dichotomous Image Segmentation#DIS-TE2#E-measure#0.786$Dichotomous Image Segmentation#DIS-TE2#HCE#574$Dichotomous Image Segmentation#DIS-TE3#max F-Measure#0.699$Dichotomous Image Segmentation#DIS-TE3#weighted F-measure#0.590$Dichotomous Image Segmentation#DIS-TE3#MAE#0.109$Dichotomous Image Segmentation#DIS-TE3#S-Measure#0.748$Dichotomous Image Segmentation#DIS-TE3#E-measure#0.801$Dichotomous Image Segmentation#DIS-TE3#HCE#1058$Dichotomous Image Segmentation#DIS-TE4#max F-Measure#0.670$Dichotomous Image Segmentation#DIS-TE4#weighted F-measure#0.559$Dichotomous Image Segmentation#DIS-TE4#MAE#0.127$Dichotomous Image Segmentation#DIS-TE4#S-Measure#0.723$Dichotomous Image Segmentation#DIS-TE4#E-measure#0.767$Dichotomous Image Segmentation#DIS-TE4#HCE#3678$Dichotomous Image Segmentation#DIS-VD#max F-Measure#0.648$Dichotomous Image Segmentation#DIS-VD#weighted F-measure#0.542$Dichotomous Image Segmentation#DIS-VD#MAE#0.118$Dichotomous Image Segmentation#DIS-VD#S-Measure#0.718$Dichotomous Image Segmentation#DIS-VD#E-measure#0.765$Dichotomous Image Segmentation#DIS-VD#HCE#1555
2104.01784v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#89.6$RGB-D Salient Object Detection#SIP#max E-Measure#93.3$RGB-D Salient Object Detection#SIP#max F-Measure#90.1$RGB-D Salient Object Detection#SIP#Average MAE#0.044$RGB-D Salient Object Detection#STERE#S-Measure#91.5$RGB-D Salient Object Detection#STERE#Average MAE#0.038$RGB-D Salient Object Detection#STERE#max F-Measure#91.1$RGB-D Salient Object Detection#STERE#max E-Measure#94.9$RGB-D Salient Object Detection#LFSD#S-Measure#86.7$RGB-D Salient Object Detection#LFSD#Average MAE#0.07$RGB-D Salient Object Detection#LFSD#max E-Measure#90.6$RGB-D Salient Object Detection#LFSD#max F-Measure#87.4$RGB-D Salient Object Detection#NJU2K#S-Measure#92.1$RGB-D Salient Object Detection#NJU2K#Average MAE#0.036$RGB-D Salient Object Detection#NJU2K#max E-Measure#95.4$RGB-D Salient Object Detection#NJU2K#max F-Measure#92.4$RGB-D Salient Object Detection#NLPR#S-Measure#93.4$RGB-D Salient Object Detection#NLPR#Average MAE#0.023$RGB-D Salient Object Detection#NLPR#max F-Measure#92.3$RGB-D Salient Object Detection#NLPR#max E-Measure#96.5$RGB-D Salient Object Detection#DES#S-Measure#94.3$RGB-D Salient Object Detection#DES#Average MAE#0.018$RGB-D Salient Object Detection#DES#max E-Measure#97.9$RGB-D Salient Object Detection#DES#max F-Measure#94.0
2207.07898v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#89.2$RGB-D Salient Object Detection#SIP#max E-Measure#93.4$RGB-D Salient Object Detection#SIP#max F-Measure#89.9$RGB-D Salient Object Detection#SIP#Average MAE#0.042$RGB-D Salient Object Detection#STERE#S-Measure#90.7$RGB-D Salient Object Detection#STERE#Average MAE#0.035$RGB-D Salient Object Detection#STERE#max F-Measure#90.0$RGB-D Salient Object Detection#STERE#max E-Measure#94.3$RGB-D Salient Object Detection#NJU2K#S-Measure#91.8$RGB-D Salient Object Detection#NJU2K#Average MAE#0.032$RGB-D Salient Object Detection#NJU2K#max E-Measure#95.0$RGB-D Salient Object Detection#NJU2K#max F-Measure#92.0$RGB-D Salient Object Detection#NLPR#S-Measure#92.6$RGB-D Salient Object Detection#NLPR#Average MAE#0.022$RGB-D Salient Object Detection#NLPR#max F-Measure#91.4$RGB-D Salient Object Detection#NLPR#max E-Measure#96.2$RGB-D Salient Object Detection#DES#S-Measure#93.8$RGB-D Salient Object Detection#DES#Average MAE#0.016$RGB-D Salient Object Detection#DES#max E-Measure#97.6$RGB-D Salient Object Detection#DES#max F-Measure#94.3
2008.12134v2.pdf	RGB-D Salient Object Detection#SIP#S-Measure#89.2$RGB-D Salient Object Detection#SIP#max E-Measure#94.9$RGB-D Salient Object Detection#SIP#max F-Measure#90.0$RGB-D Salient Object Detection#SIP#Average MAE#0.046$RGB-D Salient Object Detection#STERE#S-Measure#91.1$RGB-D Salient Object Detection#STERE#Average MAE#0.039$RGB-D Salient Object Detection#STERE#max F-Measure#90.7$RGB-D Salient Object Detection#STERE#max E-Measure#94.9$RGB-D Salient Object Detection#NJU2K#S-Measure#91.1$RGB-D Salient Object Detection#NJU2K#Average MAE#0.040$RGB-D Salient Object Detection#NJU2K#max E-Measure#94.8$RGB-D Salient Object Detection#NJU2K#max F-Measure#91.3$RGB-D Salient Object Detection#NLPR#S-Measure#92.6$RGB-D Salient Object Detection#NLPR#Average MAE#0.023$RGB-D Salient Object Detection#NLPR#max F-Measure#91.7$RGB-D Salient Object Detection#NLPR#max E-Measure#96.4$RGB-D Salient Object Detection#DES#S-Measure#93.6$RGB-D Salient Object Detection#DES#Average MAE#0.021$RGB-D Salient Object Detection#DES#max E-Measure#97.5$RGB-D Salient Object Detection#DES#max F-Measure#92.9
2004.14582v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#88.3$RGB-D Salient Object Detection#SIP#max E-Measure#92.5$RGB-D Salient Object Detection#SIP#max F-Measure#89.0$RGB-D Salient Object Detection#SIP#Average MAE#0.052$RGB-D Salient Object Detection#RGBD135#S-Measure#86.7$RGB-D Salient Object Detection#RGBD135#Average MAE#0.050$RGB-D Salient Object Detection#RGBD135#max F-Measure#84.9$RGB-D Salient Object Detection#RGBD135#max E-Measure#91.6$RGB-D Salient Object Detection#STERE#S-Measure#90.4$RGB-D Salient Object Detection#STERE#Average MAE#0.043$RGB-D Salient Object Detection#STERE#max F-Measure#89.8$RGB-D Salient Object Detection#STERE#max E-Measure#94.2$RGB-D Salient Object Detection#LFSD#Average MAE#0.0x$RGB-D Salient Object Detection#NJU2K#S-Measure#91.5$RGB-D Salient Object Detection#NJU2K#Average MAE#0.039$RGB-D Salient Object Detection#NJU2K#max E-Measure#94.8$RGB-D Salient Object Detection#NJU2K#max F-Measure#92.0$RGB-D Salient Object Detection#NLPR#S-Measure#92.5$RGB-D Salient Object Detection#NLPR#Average MAE#0.024$RGB-D Salient Object Detection#NLPR#max F-Measure#91.4$RGB-D Salient Object Detection#NLPR#max E-Measure#96.1$RGB-D Salient Object Detection#DES#S-Measure#93.1$RGB-D Salient Object Detection#DES#Average MAE#0.021$RGB-D Salient Object Detection#DES#max E-Measure#97.1$RGB-D Salient Object Detection#DES#max F-Measure#92.6
2004.08515v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#87.9$RGB-D Salient Object Detection#SIP#max E-Measure#92.3$RGB-D Salient Object Detection#SIP#max F-Measure#88.5$RGB-D Salient Object Detection#SIP#Average MAE#0.051$RGB-D Salient Object Detection#STERE#S-Measure#90.5$RGB-D Salient Object Detection#STERE#Average MAE#0.042$RGB-D Salient Object Detection#STERE#max F-Measure#90.1$RGB-D Salient Object Detection#STERE#max E-Measure#94.6$RGB-D Salient Object Detection#NJU2K#S-Measure#90.3$RGB-D Salient Object Detection#NJU2K#Average MAE#0.043$RGB-D Salient Object Detection#NJU2K#max E-Measure#94.4$RGB-D Salient Object Detection#NJU2K#max F-Measure#90.3$RGB-D Salient Object Detection#NLPR#S-Measure#92.5$RGB-D Salient Object Detection#NLPR#Average MAE#0.022$RGB-D Salient Object Detection#NLPR#max F-Measure#91.6$RGB-D Salient Object Detection#NLPR#max E-Measure#96.2$RGB-D Salient Object Detection#DES#S-Measure#92.9$RGB-D Salient Object Detection#DES#Average MAE#0.022$RGB-D Salient Object Detection#DES#max E-Measure#96.8$RGB-D Salient Object Detection#DES#max F-Measure#91.9
2007.02713v3.pdf	RGB-D Salient Object Detection#SIP#S-Measure#87.9$RGB-D Salient Object Detection#SIP#max E-Measure#92.2$RGB-D Salient Object Detection#SIP#max F-Measure#88.3$RGB-D Salient Object Detection#SIP#Average MAE#0.055$RGB-D Salient Object Detection#RGBD135#S-Measure#88.2$RGB-D Salient Object Detection#RGBD135#Average MAE#0.044$RGB-D Salient Object Detection#RGBD135#max F-Measure#85.9$RGB-D Salient Object Detection#RGBD135#max E-Measure#91.9$RGB-D Salient Object Detection#STERE#S-Measure#90.8$RGB-D Salient Object Detection#STERE#Average MAE#0.041$RGB-D Salient Object Detection#STERE#max F-Measure#90.3$RGB-D Salient Object Detection#STERE#max E-Measure#94.2$RGB-D Salient Object Detection#LFSD#S-Measure#86.4$RGB-D Salient Object Detection#LFSD#Average MAE#0.072$RGB-D Salient Object Detection#LFSD#max E-Measure#90.1$RGB-D Salient Object Detection#LFSD#max F-Measure#85.8$RGB-D Salient Object Detection#NJU2K#S-Measure#92.1$RGB-D Salient Object Detection#NJU2K#Average MAE#0.035$RGB-D Salient Object Detection#NJU2K#max E-Measure#94.9$RGB-D Salient Object Detection#NJU2K#max F-Measure#92.0$RGB-D Salient Object Detection#NLPR#S-Measure#93.0$RGB-D Salient Object Detection#NLPR#Average MAE#0.023$RGB-D Salient Object Detection#NLPR#max F-Measure#91.8$RGB-D Salient Object Detection#NLPR#max E-Measure#96.1$RGB-D Salient Object Detection#DES#S-Measure#93.3$RGB-D Salient Object Detection#DES#Average MAE#0.021$RGB-D Salient Object Detection#DES#max E-Measure#96.6$RGB-D Salient Object Detection#DES#max F-Measure#92.7
2004.05763v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#87.5$RGB-D Salient Object Detection#SIP#Average MAE#0.051$RGB-D Salient Object Detection#STERE#S-Measure#90.3$RGB-D Salient Object Detection#STERE#Average MAE#0.039$RGB-D Salient Object Detection#LFSD#S-Measure#86.4$RGB-D Salient Object Detection#LFSD#Average MAE#0.066$RGB-D Salient Object Detection#NJU2K#S-Measure#89.7$RGB-D Salient Object Detection#NJU2K#Average MAE#0.043$RGB-D Salient Object Detection#NLPR#S-Measure#92.0$RGB-D Salient Object Detection#NLPR#Average MAE#0.025$RGB-D Salient Object Detection#DES#S-Measure#93.4$RGB-D Salient Object Detection#DES#Average MAE#0.019
2008.07064v1.pdf	RGB-D Salient Object Detection#SIP#S-Measure#87.5$RGB-D Salient Object Detection#SIP#Average MAE#0.059
1907.06781v2.pdf	RGB-D Salient Object Detection#SIP#S-Measure#86.0$RGB-D Salient Object Detection#SIP#max E-Measure#90.9$RGB-D Salient Object Detection#SIP#max F-Measure#86.1$RGB-D Salient Object Detection#SIP#Average MAE#0.063$RGB-D Salient Object Detection#RGBD135#S-Measure#85.7$RGB-D Salient Object Detection#RGBD135#Average MAE#0.058$RGB-D Salient Object Detection#RGBD135#max F-Measure#83.4$RGB-D Salient Object Detection#RGBD135#max E-Measure#91.0$RGB-D Salient Object Detection#STERE#S-Measure#89.9$RGB-D Salient Object Detection#STERE#Average MAE#0.046$RGB-D Salient Object Detection#STERE#max F-Measure#89.1$RGB-D Salient Object Detection#STERE#max E-Measure#93.8$RGB-D Salient Object Detection#LFSD#S-Measure#82.5$RGB-D Salient Object Detection#LFSD#Average MAE#0.095$RGB-D Salient Object Detection#LFSD#max E-Measure#86.2$RGB-D Salient Object Detection#LFSD#max F-Measure#81.0$RGB-D Salient Object Detection#NJU2K#S-Measure#90.0$RGB-D Salient Object Detection#NJU2K#Average MAE#0.046$RGB-D Salient Object Detection#NJU2K#max E-Measure#93.9$RGB-D Salient Object Detection#NJU2K#max F-Measure#90.0$RGB-D Salient Object Detection#NLPR#S-Measure#91.2$RGB-D Salient Object Detection#NLPR#Average MAE#0.030$RGB-D Salient Object Detection#NLPR#max F-Measure#89.7$RGB-D Salient Object Detection#NLPR#max E-Measure#95.3
2104.12099v2.pdf	RGB-D Salient Object Detection#SIP#S-Measure#0.904$RGB-D Salient Object Detection#SIP#max E-Measure#0.944$RGB-D Salient Object Detection#SIP#max F-Measure#0.915$RGB-D Salient Object Detection#NJUD#S-Measure#0.922$RGB-D Salient Object Detection#NLPR#S-Measure#0.932
2102.06407v1.pdf	RGB-D Salient Object Detection#SIP#Average MAE#0.043
2006.00269v2.pdf	RGB-D Salient Object Detection#RGBD135#S-Measure#88.5$RGB-D Salient Object Detection#RGBD135#Average MAE#0.042$RGB-D Salient Object Detection#RGBD135#max F-Measure#88.1$RGB-D Salient Object Detection#STERE#S-Measure#91.0$RGB-D Salient Object Detection#STERE#Average MAE#0.037$RGB-D Salient Object Detection#STERE#max F-Measure#91.5$RGB-D Salient Object Detection#NJU2K#S-Measure#90.2$RGB-D Salient Object Detection#NJU2K#Average MAE#0.042$RGB-D Salient Object Detection#NJU2K#max F-Measure#91.1$RGB-D Salient Object Detection#NLPR#S-Measure#92.9$RGB-D Salient Object Detection#NLPR#Average MAE#0.021$RGB-D Salient Object Detection#NLPR#max F-Measure#92.9$RGB-D Salient Object Detection#DES#S-Measure#90.8$RGB-D Salient Object Detection#DES#Average MAE#0.023$RGB-D Salient Object Detection#DES#max F-Measure#92.8
2008.03087v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#91.1$RGB-D Salient Object Detection#NJU2K#Average MAE#0.035
2007.06227v3.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#91.1$RGB-D Salient Object Detection#NJU2K#Average MAE#0.037
2007.07051v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#90.4$RGB-D Salient Object Detection#NJU2K#Average MAE#0.044
2007.04901v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#90.3$RGB-D Salient Object Detection#NJU2K#Average MAE#0.046
2007.06811v2.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#89.7$RGB-D Salient Object Detection#NJU2K#Average MAE#0.046$RGB-D Salient Object Detection#NJU2K#max F-Measure#90.5
2008.04159v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#89.7$RGB-D Salient Object Detection#NJU2K#Average MAE#0.052
2007.11782v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#89.4$RGB-D Salient Object Detection#NJU2K#Average MAE#0.047
1607.03333v1.pdf	RGB-D Salient Object Detection#NJU2K#S-Measure#51.4$RGB-D Salient Object Detection#NJU2K#Average MAE#0.205$RGB-D Salient Object Detection#NJU2K#max E-Measure#72.4$RGB-D Salient Object Detection#NJU2K#max F-Measure#63.2
2205.09613v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#22.5$Few-Shot Object Detection#MS-COCO (10-shot)#AP#15.0$Few-Shot Object Detection#MS-COCO (30-shot)#AP#30.2$Few-Shot Object Detection#MS-COCO (30-shot)#AP#21.0
2208.07039v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#22.4$Few-Shot Object Detection#MS-COCO (30-shot)#AP#25.0$Few-Shot Object Detection#MS-COCO (1-shot)#AP#13.4
2204.05220v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#19.1
2102.12152v3.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#18.6
2108.09017v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#18.5$Few-Shot Object Detection#MS-COCO (30-shot)#AP#22.6$Few-Shot Object Detection#MS-COCO (1-shot)#AP#9.3
2103.11731v3.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#17.8$Few-Shot Object Detection#MS-COCO (10-shot)#AP#16.7$Few-Shot Object Detection#MS-COCO (30-shot)#AP#22.9$Few-Shot Object Detection#MS-COCO (30-shot)#AP#21.3
2103.04612v3.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#15.1
2109.07734v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#13.4$Few-Shot Object Detection#MS-COCO (30-shot)#AP#17.1
2110.13377v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#13.3$Few-Shot Object Detection#MS-COCO (10-shot)#AP#12.5
2007.12107v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#12.5$Few-Shot Object Detection#MS-COCO (30-shot)#AP#14.7
2103.01903v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#11.3$Few-Shot Object Detection#MS-COCO (30-shot)#AP#14.7
1908.01998v4.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#11.1
2103.05950v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#11.1$Few-Shot Object Detection#MS-COCO (30-shot)#AP#15.3
2103.01077v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#11.0
2003.06957v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#10.0$Few-Shot Object Detection#MS-COCO (30-shot)#AP#13.7$Few-Shot Object Detection#MS-COCO (30-shot)#AP#13.4
2007.09384v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#9.8$Few-Shot Object Detection#MS-COCO (30-shot)#AP#14.1
1812.01866v2.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#5.6$Few-Shot Object Detection#MS-COCO (30-shot)#AP#9.1
1803.01529v1.pdf	Few-Shot Object Detection#MS-COCO (10-shot)#AP#3.2$Few-Shot Object Detection#MS-COCO (30-shot)#AP#6.7
1909.13032v2.pdf	Few-Shot Object Detection#MS-COCO (30-shot)#AP#12.4
2008.05676v2.pdf	Few-Shot Object Detection#LVIS v1.0 val#AP#23.2$Few-Shot Object Detection#LVIS v1.0 val#APr#14.2$Few-Shot Object Detection#LVIS v1.0 val#APc#22.7$Few-Shot Object Detection#LVIS v1.0 val#APf#27.7
2208.09686v1.pdf	Video Object Detection#ImageNet VID#MAP#87.5
2003.12063v1.pdf	Video Object Detection#ImageNet VID#MAP#85.4
2109.03495v2.pdf	Video Object Detection#ImageNet VID#MAP#84.3$Video Object Detection#EPIC KITCHENS-unseen splits#mAP#39.6$Video Object Detection#EPIC KITCHENS-seen splits#mAP#42.2$Video Instance Segmentation#YouTube-VIS#mask AP#38
1907.06390v2.pdf	Video Object Detection#ImageNet VID#MAP#84.3$Video Object Detection#ImageNet VID#MAP#82.69
2009.11050.pdf	Video Object Detection#ImageNet VID#MAP#84.2$Video Object Detection#ImageNet VID#MAP#80.1$Video Object Detection#ImageNet VID#MAP#75.1$Video Object Detection#ImageNet VID#MAP#68.6
1811.11167v1.pdf	Video Object Detection#ImageNet VID#MAP#83.5
1911.05253v2.pdf	Video Object Detection#ImageNet VID#MAP#81.7
1703.10025v2.pdf	Video Object Detection#ImageNet VID#MAP#80.1
1903.10172v1.pdf	Video Object Detection#ImageNet VID#MAP#61.4
2210.02368v2.pdf	Video Object Detection#ImageNet VID#MAP#80.3
2201.12558v4.pdf	Object Detection In Aerial Images#DOTA#mAP#80.93%
2108.05699v1.pdf	Object Detection In Aerial Images#DOTA#mAP#80.87%
2106.01883v5.pdf	Object Detection In Aerial Images#DOTA#mAP#80.63%
2112.06701v1.pdf	Object Detection In Aerial Images#DOTA#mAP#80.37%
2101.11952v4.pdf	Object Detection In Aerial Images#DOTA#mAP#80.23%
2103.07733v1.pdf	Object Detection In Aerial Images#DOTA#mAP#80.10%
2203.15221v2.pdf	Object Detection In Aerial Images#DOTA#mAP#79.59%
2008.09397v3.pdf	Object Detection In Aerial Images#DOTA#mAP#79.42%
2105.11111v4.pdf	Object Detection In Aerial Images#DOTA#mAP#77.63%
2103.11636v3.pdf	Object Detection In Aerial Images#DOTA#mAP#77.62%
2011.09670v4.pdf	Object Detection In Aerial Images#DOTA#mAP#77.37%
2203.10747v1.pdf	Object Detection In Aerial Images#DOTA#mAP#77.05%
2109.12848v4.pdf	Object Detection In Aerial Images#DOTA#mAP#76.95%
2004.13316v2.pdf	Object Detection In Aerial Images#DOTA#mAP#76.81%
2010.08720v1.pdf	Object Detection In Aerial Images#DOTA#mAP#76.64%
1908.05612v6.pdf	Object Detection In Aerial Images#DOTA#mAP#76.47%
2003.05597v4.pdf	Object Detection In Aerial Images#DOTA#mAP#76.17%
1906.09447v1.pdf	Object Detection In Aerial Images#DOTA#mAP#75.75
2104.11435v2.pdf	Object Detection In Aerial Images#DOTA#mAP#75.26%
1911.09358v2.pdf	Object Detection In Aerial Images#DOTA#mAP#75.02%
1911.08299v3.pdf	Object Detection In Aerial Images#DOTA#mAP#74.10%
2101.06849v2.pdf	Object Detection In Aerial Images#DOTA#mAP#73.50%
2005.09973v2.pdf	Object Detection In Aerial Images#DOTA#mAP#73.23%
1912.10694v3.pdf	Object Detection In Aerial Images#DOTA#mAP#72.8%
1811.07126v4.pdf	Object Detection In Aerial Images#DOTA#mAP#72.61%
1812.00155v1.pdf	Object Detection In Aerial Images#DOTA#mAP#69.56%
1807.02700v3.pdf	Object Detection In Aerial Images#DOTA#mAP#68.16%
2007.09584v1.pdf	Object Detection In Aerial Images#DOTA#mAP#60.5%
1711.10398v3.pdf	Object Detection In Aerial Images#DOTA#mAP#52.93%
1904.01665v1.pdf	Weakly Supervised Object Detection#HICO-DET#MAP#5.39$Weakly Supervised Object Detection#Charades#MAP#10.03
1807.03342v2.pdf	Weakly Supervised Object Detection#HICO-DET#MAP#3.62$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#48.8$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#44.2$Weakly Supervised Object Detection#Charades#MAP#2.83$Weakly Supervised Object Detection#ImageNet#MAP#19.6
1511.02853v4.pdf	Weakly Supervised Object Detection#HICO-DET#MAP#3.27$Weakly Supervised Object Detection#COCO test-dev#AP50#11.5$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#39.3$Weakly Supervised Object Detection#Watercolor2k#MAP#12.7$Weakly Supervised Object Detection#Charades#MAP#0.65
2008.01178v5.pdf	Weakly Supervised Object Detection#CASPAPaintings#Mean mAP#16.2$Weakly Supervised Object Detection#PeopleArt#MAP#58.3$Weakly Supervised Object Detection#IconArt#MAP#15.1$Weakly Supervised Object Detection#Comic2k#MAP#27$Weakly Supervised Object Detection#Clipart1k#MAP#38.4$Weakly Supervised Object Detection#Watercolor2k#MAP#49.5
2003.06297v1.pdf	Weakly Supervised Object Detection#Cityscapes-to-Foggy Cityscapes#mAP#39.8
1810.02569v1.pdf	Weakly Supervised Object Detection#PeopleArt#MAP#55.4$Weakly Supervised Object Detection#IconArt#MAP#13.2$Weakly Supervised Object Detection#Watercolor2k#MAP#50.1
2208.07576v2.pdf	Weakly Supervised Object Detection#MS-COCO-2014#AP#13.7$Weakly Supervised Object Detection#MS-COCO-2017#AP#13.6$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#56.1$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#54.6
2004.04725v3.pdf	Weakly Supervised Object Detection#COCO test-dev#AP50#24.8$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#58.1$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#54.9$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#52.1
1711.08174v2.pdf	Weakly Supervised Object Detection#COCO test-dev#AP50#13.6
1611.08258v1.pdf	Weakly Supervised Object Detection#COCO test-dev#AP50#12.3$Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#42.8$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#37.9$Weakly Supervised Object Detection#ImageNet#MAP#16.3
2010.12023v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#56.8$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#53.6$Weakly Supervised Object Detection#MSCOCO#mAP#13.9$Weakly Supervised Object Detection#MSCOCO#mAP@50#27.8
1911.12148v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#54.5$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#49.5
1811.10016v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#53.6$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#49.5
1909.04972.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#53.6$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#47.2
1904.05647v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#53.1$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#46.7
1906.06023v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#52.6$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#48.0
2002.01087v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#52.6$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#46.4
1908.03792v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#52.1$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#48.1
1802.09129v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#51.2
1911.11512v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#48.8
1804.09466v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#47.6$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#42.9
1902.06057v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#47.3$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#42.4
1704.00138v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#47.0$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#42.5$Weakly Supervised Object Detection#ImageNet#MAP#6
1707.08721v2.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#46.0$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#42.8
1704.05188v2.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#43.7$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#38.3
1706.08249v8.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#41.7$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#35.4$Weakly Supervised Object Detection#COCO#MAP#56.6$Weakly Supervised Object Detection#ImageNet#MAP#13.9
1910.02101.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#40.9$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#35.2
1605.07651v3.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#38.11
1912.00384v6.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#38.0$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#36.6
1609.04331v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#36.3$Weakly Supervised Object Detection#PASCAL VOC 2012 test#MAP#35.3$Weakly Supervised Object Detection#Charades#MAP#1.12
1703.01290v1.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#31.3
1403.1024v4.pdf	Weakly Supervised Object Detection#PASCAL VOC 2007#MAP#22.7
1803.11365v1.pdf	Weakly Supervised Object Detection#Comic2k#MAP#42.2$Weakly Supervised Object Detection#Comic2k#MAP#37.2$Weakly Supervised Object Detection#Clipart1k#MAP#46.0$Weakly Supervised Object Detection#Watercolor2k#MAP#59.1$Weakly Supervised Object Detection#Watercolor2k#MAP#54.3
1709.01829v1.pdf	Weakly Supervised Object Detection#COCO#MAP#55.3
1603.00489v2.pdf	Weakly Supervised Object Detection#COCO#MAP#47.9
1511.03776v3.pdf	Weakly Supervised Object Detection#COCO#MAP#43.5
1708.00666v1.pdf	Weakly Supervised Object Detection#Charades#MAP#1.98
2004.09870v2.pdf	Rice Grain Disease Detection#Rice Grain Disease Dataset#mAP#88.24
1907.07484v2.pdf	Robust Object Detection#COCO#mPC [AP]#20.4$Robust Object Detection#COCO#rPC [%]#58.9$Robust Object Detection#COCO#mPC [AP]#18.2$Robust Object Detection#COCO#rPC [%]#50.2$Robust Object Detection#Cityscapes test#mPC [AP]#17.2$Robust Object Detection#Cityscapes test#rPC [%]#47.4$Robust Object Detection#Cityscapes test#mPC [AP]#12.2$Robust Object Detection#Cityscapes test#rPC [%]#33.4$Robust Object Detection#PASCAL VOC 2007#mPC [AP50]#56.2$Robust Object Detection#PASCAL VOC 2007#rPC [%]#69.9$Robust Object Detection#PASCAL VOC 2007#mPC [AP50]#48.6$Robust Object Detection#PASCAL VOC 2007#rPC [%]#60.4
1712.08273v1.pdf	Object Proposal Generation#PASCAL VOC 2012, 60 proposals per image#Average Recall#0.814
1703.10277v1.pdf	Object Proposal Generation#PASCAL VOC 2012, 60 proposals per image#Average Recall#0.667
2204.00298v4.pdf	Dense Object Detection#SKU-110K#AP#59.0
2007.11946v3.pdf	Dense Object Detection#SKU-110K#AP#58.7
2203.06886v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#87.16
2103.12277v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#86.83
2005.13753v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#86.6
2203.16074v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#86.05
1908.04373v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#85.22
1909.04247v3.pdf	Medical Object Detection#DeepLesion#Sensitivity#83.64
1906.02283v1.pdf	Medical Object Detection#DeepLesion#Sensitivity#82.36
1806.09648v2.pdf	Medical Object Detection#DeepLesion#Sensitivity#75.55
2110.12093v1.pdf	Medical Object Detection#MoNuSeg 2018#Average-mAP#0.487
1811.08513v2.pdf	Medical Object Detection#Barrett’s Esophagus#Mean Accuracy#81%
1703.02442v2.pdf	Medical Object Detection#Barrett’s Esophagus#Mean Accuracy#74%
2104.13921v3.pdf	Open Vocabulary Object Detection#LVIS v1.0#mask APr#26.3$Open Vocabulary Object Detection#LVIS v1.0#box APr#27.0$Open Vocabulary Object Detection#LVIS v1.0#mask APr#18.7$Open Vocabulary Object Detection#LVIS v1.0#box APr#19.8$Open Vocabulary Object Detection#LVIS v1.0#mask APr#16.6$Open Vocabulary Object Detection#LVIS v1.0#box APr#16.7$Open Vocabulary Object Detection#LVIS v1.0#mask APr#16.1$Open Vocabulary Object Detection#LVIS v1.0#box APr#16.3$Open Vocabulary Object Detection#MSCOCO#AP 0.5#27.6$Open Vocabulary Object Detection#Objects365#mask AP50#18.2
2206.11134v2.pdf	Open Vocabulary Object Detection#LVIS v1.0#mask APr#22.4$Open Vocabulary Object Detection#MSCOCO#AP 0.5#32.6
2112.09106v1.pdf	Open Vocabulary Object Detection#LVIS v1.0#mask APr#22.0$Open Vocabulary Object Detection#LVIS v1.0#mask APr#17.1$Open Vocabulary Object Detection#MSCOCO#AP 0.5#39.3$Open Vocabulary Object Detection#MSCOCO#AP 0.5#31.4
2207.03482v2.pdf	Open Vocabulary Object Detection#LVIS v1.0#mask APr#21.1$Open Vocabulary Object Detection#MSCOCO#AP 0.5#36.9$Open Vocabulary Object Detection#OpenImages-v4#mask AP50#42.9$Open Vocabulary Object Detection#Objects365#mask AP50#22.3$Zero-Shot Object Detection#MSCOCO#AP 0.5#40.5
2201.02605v3.pdf	Open Vocabulary Object Detection#LVIS v1.0#mask APr#17.8$Open Vocabulary Object Detection#MSCOCO#AP 0.5#27.8$Open Vocabulary Object Detection#OpenImages-v4#AP 0.5#42.2$Open Vocabulary Object Detection#OpenImages-v4#mask AP50#42.2
2205.06230v2.pdf	Open Vocabulary Object Detection#LVIS v1.0#box APr#31.2$One-Shot Object Detection#COCO#AP 0.5#41.8
2207.08954v1.pdf	Open Vocabulary Object Detection#MSCOCO#AP 0.5#34.4
2203.11876v1.pdf	Open Vocabulary Object Detection#MSCOCO#AP 0.5#29.4
2205.06160v2.pdf	Open Vocabulary Object Detection#MSCOCO#AP 0.5#28.6
2011.10678v2.pdf	Open Vocabulary Object Detection#MSCOCO#AP 0.5#22.8
2203.10593v1.pdf	Open Vocabulary Object Detection#MSCOCO#AP 0.5#20.3
1811.08982v3.pdf	Zero-Shot Object Detection#MS-COCO#mAP#12.62$Zero-Shot Object Detection#MS-COCO#Recall#43.56
2010.09425v1.pdf	Zero-Shot Object Detection#ImageNet Detection#mAP#24.3$Zero-Shot Object Detection#PASCAL VOC'07#mAP#64.9
1803.06049v1.pdf	Zero-Shot Object Detection#ImageNet Detection#mAP#16.4
2007.12881v3.pdf	Camouflaged Object Segmentation#CAMO#MAE#0.077$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#71.9$Camouflaged Object Segmentation#CAMO#S-Measure#78.5$Camouflaged Object Segmentation#CAMO#E-Measure#84.9$Camouflaged Object Segmentation#CAMO#F-Measure#78.4$Camouflaged Object Segmentation#CAMO#MAE#0.100$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#65.2$Camouflaged Object Segmentation#CAMO#S-Measure#74.1$Camouflaged Object Segmentation#CAMO#E-Measure#80.4
2105.09451v1.pdf	Camouflaged Object Segmentation#CAMO#F-Measure#65.4$Camouflaged Object Segmentation#CAMO#MAE#0.126$Camouflaged Object Segmentation#CAMO#Weighted F-Measure#48.4$Camouflaged Object Segmentation#CAMO#S-Measure#68.2$Camouflaged Object Segmentation#CAMO#E-Measure#68.5
1911.12529v1.pdf	One-Shot Object Detection#COCO#AP 0.5#22.0
1811.11507v2.pdf	One-Shot Object Detection#COCO#AP 0.5#16.3$One-Shot Instance Segmentation#COCO#AP 0.5#14.5
2103.02603v2.pdf	Open World Object Detection#COCO 2017 (Electronic, Indoor, Kitchen, Furniture)#MAP#26.66$Open World Object Detection#PASCAL VOC 2007#WI#0.02193$Open World Object Detection#PASCAL VOC 2007#A-OSE#8234$Open World Object Detection#PASCAL VOC 2007#MAP#56.34$Open World Object Detection#PASCAL VOC 2007#Unknown Recall#14.40$Open World Object Detection#COCO 2017 (Sports, Food)#WI#0.0081$Open World Object Detection#COCO 2017 (Sports, Food)#A-OSE#6634$Open World Object Detection#COCO 2017 (Sports, Food)#MAP#29.32$Open World Object Detection#COCO 2017 (Sports, Food)#Unknown Recall#14.79$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#A-OSE#7772$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#WI#0.0154$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#MAP#38.98$Open World Object Detection#COCO 2017 (Outdoor, Accessories, Appliance, Truck)#Unknown Recall#11.32
1812.01366v2.pdf	Surgical tool detection#Cholec80#mAP#92.9
1907.06099v1.pdf	Surgical tool detection#Cholec80#mAP#89.1
1806.05573v2.pdf	Surgical tool detection#Cholec80#mAP#87.4
1602.03012v2.pdf	Surgical tool detection#Cholec80#mAP#81.0$Surgical tool detection#Cholec80#mAP#80.9
2207.01071v1.pdf	Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#58.1
2203.10456v1.pdf	Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#55.8
1910.05483v2.pdf	Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#47.9$Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#42.8
1407.5736v1.pdf	Object Detection In Indoor Scenes#SUN RGB-D#AP 0.5#44.2
1811.12608v1.pdf	Object Skeleton Detection#SK-LARGE#F-Measure#0.732
1801.01849v4.pdf	Object Skeleton Detection#SK-LARGE#F-Measure#0.724
1905.12365v1.pdf	3D Object Detection From Monocular Images#nuScenes Cars#AP 2.0m#69.0$3D Object Detection From Monocular Images#nuScenes Cars#AP 0.5m#10.7$3D Object Detection From Monocular Images#nuScenes Cars#AP 1.0m#37.5$3D Object Detection From Monocular Images#nuScenes Cars#AP 4.0m#85.7$3D Object Detection From Monocular Images#nuScenes Cars#ATE#0.61$3D Object Detection From Monocular Images#nuScenes Cars#ASE#0.15$3D Object Detection From Monocular Images#nuScenes Cars#AOE#0.08
1504.01106v5.pdf	Text Classification#TREC-6#Error#4
1909.09389v1.pdf	Text Classification#Amazon-5#Error#35.9$Text Classification#Yelp-5#Accuracy#67.6%$Text Classification#Yelp-2#Accuracy#97.1%$Text Classification#Sogou News#Accuracy#97$Text Classification#DBpedia#Error#0.8$Text Classification#AG News#Error#6.3$Text Classification#Amazon-2#Error#3.9$Text Classification#Yahoo! Answers#Accuracy#74.3
1901.06610v2.pdf	Text Classification#Yelp-5#Accuracy#73.28%$Text Classification#IMDb#Accuracy (2 classes)#95.17$Text Classification#IMDb#Accuracy (10 classes)#-
2103.05639v1.pdf	Text Classification#An Amharic News Text classification Dataset#Accuracy#62.3$Text Classification#An Amharic News Text classification Dataset#Accuracy#62.2
2105.05727v4.pdf	Text Classification#20NEWS#Accuracy#89.5$Text Classification#20 Newsgroups#Accuracy#89.5$Text Classification#R52#Accuracy#96.6$Text Classification#MR#Accuracy#89.7$Text Classification#R8#Accuracy#98.2$Text Classification#Ohsumed#Accuracy#72.8
1805.01890v2.pdf	Text Classification#20NEWS#Accuracy#87.91$Hierarchical Text Classification of Blurbs (GermEval 2019)#LOCAL DATASET#Accuracy (%)#90.79$Image Classification#MNIST#Percentage error#0.18$Image Classification#MNIST#Accuracy#99.82$Image Classification#CIFAR-10#Percentage correct#91.21$Unsupervised Pre-training#Measles#Accuracy (%)#0.1$Unsupervised Pre-training#UCI measles#Sensitivity#89.1$Unsupervised Pre-training#UCI measles#Sensitivity#0.8739$Unsupervised Pre-training#UCI measles#Sensitivity (VEB)#90.69
2105.13988v1.pdf	Text Classification#20NEWS#Accuracy#87.3$Text Classification#20NEWS#F-measure#86.6$Text Classification#20NEWS#Precision#87.1$Text Classification#20NEWS#Recall#86.6
1909.01259v2.pdf	Text Classification#20NEWS#Accuracy#86.8$Text Classification#20NEWS#F-measure#86.2$Text Classification#R8#Accuracy#97.1$Text Classification#R8#F-measure#91.7
1911.07918v1.pdf	Text Classification#20NEWS#Accuracy#86.19$Text Classification#20NEWS#F-measure#86.16$Text Classification#20NEWS#Precision#86.2$Text Classification#20NEWS#Recall#86.18$Document Classification#Reuters-21578#F1#82.71
1806.02960v1.pdf	Text Classification#20NEWS#Accuracy#84.5$Text Classification#20NEWS#F-measure#83.9$Text Classification#R8#Accuracy#96.7$Text Classification#R8#F-measure#91$Entity Typing#Freebase FIGER#Accuracy#37.4$Entity Typing#Freebase FIGER#BEP#94.8$Entity Typing#Freebase FIGER#Macro F1#84.2$Entity Typing#Freebase FIGER#Micro F1#85.7$Entity Typing#Freebase FIGER#P@1#93.2
2010.07956v1.pdf	Text Classification#20NEWS#Accuracy#81.88
1904.01962v2.pdf	Text Classification#20NEWS#Accuracy#76.18$Text Classification#Ohsumed#Accuracy#64.06$Document Classification#Reuters-21578#Accuracy#97.17$Document Classification#Twitter#Accuracy#72.6$Document Classification#BBCSport#Accuracy#95.73$Document Classification#Classic#Accuracy#96.24$Document Classification#Recipe#Accuracy#59.06$Document Classification#Amazon#Accuracy#94.31$Graph Classification#PROTEINS#Accuracy#70.74%$Graph Classification#MUTAG#Accuracy#86.33%$Graph Classification#IMDb-B#Accuracy#71.46%$Graph Classification#REDDIT-B#Accuracy#80.3$Graph Classification#IMDb-M#Accuracy#48.92%
1912.00509v2.pdf	Text Classification#20NEWS#Accuracy#74.78$Text Classification#Ohsumed#Accuracy#58.74$Document Classification#Reuters-21578#Accuracy#95.61$Document Classification#Twitter#Accuracy#71.05$Document Classification#BBCSport#Accuracy#95.18$Document Classification#Classic#Accuracy#96.85$Document Classification#Recipe#Accuracy#56.80$Document Classification#Amazon#Accuracy#93.03
2003.05019v1.pdf	Text Classification#20NEWS#Accuracy#70.28$Document Classification#Reuters-21578#Accuracy#92.65$Document Classification#Twitter#Accuracy#69.21$Document Classification#BBCSport#Accuracy#97.73$Document Classification#Amazon#Accuracy#93.42
2001.05493v2.pdf	Text Classification#Facebook Media#F1 (Hidden Test Set)#0.677$Text Classification#Twitter-US#F1 (Hidden Test Set)#0.648
1606.01781v2.pdf	Text Classification#DBpedia#Error#1.29$Text Classification#AG News#Error#8.67
1805.07745v6.pdf	Text Classification#DBpedia#Error#2.77$Text Classification#AG News#Error#9.64$Text Classification#Yahoo! Answers#Accuracy#55.39
1910.02356v2.pdf	Text Classification#R52#Accuracy#94.6$Text Classification#R8#Accuracy#97.8$Text Classification#Ohsumed#Accuracy#69.4
2009.11898v1.pdf	Text Classification#RusAge: Corpus for Age-Based Text Classification#F1#95.77
2109.12258v1.pdf	Text Classification#WeeBit (Readability Assessment)#Accuracy (5-fold)#0.905$Text Classification#OneStopEnglish (Readability Assessment)#Accuracy (5-fold)#0.990
1907.11779v3.pdf	Text Classification#WeeBit (Readability Assessment)#Accuracy (5-fold)#0.857$Text Classification#OneStopEnglish (Readability Assessment)#Accuracy (5-fold)#0.787
2006.00377v1.pdf	Text Classification#WeeBit (Readability Assessment)#Accuracy (5-fold)#0.838
1906.07580v1.pdf	Text Classification#WeeBit (Readability Assessment)#Accuracy (5-fold)#0.803
2010.04335v1.pdf	Text Classification#WNUT-2020 Task 2#F1#0.9096
2203.07450v1.pdf	Text Classification#OneStopEnglish (Readability Assessment)#Accuracy (5-fold)#0.979
1908.10419v1.pdf	Text Classification#RCV1#Macro F1#60.1$Text Classification#RCV1#Micro F1#83.3
2006.01222v1.pdf	Text Classification#AffCon 2020 Emotion Detection#F1 score#0.558
2012.15688v2.pdf	Text Classification#IMDb#Accuracy (2 classes)#97.1$Text Classification#IMDb#Accuracy (2 classes)#96.1
2011.08626v2.pdf	Text Classification#IMDb#Accuracy (2 classes)#96.6$Text Classification#IMDb#Accuracy (10 classes)#-
1504.01255v3.pdf	Text Classification#IMDb#Accuracy (2 classes)#90.01$Text Classification#IMDb#Accuracy (10 classes)#-
2103.05167v1.pdf	Text Classification#IMDb#Accuracy (2 classes)#-$Text Classification#IMDb#Accuracy (10 classes)#54.8$Document Classification#IMDb-M#Accuracy#54.8
1904.08398v3.pdf	Text Classification#IMDb#Accuracy (2 classes)#-$Text Classification#IMDb#Accuracy (10 classes)#53.7$Document Classification#Reuters-21578#F1#88.9$Document Classification#Yelp-14#Accuracy#69.4$Document Classification#AAPD#F1#72.9
2007.09536v1.pdf	Topic Models#arXiv#Topic coherence@5#0.0074$Topic Models#arXiv#MACC#83.24$Topic Models#NYT#Topic coherence@5#0.0166$Topic Models#NYT#MACC#90.91
1902.06034v3.pdf	Topic Models#arXiv#Topic Coherence@50#0.097
1908.07599v3.pdf	Topic Models#20 Newsgroups#Test perplexity#515
2012.06274v3.pdf	Topic coverage#Topic modeling topic coverage dataset - bio#SupCov#0.44$Topic coverage#Topic modeling topic coverage dataset - bio#AuCDC#0.67$Topic coverage#Topic modeling topic coverage dataset - bio#SupCov#0.23$Topic coverage#Topic modeling topic coverage dataset - bio#AuCDC#0.56$Topic coverage#Topic modeling topic coverage dataset#Spearman Correlation#0.95$Topic coverage#Topic modeling topic coverage dataset - news#SupCov#0.64$Topic coverage#Topic modeling topic coverage dataset - news#AuCDC#0.65$Topic coverage#Topic modeling topic coverage dataset - news#SupCov#0.54
1410.2455v3.pdf	Document Classification#Reuters De-En#Accuracy#75$Document Classification#Reuters En-De#Accuracy#86.5
1709.08267v2.pdf	Document Classification#WOS-11967#Accuracy#86.07$Document Classification#WOS-46985#Accuracy#76.58$Document Classification#WOS-5736#Accuracy#90.93
1808.03965v1.pdf	Document Classification#Cora#Accuracy#83.3%$Node Classification#Pubmed#Accuracy#79.5%$Node Classification#Cora#Accuracy#83.3%$Node Classification#PPI#F1#77.2$Node Classification#Citeseer#Accuracy#73.0 ± 0.6%
1611.08402v3.pdf	Document Classification#Cora#Accuracy#81.7%$Superpixel Image Classification#75 Superpixel MNIST#Classification Error#8.89$Graph Regression#ZINC-500k#MAE#0.292$Graph Regression#ZINC 100k#MAE#0.407$Graph Classification#CIFAR10 100k#Accuracy (%)#53.42$Node Classification#PATTERN 100k#Accuracy (%)#85.482
1603.08861v2.pdf	Document Classification#Cora#Accuracy#75.7%$Node Classification#Pubmed#Accuracy#77.2%$Node Classification#USA Air-Traffic#Accuracy#64.7$Node Classification#Cora#Accuracy#75.7%$Node Classification#Citeseer#Accuracy#64.7%$Node Classification#NELL#Accuracy#61.9%
1403.6652v2.pdf	Document Classification#Cora#Accuracy#67.2%$Node Classification#Wikipedia#Accuracy#19.4%$Node Classification#Wikipedia#Macro-F1#0.183$Node Classification#Eximtradedata#Accuracy#22.5%$Node Classification#Eximtradedata#Macro-F1#0.214$Link Property Prediction#ogbl-ppa#Test Hits@100#0.2302 ± 0.0163$Link Property Prediction#ogbl-ppa#Validation Hits@100#Please tell us$Link Property Prediction#ogbl-ppa#Number of params#150138741$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.2246 ± 0.0290$Link Property Prediction#ogbl-ddi#Validation Hits@20#Please tell us$Link Property Prediction#ogbl-ddi#Number of params#1543913$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.5037 ± 0.0034$Link Property Prediction#ogbl-collab#Validation Hits@50#Please tell us$Link Property Prediction#ogbl-collab#Number of params#61390187$Link Property Prediction#ogbl-collab#Ext. data#No
2010.06040v2.pdf	Sentence Classification#ACL-ARC#F1#78.1
1904.01608v2.pdf	Sentence Classification#ACL-ARC#F1#67.9$Sentence Classification#SciCite#F1#84$Citation Intent Classification#ACL-ARC#F1#67.9$Citation Intent Classification#SciCite#F1#84.0
1808.06161v1.pdf	Sentence Classification#PubMed 20k RCT#F1#92.60
2112.05267v1.pdf	Emotion Classification#MFA#F-F1 score (NA)#0.42$Emotion Classification#MFA#F-F1 score (Persian)#0.4$Emotion Classification#MFA#F-F1 score (Comb.)#0.34$Emotion Classification#MFA#V-F1 score (NA)#0.42$Emotion Classification#MFA#V-F1 score (Persian)#0.40$Emotion Classification#MFA#V-F1 score (Comb.)#0.39$Emotion Classification#MFA#F-F1 score (Persian)#0.28$Emotion Classification#MFA#F-F1 score (Comb.)#0.33$Emotion Classification#MFA#V-F1 score (NA)#0.4$Emotion Classification#MFA#V-F1 score (Persian)#0.33$Emotion Classification#MFA#V-F1 score (Comb.)#0.36
2101.10038v1.pdf	Emotion Classification#SemEval 2018 Task 1E-c#Macro-F1#0.578$Emotion Classification#SemEval 2018 Task 1E-c#Micro-F1#0.713$Emotion Classification#SemEval 2018 Task 1E-c#Accuracy#0.601
2008.09378v1.pdf	Emotion Classification#SemEval 2018 Task 1E-c#Macro-F1#0.563$Emotion Classification#SemEval 2018 Task 1E-c#Micro-F1#0.707$Emotion Classification#SemEval 2018 Task 1E-c#Accuracy#0.589
2006.05489v2.pdf	Emotion Classification#ROCStories#F1#65.88
1805.06533v1.pdf	Emotion Classification#ROCStories#F1#30.29
2005.00547v2.pdf	Emotion Classification#GoEmotions#Average F1#46
2003.01062v2.pdf	Emotion Classification#EWALK#Accuracy#82.4$Emotion Classification#EWALK#Accuracy#78.24$Emotion Classification#EWALK#Accuracy#55.47
1912.13025v1.pdf	Semi-Supervised Text Classification#AG News (200 Labels)#Accuracy (%)#82.1$Semi-Supervised Text Classification#AG News (200 Labels)#Accuracy (%)#80.2$Semi-Supervised Text Classification#AG News (200 Labels)#Accuracy (%)#77.5$Semi-Supervised Text Classification#Yahoo! Answers (800 Labels)#Accuracy (%)#57.9$Semi-Supervised Text Classification#Yahoo! Answers (800 Labels)#Accuracy (%)#56.3$Semi-Supervised Text Classification#Yahoo! Answers (800 Labels)#Accuracy (%)#55.7
2009.14463v1.pdf	Coherence Evaluation#GCDC + RST - F1#Average F1#46.98$Coherence Evaluation#GCDC + RST - F1#Average F1#44.30$Coherence Evaluation#GCDC + RST - Accuracy#Accuracy#55.39$Coherence Evaluation#GCDC + RST - Accuracy#Accuracy#53.04
1805.04993v1.pdf	Coherence Evaluation#GCDC + RST - F1#Average F1#46.65$Coherence Evaluation#GCDC + RST - Accuracy#Accuracy#55.09
2109.02176v2.pdf	Coherence Evaluation#GCDC + RST - Accuracy#Accuracy#61.0
2109.03094v1.pdf	Toxic Comment Classification#GermEval 2021 - Toxic Comments test set#F1#71.8
2210.06023v1.pdf	Unsupervised Text Classification#AG News#F1 score#82.7$Unsupervised Text Classification#20Newsgroup (10 tasks)#F1-score#75.1
2205.05448v2.pdf	Audio Generation#Symphony music#Human listening average results#3.5
2108.11637v1.pdf	Audio Super-Resolution#Voice Bank corpus (VCTK)#Log-Spectral Distance#2.3$Audio Super-Resolution#Piano#Log-Spectral Distance#1.5$Audio Super-Resolution#VCTK Multi-Speaker#Log-Spectral Distance#1.7
1909.06628v3.pdf	Audio Super-Resolution#Voice Bank corpus (VCTK)#Log-Spectral Distance#2.5$Audio Super-Resolution#Piano#Log-Spectral Distance#2
1708.00853v1.pdf	Audio Super-Resolution#Voice Bank corpus (VCTK)#Log-Spectral Distance#3.2$Audio Super-Resolution#Piano#Log-Spectral Distance#3.4$Audio Super-Resolution#VCTK Multi-Speaker#Log-Spectral Distance#3.1
2203.14941v1.pdf	Audio Super-Resolution#VCTK Multi-Speaker#Log-Spectral Distance#0.78
2110.13492v5.pdf	Audio Super-Resolution#VCTK Multi-Speaker#Log-Spectral Distance#1.28$Audio Super-Resolution#VCTK Multi-Speaker#Log-Spectral Distance#1.36
2011.07274v2.pdf	Audio Super-Resolution#DSD100#SNR#35.26
2205.10660v1.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#91.35%
2110.00199v2.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#91.02%$Image Classification#Tiny ImageNet Classification#Validation Acc#90.74%$Image Classification#CIFAR-100#Percentage correct#93.95%$Image Classification#CIFAR-10#Percentage correct#99.13%
1912.08136v2.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#84.39%
2111.15454v2.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#72.18%$Image Classification#Tiny ImageNet Classification#Validation Acc#68.89%$Image Classification#CIFAR-100#Percentage correct#85.50$Image Classification#CIFAR-100#Percentage correct#84.42$Image Classification#Places205#Top 1 Accuracy#64.3$Image Classification#iNaturalist 2018#Top-1 Accuracy#70.54%$Image Classification#iNaturalist 2018#Top-1 Accuracy#64.84%$Image Classification#ImageNet#Top 1 Accuracy#81.08%$Image Classification#ImageNet#Top 5 Accuracy#95.54%$Image Classification#ImageNet#Number of params#44.6M$Image Classification#ImageNet#Top 1 Accuracy#79.41%$Image Classification#ImageNet#Top 5 Accuracy#94.77%$Image Classification#ImageNet#Number of params#25.6M$Image Classification#ImageNet#Top 1 Accuracy#76.35%$Image Classification#ImageNet#Top 5 Accuracy#92.32%$Image Classification#ImageNet#Number of params#21.8M$Image Classification#ImageNet#Top 1 Accuracy#72.33%$Image Classification#ImageNet#Top 5 Accuracy#91.80%$Image Classification#ImageNet#Number of params#11.7M
2103.13027v6.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#70.72%$Image Classification#Tiny ImageNet Classification#Validation Acc#67.33%$Image Classification#CIFAR-100#Percentage correct#85.16$Image Classification#CIFAR-100#Percentage correct#83.64$Image Classification#Places205#Top 1 Accuracy#64.1$Image Classification#iNaturalist 2018#Top-1 Accuracy#70.49%$Image Classification#iNaturalist 2018#Top-1 Accuracy#64.73%$Image Classification#ImageNet#Top 1 Accuracy#80.98%$Image Classification#ImageNet#Top 5 Accuracy#95.51%$Image Classification#ImageNet#Number of params#44.6M$Image Classification#ImageNet#Top 1 Accuracy#79.25%$Image Classification#ImageNet#Top 5 Accuracy#94.65%$Image Classification#ImageNet#Number of params#25.6M$Image Classification#ImageNet#Top 1 Accuracy#76.1%$Image Classification#ImageNet#Top 5 Accuracy#92.4%$Image Classification#ImageNet#Number of params#21.8M$Image Classification#ImageNet#Top 1 Accuracy#72.05%$Image Classification#ImageNet#Top 5 Accuracy#91.75%$Image Classification#ImageNet#Number of params#11.7M
2103.06132v3.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#70.24%$Image Classification#CIFAR-100#Percentage correct#86.81$Image Classification#CIFAR-100#Percentage correct#85.77$Image Classification#CIFAR-10#Percentage correct#97.73$Image Classification#CIFAR-10#PARAMS#36.5M
2103.08640v2.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#67.67$Image Classification#CIFAR-100#Percentage correct#80.29$Image Classification#Tiny-ImageNet#Top 1 Accuracy#67.67$Image Classification#CIFAR-10#Percentage correct#96.47
1904.10429v2.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#60%
2201.10271v1.pdf	Image Classification#Tiny ImageNet Classification#Validation Acc#49.56$Image Classification#CIFAR-100#Percentage correct#60.11$Image Classification#CIFAR-10#Percentage correct#94.46$Image Classification#CIFAR-10#PARAMS#1.3M
2110.07402v4.pdf	Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.5$Image Classification#DTD#Accuracy#76.6$Image Classification#Food-101#Accuracy (%)#89.3$Fine-Grained Image Classification#SUN397#Accuracy#67.4$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#6.5%$Fine-Grained Image Classification#Caltech-101#Accuracy#93.5%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#92.8%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#75.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#88.2%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#67.2%$Unsupervised Image Classification#ImageNet#Accuracy (%)#40.6$Unsupervised Image Classification#ImageNet#ARI#30.0
2106.00116v3.pdf	Image Classification#Oxford-IIIT Pet Dataset#Accuracy#93.21$Image Classification#CIFAR-100#Percentage correct#88.54$Image Classification#Flowers-102#Accuracy#99.49$Image Classification#Flowers-102#Accuracy#98.21$Image Classification#CIFAR-10#Percentage correct#97.82$Image Classification#CIFAR-10#Percentage correct#95.78
2104.14548v2.pdf	Image Classification#Oxford-IIIT Pet Dataset#Accuracy#91.8$Image Classification#CIFAR-100#Percentage correct#79$Image Classification#DTD#Accuracy#75.5$Image Classification#PASCAL VOC 2007#Accuracy#83$Image Classification#Stanford Cars#Accuracy#67.1$Image Classification#Flowers-102#Accuracy#95.1$Image Classification#CIFAR-10#Percentage correct#93.7$Image Classification#Food-101#Accuracy (%)#76.7$Fine-Grained Image Classification#SUN397#Accuracy#62.5$Fine-Grained Image Classification#Birdsnap#Accuracy#61.4%$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#8.7%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#64.1%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#89.3%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#69.8%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#80.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#56.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.4
2206.07394v2.pdf	Image Classification#CIFAR-100#Percentage correct#96.808$Image Classification#Oxford 102 Flower#ACCURACY#99.847$Image Classification#Stanford Cars#Accuracy#96.808$Image Classification#Oxford-IIIT Pets#Accuracy#98.220$Image Classification#CINIC-10#Accuracy#95.064$Image Classification#CIFAR-10#Percentage correct#99.612$Image Classification#Food-101#Accuracy (%)#96.879
2010.01412v3.pdf	Image Classification#CIFAR-100#Percentage correct#96.08$Image Classification#CIFAR-100#Percentage correct#89.7$Image Classification#ImageNet#Top 1 Accuracy#88.61%$Image Classification#ImageNet#Number of params#480M$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#Top 5 Accuracy#95.65$Image Classification#SVHN#Percentage error#0.99$Image Classification#Fashion-MNIST#Percentage error#3.59$Image Classification#Fashion-MNIST#Accuracy#96.41$Image Classification#Flowers-102#Accuracy#99.65%$Image Classification#CIFAR-10#Percentage correct#98.6$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.96%$Fine-Grained Image Classification#Birdsnap#Accuracy#90.07%$Fine-Grained Image Classification#Food-101#Accuracy#96.18$Fine-Grained Image Classification#FGVC Aircraft#Top-1 Error Rate#4.82$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#2.90%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#97.10%
2205.12755v3.pdf	Image Classification#CIFAR-100#Percentage correct#94.95$Image Classification#ImageNet#Top 1 Accuracy#86.74%$Image Classification#DTD#Accuracy#81.0$Image Classification#KMNIST#Accuracy#98.68$Image Classification#EMNIST-Digits#Accuracy (%)#99.82$Image Classification#MNIST#Accuracy#99.75$Image Classification#EuroSAT#Accuracy (%)#99.2$Image Classification#EMNIST-Letters#Accuracy#93.68$Image Classification#CIFAR-10#Percentage correct#99.49$Fine-Grained Image Classification#SUN397#Accuracy#84.8$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#7%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#95.3%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.61%
2103.15808v1.pdf	Image Classification#CIFAR-100#Percentage correct#94.09$Image Classification#ImageNet#Top 1 Accuracy#84.9%$Image Classification#ImageNet#Number of params#32M$Image Classification#ImageNet#GFLOPs#25$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#GFLOPs#24.9$Image Classification#ImageNet#Top 1 Accuracy#83%$Image Classification#ImageNet#Number of params#20M$Image Classification#ImageNet#GFLOPs#16.3$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#GFLOPs#7.1$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#18M$Image Classification#ImageNet#GFLOPs#4.1$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#GFLOPs#4.5$Image Classification#ImageNet ReaL#Accuracy#90.6%$Image Classification#ImageNet ReaL#Params#277M$Image Classification#ImageNet ReaL#Top 1 Accuracy#87.7%$Image Classification#ImageNet ReaL#Number of params#277M$Image Classification#Oxford-IIIT Pets#Accuracy#94.73$Image Classification#Flowers-102#Accuracy#99.72$Image Classification#CIFAR-10#Percentage correct#99.39$Image Classification#CIFAR-10#Top-1 Accuracy#99.39
1912.11370v3.pdf	Image Classification#CIFAR-100#Percentage correct#93.51$Image Classification#CIFAR-100#Percentage correct#92.17$Image Classification#ImageNet#Top 1 Accuracy#87.54%$Image Classification#ImageNet#Top 5 Accuracy#98.46%$Image Classification#ImageNet#Top 1 Accuracy#85.39%$Image Classification#ImageNet#Top 5 Accuracy#97.69%$Image Classification#ImageNet#Number of params#928M$Image Classification#ImageNet ReaL#Accuracy#90.54%$Image Classification#ImageNet ReaL#Params#928M$Image Classification#ImageNet ReaL#Accuracy#89.02%$Image Classification#OmniBenchmark#Average Top-1 Accuracy#40.4$Image Classification#ObjectNet (Bounding Box)#Top 5 Accuracy#85.1$Image Classification#ObjectNet (Bounding Box)#Top 5 Accuracy#76.0$Image Classification#ObjectNet (Bounding Box)#Top 5 Accuracy#64.4$Image Classification#VTAB-1k#Top-1 Accuracy#78.72$Image Classification#VTAB-1k#Top-1 Accuracy#76.3$Image Classification#VTAB-1k#Top-1 Accuracy#70.6$Image Classification#VTAB-1k#Top-1 Accuracy#66.9$Image Classification#ObjectNet#Top-5 Accuracy#80$Image Classification#ObjectNet#Top-1 Accuracy#58.7$Image Classification#ObjectNet#Top-5 Accuracy#69$Image Classification#ObjectNet#Top-1 Accuracy#47.0$Image Classification#ObjectNet#Top-5 Accuracy#57$Image Classification#ObjectNet#Top-1 Accuracy#36.0$Image Classification#Flowers-102#Accuracy#99.63%$Image Classification#Flowers-102#Accuracy#99.30%$Image Classification#CIFAR-10#Percentage correct#99.37$Image Classification#CIFAR-10#Percentage correct#98.91$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#3.38%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#96.62%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#5.53%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.47%$Fine-Grained Image Classification#Oxford 102 Flowers#Top-1 Error Rate#0.37%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.63%$Fine-Grained Image Classification#Oxford 102 Flowers#Top-1 Error Rate#0.70%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.30%
2103.17239v2.pdf	Image Classification#CIFAR-100#Percentage correct#93.1$Image Classification#iNaturalist 2018#Top-1 Accuracy#78%$Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#Number of params#438M$Image Classification#ImageNet#GFLOPs#377.3$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#Number of params#271M$Image Classification#ImageNet#GFLOPs#247.8$Image Classification#ImageNet#Top 1 Accuracy#86.1%$Image Classification#ImageNet#Number of params#270.9M$Image Classification#ImageNet#GFLOPs#173.3$Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#185.9M$Image Classification#ImageNet#GFLOPs#116.1$Image Classification#ImageNet#Top 1 Accuracy#85.4%$Image Classification#ImageNet#Number of params#68.2M$Image Classification#ImageNet#GFLOPs#48$Image Classification#ImageNet#Top 1 Accuracy#85.3%$Image Classification#ImageNet#Number of params#89.5M$Image Classification#ImageNet#GFLOPs#63.8$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Number of params#46.9M$Image Classification#ImageNet#GFLOPs#32.2$Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Number of params#38.6M$Image Classification#ImageNet#GFLOPs#28.8$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Number of params#26.6M$Image Classification#ImageNet#GFLOPs#19.3$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#17.3M$Image Classification#ImageNet#GFLOPs#14.3$Image Classification#ImageNet#Top 1 Accuracy#80.9%$Image Classification#ImageNet#Number of params#12M$Image Classification#ImageNet#GFLOPs#9.6$Image Classification#iNaturalist 2019#Top-1 Accuracy#81.8$Image Classification#ImageNet ReaL#Accuracy#90.2%$Image Classification#Stanford Cars#Accuracy#94.2$Image Classification#ImageNet V2#Top 1 Accuracy#76.7$Image Classification#Flowers-102#Accuracy#99.1$Image Classification#CIFAR-10#Percentage correct#99.4
2203.09795v1.pdf	Image Classification#CIFAR-100#Percentage correct#93.0$Image Classification#iNaturalist 2018#Top-1 Accuracy#75.3%$Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet V2#Top 1 Accuracy#73.9$Image Classification#Flowers-102#Accuracy#98.5$Image Classification#CIFAR-10#Percentage correct#99.3$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.8%
2003.13630v3.pdf	Image Classification#CIFAR-100#Percentage correct#92.6$Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Number of params#77M$Image Classification#Flowers-102#Accuracy#99.1%$Image Classification#CIFAR-10#Percentage correct#99$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.1%
2104.00298v3.pdf	Image Classification#CIFAR-100#Percentage correct#92.3$Image Classification#CIFAR-100#Percentage correct#92.2$Image Classification#CIFAR-100#Percentage correct#91.5$Image Classification#ImageNet#Top 1 Accuracy#86.8%$Image Classification#ImageNet#Number of params#121M$Image Classification#ImageNet#GFLOPs#53$Image Classification#ImageNet#Top 1 Accuracy#86.1%$Image Classification#ImageNet#Number of params#55M$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Top 1 Accuracy#85.0%$Image Classification#ImageNet#Top 1 Accuracy#83.9%$Image Classification#ImageNet#Number of params#24M$Image Classification#ImageNet#GFLOPs#8.8$Image Classification#Stanford Cars#Accuracy#95.1$Image Classification#Stanford Cars#Accuracy#94.6$Image Classification#Stanford Cars#Accuracy#93.8$Image Classification#Flowers-102#Accuracy#98.8$Image Classification#Flowers-102#Accuracy#98.5$Image Classification#Flowers-102#Accuracy#97.9$Image Classification#CIFAR-10#Percentage correct#99.1$Image Classification#CIFAR-10#PARAMS#121M$Image Classification#CIFAR-10#Top-1 Accuracy#99.1$Image Classification#CIFAR-10#Parameters#121M$Image Classification#CIFAR-10#Percentage correct#99.0$Image Classification#CIFAR-10#PARAMS#55M$Image Classification#CIFAR-10#Top-1 Accuracy#99.0$Image Classification#CIFAR-10#Parameters#55M$Image Classification#CIFAR-10#Percentage correct#98.7$Image Classification#CIFAR-10#PARAMS#24M$Image Classification#CIFAR-10#Top-1 Accuracy#98.7$Image Classification#CIFAR-10#Parameters#24M
2103.11816v2.pdf	Image Classification#CIFAR-100#Percentage correct#91.8$Image Classification#CIFAR-100#Percentage correct#89.4$Image Classification#CIFAR-100#Percentage correct#88$Image Classification#iNaturalist 2018#Top-1 Accuracy#79.4%$Image Classification#iNaturalist 2018#Top-1 Accuracy#73.3%$Image Classification#iNaturalist 2018#Top-1 Accuracy#72.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#64.3%$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Top 5 Accuracy#96.5$Image Classification#ImageNet#Number of params#24.2M$Image Classification#ImageNet#GFLOPs#12.9$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Top 5 Accuracy#95.9$Image Classification#ImageNet#GFLOPs#4.5$Image Classification#ImageNet#Top 1 Accuracy#78.8%$Image Classification#ImageNet#GFLOPs#3.6$Image Classification#ImageNet#Top 1 Accuracy#76.4%$Image Classification#ImageNet#Top 5 Accuracy#93.4$Image Classification#ImageNet#Number of params#6.4M$Image Classification#ImageNet#GFLOPs#1.2$Image Classification#iNaturalist 2019#Top-1 Accuracy#82.7$Image Classification#iNaturalist 2019#Top-1 Accuracy#78.9$Image Classification#iNaturalist 2019#Top-1 Accuracy#77.9$Image Classification#iNaturalist 2019#Top-1 Accuracy#72.8$Image Classification#ImageNet ReaL#Accuracy#88.1%$Image Classification#ImageNet ReaL#Accuracy#87.3%$Image Classification#ImageNet ReaL#Accuracy#83.6%$Image Classification#Stanford Cars#Accuracy#94.1$Image Classification#Stanford Cars#Accuracy#93.2$Image Classification#Stanford Cars#Accuracy#93$Image Classification#Stanford Cars#Accuracy#90.5$Image Classification#Oxford-IIIT Pets#Accuracy#94.9$Image Classification#Oxford-IIIT Pets#Accuracy#94.6$Image Classification#Oxford-IIIT Pets#Accuracy#94.5$Image Classification#Oxford-IIIT Pets#Accuracy#93.8$Image Classification#Flowers-102#Accuracy#98.6$Image Classification#Flowers-102#Accuracy#98.2$Image Classification#Flowers-102#Accuracy#97.8$Image Classification#Flowers-102#Accuracy#96.9$Image Classification#CIFAR-10#Percentage correct#99.1$Image Classification#CIFAR-10#Top-1 Accuracy#99.1$Image Classification#CIFAR-10#Percentage correct#99$Image Classification#CIFAR-10#Top-1 Accuracy#99$Image Classification#CIFAR-10#Percentage correct#98.5$Image Classification#CIFAR-10#Top-1 Accuracy#98.5
1905.11946v5.pdf	Image Classification#CIFAR-100#Percentage correct#91.7$Image Classification#CIFAR-100#PARAMS#64M$Image Classification#ImageNet#Top 1 Accuracy#84.4%$Image Classification#ImageNet#Top 5 Accuracy#97.1$Image Classification#ImageNet#Number of params#66M$Image Classification#ImageNet#GFLOPs#37$Image Classification#ImageNet#Top 1 Accuracy#84%$Image Classification#ImageNet#Top 5 Accuracy#96.9$Image Classification#ImageNet#Number of params#43M$Image Classification#ImageNet#GFLOPs#19$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Top 5 Accuracy#96.7$Image Classification#ImageNet#Number of params#30M$Image Classification#ImageNet#GFLOPs#9.9$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Top 5 Accuracy#96.3$Image Classification#ImageNet#Number of params#19M$Image Classification#ImageNet#GFLOPs#4.2$Image Classification#ImageNet#Top 1 Accuracy#81.1%$Image Classification#ImageNet#Top 5 Accuracy#95.5$Image Classification#ImageNet#Number of params#12M$Image Classification#ImageNet#Top 1 Accuracy#79.8%$Image Classification#ImageNet#Top 5 Accuracy#94.9$Image Classification#ImageNet#Number of params#9.2M$Image Classification#ImageNet#GFLOPs#1$Image Classification#ImageNet#Top 1 Accuracy#78.8%$Image Classification#ImageNet#Top 5 Accuracy#94.4$Image Classification#ImageNet#Number of params#7.8M$Image Classification#ImageNet#GFLOPs#0.7$Image Classification#ImageNet#Top 1 Accuracy#76.3%$Image Classification#ImageNet#Top 5 Accuracy#93.2$Image Classification#ImageNet#Number of params#5.3M$Image Classification#ImageNet#GFLOPs#0.39$Image Classification#OmniBenchmark#Average Top-1 Accuracy#35.8$Image Classification#GasHisSDB#Accuracy#98.11$Image Classification#GasHisSDB#Precision#99.94$Image Classification#GasHisSDB#F1-Score#99.01$Image Classification#Flowers-102#Accuracy#98.8%$Image Classification#CIFAR-10#Percentage correct#98.9$Image Classification#CIFAR-10#PARAMS#64M$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.7%$Fine-Grained Image Classification#Birdsnap#Accuracy#84.3%$Fine-Grained Image Classification#Food-101#Accuracy#93.0$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.9$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#95.4%$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#95.59$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#97.48$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.89$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.45
1811.06965v5.pdf	Image Classification#CIFAR-100#Percentage correct#91.3$Image Classification#ImageNet#Top 1 Accuracy#84.4%$Image Classification#ImageNet#Top 5 Accuracy#97%$Image Classification#CIFAR-10#Percentage correct#99$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.6%$Fine-Grained Image Classification#Birdsnap#Accuracy#83.6%
2107.00651v1.pdf	Image Classification#CIFAR-100#Percentage correct#91.1$Image Classification#CIFAR-100#PARAMS#23M$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Number of params#54M$Image Classification#ImageNet#GFLOPs#11$Image Classification#ImageNet#Top 1 Accuracy#81.7%$Image Classification#ImageNet#Top 5 Accuracy#95.7$Image Classification#ImageNet#Number of params#22.9M$Image Classification#ImageNet#GFLOPs#5.1$Image Classification#ImageNet#Top 1 Accuracy#74.7%$Image Classification#ImageNet#Top 5 Accuracy#92.6$Image Classification#ImageNet#Number of params#5.7M$Image Classification#ImageNet#GFLOPs#1.3$Image Classification#CIFAR-10#Percentage correct#99.1$Image Classification#CIFAR-10#PARAMS#23M$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.4%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.9%$Fine-Grained Image Classification#Oxford 102 Flowers#Top 1 Accuracy#98.8
2103.00112v3.pdf	Image Classification#CIFAR-100#Percentage correct#91.1$Image Classification#CIFAR-100#PARAMS#65.6M$Image Classification#ImageNet#Top 1 Accuracy#83.9%$Image Classification#ImageNet#Number of params#65.6M$Image Classification#CIFAR-10#Percentage correct#99.1$Image Classification#CIFAR-10#PARAMS#65.6M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#95.0%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#65.6M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.0%$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#65.6M
2007.15161v3.pdf	Image Classification#CIFAR-100#Percentage correct#90.27$Image Classification#SVHN#Percentage error#1.0$Image Classification#Surrey ASL#Accuracy (%)#94.90$Image Classification#iCassava'19#Top-1 Accuracy#0.9368$Image Classification#Fashion-MNIST#Percentage error#4.08$Image Classification#CIFAR-10#Percentage correct#98.52$Image Classification#CIFAR-10#PARAMS#20M
2203.07845v2.pdf	Image Classification#CIFAR-100#Percentage correct#90.2$Image Classification#DTD#Accuracy#81.9$Image Classification#OmniBenchmark#Average Top-1 Accuracy#45.4$Image Classification#ObjectNet#Top-1 Accuracy#53.9$Image Classification#ObjectNet#Top-1 Accuracy#38.8$Image Classification#Flowers-102#Accuracy#99.7$Image Classification#CIFAR-10#Percentage correct#98.2$Image Classification#Food-101#Accuracy (%)#92.9$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.9%$Fine-Grained Image Classification#SUN397#Accuracy#79.5$Fine-Grained Image Classification#Caltech-101#Accuracy#94.8$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#95.1%
2102.11600v3.pdf	Image Classification#CIFAR-100#Percentage correct#89.90$Image Classification#CIFAR-10#Percentage correct#98.68$Image Classification#CIFAR-10#PARAMS#26M
2105.15075v2.pdf	Image Classification#CIFAR-100#Percentage correct#89.63$Image Classification#ImageNet#Top 1 Accuracy#80.43%$Image Classification#ImageNet#GFLOPs#1.7$Image Classification#ImageNet#Top 1 Accuracy#79.74%$Image Classification#ImageNet#GFLOPs#0.7$Image Classification#ImageNet#Top 1 Accuracy#78.48%$Image Classification#ImageNet#GFLOPs#0.6$Image Classification#CIFAR-10#Percentage correct#98.53
2011.14660v4.pdf	Image Classification#CIFAR-100#Percentage correct#89.46$Image Classification#CIFAR-100#PARAMS#32.8$Image Classification#CIFAR-100#Percentage correct#87.44$Image Classification#CIFAR-100#PARAMS#26.3$Image Classification#CIFAR-100#Percentage correct#86.90$Image Classification#CIFAR-100#Percentage correct#85.74$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Top 5 Accuracy#96.69%$Image Classification#ImageNet#Number of params#98M$Image Classification#ImageNet#GFLOPs#38.2$Image Classification#ImageNet#Top 1 Accuracy#83.34%$Image Classification#ImageNet#Top 5 Accuracy#96.61%$Image Classification#ImageNet#GFLOPs#61.1$Image Classification#ImageNet#Top 1 Accuracy#82.13%$Image Classification#ImageNet#Top 5 Accuracy#95.98%$Image Classification#ImageNet#Number of params#88.6M$Image Classification#ImageNet#GFLOPs#18.8$Image Classification#CIFAR-10#Percentage correct#98.71$Image Classification#CIFAR-10#PARAMS#32.6M$Image Classification#CIFAR-10#Percentage correct#98.38$Image Classification#CIFAR-10#PARAMS#55.9M$Image Classification#CIFAR-10#Percentage correct#98.32$Image Classification#CIFAR-10#PARAMS#36.7M$Image Classification#CIFAR-10#Percentage correct#98.31$Image Classification#CIFAR-10#PARAMS#26.3M
1902.00267v1.pdf	Image Classification#CIFAR-100#Percentage correct#88.4$Image Classification#CIFAR-100#PARAMS#19.0M$Image Classification#ImageNet#Top 1 Accuracy#84.32%$Image Classification#ImageNet#Top 1 Accuracy#82.35%$Image Classification#ImageNet#Top 5 Accuracy#94.78$Image Classification#SVHN#Percentage error#1.11
2110.00476v1.pdf	Image Classification#CIFAR-100#Percentage correct#86.9$Image Classification#CIFAR-100#PARAMS#25M$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Number of params#60.2M$Image Classification#ImageNet#Top 1 Accuracy#81.8%$Image Classification#ImageNet#Top 1 Accuracy#80.4%$Image Classification#ImageNet#Number of params#22M$Image Classification#ImageNet#Number of params#25M$Image Classification#ImageNet#Top 1 Accuracy#78.1%$Image Classification#iNaturalist 2019#Top-1 Accuracy#75.0$Image Classification#ImageNet ReaL#Accuracy#85.7%$Image Classification#ImageNet ReaL#Params#25M$Image Classification#ImageNet V2#Top 1 Accuracy#68.7$Image Classification#Flowers-102#Accuracy#97.9$Image Classification#Flowers-102#FLOPS#4.1$Image Classification#Flowers-102#PARAMS#25M$Image Classification#CIFAR-10#Percentage correct#98.3$Image Classification#CIFAR-10#PARAMS#25M$Image Classification#CIFAR-10#Percentage correct#85.28$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.7%$Fine-Grained Image Classification#Stanford Cars#FLOPS#4.1B$Fine-Grained Image Classification#Stanford Cars#PARAMS#24M$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#97.9%$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#4.1$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#24M$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#95.46$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#97.46$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.91$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.43
2010.04925v4.pdf	Image Classification#CIFAR-100#Percentage correct#86.64$Image Classification#CIFAR-100#Percentage correct#78.49$Image Classification#SVHN#Percentage error#1.35$Image Classification#SVHN#Percentage error#2.30$Image Classification#CIFAR-10#Percentage correct#98.02$Image Classification#CIFAR-10#PARAMS#27.22M$Image Classification#CIFAR-10#Percentage correct#96.03
2205.09615v3.pdf	Image Classification#CIFAR-100#Percentage correct#85.6$Image Classification#SVHN#Percentage correct#97.88$Image Classification#MNIST#Percentage correct#99.66$Image Classification#CIFAR-10#Percentage correct#97.14
1903.06236v1.pdf	Image Classification#CIFAR-100#Percentage correct#85.42
2007.12927v4.pdf	Image Classification#CIFAR-100#Percentage correct#85.00$Image Classification#CIFAR-100#Percentage correct#83.06$Image Classification#CIFAR-10#Percentage correct#97.45$Image Classification#CIFAR-10#PARAMS#36.5M$Image Classification#CIFAR-10#Percentage correct#96.81
2209.15031v1.pdf	Image Classification#CIFAR-100#Percentage correct#84.89$Image Classification#CIFAR-100#Percentage correct#81.19$Image Classification#SVHN#Percentage correct#98.15$Image Classification#CIFAR-10#Percentage correct#97.85$Image Classification#CIFAR-10#Percentage correct#97.05
1709.01507v4.pdf	Image Classification#CIFAR-100#Percentage correct#84.59$Image Classification#CIFAR-10#Percentage correct#97.88
2008.05367v3.pdf	Image Classification#CIFAR-100#Percentage correct#84.38$Image Classification#CIFAR-100#Percentage correct#82.95$Image Classification#CIFAR-100#Percentage correct#80.14$Image Classification#CIFAR-100#Percentage correct#76.55$Image Classification#CIFAR-100#Percentage correct#74.14$Image Classification#CIFAR-10#Percentage correct#97.42$Image Classification#CIFAR-10#PARAMS#36.5M$Image Classification#CIFAR-10#Percentage correct#96.87$Image Classification#CIFAR-10#Percentage correct#96.12$Image Classification#CIFAR-10#Percentage correct#95.35$Image Classification#CIFAR-10#Percentage correct#94.62
1803.05407v3.pdf	Image Classification#CIFAR-100#Percentage correct#84.16$Image Classification#CIFAR-100#Percentage correct#82.15$Image Classification#ImageNet#Top 1 Accuracy#78.94%$Image Classification#ImageNet#Top 1 Accuracy#78.44%$Image Classification#CIFAR-10#Percentage correct#97.12$Image Classification#CIFAR-10#Percentage correct#96.79
2009.06962v2.pdf	Image Classification#CIFAR-100#Percentage correct#84.05$Image Classification#ImageNet#Top 1 Accuracy#78.76%$Image Classification#Tiny-ImageNet#Top 1 Accuracy#63.48
1908.09699v3.pdf	Image Classification#CIFAR-100#Percentage correct#84.04$Image Classification#CIFAR-100#PARAMS#11.4M$Image Classification#CIFAR-100#Percentage correct#83.46$Image Classification#CIFAR-100#PARAMS#3.1M$Image Classification#CIFAR-100#Percentage correct#81.87$Image Classification#CIFAR-100#PARAMS#1.1M$Image Classification#ImageNet#Top 1 Accuracy#80.5%$Image Classification#ImageNet#Top 5 Accuracy#95.2$Image Classification#ImageNet#Number of params#42.2M$Image Classification#ImageNet#GFLOPs#7.1$Image Classification#ImageNet#Top 1 Accuracy#78.5%$Image Classification#ImageNet#Top 5 Accuracy#94.2$Image Classification#ImageNet#Number of params#12.9M$Image Classification#ImageNet#GFLOPs#2.0$Image Classification#CIFAR-10#Percentage correct#97.86$Image Classification#CIFAR-10#PARAMS#11.4M$Image Classification#CIFAR-10#Percentage correct#97.71$Image Classification#CIFAR-10#PARAMS#3.1M$Image Classification#CIFAR-10#Percentage correct#96.85$Image Classification#CIFAR-10#PARAMS#1.1M
2002.12047v3.pdf	Image Classification#CIFAR-100#Percentage correct#83.95$Image Classification#Fashion-MNIST#Percentage error#3.64$Image Classification#CIFAR-10#Percentage correct#98.64$Image Classification#CIFAR-10#PARAMS#26.21M
1701.01833v2.pdf	Image Classification#CIFAR-100#Percentage correct#83.85$Image Classification#CIFAR-10#Percentage correct#97.02
2011.12982v1.pdf	Image Classification#CIFAR-100#Percentage correct#83.7$Image Classification#iNaturalist 2018#Top-1 Accuracy#81.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#69.8%$Image Classification#ImageNet#Top 1 Accuracy#79.6%$Image Classification#iNaturalist 2019#Top-1 Accuracy#84.1$Image Classification#Flowers-102#Accuracy#99.1%$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.7%$Fine-Grained Image Classification#Food-101#Accuracy#93.7$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.1%
2101.03057v1.pdf	Image Classification#CIFAR-100#Percentage correct#83.2$Image Classification#ImageNet#Top 1 Accuracy#77.0%
1911.09265v2.pdf	Image Classification#CIFAR-100#Percentage correct#83.13$Image Classification#SVHN#Percentage error#2.22$Image Classification#STL-10#Percentage correct#95.48$Image Classification#CIFAR-10#Percentage correct#98.01$Image Classification#CIFAR-10#PARAMS#36.5M$Image Classification#CIFAR-10#Top-1 Accuracy#98.01$Image Classification#CIFAR-10#Parameters#36.5M$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#91.96$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#97.58$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.18$Semi-Supervised Image Classification#CIFAR-100, 5000Labels#Percentage correct#68.17$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#96.79$Semi-Supervised Image Classification#cifar10, 250 Labels#Percentage correct#92.4$Semi-Supervised Image Classification#CIFAR-100, 1000 Labels#Percentage correct#41.27$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#22.92$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#26.93±0.21$Semi-Supervised Image Classification#STL-10#Accuracy#95.48
1907.06916v2.pdf	Image Classification#CIFAR-100#Percentage correct#82.95$Image Classification#CIFAR-10#Percentage correct#96.71
2104.05704v4.pdf	Image Classification#CIFAR-100#Percentage correct#82.72$Image Classification#CIFAR-100#Percentage correct#77.31$Image Classification#CIFAR-100#PARAMS#3.17M$Image Classification#ImageNet#Top 1 Accuracy#82.71%$Image Classification#ImageNet#Top 1 Accuracy#81.34%$Image Classification#ImageNet#Number of params#22.36M$Image Classification#ImageNet#GFLOPs#11.06$Image Classification#ImageNet#Top 1 Accuracy#80.28%$Image Classification#Flowers-102#Accuracy#99.76$Image Classification#CIFAR-10#Percentage correct#98$Image Classification#CIFAR-10#PARAMS#3.76M$Image Classification#CIFAR-10#Percentage correct#95.29$Image Classification#CIFAR-10#PARAMS#3.17M$Fine-Grained Image Classification#Oxford 102 Flowers#FLOPS#15G$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#22.5M
1903.06586v2.pdf	Image Classification#CIFAR-100#Percentage correct#82.67$Image Classification#ImageNet#Top 1 Accuracy#79.81%$Image Classification#ImageNet#Number of params#48.9M$Image Classification#ImageNet#GFLOPs#8.46$Image Classification#CIFAR-10#Percentage correct#96.53$Image Classification#CIFAR-10#Top-1 Accuracy#96.53
2105.12723v4.pdf	Image Classification#CIFAR-100#Percentage correct#82.56$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Number of params#68M$Image Classification#ImageNet#GFLOPs#17.9$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#38M$Image Classification#ImageNet#GFLOPs#10.4$Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#Number of params#17M$Image Classification#ImageNet#GFLOPs#5.8$Image Classification#CIFAR-10#Percentage correct#97.2$Image Classification#CIFAR-10#PARAMS#90.1M$Image Classification#CIFAR-10#Top-1 Accuracy#97.2$Image Classification#CIFAR-10#Parameters#90.1M
1807.07320v2.pdf	Image Classification#CIFAR-100#Percentage correct#82.18
1806.05236v7.pdf	Image Classification#CIFAR-100#Percentage correct#81.96$Image Classification#OmniBenchmark#Average Top-1 Accuracy#31.6$Image Classification#CIFAR-10#Percentage correct#97.45$Image Classification#CIFAR-10#PARAMS#36.5M
1611.01260v2.pdf	Image Classification#CIFAR-100#Percentage correct#81.73$Image Classification#CIFAR-10#Percentage correct#96.35
2007.10408v2.pdf	Image Classification#CIFAR-100#Percentage correct#81.6$Image Classification#CIFAR-100#Percentage correct#79.99$Image Classification#CIFAR-100#Percentage correct#73$Image Classification#CIFAR-100#Percentage correct#72.87$Image Classification#MNIST-rot-12k (DA)#Test Error#0.709$Image Classification#MNIST-rot-12#Test Error#1.87$Image Classification#CIFAR-10#Percentage correct#96.5$Image Classification#CIFAR-10#Percentage correct#96.32$Image Classification#CIFAR-10#Percentage correct#94.62$Image Classification#CIFAR-10#Percentage correct#94.35
1605.07146v4.pdf	Image Classification#CIFAR-100#Percentage correct#81.15$Image Classification#ImageNet#Top 1 Accuracy#78.1%$Image Classification#ImageNet#Top 5 Accuracy#93.97%$Image Classification#ImageNet#Number of params#68.9M$Image Classification#SVHN#Percentage error#1.54$Image Classification#SVHN#Percentage error#1.7$Image Classification#CIFAR-10#Percentage correct#96.11
1709.10282v1.pdf	Image Classification#CIFAR-100#Percentage correct#81.10$Image Classification#SVHN#Percentage error#1.58$Image Classification#CIFAR-10#Percentage correct#96.62
1802.06205v1.pdf	Image Classification#CIFAR-100#Percentage correct#80.29$Image Classification#CIFAR-10#Percentage correct#96.29
1901.06656v2.pdf	Image Classification#CIFAR-100#Percentage correct#79.9$Image Classification#Kuzushiji-MNIST#Accuracy#99.01$Image Classification#Kuzushiji-MNIST#Error#0.99$Image Classification#SVHN#Percentage error#1.65$Image Classification#STL-10#Percentage correct#80.75$Image Classification#MNIST#Percentage error#0.26$Image Classification#Fashion-MNIST#Percentage error#4.14$Image Classification#CIFAR-10#Percentage correct#96.4
1608.06037v7.pdf	Image Classification#CIFAR-100#Percentage correct#78.37$Image Classification#MNIST#Percentage error#0.25$Image Classification#CIFAR-10#Percentage correct#95.51
2003.13549v3.pdf	Image Classification#CIFAR-100#Percentage correct#77.7$Fine-Grained Image Classification#Stanford Dogs#Accuracy#61.2%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#54.7%
1603.05027v3.pdf	Image Classification#CIFAR-100#Percentage correct#77.3$Image Classification#ImageNet#Top 1 Accuracy#79.9%$Image Classification#ImageNet#Top 5 Accuracy#95.2%$Image Classification#Kuzushiji-MNIST#Accuracy#97.82$Image Classification#CIFAR-10#Percentage correct#95.4
1703.01041v2.pdf	Image Classification#CIFAR-100#Percentage correct#77$Image Classification#CIFAR-10#Percentage correct#95.6$Image Classification#CIFAR-10#Percentage correct#94.6
1905.10671v2.pdf	Image Classification#CIFAR-100#Percentage correct#76.98
2012.02818v2.pdf	Image Classification#CIFAR-100#Percentage correct#76.85$Image Classification#CIFAR-10#Percentage correct#95.02
2011.10951v2.pdf	Image Classification#CIFAR-100#Percentage correct#76.64$Image Classification#STL-10#Percentage correct#85.42$Image Classification#CIFAR-10#Percentage correct#95.33$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.5$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.2%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#94.0 %
2102.07870v3.pdf	Image Classification#CIFAR-100#Percentage correct#76.38 ± 0.42$Image Classification#CIFAR-10#Percentage correct#95.18 ± 0.06
1409.6070v1.pdf	Image Classification#CIFAR-100#Percentage correct#75.7$Image Classification#CIFAR-10#Percentage correct#93.7
1511.07289v5.pdf	Image Classification#CIFAR-100#Percentage correct#75.7$Image Classification#CIFAR-10#Percentage correct#93.5
2203.15331v2.pdf	Image Classification#CIFAR-100#Percentage correct#75.59$Image Classification#Kuzushiji-MNIST#Accuracy#98.75$Image Classification#MNIST#Accuracy#99.68$Image Classification#Fashion-MNIST#Percentage error#5.56$Image Classification#Fashion-MNIST#Accuracy#94.44$Image Classification#CIFAR-10#Percentage correct#94.79
1603.09382v3.pdf	Image Classification#CIFAR-100#Percentage correct#75.42$Image Classification#SVHN#Percentage error#1.75$Image Classification#CIFAR-10#Percentage correct#94.77
1908.08681v3.pdf	Image Classification#CIFAR-100#Percentage correct#74.41$Image Classification#ImageNet#Top 1 Accuracy#79.8%$Image Classification#ImageNet#Top 5 Accuracy#95.2%$Image Classification#CIFAR-10#Percentage correct#94.05$Image Classification#CIFAR-10#Percentage correct#92.02
1905.02249v2.pdf	Image Classification#CIFAR-100#Percentage correct#74.1$Image Classification#SVHN#Percentage error#2.59$Image Classification#STL-10#Percentage correct#94.41$Image Classification#STL-10#Percentage correct#88.80$Image Classification#STL-10#Percentage correct#87.36$Image Classification#CIFAR-10#Percentage correct#95.05$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#89.82$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.73$Semi-Supervised Image Classification#CIFAR-10, 2000 Labels#Accuracy#92.97$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#96.36$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.24$Semi-Supervised Image Classification#CIFAR-10, 500 Labels#Accuracy#91.35$Semi-Supervised Image Classification#SVHN, 2000 Labels#Accuracy#96.96$Semi-Supervised Image Classification#STL-10, 5000 Labels#Accuracy#94.41$Semi-Supervised Image Classification#SVHN, 4000 Labels#Accuracy#97.11$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#96.22$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#11.08$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#92.25
1412.6071v4.pdf	Image Classification#CIFAR-100#Percentage correct#73.6$Image Classification#MNIST#Percentage error#0.3$Image Classification#CIFAR-10#Percentage correct#96.5
1604.04112v4.pdf	Image Classification#CIFAR-100#Percentage correct#73.5$Image Classification#CIFAR-10#Percentage correct#94.4
2001.08856v1.pdf	Image Classification#CIFAR-100#Percentage correct#72.96$Image Classification#CIFAR-100#PARAMS#4,252,298$Image Classification#SVHN#Percentage error#1.50$Image Classification#STL-10#Percentage correct#88.08$Image Classification#MNIST#Percentage error#0.17$Image Classification#MNIST#Accuracy#99.83$Image Classification#MNIST#Trainable Parameters#1,400,000$Image Classification#CIFAR-10#Percentage correct#94.29$Image Classification#CIFAR-10#PARAMS#4.3M
1502.05700v2.pdf	Image Classification#CIFAR-100#Percentage correct#72.6$Image Classification#CIFAR-10#Percentage correct#93.6
1511.05635v1.pdf	Image Classification#CIFAR-100#Percentage correct#72.4$Image Classification#SVHN#Percentage error#1.8$Image Classification#MNIST#Percentage error#0.3$Image Classification#CIFAR-10#Percentage correct#93.1
1511.06422v7.pdf	Image Classification#CIFAR-100#Percentage correct#72.3$Image Classification#MNIST#Percentage error#0.4$Image Classification#CIFAR-10#Percentage correct#94.2
1511.02583v1.pdf	Image Classification#CIFAR-100#Percentage correct#71.1$Image Classification#SVHN#Percentage error#1.8$Image Classification#MNIST#Percentage error#0.24$Image Classification#CIFAR-10#Percentage correct#93.3
1508.00330v2.pdf	Image Classification#CIFAR-100#Percentage correct#70.8$Image Classification#SVHN#Percentage error#2.0$Image Classification#MNIST#Percentage error#0.4$Image Classification#CIFAR-10#Percentage correct#91.5
1412.6830v3.pdf	Image Classification#CIFAR-100#Percentage correct#69.2$Image Classification#CIFAR-10#Percentage correct#92.5
1506.02351v8.pdf	Image Classification#CIFAR-100#Percentage correct#69.1$Image Classification#STL-10#Percentage correct#74.3$Image Classification#MNIST#Percentage error#4.76$Image Classification#CIFAR-10#Percentage correct#92.2$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#74.30
1706.02003v2.pdf	Image Classification#CIFAR-100#Percentage correct#69
1506.03767v1.pdf	Image Classification#CIFAR-100#Percentage correct#68.4$Image Classification#CIFAR-10#Percentage correct#91.4
2104.08215v1.pdf	Image Classification#CIFAR-100#Percentage correct#68.34$Image Classification#ImageNet#Top 1 Accuracy#68.0%$Image Classification#CIFAR-10#Percentage correct#92.08
1507.06228v2.pdf	Image Classification#CIFAR-100#Percentage correct#67.8$Image Classification#MNIST#Percentage error#0.5$Image Classification#CIFAR-10#Percentage correct#92.4
1710.02286v1.pdf	Image Classification#CIFAR-100#Percentage correct#67.7$Image Classification#MNIST#Percentage error#0.5$Image Classification#CIFAR-10#Percentage correct#89.1
1509.08985v2.pdf	Image Classification#CIFAR-100#Percentage correct#67.6$Image Classification#SVHN#Percentage error#1.7$Image Classification#MNIST#Percentage error#0.3$Image Classification#CIFAR-10#Percentage correct#94.0
1410.0736v4.pdf	Image Classification#CIFAR-100#Percentage correct#67.4
1511.03719v7.pdf	Image Classification#CIFAR-100#Percentage correct#67.2$Image Classification#CIFAR-10#Percentage correct#93.3
1412.6806v3.pdf	Image Classification#CIFAR-100#Percentage correct#66.3$Image Classification#CIFAR-10#Percentage correct#95.6
2210.16914v1.pdf	Image Classification#CIFAR-100#Percentage correct#66$Image Classification#CIFAR-100#Percentage correct#60
1409.5185v2.pdf	Image Classification#CIFAR-100#Percentage correct#65.4$Image Classification#SVHN#Percentage error#1.9$Image Classification#MNIST#Percentage error#0.4$Image Classification#CIFAR-10#Percentage correct#91.8
1312.4400v3.pdf	Image Classification#CIFAR-100#Percentage correct#64.3$Image Classification#SVHN#Percentage error#2.35$Image Classification#MNIST#Percentage error#0.5$Image Classification#CIFAR-10#Percentage correct#91.2
1312.6116v2.pdf	Image Classification#CIFAR-100#Percentage correct#61.9$Image Classification#CIFAR-10#Percentage correct#90.6
1302.4389v4.pdf	Image Classification#CIFAR-100#Percentage correct#61.43$Image Classification#SVHN#Percentage error#2.5$Image Classification#MNIST#Percentage error#0.5$Image Classification#CIFAR-10#Percentage correct#90.65
1505.00853v2.pdf	Image Classification#CIFAR-100#Percentage correct#59.8$Image Classification#CIFAR-10#Percentage correct#88.8
1301.3557v1.pdf	Image Classification#CIFAR-100#Percentage correct#57.5$Image Classification#SVHN#Percentage error#2.8$Image Classification#CIFAR-10#Percentage correct#84.9
2207.08569v1.pdf	Image Classification#CIFAR-100#Top 1 Accuracy#77.5$Image Classification#Tiny-ImageNet#Top 1 Accuracy#64.41$Image Classification#CIFAR-10#Top 1 Accuracy#94.74
2009.04626v1.pdf	Image Classification#CIFAR-100#Top 1 Accuracy#70.17$Image Classification#ImageNet#Top 1 Accuracy#71.97%$Image Classification#CIFAR-10#Accuracy#86.49
2205.13331v3.pdf	Image Classification#CIFAR-100#Accuracy#85.29%$Image Classification#ImageNet#Top 1 Accuracy#83.67%$Image Classification#ImageNet#Number of params#22.05M$Image Classification#ImageNet#Top 1 Accuracy#82.46%$Image Classification#ImageNet#Number of params#28.59M$Image Classification#ImageNet#Top 1 Accuracy#82.16%$Image Classification#ImageNet#Number of params#71.71M$Image Classification#ImageNet#Top 1 Accuracy#81.15%$Image Classification#ImageNet#Number of params#25.56M$Image Classification#ImageNet#Top 1 Accuracy#80.64%$Image Classification#ImageNet#Number of params#60.19M$Image Classification#ImageNet#Top 1 Accuracy#79.86%$Image Classification#ImageNet#Number of params#44.55M$Image Classification#ImageNet#Top 1 Accuracy#79.03%$Image Classification#ImageNet#Top 1 Accuracy#78.60%$Image Classification#ImageNet#Number of params#5.29M$Image Classification#ImageNet#Top 1 Accuracy#76.81%$Image Classification#ImageNet#Number of params#5.48M$Image Classification#ImageNet#Top 1 Accuracy#76.70%$Image Classification#ImageNet#Number of params#21.8M$Image Classification#ImageNet#Top 1 Accuracy#73.36%$Image Classification#ImageNet#Number of params#11.69M$Image Classification#DTD#Accuracy#76.49%$Image Classification#SUN397#Accuracy#95.94%$Image Classification#FGVC Aircraft#Accuracy#83.80%$Image Classification#Stanford Cars#Accuracy#90.80%$Image Classification#Flowers-102#Accuracy#97.85%$Image Classification#CIFAR-10#Accuracy#97.61%$Image Classification#Food-101#Accuracy#84.30%
2103.01988v2.pdf	Image Classification#Places205#Top 1 Accuracy#66.0$Image Classification#Places205#Top 1 Accuracy#62.7$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#77.9%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#76.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#60.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#57.5%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#1.3B$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.2%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#693M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#83.8%
2006.09882v5.pdf	Image Classification#Places205#Top 1 Accuracy#56.7$Image Classification#Places205#Top 1 Accuracy#53.2$Image Classification#iNaturalist 2018#Top-1 Accuracy#48.6%$Image Classification#OmniBenchmark#Average Top-1 Accuracy#38.3$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#78.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#53.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.5%$Self-Supervised Image Classification#ImageNet#Number of Params#586M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#77.3%$Self-Supervised Image Classification#ImageNet#Number of Params#94M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.3%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#59.2$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.2%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#193M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#82.0%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#182M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#77.8%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#75.3
2103.03230v3.pdf	Image Classification#Places205#Top 1 Accuracy#54.1$Image Classification#iNaturalist 2018#Top-1 Accuracy#46.5%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#89.3%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#69.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#79.2%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#55%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#73.2%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#91%
2106.06804v4.pdf	Image Classification#CUB#Classification Accuracy#0.9295$Image Classification#CUB#Explanation Accuracy#95.24$Image Classification#CUB#Explanation complexity#3.74$Image Classification#CUB#Explanation extraction time#171.87$Image Classification#CUB#Classification Accuracy#0.9192$Image Classification#CUB#Explanation Accuracy#76.1$Image Classification#CUB#Explanation complexity#15.96$Image Classification#CUB#Explanation extraction time#3707.29$Image Classification#CUB#Classification Accuracy#0.9079$Image Classification#CUB#Explanation Accuracy#96.02$Image Classification#CUB#Explanation complexity#8.87$Image Classification#CUB#Explanation extraction time#264678.29$Image Classification#CUB#Classification Accuracy#0.8162$Image Classification#CUB#Explanation Accuracy#89.36$Image Classification#CUB#Explanation complexity#45.92$Image Classification#CUB#Explanation extraction time#8.1
2203.02751v1.pdf	Image Classification#iNaturalist 2018#Top-1 Accuracy#88.7%$Image Classification#iNaturalist 2018#Top-1 Accuracy#84.3%$Image Classification#iNaturalist#Top 1 Accuracy#83.4%$Image Classification#iNaturalist#Top 1 Accuracy#80.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#92.9%$Fine-Grained Image Classification#NABirds#Accuracy#93.0%
2201.08371v2.pdf	Image Classification#iNaturalist 2018#Top-1 Accuracy#86.0%$Image Classification#ImageNet#Top 1 Accuracy#88.6%$Image Classification#ImageNet#Number of params#633.5M$Image Classification#ImageNet#GFLOPs#1018.8$Image Classification#ImageNet ReaL#Accuracy#90.7%$Image Classification#ObjectNet#Top-1 Accuracy#69.5$Image Classification#ObjectNet#Top-1 Accuracy#64.3$Image Classification#ObjectNet#Top-1 Accuracy#60$Image Classification#ObjectNet#Top-1 Accuracy#57.3$Image Classification#ObjectNet#Top-1 Accuracy#48.9$Image Classification#Places365-Standard#Top 1 Accuracy#60.7$Image Classification#ImageNet V2#Top 1 Accuracy#81.1$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.7
2104.01136v2.pdf	Image Classification#iNaturalist 2018#Top-1 Accuracy#66.9%$Image Classification#iNaturalist 2018#Top-1 Accuracy#66.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#60.4%$Image Classification#iNaturalist 2018#Top-1 Accuracy#55.2%$Image Classification#iNaturalist 2018#Top-1 Accuracy#54%$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Number of params#39.4M$Image Classification#ImageNet#GFLOPs#2.334$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#Number of params#17.8M$Image Classification#ImageNet#GFLOPs#1.066$Image Classification#ImageNet#Top 1 Accuracy#80%$Image Classification#ImageNet#Number of params#10.4M$Image Classification#ImageNet#GFLOPs#0.624$Image Classification#ImageNet#Top 1 Accuracy#79.6%$Image Classification#ImageNet#Number of params#8.8M$Image Classification#ImageNet#GFLOPs#0.376$Image Classification#ImageNet#Top 1 Accuracy#75.7%$Image Classification#ImageNet#Number of params#4.7M$Image Classification#ImageNet#GFLOPs#0.288$Image Classification#iNaturalist 2019#Top-1 Accuracy#74.3$Image Classification#iNaturalist 2019#Top-1 Accuracy#72.3$Image Classification#iNaturalist 2019#Top-1 Accuracy#70.8$Image Classification#iNaturalist 2019#Top-1 Accuracy#68.4$Image Classification#iNaturalist 2019#Top-1 Accuracy#66.5$Image Classification#ImageNet ReaL#Accuracy#87.5%$Image Classification#ImageNet ReaL#Accuracy#86.9%$Image Classification#ImageNet ReaL#Accuracy#85.8%$Image Classification#ImageNet ReaL#Accuracy#85.6%$Image Classification#ImageNet ReaL#Accuracy#82.6%$Image Classification#Stanford Cars#Accuracy#89.8$Image Classification#Stanford Cars#Accuracy#89.3$Image Classification#Stanford Cars#Accuracy#88.6$Image Classification#Stanford Cars#Accuracy#88.4$Image Classification#Stanford Cars#Accuracy#88.2$Image Classification#ImageNet V2#Top 1 Accuracy#71.4$Image Classification#ImageNet V2#Top 1 Accuracy#69.9$Image Classification#ImageNet V2#Top 1 Accuracy#68.7$Image Classification#ImageNet V2#Top 1 Accuracy#67.5$Image Classification#ImageNet V2#Top 1 Accuracy#63.9$Image Classification#Flowers-102#Accuracy#98.3$Image Classification#Flowers-102#Accuracy#97.8$Image Classification#Flowers-102#Accuracy#97.7$Image Classification#Flowers-102#Accuracy#96.8$Image Classification#CIFAR-10#Percentage correct#98.2$Image Classification#CIFAR-10#Top-1 Accuracy#98.2$Image Classification#CIFAR-10#Percentage correct#98.1$Image Classification#CIFAR-10#Top-1 Accuracy#98.1$Image Classification#CIFAR-10#Percentage correct#98$Image Classification#CIFAR-10#Top-1 Accuracy#98$Image Classification#CIFAR-10#Percentage correct#97.6$Image Classification#CIFAR-10#Top-1 Accuracy#97.6$Image Classification#CIFAR-10#Percentage correct#97.5$Image Classification#CIFAR-10#Top-1 Accuracy#97.5
1707.06642v2.pdf	Image Classification#iNaturalist 2018#Top-1 Accuracy#60.20%$Image Classification#iNaturalist#Top 1 Accuracy#67.3%$Image Classification#iNaturalist#Top 5 Accuracy#87.5%
1912.03330v1.pdf	Image Classification#iNaturalist 2018#Top-1 Accuracy#49.7%
2106.04803v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#90.88%$Image Classification#ImageNet#Number of params#2440M$Image Classification#ImageNet#GFLOPs#2586$Image Classification#ImageNet#Top 1 Accuracy#90.45%$Image Classification#ImageNet#Number of params#1470M$Image Classification#ImageNet#GFLOPs#1521$Image Classification#ImageNet#Top 1 Accuracy#88.52%$Image Classification#ImageNet#Number of params#168M$Image Classification#ImageNet#GFLOPs#114$Image Classification#GasHisSDB#Accuracy#98.74$Image Classification#GasHisSDB#Precision#99.97$Image Classification#GasHisSDB#F1-Score#99.38
2106.04560v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#90.45%$Image Classification#ImageNet#Number of params#1843M$Image Classification#ImageNet#GFLOPs#2859.9$Image Classification#ImageNet ReaL#Accuracy#90.81%$Image Classification#VTAB-1k#Top-1 Accuracy#78.29$Image Classification#ObjectNet#Top-1 Accuracy#70.53$Image Classification#ObjectNet#Top-1 Accuracy#68.5$Image Classification#ImageNet V2#Top 1 Accuracy#83.33
2003.10580v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#90.2%$Image Classification#ImageNet#Top 5 Accuracy#98.8%$Image Classification#ImageNet#Number of params#480M$Image Classification#ImageNet#Hardware Burden#95040G$Image Classification#ImageNet#Top 1 Accuracy#90%$Image Classification#ImageNet#Top 5 Accuracy#98.7%$Image Classification#ImageNet#Number of params#390M$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Top 5 Accuracy#96.5$Image Classification#ImageNet ReaL#Accuracy#91.12%$Image Classification#ImageNet ReaL#Accuracy#91.02%$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#98.01 ± 0.07$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#3.89± 0.07$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.38%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.89%
2102.06171v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#89.2%$Image Classification#ImageNet#Number of params#527M$Image Classification#ImageNet#GFLOPs#367$Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#Top 5 Accuracy#97.9%$Image Classification#ImageNet#Number of params#438.4M$Image Classification#ImageNet#GFLOPs#377.28$Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#Number of params#377.2M$Image Classification#ImageNet#GFLOPs#289.76$Image Classification#ImageNet#Top 1 Accuracy#86.0%$Image Classification#ImageNet#Top 5 Accuracy#97.6%$Image Classification#ImageNet#Top 1 Accuracy#85.9%$Image Classification#ImageNet#Number of params#316.1M$Image Classification#ImageNet#GFLOPs#215.24$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Image Classification#ImageNet#Top 5 Accuracy#97.5%$Image Classification#ImageNet#Number of params#254.9M$Image Classification#ImageNet#GFLOPs#114.76$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Top 5 Accuracy#97.3%$Image Classification#ImageNet#Number of params#193.8M$Image Classification#ImageNet#GFLOPs#62.59$Image Classification#ImageNet#Top 1 Accuracy#84.7%$Image Classification#ImageNet#Top 5 Accuracy#97.1%$Image Classification#ImageNet#Number of params#132.6M$Image Classification#ImageNet#GFLOPs#35.54$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Top 5 Accuracy#96.8%$Image Classification#ImageNet#Number of params#71.5M$Image Classification#ImageNet#GFLOPs#12.38
2210.01820v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#89.1%$Image Classification#ImageNet#Number of params#483.2M$Image Classification#ImageNet#GFLOPs#648.5$Image Classification#ImageNet#Top 1 Accuracy#86.7%$Image Classification#ImageNet#Number of params#190M$Image Classification#ImageNet#GFLOPs#271$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#27.8M$Image Classification#ImageNet#GFLOPs#5.7
2010.11929v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#88.55%$Image Classification#ImageNet#Number of params#632M$Image Classification#ImageNet#Top 1 Accuracy#87.76%$Image Classification#ImageNet#Number of params#307M$Image Classification#ImageNet#Top 1 Accuracy#85.22$Image Classification#ImageNet#GFLOPs#33.03$Image Classification#ImageNet ReaL#Accuracy#90.72±0.05%$Image Classification#ImageNet ReaL#Params#632M$Image Classification#ImageNet ReaL#Accuracy#90.54±0.03%$Image Classification#ImageNet ReaL#Params#307M$Image Classification#OmniBenchmark#Average Top-1 Accuracy#45.8$Image Classification#VTAB-1k#Top-1 Accuracy#77.63±0.23$Image Classification#VTAB-1k#Params#632M$Image Classification#VTAB-1k#Top-1 Accuracy#76.28±0.46$Image Classification#VTAB-1k#Params#307M$Image Classification#VTAB-1k#Top-1 Accuracy#72.72±0.21$Image Classification#ObjectNet#Top-5 Accuracy#82.1$Image Classification#ObjectNet#Top-1 Accuracy#61.7$Image Classification#CIFAR-10#Percentage correct#99.5$Image Classification#CIFAR-10#PARAMS#632M$Image Classification#CIFAR-10#Percentage correct#99.42$Image Classification#CIFAR-10#PARAMS#307M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#6.2%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#86.4M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#307M$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#PARAMS#632M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#307M$Fine-Grained Image Classification#Oxford 102 Flowers#PARAMS#632M
2003.08237v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#88.5%$Image Classification#ImageNet#Top 5 Accuracy#98.7%$Image Classification#ImageNet#Number of params#480M$Image Classification#ImageNet#GFLOPs#585$Image Classification#ImageNet#Top 1 Accuracy#87.1%$Image Classification#ImageNet#Top 5 Accuracy#98.2%$Image Classification#ImageNet#Number of params#66M$Image Classification#ImageNet#GFLOPs#82$Image Classification#ImageNet#Top 1 Accuracy#86.7%$Image Classification#ImageNet#Top 5 Accuracy#98.0%$Image Classification#ImageNet#Number of params#43M$Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Top 5 Accuracy#97.9%$Image Classification#ImageNet#Number of params#30M$Image Classification#ImageNet#Top 1 Accuracy#85.9%$Image Classification#ImageNet#Top 5 Accuracy#97.7%$Image Classification#ImageNet#Number of params#19M$Image Classification#ImageNet#Top 1 Accuracy#85.7%$Image Classification#ImageNet#Top 5 Accuracy#97.6%$Image Classification#ImageNet#Top 1 Accuracy#85%$Image Classification#ImageNet#Top 5 Accuracy#97.4%$Image Classification#ImageNet#Number of params#12M$Image Classification#ImageNet#Top 1 Accuracy#84.0%$Image Classification#ImageNet#Top 5 Accuracy#97.0%$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Top 5 Accuracy#96.9%$Image Classification#ImageNet#Number of params#9.2M$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Top 5 Accuracy#96.5%$Image Classification#ImageNet#Number of params#7.8M$Image Classification#ImageNet#Top 1 Accuracy#80.2%$Image Classification#ImageNet#Top 5 Accuracy#95.4%$Image Classification#ImageNet#Number of params#5.3M$Image Classification#ImageNet#GFLOPs#1.60$Image Classification#ImageNet ReaL#Accuracy#90.9%$Image Classification#ImageNet ReaL#Params#480M$Image Classification#ImageNet ReaL#Accuracy#90.0%$Image Classification#ImageNet ReaL#Params#87M
2202.10108v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#88.5%$Image Classification#ImageNet#Number of params#644M$Image Classification#ImageNet ReaL#Accuracy#91.2%$Image Classification#ImageNet ReaL#Params#644M
1911.04252v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#88.4%$Image Classification#ImageNet#Top 5 Accuracy#98.7%$Image Classification#ImageNet#Number of params#480M$Image Classification#ImageNet#Hardware Burden#51800G$Image Classification#ImageNet#Top 1 Accuracy#86.9%$Image Classification#ImageNet#Top 5 Accuracy#98.1%$Image Classification#ImageNet#Number of params#66M$Image Classification#ImageNet#GFLOPs#37$Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Top 5 Accuracy#97.9%$Image Classification#ImageNet#Number of params#43M$Image Classification#ImageNet#Top 1 Accuracy#86.1%$Image Classification#ImageNet#Top 5 Accuracy#97.8%$Image Classification#ImageNet#Number of params#30M$Image Classification#ImageNet#Top 1 Accuracy#85.3%$Image Classification#ImageNet#Top 5 Accuracy#97.5%$Image Classification#ImageNet#Number of params#19M$Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Top 5 Accuracy#96.9%$Image Classification#ImageNet#Number of params#12M$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Top 5 Accuracy#96.3%$Image Classification#ImageNet#Number of params#9.2M$Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#Top 5 Accuracy#95.8%$Image Classification#ImageNet#Number of params#7.8M$Image Classification#ImageNet#Top 1 Accuracy#78.8%$Image Classification#ImageNet#Top 5 Accuracy#94.5%$Image Classification#ImageNet#Number of params#5.3M$Image Classification#ImageNet ReaL#Accuracy#90.55%$Image Classification#ImageNet ReaL#Params#480M
2111.12710v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#88.3%$Image Classification#ImageNet#Number of params#656M$Image Classification#ImageNet#Top 1 Accuracy#87.5%
2105.01601v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#87.94%$Image Classification#ImageNet#Top 1 Accuracy#85.3%$Image Classification#ImageNet#Top 1 Accuracy#76.44%$Image Classification#ImageNet#Number of params#46M$Image Classification#ImageNet ReaL#Accuracy#90.18%$Image Classification#ImageNet ReaL#Params#409M$Image Classification#ImageNet ReaL#Accuracy#87.86%$Image Classification#OmniBenchmark#Average Top-1 Accuracy#32.2
2203.06717v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#87.8%$Image Classification#ImageNet#Number of params#335M$Image Classification#ImageNet#GFLOPs#128.7
2204.12511v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#87.2%
2205.10505v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#87.1$Image Classification#ImageNet#Top 1 Accuracy#86.3$Image Classification#ImageNet#Top 1 Accuracy#84.2
2105.13343v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.78%$Image Classification#ImageNet#Number of params#377.2M
2205.09612v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.61%$Image Classification#ImageNet#GFLOPs#51.93$Image Classification#ImageNet#Top 1 Accuracy#86.46%$Image Classification#ImageNet#GFLOPs#57.46$Image Classification#ImageNet#Top 1 Accuracy#86.42%$Image Classification#ImageNet#GFLOPs#45.43$Image Classification#ImageNet#Top 1 Accuracy#85.28%$Image Classification#ImageNet#GFLOPs#47.43$Image Classification#ImageNet#Top 1 Accuracy#83.88%$Image Classification#ImageNet#GFLOPs#18.58
2207.10666v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#Top 5 Accuracy#97.9%$Image Classification#ImageNet#Number of params#21M$Image Classification#ImageNet#GFLOPs#27.0$Image Classification#ImageNet#Top 1 Accuracy#86.2%$Image Classification#ImageNet#Top 5 Accuracy#97.8%$Image Classification#ImageNet#GFLOPs#13.8$Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Top 5 Accuracy#97.3%$Image Classification#ImageNet#GFLOPs#4.3$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Top 5 Accuracy#96.5%$Image Classification#ImageNet#Number of params#11M$Image Classification#ImageNet#GFLOPs#2.0$Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#Top 5 Accuracy#95.8%$Image Classification#ImageNet#Top 1 Accuracy#80.7%$Image Classification#ImageNet#Top 5 Accuracy#95.6%$Image Classification#ImageNet#Number of params#5.4M$Image Classification#ImageNet#GFLOPs#1.3$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Top 5 Accuracy#94.8%
2202.07940v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.5%$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Top 1 Accuracy#77.1%
1906.06423v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.4%$Image Classification#ImageNet#Top 5 Accuracy#98.0$Image Classification#ImageNet#Number of params#829M$Image Classification#ImageNet#Hardware Burden#62G$Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Top 5 Accuracy#96.8$Image Classification#ImageNet#Number of params#86.1M$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Top 5 Accuracy#96.6$Image Classification#ImageNet#Number of params#25.6M$Image Classification#ImageNet#Top 1 Accuracy#79.8%$Image Classification#ImageNet#Top 5 Accuracy#94.9$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Top 5 Accuracy#94.6$Image Classification#ImageNet ReaL#Accuracy#89.73%$Image Classification#ImageNet ReaL#Params#829M$Image Classification#iNaturalist#Top 1 Accuracy#75.4$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.7$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.4%$Fine-Grained Image Classification#Birdsnap#Accuracy#84.3%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Top-1 Error Rate#5.2%$Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy#94.8%$Fine-Grained Image Classification#Oxford 102 Flowers#Top-1 Error Rate#4.3%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#95.7%$Fine-Grained Image Classification#NABirds#Accuracy#89.2%
2201.09450v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.3%$Image Classification#ImageNet#Number of params#100M$Image Classification#ImageNet#GFLOPs#39.2$Image Classification#ImageNet#Top 1 Accuracy#85.6%$Image Classification#ImageNet#GFLOPs#12.6$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Number of params#22M$Image Classification#ImageNet#GFLOPs#3.6
2106.03714v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#86.03$Image Classification#ImageNet#Number of params#81M
2002.09024v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#87.42M
2003.11342v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.8%$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Number of params#66M
2204.07154v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Top 5 Accuracy#97.5$Image Classification#ImageNet#Number of params#47M$Image Classification#ImageNet#GFLOPs#98.8
2207.04978v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Top 5 Accuracy#97.3%$Image Classification#ImageNet#Number of params#57.5M$Image Classification#ImageNet#GFLOPs#14.8$Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Top 5 Accuracy#97.1%$Image Classification#ImageNet#Number of params#33.5M$Image Classification#ImageNet#GFLOPs#7.2$Image Classification#ImageNet#Top 1 Accuracy#83.9%$Image Classification#ImageNet#Top 5 Accuracy#96.6%$Image Classification#ImageNet#Number of params#22.7M$Image Classification#ImageNet#GFLOPs#4.7
1911.09665v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Top 5 Accuracy#97.3$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#Top 1 Accuracy#85.2%$Image Classification#ImageNet#Top 5 Accuracy#97.2$Image Classification#ImageNet#Number of params#66M
2103.12731v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.5%$Image Classification#ImageNet#Number of params#87M
1805.00932v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.4%$Image Classification#ImageNet#Top 5 Accuracy#97.6%$Image Classification#ImageNet#Number of params#829M$Image Classification#ImageNet#GFLOPs#306$Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Top 5 Accuracy#97.5%$Image Classification#ImageNet#Number of params#466M$Image Classification#ImageNet#GFLOPs#174$Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#Top 5 Accuracy#97.2%$Image Classification#ImageNet#Number of params#194M$Image Classification#ImageNet#GFLOPs#72$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Top 5 Accuracy#96.4$Image Classification#ImageNet#Number of params#88M
2110.04035v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.2%$Image Classification#ImageNet#Number of params#73.5M$Image Classification#ImageNet#GFLOPs#23.2$Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#GFLOPs#9.9$Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Number of params#22.5M$Image Classification#ImageNet#GFLOPs#2.4$Image Classification#ImageNet#Top 1 Accuracy#80.4%$Image Classification#ImageNet#Number of params#14M$Image Classification#ImageNet#GFLOPs#0.99$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Number of params#11.9M$Image Classification#ImageNet#GFLOPs#0.56
2006.10702v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#85.1%$Image Classification#ImageNet#Top 5 Accuracy#97.4%$Image Classification#ImageNet#Number of params#76M$Image Classification#ImageNet#Top 1 Accuracy#84.0%$Image Classification#ImageNet#Top 5 Accuracy#97.0%$Image Classification#ImageNet#Number of params#25.58M$Image Classification#ImageNet#Top 1 Accuracy#83.0%$Image Classification#ImageNet#Top 5 Accuracy#96.4%$Image Classification#ImageNet#Top 1 Accuracy#79.0%$Image Classification#ImageNet#Top 5 Accuracy#94.5%$Image Classification#ImageNet#Number of params#5.47M
1905.00546v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Top 5 Accuracy#97.4$Image Classification#ImageNet#Number of params#193M$Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Top 5 Accuracy#97.2$Image Classification#ImageNet#Number of params#88M$Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Top 5 Accuracy#96.8$Image Classification#ImageNet#Number of params#42M$Image Classification#OmniBenchmark#Average Top-1 Accuracy#40.4
2111.05297v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.8%$Image Classification#ImageNet#Number of params#71.2M$Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Top 5 Accuracy#97.0$Image Classification#ImageNet#Number of params#21.3M$Image Classification#ImageNet#GFLOPs#42.8$Image Classification#ImageNet#Top 1 Accuracy#83.8%$Image Classification#ImageNet#Top 5 Accuracy#96.8$Image Classification#ImageNet#Number of params#21M$Image Classification#ImageNet#GFLOPs#18.5$Image Classification#ImageNet#Top 1 Accuracy#77.6%$Image Classification#ImageNet#Number of params#4.8M$Image Classification#ImageNet#GFLOPs#1.1$Image Classification#ImageNet#Top 1 Accuracy#74.0%$Image Classification#ImageNet#Number of params#4M$Image Classification#ImageNet#GFLOPs#0.7
2207.05501v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.7%$Image Classification#ImageNet#Number of params#57.8M$Image Classification#ImageNet#GFLOPs#32$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#44.8M$Image Classification#ImageNet#GFLOPs#8.3$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Number of params#31.7M$Image Classification#ImageNet#GFLOPs#5.8
2205.13213v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.7%$Image Classification#ImageNet#Number of params#87M$Image Classification#ImageNet#GFLOPs#39.7$Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#GFLOPs#13.2$Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#Number of params#49M$Image Classification#ImageNet#GFLOPs#7.5$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Number of params#28M$Image Classification#ImageNet#GFLOPs#3.7
2107.12292v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.6%$Image Classification#ImageNet#Top 5 Accuracy#97.1%$Image Classification#ImageNet#Number of params#55.8M$Image Classification#ImageNet#GFLOPs#26.5$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Top 5 Accuracy#96.5%$Image Classification#ImageNet#Number of params#40.9M$Image Classification#ImageNet#GFLOPs#8.5$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#Top 5 Accuracy#95.8%$Image Classification#ImageNet#Number of params#23.1M$Image Classification#ImageNet#GFLOPs#4.1
2102.08602v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.3%$Image Classification#ImageNet#Number of params#42M$Image Classification#ImageNet#Top 1 Accuracy#84.0%$Image Classification#ImageNet#Number of params#35M
2001.06268v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#GFLOPs#15.8$Image Classification#ImageNet ReaL#Accuracy#88.65%$Image Classification#ImageNet ReaL#Accuracy#87.82%$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.4%$Fine-Grained Image Classification#SOP#Recall@1#85.9$Fine-Grained Image Classification#Food-101#Top 1 Accuracy#92.47$Fine-Grained Image Classification#Food-101#Accuracy#92.5$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.4$Fine-Grained Image Classification#Oxford-IIIT Pets#Accuracy#94.3%$Fine-Grained Image Classification#Oxford-IIIT Pets#Top-1 Error Rate#5.7$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.9%
2107.05790v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.2%
2206.14098v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.2%$Image Classification#ImageNet#Number of params#142.3M$Image Classification#ImageNet#GFLOPs#38.1$Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Number of params#82M$Image Classification#ImageNet#GFLOPs#21.8$Image Classification#ImageNet#Top 1 Accuracy#83%$Image Classification#ImageNet#Number of params#48.7M$Image Classification#ImageNet#GFLOPs#10.6$Image Classification#ImageNet#Top 1 Accuracy#81.1%$Image Classification#ImageNet#Number of params#19.6M$Image Classification#ImageNet#GFLOPs#3.33$Image Classification#ImageNet#Top 1 Accuracy#79%$Image Classification#ImageNet#Number of params#10.6M$Image Classification#ImageNet#GFLOPs#1.37$Image Classification#ImageNet#Top 1 Accuracy#75.9%$Image Classification#ImageNet#Number of params#5.11M$Image Classification#ImageNet#GFLOPs#0.62$Image Classification#ImageNet#Top 1 Accuracy#72.8%$Image Classification#ImageNet#Number of params#3.42M$Image Classification#ImageNet#GFLOPs#0.31
2105.03889v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#84.1%$Image Classification#ImageNet#Number of params#83.3M$Image Classification#ImageNet#GFLOPs#46.6
2103.16302v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#84%$Image Classification#ImageNet#Number of params#73.8M$Image Classification#ImageNet#GFLOPs#12.5$Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#Number of params#23.5M$Image Classification#ImageNet#GFLOPs#2.9$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Number of params#10.6M$Image Classification#ImageNet#GFLOPs#1.4$Image Classification#ImageNet#Top 1 Accuracy#74.6%$Image Classification#ImageNet#Number of params#4.9M$Image Classification#ImageNet#GFLOPs#0.7
2106.02034v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.9$Image Classification#ImageNet#Number of params#57.1M
2112.11435v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.7%$Image Classification#ImageNet#Number of params#56M$Image Classification#ImageNet#GFLOPs#9.7$Image Classification#ImageNet#Top 1 Accuracy#83.2%$Image Classification#ImageNet#Number of params#25M$Image Classification#ImageNet#GFLOPs#4.4$Image Classification#ImageNet#Top 1 Accuracy#81.7%$Image Classification#ImageNet#Number of params#16M$Image Classification#ImageNet#GFLOPs#2.5
2105.13677v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.6%$Image Classification#ImageNet#Top 5 Accuracy#96.3$Image Classification#ImageNet#Number of params#51.63M$Image Classification#ImageNet#GFLOPs#7.9$Image Classification#ImageNet#Top 1 Accuracy#79.6%$Image Classification#ImageNet#Top 5 Accuracy#94.9$Image Classification#ImageNet#Number of params#13.66M$Image Classification#ImageNet#GFLOPs#1.9
2109.05422v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.4%$Image Classification#ImageNet#Number of params#65.9M$Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Number of params#48.6M$Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#Number of params#24.1M
2101.11986v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.3%$Image Classification#ImageNet#GFLOPs#34.2$Image Classification#ImageNet#Top 1 Accuracy#82.6%$Image Classification#ImageNet#Number of params#64.4M$Image Classification#ImageNet#GFLOPs#30$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#GFLOPs#27.6$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#39.2M$Image Classification#ImageNet#GFLOPs#19.6$Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#GFLOPs#17.0$Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#Number of params#21.5M$Image Classification#ImageNet#GFLOPs#9.6
2103.11886v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#83.1%$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#55M
1712.00559v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.9%$Image Classification#ImageNet#Top 5 Accuracy#96.2$Image Classification#ImageNet#Number of params#86.1M$Image Classification#ImageNet#Operations per network pass#2.5G$Image Classification#ImageNet#GFLOPs#50
2001.06570v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.85%$Image Classification#ImageNet#Top 5 Accuracy#96.44$Image Classification#ImageNet#Number of params#88.2M$Image Classification#ImageNet#GFLOPs#31.4
2007.00992v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Top 5 Accuracy#96.3$Image Classification#ImageNet#Number of params#34.7M$Image Classification#ImageNet#GFLOPs#3.4$Image Classification#ImageNet#Top 1 Accuracy#81.6%$Image Classification#ImageNet#Top 5 Accuracy#95.7$Image Classification#ImageNet#Number of params#19M$Image Classification#ImageNet#GFLOPs#1.5$Image Classification#ImageNet#Top 1 Accuracy#80.3%$Image Classification#ImageNet#Top 5 Accuracy#95.2$Image Classification#ImageNet#Number of params#9.7M$Image Classification#ImageNet#GFLOPs#0.86$Image Classification#ImageNet#Top 1 Accuracy#79.5%$Image Classification#ImageNet#Top 5 Accuracy#94.7$Image Classification#ImageNet#Number of params#7.6M$Image Classification#ImageNet#GFLOPs#0.66$Image Classification#ImageNet#Top 1 Accuracy#77.9%$Image Classification#ImageNet#Top 5 Accuracy#93.9$Image Classification#ImageNet#Number of params#4.8M$Image Classification#ImageNet#GFLOPs#0.40$Image Classification#ImageNet#Top 1 Accuracy#77.2%$Image Classification#ImageNet#Top 5 Accuracy#93.5$Image Classification#ImageNet#Number of params#4.1M$Image Classification#ImageNet#GFLOPs#0.35$Image Classification#ImageNet#Top 1 Accuracy#74.6%$Image Classification#ImageNet#Top 5 Accuracy#92.1$Image Classification#ImageNet#Number of params#2.7M
2106.05237v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.8%
2103.14899v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.8%$Image Classification#ImageNet#Number of params#44.3M$Image Classification#ImageNet#GFLOPs#9.5$Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Number of params#43.3M$Image Classification#ImageNet#GFLOPs#9$Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#Number of params#28.2M$Image Classification#ImageNet#GFLOPs#6.1$Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#Number of params#27.4M$Image Classification#ImageNet#GFLOPs#5.8
1707.07012v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Top 5 Accuracy#96.2$Image Classification#ImageNet#Number of params#88.9M$Image Classification#ImageNet#Hardware Burden#1648G$Image Classification#ImageNet#Operations per network pass#2.38G$Image Classification#ImageNet#GFLOPs#23.8$Image Classification#ImageNet ReaL#Accuracy#87.56%$Image Classification#ImageNet ReaL#Accuracy#81.15%
2106.01401v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.7%$Image Classification#ImageNet#Number of params#22.1M$Image Classification#ImageNet#GFLOPs#8.1$Image Classification#ImageNet#Top 1 Accuracy#82%$Image Classification#ImageNet#Number of params#20M$Image Classification#ImageNet#GFLOPs#3.2
2103.10697v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.5%$Image Classification#ImageNet#Number of params#152M$Image Classification#ImageNet#GFLOPs#30$Image Classification#ImageNet#Top 1 Accuracy#82.4%$Image Classification#ImageNet#Number of params#86M$Image Classification#ImageNet#GFLOPs#17$Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#48M$Image Classification#ImageNet#GFLOPs#10$Image Classification#ImageNet#Top 1 Accuracy#81.3%$Image Classification#ImageNet#Number of params#27M$Image Classification#ImageNet#GFLOPs#5.4$Image Classification#ImageNet#Top 1 Accuracy#76.7%$Image Classification#ImageNet#Number of params#10M$Image Classification#ImageNet#GFLOPs#2$Image Classification#ImageNet#Top 1 Accuracy#73.1%$Image Classification#ImageNet#Number of params#6M$Image Classification#ImageNet#GFLOPs#1
2107.02960v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.3%$Image Classification#ImageNet#Number of params#96.1M$Image Classification#ImageNet#GFLOPs#17$Image Classification#ImageNet#Top 1 Accuracy#80.5%$Image Classification#ImageNet#Number of params#24.6M$Image Classification#ImageNet#GFLOPs#4.4$Image Classification#ImageNet#Top 1 Accuracy#76.3%$Image Classification#ImageNet#Number of params#7.2M$Image Classification#ImageNet#GFLOPs#1.4
2108.01390v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#39.6M
2104.12533v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.2%$Image Classification#ImageNet#Number of params#40.2M$Image Classification#ImageNet#GFLOPs#4.9$Image Classification#ImageNet#Top 1 Accuracy#78.6%$Image Classification#ImageNet#Number of params#10.3M$Image Classification#ImageNet#GFLOPs#1.3
2201.09792v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#82.20$Image Classification#ImageNet#Number of params#51.6M$Image Classification#CIFAR-10#Percentage correct#96.74$Image Classification#CIFAR-10#PARAMS#1.34M$Image Classification#CIFAR-10#Percentage correct#96.03$Image Classification#CIFAR-10#PARAMS#0.71M
2112.01528v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#81.9%$Image Classification#ImageNet#Top 5 Accuracy#95.7$Image Classification#ImageNet#Top 1 Accuracy#80.1%$Image Classification#ImageNet#Top 5 Accuracy#94.8$Image Classification#ImageNet#Top 1 Accuracy#78.7%$Image Classification#ImageNet#Number of params#5M$Image Classification#ImageNet#GFLOPs#1.2
2009.08453v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#81.72%$Image Classification#ImageNet#Top 5 Accuracy#95.81%$Image Classification#ImageNet#Number of params#25.6M$Image Classification#ImageNet#Top 1 Accuracy#80.67%$Image Classification#ImageNet#Top 5 Accuracy#95.09%$Image Classification#ImageNet#Top 1 Accuracy#73.19%$Image Classification#ImageNet#Top 5 Accuracy#90.82$Image Classification#OmniBenchmark#Average Top-1 Accuracy#36.6
2107.03815v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#81.5%$Image Classification#ImageNet#GFLOPs#0.214$Image Classification#ImageNet#Top 1 Accuracy#80.7%$Image Classification#ImageNet#Number of params#95.3M$Image Classification#ImageNet#GFLOPs#0.194$Image Classification#ImageNet#Top 1 Accuracy#80%$Image Classification#ImageNet#GFLOPs#0.100
1912.11188v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#81.32%$Image Classification#ImageNet#Top 5 Accuracy#95.30%$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Top 5 Accuracy#94.47%
2010.05981v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#81.2
1611.05431v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.9%$Image Classification#ImageNet#Top 5 Accuracy#95.6%$Image Classification#ImageNet#Number of params#83.6M$Image Classification#ImageNet#GFLOPs#31.5$Image Classification#GasHisSDB#Accuracy#98.59$Image Classification#GasHisSDB#Precision#99.94$Image Classification#GasHisSDB#F1-Score#99.25
2102.08606v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.9%$Image Classification#ImageNet#Number of params#22.3M$Image Classification#ImageNet#GFLOPs#9.4
2004.11362v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.8%$Image Classification#ImageNet#Top 5 Accuracy#95.6%$class-incremental learning#cifar100#10-stage average accuracy#65.98
2104.05707v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.8%$Image Classification#ImageNet#Top 5 Accuracy#95.4$Image Classification#ImageNet#Number of params#22.4M$Image Classification#ImageNet#GFLOPs#4.6$Image Classification#ImageNet#Top 1 Accuracy#78.2%$Image Classification#ImageNet#Top 5 Accuracy#94.2$Image Classification#ImageNet#Number of params#13.5M$Image Classification#ImageNet#GFLOPs#4.8$Image Classification#ImageNet#Top 1 Accuracy#75.9%$Image Classification#ImageNet#Top 5 Accuracy#93$Image Classification#ImageNet#Number of params#6.3M$Image Classification#ImageNet#GFLOPs#1.4$Image Classification#ImageNet#Top 1 Accuracy#74.8%$Image Classification#ImageNet#Top 5 Accuracy#92.6$Image Classification#ImageNet#Number of params#5.9M$Image Classification#ImageNet#GFLOPs#1.3$Image Classification#ImageNet#Top 1 Accuracy#72.5%$Image Classification#ImageNet#Number of params#4.3M$Image Classification#ImageNet#GFLOPs#1.2
1704.06904v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.5%$Image Classification#ImageNet#Top 5 Accuracy#95.2%
2009.14082v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.22%$Image Classification#ImageNet#Top 5 Accuracy#94.9%$Image Classification#ImageNet#Number of params#34.7M
1602.07261v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.1%$Image Classification#ImageNet#Top 5 Accuracy#95.1%$Image Classification#ImageNet#Number of params#55.8M$Image Classification#OmniBenchmark#Average Top-1 Accuracy#32.3
2107.11817v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#80.09%$Image Classification#ImageNet#Number of params#63M$Image Classification#ImageNet#Top 1 Accuracy#79.49%$Image Classification#ImageNet#Number of params#40M$Image Classification#ImageNet#Top 1 Accuracy#77.54%$Image Classification#ImageNet#Number of params#29M
2105.03014v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#80%$Image Classification#ImageNet#GFLOPs#0.198
2003.13678v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.9%$Image Classification#ImageNet#Number of params#39.2M$Image Classification#ImageNet#GFLOPs#8$Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Number of params#20.6M$Image Classification#ImageNet#GFLOPs#4$Image Classification#ImageNet#Top 1 Accuracy#78%$Image Classification#ImageNet#Number of params#11.2M$Image Classification#ImageNet#GFLOPs#1.6$Image Classification#ImageNet#Top 1 Accuracy#76.3%$Image Classification#ImageNet#Number of params#6.3M$Image Classification#ImageNet#GFLOPs#0.8$Image Classification#ImageNet#Top 1 Accuracy#75.5%$Image Classification#ImageNet#Number of params#6.1M$Image Classification#ImageNet#GFLOPs#0.6$Image Classification#ImageNet#Top 1 Accuracy#74.1%$Image Classification#ImageNet#Number of params#4.3M$Image Classification#ImageNet#GFLOPs#0.4
1911.11929v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.8%$Image Classification#ImageNet#Top 5 Accuracy#95.2%$Image Classification#ImageNet#Number of params#20.5M
2010.14819v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.4%$Image Classification#ImageNet#Top 5 Accuracy#94.5$Image Classification#ImageNet#Number of params#11.9$Image Classification#ImageNet#GFLOPs#0.591$Image Classification#ImageNet#Top 1 Accuracy#77.7%$Image Classification#ImageNet#Top 5 Accuracy#93.5$Image Classification#ImageNet#Number of params#5.1M$Image Classification#ImageNet#GFLOPs#0.339
1904.09460v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.38%$Image Classification#ImageNet#Top 5 Accuracy#94.82$Image Classification#ImageNet#GFLOPs#11.2$Image Classification#ImageNet#Top 1 Accuracy#79.03%$Image Classification#ImageNet#Top 5 Accuracy#94.58$Image Classification#ImageNet#GFLOPs#7.5$Image Classification#ImageNet#Top 1 Accuracy#77.8%$Image Classification#ImageNet#GFLOPs#3.8
2209.15159v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.3%$Image Classification#ImageNet#Number of params#5.8 M$Image Classification#ImageNet#GFLOPs#1.8$Image Classification#ImageNet#Top 1 Accuracy#78.64%$Image Classification#ImageNet#Number of params#5.1 M$Image Classification#ImageNet#GFLOPs#1.9$Image Classification#ImageNet#Top 1 Accuracy#76.7%$Image Classification#ImageNet#Number of params#2.5 M$Image Classification#ImageNet#GFLOPs#0.9$Image Classification#ImageNet#Top 1 Accuracy#76.55%$Image Classification#ImageNet#Number of params#3 M$Image Classification#ImageNet#GFLOPs#1.1$Image Classification#ImageNet#Top 1 Accuracy#72.33%$Image Classification#ImageNet#Number of params#1.4 M$Image Classification#ImageNet#GFLOPs#0.5$Image Classification#ImageNet#Top 1 Accuracy#70.98%$Image Classification#ImageNet#Number of params#1.2 M$Image Classification#ImageNet#GFLOPs#0.3
2103.06255v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#79.3%$Image Classification#ImageNet#Number of params#34M$Image Classification#ImageNet#GFLOPs#6.8$Image Classification#ImageNet#Top 1 Accuracy#79.1%$Image Classification#ImageNet#Number of params#25.6M$Image Classification#ImageNet#GFLOPs#4.7$Image Classification#ImageNet#Top 1 Accuracy#78.4%$Image Classification#ImageNet#Number of params#15.5M$Image Classification#ImageNet#GFLOPs#2.7$Image Classification#ImageNet#Top 1 Accuracy#77.6%$Image Classification#ImageNet#Number of params#12.4M$Image Classification#ImageNet#GFLOPs#2.2$Image Classification#ImageNet#Top 1 Accuracy#75.9%$Image Classification#ImageNet#Number of params#9.2M$Image Classification#ImageNet#GFLOPs#1.7
1610.02357v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#79%$Image Classification#ImageNet#Top 5 Accuracy#94.5$Image Classification#ImageNet#Number of params#22.855952M$Image Classification#ImageNet#Hardware Burden#87G$Image Classification#ImageNet#Operations per network pass#0.838G
1911.09737v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.95%$Image Classification#ImageNet#Top 5 Accuracy#94.49%$Image Classification#ImageNet#Top 1 Accuracy#77.21%$Image Classification#ImageNet#Top 5 Accuracy#93.57%
1910.03151v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.92%$Image Classification#ImageNet#Top 5 Accuracy#94.55$Image Classification#ImageNet#Number of params#57.40M$Image Classification#ImageNet#GFLOPs#10.83$Image Classification#ImageNet#Top 1 Accuracy#78.65%$Image Classification#ImageNet#Top 5 Accuracy#94.34$Image Classification#ImageNet#Number of params#42.49M$Image Classification#ImageNet#GFLOPs#7.35$Image Classification#ImageNet#Top 1 Accuracy#77.48%$Image Classification#ImageNet#Top 5 Accuracy#93.68$Image Classification#ImageNet#Number of params#24.37M$Image Classification#ImageNet#GFLOPs#3.86$Image Classification#ImageNet#Top 1 Accuracy#72.56%$Image Classification#ImageNet#Top 5 Accuracy#90.81$Image Classification#ImageNet#Number of params#3.34M$Image Classification#ImageNet#GFLOPs#0.320
1907.09595v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.9%$Image Classification#ImageNet#Top 5 Accuracy#94.2$Image Classification#ImageNet#Number of params#7.3M$Image Classification#ImageNet#GFLOPs#0.565$Image Classification#ImageNet#Top 1 Accuracy#77%$Image Classification#ImageNet#Top 5 Accuracy#93.3$Image Classification#ImageNet#Number of params#5.0M$Image Classification#ImageNet#GFLOPs#0.360$Image Classification#ImageNet#Top 1 Accuracy#75.8%$Image Classification#ImageNet#Top 5 Accuracy#92.8$Image Classification#ImageNet#Number of params#4.1M$Image Classification#ImageNet#GFLOPs#0.256
1905.09646v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.798%$Image Classification#ImageNet#Top 5 Accuracy#94.368$Image Classification#ImageNet#Number of params#44.55M$Image Classification#ImageNet#GFLOPs#7.858$Image Classification#ImageNet#Top 1 Accuracy#77.584%$Image Classification#ImageNet#Top 5 Accuracy#93.664$Image Classification#ImageNet#Number of params#25.56M$Image Classification#ImageNet#GFLOPs#4.127
2203.03952v5.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.63%$Image Classification#ImageNet#Number of params#5M$Image Classification#ImageNet#GFLOPs#3.48
2105.01883v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.60%$Image Classification#ImageNet#Number of params#52.77M
1903.10829v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.47%$Image Classification#CIFAR-10#Percentage correct#95.05
2110.02178v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.4%$Image Classification#ImageNet#Top 5 Accuracy#94.1%$Image Classification#ImageNet#Number of params#5.6M$Image Classification#ImageNet#Top 1 Accuracy#74.8%$Image Classification#ImageNet#Top 5 Accuracy#92.3%$Image Classification#ImageNet#Number of params#2.3 M$Image Classification#ImageNet#GFLOPs#0.7
2101.05022v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.4%$Image Classification#ImageNet#Number of params#4.8M$Image Classification#OmniBenchmark#Average Top-1 Accuracy#30.8
1810.12890v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.35%$Image Classification#ImageNet#Top 5 Accuracy#94.15%
1904.04971v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.3%$Image Classification#ImageNet#GFLOPs#0.826
2103.10619v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#78.00%$Image Classification#ImageNet#Top 5 Accuracy#93.83$Image Classification#ImageNet#Number of params#21.74M$Image Classification#ImageNet#GFLOPs#2.4$Image Classification#ImageNet#Top 1 Accuracy#69.64%$Image Classification#ImageNet#Top 5 Accuracy#89.4$Image Classification#ImageNet#Number of params#5.74M$Image Classification#ImageNet#GFLOPs#0.64
1812.01187v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#77.16%$Image Classification#ImageNet#Top 5 Accuracy#93.52%$Image Classification#ImageNet#Number of params#25M
1803.08337v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#77.12%
2107.11170v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#77.1%$Image Classification#ImageNet#Top 5 Accuracy#93.4$Image Classification#ImageNet#Number of params#7.1M$Image Classification#ImageNet#GFLOPs#0.364$Image Classification#ImageNet#Top 1 Accuracy#76.2%$Image Classification#ImageNet#Top 5 Accuracy#92.8$Image Classification#ImageNet#Number of params#5.5M$Image Classification#ImageNet#GFLOPs#0.246
1807.11626v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#76.7%$Image Classification#ImageNet#Top 5 Accuracy#93.3$Image Classification#ImageNet#Number of params#5.2M$Image Classification#ImageNet#Operations per network pass#0.0403G$Image Classification#ImageNet#GFLOPs#0.806$Image Classification#ImageNet#Top 1 Accuracy#75.6%$Image Classification#ImageNet#Top 5 Accuracy#92.7$Image Classification#ImageNet#Number of params#4.8M$Image Classification#ImageNet#GFLOPs#0.680$Image Classification#ImageNet#Top 1 Accuracy#75.2%$Image Classification#ImageNet#Top 5 Accuracy#92.5$Image Classification#ImageNet#Number of params#3.9M$Image Classification#ImageNet#GFLOPs#0.624
1908.01314v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.9%$Image Classification#ImageNet#Top 5 Accuracy#92.8$Image Classification#ImageNet#Number of params#5.1M$Image Classification#ImageNet#Operations per network pass#0.0304G$Image Classification#ImageNet#GFLOPs#0.608
1605.07648v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.88%$Image Classification#ImageNet#Top 5 Accuracy#92.61$Image Classification#SVHN#Percentage error#2.01
1807.03247v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.74%$Image Classification#ImageNet#Top 5 Accuracy#92.75%
1911.11907v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.7%$Image Classification#ImageNet#Top 5 Accuracy#92.7$Image Classification#ImageNet#Number of params#7.3M$Image Classification#ImageNet#GFLOPs#0.226$Image Classification#ImageNet#Top 1 Accuracy#75%$Image Classification#ImageNet#Top 5 Accuracy#92.3$Image Classification#ImageNet#Number of params#13M$Image Classification#ImageNet#GFLOPs#2.2$Image Classification#ImageNet#Top 1 Accuracy#74.1%$Image Classification#ImageNet#Top 5 Accuracy#91.9$Image Classification#ImageNet#Number of params#6.5M$Image Classification#ImageNet#GFLOPs#1.2$Image Classification#ImageNet#Top 1 Accuracy#73.9%$Image Classification#ImageNet#Top 5 Accuracy#91.4$Image Classification#ImageNet#Number of params#5.2M$Image Classification#ImageNet#GFLOPs#0.141$Image Classification#ImageNet#Top 1 Accuracy#66.2%$Image Classification#ImageNet#Top 5 Accuracy#86.6$Image Classification#ImageNet#Number of params#2.6M$Image Classification#ImageNet#GFLOPs#0.042
1904.11491v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.7%$Image Classification#ImageNet#Top 5 Accuracy#92.6$Image Classification#ImageNet#Number of params#14.7M$Image Classification#ImageNet#GFLOPs#2.6
2104.13963v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.5%$Image Classification#ImageNet#Top 1 Accuracy#66.5%$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.0 ± 0.25$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#79.0%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#77.8%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#75.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#69.9%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#69.6%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#66.5%
1807.11164v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.4%$Image Classification#ImageNet#GFLOPs#0.597
2104.07770v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#75.4%$Image Classification#ImageNet#Number of params#5.99M$Image Classification#ImageNet#GFLOPs#0.4338$Image Classification#ImageNet#Top 1 Accuracy#69.2%$Image Classification#ImageNet#Number of params#2.8M$Image Classification#ImageNet#GFLOPs#0.1344$Image Classification#ImageNet#Top 1 Accuracy#68.4%$Image Classification#ImageNet#Number of params#3.1M$Image Classification#ImageNet#GFLOPs#0.1154
1904.02877v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#74.96%$Image Classification#ImageNet#Top 5 Accuracy#92.21%
2105.02723v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#74.9
1812.03443v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#74.9%$Image Classification#ImageNet#Number of params#5.5M$Image Classification#ImageNet#GFLOPs#0.375
1502.03167v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#74.8%$Image Classification#ImageNet#Top 5 Accuracy#92.2%$Image Classification#ImageNet#Number of params#11.2M
1912.03458v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#74.4%$Image Classification#ImageNet#Number of params#11.1M$Image Classification#ImageNet#GFLOPs#0,626$Image Classification#ImageNet#Top 1 Accuracy#72.8%$Image Classification#ImageNet#Number of params#7M$Image Classification#ImageNet#GFLOPs#0.435$Image Classification#ImageNet#Top 1 Accuracy#72.7%$Image Classification#ImageNet#Number of params#42.7M$Image Classification#ImageNet#GFLOPs#3.7$Image Classification#ImageNet#Top 1 Accuracy#69.7%$Image Classification#ImageNet#Number of params#4.8M$Image Classification#ImageNet#GFLOPs#0.137$Image Classification#ImageNet#Top 1 Accuracy#69.4%$Image Classification#ImageNet#Number of params#4M$Image Classification#ImageNet#GFLOPs#0.203$Image Classification#ImageNet#Top 1 Accuracy#67.7%$Image Classification#ImageNet#Number of params#18.6M$Image Classification#ImageNet#GFLOPs#1.82$Image Classification#ImageNet#Top 1 Accuracy#64.9%$Image Classification#ImageNet#Number of params#2.8M$Image Classification#ImageNet#GFLOPs#0.124
1911.13299v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#73.3%$Image Classification#ImageNet#Number of params#20.6M
2105.10305v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#68.6%$Image Classification#ImageNet#Top 5 Accuracy#87.1%$Image Classification#WebVision-1000#Top-1 Accuracy#76.6%$Image Classification#WebVision-1000#Top-5 Accuracy#92.1%
1511.00175v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#68.3%$Image Classification#ImageNet#Top 5 Accuracy#88.7%$Image Classification#ImageNet#Top 1 Accuracy#58.9%
1902.10814v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#68.29%$Image Classification#ImageNet#Top 5 Accuracy#87.75%$Image Classification#iNaturalist#Top 1 Accuracy#31.12%$Image Classification#iNaturalist#Top 5 Accuracy#52.76%
1312.5402v1.pdf	Image Classification#ImageNet#Top 1 Accuracy#66.3%$Image Classification#ImageNet#Top 5 Accuracy#86.3%
1312.6229v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#66.04%$Image Classification#ImageNet#Top 5 Accuracy#86.76
1311.2901v3.pdf	Image Classification#ImageNet#Top 1 Accuracy#64%$Image Classification#ImageNet#Top 5 Accuracy#85.3$Image Classification#ImageNet#Hardware Burden#2G$Image Classification#ImageNet#Top 1 Accuracy#62.5%$Image Classification#ImageNet#Top 5 Accuracy#84.0
1909.12117v2.pdf	Image Classification#ImageNet#Top 1 Accuracy#62.6%$Image Classification#ImageNet#Top 5 Accuracy#84.1%$Image Classification#ImageNet#Top 1 Accuracy#59.4%$Image Classification#ImageNet#Top 5 Accuracy#81.3%
1602.07360v4.pdf	Image Classification#ImageNet#Top 1 Accuracy#60.4%$Image Classification#ImageNet#Top 5 Accuracy#82.5%$Image Classification#ImageNet#Number of params#1.24M$Image Classification#ImageNet#GFLOPs#1.432$Network Pruning#ImageNet#Accuracy#57.5%$Network Pruning#ImageNet#MParams#1.24
2007.03347v3.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#99.15$Image Classification#Kuzushiji-MNIST#Error#0.85$Image Classification#STL-10#Percentage correct#98.66$Image Classification#STL-10#Percentage correct#95.44$Image Classification#EMNIST-Balanced#Accuracy#91.05$Image Classification#EMNIST-Balanced#Accuracy#91.04$Image Classification#MNIST#Percentage error#0.28$Image Classification#MNIST#Accuracy#99.72$Image Classification#EMNIST-Letters#Accuracy#95.88$Image Classification#EMNIST-Letters#Accuracy#95.86$Image Classification#Flowers-102#Accuracy#99.30$Fine-Grained Image Classification#Fruits-360#Accuracy (%)#99.90$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#2.68%$Fine-Grained Image Classification#Caltech-101#Accuracy#97.32$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#2.89%$Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#6.84%$Fine-Grained Image Classification#Bird-225#Accuracy#99.02$Fine-Grained Image Classification#Bird-225#Accuracy#98.67$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#99.30%
1907.11519v1.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#99.05$Image Classification#Kuzushiji-MNIST#Error#0.95
1905.09113v1.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#98.79
1905.09688v5.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#96.3$Image Classification#MNIST#Percentage error#0.6$Image Classification#MNIST#Accuracy#99.4$Image Classification#Fashion-MNIST#Percentage error#8.6$Image Classification#Fashion-MNIST#Accuracy#91.4
1910.08336v1.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#93.13
2001.04243v3.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#79.90$Image Classification#Kuzushiji-MNIST#Accuracy#79.5
1810.04327v4.pdf	Image Classification#Kuzushiji-MNIST#Accuracy#67.1
1812.01718v1.pdf	Image Classification#Kuzushiji-MNIST#Error#1.10
2102.00515v3.pdf	Image Classification#Fracture/Normal Shoulder Bone X-ray Images on MURA#Test Accuracy#84.72%$Image Classification#Fracture/Normal Shoulder Bone X-ray Images on MURA#Cohen’s Kappa score#0.6942$Image Classification#Fracture/Normal Shoulder Bone X-ray Images on MURA#AUC score#0.8862
2107.08585v2.pdf	Image Classification#DTD#Accuracy#79.79$Image Classification#Caltech-256#Accuracy#85.94$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.35%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#95.11
1907.02893v3.pdf	Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#66.9
2002.04692v2.pdf	Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#59.91
1702.02030v1.pdf	Image Classification#Colored-MNIST(with spurious correlation)#Accuracy#17.10
2208.08900v2.pdf	Image Classification#iNaturalist 2019#Top-1 Accuracy#82.85$Fine-Grained Image Classification#Herbarium 2021 Half–Earth#Test F1 score#.719$Fine-Grained Image Classification#Herbarium 2022#Test F1 score (private)#.868
2104.15092v1.pdf	Image Classification#CIFAR-100, 60% Symmetric Noise#Percentage correct#64.6$Image Classification#Red MiniImageNet 20% label noise#Accuracy#51.42$Image Classification#CIFAR-10, 60% Symmetric Noise#Percentage correct#91.3$Image Classification#CIFAR-10, 60% Symmetric Noise#Percentage correct#26.42$Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.4$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.80$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#77$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#92.76$Image Classification#Red MiniImageNet 80% label noise#Accuracy#35.5$Image Classification#CIFAR-10, 40% Symmetric Noise#Percentage correct#95.37$Image Classification#CIFAR-10, 40% Symmetric Noise#Percentage correct#94.2$Image Classification#CIFAR-100, 40% Symmetric Noise#Percentage correct#75.91$Image Classification#CIFAR-100, 40% Symmetric Noise#Percentage correct#71.3$Image Classification#Red MiniImageNet 60% label noise#Accuracy#45.1$Image Classification#Red MiniImageNet 40% label noise#Accuracy#48.06
1905.05393v1.pdf	Image Classification#SVHN#Percentage error#1.2
1901.09321v2.pdf	Image Classification#SVHN#Percentage error#1.4$Image Classification#CIFAR-10#Percentage correct#97.7$Image Classification#CIFAR-10#PARAMS#18M
1811.05850v5.pdf	Image Classification#SVHN#Percentage error#1.46
1709.07634v2.pdf	Image Classification#SVHN#Percentage error#1.54
1608.02908v2.pdf	Image Classification#SVHN#Percentage error#1.59
1312.6082v4.pdf	Image Classification#SVHN#Percentage error#2.2
1511.00363v3.pdf	Image Classification#SVHN#Percentage error#2.2$Image Classification#MNIST#Percentage error#1.0$Image Classification#CIFAR-10#Percentage correct#91.7
1505.00393v3.pdf	Image Classification#SVHN#Percentage error#2.4$Image Classification#MNIST#Percentage error#0.5$Image Classification#CIFAR-10#Percentage correct#87.7
1705.09792v4.pdf	Image Classification#SVHN#Percentage error#3.3$Image Classification#CIFAR-10#Percentage correct#94.4$Music Transcription#MusicNet#APS#72.9$Music Transcription#MusicNet#Number of params#8.8M$Music Transcription#MusicNet#APS#69.6$Music Transcription#MusicNet#Number of params#10.0M
1503.04596v3.pdf	Image Classification#SVHN#Percentage error#4.0$Image Classification#MNIST#Percentage error#0.4$Image Classification#CIFAR-10#Percentage correct#75.9
1701.06264v6.pdf	Image Classification#SVHN#Percentage error#5.98$Image Classification#CIFAR-10#Percentage correct#91.7
2201.04368v1.pdf	Image Classification#SVHN#Percentage error#8.20$Image Classification#Fashion-MNIST#Percentage error#5.97$Image Classification#CIFAR-10#Percentage correct#95.97
1904.01681v3.pdf	Image Classification#SVHN#Percentage error#16.5$Image Classification#MNIST#Percentage error#0.37$Image Classification#MNIST#Accuracy#99.63$Image Classification#MNIST#Percentage error#1.8$Image Classification#MNIST#Accuracy#98.2$Image Classification#CIFAR-10#Percentage correct#60.6
1602.05473v4.pdf	Image Classification#SVHN#Percentage error#16.61$Image Classification#SVHN#Percentage error#22.86
1406.5298v2.pdf	Image Classification#SVHN#Percentage error#36.02$Image Classification#SVHN#Percentage error#54.33$Image Classification#SVHN#Percentage error#65.63
2007.13693v3.pdf	Image Classification#MAMe#Acc#88.95$Image Classification#MAMe#Acc#88.25$Image Classification#MAMe#Acc#88.15$Image Classification#MAMe#Acc#85.42
2110.11809v1.pdf	Image Classification#Red MiniImageNet 20% label noise#Accuracy#61.24$Image Classification#Red MiniImageNet 80% label noise#Accuracy#43.42$Image Classification#WebVision#Top 1 Accuracy#78.84$Image Classification#Red MiniImageNet 60% label noise#Accuracy#52.84$Image Classification#Red MiniImageNet 40% label noise#Accuracy#56.22
2209.00906v1.pdf	Image Classification#Red MiniImageNet 20% label noise#Accuracy#60.89$Image Classification#Red MiniImageNet 20% label noise#Accuracy#58.38$Image Classification#Red MiniImageNet 80% label noise#Accuracy#44.03$Image Classification#Red MiniImageNet 80% label noise#Accuracy#39.62$Image Classification#Clothing1M#Accuracy#74.40%$Image Classification#Red MiniImageNet 60% label noise#Accuracy#53.21$Image Classification#Red MiniImageNet 60% label noise#Accuracy#47.96$Image Classification#Red MiniImageNet 40% label noise#Accuracy#56.37$Image Classification#Red MiniImageNet 40% label noise#Accuracy#52.24$Learning with noisy labels#ANIMAL#Accuracy#84.7$Learning with noisy labels#ANIMAL#Network#ConvNeXt$Learning with noisy labels#ANIMAL#ImageNet Pretrained#NO$Learning with noisy labels#ANIMAL#Accuracy#84.6$Learning with noisy labels#ANIMAL#Network#Vgg19-BN$Learning with noisy labels#ANIMAL#Accuracy#82.3$Learning with noisy labels#ANIMAL#Network#ResNet$Learning with noisy labels#CIFAR-10#Test Accuracy#95.9$Learning with noisy labels#CIFAR-100#Test Accuracy#77.19$Learning with noisy labels#Red MiniImageNet 20% label noise#Test Accuracy#60.89$Learning with noisy labels#Red MiniImageNet 20% label noise#Test Accuracy#58.38$Learning with noisy labels#Red MiniImageNet 40% label noise#Test Accuracy#56.37$Learning with noisy labels#Red MiniImageNet 40% label noise#Test Accuracy#52.24$Learning with noisy labels#Red MiniImageNet 80% label noise#Test Accuracy#44.03$Learning with noisy labels#Red MiniImageNet 80% label noise#Test Accuracy#39.62$Learning with noisy labels#Red MiniImageNet 60% label noise#Test Accuracy#53.21$Learning with noisy labels#Red MiniImageNet 60% label noise#Test Accuracy#47.96
2203.01726v3.pdf	Image Classification#Tiger-beetle-image-dataset#Accuracy#93.2$Image Classification#EILAT#Accuracy#99.7$Image Classification#Florida Wildlife Camera Trap Dataset#Accuracy#93.2$Image Classification#RSMAS#Accuracy#1$Image Classification#Data for: Deep Learning Classification of Lake Zooplankton#Accuracy#99.6$Fine-Grained Image Classification#Stanford Dogs#Accuracy#97.2%$Fine-Grained Image Classification#NABirds#Accuracy#93.5%
2205.04095v1.pdf	Image Classification#Imagenette#Accuracy#69.7$Image Classification#CIFAR-10#Percentage correct#73.5
2206.04673v2.pdf	Image Classification#OmniBenchmark#Average Top-1 Accuracy#47.6
1902.00751v2.pdf	Image Classification#OmniBenchmark#Average Top-1 Accuracy#44.5
2009.07995v1.pdf	Image Classification#OmniBenchmark#Average Top-1 Accuracy#36.1$Image Classification#WebVision-1000#Top-1 Accuracy#73.9%$Image Classification#WebVision-1000#Top-5 Accuracy#90.0%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#67.8%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#87.0%
1911.05722v3.pdf	Image Classification#OmniBenchmark#Average Top-1 Accuracy#34.8$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#68.6%$Self-Supervised Image Classification#ImageNet#Number of Params#375M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#65.4%$Self-Supervised Image Classification#ImageNet#Number of Params#94M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#60.6%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#47.1%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#77.3%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#77.0%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#60.6
2112.02960v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#81.84$Image Classification#mini WebVision 1.0#Top-5 Accuracy#94.12$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.48$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.76
2112.01197v3.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#81.47$Image Classification#mini WebVision 1.0#Top-5 Accuracy#94.03$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.45$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.11$Image Classification#Clothing1M#Accuracy#75.19%$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 20% Sym. label noise)#96.7%$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 50% Sym. label noise)#96.3%$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 80% Sym. label noise)#94.7%$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 90% Sym. label noise)#84.0%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#96.01$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#74.08$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#93.65$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#96.11
2111.11288v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#80.92$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.80$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.76$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.76$Image Classification#Clothing1M#Accuracy#74.91$Learning with noisy labels#ANIMAL#Accuracy#88.5$Learning with noisy labels#ANIMAL#Network#Vgg19-BN$Learning with noisy labels#ANIMAL#ImageNet Pretrained#NO
2111.11652v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#80.88$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.48$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#76.52$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.96$Image Classification#mini WebVision 1.0#Top-1 Accuracy#80.12$Image Classification#mini WebVision 1.0#Top-5 Accuracy#93.52$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#77.24$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#92.48
2202.02200v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#80.5$Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.4$Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.1$Image Classification#WebVision-1000#Top-1 Accuracy#76.8$Image Classification#WebVision-1000#Top-1 Accuracy#75.7%
2202.05613v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#80.44$Image Classification#mini WebVision 1.0#Top-5 Accuracy#93.36$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#77.36$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.48$Image Classification#mini WebVision 1.0#Top-1 Accuracy#78.08$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.96$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.72$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#92.52$Image Classification#WebVision-1000#Top-1 Accuracy#75.4%$Image Classification#WebVision-1000#Top-5 Accuracy#91.5%
2203.04181v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.96$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.64$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#76.84$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.04
2103.13646v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.42 ± 0.34$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.32 ± 0.33$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#78.57 ± 0.37$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.04 ± 0.10$Image Classification#Clothing1M#Accuracy#74.58 ± 0.15%$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 20% Sym. label noise)#96.74 ± 0.12$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 50% Sym. label noise)#95.55 ± 0.32$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 80% Sym. label noise)#93.11 ± 0.70$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 90% Sym. label noise)#89.30 ± 0.21$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 95% Sym. label noise)#80.21 ± 1.91$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 20% Sym. label noise)#96.23 ± 0.09$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 50% Sym. label noise)#95.15 ± 0.16$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 80% Sym. label noise)#94.30 ± 0.12$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 90% Sym. label noise)#93.42 ± 0.09$Image Classification#CIFAR-10 (with noisy labels)#Accuracy (under 95% Sym. label noise)#87.72 ± 2.21
2207.14476v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.36$Image Classification#mini WebVision 1.0#Top-5 Accuracy#93.64$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#76.08$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#93.86$Image Classification#Clothing1M#Accuracy#75.4%
2105.04522v4.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.28$Image Classification#mini WebVision 1.0#Top-5 Accuracy#91.22$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.50$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.27
2108.11035v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#79.16$Image Classification#mini WebVision 1.0#Top-5 Accuracy#91.84$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#74.44$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.04
2103.04173v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#78.92$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.32$Image Classification#Food-101N#Accuracy#87.39%$Image Classification#Clothing1M#Accuracy#74.38%
2012.04462v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#78.76
2007.00151v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.78$Image Classification#mini WebVision 1.0#Top-5 Accuracy#91.68$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#70.29$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#89.76$Image Classification#Clothing1M#Accuracy#74.81%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#94.43$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#91.46$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#94.20$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#91.61$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#94.34$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#91.41$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#66.72$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#58.94$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#91.09$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#83.58$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#94.83$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#92.38
2103.11395v3.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.72
2108.11569v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.64$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.44$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#74.64$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#92.48
2106.00445v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.53
2112.03694v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.52$Image Classification#Chaoyang#Accuracy#83.4$Learning with noisy labels#Chaoyang#ACCURACY#83.4
2108.08212v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.41$Image Classification#mini WebVision 1.0#Top-5 Accuracy#92.25$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#74.09$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#92.09
2002.07394v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#77.32$Image Classification#mini WebVision 1.0#Top-5 Accuracy#91.64$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#75.20$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.64$Image Classification#mini WebVision 1.0#Top-1 Accuracy#76.32 ±0.36$Image Classification#mini WebVision 1.0#Top-5 Accuracy#90.65 ±0.16$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#74.42 ±0.29$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.21 ±0.12$Image Classification#mini WebVision 1.0#Top-1 Accuracy#76.08$Image Classification#Clothing1M#Accuracy#74.76%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#90.18$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#90.90$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#89.97$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#71.13$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#92.56$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#86.68
1911.09781v3.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#76.0$Image Classification#mini WebVision 1.0#Top-5 Accuracy#90.2$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#72.9$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.1$Image Classification#WebVision-1000#Top-1 Accuracy#74.3%$Image Classification#WebVision-1000#Top-5 Accuracy#90.5%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#67.5%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#87.2%
2009.08325v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#75.16$Image Classification#mini WebVision 1.0#Top-5 Accuracy#90.77$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#71.73$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#91.61
2003.10647v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#74.6$Image Classification#mini WebVision 1.0#Top-5 Accuracy#90.6$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#66.7$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#86.3
2011.07451v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#72.40$Image Classification#mini WebVision 1.0#Top-5 Accuracy#89.56$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#67.36$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#87.84
1905.05040v1.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#65.2$Image Classification#mini WebVision 1.0#Top-5 Accuracy#85.3$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#61.6$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#85.0
1804.06872v3.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#63.58$Image Classification#mini WebVision 1.0#Top-5 Accuracy#85.20$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#61.48$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#84.70$Image Classification#Clothing1M#Accuracy#70.15%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#90.33$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#90.30$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#90.15$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#60.37$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#83.83$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.20
1806.02612v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#62.68$Image Classification#mini WebVision 1.0#Top-5 Accuracy#84.00$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#57.80$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#81.36$Image Classification#Clothing1M#Accuracy#69.47%
1609.03683v2.pdf	Image Classification#mini WebVision 1.0#Top-1 Accuracy#61.12$Image Classification#mini WebVision 1.0#Top-5 Accuracy#82.68$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#57.36$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#82.36$Image Classification#Clothing1M (using clean data)#Accuracy#80.27$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#87.14$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#86.88$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#86.28$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#86.14$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#87.04$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#86.86$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.14$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.01$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#79.79$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#77.61$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#88.24$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#88.13
2109.14563v1.pdf	Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#80.84$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#97.24
1712.05055v2.pdf	Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#63.8$Image Classification#mini WebVision 1.0#ImageNet Top-5 Accuracy#85.8$Image Classification#WebVision-1000#Top-1 Accuracy#70.8%$Image Classification#WebVision-1000#Top-5 Accuracy#88.0%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#62.5%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#83.0%
2006.13554v1.pdf	Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#62.64$Image Classification#mini WebVision 1.0#ImageNet Top-1 Accuracy#62.36
1711.07131v2.pdf	Image Classification#Food-101N#Accuracy#90.39$Image Classification#Clothing1M (using clean data)#Accuracy#79.90
2008.05248v1.pdf	Image Classification#CelebA 64x64#Accuracy#0.82$Image Classification#CelebA 64x64#Accuracy#0.81$Image Classification#CelebA 64x64#Accuracy#0.67
2106.04919v1.pdf	Image Classification#SIPaKMeD#Accuracy#97.87$Image Classification#HErlev#Accuracy#98.32
2004.02042v1.pdf	Image Classification#ObjectNet (Bounding Box)#Top 5 Accuracy#61.5
2111.14932v2.pdf	Image Classification#Clothing1M#Accuracy#77.83%
1911.03809v2.pdf	Image Classification#Clothing1M#Accuracy#75.78%
2103.02130v3.pdf	Image Classification#Clothing1M#Accuracy#75.11%
2206.13140v1.pdf	Image Classification#Clothing1M#Accuracy#75%
2104.13766v1.pdf	Image Classification#Clothing1M#Accuracy#74.9%$Learning with noisy labels#ANIMAL#Accuracy#81.3$Learning with noisy labels#ANIMAL#Network#Vgg19-BN$Learning with noisy labels#ANIMAL#ImageNet Pretrained#NO
2102.11628v3.pdf	Image Classification#Clothing1M#Accuracy#74.37%$Image Classification#WebVision#Top 1 Accuracy#77.28$Image Classification#WebVision#Top 5 Accuracy#91.44
2106.04149v6.pdf	Image Classification#Clothing1M#Accuracy#74.24%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#90.29$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#90.37$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#90.13$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#58.59$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.97
2012.11854v2.pdf	Image Classification#Clothing1M#Accuracy#74.17%
2003.06729v1.pdf	Image Classification#Clothing1M#Accuracy#73.82%
2008.06218v1.pdf	Image Classification#Clothing1M#Accuracy#73.8%
1902.07379v6.pdf	Image Classification#Clothing1M#Accuracy#73.72%
1903.07788v1.pdf	Image Classification#Clothing1M#Accuracy#73.49%
1812.05214v2.pdf	Image Classification#Clothing1M#Accuracy#73.47%
2102.05291v2.pdf	Image Classification#Clothing1M#Accuracy#73.39%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#90.93$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#90.75$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#90.74$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#61.73$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#85.36$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.97
2104.08984v1.pdf	Image Classification#Clothing1M#Accuracy#73.36%$Image Classification#Clothing1M#Accuracy#73.35%$Image Classification#Clothing1M#Accuracy#73.27%
1905.11233v9.pdf	Image Classification#Clothing1M#Accuracy#73.3%
2010.02347v2.pdf	Image Classification#Clothing1M#Accuracy#73.24%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#94.45$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#89.66$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#94.88$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#89.91$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#94.74$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#89.79$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#61.15$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#55.72$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#91.66$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#83.60$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#95.25$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.23
1903.12141v9.pdf	Image Classification#Clothing1M#Accuracy#73.2%
2011.03687v3.pdf	Image Classification#Clothing1M#Accuracy#73.09%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#89.70$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#89.79$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#89.55$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.10$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#82.53$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.64
1903.02152v2.pdf	Image Classification#Clothing1M#Accuracy#73.07%
1909.03388v2.pdf	Image Classification#Clothing1M#Accuracy#72.46%
2106.15292v2.pdf	Image Classification#Clothing1M#Accuracy#72.28%$Image Classification#Clothing1M#Accuracy#68.94%
1803.11364v1.pdf	Image Classification#Clothing1M#Accuracy#72.23%
2011.10077v1.pdf	Image Classification#Clothing1M#Accuracy#71.74%
1805.08193v2.pdf	Image Classification#Clothing1M#Accuracy#71.1%
1908.06112v1.pdf	Image Classification#Clothing1M#Accuracy#71.02%
1904.11238v2.pdf	Image Classification#Clothing1M#Accuracy#71%
2012.05458v1.pdf	Image Classification#Clothing1M#Accuracy#70.63%
2003.02752v3.pdf	Image Classification#Clothing1M#Accuracy#70.3%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#90.30$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#90.21$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#90.11$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#59.97$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#83.37$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.44
1805.07836v4.pdf	Image Classification#Clothing1M#Accuracy#69.75%$Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#87.61$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#87.70$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#87.58$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#56.73$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#80.66$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#87.85
2010.06866v2.pdf	Image Classification#VTAB-1k#Top-1 Accuracy#77.6
1910.04867v2.pdf	Image Classification#VTAB-1k#Top-1 Accuracy#72.7$Image Classification#VTAB-1k#Top-1 Accuracy#71.5$Image Classification#VTAB-1k#Top-1 Accuracy#71.2$Image Classification#VTAB-1k#Top-1 Accuracy#67.5$Image Classification#VTAB-1k#Top-1 Accuracy#67.0$Image Classification#VTAB-1k#Top-1 Accuracy#65.6$Image Classification#VTAB-1k#Top-1 Accuracy#64.8$Image Classification#VTAB-1k#Top-1 Accuracy#63.9$Image Classification#VTAB-1k#Top-1 Accuracy#61.6$Image Classification#VTAB-1k#Top-1 Accuracy#59.5$Image Classification#VTAB-1k#Top-1 Accuracy#59.2$Image Classification#VTAB-1k#Top-1 Accuracy#59.1$Image Classification#VTAB-1k#Top-1 Accuracy#57.5$Image Classification#VTAB-1k#Top-1 Accuracy#51.1$Image Classification#VTAB-1k#Top-1 Accuracy#50.8$Image Classification#VTAB-1k#Top-1 Accuracy#44.0$Image Classification#VTAB-1k#Top-1 Accuracy#42.1$Image Classification#VTAB-1k#Top-1 Accuracy#37.5$Image Classification#VTAB-1k#Top-1 Accuracy#37.3$Image Classification#VTAB-1k#Top-1 Accuracy#35.3$Image Classification#VTAB-1k#Top-1 Accuracy#32.0$Image Classification#VTAB-1k#Top-1 Accuracy#31.0
2009.13239v1.pdf	Image Classification#VTAB-1k#Top-1 Accuracy#72.3
1912.02783v2.pdf	Image Classification#VTAB-1k#Top-1 Accuracy#70.4
2001.07685.pdf	Image Classification#STL-10#Percentage correct#94.83$Image Classification#STL-10#Percentage correct#94.77$Image Classification#STL-10#Percentage correct#92.34$Image Classification#STL-10#Percentage correct#92.02$Image Classification#STL-10#Percentage correct#89.59$Image Classification#STL-10#Percentage correct#78.57$Image Classification#STL-10#Percentage correct#73.77$Image Classification#STL-10#Percentage correct#72.01
1906.00910v2.pdf	Image Classification#STL-10#Percentage correct#94.5$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#68.1%$Self-Supervised Image Classification#ImageNet#Number of Params#626M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#63.5%
1911.09785v2.pdf	Image Classification#STL-10#Percentage correct#93.82$Image Classification#STL-10#Percentage correct#93.23$Image Classification#STL-10#Percentage correct#89.82$Image Classification#STL-10#Percentage correct#77.80$Image Classification#STL-10#Percentage correct#74.30$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#19.10$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#93.82$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#97.17$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#27.43±0.31$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#44.28±2.06$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#5.14$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#6.27$Semi-Supervised Image Classification#cifar10, 250 Labels#Percentage correct#93.73
2009.00104v1.pdf	Image Classification#STL-10#Percentage correct#93.80$Image Classification#STL-10#Percentage correct#92.15$Image Classification#STL-10#Percentage correct#78.36$Image Classification#STL-10#Percentage correct#61
2007.01472v1.pdf	Image Classification#STL-10#Percentage correct#93.19$Image Classification#STL-10#Percentage correct#88.03$Image Classification#STL-10#Percentage correct#71.65$Image Classification#STL-10#Percentage correct#71.05$Image Classification#STL-10#Percentage correct#68.62
1910.11093v2.pdf	Image Classification#STL-10#Percentage correct#91.49
1905.00135v1.pdf	Image Classification#STL-10#Percentage correct#90.45
1911.08251v2.pdf	Image Classification#STL-10#Percentage correct#90.20$Image Classification#STL-10#Percentage correct#89.43$Image Classification#STL-10#Percentage correct#88.95$Image Classification#STL-10#Percentage correct#88.83$Image Classification#STL-10#Percentage correct#87.26
1709.03698v2.pdf	Image Classification#STL-10#Percentage correct#85.5$Image Classification#STL-10#Percentage correct#84.6$Image Classification#STL-10#Percentage correct#83.7
1807.11407v1.pdf	Image Classification#STL-10#Percentage correct#84.10$Image Classification#STL-10#Percentage correct#82.00$Image Classification#STL-10#Percentage correct#74.33
1905.11786v3.pdf	Image Classification#STL-10#Percentage correct#81.9
2003.05569v1.pdf	Image Classification#STL-10#Percentage correct#81.04$Image Classification#STL-10#Percentage correct#79.3$Image Classification#STL-10#Percentage correct#78.65$Image Classification#STL-10#Percentage correct#76.49$Image Classification#STL-10#Percentage correct#75.57$Image Classification#STL-10#Percentage correct#72.66
1804.04272v2.pdf	Image Classification#STL-10#Percentage correct#78.3$Image Classification#STL-10#Percentage correct#77.0$Image Classification#STL-10#Percentage correct#74.3
1611.06430v1.pdf	Image Classification#STL-10#Percentage correct#77.8$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#77.80
1703.08961v2.pdf	Image Classification#STL-10#Percentage correct#76.6$Image Classification#STL-10#Percentage correct#75.7$Image Classification#STL-10#Percentage correct#74.33$Image Classification#STL-10#Percentage correct#70.7$Image Classification#STL-10#Percentage correct#64.6$Image Classification#STL-10#Percentage correct#60.2
1511.06241v2.pdf	Image Classification#STL-10#Percentage correct#74.1$Image Classification#MNIST#Percentage error#1.4
2006.12360.pdf	Image Classification#STL-10#Percentage correct#71.12$Image Classification#STL-10#Percentage correct#69.15$Image Classification#STL-10#Percentage correct#68.19$Image Classification#STL-10#Percentage correct#63.13
1412.6597v4.pdf	Image Classification#STL-10#Percentage correct#70.2$Image Classification#CIFAR-10#Percentage correct#86.7
1412.7259v3.pdf	Image Classification#STL-10#Percentage correct#68.2$Image Classification#MNIST#Percentage error#0.4
1406.5947v1.pdf	Image Classification#STL-10#Percentage correct#68
1406.3332v2.pdf	Image Classification#STL-10#Percentage correct#62.3$Image Classification#MNIST#Percentage error#0.4$Image Classification#CIFAR-10#Percentage correct#82.2
1606.02210v1.pdf	Image Classification#STL-10#Percentage correct#61.94
1402.5766v1.pdf	Image Classification#STL-10#Percentage correct#61
2006.12456v1.pdf	Image Classification#STL-10#Percentage correct#59.45$Image Classification#STL-10#Percentage correct#59.33$Image Classification#STL-10#Percentage correct#59.13$Image Classification#STL-10#Percentage correct#58.93$Image Classification#STL-10#Percentage correct#58.84$Image Classification#STL-10#Percentage correct#58.81$Image Classification#STL-10#Percentage correct#58.15$Image Classification#STL-10#Percentage correct#57.35$Image Classification#STL-10#Percentage correct#57.31
2101.12491v2.pdf	Image Classification#smallNORB#Classification Error#1.23$Image Classification#MNIST#Percentage error#0.16$Image Classification#MNIST#Accuracy#99.84$Image Classification#MNIST#Trainable Parameters#161,824
1905.11455v3.pdf	Image Classification#smallNORB#Classification Error#1.29
1805.10807v2.pdf	Image Classification#smallNORB#Classification Error#2.2
1710.09829v2.pdf	Image Classification#smallNORB#Classification Error#3.77$Image Classification#EMNIST-Balanced#Accuracy#90.46$Image Classification#MNIST#Percentage error#0.25$Image Classification#MultiMNIST#Percentage error#5.2$Image Classification#CIFAR-10#Percentage correct#89.4
1805.04001v1.pdf	Image Classification#smallNORB#Classification Error#5.57
1702.05373v2.pdf	Image Classification#EMNIST-Digits#Accuracy (%)#96.30$Image Classification#EMNIST-Digits#Accuracy (%)#84.70$Image Classification#EMNIST-Balanced#Accuracy#78.94$Image Classification#EMNIST-Balanced#Accuracy#50.93$Image Classification#EMNIST-Letters#Accuracy#85.27$Image Classification#EMNIST-Letters#Accuracy#55.78
2101.00590v1.pdf	Image Classification#GasHisSDB#Accuracy#97.48$Image Classification#GasHisSDB#Precision#99.97$Image Classification#GasHisSDB#F1-Score#98.70$Medical Image Classification#NCT-CRC-HE-100K#Accuracy (%)#95.42$Medical Image Classification#NCT-CRC-HE-100K#F1-Score#97.39$Medical Image Classification#NCT-CRC-HE-100K#Precision#99.97$Medical Image Classification#NCT-CRC-HE-100K#Specificity#99.43
2010.03071v1.pdf	Image Classification#Stanford Cars#Accuracy#94.1$Image Classification#Flowers-102#Accuracy#98.9%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.2$Fine-Grained Image Classification#Food-101#Top 1 Accuracy#88.7$Fine-Grained Image Classification#FGVC Aircraft#Top-1#91.5$Fine-Grained Image Classification#Stanford Dogs#Accuracy#90%
1808.01097v4.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#79.3%$Image Classification#WebVision-1000#Top-5 Accuracy#93.6%$Image Classification#WebVision-1000#Top-1 Accuracy#72.1%$Image Classification#WebVision-1000#Top-5 Accuracy#89.2%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#64.8%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#84.9%$Image Classification#Clothing1M (using clean data)#Accuracy#81.5%
2111.12172v1.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#76.5%$Image Classification#WebVision-1000#Top-5 Accuracy#90.9%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#68.7$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#86.4$Image Classification#WebVision-1000#Top-1 Accuracy#75.2%$Image Classification#WebVision-1000#Top-5 Accuracy#90.3%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#67.1$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#85.6
2008.11894v1.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#75.78%$Image Classification#WebVision-1000#Top-5 Accuracy#91.07%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#70.66%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#88.46%
2010.05864v1.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#75.48%$Image Classification#WebVision-1000#Top-5 Accuracy#90.15%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#69.42%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#87.29%
2006.15766v2.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#75.0%$Image Classification#WebVision-1000#Top-5 Accuracy#90.6%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#67.1%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#86.7%
1906.12028v5.pdf	Image Classification#WebVision-1000#Top-1 Accuracy#72.2%$Image Classification#WebVision-1000#Top-5 Accuracy#89.5%$Image Classification#WebVision-1000#ImageNet Top-1 Accuracy#65.0%$Image Classification#WebVision-1000#ImageNet Top-5 Accuracy#85.1%
2111.07991v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#82.5$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Private)#81.1$Zero-Shot Transfer Image Classification#ObjectNet#Accuracy (Public)#54.5$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#78.7$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Public)#66.6$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#84.5$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Public)#75.7$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#93.9$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Public)#60.4$Zero-Shot Transfer Image Classification#ImageNet ReaL#Accuracy (Private)#88.0$Zero-Shot Transfer Image Classification#ImageNet ReaL#Accuracy (Public)#82.2$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#79.4$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Public)#37.8
2111.10050v2.pdf	Image Classification#ObjectNet#Top-1 Accuracy#82.3$Image Classification#ObjectNet#Top-1 Accuracy#72.2$Zero-Shot Transfer Image Classification#ImageNet V2#Accuracy (Private)#80.6$Zero-Shot Transfer Image Classification#ImageNet#Accuracy (Private)#85.7$Zero-Shot Transfer Image Classification#ImageNet-Sketch#Accuracy (Private)#76.1$Zero-Shot Transfer Image Classification#ImageNet-R#Accuracy (Private)#95.7$Zero-Shot Transfer Image Classification#ImageNet-A#Accuracy (Private)#85.6
2109.01903v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#72.1
2206.01161v1.pdf	Image Classification#ObjectNet#Top-5 Accuracy#73.5$Image Classification#ObjectNet#Top-1 Accuracy#52.0$Image Classification#ObjectNet#Top-5 Accuracy#70$Image Classification#ObjectNet#Top-1 Accuracy#47.1$Image Classification#ObjectNet#Top-5 Accuracy#68.3$Image Classification#ObjectNet#Top-1 Accuracy#46.5$Image Classification#ObjectNet#Top-5 Accuracy#65.8$Image Classification#ObjectNet#Top-1 Accuracy#43.2$Image Classification#ObjectNet#Top-5 Accuracy#65.1$Image Classification#ObjectNet#Top-1 Accuracy#42.2$Image Classification#ObjectNet#Top-5 Accuracy#63.7$Image Classification#ObjectNet#Top-1 Accuracy#41.4$Image Classification#ObjectNet#Top-5 Accuracy#61.7$Image Classification#ObjectNet#Top-1 Accuracy#39.3$Image Classification#ObjectNet#Top-5 Accuracy#59.5$Image Classification#ObjectNet#Top-1 Accuracy#37.4$Image Classification#ObjectNet#Top-5 Accuracy#56.6$Image Classification#ObjectNet#Top-1 Accuracy#36.3$Image Classification#ObjectNet#Top-5 Accuracy#56.4$Image Classification#ObjectNet#Top-1 Accuracy#35.1$Image Classification#ObjectNet#Top-5 Accuracy#55.8$Image Classification#ObjectNet#Top-1 Accuracy#34.3$Image Classification#ObjectNet#Top-5 Accuracy#53$Image Classification#ObjectNet#Top-1 Accuracy#31.6$Image Classification#ObjectNet#Top-5 Accuracy#48.5$Image Classification#ObjectNet#Top-1 Accuracy#31.4$Image Classification#ObjectNet#Top-5 Accuracy#47.3$Image Classification#ObjectNet#Top-1 Accuracy#28.3
2205.13147v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#51.6
2108.05887v1.pdf	Image Classification#ObjectNet#Top-1 Accuracy#50.7$Image Classification#ObjectNet#Top-1 Accuracy#49.1$Image Classification#ObjectNet#Top-1 Accuracy#48.4$Image Classification#ObjectNet#Top-1 Accuracy#42.5
2201.00057v2.pdf	Image Classification#ObjectNet#Top-1 Accuracy#42.80$Image Classification#ObjectNet#Top-1 Accuracy#42.10
2012.12265v2.pdf	Image Classification#ObjectNet#Top-5 Accuracy#61.43$Image Classification#ObjectNet#Top-1 Accuracy#39.38$Image Classification#ObjectNet#Top-5 Accuracy#48.02$Image Classification#ObjectNet#Top-1 Accuracy#27.03
1910.05577v4.pdf	Image Classification#ObjectNet#Top-5 Accuracy#50.16$Image Classification#ObjectNet#Top-1 Accuracy#31.53
2006.06049v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#28.37
2109.12909v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#25.5$Image Classification#ObjectNet#Top-1 Accuracy#20.8$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.8%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#94.5%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.7%
2103.12719v2.pdf	Image Classification#ObjectNet#Top-1 Accuracy#23.9$Image Classification#ObjectNet#Top-1 Accuracy#21.9$Image Classification#ObjectNet#Top-1 Accuracy#20.8
2204.04788v1.pdf	Image Classification#ObjectNet#Top-1 Accuracy#20.51
2205.01397v2.pdf	Image Classification#ObjectNet#Top-1 Accuracy#18.70
2107.07110v3.pdf	Image Classification#ObjectNet#Top-1 Accuracy#16.5
2204.04588v1.pdf	Image Classification#ObjectNet#Top-1 Accuracy#15.24
2011.14204v1.pdf	Image Classification#ObjectNet#Top-5 Accuracy#29.7$Image Classification#ObjectNet#Top-1 Accuracy#13.2
2008.10312v2.pdf	Image Classification#ObjectNet#Top-1 Accuracy#4.92$Unsupervised Image Classification#ObjectNet#Accuracy (%)#6.53±0.19$Unsupervised Image Classification#ObjectNet#ARI#1.59±0.04$Unsupervised Image Classification#ObjectNet#Accuracy (%)#6.47±0.07$Unsupervised Image Classification#ObjectNet#ARI#1.32±0.05$Unsupervised Image Classification#ImageNet#Accuracy (%)#46.03±0.21$Unsupervised Image Classification#ImageNet#ARI#23.94±0.16$Unsupervised Image Classification#ImageNet#Accuracy (%)#39.07±0.61$Unsupervised Image Classification#ImageNet#ARI#22.80±0.60
2205.13282v1.pdf	Image Classification#iNaturalist#Top 1 Accuracy#72.3$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.6%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.5$Fine-Grained Image Classification#Stanford Dogs#Accuracy#93.0%
2103.07976v5.pdf	Image Classification#iNaturalist#Top 1 Accuracy#71.7$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.7$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.8%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#92.3% (90.6%)$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.7%$Fine-Grained Image Classification#NABirds#Accuracy#90.8%
2008.10400v2.pdf	Image Classification#MNIST#Percentage error#0.09$Image Classification#MNIST#Accuracy#99.91
2001.09136v6.pdf	Image Classification#MNIST#Percentage error#0.13$Image Classification#MNIST#Accuracy#99.87$Image Classification#MNIST#Trainable Parameters#1,514,187
2003.08562v3.pdf	Image Classification#MNIST#Percentage error#0.16$Image Classification#MNIST#Accuracy#99.84
1202.2745v1.pdf	Image Classification#MNIST#Percentage error#0.23$Image Classification#CIFAR-10#Percentage correct#88.8
1505.03229v1.pdf	Image Classification#MNIST#Percentage error#0.23$Image Classification#CIFAR-10#Percentage correct#89.7
1904.08095v1.pdf	Image Classification#MNIST#Percentage error#0.29$Image Classification#MNIST#Accuracy#99.71$Image Classification#Fashion-MNIST#Percentage error#6.29$Image Classification#EMNIST-Letters#Accuracy#95.39
2105.09008v5.pdf	Image Classification#MNIST#Percentage error#0.29$Image Classification#MNIST#Accuracy#99.71$Image Classification#MNIST#Trainable Parameters#518,230$Image Classification#CIFAR-10#PARAMS#518,230
2203.03689v1.pdf	Image Classification#MNIST#Percentage error#0.29
2006.07220v2.pdf	Image Classification#MNIST#Percentage error#0.37$Image Classification#MNIST#Accuracy#99.63
1502.00702v2.pdf	Image Classification#MNIST#Percentage error#0.4
1908.03190v1.pdf	Image Classification#MNIST#Percentage error#0.51$Image Classification#Fashion-MNIST#Percentage error#7.6
1905.11528v3.pdf	Image Classification#MNIST#Percentage error#0.53
1404.3606v2.pdf	Image Classification#MNIST#Percentage error#0.6$Image Classification#CIFAR-10#Percentage correct#78.7
2003.12346v2.pdf	Image Classification#MNIST#Percentage error#0.6$Event data classification#CIFAR10-DVS#Accuracy#68.3
2012.03653v2.pdf	Image Classification#MNIST#Percentage error#0.6
1412.7149v4.pdf	Image Classification#MNIST#Percentage error#0.7
1603.08367v1.pdf	Image Classification#MNIST#Percentage error#0.8
1412.6572v3.pdf	Image Classification#MNIST#Percentage error#0.8
1907.04840v2.pdf	Image Classification#MNIST#Percentage error#1.26$Image Classification#CIFAR-10#Percentage correct#95.04
1911.12607v4.pdf	Image Classification#MNIST#Percentage error#1.5$Image Classification#MNIST#Accuracy#98.5
1509.06569v2.pdf	Image Classification#MNIST#Percentage error#1.8$Image Classification#MNIST#Accuracy#98.2
1804.01508v10.pdf	Image Classification#MNIST#Percentage error#1.8$Image Classification#MNIST#Accuracy#98.2
1708.00630v2.pdf	Image Classification#MNIST#Percentage error#5.0$Image Classification#MNIST#Accuracy#95.0
2111.10854v2.pdf	Image Classification#MNIST#Accuracy#99.68$Image Classification#CIFAR-10#Percentage correct#96.87
2106.08882v1.pdf	Image Classification#MNIST#Accuracy#99.27
2106.07030v2.pdf	Image Classification#MNIST#Accuracy#96.2
2202.02248v1.pdf	Image Classification#MNIST#Error rate#5.19
1701.02620v2.pdf	Image Classification#FlickrLogos-32#Accuracy#96.0$Image Classification#FlickrLogos-32#Accuracy#91.7
2105.13892v1.pdf	Image Classification#Clothing1M (using clean data)#Accuracy#77.70
2202.04291v1.pdf	Image Classification#Clothing1M (using clean data)#Accuracy#77.5 ± 0.2%
2006.09042v1.pdf	Image Classification#Fashion-MNIST#Percentage error#3.09$Image Classification#Fashion-MNIST#Accuracy#96.91$Fine-Grained Image Classification#CompCars#Accuracy#95.9%
2206.00255v1.pdf	Image Classification#Fashion-MNIST#Percentage error#7.7$Image Classification#Fashion-MNIST#Accuracy#92.3
2012.13052v2.pdf	Image Classification#LabelMe#Test Accuracy#87.12
2112.05404v1.pdf	Image Classification#Large Labelled Logo Dataset (L3D)#Eval F1#0.2786$Image Classification#Large Labelled Logo Dataset (L3D)#Eval F1#0.1155
2010.11697v3.pdf	Image Classification#ArtDL#F1#70.25%$Image Classification#ArtDL#Average Precision#72.73%
2103.10107v4.pdf	Image Classification#DF20#Top-1#80.45$Image Classification#DF20#Top-3#91.68$Image Classification#DF20#F1 - macro#0.743$Image Classification#DF20#Top-1#79.48$Image Classification#DF20#Top-3#90.95$Image Classification#DF20#F1 - macro#0.727$Image Classification#DF20#Top-1#77.13$Image Classification#DF20#Top-1#76.1$Image Classification#DF20#Top-3#88.85$Image Classification#DF20#F1 - macro#0.678$Image Classification#DF20#Top-1#75.69$Image Classification#DF20#Top-3#88.72$Image Classification#DF20#F1 - macro#0.673$Image Classification#DF20#Top-1#75.29$Image Classification#DF20#Top-3#88.34$Image Classification#DF20#F1 - macro#0.675$Image Classification#DF20#Top-1#74.26$Image Classification#DF20#Top-3#87.78$Image Classification#DF20#F1 - macro#0.66$Image Classification#DF20#Top-1#74.08$Image Classification#DF20#Top-3#87.68$Image Classification#DF20#F1 - macro#0.654$Image Classification#DF20#Top-1#74.01$Image Classification#DF20#Top-3#87.49$Image Classification#DF20#F1 - macro#0.651$Image Classification#DF20#Top-1#73.65$Image Classification#DF20#Top-1#73.49$Image Classification#DF20#Top-3#87.13$Image Classification#DF20#Top-1#73$Image Classification#DF20#Top-3#86.87$Image Classification#DF20#F1 - macro#0.637$Image Classification#DF20#Top-1#72.51$Image Classification#DF20#Top-3#86.77$Image Classification#DF20#F1 - macro#0.634$Image Classification#DF20#Top-1#72.1$Image Classification#DF20#Top-3#86.58$Image Classification#DF20#Top-1#70.33$Image Classification#DF20#Top-3#85.19$Image Classification#DF20#F1 - macro#0.613$Image Classification#DF20#Top-1#69.77$Image Classification#DF20#Top-3#85.01$Image Classification#DF20#Top-1#67.13$Image Classification#DF20#Top-3#82.65$Image Classification#DF20#F1 - macro#0.580$Image Classification#DF20#Top-3#89.48$Image Classification#DF20#F1 - macro#0.693$Image Classification#DF20#Top-3#84.76$Image Classification#DF20#F1 - macro#0.60$Image Classification#DF20 - Mini#Top-1#75.85$Image Classification#DF20 - Mini#Top-3#89.95$Image Classification#DF20 - Mini#F1 - macro#0.669$Image Classification#DF20 - Mini#Top-1#74.23$Image Classification#DF20 - Mini#Top-3#89.12$Image Classification#DF20 - Mini#F1 - macro#0.639$Image Classification#DF20 - Mini#Top-1#72.23$Image Classification#DF20 - Mini#Top-1#71.04$Image Classification#DF20 - Mini#Top-3#86.15$Image Classification#DF20 - Mini#F1 - macro#0.603$Image Classification#DF20 - Mini#Top-1#69.59$Image Classification#DF20 - Mini#Top-3#85.55$Image Classification#DF20 - Mini#F1 - macro#0.59$Image Classification#DF20 - Mini#Top-1#68.87$Image Classification#DF20 - Mini#Top-3#85.14$Image Classification#DF20 - Mini#F1 - macro#0.585$Image Classification#DF20 - Mini#Top-1#68.76$Image Classification#DF20 - Mini#Top-3#85$Image Classification#DF20 - Mini#Top-1#68.49$Image Classification#DF20 - Mini#Top-3#85.22$Image Classification#DF20 - Mini#Top-1#68.35$Image Classification#DF20 - Mini#Top-3#84.67$Image Classification#DF20 - Mini#Top-1#67.94$Image Classification#DF20 - Mini#Top-3#85.71$Image Classification#DF20 - Mini#F1 - macro#0.567$Image Classification#DF20 - Mini#Top-1#67.45$Image Classification#DF20 - Mini#Top-3#82.78$Image Classification#DF20 - Mini#Top-1#67.39$Image Classification#DF20 - Mini#Top-3#83.74$Image Classification#DF20 - Mini#F1 - macro#0.55$Image Classification#DF20 - Mini#Top-1#65.91$Image Classification#DF20 - Mini#Top-3#82.97$Image Classification#DF20 - Mini#F1 - macro#0.535$Image Classification#DF20 - Mini#Top-1#65.66$Image Classification#DF20 - Mini#Top-3#83.65$Image Classification#DF20 - Mini#F1 - macro#0.531$Image Classification#DF20 - Mini#Top-1#65.58$Image Classification#DF20 - Mini#Top-1#64.67$Image Classification#DF20 - Mini#Top-3#81.42$Image Classification#DF20 - Mini#Top-1#62.91$Image Classification#DF20 - Mini#Top-3#81.65$Image Classification#DF20 - Mini#F1 - macro#0.514$Image Classification#DF20 - Mini#Top-3#87.28$Image Classification#DF20 - Mini#F1 - macro#0.62$Image Classification#DF20 - Mini#Top-3#83.52$Image Classification#DF20 - Mini#F1 - macro#0.559
1909.07075v1.pdf	Image Classification#Flowers-102#Accuracy#96.9%$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.5%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.5%$Fine-Grained Image Classification#NABirds#Accuracy#88.5%
2002.08335v2.pdf	Image Classification#QMNIST#Accuracy (%)#99.67
1810.03505v1.pdf	Image Classification#CINIC-10#Accuracy#91.45$Image Classification#CINIC-10#Accuracy#91.26$Image Classification#CINIC-10#Accuracy#90.27$Image Classification#CINIC-10#Accuracy#87.77
2106.04619v4.pdf	Image Classification#Causal3DIdent#Accuracy#1.00$Image Classification#Causal3DIdent#Accuracy#0.99
2203.11834v3.pdf	Image Classification#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#51.58$Federated Learning#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#41.62$Federated Learning#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#40.81$Federated Learning#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#39.24$Federated Learning#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#38.59$Federated Learning#CIFAR-100 (alpha=0, 20 clients per round)#ACC@1-100Clients#38.56$Federated Learning#CIFAR-100 (alpha=0.5, 10 clients per round)#ACC@1-100Clients#48.72$Federated Learning#CIFAR-100 (alpha=0.5, 10 clients per round)#ACC@1-100Clients#46.76$Federated Learning#CIFAR-100 (alpha=0.5, 10 clients per round)#ACC@1-100Clients#46.58$Federated Learning#CIFAR-100 (alpha=0.5, 10 clients per round)#ACC@1-100Clients#44.84$Federated Learning#CIFAR-100 (alpha=0.5, 10 clients per round)#ACC@1-100Clients#41.27$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#68.32$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#68.12$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#67.52$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#64.23$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#63.72$Federated Learning#Landmarks-User-160k#Acc@1-1262Clients#61.91$Federated Learning#CIFAR-100 (alpha=1000, 20 clients per round)#ACC@1-100Clients#54.5$Federated Learning#CIFAR-100 (alpha=1000, 20 clients per round)#ACC@1-100Clients#54.36$Federated Learning#CIFAR-100 (alpha=1000, 20 clients per round)#ACC@1-100Clients#54.1$Federated Learning#CIFAR-100 (alpha=1000, 20 clients per round)#ACC@1-100Clients#53.97$Federated Learning#CIFAR-100 (alpha=1000, 20 clients per round)#ACC@1-100Clients#50.66$Federated Learning#CIFAR-100 (alpha=0, 5 clients per round)#ACC@1-100Clients#42.01$Federated Learning#CIFAR-100 (alpha=0, 5 clients per round)#ACC@1-100Clients#39.3$Federated Learning#CIFAR-100 (alpha=0, 5 clients per round)#ACC@1-100Clients#36.04$Federated Learning#CIFAR-100 (alpha=0, 5 clients per round)#ACC@1-100Clients#31.04$Federated Learning#CIFAR-100 (alpha=0, 5 clients per round)#ACC@1-100Clients#30.25$Federated Learning#CIFAR-100 (alpha=1000, 5 clients per round)#ACC@1-100Clients#54.81$Federated Learning#CIFAR-100 (alpha=1000, 5 clients per round)#ACC@1-100Clients#54.01$Federated Learning#CIFAR-100 (alpha=1000, 5 clients per round)#ACC@1-100Clients#53.9$Federated Learning#CIFAR-100 (alpha=1000, 5 clients per round)#ACC@1-100Clients#53.86$Federated Learning#CIFAR-100 (alpha=1000, 5 clients per round)#ACC@1-100Clients#49.92$Federated Learning#Cityscapes heterogeneous#mIoU#49.75$Federated Learning#Cityscapes heterogeneous#mIoU#49.1$Federated Learning#Cityscapes heterogeneous#mIoU#45.96$Federated Learning#Cityscapes heterogeneous#mIoU#43.42$Federated Learning#Cityscapes heterogeneous#mIoU#43.02$Federated Learning#Cityscapes heterogeneous#mIoU#42.48$Federated Learning#Cityscapes heterogeneous#mIoU#42.27$Federated Learning#Cityscapes heterogeneous#mIoU#41.22$Federated Learning#Cityscapes heterogeneous#mIoU#38.65$Federated Learning#CIFAR-100 (alpha=1000, 10 clients per round)#ACC@1-100Clients#54.97$Federated Learning#CIFAR-100 (alpha=1000, 10 clients per round)#ACC@1-100Clients#54.79$Federated Learning#CIFAR-100 (alpha=1000, 10 clients per round)#ACC@1-100Clients#53.67$Federated Learning#CIFAR-100 (alpha=1000, 10 clients per round)#ACC@1-100Clients#53.39$Federated Learning#CIFAR-100 (alpha=1000, 10 clients per round)#ACC@1-100Clients#50.25$Federated Learning#CIFAR-100 (alpha=0.5, 5 clients per round)#ACC@1-100Clients#49.17$Federated Learning#CIFAR-100 (alpha=0.5, 5 clients per round)#ACC@1-100Clients#47.96$Federated Learning#CIFAR-100 (alpha=0.5, 5 clients per round)#ACC@1-100Clients#45.61$Federated Learning#CIFAR-100 (alpha=0.5, 5 clients per round)#ACC@1-100Clients#44.73$Federated Learning#CIFAR-100 (alpha=0.5, 5 clients per round)#ACC@1-100Clients#40.43$Federated Learning#CIFAR-100 (alpha=0, 10 clients per round)#ACC@1-100Clients#42.64$Federated Learning#CIFAR-100 (alpha=0, 10 clients per round)#ACC@1-100Clients#39.76$Federated Learning#CIFAR-100 (alpha=0, 10 clients per round)#ACC@1-100Clients#39.51$Federated Learning#CIFAR-100 (alpha=0, 10 clients per round)#ACC@1-100Clients#36.93$Federated Learning#CIFAR-100 (alpha=0, 10 clients per round)#ACC@1-100Clients#36.74$Federated Learning#CIFAR-100 (alpha=0.5, 20 clients per round)#ACC@1-100Clients#48.27$Federated Learning#CIFAR-100 (alpha=0.5, 20 clients per round)#ACC@1-100Clients#47.78$Federated Learning#CIFAR-100 (alpha=0.5, 20 clients per round)#ACC@1-100Clients#46.47$Federated Learning#CIFAR-100 (alpha=0.5, 20 clients per round)#ACC@1-100Clients#46.05$Federated Learning#CIFAR-100 (alpha=0.5, 20 clients per round)#ACC@1-100Clients#42.17
2001.07627v1.pdf	Image Classification#CIFAR-10#Percentage correct#97.54$Image Classification#CIFAR-10#PARAMS#25.6M
1610.02915v4.pdf	Image Classification#CIFAR-10#Percentage correct#96.69
2102.08098v3.pdf	Image Classification#CIFAR-10#Percentage correct#94.71$Image Classification#CIFAR-10#PARAMS#20.03M
1707.04873v2.pdf	Image Classification#CIFAR-10#Percentage correct#94.6
1911.03584v2.pdf	Image Classification#CIFAR-10#Percentage correct#93.8
2105.04319v3.pdf	Image Classification#CIFAR-10#Percentage correct#92.3
2110.08059v3.pdf	Image Classification#CIFAR-10#Percentage correct#92.2±0.1$Image Classification#CIFAR-10#PARAMS#0.67M$Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#69.87%$Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#80.82%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.72%$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.62%$Time Series#Speech Commands#% Test Accuracy#97.73$Time Series#Speech Commands#% Test Accuracy (Raw Data)#91.73
1407.3068v2.pdf	Image Classification#CIFAR-10#Percentage correct#90.8
1206.2944v2.pdf	Image Classification#CIFAR-10#Percentage correct#90.5
1207.0580v1.pdf	Image Classification#CIFAR-10#Percentage correct#84.4
2107.02239v4.pdf	Image Classification#CIFAR-10#Percentage correct#83.36$Image Classification#CIFAR-10#PARAMS#906075$Image Classification#CIFAR-10#Percentage correct#83.26$Image Classification#CIFAR-10#Percentage correct#83.19$Image Classification#CIFAR-10#Percentage correct#79.50$Image Classification#CIFAR-10#Percentage correct#76.9$Image Classification#CIFAR-10#Percentage correct#75.26$Image Classification#CIFAR-10#PARAMS#0.623706M$Image Classification#CIFAR-10#Percentage correct#74$Image Classification#CIFAR-10#PARAMS#0.990298M$Image Classification#CIFAR-10#Percentage correct#65.06$Image Classification#CIFAR-10#PARAMS#0.530970M
1911.05329v1.pdf	Image Classification#CIFAR-10#Accuracy#90.65
2011.01424v2.pdf	Knowledge Distillation#PASCAL VOC#mAP#93.17$Knowledge Distillation#PASCAL VOC#mAP#90.14$Knowledge Distillation#ImageNet#Top-1 accuracy %#71.72$Knowledge Distillation#COCO#mAP#77.16$Knowledge Distillation#COCO#mAP#73.73
1909.08097v3.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#78.79$Knowledge Distillation#ImageNet#model size#56.9M$Knowledge Distillation#ImageNet#Top-1 accuracy %#78.07$Knowledge Distillation#ImageNet#model size#40.5M$Knowledge Distillation#ImageNet#Top-1 accuracy %#76.376$Knowledge Distillation#ImageNet#model size#27M
1503.02531v1.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#77.14$Knowledge Distillation#ImageNet#model size#99M$Knowledge Distillation#ImageNet#Top-1 accuracy %#70.66
2107.13715v2.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#72.39
2102.00650v1.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#72.04
2103.16367v1.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.96
2203.08679v2.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.70
2006.07114v2.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.62
2104.09044v1.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.61
2110.09674v2.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.61
2102.02973v1.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.38
1910.10699v3.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#71.38
1904.01866v2.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#70.81
1612.03928v3.pdf	Knowledge Distillation#ImageNet#Top-1 accuracy %#70.70
2001.04732v1.pdf	Fine-Grained Image Classification#Bottles#mAP#77.4$Fine-Grained Image Classification#Con-Text#mAP#80.2
2103.11373v1.pdf	Fine-Grained Image Classification#EMNIST-Letters#Accuracy#95.86$Fine-Grained Image Classification#Fruits-360#Accuracy#99.97$Fine-Grained Image Classification#EMNIST-Digits#Accuracy#99.82$Fine-Grained Image Classification#MNIST#Accuracy#98.19$Fine-Grained Image Classification#Kuzushiji-MNIST#Accuracy#98.98$Fine-Grained Image Classification#Caltech-101#Accuracy#97.76$Fine-Grained Image Classification#Bird-225#Accuracy#99.55$Fine-Grained Image Classification#STL-10#Accuracy#98.18$Fine-Grained Image Classification#QMNIST#Accuracy#99.6867
2202.03822v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#92.8$Fine-Grained Image Classification#CUB-200-2011#Accuracy#92.8%$Fine-Grained Image Classification#NABirds#Accuracy#92.8%$Fine-Grained Image Recognition#CUB-200-2011#Accuracy#92.8
2101.06635v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.8$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.7%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#94.9%
2107.02341v3.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.6$Fine-Grained Image Classification#Stanford Dogs#Accuracy#91.5%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.6%
2003.09150v3.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.6$Fine-Grained Image Classification#Stanford Cars#Accuracy#95.0%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#94.7%
2103.02782v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.5
1901.09891v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.4$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.5%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.0%
1712.01034v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.7$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.3%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#91.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.7%
2003.14142v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.0$Fine-Grained Image Classification#Stanford Cars#Accuracy#94.5%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.7%$Image Recognition#ImageNet#Top-1 Error Rate#22.87
1903.06150v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.9$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.8%$Fine-Grained Image Classification#iNaturalist#Top 1 Accuracy#68.2
1611.09932v3.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.4$Fine-Grained Image Classification#Stanford Cars#Accuracy#93.8%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.0%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.4%
1705.08016v3.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#86.9$Fine-Grained Image Classification#Stanford Cars#Accuracy#92.86%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#83.75%$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#93.65%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#86.87%$Fine-Grained Image Classification#NABirds#Accuracy#82.79%
2110.07097v1.pdf	Fine-Grained Image Classification#Fruits-360#Accuracy (%)#99.98$Fine-Grained Image Classification#10 Monkey Species#Accuracy#99.26$Fine-Grained Image Classification#10 Monkey Species#Accuracy#98.90$Fine-Grained Image Classification#Bird-225#Accuracy#99.56$Fine-Grained Image Classification#Bird-225#Accuracy#99.38$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.36$Fine-Grained Image Classification#Oxford 102 Flowers#Accuracy#98.29
1811.07056v2.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#96.2%
2005.05123v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#95.6%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#94.1%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.9%
2002.10191v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#95.3%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.9%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#90.3%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#90.0%$Fine-Grained Image Classification#NABirds#Accuracy#88.1%
2003.03836v3.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#95.1%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.6%
2011.09040v3.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#95.1%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.6%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.9%
1911.07344v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#95.0%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.5%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.5%
1912.06842v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.9%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.5%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#87.7%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.6%
2004.02684v2.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.9%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.1%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#90.2%
1910.12423.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.8%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.5%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.2%
1909.04412v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.6%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.7%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.7%$Fine-Grained Image Classification#NABirds#Accuracy#86.4%
2003.05235v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.5%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.3%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.3%
2002.04264v3.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.4%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.9%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.3%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#86.4%
2006.13457v3.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#94.0%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.1%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#88.8%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.3%
1809.00287v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#93.9%$Fine-Grained Image Classification#FGVC Aircraft#Accuracy#91.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#87.5%
1806.05372v1.pdf	Fine-Grained Image Classification#Stanford Cars#Accuracy#93.0%
2108.13576v1.pdf	Fine-Grained Image Classification#Caltech-101#Top-1 Error Rate#4.42%$Fine-Grained Image Classification#Caltech-101#Accuracy#95.58
2205.10529v1.pdf	Fine-Grained Image Classification#FGVC Aircraft#Accuracy#93.1%$Fine-Grained Image Classification#Stanford Dogs#Accuracy#93.1%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.8%
1909.11378v2.pdf	Fine-Grained Image Classification#FGVC Aircraft#Accuracy#92.4%$Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.1%
2109.00891v1.pdf	Fine-Grained Image Classification#Oxford-IIIT Pet Dataset#Accuracy (%)#96.28
1506.08959v2.pdf	Fine-Grained Image Classification#CompCars#Accuracy#91.2%$Fine-Grained Image Classification#CompCars#Accuracy#81.9%
2205.02151v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#92.0%
2209.02109v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.9%
2208.14607v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.8%
2110.01240v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.5%
2107.06538v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.3%
2107.08192v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.3%
2102.09875v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#91.1%
2007.02080v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#90.95%
1903.02827v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#90.4%
1806.06193v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.6%
2012.04846v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.58%
1801.09057v4.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.2%$Fine-Grained Image Classification#NABirds#Accuracy#87.9%
2012.11389v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#89.1%
2101.08527v2.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.9%
2111.01628v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.66%
2101.09666v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.45%
2012.06793v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.2%
1808.04505v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#88.1%
1512.08086v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#76.6%
1407.3867v1.pdf	Fine-Grained Image Classification#CUB-200-2011#Accuracy#76.4%
1504.07889v6.pdf	Fine-Grained Image Classification#NABirds#Accuracy#79.4%
1905.02025v1.pdf	Displaced People Recognition#Human Righst Archive (HRA)#coverage#58%
2103.16725v2.pdf	Semi-Supervised Image Classification#Mini-ImageNet, 4000 Labels#Accuracy#66.55$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.89
2007.08505v1.pdf	Semi-Supervised Image Classification#Mini-ImageNet, 4000 Labels#Accuracy#60.95$Semi-Supervised Image Classification#Mini-ImageNet, 10000 Labels#Accuracy#65.21
2104.05248v1.pdf	Semi-Supervised Image Classification#Mini-ImageNet, 4000 Labels#Accuracy#53.99±0.93$Semi-Supervised Image Classification#Mini-ImageNet, 4000 Labels#Accuracy#50.54±2.20$Semi-Supervised Image Classification#Mini-ImageNet, 1000 Labels#Accuracy#44.65±0.71$Semi-Supervised Image Classification#Mini-ImageNet, 1000 Labels#Accuracy#40.65±0.23$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#3.8±0.08$Semi-Supervised Image Classification#Mini-ImageNet, 10000 Labels#Accuracy#58.75±0.76$Semi-Supervised Image Classification#Mini-ImageNet, 10000 Labels#Accuracy#57.22±0.35$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#24.45±0.12
2011.11183v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 20 Labels#Percentage error#12.33±8.47$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#6.91±1.39$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#77.46$Semi-Supervised Image Classification#CIFAR-10, 80 Labels#Percentage error#5.98$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.4%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#87.1%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#67.1%
2012.00504v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 20 Labels#Percentage error#28.1±5.5$Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#7.39±0.61$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#95.22±0.29$Semi-Supervised Image Classification#cifar-10, 10 Labels#Accuracy (Test)#70.84±8.1$Semi-Supervised Image Classification#SVHN, 40 Labels#Percentage error#3.09±0.54$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#97.7±0.03$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#5.51±0.25
2207.01066v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#4.91$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#94.53$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#26.03$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#38.67$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.11±0.02$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.25$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#58.22%$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.87$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.22$Semi-Supervised Image Classification#STL-10, 40 Labels#Accuracy#85.8
2110.08263v3.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#4.99±0.16$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#26.49±0.20$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#39.94±1.62$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.19±0.01$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#86.04%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#64.79%$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.8±0.06$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.90±0.15
2203.06915v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#5.6$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#25.07$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#37.81$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#3.96$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#74.4%$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.84$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#67.2%$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#20.58
2201.06247v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#5.69$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#27.58$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#49.23$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.16$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#5.04$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.03
2110.13740v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#6.54±0.98$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#43.17±1.29$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.23±0.20$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.78±0.26$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#22.24±0.31
2101.06480v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#6.81±1.08$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.06±0.08$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.87±0.26
2001.07685v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#11.39±3.35$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#94.83±0.63$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#97.64±0.19$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#28.64±0.24$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#49.95±3.01$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.31$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#89.13%$Semi-Supervised Image Classification#SVHN, 40 Labels#Percentage error#7.65±7.65$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#5.07±0.33$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#22.6$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#23.18±0.11
2205.05575v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 40 Labels#Percentage error#13.59±5.60$Semi-Supervised Image Classification#STL-10, 1000 Labels#Accuracy#95.65±0.20$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#97.90 ± 0.07$Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#27.07± 0.26$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#41.83± 1.22$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.65±0.17$Semi-Supervised Image Classification#SVHN, 40 Labels#Percentage error#15.37±11.81$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#97.63±0.35$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#5.56±0.42$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.22± 0.17
1912.09784v2.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.55$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.04$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#96.39$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#96.16$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.54$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#10.01$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#12.41$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#96.52$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#95.81$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#91.59$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#85.00$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#81.81
1903.03825v5.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.47$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.11$Semi-Supervised Image Classification#CIFAR-10, 2000 Labels#Accuracy#90.74$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#7.29$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#7.66$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#84.52
1908.04345v2.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.36$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#5.72$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#90.48%$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#32.87
1704.03976v2.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#96.14$Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#94.58$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#10.55$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#11.36$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#91.59$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#36.03$Semi-Supervised Image Classification#cifar10, 250 Labels#Percentage correct#63.97
1610.02242v3.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#95.58$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#12.16$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#53.12$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#38.65
1906.10343v2.pdf	Semi-Supervised Image Classification#SVHN, 1000 labels#Accuracy#94.41$Semi-Supervised Image Classification#CIFAR-10, 2000 Labels#Accuracy#85.78$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#93.5$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#11.65$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#91.68$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#82.12$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#38.7
1909.01804v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 2000 Labels#Accuracy#89.28$Semi-Supervised Image Classification#SVHN, 500 Labels#Accuracy#96.04$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#8.89$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.58%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#63.52%$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#95.76$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#85.83$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#32.77
2203.02261v3.pdf	Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#24.3$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#38.81$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#19.32
2203.10761v2.pdf	Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#25.88±0.23$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#40.25±0.95$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.77±0.09$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#20.42±0.17
2010.06668v2.pdf	Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#26.50$Semi-Supervised Image Classification#CIFAR-100, 5000 Labels#Accuracy (%)#75.14$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#7.48$Semi-Supervised Image Classification#CIFAR-100, 5000Labels#Percentage correct#75.14$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#19.17$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#89.04$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#23.22
2109.00650v1.pdf	Semi-Supervised Image Classification#CIFAR-100, 2500 Labels#Percentage error#27.18±0.21$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#44.76±0.96$Semi-Supervised Image Classification#CIFAR-100, 400 Labels#Percentage error#44.83±1.36$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.08±0.06$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#4.56±0.13$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#21.97±0.14
2006.09363v2.pdf	Semi-Supervised Image Classification#cifar-10, 10 Labels#Accuracy (Test)#95.1
2101.06329v3.pdf	Semi-Supervised Image Classification#CIFAR-100, 4000 Labels#Accuracy#59.23$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.86$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.39±0.02$Semi-Supervised Image Classification#CIFAR-10, 1000 Labels#Accuracy#91.82$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#32
2106.04527v3.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#2.87± 0.18$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.35±0.10$Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#4.99±0.08$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#22.11± 0.23
1806.05594v3.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#5
2011.10684v4.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.11$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#25.3
1912.08766v1.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#6.38$Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#96.47$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#7.6$Semi-Supervised Image Classification#CIFAR-10, 250 Labels#Percentage error#9.79$Semi-Supervised Image Classification#cifar10, 250 Labels#Percentage correct#90.21
1905.08171v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#8.72
1705.09783v3.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#14.41
1507.02672v2.pdf	Semi-Supervised Image Classification#CIFAR-10, 4000 Labels#Percentage error#20.4
2208.05688v1.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#84.3%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#83.3%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#79.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#93.1$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#80%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#77.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#71%
2006.10029v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#95.5%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#80.9%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#95.0%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#80.2%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#80.1%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#93.4%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#77.5%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.9%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.9%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#89.2%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#68.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#93.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#76.6%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#93.0%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#75.9%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#92.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#74.9%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#91.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#73.9%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#87.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#66.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#82.5%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#57.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.8%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#94.9%$Self-Supervised Image Classification#ImageNet#Number of Params#795M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.7%$Self-Supervised Image Classification#ImageNet#Number of Params#94M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#71.7%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#90.4%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#795M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#83.1%
2111.11067v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#75.5%
2101.08482v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#74%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#63%$Semi-Supervised Image Classification#ImageNet - 0.2% labeled data#ImageNet Top-1 Accuracy#43.6%
2003.12022v3.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.24%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.94%$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#23.07±0.30
1905.03670v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.23%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.21%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.82%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.72%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.39%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#82.78%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#82.41%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#81.01%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#78.53%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#53.37%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#51.56%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#47.02%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#46.96%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#45.11%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#44.90%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#44.05%
1905.09272v3.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.2%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#73.1%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#71.5%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#90.1$Self-Supervised Image Classification#ImageNet#Number of Params#305M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#63.8%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#85.3%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#63.8$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#48.7
2110.04770v1.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#91.2%$Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 1 Accuracy#72.0%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#86.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#65.0%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.7%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
2012.11552v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#90.7%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#82.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#73.8%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.2%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
1807.03748v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#84.88%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#64.03%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#48.7%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#73.6%
1905.01152v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.82%
1912.01991v1.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#83.8%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#63.6%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#63.6
1907.02544v2.pdf	Semi-Supervised Image Classification#ImageNet - 10% labeled data#Top 5 Accuracy#78.8%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#55.2%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#61.3%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#81.9%$Self-Supervised Image Classification#ImageNet#Number of Params#86M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#60.8%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#81.4%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#56.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#78.6%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#55.4%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#77.4%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#61.3
1606.04586v1.pdf	Semi-Supervised Image Classification#SVHN, 250 Labels#Accuracy#82.35$Semi-Supervised Image Classification#cifar-100, 10000 Labels#Percentage error#39.19
2204.07141v1.pdf	Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#75.7%
2011.11765v2.pdf	Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#85.3%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#63.7%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.4%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#91.8%
2111.07832v3.pdf	Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#61.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#82.3%$Self-Supervised Image Classification#ImageNet#Number of Params#307M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#72.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#81.3%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#77.7%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#87.8%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#86.6%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.8%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#85M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.4%$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.0%$Unsupervised Image Classification#ImageNet#Accuracy (%)#43.4$Unsupervised Image Classification#ImageNet#ARI#32.8
2105.04906v3.pdf	Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#79.4%$Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 1 Accuracy#54.8%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#73.2$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#91.1
2005.04966v5.pdf	Semi-Supervised Image Classification#ImageNet - 1% labeled data#Top 5 Accuracy#75.6%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#65.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#54.5%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#67.6$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#61.5
2207.10276v2.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#96.97$Learning with noisy labels#CIFAR-10N#Accuracy#97.39$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#73.39$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#96.16$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#97.39
2202.14026v2.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#95.28$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#95.31$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#95.39$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#67.81$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#93.24$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#95.61
2003.02819v1.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#89.80$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#89.35$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#89.82$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#55.84$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#82.76$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#91.57
1901.04215v3.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#89.70$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#89.47$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#89.54$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.88$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#83.26$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#90.61
1910.03231v7.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#89.06$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#88.76$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#88.57$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.59$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#82.53$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#90.75
1906.00189v2.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#88.33$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#87.71$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#87.79$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#51.55$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#80.48$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#88.52
2102.02400v4.pdf	Learning with noisy labels#CIFAR-10N-Random1#Accuracy (mean)#88.30$Learning with noisy labels#CIFAR-10N-Random2#Accuracy (mean)#88.27$Learning with noisy labels#CIFAR-10N-Random3#Accuracy (mean)#88.19$Learning with noisy labels#CIFAR-100N#Accuracy (mean)#57.80$Learning with noisy labels#CIFAR-10N-Worst#Accuracy (mean)#80.53$Learning with noisy labels#CIFAR-10N-Aggregate#Accuracy (mean)#89.70
2103.07756v3.pdf	Learning with noisy labels#ANIMAL#Accuracy#83.4$Learning with noisy labels#ANIMAL#Network#Vgg19-BN$Learning with noisy labels#ANIMAL#ImageNet Pretrained#NO$Learning with noisy labels#ANIMAL#Accuracy#79.4
2203.14542v4.pdf	Learning with noisy labels#Clothing1M (using clean data)#1:1 Accuracy#74.98
2203.14415v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#82.1%$Self-Supervised Image Classification#ImageNet#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#307M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#85.2%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#85M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.3%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#21M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#82.6%
2106.09785v2.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#81.3%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#95.5%$Self-Supervised Image Classification#ImageNet#Number of Params#87M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#79.3%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#80.8%$Self-Supervised Image Classification#ImageNet#Number of Params#49M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#79.1%
2104.02057v4.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#81.0%$Self-Supervised Image Classification#ImageNet#Number of Params#304M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.1%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.1%$Self-Supervised Image Classification#ImageNet#Number of Params#632M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#77.6%$Self-Supervised Image Classification#ImageNet#Number of Params#307M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.7%$Self-Supervised Image Classification#ImageNet#Number of Params#86M$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#304M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.1%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#86M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#83.2%
2207.06167v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#79.0%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#94.4$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#78.0%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#93.9$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.4%
2105.11527v3.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.4%
2203.08717v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.3%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#76.0%
2105.08054v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.8%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#78.2%
2203.14370v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.7%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
2012.13493v2.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.5%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
2005.10243v3.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#75.2%$Self-Supervised Image Classification#ImageNet#Number of Params#120M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#73.0%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#91.1%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#73
2010.07922v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.8%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
2107.09282v2.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.7%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#92.3%$Self-Supervised Image Classification#ImageNet#Number of Params#24M
2103.10994v3.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#74.2%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Unsupervised Image Classification#ImageNet#Accuracy (%)#41.1$Unsupervised Image Classification#ImageNet#ARI#29.5
2011.10566v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#71.3%
2112.11450v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#63.8%
1903.12355v2.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#60.2%$Self-Supervised Image Classification#ImageNet#Number of Params#24M$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy (kNN, k=20)#49.4%$Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#60.2
1901.09005v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#55.4%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#77.9%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#51.4%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#74.0%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#46.0%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#68.8%$Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#44.6%$Self-Supervised Image Classification#ImageNet#Top 5 Accuracy#68.0%
1803.07728v1.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#36.5$Self-Supervised Image Classification#ImageNet#Number of Params#86M
1611.09842v3.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#35.4%
1603.08511v5.pdf	Self-Supervised Image Classification#ImageNet#Top 1 Accuracy#32.6%
2111.09886v2.pdf	Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#658M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#87.1%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#197M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#85.4%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#88M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.0%$Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#85M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#83.8%
2203.15371v4.pdf	Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#86M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#84.1%
2205.05194v2.pdf	Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#83.2%
1905.01278v3.pdf	Self-Supervised Image Classification#ImageNet (finetuned)#Number of Params#138M$Self-Supervised Image Classification#ImageNet (finetuned)#Top 1 Accuracy#74.9%
2107.09539v4.pdf	Small Data Image Classification#CIFAR-10, 100 Labels#Accuracy (%)#43.6$Small Data Image Classification#CIFAR-10, 100 Labels#Accuracy (%)#43.16$Small Data Image Classification#CIFAR-10, 100 Labels#Accuracy (%)#38.78$Small Data Image Classification#CIFAR-10, 500 Labels#Accuracy (%)#63.13$Small Data Image Classification#CIFAR-10, 500 Labels#Accuracy (%)#62.97$Small Data Image Classification#CIFAR-10, 500 Labels#Accuracy (%)#61.66$Small Data Image Classification#CIFAR-10, 1000 Labels#Accuracy (%)#71.37$Small Data Image Classification#CIFAR-10, 1000 Labels#Accuracy (%)#70.14$Small Data Image Classification#CIFAR-10, 1000 Labels#Accuracy (%)#68.16
2003.14297v5.pdf	Small Data Image Classification#CIFAR-10, 500 Labels#Accuracy (%)#56.22$Small Data Image Classification#CUB-200-2011, 5 samples per class#Accuracy#51.52$Small Data Image Classification#CIFAR-100, 1000 Labels#Accuracy#28.55$Small Data Image Classification#CIFAR-10, 250 Labels#Top-1 accuracy %#43$Small Data Image Classification#CUB-200-2011, 30 samples per class#Accuracy#77.75
2108.13122v1.pdf	Small Data Image Classification#ImageNet 50 samples per class#1:1 Accuracy#46.36$Small Data Image Classification#ImageNet 50 samples per class#1:1 Accuracy#45.21$Small Data Image Classification#ImageNet 50 samples per class#1:1 Accuracy#44.97$Small Data Image Classification#ciFAIR-10 50 samples per class#Accuracy#58.22$Small Data Image Classification#ciFAIR-10 50 samples per class#Accuracy#57.50$Small Data Image Classification#ciFAIR-10 50 samples per class#Accuracy#56.50$Small Data Image Classification#EuroSAT 50 samples per class#Accuracy#92.09$Small Data Image Classification#EuroSAT 50 samples per class#Accuracy#91.25$Small Data Image Classification#EuroSAT 50 samples per class#Accuracy#91.15$Small Data Image Classification#CUB-200-2011, 30 samples per class#Accuracy#72.26$Small Data Image Classification#CUB-200-2011, 30 samples per class#Accuracy#71.44$Small Data Image Classification#CUB-200-2011, 30 samples per class#Accuracy#71.02$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#68.70$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#67.90$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#64.92$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#64.67$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#64.64$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#64.15$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#62.73$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#62.06$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#60.33$Small Data Image Classification#DEIC Benchmark#Average Balanced Accuracy (across datasets)#55.47
2002.12164v1.pdf	Small Data Image Classification#cifar10, 10 labels#% Test Accuracy#45.96%
1707.04916v1.pdf	Genre classification#FMA#CNN#855
1610.09204v3.pdf	Genre classification#Book Cover Dataset#Top 1 Accuracy#24.7%$Genre classification#Book Cover Dataset#Top 1 Accuracy#13.5%
2006.12070v3.pdf	Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#59.0$Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#64.2$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.4$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#96.3%
1902.09689v1.pdf	Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#54.7$Sequential Image Classification#noise padded CIFAR-10#% Test Accuracy#11.6
2110.13985v1.pdf	Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#84.65%$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.53%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.76%
1910.09890v2.pdf	Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#74.4%
2106.08928v5.pdf	Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#65.72$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#96.94
2102.02611v3.pdf	Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#63.74%$Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#62.25%$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.32%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.54%$Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.31%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98%$Time Series#Speech Commands#% Test Accuracy#95.27
1803.00144v3.pdf	Sequential Image Classification#Sequential CIFAR-10#Unpermuted Accuracy#62.2%
2008.07669v2.pdf	Sequential Image Classification#Sequential MNIST#Permuted Accuracy#98.3%
2006.04418v4.pdf	Sequential Image Classification#Sequential MNIST#Permuted Accuracy#97.83%
1710.02224v3.pdf	Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#99.2%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#94.6%
1611.00035v1.pdf	Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#96.9%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#94.1%
1511.06464v4.pdf	Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#98.2%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#88%
1504.00941v2.pdf	Sequential Image Classification#Sequential MNIST#Unpermuted Accuracy#97%$Sequential Image Classification#Sequential MNIST#Permuted Accuracy#82%
1802.03063v1.pdf	Unsupervised Image Classification#MNIST#Accuracy#98.32$Unsupervised Image Classification#SVHN#Acc#76.80$Unsupervised Image Classification#SVHN## of clusters (k)#10
1803.02627v1.pdf	Unsupervised Image Classification#MNIST#Accuracy#96.61
1511.05644v2.pdf	Unsupervised Image Classification#MNIST#Accuracy#95.9
1511.06390v2.pdf	Unsupervised Image Classification#MNIST#Accuracy#95.73
1706.00531v1.pdf	Unsupervised Image Classification#MNIST#Accuracy#94.73
2203.14309v1.pdf	Unsupervised Image Classification#ImageNet#Accuracy (%)#25$Unsupervised Image Classification#ImageNet#ARI#14
1702.08720v3.pdf	Unsupervised Image Classification#SVHN#Acc#57.30$Unsupervised Image Classification#SVHN## of clusters (k)#10
2108.13939v1.pdf	Unsupervised Image Classification#CIFAR-20#Accuracy#63.76$Unsupervised Image Classification#STL-10#Accuracy#85.11
2205.00224v2.pdf	Unsupervised Image Classification#CIFAR-20#Accuracy#56.1
1904.11093v1.pdf	Sparse Representation-based Classification#SVHN#Accuracy#67.75
1911.07747v1.pdf	Satellite Image Classification#SAT-6#Accuracy#99.84$Satellite Image Classification#SAT-4#Accuracy#99.90
1509.03602v1.pdf	Satellite Image Classification#SAT-6#Accuracy#93.92$Satellite Image Classification#SAT-6#Accuracy#76.47$Satellite Image Classification#SAT-4#Accuracy#97.95$Satellite Image Classification#SAT-4#Accuracy#81.78
2009.12931v4.pdf	Satellite Image Classification#NASA Worldview#DSC#0.6611
2003.08013v1.pdf	Superpixel Image Classification#75 Superpixel MNIST#Classification Error#0.95
2010.10876v1.pdf	Superpixel Image Classification#75 Superpixel MNIST#Classification Error#1.24
2002.05544v2.pdf	Superpixel Image Classification#75 Superpixel MNIST#Classification Error#3.81
1905.05739v1.pdf	Superpixel Image Classification#75 Superpixel MNIST#Classification Error#4.2
1711.08920v2.pdf	Superpixel Image Classification#75 Superpixel MNIST#Classification Error#4.78$Node Classification#Pubmed#Accuracy#88.88%$Node Classification#Cora#Accuracy#89.48% ± 0.31%$Node Classification#Citeseer#Accuracy#79.20%
1808.02130v1.pdf	Photo geolocation estimation#Im2GPS#Street level (1 km)#16.5$Photo geolocation estimation#Im2GPS#City level (25 km)#37.1$Photo geolocation estimation#Im2GPS#Region level (200 km)#46.6$Photo geolocation estimation#Im2GPS#Country level (750 km)#62.0$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#78.5$Photo geolocation estimation#Im2GPS#Training images#30.3M$Photo geolocation estimation#Im2GPS#Reference images#0$Photo geolocation estimation#Im2GPS3k#Street level (1 km)#10.2$Photo geolocation estimation#Im2GPS3k#City level (25 km)#26.5$Photo geolocation estimation#Im2GPS3k#Region level (200 km)#34.6$Photo geolocation estimation#Im2GPS3k#Country level (750 km)#48.6$Photo geolocation estimation#Im2GPS3k#Continent level (2500 km)#64.4$Photo geolocation estimation#Im2GPS3k#Training images#30.3M
1705.04838v1.pdf	Photo geolocation estimation#Im2GPS#Street level (1 km)#14.4$Photo geolocation estimation#Im2GPS#City level (25 km)#33.3$Photo geolocation estimation#Im2GPS#Region level (200 km)#47.7$Photo geolocation estimation#Im2GPS#Country level (750 km)#61.6$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#73.4$Photo geolocation estimation#Im2GPS#Training images#6M$Photo geolocation estimation#Im2GPS#Reference images#28M$Photo geolocation estimation#Im2GPS#Street level (1 km)#12.2$Photo geolocation estimation#Im2GPS#Region level (200 km)#44.3$Photo geolocation estimation#Im2GPS#Country level (750 km)#57.4$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#71.3$Photo geolocation estimation#Im2GPS#Reference images#0$Photo geolocation estimation#Im2GPS#Street level (1 km)#6.8$Photo geolocation estimation#Im2GPS#City level (25 km)#21.9$Photo geolocation estimation#Im2GPS#Region level (200 km)#34.6$Photo geolocation estimation#Im2GPS#Country level (750 km)#49.4$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#63.7$Photo geolocation estimation#Im2GPS3k#Street level (1 km)#7.2$Photo geolocation estimation#Im2GPS3k#City level (25 km)#19.4$Photo geolocation estimation#Im2GPS3k#Region level (200 km)#26.9$Photo geolocation estimation#Im2GPS3k#Country level (750 km)#38.9$Photo geolocation estimation#Im2GPS3k#Continent level (2500 km)#55.9$Photo geolocation estimation#Im2GPS3k#Training images#6M$Photo geolocation estimation#Im2GPS3k#Street level (1 km)#4.0$Photo geolocation estimation#Im2GPS3k#City level (25 km)#14.8$Photo geolocation estimation#Im2GPS3k#Region level (200 km)#21.4$Photo geolocation estimation#Im2GPS3k#Country level (750 km)#32.6$Photo geolocation estimation#Im2GPS3k#Continent level (2500 km)#52.4$Photo geolocation estimation#Im2GPS3k#Street level (1 km)#3.7$Photo geolocation estimation#Im2GPS3k#City level (25 km)#14.2$Photo geolocation estimation#Im2GPS3k#Region level (200 km)#21.3$Photo geolocation estimation#Im2GPS3k#Country level (750 km)#33.5$Photo geolocation estimation#Im2GPS3k#Continent level (2500 km)#52.7
1602.05314v1.pdf	Photo geolocation estimation#Im2GPS#Street level (1 km)#8.4$Photo geolocation estimation#Im2GPS#City level (25 km)#24.5$Photo geolocation estimation#Im2GPS#Region level (200 km)#37.6$Photo geolocation estimation#Im2GPS#Country level (750 km)#53.6$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#71.3$Photo geolocation estimation#Im2GPS#Training images#91M$Photo geolocation estimation#Im2GPS#Reference images#0$Photo geolocation estimation#Im2GPS#Street level (1 km)#6.3$Photo geolocation estimation#Im2GPS#City level (25 km)#18.1$Photo geolocation estimation#Im2GPS#Region level (200 km)#30.0$Photo geolocation estimation#Im2GPS#Country level (750 km)#45.6$Photo geolocation estimation#Im2GPS#Continent level (2500 km)#65.8$Photo geolocation estimation#Im2GPS#Training images#6.2M
2210.03403v1.pdf	Image Classification with Differential Privacy#ImageNet#Top 1 Accuracy#39.2
2204.13650v2.pdf	Image Classification with Differential Privacy#ImageNet#Top 1 Accuracy#32.4
2201.12328v2.pdf	Image Classification with Differential Privacy#ImageNet#Top 1 Accuracy#6.9$Image Classification with Differential Privacy#ImageNet#Top 1 Accuracy#5
1904.11486v2.pdf	Classification Consistency#ImageNet#Consistency#91.31
2103.04736v2.pdf	Temporal Metadata Manipulation Detection#Cross-View Time Dataset (Cross-Camera Split)#2-Class Accuracy#67.9$Temporal Metadata Manipulation Detection#Cross-View Time Dataset (Cross-Camera Split)#AUC#0.749$Temporal Metadata Manipulation Detection#Cross-View Time Dataset#2-Class Accuracy#81.1$Temporal Metadata Manipulation Detection#Cross-View Time Dataset#AUC#0.885
2204.11433v1.pdf	Gallbladder Cancer Detection#GBCU#10 fold Cross validation#91
2106.06418v2.pdf	Scale Generalisation#MNIST Large Scale dataset#Average Accuracy#99.32
1808.04409v1.pdf	Counterspeech Detection#Youtube counterspeech dataset#F1 score#0.715
1606.03976v5.pdf	Causal Inference#IDHP#Average Treatment Effect Error#0.27$Causal Inference#IDHP#Average Treatment Effect Error#0.28$Causal Inference#IDHP#Average Treatment Effect Error#0.4$Causal Inference#IDHP#Average Treatment Effect Error#0.42$Causal Inference#IDHP#Average Treatment Effect Error#0.79$Causal Inference#IDHP#Average Treatment Effect Error#0.93$Causal Inference#IDHP#Average Treatment Effect Error#0.96
1906.03118v1.pdf	Causal Inference#IDHP#Average Treatment Effect Error#0.31
1705.08821v2.pdf	Causal Inference#IDHP#Average Treatment Effect Error#0.46
2112.03558v1.pdf	Traffic Prediction#PeMSD7(M)#12 steps MAE#2.68$Traffic Prediction#PeMSD7(M)#12 steps RMSE#5.39$Traffic Prediction#PeMSD7(M)#12 steps MAPE#6.76$Traffic Prediction#PeMSD7#12 steps MAE#20.53$Traffic Prediction#PeMSD7#12 steps RMSE#33.84$Traffic Prediction#PeMSD7#12 steps MAPE#8.8$Traffic Prediction#PeMSD3#12 steps MAE#15.57$Traffic Prediction#PeMSD3#12 steps RMSE#27.09$Traffic Prediction#PeMSD3#12 steps MAPE#15.06$Traffic Prediction#PeMSD7(L)#12 steps MAE#2.87$Traffic Prediction#PeMSD7(L)#12 steps RMSE#5.76$Traffic Prediction#PeMSD7(L)#12 steps MAPE#7.31$Traffic Prediction#PeMSD4#12 steps MAE#19.21$Traffic Prediction#PeMSD4#12 steps RMSE#31.09$Traffic Prediction#PeMSD4#12 steps MAPE#12.76$Traffic Prediction#PeMSD8#12 steps MAE#15.45$Traffic Prediction#PeMSD8#12 steps RMSE#24.81$Traffic Prediction#PeMSD8#12 steps MAPE#9.92
2205.08689v5.pdf	Traffic Prediction#PeMSD7#12 steps MAE#19.28$Traffic Prediction#PeMSD7#12 steps RMSE#32.26$Traffic Prediction#PeMSD7#12 steps MAPE#8.36$Traffic Prediction#PeMSD3#12 steps MAE#14.55$Traffic Prediction#PeMSD3#12 steps RMSE#24.42$Traffic Prediction#PeMSD3#12 steps MAPE#14.68$Traffic Prediction#PeMSD4#12 steps MAE#18.42$Traffic Prediction#PeMSD4#12 steps RMSE#29.81$Traffic Prediction#PeMSD4#12 steps MAPE#12.27$Traffic Prediction#PeMSD8#12 steps MAE#14.03$Traffic Prediction#PeMSD8#12 steps RMSE#23.35$Traffic Prediction#PeMSD8#12 steps MAPE#9.15
2206.09112v4.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.35$Traffic Prediction#PEMS-BAY#MAE @ 12 step#1.85$Traffic Prediction#PEMS-BAY#RMSE#4.30
2206.09113v2.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.37$Traffic Prediction#PEMS-BAY#MAE @ 12 step#1.79$Traffic Prediction#PEMS-BAY#RMSE#4.20
2202.03539v1.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.42$Traffic Prediction#PeMS07#MAE@1h#21.62
1912.07390v1.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.47
1906.00121v1.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.53$Traffic Prediction#PEMS-BAY#MAE @ 12 step#1.95$Traffic Prediction#PEMS-BAY#RMSE#4.52$Traffic Prediction#PeMS07#MAE@1h#26.85
1903.05631v2.pdf	Traffic Prediction#METR-LA#MAE @ 12 step#3.55$Traffic Prediction#PeMS-M#MAE (60 min)#3.38$Traffic Prediction#PeMS-M#MAE (60 min)#7.036
2202.03630v2.pdf	Traffic Prediction#PeMSD7 (10 days' training data, 15min)#MAE#20.91$Traffic Prediction#PeMSD7 (10 days' training data, 15min)#RMSE#31.85$Traffic Prediction#PeMSD7 (10 days' training data, 15min)#MAPE#8.95$Traffic Prediction#PeMSD8 (10 days' training data, 60min)#MAE#18.84$Traffic Prediction#PeMSD8 (10 days' training data, 60min)#RMSE#28.06$Traffic Prediction#PeMSD8 (10 days' training data, 60min)#MAPE#11.72$Traffic Prediction#PeMSD7 (10 days' training data, 30min)#MAE#22.96$Traffic Prediction#PeMSD7 (10 days' training data, 30min)#RMSE#34.8$Traffic Prediction#PeMSD7 (10 days' training data, 30min)#MAPE#9.87$Traffic Prediction#PeMSD4 (10 days' training data, 15min)#MAE#19.25$Traffic Prediction#PeMSD4 (10 days' training data, 15min)#RMSE#28.91$Traffic Prediction#PeMSD4 (10 days' training data, 15min)#MAPE#13.30$Traffic Prediction#PeMSD4 (10 days' training data, 60min)#MAE#22.82$Traffic Prediction#PeMSD4 (10 days' training data, 60min)#RMSE#33.77$Traffic Prediction#PeMSD4 (10 days' training data, 60min)#MAPE#16.1$Traffic Prediction#PeMSD7 (10 days' training data, 60min)#MAE#26.88$Traffic Prediction#PeMSD7 (10 days' training data, 60min)#RMSE#40.12$Traffic Prediction#PeMSD7 (10 days' training data, 60min)#MAPE#11.75$Traffic Prediction#PeMSD4 (10 days' training data, 30min)#MAE#20.67$Traffic Prediction#PeMSD4 (10 days' training data, 30min)#RMSE#30.78$Traffic Prediction#PeMSD4 (10 days' training data, 30min)#MAPE#14.56$Traffic Prediction#PeMSD8 (10 days' training data, 15min)#MAE#15.26$Traffic Prediction#PeMSD8 (10 days' training data, 15min)#RMSE#22.7$Traffic Prediction#PeMSD8 (10 days' training data, 15min)#MAPE#9.64$Traffic Prediction#PeMSD8 (10 days' training data, 30min)#MAE#16.41$Traffic Prediction#PeMSD8 (10 days' training data, 30min)#RMSE#24.57$Traffic Prediction#PeMSD8 (10 days' training data, 30min)#MAPE#10.46
2104.13414v2.pdf	Traffic Prediction#PEMS-BAY#RMSE#4.44
2209.01967v1.pdf	Traffic Prediction#PeMSD4#12 steps MAE#18.70$Traffic Prediction#PeMSD8#12 steps MAE#14.85
2007.02842v2.pdf	Traffic Prediction#PeMS04#12 Steps MAE#19.83
1806.07380v1.pdf	Traffic Prediction#Q-Traffic#MAPE#8.63
1903.00919v1.pdf	Traffic Prediction#PeMS-M#MAE (60 min)#3.65
2012.09641v2.pdf	Traffic Prediction#PeMS07#MAE@1h#22.07
2106.12931v1.pdf	Traffic Prediction#PeMS07#MAE@1h#22.99
2005.09409v2.pdf	Voice Conversion#ZeroSpeech 2019 English#Speaker Similarity#3.8$Voice Conversion#ZeroSpeech 2019 English#Speaker Similarity#3.49
2011.14654v2.pdf	Out-of-Distribution Detection#Fashion-MNIST#AUROC#0.996$Out-of-Distribution Detection#CIFAR-10#AUROC#99.5$Out-of-Distribution Detection#ImageNet dogs vs ImageNet non-dogs#AUROC#93.1$Out-of-Distribution Detection#MS-1M vs. IJB-C#AUROC#86.7
2110.09246v1.pdf	Out-of-Distribution Detection#CIFAR-100 vs LSUN (R)#AUROC#99.7$Out-of-Distribution Detection#CIFAR-100 vs LSUN (R)#AUROC#99.6$Out-of-Distribution Detection#CIFAR-10 vs SVHN#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs SVHN#AUROC#99.8$Out-of-Distribution Detection#SVHN vs ImageNet (R)#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs ImageNet (R)#AUROC#99.9$Out-of-Distribution Detection#CIFAR-100 vs iSUN#AUROC#99.5$Out-of-Distribution Detection#CIFAR-100 vs iSUN#AUROC#99.3$Out-of-Distribution Detection#CIFAR-10 vs LSUN (R)#AUROC#100$Out-of-Distribution Detection#SVHN vs iSUN#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs LSUN (C)#AUROC#99.9$Out-of-Distribution Detection#CIFAR-10 vs LSUN (C)#AUROC#99.5$Out-of-Distribution Detection#CIFAR-10 vs ImageNet (C)#AUROC#99.9$Out-of-Distribution Detection#CIFAR-10 vs ImageNet (C)#AUROC#99.8$Out-of-Distribution Detection#CIFAR-100 vs SVHN#AUROC#98.4$Out-of-Distribution Detection#CIFAR-100 vs SVHN#AUROC#97.9$Out-of-Distribution Detection#CIFAR-100 vs Gaussian#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs Gaussian#AUROC#100$Out-of-Distribution Detection#SVHN vs LSUN (C)#AUROC#100$Out-of-Distribution Detection#SVHN vs LSUN (C)#AUROC#99.9$Out-of-Distribution Detection#SVHN vs Uniform#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs iSUN#AUROC#100$Out-of-Distribution Detection#CIFAR-10 vs Uniform#AUROC#100$Out-of-Distribution Detection#CIFAR-100 vs LSUN (C)#AUROC#97.8$Out-of-Distribution Detection#CIFAR-100 vs LSUN (C)#AUROC#96.1$Out-of-Distribution Detection#SVHN vs ImageNet (C)#AUROC#100$Out-of-Distribution Detection#CIFAR-100 vs ImageNet (R)#AUROC#99.5$Out-of-Distribution Detection#CIFAR-100 vs ImageNet (R)#AUROC#99.2$Out-of-Distribution Detection#SVHN vs LSUN (R)#AUROC#100$Out-of-Distribution Detection#CIFAR-100 vs ImageNet (C)#AUROC#99.0$Out-of-Distribution Detection#CIFAR-100 vs ImageNet (C)#AUROC#98.4$Out-of-Distribution Detection#SVHN vs CIFAR-100#AUROC#100$Out-of-Distribution Detection#SVHN vs CIFAR-100#AUROC#99.8$Out-of-Distribution Detection#CIFAR-100 vs Uniform#AUROC#100$Out-of-Distribution Detection#SVHN vs CIFAR-10#AUROC#100$Out-of-Distribution Detection#SVHN vs CIFAR-10#AUROC#99.8$Out-of-Distribution Detection#SVHN vs Gaussian#AUROC#100
2105.07107v1.pdf	Out-of-Distribution Detection#CIFAR-10#FPR95#2.0$Out-of-Distribution Detection#CIFAR-10#AUROC#99.9$Out-of-Distribution Detection#CIFAR-100#FPR95#23.4$Out-of-Distribution Detection#CIFAR-100#AUROC#97.7$Out-of-Distribution Detection#SST#AUROC#99.7$Out-of-Distribution Detection#SST#FPR95#20.9$Out-of-Distribution Detection#TREC-NEWS#AUROC#99.9$Out-of-Distribution Detection#TREC-NEWS#FPR95#4.7$Out-of-Distribution Detection#20 Newsgroups#AUROC#99.6$Out-of-Distribution Detection#20 Newsgroups#FPR95#1.78
1906.03509v4.pdf	Out-of-Distribution Detection#CIFAR-10#AUROC#99.7$Out-of-Distribution Detection#ImageNet dogs vs ImageNet non-dogs#AUROC#92.5$Out-of-Distribution Detection#CIFAR-100#FPR95#28.89$Out-of-Distribution Detection#CIFAR-100 vs SVHN#AUROC#98.7$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#78.7$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUPR#35.2$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#82.0$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#94.9$Out-of-Distribution Detection#MS-1M vs. IJB-C#AUROC#52.6$Out-of-Distribution Detection#20 Newsgroups#AUROC#99.18
2204.02553v3.pdf	Out-of-Distribution Detection#CIFAR-10#FPR95#3.87$Out-of-Distribution Detection#CIFAR-10#AUROC#99.43$Out-of-Distribution Detection#CIFAR10#AUROC#99.3
1812.04606v3.pdf	Out-of-Distribution Detection#CIFAR-10#FPR95#9.50$Out-of-Distribution Detection#CIFAR-10#AUROC#97.8$Out-of-Distribution Detection#CIFAR-10#FPR95#34.94$Out-of-Distribution Detection#CIFAR-100#FPR95#38.50$Out-of-Distribution Detection#CIFAR-100#FPR95#62.66$Out-of-Distribution Detection#CIFAR-100 vs SVHN#AUROC#86.9$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#76.2$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#93.3
2203.10807v1.pdf	Out-of-Distribution Detection#ImageNet-1K vs ImageNet-O#AUROC#92.55$Out-of-Distribution Detection#ImageNet-1K vs ImageNet-O#FPR95#36.75$Out-of-Distribution Detection#ImageNet-1K vs OpenImage-O#AUROC#97.61$Out-of-Distribution Detection#ImageNet-1K vs OpenImage-O#FPR95#12.61
1706.02690v5.pdf	Out-of-Distribution Detection#ImageNet dogs vs ImageNet non-dogs#AUROC#90.8$Out-of-Distribution Detection#MS-1M vs. IJB-C#AUROC#61.3
2104.00269v3.pdf	Out-of-Distribution Detection#CIFAR-100 vs SVHN#AUROC#87.2
2012.05825v3.pdf	Out-of-Distribution Detection#CIFAR-10 vs CIFAR-10.1#AUROC#91.4$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#94.3$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#95.1
2106.03004v3.pdf	Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#98.11$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#97.98$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#96.23$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUPR#92.08$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#95.53$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUPR#91.89$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#95.31$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUPR#90.22$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#94.68$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#97.75$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#98.52$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#97.68$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#98.42$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#96.28$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#97.85
2003.12506v2.pdf	Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#85.6$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#95.1
2110.06207v2.pdf	Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#83.2
2007.05566v1.pdf	Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#78.3
1912.12510v2.pdf	Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#76.6$Out-of-Distribution Detection#CIFAR-100 vs CIFAR-10#AUROC#70.1$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#79.7
1905.11001v5.pdf	Out-of-Distribution Detection#STL-10#Percentage correct#95.93$Out-of-Distribution Detection#STL-10#Percentage correct#83.28$Out-of-Distribution Detection#STL-10#Percentage correct#80.57$Out-of-Distribution Detection#STL-10#Percentage correct#78.93$Out-of-Distribution Detection#STL-10#Percentage correct#73.28$Out-of-Distribution Detection#STL-10#Percentage correct#70.57
2108.08218v2.pdf	Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#91.95
1610.02136v3.pdf	Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUPR#55.8$Out-of-Distribution Detection#CIFAR-10 vs CIFAR-100#AUROC#87.9
1807.03888v2.pdf	Out-of-Distribution Detection#MS-1M vs. IJB-C#AUROC#82.5
1811.01136v2.pdf	Cross-Lingual Bitext Mining#BUCC German-to-English#F1 score#95.58$Cross-Lingual Bitext Mining#BUCC French-to-English#F1 score#92.89
1511.06709v4.pdf	Cross-Lingual Bitext Mining#BUCC German-to-English#F1 score#76.9$Cross-Lingual Bitext Mining#BUCC French-to-English#F1 score#75.8
2004.13580v1.pdf	Aspect Category Detection#Citysearch#F-measure (%)#86.4
2204.06964v1.pdf	Aspect Category Detection#SemEval 2014 Task 4 Sub Task 2#MRR#0.66$Aspect Category Detection#SemEval 2014 Task 4 Sub Task 2#Average Recall#0.72$Aspect Category Detection#SemEval 2014 Task 4 Sub Task 2#NDCG#0.66$Aspect Category Detection#SemEval 2014 Task 4 Sub Task 2#Hit@5#0.82
1906.11081v1.pdf	Graph Regression#Lipophilicity#RMSE#0.799$Graph Regression#Lipophilicity#RMSE#0.876
1803.03735v1.pdf	Graph Regression#Lipophilicity#RMSE#0.963
2210.01765v2.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0772$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.0782
2208.05863v4.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0793$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.0806
2205.12454v3.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0858$Graph Regression#ZINC-500k#MAE#0.070$Graph Regression#ZINC#MAE#0.070 ± 0.002$Graph Regression#ZINC#MAE#0.070 ± 0.004$Graph Classification#MalNet-Tiny#Accuracy#93.36 ± 0.6$Graph Classification#MNIST#Accuracy#98.05$Graph Classification#CIFAR10 100k#Accuracy (%)#72.298$Node Classification#PATTERN#Accuracy#90.324$Node Classification#CLUSTER#Accuracy#77.95$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.8015$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.7556 ± 0.0027$Graph Property Prediction#ogbg-ppa#Number of params#3434533$Graph Property Prediction#ogbg-ppa#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2907$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3015 ± 0.0038$Graph Property Prediction#ogbg-molpcba#Number of params#9744496$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7880$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8255 ± 0.0092$Graph Property Prediction#ogbg-molhiv#Number of params#558625$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-code2#Test F1 score#0.1894$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1739 ± 0.001$Graph Property Prediction#ogbg-code2#Number of params#12454066$Graph Property Prediction#ogbg-code2#Ext. data#No
2203.04810v1.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0864
2201.12787v3.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0869$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.0872
2207.02505v2.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.0910$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.0919
1810.00826v3.pdf	Graph Regression#PCQM4Mv2-LSC#Validation MAE#0.1195$Graph Regression#PCQM4Mv2-LSC#Test MAE#0.1218$Graph Regression#ZINC-500k#MAE#0.526$Graph Classification#HIV-fMRI-77#Accuracy#52.5%$Graph Classification#HIV-fMRI-77#F1#35.6%$Graph Classification#PTC#Accuracy#64.40%$Graph Classification#PROTEINS#Accuracy#76,2%$Graph Classification#NCI1#Accuracy#82.7%$Graph Classification#MUTAG#Accuracy#89.4%$Graph Classification#RE-M5K#Accuracy#57.5%$Graph Classification#IMDb-B#Accuracy#75.1%$Graph Classification#COLLAB#Accuracy#80.2%$Graph Classification#BP-fMRI-97#Accuracy#45.4%$Graph Classification#BP-fMRI-97#F1#42.3%$Graph Classification#REDDIT-B#Accuracy#92.4$Graph Classification#IMDb-M#Accuracy#52.3%$Graph Classification#CIFAR10 100k#Accuracy (%)#53.28$Graph Classification#HIV-DTI-77#Accuracy#55.1%$Graph Classification#HIV-DTI-77#F1#53.6%$Node Classification#PATTERN 100k#Accuracy (%)#85.590$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.7037 ± 0.0107$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6678 ± 0.0105$Graph Property Prediction#ogbg-ppa#Number of params#3288042$Graph Property Prediction#ogbg-ppa#Ext. data#No$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.6892 ± 0.0100$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6562 ± 0.0107$Graph Property Prediction#ogbg-ppa#Number of params#1836942$Graph Property Prediction#ogbg-molpcba#Test AP#0.2703 ± 0.0023$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2798 ± 0.0025$Graph Property Prediction#ogbg-molpcba#Number of params#3374533$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2266 ± 0.0028$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2305 ± 0.0027$Graph Property Prediction#ogbg-molpcba#Number of params#1923433$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7707 ± 0.0149$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8479 ± 0.0068$Graph Property Prediction#ogbg-molhiv#Number of params#3336306$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7558 ± 0.0140$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8232 ± 0.0090$Graph Property Prediction#ogbg-molhiv#Number of params#1885206$Graph Property Prediction#ogbg-code2#Test F1 score#0.1581 ± 0.0026$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1439 ± 0.0020$Graph Property Prediction#ogbg-code2#Number of params#13841815$Graph Property Prediction#ogbg-code2#Ext. data#No$Graph Property Prediction#ogbg-code2#Test F1 score#0.1495 ± 0.0023$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1376 ± 0.0016$Graph Property Prediction#ogbg-code2#Number of params#12390715
2206.02886v2.pdf	Graph Regression#GlassTemp#RMSE#41.2±0.8
2112.07160v2.pdf	Graph Regression#ZINC-500k#MAE#0.0698$Graph Classification#NCI109#Accuracy#83.62$Graph Classification#PTC#Accuracy#68.05%$Graph Classification#NCI1#Accuracy#84.87%$Graph Classification#ENZYMES#Accuracy#73.33
2106.12575v3.pdf	Graph Regression#ZINC-500k#MAE#0.079$Graph Regression#ZINC-500k#MAE#0.094$Graph Regression#ZINC#MAE#0.079$Graph Regression#ZINC#MAE#0.094$Graph Regression#ZINC 100k#MAE#0.094$Graph Classification#CSL#Acc#1$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8094 ± 0.0057$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8277 ± 0.0099$Graph Property Prediction#ogbg-molhiv#Number of params#239745$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8055 ± 0.0104$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8310 ± 0.0102$Graph Property Prediction#ogbg-molhiv#Number of params#138337
2202.13013v4.pdf	Graph Regression#ZINC-500k#MAE#0.084
2102.08786v2.pdf	Graph Regression#ZINC-500k#MAE#0.088$Graph Regression#ZINC-500k#MAE#0.101$Graph Regression#ZINC#MAE#0.088$Graph Regression#ZINC#MAE#0.101$Graph Classification#REDDIT-B#Accuracy#93.15$Graph Property Prediction#ogbg-molpcba#Test AP#0.2986 ± 0.0025$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3075 ± 0.0020$Graph Property Prediction#ogbg-molpcba#Number of params#6115728$Graph Property Prediction#ogbg-molpcba#Ext. data#No
2110.07875v2.pdf	Graph Regression#ZINC-500k#MAE#0.090$Graph Regression#ZINC-500k#MAE#0.095$Graph Regression#ZINC-500k#MAE#0.104
2006.09252v3.pdf	Graph Regression#ZINC-500k#MAE#0.101$Graph Regression#ZINC 100k#MAE#0.115$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8039 ± 0.0090$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8473 ± 0.0096$Graph Property Prediction#ogbg-molhiv#Number of params#114211$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7799 ± 0.0100$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8658 ± 0.0084$Graph Property Prediction#ogbg-molhiv#Number of params#3338701
2106.05234v5.pdf	Graph Regression#ZINC-500k#MAE#0.122$Graph Regression#PCQM4M-LSC#Validation MAE#0.1234$Graph Regression#PCQM4M-LSC#Test MAE#13.28$Graph Property Prediction#ogbg-molpcba#Test AP#0.3140 ± 0.0032$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3227 ± 0.0024$Graph Property Prediction#ogbg-molpcba#Number of params#119529664$Graph Property Prediction#ogbg-molpcba#Ext. data#Yes$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8225 ± 0.0001$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8396 ± 0.0001$Graph Property Prediction#ogbg-molhiv#Number of params#47085378$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8051 ± 0.0053$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8310 ± 0.0089$Graph Property Prediction#ogbg-molhiv#Number of params#47183040$Graph Property Prediction#ogbg-molhiv#Ext. data#Yes
1711.07553v2.pdf	Graph Regression#ZINC-500k#MAE#0.282$Graph Classification#CIFAR10 100k#Accuracy (%)#69.37$Node Classification#PATTERN 100k#Accuracy (%)#84.480
1905.11136v4.pdf	Graph Regression#ZINC-500k#MAE#0.303$Graph Classification#NCI109#Accuracy#82.23$Graph Classification#PTC#Accuracy#66.17%$Graph Classification#PROTEINS#Accuracy#77.20%$Graph Classification#NCI1#Accuracy#83.19%$Graph Classification#MUTAG#Accuracy#90.55%$Graph Classification#IMDb-B#Accuracy#72.6%$Graph Classification#COLLAB#Accuracy#81.38%$Graph Classification#IMDb-M#Accuracy#50%
1905.12560v1.pdf	Graph Regression#ZINC-500k#MAE#0.353
1706.02216v4.pdf	Graph Regression#ZINC-500k#MAE#0.398$Graph Classification#CIFAR10 100k#Accuracy (%)#66.08$Node Classification#Cora (3%)#Accuracy#64.2%$Node Classification#Flickr#Accuracy#0.641$Node Classification#Wiki-Vote#Accuracy#24.5$Node Classification#CiteSeer (1%)#Accuracy#51.0%$Node Classification#PATTERN 100k#Accuracy (%)#50.516$Node Classification#Citeseer Full-supervised#Accuracy#71.40%$Node Classification#USA Air-Traffic#Accuracy#31.6$Node Classification#Facebook#Accuracy#38.9$Node Classification#Pubmed Full-supervised#Accuracy#87.10%$Node Classification#Brazil Air-Traffic#Accuracy#0.404$Node Classification#PPI#F1#61.2$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#67.2%$Node Classification#PubMed (0.05%)#Accuracy#53.0%$Node Classification#PubMed (0.03%)#Accuracy#45.4%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#74.5%$Node Classification#CiteSeer (0.5%)#Accuracy#33.8%$Node Classification#Europe Air-Traffic#Accuracy#27.2$Node Classification#Cora (0.5%)#Accuracy#37.5%$Node Classification#Reddit#Accuracy#94.32%$Node Classification#Cora Full-supervised#Accuracy#82.20%$Node Classification#PubMed (0.1%)#Accuracy#65.4%$Node Classification#Cora (1%)#Accuracy#49.0%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#76.8%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#71.41 ± 1.24$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#64.85 ± 5.14$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#79.03 ± 1.20$Link Property Prediction#ogbl-ppa#Test Hits@100#0.1655 ± 0.0240$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.1724 ± 0.0264$Link Property Prediction#ogbl-ppa#Number of params#424449$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.8260 ± 0.0036$Link Property Prediction#ogbl-citation2#Validation MRR#0.8263 ± 0.0033$Link Property Prediction#ogbl-citation2#Number of params#460289$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.8044 ± 0.0010$Link Property Prediction#ogbl-citation2#Validation MRR#0.8054 ± 0.0009$Link Property Prediction#ogbl-ddi#Test Hits@20#0.5390 ± 0.0474$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.6262 ± 0.0037$Link Property Prediction#ogbl-ddi#Number of params#1421057$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.5463 ± 0.0112$Link Property Prediction#ogbl-collab#Validation Hits@50#0.5688 ± 0.0077$Link Property Prediction#ogbl-collab#Number of params#460289$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.4810 ± 0.0081
2004.05718v5.pdf	Graph Regression#ZINC#MAE#0.142$Graph Classification#CIFAR10 100k#Accuracy (%)#70.47$Node Classification#PATTERN 100k#Accuracy (%)#86.567$Graph Property Prediction#ogbg-molpcba#Test AP#0.2838 ± 0.0035$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2926 ± 0.0026$Graph Property Prediction#ogbg-molpcba#Number of params#6550839$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7905 ± 0.0132$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8519 ± 0.0099$Graph Property Prediction#ogbg-molhiv#Number of params#326081$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2012.10258v1.pdf	Graph Regression#ZINC#MAE#0.360
2010.05421v1.pdf	Graph Regression#ZINC#MAE#0.366$Graph Classification#MUTAG#Accuracy#89.9%$Graph Classification#MUTAG#Accuracy (10-fold)#89.9%$Graph Classification#IMDb-B#Accuracy#75.3%$Graph Classification#IMDb-B#Accuracy (10-fold)#75.3%$Graph Classification#COLLAB#Accuracy#81.2%$Graph Classification#COLLAB#Accuracy (10-fold)#81.2%$Node Classification#PATTERN 100k#Accuracy (%)#86.57 ± 0.02
2110.14416v2.pdf	Graph Regression#PCQM4M-LSC#Validation MAE#0.1263
2201.10005v1.pdf	Code Search#CodeSearchNet#Overall#93.5$Code Search#CodeSearchNet#Go#97.5$Code Search#CodeSearchNet#Ruby#85.5$Code Search#CodeSearchNet#Python#99.9$Code Search#CodeSearchNet#Java#94.4$Code Search#CodeSearchNet#JS#86.5$Code Search#CodeSearchNet#PHP#97.2$Code Search#CodeSearchNet#Overall#93.4$Code Search#CodeSearchNet#Go#97.7$Code Search#CodeSearchNet#Ruby#86.3$Code Search#CodeSearchNet#Python#99.8$Code Search#CodeSearchNet#Java#94.0$Code Search#CodeSearchNet#JS#86.0$Code Search#CodeSearchNet#PHP#96.7$Passage Ranking#MS MARCO#MRR@10#44.3$Passage Ranking#MS MARCO#MRR@10#22.7$Passage Ranking#MS MARCO#MRR@10#21.5$Passage Ranking#MS MARCO#MRR@10#18.4
2107.00992v3.pdf	Code Search#CodeSearchNet - Ruby#MRR#0.3639$Code Search#CodeSearchNet - Python#MRR#0.8707
2102.04664v2.pdf	Code Search#CodeXGLUE - AdvTest#MRR#27.19$Code Search#CodeXGLUE - WebQueryTest#F1#58.95$Code Search#CodeXGLUE - WebQueryTest#Accuracy#47.8$Cloze Test#CodeXGLUE - CT-maxmin#Ruby#86.84$Cloze Test#CodeXGLUE - CT-maxmin#JS#86.4$Cloze Test#CodeXGLUE - CT-maxmin#Go#90.79$Cloze Test#CodeXGLUE - CT-maxmin#Python#82.2$Cloze Test#CodeXGLUE - CT-maxmin#Java#90.46$Cloze Test#CodeXGLUE - CT-maxmin#PHP#88.21$Cloze Test#CodeXGLUE - CT-all#Ruby#80.17$Cloze Test#CodeXGLUE - CT-all#JS#81.77$Cloze Test#CodeXGLUE - CT-all#Go#83.31$Cloze Test#CodeXGLUE - CT-all#Python#87.21$Cloze Test#CodeXGLUE - CT-all#Java#80.63$Cloze Test#CodeXGLUE - CT-all#PHP#85.05
2008.12193v1.pdf	Annotated Code Search#PACS-StaQC-py#MRR#0.126$Annotated Code Search#PACS-StaQC-py#MRR#0.117$Annotated Code Search#PACS-StaQC-py#MRR#0.104$Annotated Code Search#PACS-StaQC-py#MRR#0.030$Annotated Code Search#PACS-SO-DS#MRR#0.323$Annotated Code Search#PACS-SO-DS#MRR#0.304$Annotated Code Search#PACS-SO-DS#MRR#0.244$Annotated Code Search#PACS-SO-DS#MRR#0.113$Annotated Code Search#PACS-CoNaLa#MRR#0.351$Annotated Code Search#PACS-CoNaLa#MRR#0.340$Annotated Code Search#PACS-CoNaLa#MRR#0.181$Annotated Code Search#PACS-CoNaLa#MRR#0.167
1809.05231v3.pdf	Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Dice Score#76.3$Diffeomorphic Medical Image Registration#Automatic Cardiac Diagnosis Challenge (ACDC)#Grad Det-Jac#9.2$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Dice (Average)#0.753$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#GPU sec#0.45$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#CPU (sec)#57.0$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Dice#0.79
1812.07460v2.pdf	Diffeomorphic Medical Image Registration#Automatic Cardiac Diagnosis Challenge (ACDC)#Dice#0.812$Diffeomorphic Medical Image Registration#Automatic Cardiac Diagnosis Challenge (ACDC)#RMSE#0.30$Diffeomorphic Medical Image Registration#Automatic Cardiac Diagnosis Challenge (ACDC)#Hausdorff Distance (mm)#7.3$Diffeomorphic Medical Image Registration#Automatic Cardiac Diagnosis Challenge (ACDC)#Grad Det-Jac#1.4
1903.03545v2.pdf	Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Dice (Average)#0.754$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#GPU sec#0.47$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#CPU (sec)#84.2$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Neg Jacob Det#0.2$Diffeomorphic Medical Image Registration#OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP#Dice (SE)#0.139
1904.09524v1.pdf	Diffeomorphic Medical Image Registration#CUMC12#Mean target overlap ratio#0.520$Diffeomorphic Medical Image Registration#CUMC12#Mean target overlap ratio#0.480
1910.14388v1.pdf	Graph Generation#Toulouse Road Network#StreetMover#0.0158$Graph Generation#Toulouse Road Network#StreetMover#0.0192$Graph Generation#Toulouse Road Network#StreetMover#0.0245$Graph Generation#Toulouse Road Network#StreetMover#0.0289
2202.00678v1.pdf	Interpretable Machine Learning#Skin Cancer#Accuracy (%)#86.5
2104.00680v1.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.68503
2109.12925v6.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.65606
2006.13566v2.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.65435
1711.06704v4.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.64212
1904.00889v3.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.60285
1905.03561v1.pdf	Image Matching#IMC PhotoTourism#mean average accuracy @ 10#0.36285
2209.08742v2.pdf	Semantic correspondence#SPair-71k#PCK#64.4$Geometric Matching#HPatches#Average End-Point Error#17.59
2202.06817v2.pdf	Semantic correspondence#SPair-71k#PCK#59.8$Semantic correspondence#PF-PASCAL#PCK#93.8
2108.00211v2.pdf	Semantic correspondence#SPair-71k#PCK#50.4
2106.02520v3.pdf	Semantic correspondence#SPair-71k#PCK#49.9$Semantic correspondence#PF-PASCAL#PCK#92.6$Semantic correspondence#PF-WILLOW#PCK#79.2
2103.16831v1.pdf	Semantic correspondence#SPair-71k#PCK#46.3$Semantic correspondence#PF-PASCAL#PCK#91.6$Semantic correspondence#PF-WILLOW#PCK#79.4
2007.10587v1.pdf	Semantic correspondence#SPair-71k#PCK#37.3$Semantic correspondence#Caltech-101#LT-ACC#87$Semantic correspondence#Caltech-101#IoU#62$Semantic correspondence#Caltech-101#LT-ACC (weak)#86$Semantic correspondence#Caltech-101#IoU (weak)#61$Semantic correspondence#PF-PASCAL#PCK#90.7$Semantic correspondence#PF-PASCAL#PCK (weak)#82.1$Semantic correspondence#PF-WILLOW#PCK#77.6$Semantic correspondence#PF-WILLOW#PCK (weak)#80.2
2003.12059v1.pdf	Semantic correspondence#SPair-71k#PCK#30.1$Semantic correspondence#PF-PASCAL#PCK#88.7
1908.06537v1.pdf	Semantic correspondence#SPair-71k#PCK#28.2$Semantic correspondence#Caltech-101#LT-ACC#87$Semantic correspondence#Caltech-101#IoU#63$Semantic correspondence#PF-PASCAL#PCK#88.3$Semantic correspondence#PF-WILLOW#PCK#76.3
1810.10510v2.pdf	Semantic correspondence#PF-PASCAL#PCK (weak)#78.9
2103.11247v1.pdf	Patch Matching#Brown Dataset#FPR95#0.9$Multimodal Patch Matching#VisNir#FPR95#1.44
2109.02051v2.pdf	Spoof Detection#ASVspoof 2019 - LA#EER#1.89$Spoof Detection#ASVspoof 2019 - LA#t-DCF#0.0507$Spoof Detection#ASVspoof 2019 - PA#EER#0.86$Spoof Detection#ASVspoof 2019 - PA#t-DCF#0.0239
2111.11127v1.pdf	Face Presentation Attack Detection#ROSE-YOUTU#Equal Error Rate#0.24
1909.08848v1.pdf	Face Presentation Attack Detection#WMCA#ACER#0.3
2006.16836v2.pdf	Face Presentation Attack Detection#WMCA#ACER@0.2BPCER#1.5
1909.00321v1.pdf	3D Shape Reconstruction#Pix3D#CD#0.0903$3D Shape Reconstruction#Pix3D#EMD#N/A$3D Shape Reconstruction#Pix3D#IoU#N/A
1804.04610v1.pdf	3D Shape Reconstruction#Pix3D#CD#0.119$3D Shape Reconstruction#Pix3D#EMD#0.118$3D Shape Reconstruction#Pix3D#IoU#0.282$3D Shape Classification#Pix3D#R@1#0.53$3D Shape Classification#Pix3D#R@16#0.85$3D Shape Classification#Pix3D#R@2#0.62$3D Shape Classification#Pix3D#R@32#0.90$3D Shape Classification#Pix3D#R@4#0.71$3D Shape Classification#Pix3D#R@8#0.78
2110.07882v1.pdf	3D Object Classification#ModelNet10#Accuracy#94.93$3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.42
1604.03351v2.pdf	3D Object Classification#ModelNet10#Accuracy#93.8$3D Point Cloud Classification#Sydney Urban Objects#F1#77.8
1704.02901v3.pdf	3D Object Classification#ModelNet10#Accuracy#90$3D Object Classification#ModelNet40#Accuracy#83.2$Graph Classification#NCI109#Accuracy#82.14$Graph Classification#NCI1#Accuracy#83.8%$Graph Classification#MUTAG#Accuracy#88.33%$Graph Classification#ENZYMES#Accuracy#52.67%$Graph Classification#D&D#Accuracy#74.1%$3D Point Cloud Classification#Sydney Urban Objects#F1#78.4$3D Point Cloud Classification#ModelNet40#Overall Accuracy#87.4$3D Point Cloud Classification#ModelNet40#Mean Accuracy#83.2
1812.10775v2.pdf	3D Object Classification#ModelNet40#Classification Accuracy#89.3%
2110.08636v1.pdf	3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#5.6$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#15.3$3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#6.1$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#17.7
2012.15638v2.pdf	3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#6.9$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#6.0$3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#33.8$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#0.4
2010.13136v1.pdf	3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#7.1$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#4.0
1908.04725v2.pdf	3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#7.6$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#2.3
1806.05228v2.pdf	3D Dense Shape Correspondence#SHREC'19#Euclidean Mean Error (EME)#8.1$3D Dense Shape Correspondence#SHREC'19#Accuracy at 1%#2.1
1711.03129v1.pdf	3D Shape Classification#Pix3D#R@1#0.42$3D Shape Classification#Pix3D#R@16#0.71$3D Shape Classification#Pix3D#R@2#0.51$3D Shape Classification#Pix3D#R@32#0.78$3D Shape Classification#Pix3D#R@4#0.57$3D Shape Classification#Pix3D#R@8#0.64
1610.07584v2.pdf	3D Shape Classification#Pix3D#R@1#0.02$3D Shape Classification#Pix3D#R@16#0.21$3D Shape Classification#Pix3D#R@2#0.03$3D Shape Classification#Pix3D#R@32#0.34$3D Shape Classification#Pix3D#R@4#0.07$3D Shape Classification#Pix3D#R@8#0.12$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#83.3
2210.01448v2.pdf	Gesture Generation#TED Gesture Dataset#FGD#2.04
2203.13161v1.pdf	Gesture Generation#TED Gesture Dataset#FGD#3.072
2108.00262v2.pdf	Gesture Generation#TED Gesture Dataset#FGD#3.54
2009.02119v1.pdf	Gesture Generation#TED Gesture Dataset#FGD#3.729
2104.11280v1.pdf	Video Reconstruction#Tai-Chi-HD (256)#L1#0.047$Video Reconstruction#Tai-Chi-HD (256)#AED#0.152$Video Reconstruction#Tai-Chi-HD (256)#AKD#5.58$Video Reconstruction#Tai-Chi-HD (256)#MKR#0.027$Video Reconstruction#Tai-Chi-HD (256)#L1#0.056$Video Reconstruction#Tai-Chi-HD (256)#AED#0.172$Video Reconstruction#Tai-Chi-HD (256)#AKD#6.53$Video Reconstruction#Tai-Chi-HD (256)#MKR#0.033$Video Reconstruction#MGif#L1#0.0206$Video Reconstruction#MGif#L1#0.0223$Video Reconstruction#VoxCeleb#L1#0.040$Video Reconstruction#VoxCeleb#AKD#1.28$Video Reconstruction#VoxCeleb#AED#0.133$Video Reconstruction#VoxCeleb#L1#0.041$Video Reconstruction#VoxCeleb#AKD#1.27$Video Reconstruction#VoxCeleb#AED#0.134$Video Reconstruction#Tai-Chi-HD (512)#L1#0.064$Video Reconstruction#Tai-Chi-HD (512)#AKD#13.86$Video Reconstruction#Tai-Chi-HD (512)#MKR#0.043$Video Reconstruction#Tai-Chi-HD (512)#AED#0.172$Video Reconstruction#Tai-Chi-HD (512)#L1#0.075$Video Reconstruction#Tai-Chi-HD (512)#AKD#17.12$Video Reconstruction#Tai-Chi-HD (512)#MKR#0.066$Video Reconstruction#Tai-Chi-HD (512)#AED#0.203$Video Reconstruction#TED-talks#L1#0.026$Video Reconstruction#TED-talks#AKD#3.75$Video Reconstruction#TED-talks#MKR#0.007$Video Reconstruction#TED-talks#AED#0.114$Video Reconstruction#TED-talks#L1#0.033$Video Reconstruction#TED-talks#AKD#7.07$Video Reconstruction#TED-talks#MKR#0.014$Video Reconstruction#TED-talks#AED#0.163
2003.00196v3.pdf	Video Reconstruction#Tai-Chi-HD#L1#0.063
2011.13244v3.pdf	3D Object Retrieval#ModelNet40#Mean AP#92.9$3D Object Retrieval#ShapeNetCore 55#Mean AP#82.9$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#82.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8$3D Point Cloud Classification#ModelNet40#Mean Accuracy#92.2
1909.01754v4.pdf	License Plate Recognition#SSIG-SegPlate#Rank-1 Recognition Rate#98.2$License Plate Recognition#Caltech Cars#Rank-1 Recognition Rate#98.7$License Plate Recognition#UCSD-Stills#Rank-1 Recognition Rate#98$License Plate Recognition#EnglishLP#Rank-1 Recognition Rate#95.7$License Plate Recognition#AOLP#Rank-1 Recognition Rate#99.2$License Plate Recognition#ChineseLP#Rank-1 Recognition Rate#97.5$License Plate Recognition#OpenALPR-EU#Rank-1 Recognition Rate#97.8$License Plate Recognition#UFPR-ALPR#Rank-1 Recognition Rate#90
1802.09567v6.pdf	License Plate Recognition#SSIG-SegPlate#Rank-1 Recognition Rate#85.45$License Plate Recognition#UFPR-ALPR#Rank-1 Recognition Rate#64.89
1806.10447v1.pdf	License Plate Recognition#Chinese License Plates#GFLOPs#0.34$License Plate Recognition#Chinese License Plates#GFLOPs#0.94$License Plate Recognition#Chinese License Plates#Accuracy#94.1
1910.03876v1.pdf	License Plate Recognition#AOLP-RP#Average Recall#99.18
1910.04324v1.pdf	License Plate Recognition#AOLP-RP#Average Recall#96.74
2102.08643v2.pdf	Video Semantic Segmentation#Cityscapes val#mIoU#80.3$Video Semantic Segmentation#CamVid#Mean IoU#76.5$Video Semantic Segmentation#CamVid#Mean IoU#76.2$Video Semantic Segmentation#CamVid#Mean IoU#76$Video Semantic Segmentation#CamVid#Mean IoU#74.7$Video Semantic Segmentation#CamVid#Mean IoU#67.1
1804.00389v1.pdf	Video Semantic Segmentation#Cityscapes val#mIoU#76.8
1612.08871v2.pdf	Video Semantic Segmentation#Cityscapes val#mIoU#73.6
1611.07715v2.pdf	Video Semantic Segmentation#Cityscapes val#mIoU#69.2
2012.03826v6.pdf	Hyperparameter Optimization#Bayesmark#Mean#100.117$Hyperparameter Optimization#Bayesmark#Mean#97.951
2102.03898v2.pdf	Vehicle Re-Identification#VeRi-Wild Small#mAP#86.9$Vehicle Re-Identification#VeRi-Wild Small#Rank1#96.5$Vehicle Re-Identification#VeRi-Wild Small#Rank5#99.2$Vehicle Re-Identification#VeRi-776#mAP#81.2$Vehicle Re-Identification#VeRi-776#Rank-1#96.8$Vehicle Re-Identification#VeRi-776#Rank1#96.8$Vehicle Re-Identification#VeRi-776#Rank5#98.4$Vehicle Re-Identification#VeRi-Wild Medium#mAP#82.5$Vehicle Re-Identification#VeRi-Wild Medium#Rank1#95.2$Vehicle Re-Identification#VeRi-Wild Medium#Rank5#98.3$Vehicle Re-Identification#VeRi-Wild Large#mAP#75.9$Vehicle Re-Identification#VeRi-Wild Large#Rank1#92.5$Vehicle Re-Identification#VeRi-Wild Large#Rank5#97.2$Vehicle Re-Identification#VehicleID Medium#Rank-1#82.8$Vehicle Re-Identification#VehicleID Medium#Rank-5#96.2$Vehicle Re-Identification#VehicleID Medium#Rank1#82.8$Vehicle Re-Identification#VehicleID Medium#Rank5#96.2$Vehicle Re-Identification#VehicleID Small#Rank-1#87.9$Vehicle Re-Identification#VehicleID Small#Rank-5#97.8$Vehicle Re-Identification#VehicleID Small#Rank1#87.9$Vehicle Re-Identification#VehicleID Small#Rank5#97.8$Vehicle Re-Identification#VehicleID Large#Rank-1#80.5$Vehicle Re-Identification#VehicleID Large#Rank-5#94.6$Vehicle Re-Identification#VehicleID Large#Rank1#80.5$Vehicle Re-Identification#VehicleID Large#Rank5#94.6
2110.07933v1.pdf	Vehicle Re-Identification#VeRi-776#mAP#87.4$Vehicle Re-Identification#VeRi-776#Rank-1#96.2$Vehicle Re-Identification#VeRi-776#Rank1#96.2$Vehicle Re-Identification#VeRi-776#Rank5#98.1$Vehicle Re-Identification#VehicleID Medium#mAP#81.2$Vehicle Re-Identification#VehicleID Medium#Rank-1#93.3$Vehicle Re-Identification#VehicleID Medium#Rank-5#96.9$Vehicle Re-Identification#VehicleID Small#mAP#84.8$Vehicle Re-Identification#VehicleID Small#Rank-1#95.1$Vehicle Re-Identification#VehicleID Small#Rank-5#97.4$Vehicle Re-Identification#VehicleID Large#mAP#80.5$Vehicle Re-Identification#VehicleID Large#Rank-1#92.7$Vehicle Re-Identification#VehicleID Large#Rank-5#96.5
2104.10850v1.pdf	Vehicle Re-Identification#VeRi-776#mAP#87.1$Vehicle Re-Identification#CityFlow#mAP#61.34
2004.06305.pdf	Vehicle Re-Identification#VeRi-776#mAP#83.41$Vehicle Re-Identification#VeRi-776#Rank-1#96.78$Vehicle Re-Identification#VeRi#mAP#83.41$Vehicle Re-Identification#VeRi#Rank-1#96.78$Vehicle Re-Identification#VehicleID Medium#Rank-1#81.35$Vehicle Re-Identification#VehicleID Small#Rank-1#83.64$Vehicle Re-Identification#VehicleID Large#Rank-1#79.46
2004.06305v2.pdf	Vehicle Re-Identification#VeRi-776#mAP#83.41$Vehicle Re-Identification#VeRi-776#Rank1#96.78$Vehicle Re-Identification#VehicleID#Rank1#83.64
1811.05163v1.pdf	Vehicle Re-Identification#VeRi-776#mAP#61.83$Vehicle Re-Identification#VehicleID Medium#mAP#74.63$Vehicle Re-Identification#VehicleID Small#mAP#76.54$Vehicle Re-Identification#VehicleID Large#mAP#68.41
1702.06925v3.pdf	Pain Intensity Regression#UNBC-McMaster ShoulderPain dataset#MAE#0.389
2101.03251v1.pdf	Pain Intensity Regression#UNBC-McMaster ShoulderPain dataset#Pearson Correlation Coefficient#0.71
1806.01873v2.pdf	Memex Question Answering#MemexQA#Accuracy#0.357
2204.02663v2.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#33.71$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9700$Video Inpainting#YouTube-VOS 2018 val#VFID#0.046$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.0864$Video Inpainting#DAVIS#PSNR#33.01$Video Inpainting#DAVIS#SSIM#0.9721$Video Inpainting#DAVIS#VFID#0.116$Video Inpainting#DAVIS#Ewarp#0.1315
2109.02974v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#33.29$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9681$Video Inpainting#YouTube-VOS 2018 val#VFID#0.053$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.0900$Video Inpainting#DAVIS#PSNR#32.54$Video Inpainting#DAVIS#SSIM#0.9700$Video Inpainting#DAVIS#VFID#0.138$Video Inpainting#DAVIS#Ewarp#0.1362
2007.10247v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#32.34$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9655$Video Inpainting#YouTube-VOS 2018 val#VFID#0.053$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.0907$Video Inpainting#DAVIS#PSNR#30.67$Video Inpainting#DAVIS#SSIM#0.9560$Video Inpainting#DAVIS#VFID#0.149$Video Inpainting#DAVIS#Ewarp#0.1449
1908.11587v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#31.58$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9607$Video Inpainting#YouTube-VOS 2018 val#VFID#0.071$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.1470$Video Inpainting#DAVIS#PSNR#30.28$Video Inpainting#DAVIS#SSIM#0.9521$Video Inpainting#DAVIS#VFID#0.182$Video Inpainting#DAVIS#Ewarp#0.1533
1907.01131v2.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#29.74$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9504$Video Inpainting#YouTube-VOS 2018 val#VFID#0.070$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.1859$Video Inpainting#DAVIS#PSNR#28.57$Video Inpainting#DAVIS#SSIM#0.9409$Video Inpainting#DAVIS#VFID#0.170$Video Inpainting#DAVIS#Ewarp#0.1640
2009.01835v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#29.67$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9403$Video Inpainting#YouTube-VOS 2018 val#VFID#0.064$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.1022$Video Inpainting#DAVIS#PSNR#30.80$Video Inpainting#DAVIS#SSIM#0.9497$Video Inpainting#DAVIS#VFID#0.165$Video Inpainting#DAVIS#Ewarp#0.1586
1905.01639v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#29.20$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9434$Video Inpainting#YouTube-VOS 2018 val#VFID#0.072$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.1490$Video Inpainting#DAVIS#PSNR#28.96$Video Inpainting#DAVIS#SSIM#0.9411$Video Inpainting#DAVIS#VFID#0.199$Video Inpainting#DAVIS#Ewarp#0.1785
1905.02884v1.pdf	Video Inpainting#YouTube-VOS 2018 val#PSNR#29.16$Video Inpainting#YouTube-VOS 2018 val#SSIM#0.9429$Video Inpainting#YouTube-VOS 2018 val#VFID#0.066$Video Inpainting#YouTube-VOS 2018 val#Ewarp#0.1509$Video Inpainting#DAVIS#PSNR#28.81$Video Inpainting#DAVIS#SSIM#0.9404$Video Inpainting#DAVIS#VFID#0.187$Video Inpainting#DAVIS#Ewarp#0.1608
1704.08992v1.pdf	Defocus Estimation#CUHK - Blur Detection Dataset#Blur Segmentation Accuracy#83.73
1712.01815v1.pdf	Game of Go#ELO Ratings#ELO Rating#5185$Game of Shogi#ELO Ratings#ELO Rating#4650
1910.01465v2.pdf	Multi-agent Reinforcement Learning#ParticleEnvs Cooperative Communication#final agent reward#-14
2204.05449v1.pdf	Multi-agent Reinforcement Learning#SMAC+#Median Win Rate#15
2102.07936v2.pdf	SMAC#SMAC corridor#Median Win Rate#95.4$SMAC#SMAC corridor#Average Score#20$SMAC#SMAC corridor#Median Win Rate#91.62$SMAC#SMAC corridor#Average Score#19.68$SMAC#SMAC corridor#Median Win Rate#90.45$SMAC#SMAC corridor#Average Score#19.66$SMAC#SMAC corridor#Median Win Rate#85.34$SMAC#SMAC corridor#Average Score#19.47$SMAC#SMAC corridor#Median Win Rate#84.87$SMAC#SMAC corridor#Average Score#19.42$SMAC#SMAC corridor#Median Win Rate#37.61$SMAC#SMAC corridor#Average Score#15.07$SMAC#SMAC 27m_vs_30m#Median Win Rate#91.48$SMAC#SMAC 27m_vs_30m#Average Score#19.71$SMAC#SMAC 27m_vs_30m#Median Win Rate#85.45$SMAC#SMAC 27m_vs_30m#Average Score#19.43$SMAC#SMAC 27m_vs_30m#Median Win Rate#84.77$SMAC#SMAC 27m_vs_30m#Average Score#19.41$SMAC#SMAC 27m_vs_30m#Median Win Rate#63.12$SMAC#SMAC 27m_vs_30m#Average Score#18.45$SMAC#SMAC 27m_vs_30m#Median Win Rate#6.02$SMAC#SMAC 27m_vs_30m#Average Score#14.45$SMAC#SMAC 27m_vs_30m#Median Win Rate#2.27$SMAC#SMAC 27m_vs_30m#Average Score#14.01$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#94.03$SMAC#SMAC 3s5z_vs_3s6z#Average Score#20.94$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#91.08$SMAC#SMAC 3s5z_vs_3s6z#Average Score#19.7$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#89.2$SMAC#SMAC 3s5z_vs_3s6z#Average Score#19.75$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#67.22$SMAC#SMAC 3s5z_vs_3s6z#Average Score#20.16$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#62.22$SMAC#SMAC 3s5z_vs_3s6z#Average Score#17.52$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#29.83$SMAC#SMAC 3s5z_vs_3s6z#Average Score#16.54$SMAC#SMAC 6h_vs_8z#Median Win Rate#83.92$SMAC#SMAC 6h_vs_8z#Average Score#19.4$SMAC#SMAC 6h_vs_8z#Median Win Rate#49.43$SMAC#SMAC 6h_vs_8z#Average Score#17.14$SMAC#SMAC 6h_vs_8z#Median Win Rate#12.78$SMAC#SMAC 6h_vs_8z#Average Score#14.37$SMAC#SMAC 6h_vs_8z#Median Win Rate#0$SMAC#SMAC 6h_vs_8z#Average Score#15.41$SMAC#SMAC 6h_vs_8z#Median Win Rate#0.00$SMAC#SMAC 6h_vs_8z#Average Score#14.94$SMAC#SMAC 6h_vs_8z#Average Score#13.78$SMAC#SMAC MMM2#Median Win Rate#97.22$SMAC#SMAC MMM2#Average Score#20.9$SMAC#SMAC MMM2#Median Win Rate#95.11$SMAC#SMAC MMM2#Average Score#19.87$SMAC#SMAC MMM2#Median Win Rate#92.44$SMAC#SMAC MMM2#Average Score#19.42$SMAC#SMAC MMM2#Median Win Rate#89.2$SMAC#SMAC MMM2#Average Score#19.36$SMAC#SMAC MMM2#Median Win Rate#85.23$SMAC#SMAC MMM2#Average Score#19.21$SMAC#SMAC MMM2#Median Win Rate#68.92$SMAC#SMAC MMM2#Average Score#17.5$SMAC+#Off_Distant_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_sequential#Median Win Rate#81.3$SMAC+#Def_Armored_sequential#Median Win Rate#71.9$SMAC+#Def_Armored_sequential#Median Win Rate#53.1$SMAC+#Off_Complicated_parallel#Median Win Rate#0.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#100$SMAC+#Def_Infantry_sequential#Median Win Rate#93.8$SMAC+#Def_Infantry_sequential#Median Win Rate#90.6$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#90.0$SMAC+#Def_Armored_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_parallel#Median Win Rate#90.0$SMAC+#Def_Infantry_parallel#Median Win Rate#20.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#0.0$SMAC+#Def_Outnumbered_parallel#Median Win Rate#5.0$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0$SMAC+#Off_Near_parallel#Median Win Rate#0.0
1902.04043v5.pdf	SMAC#SMAC corridor#Median Win Rate#1$SMAC#SMAC corridor#Median Win Rate#0$SMAC#SMAC 27m_vs_30m#Median Win Rate#49$SMAC#SMAC 27m_vs_30m#Median Win Rate#0$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#2$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#0$SMAC#SMAC 6h_vs_8z#Median Win Rate#3$SMAC#SMAC 6h_vs_8z#Median Win Rate#0$SMAC#SMAC MMM2#Median Win Rate#69$SMAC#SMAC MMM2#Median Win Rate#1$SMAC#SMAC MMM2#Median Win Rate#0
2003.08839v2.pdf	SMAC#SMAC corridor#Median Win Rate#1$SMAC#SMAC 27m_vs_30m#Median Win Rate#49$SMAC#SMAC 3s5z_vs_3s6z#Median Win Rate#2$SMAC#SMAC 6h_vs_8z#Median Win Rate#3$SMAC#SMAC MMM2#Median Win Rate#69
1706.05296v1.pdf	SMAC+#Off_Distant_parallel#Median Win Rate#85.0$SMAC+#Def_Armored_sequential#Median Win Rate#96.9$SMAC+#Off_Complicated_parallel#Median Win Rate#70.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#96.9$SMAC+#Off_Hard_parallel#Median Win Rate#15.0$SMAC+#Def_Armored_parallel#Median Win Rate#5.0$SMAC+#Def_Infantry_parallel#Median Win Rate#95.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#15.6$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0$SMAC+#Off_Near_parallel#Median Win Rate#90.0
2104.06655v2.pdf	SMAC+#Off_Distant_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_sequential#Median Win Rate#0.0$SMAC+#Off_Complicated_parallel#Median Win Rate#0.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#37.5$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_parallel#Median Win Rate#30.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#0.0$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0$SMAC+#Off_Near_parallel#Median Win Rate#0.0
1705.08926v2.pdf	SMAC+#Off_Distant_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_sequential#Median Win Rate#0.0$SMAC+#Off_Complicated_parallel#Median Win Rate#0.0$SMAC+#Off_Superhard_sequential#Median Win Rate#0.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Off_Hard_sequential#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#28.1$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_parallel#Median Win Rate#50.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#0.0$SMAC+#Off_Complicated_sequential#Median Win Rate#0.0$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0$SMAC+#Off_Near_parallel#Median Win Rate#20.0$SMAC+#Off_Near_sequential#Median Win Rate#0.0$SMAC+#Off_Distant_sequential#Median Win Rate#0.0
1905.05408v1.pdf	SMAC+#Off_Distant_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_sequential#Median Win Rate#93.8$SMAC+#Off_Complicated_parallel#Median Win Rate#0.0$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#100$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#5.0$SMAC+#Def_Infantry_parallel#Median Win Rate#100.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#81.3$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0$SMAC+#Off_Near_parallel#Median Win Rate#0.0
1706.02275v4.pdf	SMAC+#Def_Armored_sequential#Median Win Rate#90.6$SMAC+#Off_Superhard_sequential#Median Win Rate#0.0$SMAC+#Off_Hard_sequential#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#100$SMAC+#Def_Outnumbered_sequential#Median Win Rate#81.3$SMAC+#Off_Complicated_sequential#Median Win Rate#0.0$SMAC+#Off_Near_sequential#Median Win Rate#75.0$SMAC+#Off_Distant_sequential#Median Win Rate#0.0
2207.02007v2.pdf	SMAC+#Def_Armored_sequential#Median Win Rate#9.4$SMAC+#Off_Superhard_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_sequential#Median Win Rate#93.8$SMAC+#Off_Hard_parallel#Median Win Rate#0.0$SMAC+#Def_Armored_parallel#Median Win Rate#0.0$SMAC+#Def_Infantry_parallel#Median Win Rate#40.0$SMAC+#Def_Outnumbered_sequential#Median Win Rate#0.0$SMAC+#Def_Outnumbered_parallel#Median Win Rate#0.0
1908.02111v1.pdf	Point Cloud Super Resolution#SHREC15#F-measure (%)#93.1%
1801.06761v2.pdf	Point Cloud Super Resolution#SHREC15#F-measure (%)#56.4%
1909.04538v1.pdf	Face Anonymization#2019_test set#10%#122
1903.11410v2.pdf	Graph-to-Sequence#LDC2015E86:#BLEU#23.95
1904.08375v2.pdf	Passage Re-Ranking#MS MARCO#MRR#0.368$Passage Re-Ranking#TREC-PM#mAP#36.5
1901.04085v5.pdf	Passage Re-Ranking#MS MARCO#MRR#0.359
1903.07666v1.pdf	Passage Re-Ranking#MS MARCO#MRR#0.253
2204.13635v1.pdf	Depth Completion#KITTI Depth Completion#RMSE#709.41
2107.13802v5.pdf	Depth Completion#KITTI Depth Completion#RMSE#713.44
2103.00783v3.pdf	Depth Completion#KITTI Depth Completion#iRMSE#2.17$Depth Completion#KITTI Depth Completion#iMAE#0.94$Depth Completion#KITTI Depth Completion#RMSE#730.08$Depth Completion#KITTI Depth Completion#MAE#210.55$Depth Completion#KITTI Depth Completion#Runtime [ms]#32
1902.05356v1.pdf	Depth Completion#KITTI Depth Completion#iRMSE#2.19$Depth Completion#KITTI Depth Completion#iMAE#0.93$Depth Completion#KITTI Depth Completion#RMSE#772.87$Depth Completion#KITTI Depth Completion#MAE#215.02$Depth Completion#KITTI Depth Completion#Runtime [ms]#20
1811.01791v2.pdf	Depth Completion#KITTI Depth Completion#RMSE#830$Depth Completion#KITTI Depth Completion#MAE#233$Depth Completion#KITTI Depth Completion#Runtime [ms]#20$Depth Completion#KITTI Depth Completion#RMSE#859$Depth Completion#KITTI Depth Completion#MAE#208$Depth Completion#KITTI Depth Completion#RMSE#1268$Depth Completion#KITTI Depth Completion#MAE#360$Depth Completion#KITTI Depth Completion#Runtime [ms]#10
1808.00769v2.pdf	Depth Completion#KITTI Depth Completion#RMSE#918$Depth Completion#KITTI Depth Completion#MAE#235$Depth Completion#KITTI Depth Completion#Runtime [ms]#70$Depth Completion#KITTI Depth Completion#RMSE#1035$Depth Completion#KITTI Depth Completion#MAE#248$Depth Completion#KITTI Depth Completion#Runtime [ms]#40
1808.08685v2.pdf	Depth Completion#KITTI Depth Completion#RMSE#937$Depth Completion#KITTI Depth Completion#MAE#258
2108.10531v2.pdf	Depth Completion#KITTI Depth Completion#iRMSE#2.95$Depth Completion#KITTI Depth Completion#iMAE#1.02$Depth Completion#KITTI Depth Completion#RMSE#1069.47$Depth Completion#KITTI Depth Completion#MAE#256.76$Depth Completion#KITTI Depth Completion#Runtime [ms]#16$Depth Completion#VOID#MAE#39.80$Depth Completion#VOID#RMSE#95.86$Depth Completion#VOID#iMAE#21.16$Depth Completion#VOID#iRMSE#49.72
2106.02994v3.pdf	Depth Completion#KITTI Depth Completion#iRMSE#3.30$Depth Completion#KITTI Depth Completion#iMAE#1.15$Depth Completion#KITTI Depth Completion#RMSE#1121.93$Depth Completion#KITTI Depth Completion#MAE#280.76$Depth Completion#VOID#MAE#59.53$Depth Completion#VOID#RMSE#119.14$Depth Completion#VOID#iMAE#35.72$Depth Completion#VOID#iRMSE#68.36
1905.08616v4.pdf	Depth Completion#KITTI Depth Completion#iRMSE#3.56$Depth Completion#KITTI Depth Completion#iMAE#1.20$Depth Completion#KITTI Depth Completion#RMSE#1169.97$Depth Completion#KITTI Depth Completion#MAE#299.41$Depth Completion#KITTI Depth Completion#Runtime [ms]#20$Depth Completion#VOID#MAE#85.05$Depth Completion#VOID#RMSE#169.79$Depth Completion#VOID#iMAE#48.92$Depth Completion#VOID#iRMSE#104.02
1708.06500v2.pdf	Depth Completion#KITTI Depth Completion#RMSE#1601$Depth Completion#KITTI Depth Completion#MAE#481$Depth Completion#KITTI Depth Completion#Runtime [ms]#10
1901.10034v2.pdf	Depth Completion#VOID#MAE#151.86$Depth Completion#VOID#RMSE#222.36$Depth Completion#VOID#iMAE#74.59$Depth Completion#VOID#iRMSE#112.36
1807.00275v2.pdf	Depth Completion#VOID#MAE#178.85$Depth Completion#VOID#RMSE#243.84$Depth Completion#VOID#iMAE#80.12$Depth Completion#VOID#iRMSE#107.69
2109.09628v4.pdf	Depth Completion#KITTI#RMSE#1193.92
1906.08967v3.pdf	Depth Completion#KITTI Depth Completion 500 points#RMSE#2.964
2005.08607v2.pdf	Depth Completion#Matterport3D#RMSE#1.001
1908.08344v3.pdf	Depth Completion#Matterport3D#RMSE#1.092
2104.10011v1.pdf	Homography Estimation#PDS-COCO#MACE#2.11$Homography Estimation#S-COCO#MACE#1.79
1606.03798v1.pdf	Homography Estimation#PDS-COCO#MACE#2.50$Homography Estimation#S-COCO#MACE#1.96
1709.03966v3.pdf	Homography Estimation#S-COCO#MACE#2.07
1909.05983v2.pdf	Homography Estimation#S-COCO#MACE#2.08
2109.04753v1.pdf	Homography Estimation#Oxford and Paris#AUC@5px#29.5$Homography Estimation#Oxford and Paris#AUC@10px#52.1$Homography Estimation#Oxford and Paris#AUC@20px#69.4$Homography Estimation#Oxford and Paris#P#57.7$Homography Estimation#Oxford and Paris#R#61.5$Homography Estimation#Oxford and Paris#F#59.5$Homography Estimation#Oxford and Paris#AUC@5px#31.8$Homography Estimation#Oxford and Paris#AUC@10px#51.5$Homography Estimation#Oxford and Paris#AUC@20px#67.1$Homography Estimation#Oxford and Paris#P#41.1$Homography Estimation#Oxford and Paris#R#45.8$Homography Estimation#Oxford and Paris#F#43.3
2204.06228v1.pdf	DeepFake Detection#LAV-DF#AUC#0.990$DeepFake Detection#DFDC#AUC#0.846
2004.07676v1.pdf	DeepFake Detection#FaceForensics++#AUC#0.9444$DeepFake Detection#FaceForensics++#LogLoss#0.3269$DeepFake Detection#DFDC#LogLoss#0.4640
2107.02612v2.pdf	DeepFake Detection#DFDC#AUC#0.951$DeepFake Detection#DFDC#AUC#0.919
1901.08971v3.pdf	DeepFake Detection#FaceForensics#DF#96.36$DeepFake Detection#FaceForensics#FS#90.29$DeepFake Detection#FaceForensics#FSF#86.86$DeepFake Detection#FaceForensics#NT#80.67$DeepFake Detection#FaceForensics#Real#52.4$DeepFake Detection#FaceForensics#Total Accuracy#70.1
0710.3742v1.pdf	Change Point Detection#TSSB#Relative Change Point Distance#0.17803
2103.08907v1.pdf	Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.25#76.8$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.5#63.7$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.75#31.8$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#Average Best Overlap#63.0
2001.11207v3.pdf	Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.25#56.6$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.5#38.1$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.75#12.3$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#Average Best Overlap#48.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#38.1$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#56.6$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#12.3
2109.09477v3.pdf	Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.25#66.4$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.5#56.1$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.75#30.2$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#Average Best Overlap#-$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.25#61.2$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.5#51.0$Weakly-supervised instance segmentation#PASCAL VOC 2012 val#mAP@0.75#26.6$Image-level Supervised Instance Segmentation#COCO 2017 val#AP#14.3$Image-level Supervised Instance Segmentation#COCO 2017 val#AP@50#28.0$Image-level Supervised Instance Segmentation#COCO 2017 val#AP@75#13.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#51.0$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#61.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.7#31.9$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#26.6$Image-level Supervised Instance Segmentation#COCO test-dev#AP#14.4$Image-level Supervised Instance Segmentation#COCO test-dev#AP@50#28.0$Image-level Supervised Instance Segmentation#COCO test-dev#AP@75#13.5$Point-Supervised Instance Segmentation#COCO 2017 val#AP#17.7$Point-Supervised Instance Segmentation#COCO 2017 val#AP@50#34.0$Point-Supervised Instance Segmentation#COCO 2017 val#AP@75#16.4$Point-Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#66.4$Point-Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#56.1$Point-Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.7#36.5$Point-Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#30.2$Point-Supervised Instance Segmentation#COCO test-dev#AP#17.8$Point-Supervised Instance Segmentation#COCO test-dev#AP@50#34.1$Point-Supervised Instance Segmentation#COCO test-dev#AP@75#16.7
2105.06464v2.pdf	Weakly-supervised instance segmentation#COCO 2017 val#AP#31.4$Weakly-supervised instance segmentation#COCO 2017 val#AP@50#52.6$Weakly-supervised instance segmentation#COCO 2017 val#AP@75#32.2$Weakly-supervised instance segmentation#COCO 2017 val#AP@S#11.5$Weakly-supervised instance segmentation#COCO 2017 val#AP@M#33.8$Weakly-supervised instance segmentation#COCO 2017 val#AP@L#50.1$Weakly-supervised instance segmentation#COCO test-dev#AP#37.9$Weakly-supervised instance segmentation#COCO test-dev#AP@50#61.4$Weakly-supervised instance segmentation#COCO test-dev#AP@75#40.0$Weakly-supervised instance segmentation#COCO test-dev#AP@S#18.0$Weakly-supervised instance segmentation#COCO test-dev#AP@M#41.1$Weakly-supervised instance segmentation#COCO test-dev#AP@L#53.9$Weakly-supervised instance segmentation#COCO test-dev#AP#35.8$Weakly-supervised instance segmentation#COCO test-dev#AP@50#59.8$Weakly-supervised instance segmentation#COCO test-dev#AP@75#36.4$Weakly-supervised instance segmentation#COCO test-dev#AP@S#16.9$Weakly-supervised instance segmentation#COCO test-dev#AP@M#38.7$Weakly-supervised instance segmentation#COCO test-dev#AP@L#52.1$Weakly-supervised instance segmentation#COCO test-dev#AP#32.0$Weakly-supervised instance segmentation#COCO test-dev#AP@50#53.6$Weakly-supervised instance segmentation#COCO test-dev#AP@75#32.6$Weakly-supervised instance segmentation#COCO test-dev#AP@S#11.7$Weakly-supervised instance segmentation#COCO test-dev#AP@M#33.7$Weakly-supervised instance segmentation#COCO test-dev#AP@L#48.4
2110.00934v1.pdf	Weakly-supervised instance segmentation#COCO 2017 val#AP#21.1$Weakly-supervised instance segmentation#COCO 2017 val#AP@50#45.5$Weakly-supervised instance segmentation#COCO 2017 val#AP@75#17.2$Weakly-supervised instance segmentation#COCO 2017 val#AP@S#11.2$Weakly-supervised instance segmentation#COCO 2017 val#AP@M#22.0$Weakly-supervised instance segmentation#COCO 2017 val#AP@L#29.8
2012.02310v1.pdf	Weakly-supervised instance segmentation#COCO test-dev#AP#35.0$Weakly-supervised instance segmentation#COCO test-dev#AP@50#59.3$Weakly-supervised instance segmentation#COCO test-dev#AP@75#35.6$Weakly-supervised instance segmentation#COCO test-dev#AP@S#17.1$Weakly-supervised instance segmentation#COCO test-dev#AP@M#37.2$Weakly-supervised instance segmentation#COCO test-dev#AP@L#48.9$Weakly-supervised instance segmentation#COCO test-dev#AP#33.9$Weakly-supervised instance segmentation#COCO test-dev#AP@50#57.7$Weakly-supervised instance segmentation#COCO test-dev#AP@75#34.5$Weakly-supervised instance segmentation#COCO test-dev#AP@S#16.5$Weakly-supervised instance segmentation#COCO test-dev#AP@M#36.1$Weakly-supervised instance segmentation#COCO test-dev#AP@L#46.6$Weakly-supervised instance segmentation#COCO test-dev#AP#33.2$Weakly-supervised instance segmentation#COCO test-dev#AP@50#56.5$Weakly-supervised instance segmentation#COCO test-dev#AP@75#33.6$Weakly-supervised instance segmentation#COCO test-dev#AP@S#16.2$Weakly-supervised instance segmentation#COCO test-dev#AP@M#35.3$Weakly-supervised instance segmentation#COCO test-dev#AP@L#45.1$Weakly-supervised instance segmentation#COCO test-dev#AP#32.1$Weakly-supervised instance segmentation#COCO test-dev#AP@50#55.1$Weakly-supervised instance segmentation#COCO test-dev#AP@75#32.4$Weakly-supervised instance segmentation#COCO test-dev#AP@S#15.6$Weakly-supervised instance segmentation#COCO test-dev#AP@M#34.3$Weakly-supervised instance segmentation#COCO test-dev#AP@L#43.5
2004.12765v6.pdf	Humor Detection#200k Short Texts for Humor Detection#F1-score#0.982$Humor Detection#200k Short Texts for Humor Detection#F1-score#0.882$Humor Detection#200k Short Texts for Humor Detection#F1-score#0.874$Humor Detection#200k Short Texts for Humor Detection#F1-score#0.794
1603.02754v3.pdf	Humor Detection#200k Short Texts for Humor Detection#F1-score#0.813
1904.03603v1.pdf	Seizure prediction#Melbourne University Seizure Prediction#AUC#0.84
1811.00915v2.pdf	Seizure prediction#Melbourne University Seizure Prediction#AUC#0.591
1903.00614v1.pdf	graph partitioning#custom#All#min
1806.02199v7.pdf	Time Series Clustering#eICU Collaborative Research Database#NMI (physiology_6_hours)#0.0474$Time Series Clustering#eICU Collaborative Research Database#NMI (physiology_24_hours)#0.0421$Time Series Clustering#eICU Collaborative Research Database#NMI (physiology_6_hours)#0.0407$Time Series Clustering#eICU Collaborative Research Database#NMI (physiology_12_hours)#0.0444$Time Series Clustering#eICU Collaborative Research Database#NMI (physiology_24_hours)#0.0354
1706.02256v2.pdf	Abstract Anaphora Resolution#The ARRAU Corpus#Average Precision#43.83
2106.12379v2.pdf	Network Pruning#ImageNet - ResNet 50 - 90% sparsity#Top-1 Accuracy#75.64$Network Pruning#ImageNet#Accuracy#73.14$Network Pruning#CIFAR-100#Accuracy#79$Network Pruning#CIFAR-100#Accuracy#78.2
1912.04427v4.pdf	Network Pruning#ImageNet - ResNet 50 - 90% sparsity#Top-1 Accuracy#75.5
2002.03231v9.pdf	Network Pruning#ImageNet - ResNet 50 - 90% sparsity#Top-1 Accuracy#74.31$Network Pruning#ImageNet - ResNet 50 - 90% sparsity#Top-1 Accuracy#73.91
1906.00586v5.pdf	Network Pruning#ImageNet - ResNet 50 - 90% sparsity#Top-1 Accuracy#74
1608.08710v3.pdf	Network Pruning#ImageNet#Accuracy#78.79$Network Pruning#ImageNet#GFLOPs#2.335$Network Pruning#ImageNet#MParams#14.811$Network Pruning#ImageNet#Accuracy#78.07$Network Pruning#ImageNet#GFLOPs#1.635$Network Pruning#ImageNet#MParams#10.511$Network Pruning#ImageNet#Accuracy#76.376$Network Pruning#ImageNet#GFLOPs#1.075$Network Pruning#ImageNet#MParams#6.954
2002.08258v3.pdf	Network Pruning#ImageNet#Accuracy#78.0$Network Pruning#ImageNet#GFLOPs#2.5$Network Pruning#ImageNet#Accuracy#77.70$Network Pruning#ImageNet#GFLOPs#2
2007.02491v2.pdf	Network Pruning#ImageNet#Accuracy#77.1$Network Pruning#ImageNet#Accuracy#76.4$Network Pruning#ImageNet#Accuracy#74.2$Network Pruning#ImageNet#Accuracy#70.7
1905.09717v5.pdf	Network Pruning#ImageNet#Accuracy#76.20$Network Pruning#ImageNet#GFLOPs#2.3$Network Pruning#CIFAR-100#Accuracy#73.16$Network Pruning#CIFAR-100#GFLOPs#0.12$Network Pruning#CIFAR-10#Accuracy#94.33$Network Pruning#CIFAR-10#GFLOPs#0.119
2105.03193v1.pdf	Network Pruning#ImageNet#Accuracy#75.59
1904.08166v1.pdf	Network Pruning#MNIST#Avg #Steps#12.05
2111.13673v1.pdf	Instance Segmentation#COCO 2017 val#mask AP*#43.1$Instance Segmentation#BDD100K#AP#23.6$Instance Segmentation#COCO test-dev#mask AP#42.2$Instance Segmentation#BDD100K val#AP#23.6
1912.02801v4.pdf	Instance Segmentation#Cityscapes test#Average Precision#40.1
2006.07802v1.pdf	Instance Segmentation#Cityscapes test#Average Precision#32.5$Instance Segmentation#Cityscapes val#mask AP#37.1
1906.11109v2.pdf	Instance Segmentation#Cityscapes test#Average Precision#27.7$Instance Segmentation#Cityscapes test#Average Precision#27.6
1611.08303v2.pdf	Instance Segmentation#Cityscapes test#Average Precision#19.4
2210.10046v1.pdf	Instance Segmentation#COCO test-dev#mask AP#45.9$Instance Segmentation#Occluded COCO#Mean Recall#63.64$Instance Segmentation#Occluded COCO#Mean Recall#62.58$Instance Segmentation#Occluded COCO#Mean Recall#62.00$Instance Segmentation#Separated COCO#Mean Recall#36.88$Instance Segmentation#Separated COCO#Mean Recall#35.80$Instance Segmentation#Separated COCO#Mean Recall#34.72
2003.10152v3.pdf	Instance Segmentation#COCO test-dev#mask AP#41.7$Instance Segmentation#COCO test-dev#AP50#63.2$Instance Segmentation#COCO test-dev#AP75#45.1$Instance Segmentation#COCO test-dev#APS#18.0$Instance Segmentation#COCO test-dev#APM#45.0$Instance Segmentation#COCO test-dev#APL#61.6$Real-time Instance Segmentation#MSCOCO#Frame (fps)#31.3$Real-time Instance Segmentation#MSCOCO#mask AP#37.1$Real-time Instance Segmentation#MSCOCO#AP50#57.7$Real-time Instance Segmentation#MSCOCO#AP75#39.7
2001.00309v3.pdf	Instance Segmentation#COCO test-dev#mask AP#41.3$Instance Segmentation#COCO test-dev#AP50#63.1$Instance Segmentation#COCO test-dev#AP75#44.6$Instance Segmentation#COCO test-dev#APS#22.7$Instance Segmentation#COCO test-dev#APM#44.1$Instance Segmentation#COCO test-dev#APL#54.5$Real-time Instance Segmentation#MSCOCO#Frame (fps)#33.3$Real-time Instance Segmentation#MSCOCO#mask AP#35.2
1904.09730v1.pdf	Instance Segmentation#COCO test-dev#mask AP#40.8%$Instance Segmentation#COCO test-dev#mask AP#39.7%
1912.04488v3.pdf	Instance Segmentation#COCO test-dev#mask AP#40.4$Instance Segmentation#COCO test-dev#AP50#62.7$Instance Segmentation#COCO test-dev#AP75#43.3$Instance Segmentation#COCO test-dev#APS#17.6$Instance Segmentation#COCO test-dev#APM#43.3$Instance Segmentation#COCO test-dev#APL#58.9$Instance Segmentation#COCO test-dev#mask AP#40.4%$Instance Segmentation#COCO test-dev#AP50#62.7%$Instance Segmentation#COCO test-dev#AP75#43.3%$Instance Segmentation#COCO test-dev#APS#17.6%$Instance Segmentation#COCO test-dev#APM#43.3%$Instance Segmentation#COCO test-dev#APL#58.9%
1903.00241v1.pdf	Instance Segmentation#COCO test-dev#mask AP#39.6%$Instance Segmentation#COCO minival#mask AP#39.1$Instance Segmentation#COCO minival#mask AP#38.2$Instance Segmentation#COCO minival#mask AP#36.0
2007.12387v1.pdf	Instance Segmentation#COCO test-dev#mask AP#39.2$Instance Segmentation#COCO test-dev#AP50#60.8$Instance Segmentation#COCO test-dev#AP75#42.2$Instance Segmentation#COCO test-dev#APS#22.2$Instance Segmentation#COCO test-dev#APM#41.8$Instance Segmentation#COCO test-dev#APL#50.1
2105.02184v1.pdf	Instance Segmentation#COCO test-dev#mask AP#38.7$Instance Segmentation#COCO test-dev#AP50#64.1$Instance Segmentation#COCO test-dev#AP75#40.0$Instance Segmentation#COCO test-dev#APS#22.2$Instance Segmentation#COCO test-dev#APM#40.2$Instance Segmentation#COCO test-dev#APL#52.0
2007.14772v1.pdf	Instance Segmentation#COCO test-dev#mask AP#38.1$Instance Segmentation#COCO test-dev#AP50#60.2$Instance Segmentation#COCO test-dev#AP75#40.8$Instance Segmentation#COCO test-dev#APS#17.8$Instance Segmentation#COCO test-dev#APM#40.8$Instance Segmentation#COCO test-dev#APL#54.3$Real-time Instance Segmentation#MSCOCO#Frame (fps)#27.0 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#35.4$Real-time Instance Segmentation#MSCOCO#AP50#55.6$Real-time Instance Segmentation#MSCOCO#AP75#37.6$Real-time Instance Segmentation#MSCOCO#APS#11.2$Real-time Instance Segmentation#MSCOCO#APM#38.3$Real-time Instance Segmentation#MSCOCO#APL#56.8$Real-time Instance Segmentation#MSCOCO#Frame (fps)#31.3 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#32.8$Real-time Instance Segmentation#MSCOCO#AP50#53.4$Real-time Instance Segmentation#MSCOCO#AP75#34.3$Real-time Instance Segmentation#MSCOCO#APS#9.3$Real-time Instance Segmentation#MSCOCO#APM#35.6$Real-time Instance Segmentation#MSCOCO#APL#54.0$Real-time Instance Segmentation#MSCOCO#Frame (fps)#41.7 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#31.2$Real-time Instance Segmentation#MSCOCO#AP50#51.9$Real-time Instance Segmentation#MSCOCO#AP75#32.3$Real-time Instance Segmentation#MSCOCO#APS#9.2$Real-time Instance Segmentation#MSCOCO#APM#33.6$Real-time Instance Segmentation#MSCOCO#APL#49.8$Video Instance Segmentation#YouTube-VIS validation#mask AP#33.7$Video Instance Segmentation#YouTube-VIS validation#AP50#54.1$Video Instance Segmentation#YouTube-VIS validation#AP75#35.8$Video Instance Segmentation#YouTube-VIS validation#AR1#35.4$Video Instance Segmentation#YouTube-VIS validation#AR10#40.1$Video Instance Segmentation#YouTube-VIS validation#mask AP#32.5$Video Instance Segmentation#YouTube-VIS validation#AP50#53$Video Instance Segmentation#YouTube-VIS validation#AP75#33.3$Video Instance Segmentation#YouTube-VIS validation#AR1#33.5$Video Instance Segmentation#YouTube-VIS validation#AR10#38.9
1712.04837v1.pdf	Instance Segmentation#COCO test-dev#mask AP#38.1%
1912.01954v2.pdf	Instance Segmentation#COCO test-dev#mask AP#37.7%$Instance Segmentation#COCO test-dev#AP50#59.1%$Instance Segmentation#COCO test-dev#AP75#40.3%$Instance Segmentation#COCO test-dev#APS#17.9%$Instance Segmentation#COCO test-dev#APM#40.4%$Instance Segmentation#COCO test-dev#APL#53%$Instance Segmentation#COCO test-dev#mask AP#37.7$Instance Segmentation#COCO test-dev#AP50#59.1$Instance Segmentation#COCO test-dev#AP75#40.3$Instance Segmentation#COCO test-dev#APS#17.9$Instance Segmentation#COCO test-dev#APM#40.4
1903.12174v2.pdf	Instance Segmentation#COCO test-dev#mask AP#37.3%
2203.04074v1.pdf	Instance Segmentation#COCO test-dev#mask AP#33.8$Instance Segmentation#COCO test-dev#AP50#52.9$Instance Segmentation#COCO test-dev#AP75#35.9
1611.07709v2.pdf	Instance Segmentation#COCO test-dev#mask AP#33.6%$Instance Segmentation#COCO test-dev#AP50#54.5%$Instance Segmentation#COCO test-dev#mask AP#29.2%$Instance Segmentation#COCO test-dev#AP50#49.5%$Instance Segmentation#COCO test-dev#APS#7.1%$Instance Segmentation#COCO test-dev#APM#31.3%$Instance Segmentation#COCO test-dev#APL#50.0%
1909.13226v4.pdf	Instance Segmentation#COCO test-dev#mask AP#32.9%$Instance Segmentation#COCO test-dev#AP50#55.4%$Instance Segmentation#COCO test-dev#AP75#33.8%$Instance Segmentation#COCO test-dev#APS#15.5%$Instance Segmentation#COCO test-dev#APM#35.1%$Instance Segmentation#COCO test-dev#APL#46.3%$Instance Segmentation#COCO test-dev#mask AP#30.4%$Instance Segmentation#COCO test-dev#AP50#51.9%$Instance Segmentation#COCO test-dev#AP75#31%$Instance Segmentation#COCO test-dev#APS#13.4%$Instance Segmentation#COCO test-dev#APM#32.4%$Instance Segmentation#COCO test-dev#APL#42.8%
1904.02689v2.pdf	Instance Segmentation#COCO test-dev#mask AP#29.8%$Instance Segmentation#COCO minival#mask AP#29.9$Real-time Instance Segmentation#MSCOCO#Frame (fps)#33.3 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#28.2$Real-time Instance Segmentation#MSCOCO#AP50#46.6$Real-time Instance Segmentation#MSCOCO#AP75#29.2$Real-time Instance Segmentation#MSCOCO#APS#9.2$Real-time Instance Segmentation#MSCOCO#APM#29.3$Real-time Instance Segmentation#MSCOCO#APL#44.8$Real-time Instance Segmentation#MSCOCO#Frame (fps)#45.3 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#24.9$Real-time Instance Segmentation#MSCOCO#AP50#42.0$Real-time Instance Segmentation#MSCOCO#AP75#25.4$Real-time Instance Segmentation#MSCOCO#APS#5.0$Real-time Instance Segmentation#MSCOCO#APM#25.3$Real-time Instance Segmentation#MSCOCO#APL#45.0
1512.04412v1.pdf	Instance Segmentation#COCO test-dev#AP50#44.3%$Multi-Human Parsing#PASCAL-Part#AP 0.5#38.80%
2207.10936v2.pdf	Instance Segmentation#LVIS v1.0 val#mask AP#29.0$Instance Segmentation#LVIS v1.0 val#mask AP#27.7
2012.08548v2.pdf	Instance Segmentation#LVIS v1.0 val#mask AP#28.8$Instance Segmentation#LVIS v1.0 val#mask AP#27.5$Instance Segmentation#LVIS v1.0 val#mask AP#23.7
2009.01559v1.pdf	Instance Segmentation#LVIS v1.0 test-dev#mask AP#41.23
2108.03568v1.pdf	Instance Segmentation#Leaf Segmentation Challenge#Dice Scoe#90.09
2109.15068v1.pdf	Instance Segmentation#iShape#mask AP#62.93
2112.11010v2.pdf	Instance Segmentation#COCO minival#mask AP#47.0$Instance Segmentation#COCO minival#mask AP#45.8
2210.03105v1.pdf	3D Instance Segmentation#STPLS3D#AP50#74.3$3D Instance Segmentation#STPLS3D#AP25#81.6$3D Instance Segmentation#STPLS3D#AP#57.3$3D Instance Segmentation#ScanNet200#mAP#27.8$3D Instance Segmentation#S3DIS#AP@50#75.5$3D Instance Segmentation#S3DIS#mAP#64.5$3D Instance Segmentation#ScanNet(v2)#mAP#55.2$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#78.0
2108.02350v1.pdf	3D Instance Segmentation#STPLS3D#AP50#46.7$3D Instance Segmentation#STPLS3D#AP25#52.8$3D Instance Segmentation#STPLS3D#AP#35.1$3D Instance Segmentation#S3DIS#mRec#69.4$3D Instance Segmentation#S3DIS#mPrec#73.2$3D Instance Segmentation#S3DIS#mCov#67.0$3D Instance Segmentation#S3DIS#mWCov#70.4$3D Instance Segmentation#ScanNet(v2)#mAP#45.7$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#69.9
2004.01658v1.pdf	3D Instance Segmentation#STPLS3D#AP50#38.5$3D Instance Segmentation#STPLS3D#AP25#48.6$3D Instance Segmentation#STPLS3D#AP#23.3$3D Instance Segmentation#S3DIS#mRec#69.2$3D Instance Segmentation#S3DIS#mPrec#69.6$3D Instance Segmentation#S3DIS#AP@50#64.0$3D Instance Segmentation#ScanNet(v2)#mAP#40.7$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#63.6
2003.06537v3.pdf	3D Instance Segmentation#SceneNN#mAP@0.5#47.1$3D Instance Segmentation#ScanNet(v2)#mAP#44.3$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#63.4
1904.00699v2.pdf	3D Instance Segmentation#SceneNN#mAP@0.5#12.1$3D Instance Segmentation#SceneNN#mAP@0.5#8.5
2104.07961v4.pdf	3D Instance Segmentation#MitoEM#AP75-R-Val#0.917$3D Instance Segmentation#MitoEM#AP75-H-Val#0.828$3D Instance Segmentation#MitoEM#AP75-R-Test#0.851$3D Instance Segmentation#MitoEM#AP75-H-Test#0.829
2203.14662v1.pdf	3D Instance Segmentation#S3DIS#mRec#69.6$3D Instance Segmentation#S3DIS#mPrec#66.6$3D Instance Segmentation#S3DIS#AP@50#69.9$3D Instance Segmentation#ScanNet(v2)#mAP#43.4$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#66.4
2108.07478v1.pdf	3D Instance Segmentation#S3DIS#mRec#73.4$3D Instance Segmentation#S3DIS#mPrec#73.5$3D Instance Segmentation#S3DIS#AP@50#67.8$3D Instance Segmentation#S3DIS#mAP#54.1$3D Instance Segmentation#ScanNet(v2)#mAP#50.6$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#69.8
2207.07372v2.pdf	3D Instance Segmentation#S3DIS#mRec#71.1$3D Instance Segmentation#S3DIS#mPrec#75.3$3D Instance Segmentation#S3DIS#mCov#70.3$3D Instance Segmentation#S3DIS#mWCov#72.8$3D Instance Segmentation#ScanNet(v2)#mAP#53.2$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#71.8
2007.09860v1.pdf	3D Instance Segmentation#S3DIS#mRec#50.8$3D Instance Segmentation#S3DIS#mPrec#68.5$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#63.8
1906.01140v2.pdf	3D Instance Segmentation#S3DIS#mRec#47.6$3D Instance Segmentation#S3DIS#mPrec#65.6$3D Instance Segmentation#ScanNet(v2)#mRec#47.6$3D Instance Segmentation#ScanNet(v2)#mAP#25.3$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#48.8
2006.15015v1.pdf	3D Instance Segmentation#S3DIS#mIoU#61.1$3D Instance Segmentation#S3DIS#mRec#50.8$3D Instance Segmentation#S3DIS#mAcc#72.8$3D Instance Segmentation#S3DIS#mPrec#64.2$3D Instance Segmentation#S3DIS#mCov#54.5$3D Instance Segmentation#S3DIS#mWCov#58.3
2107.03180v1.pdf	3D Instance Segmentation#ScanNet(v2)#mAP#43.6$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#63.5
1902.04478v1.pdf	3D Instance Segmentation#ScanNet(v2)#mAP#25.4$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#44.7$3D Instance Segmentation#ScanNet(v2)#mAP @ 50#45.9$3D Instance Segmentation#ScanNet#mAP#0.447
2112.02990v2.pdf	3D Instance Segmentation#ScanNet(v2)#mAP @ 50#57.6
2001.01349v1.pdf	3D Instance Segmentation#ScanNet(v2)#mAP @ 50#31
2104.10412v4.pdf	Referring Expression Segmentation#ReferIt#Overall IoU#68.58$Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#45.49$Referring Expression Segmentation#RefCOCOg-val#Overall IoU#49.49$Referring Expression Segmentation#RefCOCO testA#Overall IoU#69.33$Referring Expression Segmentation#RefCOCO testB#Overall IoU#60.93$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#60.06$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#53.97$Referring Expression Segmentation#RefCoCo val#Overall IoU#65.76$Referring Expression Segmentation#RefCoCo val#Precision@0.9#20.03$Referring Expression Segmentation#RefCoCo val#Precision@0.8#50.73$Referring Expression Segmentation#RefCoCo val#Precision@0.7#65.34$Referring Expression Segmentation#RefCoCo val#Precision@0.6#72.99$Referring Expression Segmentation#RefCoCo val#Precision@0.5#77.82
2111.10747v2.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#56.06$Referring Expression Segmentation#G-Ref test A#Overall IoU#62.87$Referring Expression Segmentation#G-Ref test B#Overall IoU#61.81$Referring Expression Segmentation#RefCOCO testA#Overall IoU#71.71$Referring Expression Segmentation#G-Ref val#Overall IoU#62.45$Referring Expression Segmentation#RefCOCO testB#Overall IoU#66.92$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#65.92$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#62.23$Referring Expression Segmentation#RefCoCo val#Overall IoU#70.13
2112.02244v2.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#55.1$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#68.38$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#62.14
2111.15174v2.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#53.68$Referring Expression Segmentation#RefCOCO testA#Overall IoU#73.18$Referring Expression Segmentation#RefCOCO testB#Overall IoU#66.1$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#68.08$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#62.27$Referring Expression Segmentation#RefCoCo val#Overall IoU#70.47
2108.05565v1.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#49.36$Referring Expression Segmentation#RefCOCOg-val#Overall IoU#52.99$Referring Expression Segmentation#RefCOCO testA#Overall IoU#68.29$Referring Expression Segmentation#RefCOCO testB#Overall IoU#62.73$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#59.20$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#55.50$Referring Expression Segmentation#RefCoCo val#Overall IoU#65.65$Referring Expression Segmentation#RefCOCOg-test#Overall IoU#56.65
2010.00514v1.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#43.23$Referring Expression Segmentation#RefCOCO testA#Overall IoU#64.53$Referring Expression Segmentation#RefCOCO testB#Overall IoU#59.64$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#53.44$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#49.56$Referring Expression Segmentation#RefCoCo val#Overall IoU#61.36
1801.08186v3.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#40.08$Referring Expression Segmentation#RefCOCO testA#Overall IoU#62.37$Referring Expression Segmentation#RefCOCO testB#Overall IoU#51.70$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#52.39$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#46.67$Referring Expression Segmentation#RefCoCo val#Overall IoU#56.51
1904.04745v1.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#37.89$Referring Expression Segmentation#RefCOCO testA#Overall IoU#60.61$Referring Expression Segmentation#RefCOCO testB#Overall IoU#55.09$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#47.60$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#43.76$Referring Expression Segmentation#RefCoCo val#Overall IoU#58.32
2010.00263v1.pdf	Referring Expression Segmentation#RefCOCO+ test B#Overall IoU#36.17$Referring Expression Segmentation#A2Dre test#Overall IoU#47.5$Referring Expression Segmentation#A2Dre test#Mean IoU#33.2$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.495$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.064$Referring Expression Segmentation#A2D Sentences#IoU overall#0.599$Referring Expression Segmentation#A2D Sentences#IoU mean#0.599$Referring Expression Segmentation#RefCOCO testA#Overall IoU#63.19$Referring Expression Segmentation#RefCOCO testA#Overall IoU#52.90$Referring Expression Segmentation#DAVIS 2017 (val)#J&F 1st frame#44.5$Referring Expression Segmentation#DAVIS 2017 (val)#J&F Full video#45.1$Referring Expression Segmentation#RefCOCO testB#Overall IoU#54.17$Referring Expression Segmentation#RefCOCO+ testA#Overall IoU#49.73$Referring Expression Segmentation#RefCOCO+ val#Overall IoU#44.71$Referring Expression Segmentation#RefCoCo val#Overall IoU#59.45$Referring Expression Segmentation#RefCoCo val#Overall IoU#58.65
1901.00850v2.pdf	Referring Expression Segmentation#CLEVR-Ref+#IoU#80.6
2201.00487v2.pdf	Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#62.9$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#61.3$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#64.6$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#62.4$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#60.8$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#64.0$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#57.3$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#56.1$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#58.4$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#55.6$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#54.8$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#56.6$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.831$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.212$Referring Expression Segmentation#A2D Sentences#IoU overall#0.786$Referring Expression Segmentation#A2D Sentences#IoU mean#0.703$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.804$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.741$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.579$Referring Expression Segmentation#A2D Sentences#AP#0.550
2111.14821v2.pdf	Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#55.32$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#54.00$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#56.64$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.754$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.169$Referring Expression Segmentation#A2D Sentences#IoU overall#0.72$Referring Expression Segmentation#A2D Sentences#IoU mean#0.64$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.712$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.638$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.485$Referring Expression Segmentation#A2D Sentences#AP#0.461$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.721$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.164$Referring Expression Segmentation#A2D Sentences#IoU overall#0.702$Referring Expression Segmentation#A2D Sentences#IoU mean#0.618$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.684$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.607$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.456$Referring Expression Segmentation#A2D Sentences#AP#0.447$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.939$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.852$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.616$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.166$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.001$Referring Expression Segmentation#J-HMDB#AP#0.392$Referring Expression Segmentation#J-HMDB#IoU overall#0.701$Referring Expression Segmentation#J-HMDB#IoU mean#0.698$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.91$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.815$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.57$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.144$Referring Expression Segmentation#J-HMDB#AP#0.366$Referring Expression Segmentation#J-HMDB#IoU overall#0.674$Referring Expression Segmentation#J-HMDB#IoU mean#0.679
2203.15969v1.pdf	Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J&F#49.56$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#J#48.44$Referring Expression Segmentation#Refer-YouTube-VOS (2021 public validation)#F#50.67$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.702$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.151$Referring Expression Segmentation#A2D Sentences#IoU overall#0.714$Referring Expression Segmentation#A2D Sentences#IoU mean#0.598$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.663$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.585$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.428$Referring Expression Segmentation#A2D Sentences#AP#0.469$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.874$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.791$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.586$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.182$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.30$Referring Expression Segmentation#J-HMDB#AP#0.441$Referring Expression Segmentation#J-HMDB#IoU overall#0.68$Referring Expression Segmentation#J-HMDB#IoU mean#0.666
2105.07175v1.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.655$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.098$Referring Expression Segmentation#A2D Sentences#IoU overall#0.653$Referring Expression Segmentation#A2D Sentences#IoU mean#0.573$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.592$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.506$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.342$Referring Expression Segmentation#A2D Sentences#AP#0.404$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.590$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.068$Referring Expression Segmentation#A2D Sentences#IoU overall#0.649$Referring Expression Segmentation#A2D Sentences#IoU mean#0.515$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.527$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.434$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.284$Referring Expression Segmentation#A2D Sentences#AP#0.351$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.813$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.657$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.371$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.07$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.000$Referring Expression Segmentation#J-HMDB#AP#0.342$Referring Expression Segmentation#J-HMDB#IoU overall#0.616$Referring Expression Segmentation#J-HMDB#IoU mean#0.617
2105.06818v1.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.654$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.091$Referring Expression Segmentation#A2D Sentences#IoU overall#0.662$Referring Expression Segmentation#A2D Sentences#IoU mean#0.561$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.589$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.497$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.333$Referring Expression Segmentation#A2D Sentences#AP#0.399$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.783$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.639$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.378$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.076$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.000$Referring Expression Segmentation#J-HMDB#AP#0.335$Referring Expression Segmentation#J-HMDB#IoU overall#0.598$Referring Expression Segmentation#J-HMDB#IoU mean#0.604
2011.00786v2.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.681$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.029$Referring Expression Segmentation#A2D Sentences#IoU overall#0.617$Referring Expression Segmentation#A2D Sentences#IoU mean#0.552$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.629$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.523$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.296$Referring Expression Segmentation#A2D Sentences#AP#0.396$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.773$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.627$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.360$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.044$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.000$Referring Expression Segmentation#J-HMDB#AP#0.321$Referring Expression Segmentation#J-HMDB#IoU overall#0.583$Referring Expression Segmentation#J-HMDB#IoU mean#0.576
1803.07485v1.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.5$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.004$Referring Expression Segmentation#A2D Sentences#IoU overall#0.551$Referring Expression Segmentation#A2D Sentences#IoU mean#0.426$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.376$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.231$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.094$Referring Expression Segmentation#A2D Sentences#AP#0.215$Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.475$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.002$Referring Expression Segmentation#A2D Sentences#IoU overall#0.536$Referring Expression Segmentation#A2D Sentences#IoU mean#0.421$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.347$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.211$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.08$Referring Expression Segmentation#A2D Sentences#AP#0.198$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.712$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.518$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.264$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.030$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.000$Referring Expression Segmentation#J-HMDB#AP#0.267$Referring Expression Segmentation#J-HMDB#IoU overall#0.555$Referring Expression Segmentation#J-HMDB#IoU mean#0.570$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.699$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.460$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.173$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.014$Referring Expression Segmentation#J-HMDB#AP#0.233$Referring Expression Segmentation#J-HMDB#IoU overall#0.541$Referring Expression Segmentation#J-HMDB#IoU mean#0.542
1603.06180v1.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.348$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.000$Referring Expression Segmentation#A2D Sentences#IoU overall#0.474$Referring Expression Segmentation#A2D Sentences#IoU mean#0.350$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.236$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.133$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.033$Referring Expression Segmentation#A2D Sentences#AP#0.132$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.633$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.350$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.085$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.002$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.000$Referring Expression Segmentation#J-HMDB#AP#0.178$Referring Expression Segmentation#J-HMDB#IoU overall#0.546$Referring Expression Segmentation#J-HMDB#IoU mean#0.528
2103.10702v3.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.704$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.171$Referring Expression Segmentation#A2D Sentences#IoU overall#0.644$Referring Expression Segmentation#A2D Sentences#IoU mean#0.655$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.677$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.617$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.489$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.880$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.796$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.566$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.147$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.002$Referring Expression Segmentation#J-HMDB#IoU overall#0.644$Referring Expression Segmentation#J-HMDB#IoU mean#0.655
2102.04762v1.pdf	Referring Expression Segmentation#A2D Sentences#Precision@0.5#0.487$Referring Expression Segmentation#A2D Sentences#Precision@0.9#0.052$Referring Expression Segmentation#A2D Sentences#IoU overall#0.618$Referring Expression Segmentation#A2D Sentences#IoU mean#0.432$Referring Expression Segmentation#A2D Sentences#Precision@0.6#0.431$Referring Expression Segmentation#A2D Sentences#Precision@0.7#0.358$Referring Expression Segmentation#A2D Sentences#Precision@0.8#0.231$Referring Expression Segmentation#J-HMDB#Precision@0.5#0.764$Referring Expression Segmentation#J-HMDB#Precision@0.6#0.625$Referring Expression Segmentation#J-HMDB#Precision@0.7#0.389$Referring Expression Segmentation#J-HMDB#Precision@0.8#0.09$Referring Expression Segmentation#J-HMDB#Precision@0.9#0.001$Referring Expression Segmentation#J-HMDB#IoU overall#0.628$Referring Expression Segmentation#J-HMDB#IoU mean#0.581
2106.04403v2.pdf	Referring Expression Segmentation#Refer-YouTube-VOS#Precision@0.5#38.6$Referring Expression Segmentation#Refer-YouTube-VOS#Precision@0.9#6.9$Referring Expression Segmentation#Refer-YouTube-VOS#Mean IoU#39.5$Referring Expression Segmentation#Refer-YouTube-VOS#Precision@0.5#32.3$Referring Expression Segmentation#Refer-YouTube-VOS#Precision@0.9#1.8$Referring Expression Segmentation#Refer-YouTube-VOS#Mean IoU#35.0$Referring Expression Segmentation#DAVIS 2017 (val)#J&F 1st frame#45.3$Referring Expression Segmentation#DAVIS 2017 (val)#J&F Full video#44.8$Referring Expression Segmentation#DAVIS 2017 (val)#J&F 1st frame#45.1
2008.01187v1.pdf	Referring Expression Segmentation#PhraseCut#Mean IoU#41.3$Referring Expression Segmentation#PhraseCut#Pr@0.5#42.9$Referring Expression Segmentation#PhraseCut#Pr@0.7#27.8$Referring Expression Segmentation#PhraseCut#Pr@0.9#5.9$Referring Expression Segmentation#PhraseCut#Mean IoU#21.1$Referring Expression Segmentation#PhraseCut#Pr@0.5#22$Referring Expression Segmentation#PhraseCut#Pr@0.7#11.6$Referring Expression Segmentation#PhraseCut#Pr@0.9#1.5$Referring Expression Segmentation#PhraseCut#Mean IoU#20.2$Referring Expression Segmentation#PhraseCut#Pr@0.5#19.7$Referring Expression Segmentation#PhraseCut#Pr@0.7#13.5$Referring Expression Segmentation#PhraseCut#Pr@0.9#3
2106.03089v2.pdf	Referring Expression Segmentation#RefCOCO testA#Overall IoU#73.49$Referring Expression Segmentation#RefCOCO testB#Overall IoU#66.57$Referring Expression Segmentation#RefCoCo val#Overall IoU#70.56
1910.04748v1.pdf	Referring Expression Segmentation#RefCOCO testA#Overall IoU#61.77$Referring Expression Segmentation#RefCOCO testB#Overall IoU#53.81$Referring Expression Segmentation#RefCoCo val#Overall IoU#58.90
2108.08923v2.pdf	Real-time Instance Segmentation#KITTI#AP#8.73$Real-time Instance Segmentation#Cityscapes test#AP#15.54$Real-time Instance Segmentation#India Driving Dataset#AP#14.4
2203.12827v1.pdf	Real-time Instance Segmentation#MSCOCO#Frame (fps)#40 (2080 Ti)$Real-time Instance Segmentation#MSCOCO#mask AP#37.9$Real-time Instance Segmentation#MSCOCO#AP50#59.2$Real-time Instance Segmentation#MSCOCO#AP75#40.2$Real-time Instance Segmentation#MSCOCO#APS#15.7$Real-time Instance Segmentation#MSCOCO#APM#39.4$Real-time Instance Segmentation#MSCOCO#APL#56.9$Real-time Instance Segmentation#MSCOCO#Frame (fps)#58.5 (2080 Ti)$Real-time Instance Segmentation#MSCOCO#mask AP#35.9$Real-time Instance Segmentation#MSCOCO#AP50#56.5$Real-time Instance Segmentation#MSCOCO#AP75#37.7$Real-time Instance Segmentation#MSCOCO#APS#12.3$Real-time Instance Segmentation#MSCOCO#APM#37.1$Real-time Instance Segmentation#MSCOCO#APL#57.0
2110.09734v1.pdf	Real-time Instance Segmentation#MSCOCO#Frame (fps)#25 (Tesla V100)$Real-time Instance Segmentation#MSCOCO#mask AP#37.7$Real-time Instance Segmentation#MSCOCO#AP50#59.4$Real-time Instance Segmentation#MSCOCO#AP75#39.9$Real-time Instance Segmentation#MSCOCO#APS#18.1$Real-time Instance Segmentation#MSCOCO#APM#40.8$Real-time Instance Segmentation#MSCOCO#APL#52.5$Real-time Instance Segmentation#MSCOCO#Frame (fps)#30 (Tesla V100)$Real-time Instance Segmentation#MSCOCO#mask AP#35.2$Real-time Instance Segmentation#MSCOCO#AP50#56.2$Real-time Instance Segmentation#MSCOCO#AP75#37.1$Real-time Instance Segmentation#MSCOCO#APS#14.7$Real-time Instance Segmentation#MSCOCO#APM#38.0$Real-time Instance Segmentation#MSCOCO#APL#51.4
1912.06218v2.pdf	Real-time Instance Segmentation#MSCOCO#Frame (fps)#27.3 (Titan Xp)$Real-time Instance Segmentation#MSCOCO#mask AP#34.6$Real-time Instance Segmentation#MSCOCO#AP50#53.8$Real-time Instance Segmentation#MSCOCO#AP75#36.9$Real-time Instance Segmentation#MSCOCO#APS#11.9$Real-time Instance Segmentation#MSCOCO#APM#36.8$Real-time Instance Segmentation#MSCOCO#APL#55.1
2205.13271v2.pdf	Unsupervised Object Segmentation#ObjectsRoom#ARI-FG#0.87$Unsupervised Object Segmentation#ShapeStacks#ARI-FG#0.82$Unsupervised Object Segmentation#ClevrTex#mIoU#79.58±0.54$Unsupervised Object Segmentation#ClevrTex#MSE#139±7$Unsupervised Object Segmentation#ClevrTex#mIoU#66.62± 0.80$Unsupervised Object Segmentation#ClevrTex#MSE#167± 1
2111.10265v1.pdf	Unsupervised Object Segmentation#ClevrTex#mIoU#42.25± 0.18$Unsupervised Object Segmentation#ClevrTex#MSE#383± 2$Unsupervised Object Segmentation#ClevrTex#mIoU#33.79± 1.30$Unsupervised Object Segmentation#ClevrTex#MSE#438± 22$Unsupervised Object Segmentation#ClevrTex#mIoU#30.17± 2.60$Unsupervised Object Segmentation#ClevrTex#MSE#347± 20$Unsupervised Object Segmentation#ClevrTex#mIoU#29.16± 0.75$Unsupervised Object Segmentation#ClevrTex#MSE#340± 3$Unsupervised Object Segmentation#ClevrTex#mIoU#22.58± 2.07$Unsupervised Object Segmentation#ClevrTex#MSE#254± 8$Unsupervised Object Segmentation#ClevrTex#mIoU#19.78± 1.02$Unsupervised Object Segmentation#ClevrTex#MSE#146± 7$Unsupervised Object Segmentation#ClevrTex#mIoU#10.46± 0.10$Unsupervised Object Segmentation#ClevrTex#MSE#335± 1$Unsupervised Object Segmentation#ClevrTex#mIoU#9.14± 3.46$Unsupervised Object Segmentation#ClevrTex#MSE#298± 80$Unsupervised Object Segmentation#ClevrTex#mIoU#7.93± 1.53$Unsupervised Object Segmentation#ClevrTex#MSE#315±106$Unsupervised Object Segmentation#ClevrTex#mIoU#0.0 ± 0.0$Unsupervised Object Segmentation#ClevrTex#MSE#1101± 2
2007.09397v1.pdf	Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#50.9$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#59.7$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.7#30.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#28.5
1907.01430v1.pdf	Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#41.7$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#49.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#23.7
1910.02624v3.pdf	Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.5#30.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.25#49.2$Image-level Supervised Instance Segmentation#PASCAL VOC 2012 val#mAP@0.75#12.9
1906.08650v2.pdf	3D Semantic Instance Segmentation#ScanNetV2#mAP@0.50#54.9
1904.02199v3.pdf	3D Semantic Instance Segmentation#ScanNetV2#mAP@0.50#24.8
1809.05825v2.pdf	Unseen Object Instance Segmentation#WISDOM#mAP @0.5:0.95#51.6
2009.13436v2.pdf	Event-based vision#1 Megapixel Automotive Detection Dataset#mAP#43
2010.02358v5.pdf	Document Layout Analysis#RVL-CDIP#FAR#28.7$Document Layout Analysis#RVL-CDIP#WAR#18.7
2102.01120v1.pdf	MS-SSIM#DocUNet#MS-SSIM#0.45$SSIM#DocUNet#SSIM#0.507434
2007.09824v1.pdf	MS-SSIM#DocUNet#MS-SSIM#0.415$Local Distortion#DocUNet#LD#13.2$SSIM#DocUNet#SSIM#0.548915
2003.13743v1.pdf	Pose Tracking#PoseTrack2017#MOTA#64.09$Pose Tracking#PoseTrack2017#mAP#74.14$Pose Tracking#PoseTrack2018#MOTA#64.3$Pose Tracking#PoseTrack2018#mAP#73.5
1912.02323v2.pdf	Pose Tracking#PoseTrack2017#MOTA#61.15$Pose Tracking#PoseTrack2017#mAP#74.04
1905.02822v1.pdf	Pose Tracking#PoseTrack2017#MOTA#58.01$Pose Tracking#PoseTrack2017#mAP#66.65
1905.09500v1.pdf	Pose Tracking#PoseTrack2017#MOTA#54.46$Pose Tracking#PoseTrack2017#mAP#68.78$Pose Tracking#PoseTrack2018#MOTA#54.86$Pose Tracking#PoseTrack2018#mAP#67.81
1811.11975v3.pdf	Pose Tracking#PoseTrack2017#MOTA#53.81$Pose Tracking#PoseTrack2017#mAP#70.28
1904.08452v3.pdf	Direction of Arrival Estimation#SOFA#Angular Error#9.68
2203.10430v5.pdf	Polyphone disambiguation#CPP#Accuracy#99.08
2004.03136v5.pdf	Polyphone disambiguation#CPP#Accuracy#97.85$Polyphone disambiguation#CPP#Accuracy#97.31
1902.06871v1.pdf	Safety Perception Recognition#Google Street Images#Accuracy#81%
2105.02216v1.pdf	Scene Flow Estimation#KITTI 2015 Scene Flow Test#D1-all#30.78$Scene Flow Estimation#KITTI 2015 Scene Flow Test#D2-all#34.41$Scene Flow Estimation#KITTI 2015 Scene Flow Test#Fl-all#19.54$Scene Flow Estimation#KITTI 2015 Scene Flow Test#SF-all#44.04$Scene Flow Estimation#KITTI 2015 Scene Flow Test#Runtime (s)#0.063$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D1-all#27.33$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D2-all#30.44$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Fl-all#18.92$Scene Flow Estimation#KITTI 2015 Scene Flow Training#SF-all#39.82$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Runtime (s)#0.063
2004.04143v2.pdf	Scene Flow Estimation#KITTI 2015 Scene Flow Test#D1-all#34.02$Scene Flow Estimation#KITTI 2015 Scene Flow Test#D2-all#36.34$Scene Flow Estimation#KITTI 2015 Scene Flow Test#Fl-all#23.54$Scene Flow Estimation#KITTI 2015 Scene Flow Test#SF-all#49.54$Scene Flow Estimation#KITTI 2015 Scene Flow Test#Runtime (s)#0.09$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D1-all#31.25$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D2-all#34.86$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Fl-all#23.49$Scene Flow Estimation#KITTI 2015 Scene Flow Training#SF-all#47.05$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Runtime (s)#0.09
2004.09548v1.pdf	Scene Flow Estimation#Scene Flow#EPE#0.068
1810.06125v2.pdf	Scene Flow Estimation#KITTI 2015 Scene Flow Training#D1-all#23.84$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D2-all#60.32$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Fl-all#19.64$Scene Flow Estimation#KITTI 2015 Scene Flow Training#SF-all#(>60.32)$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Runtime (s)#0.05
1806.10556v2.pdf	Scene Flow Estimation#KITTI 2015 Scene Flow Training#D1-all#26.81$Scene Flow Estimation#KITTI 2015 Scene Flow Training#D2-all#60.97$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Fl-all#25.74$Scene Flow Estimation#KITTI 2015 Scene Flow Training#SF-all#(>60.97)$Scene Flow Estimation#KITTI 2015 Scene Flow Training#Runtime (s)#0.05
2101.01909v2.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.669$Line Segment Detection#York Urban Dataset#sAP10#29.4$Line Segment Detection#York Urban Dataset#sAP15#31.7$Line Segment Detection#wireframe dataset#F1 score#0.833$Line Segment Detection#wireframe dataset#sAP10#65.2$Line Segment Detection#wireframe dataset#sAP15#67.7
2003.01663v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.663$Line Segment Detection#York Urban Dataset#sAP5#26.1$Line Segment Detection#York Urban Dataset#sAP10#28.5$Line Segment Detection#York Urban Dataset#sAP15#29.7$Line Segment Detection#wireframe dataset#F1 score#0.831$Line Segment Detection#wireframe dataset#sAP5#62.5$Line Segment Detection#wireframe dataset#sAP10#66.5$Line Segment Detection#wireframe dataset#sAP15#68.2
2209.04642v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.654$Line Segment Detection#Wireframe#F1 score#77.5$Line Segment Detection#wireframe dataset#F1 score#0.775$Line Segment Detection#wireframe dataset#Params (M)#0.5$Line Segment Detection#wireframe dataset#FPS#214
2104.14205v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.648$Line Segment Detection#York Urban Dataset#sAP5#27.6$Line Segment Detection#York Urban Dataset#sAP10#30.2$Line Segment Detection#York Urban Dataset#sAP15#31.8$Line Segment Detection#wireframe dataset#F1 score#0.831$Line Segment Detection#wireframe dataset#sAP5#64.3$Line Segment Detection#wireframe dataset#sAP10#68.9$Line Segment Detection#wireframe dataset#sAP15#70.9
1812.02122v2.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.646$Line Segment Detection#York Urban Dataset#sAP5#7.3$Line Segment Detection#York Urban Dataset#sAP10#9.4$Line Segment Detection#York Urban Dataset#sAP15#11.1$Line Segment Detection#wireframe dataset#sAP15#27.5
2106.00186v3.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.642$Line Segment Detection#York Urban Dataset#sAP5#24.6$Line Segment Detection#York Urban Dataset#sAP10#27.3$Line Segment Detection#wireframe dataset#F1 score#0.800$Line Segment Detection#wireframe dataset#sAP5#56.4$Line Segment Detection#wireframe dataset#sAP10#62.1$Line Segment Detection#wireframe dataset#LAP#61.5$Line Segment Detection#wireframe dataset#Params (M)#1.5$Line Segment Detection#wireframe dataset#FPS#115.4
2011.03174v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.633$Line Segment Detection#York Urban Dataset#sAP10#27.4$Line Segment Detection#York Urban Dataset#sAP15#28.9$Line Segment Detection#wireframe dataset#F1 score#0.794$Line Segment Detection#wireframe dataset#sAP10#66.4$Line Segment Detection#wireframe dataset#sAP15#68.1
2007.07527v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.627$Line Segment Detection#York Urban Dataset#sAP5#2.8$Line Segment Detection#York Urban Dataset#sAP10#3.9$Line Segment Detection#wireframe dataset#F1 score#0.728$Line Segment Detection#wireframe dataset#sAP5#3.7$Line Segment Detection#wireframe dataset#sAP10#5.1$Line Segment Detection#wireframe dataset#sAP15#5.9$Line Segment Detection#wireframe dataset#sAP5#6.9$Line Segment Detection#wireframe dataset#sAP10#9.0
2108.03144v1.pdf	Line Segment Detection#York Urban Dataset#F1 score#0.415
2104.11207v2.pdf	Line Segment Detection#York Urban Dataset#sAP5#28.5$Line Segment Detection#York Urban Dataset#sAP10#30.8$Line Segment Detection#wireframe dataset#sAP5#64.3$Line Segment Detection#wireframe dataset#sAP10#68.3
2009.05505v1.pdf	Line Segment Detection#York Urban Dataset#sAP5#27.6$Line Segment Detection#York Urban Dataset#sAP10#27.7$Line Segment Detection#wireframe dataset#sAP5#57.6$Line Segment Detection#wireframe dataset#sAP10#57.2
2007.09493v1.pdf	Line Segment Detection#York Urban Dataset#sAP5#25.0$Line Segment Detection#York Urban Dataset#sAP10#27.4$Line Segment Detection#wireframe dataset#sAP5#62.9$Line Segment Detection#wireframe dataset#sAP10#66.6
1905.03246v3.pdf	Line Segment Detection#York Urban Dataset#sAP5#24.3$Line Segment Detection#York Urban Dataset#sAP10#26.4$Line Segment Detection#wireframe dataset#sAP5#58.9$Line Segment Detection#wireframe dataset#sAP10#62.9$Line Segment Detection#wireframe dataset#sAP15#64.7
1808.09419v1.pdf	Query Wellformedness#Query Wellformedness#Accuracy#70.7
2203.10833v2.pdf	Metric Learning#Stanford Online Products#R@1#85.9$Metric Learning#Stanford Online Products#R@1#85.1$Metric Learning#In-Shop#R@1#92.5$Metric Learning#In-Shop#R@1#92.4$Metric Learning#CARS196#R@1#92.8$Metric Learning#CARS196#R@1#89.2$Metric Learning#CARS196#R@1#86.5$Metric Learning#CUB-200-2011#R@1#80.9$Metric Learning#CUB-200-2011#R@1#85.6
2201.11307v1.pdf	Metric Learning#Stanford Online Products#R@1#82.3$Metric Learning#In-Shop#R@1#92.21$Metric Learning#CARS196#R@1#86.5$Metric Learning#CUB-200-2011#R@1#63.8
2007.12749v2.pdf	Metric Learning#Stanford Online Products#R@1#81.6$Metric Learning#In-Shop#R@1#90$Metric Learning#CARS196#R@1#73.2$Metric Learning#CUB-200-2011#R@1#57.7
2106.04990v2.pdf	Metric Learning#Stanford Online Products#R@1#81.3$Metric Learning#In-Shop#R@1#92.2$Metric Learning#CARS196#R@1#89.6$Metric Learning#CUB-200-2011#R@1#71.4
2203.08543v1.pdf	Metric Learning#Stanford Online Products#R@1#81.3$Metric Learning#CARS196#R@1#90.2$Metric Learning#CUB-200-2011#R@1#71.4
2006.04935v1.pdf	Metric Learning#Stanford Online Products#R@1#81.2$Metric Learning#In-Shop#R@1#91.3$Metric Learning#CARS196#R@1#91.5$Metric Learning#CUB-200-2011#R@1#74.9
2003.08983v3.pdf	Metric Learning#Stanford Online Products#R@1#81.1$Metric Learning#In-Shop#R@1#90.6$Metric Learning#CARS196#R@1#89.3$Metric Learning#CUB-200-2011#R@1#69.2
2009.08348v3.pdf	Metric Learning#Stanford Online Products#R@1#81.0$Metric Learning#CARS196#R@1#89.5$Metric Learning#CUB-200-2011#R@1#70.1
2203.08547v1.pdf	Metric Learning#Stanford Online Products#R@1#80.7$Metric Learning#CARS196#R@1#89.1$Metric Learning#CUB-200-2011#R@1#70.5
2208.00119v1.pdf	Metric Learning#Stanford Online Products#R@1#80.59$Metric Learning#CARS196#R@1#88.34$Metric Learning#CARS196#R@1#87.8$Metric Learning#CUB-200-2011#R@1#69.19
2003.13911v1.pdf	Metric Learning#Stanford Online Products#R@1#80.3$Metric Learning#CARS196#R@1#88.3$Metric Learning#CUB-200-2011#R@1#71.1
2004.13458v4.pdf	Metric Learning#Stanford Online Products#R@1#79.6$Metric Learning#CARS196#R@1#87.6$Metric Learning#CUB-200-2011#R@1#69.2
2203.14932v1.pdf	Metric Learning#Stanford Online Products#R@1#79.6$Metric Learning#CARS196#R@1#91.5$Metric Learning#CUB-200-2011#R@1#71.9
2108.05889v1.pdf	Metric Learning#Stanford Online Products#R@1#79.26$Metric Learning#CARS196#R@1#87.01$Metric Learning#CUB-200-2011#R@1#68.15
1909.11574v1.pdf	Metric Learning#Stanford Online Products#R@1#77.2$Metric Learning#CARS196#R@1#82.6$Metric Learning#CUB-200-2011#R@1#66.1
2003.11113v2.pdf	Metric Learning#Stanford Online Products#R@1#76.5$Metric Learning#CARS196#R@1#83.5$Metric Learning#CUB-200-2011#R@1#67.3
1912.00385v4.pdf	Metric Learning#Stanford Online Products#R@1#75.7$Metric Learning#CARS196#R@1#85.6$Metric Learning#CUB-200-2011#R@1#65.5
2102.07753v3.pdf	Metric Learning#CARS196#R@1#91.5$Metric Learning#CARS196#R@1#88.1$Metric Learning#CUB-200-2011#R@1#71.8
1908.02735v1.pdf	Metric Learning#CARS196#R@1#88.0$Metric Learning#CUB-200-2011#R@1#66.8
1909.05235v2.pdf	Metric Learning#CARS196#R@1#84.5$Metric Learning#CUB-200-2011#R@1#65.4
1903.05503v2.pdf	Metric Learning#CARS196#R@1#79.1$Metric Learning#CUB-200-2011#R@1#53.7
1610.08904v1.pdf	Metric Learning#CUB-200-2011#R@1#58.3
2003.10826v1.pdf	Surface Normals Estimation#PCPNet#RMSE#11.8
1904.07172v3.pdf	Surface Normals Estimation#PCPNet#RMSE#11.84
1812.00709v1.pdf	Surface Normals Estimation#PCPNet#RMSE#12.41
2109.09881v1.pdf	Surface Normals Estimation#ScanNetV2#% < 11.25#71.1$Surface Normals Estimation#ScanNetV2#% < 22.5#85.4$Surface Normals Estimation#ScanNetV2#% < 30#89.8$Surface Normals Estimation#ScanNetV2#Mean Angle Error#11.8$Surface Normals Estimation#NYU Depth v2#% < 11.25#62.2$Surface Normals Estimation#NYU Depth v2#% < 22.5#79.3$Surface Normals Estimation#NYU Depth v2#% < 30#85.2$Surface Normals Estimation#NYU Depth v2#Mean Angle Error#14.9$Surface Normals Estimation#NYU Depth v2#RMSE#23.5
2004.12629v2.pdf	Table Detection#ICDAR2013#Avg F1#1.0
2008.10831v1.pdf	Table Detection#ICDAR2013#Avg F1#1.0
2001.01469v1.pdf	Table Detection#ICDAR2013#Avg F1#0.9662
2209.09207v1.pdf	Table Detection#STDW#IoU#0.5$Table Detection#STDW#AP#0.78$Table Detection#STDW#AP#0.61
2004.11964v1.pdf	Question Similarity#Q2Q Arabic Benchmark#F1 score#0.95924
1912.12514v1.pdf	Question Similarity#Q2Q Arabic Benchmark#F1 score#0.94848
1902.03283v1.pdf	Music Genre Recognition#chords#Accuracy#62%
2003.04820v1.pdf	Music Genre Recognition#1B Words#10 Hops#24.5
2109.09113v3.pdf	Quantization#COCO#MAP#34.3$Quantization#ImageNet#Accuracy (%)#78.972$Quantization#ImageNet#Accuracy (%)#77.092$Quantization#ImageNet#Accuracy (%)#74.216$Quantization#ImageNet#Accuracy (%)#73.356$Quantization#ImageNet#Accuracy#71.46
2007.09952v1.pdf	Quantization#ImageNet#Accuracy (%)#76.4$Quantization#ImageNet#Accuracy (%)#76$Quantization#ImageNet#Accuracy (%)#75.45$Quantization#ImageNet#Accuracy (%)#70.9
2004.09576v1.pdf	Quantization#ImageNet#Accuracy (%)#73.8$Quantization#ImageNet#Accuracy (%)#71.7
2104.00210v1.pdf	Quantization#ImageNet#Accuracy#71.5$Quantization#ImageNet#Top 1 Accuracy#65.8
2103.09377v1.pdf	Quantization#ImageNet#Top-1#74.03
2111.02625v1.pdf	Data Free Quantization#CIFAR-100#CIFAR-100 W5A5 Top-1 Accuracy#69.02$Data Free Quantization#CIFAR-100#CIFAR-100 W4A4 Top-1 Accuracy#65.10$Data Free Quantization#CIFAR10#CIFAR-10 W4A4 Top-1 Accuracy#91.26$Data Free Quantization#CIFAR10#CIFAR-10 W5A5 Top-1 Accuracy#93.46
2003.03603v3.pdf	Data Free Quantization#CIFAR-100#CIFAR-100 W8A8 Top-1 Accuracy#70.29$Data Free Quantization#CIFAR-100#CIFAR-100 W6A6 Top-1 Accuracy#68.63$Data Free Quantization#CIFAR-100#CIFAR-100 W5A5 Top-1 Accuracy#64.03$Data Free Quantization#CIFAR-100#CIFAR-100 W4A4 Top-1 Accuracy#43.12$Data Free Quantization#CIFAR10#CIFAR-10 W6A6 Top-1 Accuracy#93.38$Data Free Quantization#CIFAR10#CIFAR-10 W4A4 Top-1 Accuracy#85.20$Data Free Quantization#CIFAR10#CIFAR-10 W5A5 Top-1 Accuracy#92.39$Data Free Quantization#CIFAR10#CIFAR-10 W8A8 Top-1 Accuracy#93.92$Data Free Quantization#ImageNet#ImageNet W8A8 Top-1 Accuracy#71.43$Data Free Quantization#ImageNet#ImageNet W4A4 Top-1 Accuracy#55.65
2103.15263v2.pdf	Data Free Quantization#CIFAR-100#CIFAR-100 W5A5 Top-1 Accuracy#67.94
2001.00281v1.pdf	Data Free Quantization#CIFAR10#CIFAR-10 W8A8 Top-1 Accuracy#93.94
2103.14167v2.pdf	Dense Pixel Correspondence Estimation#ETH3D#AEPE (rate=3)#1.66$Dense Pixel Correspondence Estimation#ETH3D#AEPE (rate=5)#1.71$Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#7.75$Dense Pixel Correspondence Estimation#HPatches#PCK-1px#40.91$Dense Pixel Correspondence Estimation#HPatches#PCK-3px#82.37$Dense Pixel Correspondence Estimation#HPatches#PCK-5px#91.1$Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#7.98$Dense Pixel Correspondence Estimation#HPatches#PCK-1px#33.08$Dense Pixel Correspondence Estimation#HPatches#PCK-3px#77.09$Dense Pixel Correspondence Estimation#HPatches#PCK-5px#86.33$Dense Pixel Correspondence Estimation#KITTI 2012#Average End-Point Error#1.28$Dense Pixel Correspondence Estimation#KITTI 2012#Average End-Point Error#2.62$Dense Pixel Correspondence Estimation#KITTI 2015#Average End-Point Error#2.26$Dense Pixel Correspondence Estimation#KITTI 2015#Average End-Point Error#6.12
2106.03090v3.pdf	Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#0.48$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#2.24$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#2.41$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#4.32$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#5.16$Dense Pixel Correspondence Estimation#HPatches#PCK-5px#97.52
1810.08393v2.pdf	Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#1.55$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#5.53$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#8.98$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#11.66$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#16.70
1506.07656v2.pdf	Dense Pixel Correspondence Estimation#HPatches#Viewpoint I AEPE#5.84$Dense Pixel Correspondence Estimation#HPatches#Viewpoint II AEPE#4.63$Dense Pixel Correspondence Estimation#HPatches#Viewpoint III AEPE#12.43$Dense Pixel Correspondence Estimation#HPatches#Viewpoint IV AEPE#12.17$Dense Pixel Correspondence Estimation#HPatches#Viewpoint V AEPE#22.55
2107.07235v1.pdf	Image Matting#AIM-500#SAD#43.92$Image Matting#AIM-500#MSE#0.0161$Image Matting#AIM-500#MAD#0.0262$Image Matting#AIM-500#Conn.#43.18$Image Matting#AIM-500#Grad.#33.05
2010.16188v3.pdf	Image Matting#AIM-500#SAD#52.66$Image Matting#AIM-500#MSE#0.0213$Image Matting#AIM-500#MAD#0.0313$Image Matting#AIM-500#Conn.#52.69$Image Matting#AIM-500#Grad.#46.11$Image Matting#AM-2K#SAD#9.66$Image Matting#AM-2K#MSE#0.0024$Image Matting#AM-2K#MAD#0.0056$Image Matting#AM-2K#SAD#10.24$Image Matting#AM-2K#MSE#0.0028$Image Matting#AM-2K#MAD#0.0060$Image Matting#AM-2K#SAD#10.26$Image Matting#AM-2K#MSE#0.0029$Image Matting#AM-2K#MAD#0.0059$Image Matting#AM-2K#SAD#10.89$Image Matting#AM-2K#MAD#0.0064$Image Matting#P3M-10k#SAD#13.20$Image Matting#P3M-10k#MSE#0.0050$Image Matting#P3M-10k#MAD#0.0080
1901.07929v2.pdf	Image Matting#AIM-500#SAD#83.46$Image Matting#AIM-500#MSE#0.0348$Image Matting#AIM-500#MAD#0.0493$Image Matting#AIM-500#Conn.#82.14$Image Matting#AIM-500#Grad.#51.02
1809.01354v2.pdf	Image Matting#AIM-500#SAD#170.44$Image Matting#AIM-500#MSE#0.0921$Image Matting#AIM-500#MAD#0.1012$Image Matting#AIM-500#Conn.#170.67$Image Matting#AIM-500#Grad.#115.29$Image Matting#AM-2K#SAD#17.81$Image Matting#AM-2K#MSE#0.0068$Image Matting#AM-2K#MAD#0.0102$Image Matting#P3M-10k#SAD#21.56$Image Matting#P3M-10k#MSE#0.0100$Image Matting#P3M-10k#MAD#0.0125
2204.09433v1.pdf	Image Matting#Distinctions-646#SAD#40.69$Image Matting#Distinctions-646#MSE#0.009$Image Matting#Distinctions-646#Grad#43.91$Image Matting#Distinctions-646#Conn#40.56$Image Matting#Composition-1K#MSE#5.0$Image Matting#Composition-1K#SAD#46.22$Image Matting#Composition-1K#Grad#22.69$Image Matting#Composition-1K#Conn#45.4
2004.00626v2.pdf	Image Matting#Adobe Matting#SAD#1.72$Image Matting#Adobe Matting#MSE#0.97$Image Matting#Adobe Matting#SAD#1.92$Image Matting#Adobe Matting#MSE#1.16$Image Matting#Adobe Matting#SAD#2.53$Image Matting#Adobe Matting#MSE#1.33$Image Matting#Adobe Matting#SAD#3.67$Image Matting#Adobe Matting#MSE#4.5
2011.11961v4.pdf	Image Matting#AMD#MSE#0.0024$Image Matting#AMD#MAD#0.81$Image Matting#PPM-100#MSE#0.0046$Image Matting#PPM-100#MAD#0.97
2004.04955v1.pdf	Image Matting#AM-2K#SAD#61.50$Image Matting#AM-2K#MSE#0.0270$Image Matting#AM-2K#MAD#0.0356
2104.14222v2.pdf	Image Matting#P3M-10k#SAD#8.73$Image Matting#P3M-10k#MSE#0.0026$Image Matting#P3M-10k#MAD#0.0051
2203.15662v1.pdf	Image Matting#Composition-1K#MSE#4.0$Image Matting#Composition-1K#SAD#23.8$Image Matting#Composition-1K#Grad#8.7$Image Matting#Composition-1K#Conn#18.9
2109.12252v1.pdf	Image Matting#Composition-1K#MSE#4.1$Image Matting#Composition-1K#SAD#23.6$Image Matting#Composition-1K#Grad#8.4$Image Matting#Composition-1K#Conn#18.5
2003.07711v1.pdf	Image Matting#Composition-1K#MSE#5.3$Image Matting#Composition-1K#SAD#26.4$Image Matting#Composition-1K#Grad#10.6$Image Matting#Composition-1K#Conn#21.5
2112.13809v2.pdf	Image Matting#Composition-1K#MSE#5.4$Image Matting#Composition-1K#SAD#25.9$Image Matting#Composition-1K#Grad#9.25$Image Matting#Composition-1K#Conn#21.5
2104.08201v1.pdf	Image Matting#Composition-1K#MSE#5.8$Image Matting#Composition-1K#SAD#28.0$Image Matting#Composition-1K#Grad#10.8$Image Matting#Composition-1K#Conn#1111$Semantic Image Matting#Semantic Image Matting Dataset#SAD#27.87$Semantic Image Matting#Semantic Image Matting Dataset#MSE(10^3)#4.7$Semantic Image Matting#Semantic Image Matting Dataset#Grad#11.57$Semantic Image Matting#Semantic Image Matting Dataset#Conn#20.83
1909.09725v2.pdf	Image Matting#Composition-1K#MSE#8.2$Image Matting#Composition-1K#SAD#35.8$Image Matting#Composition-1K#Grad#17.3$Image Matting#Composition-1K#Conn#33.2
1908.00672v1.pdf	Image Matting#Composition-1K#MSE#13.0$Image Matting#Composition-1K#SAD#45.8$Image Matting#Composition-1K#Grad#25.9$Image Matting#Composition-1K#Conn#43.7$Semantic Image Matting#Semantic Image Matting Dataset#SAD#51.29$Semantic Image Matting#Semantic Image Matting Dataset#MSE(10^3)#14.0$Semantic Image Matting#Semantic Image Matting Dataset#Grad#34.19$Semantic Image Matting#Semantic Image Matting Dataset#Conn#48.77
1703.03872v3.pdf	Image Matting#Composition-1K#MSE#14.0$Image Matting#Composition-1K#Grad#31.0$Image Matting#Composition-1K#Conn#50.8$Semantic Image Matting#Semantic Image Matting Dataset#SAD#48.07$Semantic Image Matting#Semantic Image Matting Dataset#MSE(10^3)#15.0$Semantic Image Matting#Semantic Image Matting Dataset#Grad#31.67$Semantic Image Matting#Semantic Image Matting Dataset#Conn#46.26
2001.04069v1.pdf	Semantic Image Matting#Semantic Image Matting Dataset#SAD#39.28$Semantic Image Matting#Semantic Image Matting Dataset#MSE(10^3)#11.0$Semantic Image Matting#Semantic Image Matting Dataset#Grad#28.70$Semantic Image Matting#Semantic Image Matting Dataset#Conn#36.03
1705.07057v4.pdf	Density Estimation#CIFAR-10 (Conditional)#Log-likelihood#3058$Density Estimation#MNIST#Log-likelihood#-1038.5$Density Estimation#UCI HEPMASS#Log-likelihood#-15.15$Density Estimation#BSDS300#Log-likelihood#153.71$Density Estimation#CIFAR-10#Log-likelihood#3049$Density Estimation#MNIST (Conditional)#Log-likelihood#-1030.3$Density Estimation#UCI POWER#Log-likelihood#0.4$Density Estimation#UCI MINIBOONE#Log-likelihood#-12.27
1904.04676v1.pdf	Density Estimation#MNIST#NLL#83.59$Density Estimation#MNIST#Negative ELBO#80.71$Density Estimation#UCI HEPMASS#Log-likelihood#-14.71$Density Estimation#Freyfaces#Negative ELBO#4.33$Density Estimation#Freyfaces#NLL#4.42$Density Estimation#BSDS300#Log-likelihood#157.36$Density Estimation#Caltech-101#Negative ELBO#94.91$Density Estimation#Caltech-101#NLL#105.42$Density Estimation#UCI POWER#Log-likelihood#0.61$Density Estimation#UCI MINIBOONE#Log-likelihood#-8.95$Density Estimation#UCI GAS#Log-likelihood#12.06$Density Estimation#OMNIGLOT#Negative ELBO#94.83$Density Estimation#OMNIGLOT#NLL#100.08
2001.02728v2.pdf	Density Estimation#UCI HEPMASS#Log-likelihood#-11.3$Density Estimation#UCI POWER#Log-likelihood#0.97$Density Estimation#UCI MINIBOONE#Log-likelihood#-6.94$Density Estimation#UCI GAS#Log-likelihood#9.73
1712.08786v1.pdf	Density Estimation#ImageNet#NLL#0.02$Speech Synthesis#North American English#Mean Opinion Score#0
2106.04741v1.pdf	Density Estimation#UCI POWER#Log-likelihood#1.78
2204.02574v2.pdf	Interactive Segmentation#DAVIS-585#NoC@90#2.76$Interactive Segmentation#Berkeley#NoC@90#1.48$Interactive Segmentation#SBD#NoC@85#3.53$Interactive Segmentation#SBD#NoC@90#5.59$Interactive Segmentation#DAVIS#NoC@85#2.92$Interactive Segmentation#DAVIS#NoC@90#4.52$Interactive Segmentation#GrabCut#NoC@85#1.22$Interactive Segmentation#GrabCut#NoC@90#1.26
2210.11006v1.pdf	Interactive Segmentation#Berkeley#NoC@90#1.75$Interactive Segmentation#Berkeley#NoC@90#2.09$Interactive Segmentation#SBD#NoC@85#2.51$Interactive Segmentation#SBD#NoC@90#4.15$Interactive Segmentation#DAVIS#NoC@85#3.41$Interactive Segmentation#DAVIS#NoC@90#4.70$Interactive Segmentation#DAVIS#NoC@85#4.20$Interactive Segmentation#DAVIS#NoC@90#5.34$Interactive Segmentation#GrabCut#NoC@85#1.32$Interactive Segmentation#GrabCut#NoC@90#1.40$Interactive Segmentation#GrabCut#NoC@90#1.44
2203.05145v2.pdf	Interactive Segmentation#Berkeley#NoC@90#2.12$Interactive Segmentation#SBD#NoC@85#3.33$Interactive Segmentation#SBD#NoC@90#5.25$Interactive Segmentation#DAVIS#NoC@85#4.03$Interactive Segmentation#DAVIS#NoC@90#5.22$Interactive Segmentation#GrabCut#NoC@90#1.68
2102.06583v1.pdf	Interactive Segmentation#Berkeley#NoC@90#2.26$Interactive Segmentation#Berkeley#NoC@90#3.22$Interactive Segmentation#SBD#NoC@85#3.39$Interactive Segmentation#SBD#NoC@90#5.43$Interactive Segmentation#DAVIS#NoC@85#4.11$Interactive Segmentation#DAVIS#NoC@90#5.34$Interactive Segmentation#DAVIS#NoC@85#4.36$Interactive Segmentation#DAVIS#NoC@90#5.74$Interactive Segmentation#GrabCut#NoC@85#1.42$Interactive Segmentation#GrabCut#NoC@90#1.54$Interactive Segmentation#GrabCut#NoC@85#1.76$Interactive Segmentation#GrabCut#NoC@90#2.04
2109.09406v2.pdf	Interactive Segmentation#Berkeley#NoC@90#2.4$Interactive Segmentation#PASCAL VOC#NoC@85#2.5$Interactive Segmentation#DAVIS#NoC@85#4.54$Interactive Segmentation#DAVIS#NoC@90#5.77$Interactive Segmentation#GrabCut#NoC@85#1.6$Interactive Segmentation#GrabCut#NoC@90#1.72
2109.07592v1.pdf	Interactive Segmentation#Berkeley#NoC@90#2.70$Interactive Segmentation#SBD#NoC@85#2.73$Interactive Segmentation#SBD#NoC@90#5.00$Interactive Segmentation#GrabCut#NoC@85#2$Interactive Segmentation#GrabCut#NoC@90#2.76
2001.10331v3.pdf	Interactive Segmentation#Berkeley#NoC@90#4.34$Interactive Segmentation#SBD#NoC@85#4.81$Interactive Segmentation#SBD#NoC@90#7.73$Interactive Segmentation#DAVIS#NoC@85#5.04$Interactive Segmentation#DAVIS#NoC@90#7.41$Interactive Segmentation#GrabCut#NoC@85#2$Interactive Segmentation#GrabCut#NoC@90#2.46
1911.12709v4.pdf	Interactive Segmentation#Berkeley#NoC@90#4.94$Interactive Segmentation#DRIONS-DB#NoC@90#3.1$Interactive Segmentation#DAVIS#NoC@85#5.16$Interactive Segmentation#GrabCut#NoC@90#3.07$Interactive Segmentation#Rooftop#NoC@80#3.6
1603.04042v1.pdf	Interactive Segmentation#SBD#NoC@85#9.22$Interactive Segmentation#SBD#NoC@90#12.80$Interactive Segmentation#SBD#NoC@85#14.30$Interactive Segmentation#SBD#NoC@90#16.79$Interactive Segmentation#DAVIS#NoC@85#9.03$Interactive Segmentation#DAVIS#NoC@90#12.58$Interactive Segmentation#DAVIS#NoC@85#12.52$Interactive Segmentation#DAVIS#NoC@90#17.11$Interactive Segmentation#GrabCut#NoC@85#5.08$Interactive Segmentation#GrabCut#NoC@90#6.08$Interactive Segmentation#GrabCut#NoC@85#8.02$Interactive Segmentation#GrabCut#NoC@90#12.59
1904.07750v2.pdf	Audio Denoising#AV-Bench - Wooden Horse#NSDR#14.5$Audio Denoising#AV-Bench - Guitar Solo#NSDR#11.9$Audio Denoising#AV-Bench - Violin Yanni#NSDR#8.53$Audio Source Separation#AudioSet#SAR#13$Audio Source Separation#AudioSet#SDR#4.26$Audio Source Separation#AudioSet#SIR#7.07$Audio Source Separation#MUSIC (multi-source)#SAR#11.3$Audio Source Separation#MUSIC (multi-source)#SIR#13.8
1912.01369v3.pdf	Pneumonia Detection#ChestX-ray14#AUROC#0.847$Pneumonia Detection#ChestX-ray14#Params#5.0M$Pneumonia Detection#ChestX-ray14#AUROC#0.846$Pneumonia Detection#ChestX-ray14#Params#2.2.M
1711.05225v3.pdf	Pneumonia Detection#ChestX-ray14#AUROC#0.844$Pneumonia Detection#ChestX-ray14#Params#7.0M$Pneumonia Detection#ChestX-ray14#FLOPS#2800M
2006.13807v2.pdf	Pneumonia Detection#COVID-19 CXR Dataset#F-Score#0.85
1911.03688v2.pdf	Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#71.8%$Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#68.3%$Conversational Response Selection#DSTC7 Ubuntu#1-of-100 Accuracy#71.2%$Conversational Response Selection#PolyAI AmazonQA#1-of-100 Accuracy#84.3%
1904.06472v2.pdf	Conversational Response Selection#PolyAI Reddit#1-of-100 Accuracy#61.3%$Conversational Response Selection#PolyAI AmazonQA#1-of-100 Accuracy#71.3%$Conversational Response Selection#PolyAI OpenSubtitles#1-of-100 Accuracy#30.6%
1905.01969v4.pdf	Conversational Response Selection#RRS Ranking Test#NDCG@3#0.679$Conversational Response Selection#RRS Ranking Test#NDCG@5#0.765$Conversational Response Selection#DSTC7 Ubuntu#1-of-100 Accuracy#70.9%$Conversational Response Selection#DSTC7 Ubuntu#1-of-100 Accuracy#66.3%$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.882$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.949$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.990$Conversational Response Selection#Douban#MAP#0.608$Conversational Response Selection#Douban#MRR#0.650$Conversational Response Selection#Douban#P@1#0.475$Conversational Response Selection#Douban#R10@1#0.299$Conversational Response Selection#Douban#R10@2#0.494$Conversational Response Selection#Douban#R10@5#0.822
2004.03588v2.pdf	Conversational Response Selection#RRS Ranking Test#NDCG@3#0.674$Conversational Response Selection#RRS Ranking Test#NDCG@5#0.753$Conversational Response Selection#RRS#R10@1#0.497$Conversational Response Selection#RRS#MAP#0.701$Conversational Response Selection#RRS#MRR#0.715$Conversational Response Selection#RRS#P@1#0.555$Conversational Response Selection#RRS#R10@2#0.685$Conversational Response Selection#RRS#R10@5#0.931$Conversational Response Selection#E-commerce#R10@1#0.704$Conversational Response Selection#E-commerce#R10@2#0.879$Conversational Response Selection#E-commerce#R10@5#0.985$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.855$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.928$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.983$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.965$Conversational Response Selection#Douban#MAP#0.619$Conversational Response Selection#Douban#MRR#0.659$Conversational Response Selection#Douban#P@1#0.496$Conversational Response Selection#Douban#R10@1#0.313$Conversational Response Selection#Douban#R10@2#0.481$Conversational Response Selection#Douban#R10@5#0.847
1908.04812v2.pdf	Conversational Response Selection#RRS Ranking Test#NDCG@3#0.625$Conversational Response Selection#RRS Ranking Test#NDCG@5#0.714$Conversational Response Selection#RRS#R10@1#0.404$Conversational Response Selection#RRS#MAP#0.625$Conversational Response Selection#RRS#MRR#0.639$Conversational Response Selection#RRS#P@1#0.453$Conversational Response Selection#RRS#R10@2#0.606$Conversational Response Selection#RRS#R10@5#0.875$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.855$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.928$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.985$Conversational Response Selection#Douban#MAP#0.591$Conversational Response Selection#Douban#MRR#0.633$Conversational Response Selection#Douban#P@1#0.454$Conversational Response Selection#Douban#R10@1#0.280$Conversational Response Selection#Douban#R10@2#0.470$Conversational Response Selection#Douban#R10@5#0.828
2012.14756v3.pdf	Conversational Response Selection#RRS#R10@1#0.454$Conversational Response Selection#RRS#MAP#0.671$Conversational Response Selection#RRS#MRR#0.683$Conversational Response Selection#RRS#P@1#0.503$Conversational Response Selection#RRS#R10@2#0.659$Conversational Response Selection#RRS#R10@5#0.917$Conversational Response Selection#E-commerce#R10@1#0.721$Conversational Response Selection#E-commerce#R10@2#0.896$Conversational Response Selection#E-commerce#R10@5#0.993$Conversational Response Selection#Douban#MAP#0.639$Conversational Response Selection#Douban#MRR#0.681$Conversational Response Selection#Douban#P@1#0.514$Conversational Response Selection#Douban#R10@1#0.330$Conversational Response Selection#Douban#R10@2#0.531$Conversational Response Selection#Douban#R10@5#0.858
1612.01627v2.pdf	Conversational Response Selection#RRS#R10@1#0.281$Conversational Response Selection#RRS#MAP#0.487$Conversational Response Selection#RRS#MRR#0.501$Conversational Response Selection#RRS#P@1#0.309$Conversational Response Selection#RRS#R10@2#0.442$Conversational Response Selection#RRS#R10@5#0.723$Conversational Response Selection#E-commerce#R10@1#0.453$Conversational Response Selection#E-commerce#R10@2#0.654$Conversational Response Selection#E-commerce#R10@5#0.886$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.726$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.822$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.960$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.926$Conversational Response Selection#Douban#MAP#0.529$Conversational Response Selection#Douban#MRR#0.569$Conversational Response Selection#Douban#P@1#0.397$Conversational Response Selection#Douban#R10@1#0.233$Conversational Response Selection#Douban#R10@2#0.396$Conversational Response Selection#Douban#R10@5#0.724
1901.02609v3.pdf	Conversational Response Selection#DSTC7 Ubuntu#1-of-100 Accuracy#64.5%$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.796$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.894$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.975$Conversational Response Selection#Advising Corpus#R@1#31.0$Conversational Response Selection#Advising Corpus#R@10#78.8$Conversational Response Selection#Advising Corpus#R@50#97.8
1812.00686v1.pdf	Conversational Response Selection#DSTC7 Ubuntu#1-of-100 Accuracy#60.8%
2009.06265v1.pdf	Conversational Response Selection#E-commerce#R10@1#0.776$Conversational Response Selection#E-commerce#R10@2#0.919$Conversational Response Selection#E-commerce#R10@5#0.991$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.884$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.946$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.990$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.975
2009.04703v2.pdf	Conversational Response Selection#E-commerce#R10@1#0.762$Conversational Response Selection#E-commerce#R10@2#0.905$Conversational Response Selection#E-commerce#R10@5#0.986$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.875$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.942$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.988$Conversational Response Selection#Douban#MAP#0.625$Conversational Response Selection#Douban#MRR#0.664$Conversational Response Selection#Douban#P@1#0.499$Conversational Response Selection#Douban#R10@1#0.318$Conversational Response Selection#Douban#R10@2#0.482$Conversational Response Selection#Douban#R10@5#0.858
1901.01824v2.pdf	Conversational Response Selection#E-commerce#R10@1#0.621$Conversational Response Selection#E-commerce#R10@2#0.797$Conversational Response Selection#E-commerce#R10@5#0.964$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.794$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.889$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.974$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.946$Conversational Response Selection#Douban#MAP#0.570$Conversational Response Selection#Douban#MRR#0.615$Conversational Response Selection#Douban#P@1#0.433$Conversational Response Selection#Douban#R10@1#0.262$Conversational Response Selection#Douban#R10@2#0.452$Conversational Response Selection#Douban#R10@5#0.789
1911.06940v1.pdf	Conversational Response Selection#E-commerce#R10@1#0.616$Conversational Response Selection#E-commerce#R10@2#0.806$Conversational Response Selection#E-commerce#R10@5#0.966$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.786$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.886$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.976$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.945
2004.02421v4.pdf	Conversational Response Selection#E-commerce#R10@1#0.613$Conversational Response Selection#E-commerce#R10@2#0.786$Conversational Response Selection#E-commerce#R10@5#0.964
1806.09102v2.pdf	Conversational Response Selection#E-commerce#R10@1#0.501$Conversational Response Selection#E-commerce#R10@2#0.700$Conversational Response Selection#E-commerce#R10@5#0.921$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.752$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.868$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.962$Conversational Response Selection#Douban#MAP#0.551$Conversational Response Selection#Douban#MRR#0.599$Conversational Response Selection#Douban#P@1#0.421$Conversational Response Selection#Douban#R10@1#0.243$Conversational Response Selection#Douban#R10@2#0.421$Conversational Response Selection#Douban#R10@5#0.780
2111.10154v2.pdf	Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.886$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.948$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.990
1909.10666v2.pdf	Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.790$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.885$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.970$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.943
1908.09890v1.pdf	Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.753$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.935
1510.03753v2.pdf	Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.630$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.780$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.944$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.895
1506.08909v3.pdf	Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@1#0.604$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@2#0.745$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R10@5#0.926$Conversational Response Selection#Ubuntu Dialogue (v1, Ranking)#R2@1#0.878
2010.15417v3.pdf	Lung Nodule Classification#LIDC-IDRI#Accuracy#94.11$Lung Nodule Classification#LIDC-IDRI#AUC#97.13
1901.00120v2.pdf	Lung Nodule Classification#LIDC-IDRI#Accuracy#92.57$Lung Nodule Classification#LIDC-IDRI#Accuracy(10-fold)#92.57$Lung Nodule Classification#LIDC-IDRI#AUC#95.14
1801.09555v1.pdf	Lung Nodule Classification#LIDC-IDRI#Accuracy#90.44$Lung Nodule Classification#LIDC-IDRI#Acc#90.44
1904.10126v1.pdf	Lung Nodule Classification#LIDC-IDRI#Accuracy#88.46$Lung Nodule Classification#LIDC-IDRI#Accuracy(10-fold)#88.46$Lung Nodule Classification#LIDC-IDRI#AUC#95.62
2109.13318v2.pdf	Sign Language Translation#RWTH-PHOENIX-Weather 2014 T#BLEU-4#25.59
2004.00588v2.pdf	Sign Language Translation#RWTH-PHOENIX-Weather 2014 T#BLEU-4#25.40$Sign Language Translation#ASLG-PC12#BLEU-4#82.87
2110.01274v1.pdf	Clustering Algorithms Evaluation#MNIST#F1-score#88%$Clustering Algorithms Evaluation#MNIST#ARI#77%$Clustering Algorithms Evaluation#MNIST#NMI#81%$Clustering Algorithms Evaluation#MNIST#F1-score#59%$Clustering Algorithms Evaluation#MNIST#ARI#42%$Clustering Algorithms Evaluation#MNIST#NMI#53%$Clustering Algorithms Evaluation#MNIST#F1-score#50%$Clustering Algorithms Evaluation#MNIST#ARI#36%$Clustering Algorithms Evaluation#MNIST#NMI#45%$Clustering Algorithms Evaluation#MNIST#F1-score#41%$Clustering Algorithms Evaluation#MNIST#ARI#33%$Clustering Algorithms Evaluation#MNIST#NMI#44%$Clustering Algorithms Evaluation#MNIST#F1-score#40%$Clustering Algorithms Evaluation#MNIST#ARI#17%$Clustering Algorithms Evaluation#MNIST#NMI#33%$Clustering Algorithms Evaluation#MNIST#F1-score#45%$Clustering Algorithms Evaluation#MNIST#ARI#13%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#65%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#49%$Clustering Algorithms Evaluation#Fashion-MNIST#NMI#61%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#39%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#35%$Clustering Algorithms Evaluation#Fashion-MNIST#NMI#51%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#43%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#34%$Clustering Algorithms Evaluation#Fashion-MNIST#NMI#49%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#56%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#32%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#47%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#29%$Clustering Algorithms Evaluation#Fashion-MNIST#NMI#45%$Clustering Algorithms Evaluation#Fashion-MNIST#F1-score#42%$Clustering Algorithms Evaluation#Fashion-MNIST#ARI#16%$Clustering Algorithms Evaluation#Fashion-MNIST#NMI#41%$Clustering Algorithms Evaluation#Olivetti face#F1-score#62%$Clustering Algorithms Evaluation#Olivetti face#NMI#78%$Clustering Algorithms Evaluation#Olivetti face#ARI#45%$Clustering Algorithms Evaluation#Olivetti face#F1-score#60%$Clustering Algorithms Evaluation#Olivetti face#NMI#79%$Clustering Algorithms Evaluation#Olivetti face#ARI#38%$Clustering Algorithms Evaluation#Olivetti face#F1-score#52%$Clustering Algorithms Evaluation#Olivetti face#NMI#74%$Clustering Algorithms Evaluation#Olivetti face#F1-score#37%$Clustering Algorithms Evaluation#Olivetti face#NMI#66%$Clustering Algorithms Evaluation#Olivetti face#ARI#19%$Clustering Algorithms Evaluation#Olivetti face#F1-score#34%$Clustering Algorithms Evaluation#Olivetti face#NMI#61%$Clustering Algorithms Evaluation#Olivetti face#ARI#21%
2009.01328v2.pdf	Clustering Algorithms Evaluation#97 synthetic datasets#HIT-THE-BEST#40$Clustering Algorithms Evaluation#97 synthetic datasets#Rank difference#415
2106.15252v1.pdf	Novel Class Discovery#cifar10#Clustering Accuracy#0.924$Novel Class Discovery#SVHN#Clustering Accuracy#0.954$Novel Class Discovery#cifar100#Clustering Accuracy#0.746
1902.06326v3.pdf	Birds Eye View Object Detection#KITTI Cars Easy#AP#81.7%$Birds Eye View Object Detection#KITTI Cars Moderate#AP#77.05%$Birds Eye View Object Detection#KITTI Cars Moderate val#AP#80.75$Birds Eye View Object Detection#KITTI Cars Hard#AP#72.95
1906.10958v3.pdf	Link Sign Prediction#Slashdot#AUC#0.8864$Link Sign Prediction#Slashdot#Accuracy#0.8482$Link Sign Prediction#Slashdot#Macro-F1#0.766$Link Sign Prediction#Bitcoin-Alpha#AUC#0.8942$Link Sign Prediction#Bitcoin-Alpha#Accuracy#0.9480$Link Sign Prediction#Bitcoin-Alpha#Macro-F1#0.7138$Link Sign Prediction#Epinions#AUC#0.9333$Link Sign Prediction#Epinions#Accuracy#0.9293$Link Sign Prediction#Epinions#Macro-F1#0.8449
1808.06354v1.pdf	Link Sign Prediction#Slashdot#AUC#0.804$Link Sign Prediction#Bitcoin-OTC#AUC#0.823$Link Sign Prediction#Bitcoin-Alpha#AUC#0.796$Link Sign Prediction#Epinions#AUC#0.864
1810.05080v1.pdf	Person Retrieval#SoftBioSearch#Average IOU#0.503$Person Retrieval#SoftBioSearch#Average IOU#0.363$Person Retrieval#SoftBioSearch#Average IOU#0.290
1904.10434v1.pdf	Stress-Strain Relation#Non-Linear Elasticity Benchmark#Time (ms)#3.5
1810.04394v1.pdf	Stress-Strain Relation#Non-Linear Elasticity Benchmark#Time (ms)#309.4
2106.04939v1.pdf	Keyword Extraction#SemEval2017#F1 score#67.13$Keyword Extraction#SemEval2017#F1 score#66.96$Keyword Extraction#SemEval2017#F1 score#65.94$Keyword Extraction#SemEval2017#F1 score#65.70$Keyword Extraction#SemEval 2010 Task 8#F1 score#48.65$Keyword Extraction#SemEval 2010 Task 8#F1 score#48.48$Keyword Extraction#SemEval 2010 Task 8#F1 score#47.46$Keyword Extraction#SemEval 2010 Task 8#F1 score#47.22$Keyword Extraction#Inspec#F1 score#69.87$Keyword Extraction#Inspec#F1 score#69.70$Keyword Extraction#Inspec#F1 score#68.68$Keyword Extraction#Inspec#F1 score#68.44
2104.04830v2.pdf	Keyword Extraction#SemEval2017#Precision@10#53.6$Keyword Extraction#SemEval2017#Recall@10#54.4$Keyword Extraction#SemEval2017#F1 score#54$Keyword Extraction#SemEval 2010 Task 8#Precision@10#41.5$Keyword Extraction#SemEval 2010 Task 8#Recall@10#34.3$Keyword Extraction#SemEval 2010 Task 8#F1 score#37.5$Keyword Extraction#Inspec#Precision@10#57.2$Keyword Extraction#Inspec#Recall @ 10#60.7$Keyword Extraction#Inspec#F1 score#58.9
2012.01634v1.pdf	Spatial Relation Recognition#Rel3D#Acc#94.25$Spatial Relation Recognition#Rel3D#Acc#85.03$Spatial Relation Recognition#Rel3D#Acc#81.24$Spatial Relation Recognition#Rel3D#Acc#74.14$Spatial Relation Recognition#Rel3D#Acc#73.3$Spatial Relation Recognition#Rel3D#Acc#73.25$Spatial Relation Recognition#Rel3D#Acc#72.32$Spatial Relation Recognition#Rel3D#Acc#72.27$Spatial Relation Recognition#Rel3D#Acc#50
1912.01131v2.pdf	Feature Engineering#2019_test set#14 gestures accuracy#0.98
1905.12149v1.pdf	Game of Sudoku#Sudoku 9x9#Accuracy#98.3
2106.11455v1.pdf	Text-To-Sql#KaggleDBQA#Exact Match (EM)#26.77$Text-To-Sql#KaggleDBQA#Exact Match (EM)#11.73
2112.08735v2.pdf	Text-To-Sql#SParC#interaction match accuracy#43.2$Text-To-Sql#SParC#question match accuracy#65.7
1810.05237v2.pdf	Text-To-Sql#SParC#interaction match accuracy#5.2$Text-To-Sql#SParC#question match accuracy#20.2
2106.05006v1.pdf	Text-To-Sql#SEDE#PCM-F1 (dev)#48.2$Text-To-Sql#SEDE#PCM-F1 (test)#50.6
2004.03125v1.pdf	Text-To-Sql#spider#Accuracy (Dev)#66.6$Text-To-Sql#spider#Accuracy (Test)#58.2
2202.08862v3.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#19.7$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.95$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#16.0$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.34$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#Unsupervised#Yes (MixIT pr-tr on LFSD50K)
2102.04629.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.82$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.79$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.77
2008.04470v1.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.7885
2010.15508v2.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#17.29$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.305$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.777
2102.07330v1.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.75$Speech Enhancement#DNS Challenge#PESQ-WB#2.75$Speech Enhancement#DEMAND#PESQ-WB#2.82
2005.11611v3.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.73$Speech Dereverberation#Deep Noise Suppression (DNS) Challenge#PESQ#2.75$Speech Dereverberation#Deep Noise Suppression (DNS) Challenge#ΔPESQ#0.93$Speech Dereverberation#Deep Noise Suppression (DNS) Challenge#PESQ#1.82
2110.10103v2.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#18.6$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.69$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#18.0$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.60$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#Unsupervised#Semi (pr-tr on WHAM!)
2001.10601v2.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#2.65$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-WB#2.65
2012.09408v2.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.39$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-NB#19.52
2008.00264v4.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.214$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.04
2005.07551v1.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#16.34$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.04$Speech Enhancement#WHAMR!#SI-SDR#2.12$Speech Enhancement#WHAMR!#PESQ#2.23$Speech Enhancement#WHAMR!#ΔPESQ#0.4
2006.00687v1.pdf	Speech Enhancement#Deep Noise Suppression (DNS) Challenge#SI-SDR-WB#16.22$Speech Enhancement#Deep Noise Suppression (DNS) Challenge#PESQ-NB#3.01$Speech Enhancement#WHAMR!#SI-SDR#5.33$Speech Enhancement#WHAMR!#PESQ#1.52$Speech Dereverberation#WHAMR!#SI-SDR#10.4$Speech Dereverberation#WHAMR!#PESQ#3.16
2202.02884v1.pdf	Speech Enhancement#WHAM!#PESQ#3.07$Speech Enhancement#WHAM!#SDR#15.04$Speech Enhancement#WHAM!#SI-SNR#14.35$Speech Enhancement#WHAMR!#PESQ#2.84$Speech Enhancement#WHAMR!#SI-SNR#10.58$Speech Enhancement#WHAMR!#SDR#12.29
2111.04312v1.pdf	Speech Enhancement#CHiME-3#SDR#19.67$Speech Enhancement#CHiME-3#PESQ#2.67$Speech Enhancement#CHiME-3#STOI#0.973
2001.11542v1.pdf	Speech Enhancement#CHiME-3#SDR#18.635$Speech Enhancement#CHiME-3#PESQ#2.436$Speech Enhancement#CHiME-3#ΔPESQ#1.16$Speech Enhancement#CHiME-3#SDR#18.402$Speech Enhancement#CHiME-3#SDR#16.855$Speech Enhancement#CHiME-3#SDR#15.967$Speech Enhancement#CHiME-3#PESQ#2.176$Speech Enhancement#CHiME-3#SDR#6.50$Speech Enhancement#CHiME-3#PESQ#1.27
2102.01993v1.pdf	Speech Enhancement#DNS Challenge#PESQ-NB#3.3$Speech Enhancement#DNS Challenge#PESQ-NB#3.21$Speech Enhancement#DNS Challenge#PESQ-NB#3.15$Speech Enhancement#DNS Challenge#PESQ-NB#3.04$Speech Enhancement#WSJ0 + DEMAND + RNNoise#PESQ-NB#3.44$Speech Enhancement#WSJ0 + DEMAND + RNNoise#PESQ-NB#3.28$Speech Enhancement#WSJ0 + DEMAND + RNNoise#PESQ-NB#3.25
2209.11112v2.pdf	Speech Enhancement#DEMAND#PESQ#3.41$Speech Enhancement#DEMAND#CSIG#4.63$Speech Enhancement#DEMAND#CBAK#3.94$Speech Enhancement#DEMAND#COVL#4.12$Speech Enhancement#DEMAND#STOI#96$Speech Enhancement#DEMAND#SSNR#11.1
2203.17152v4.pdf	Speech Enhancement#DEMAND#PESQ#3.35$Speech Enhancement#DEMAND#CSIG#4.43$Speech Enhancement#DEMAND#COVL#3.92$Speech Enhancement#DEMAND#STOI#95
2203.02181v1.pdf	Speech Enhancement#DEMAND#PESQ#3.21$Speech Enhancement#DEMAND#CSIG#4.53$Speech Enhancement#DEMAND#CBAK#3.65$Speech Enhancement#DEMAND#COVL#3.91
2204.03339v2.pdf	Speech Enhancement#DEMAND#PESQ#3.20$Speech Enhancement#DEMAND#CSIG#4.52$Speech Enhancement#DEMAND#CBAK#3.58$Speech Enhancement#DEMAND#COVL#3.88$Speech Enhancement#DEMAND#STOI#95.7
2010.11860v1.pdf	Speech Enhancement#DEMAND#PESQ#3.17$Speech Enhancement#DEMAND#CSIG#4.43$Speech Enhancement#DEMAND#CBAK#3.53$Speech Enhancement#DEMAND#COVL#3.83
2010.15174v3.pdf	Speech Enhancement#DEMAND#PESQ#3.15$Speech Enhancement#DEMAND#CSIG#4.18$Speech Enhancement#DEMAND#CBAK#3.60$Speech Enhancement#DEMAND#COVL#3.67
2104.03538v2.pdf	Speech Enhancement#DEMAND#PESQ#3.15$Speech Enhancement#DEMAND#CSIG#4.14$Speech Enhancement#DEMAND#CBAK#3.16$Speech Enhancement#DEMAND#COVL#3.64
2002.12794v1.pdf	Speech Enhancement#DEMAND#PESQ#3.02$Speech Enhancement#DEMAND#CSIG#4.38$Speech Enhancement#DEMAND#CBAK#3.43$Speech Enhancement#DEMAND#COVL#3.72$Speech Enhancement#DEMAND#PESQ#2.94$Speech Enhancement#DEMAND#CSIG#4.36$Speech Enhancement#DEMAND#CBAK#3.35$Speech Enhancement#DEMAND#COVL#3.67$Speech Enhancement#DEMAND#PESQ#2.93$Speech Enhancement#DEMAND#CSIG#4.29$Speech Enhancement#DEMAND#CBAK#3.32$Speech Enhancement#DEMAND#COVL#3.62$Speech Enhancement#DEMAND#PESQ#2.84$Speech Enhancement#DEMAND#CSIG#4.27$Speech Enhancement#DEMAND#CBAK#3.23$Speech Enhancement#DEMAND#COVL#3.56
1905.04874v1.pdf	Speech Enhancement#DEMAND#PESQ#2.86$Speech Enhancement#DEMAND#CSIG#3.99$Speech Enhancement#DEMAND#CBAK#3.18$Speech Enhancement#DEMAND#COVL#3.42
1910.07840v4.pdf	Speech Enhancement#DEMAND#PESQ#2.7$Speech Enhancement#DEMAND#CSIG#3.9$Speech Enhancement#DEMAND#CBAK#3.29$Speech Enhancement#DEMAND#COVL#3.29
1811.11307v1.pdf	Speech Enhancement#DEMAND#PESQ#2.4$Speech Enhancement#DEMAND#CSIG#3.52$Speech Enhancement#DEMAND#CBAK#3.24$Speech Enhancement#DEMAND#COVL#2.96
2107.04174v2.pdf	Speech Enhancement#EasyCom#STOI#0.544$Speech Enhancement#EasyCom#PESQ#1.17$Speech Enhancement#EasyCom#ViSQOL#1.68$Speech Enhancement#EasyCom#HASQI#0.249$Speech Enhancement#EasyCom#SIIB#139$Speech Enhancement#EasyCom#HASPI#0.830$Speech Enhancement#EasyCom#ESTOI#0.379$Speech Enhancement#EasyCom#SDR#-12.9$Speech Enhancement#EasyCom#SegSNR#-12.2$Speech Enhancement#EasyCom#SNR#-10.1$Speech Enhancement#EasyCom#SI-SDR#-23.4
2006.07637v1.pdf	Speech Enhancement#LibriSpeechDuplicate#Audio Quality MOS#3.1
2204.06439v3.pdf	Speech Dereverberation#WHAMR_ext#SI-SDR#7.07$Speech Dereverberation#WHAMR_ext#SI-SDRi#10.81$Speech Dereverberation#WHAMR_ext#PESQ#2.46$Speech Dereverberation#WHAMR_ext#ESTOI#81$Speech Dereverberation#WHAMR_ext#SRMR#9.18$Speech Dereverberation#WHAMR!#SI-SDR#12.03$Speech Dereverberation#WHAMR!#PESQ#3.46$Speech Dereverberation#WHAMR!#SI-SDRi#7.63$Speech Dereverberation#WHAMR!#ESTOI#93$Speech Dereverberation#WHAMR!#SRMR#8.7
2205.08455v3.pdf	Speech Dereverberation#WHAMR!#SI-SDR#12.26$Speech Dereverberation#WHAMR!#PESQ#3.5$Speech Dereverberation#WHAMR!#ESTOI#93.5$Speech Dereverberation#WHAMR!#SRMR#8.8
2205.13012v2.pdf	Time Series#2019_test set#Accuracy#83.1
2008.04210v3.pdf	COVID-19 Modelling#WHO-COVID19 Dataset#KS-GoF#0.99
1712.05884v2.pdf	Speech Synthesis#North American English#Mean Opinion Score#4.526$Speech Synthesis#North American English#Mean Opinion Score#4.341
1609.03499v2.pdf	Speech Synthesis#North American English#Mean Opinion Score#4.21$Speech Synthesis#North American English#Mean Opinion Score#3.86$Speech Synthesis#North American English#Mean Opinion Score#3.67$Speech Synthesis#Mandarin Chinese#Mean Opinion Score#4.08$Speech Synthesis#Mandarin Chinese#Mean Opinion Score#3.79$Speech Synthesis#Mandarin Chinese#Mean Opinion Score#3.47
1703.10135v2.pdf	Speech Synthesis#North American English#Mean Opinion Score#4.001
2108.13320v6.pdf	Speech Synthesis#LJSpeech#Mean Opinion Score#3.24$Speech Synthesis#LJSpeech#Mean Opinion Score#2.68
2108.11792v2.pdf	Information Retrieval#BSARD#Recall@100#74.78$Information Retrieval#BSARD#Recall@200#78.04$Information Retrieval#BSARD#Recall@500#83.39$Information Retrieval#BSARD#Recall@100#71.63$Information Retrieval#BSARD#Recall@200#78.38$Information Retrieval#BSARD#Recall@500#83.77$Information Retrieval#BSARD#Recall@100#51.33$Information Retrieval#BSARD#Recall@200#56.78$Information Retrieval#BSARD#Recall@500#64.71
2205.03284v2.pdf	Information Retrieval#MS MARCO#Time (ms)#0.3245$Information Retrieval#MS MARCO#Time (ms)#0.3294
2202.10728v1.pdf	Information Retrieval#MSLR-WEB30K#nDCG@10#0.5259
2107.13602v1.pdf	Passage Retrieval#Natural Questions#Precision@20#84.68$Passage Retrieval#Natural Questions#Precision@100#89.22
2110.06918v2.pdf	Passage Retrieval#Natural Questions#Precision@100#88.8
2010.08191v2.pdf	Passage Retrieval#Natural Questions#Precision@20#82.7$Passage Retrieval#Natural Questions#Precision@100#88.5
2007.00808v2.pdf	Passage Retrieval#Natural Questions#Precision@20#81.9$Passage Retrieval#Natural Questions#Precision@100#87.5
2009.08553v4.pdf	Passage Retrieval#Natural Questions#Precision@20#64.2$Passage Retrieval#Natural Questions#Precision@100#79.6
2203.07735v2.pdf	Passage Retrieval#Natural Questions#MRR#42.92
2004.14356v1.pdf	Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro Precision#27.4$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro Recall#24.4$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro F1#25.8$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro Precision#20.2$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro Recall#20.6$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro F1#19.7$Scientific Results Extraction#PWC Leaderboards (restricted)#Micro Precision#37.4$Scientific Results Extraction#PWC Leaderboards (restricted)#Micro Recall#23.2$Scientific Results Extraction#PWC Leaderboards (restricted)#Micro F1#28.7$Scientific Results Extraction#PWC Leaderboards (restricted)#Macro Precision#24$Scientific Results Extraction#PWC Leaderboards (restricted)#Macro Recall#21.8$Scientific Results Extraction#PWC Leaderboards (restricted)#Macro F1#21.1
1906.09317v1.pdf	Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro Precision#6.8$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro Recall#8.4$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Micro F1#7.5$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro Precision#9.5$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro Recall#8.6$Scientific Results Extraction#NLP-TDMS (Exp, arXiv only)#Macro F1#8.8
2203.12235v2.pdf	CCG Supertagging#CCGbank#Accuracy#96.29
2104.12259v1.pdf	Graph Classification#UPFD-GOS#Accuracy (%)#97.54$Graph Classification#UPFD-GOS#Accuracy (%)#96.52$Graph Classification#UPFD-GOS#Accuracy (%)#96.11$Graph Classification#UPFD-GOS#Accuracy (%)#95.90$Graph Classification#UPFD-GOS#Accuracy (%)#95.11$Graph Classification#UPFD-GOS#Accuracy (%)#93.60$Graph Classification#UPFD-GOS#Accuracy (%)#91.27$Graph Classification#UPFD-POL#Accuracy (%)#84.62$Graph Classification#UPFD-POL#Accuracy (%)#83.71$Graph Classification#UPFD-POL#Accuracy (%)#83.26$Graph Classification#UPFD-POL#Accuracy (%)#82.81$Graph Classification#UPFD-POL#Accuracy (%)#82.35$Graph Classification#UPFD-POL#Accuracy (%)#81.90$Graph Classification#UPFD-POL#Accuracy (%)#60.18
1907.09495v2.pdf	Graph Classification#HIV-fMRI-77#Accuracy#73.4%$Graph Classification#HIV-fMRI-77#F1#72.2%$Graph Classification#HIV-fMRI-77#Accuracy#70.5%$Graph Classification#HIV-fMRI-77#F1#69.9%$Graph Classification#HIV-fMRI-77#Accuracy#73.4$Graph Classification#HIV-fMRI-77#F1#72.2$Graph Classification#PTC#Accuracy#59.9%$Graph Classification#MUTAG#Accuracy#83.3%$Graph Classification#BP-fMRI-97#Accuracy#64.9%$Graph Classification#BP-fMRI-97#F1#69.7%$Graph Classification#BP-fMRI-97#Accuracy#62.3%$Graph Classification#BP-fMRI-97#F1#63.2%$Graph Classification#HIV-DTI-77#Accuracy#67.5%$Graph Classification#HIV-DTI-77#F1#68.3%$Graph Classification#HIV-DTI-77#Accuracy#60.1%$Graph Classification#HIV-DTI-77#F1#61.9%
1905.06393v1.pdf	Graph Classification#IPC-grounded#Accuracy#73.1%$Graph Classification#IPC-lifted#Accuracy#86.9%
1904.12189v2.pdf	Graph Classification#NEURON-Average#Accuracy#77.80$Graph Classification#NEURON-Average#Accuracy#73.50$Graph Classification#NCI109#Accuracy#87.3$Graph Classification#PROTEINS#Accuracy#78.8%$Graph Classification#NCI1#Accuracy#87.2%$Graph Classification#NEURON-BINARY#Accuracy#90.3$Graph Classification#NEURON-BINARY#Accuracy#86.5$Graph Classification#MUTAG#Accuracy#87.5%$Graph Classification#IMDb-B#Accuracy#75.4%$Graph Classification#NEURON-MULTI#Accuracy#69.1$Graph Classification#NEURON-MULTI#Accuracy#56.2$Graph Classification#IMDb-M#Accuracy#49.5%$Graph Classification#D&D#Accuracy#82.0%
1706.03358v3.pdf	Graph Classification#NEURON-Average#Accuracy#71.20$Graph Classification#NEURON-BINARY#Accuracy#85.1$Graph Classification#NEURON-MULTI#Accuracy#57.3
1507.06217v3.pdf	Graph Classification#NEURON-Average#Accuracy#64.20$Graph Classification#NEURON-BINARY#Accuracy#84.1$Graph Classification#NEURON-MULTI#Accuracy#44.3
1706.03472v1.pdf	Graph Classification#NEURON-Average#Accuracy#62.80$Graph Classification#NEURON-BINARY#Accuracy#80.1$Graph Classification#NEURON-MULTI#Accuracy#45.5
1910.11436v2.pdf	Graph Classification#Bench-hard#Accuracy#72.6$Graph Classification#PROTEINS#Accuracy#73.3%$Graph Classification#NCI1#Accuracy#73.5%$Graph Classification#MUTAG#Accuracy#84.7%$Graph Classification#Mutagenicity#Accuracy#78.1$Graph Classification#COLLAB#Accuracy#79.1%$Graph Classification#ENZYMES#Accuracy#43.9%$Graph Classification#5pt. Bench-Easy#Accuracy#97.9$Graph Classification#REDDIT-B#Accuracy#84.3$Graph Classification#D&D#Accuracy#72%
1606.01141v3.pdf	Graph Classification#NCI109#Accuracy#86.3$Graph Classification#PROTEINS#Accuracy#76.4%$Graph Classification#NCI1#Accuracy#86.1%$Graph Classification#MUTAG#Accuracy#84.5%
1904.01543v3.pdf	Graph Classification#NCI109#Accuracy#84.7$Graph Classification#PTC#Accuracy#62.70%$Graph Classification#PROTEINS#Accuracy#74.60%$Graph Classification#NCI1#Accuracy#85.5%$Graph Classification#IMDb-B#Accuracy#73.4%$Graph Classification#ENZYMES#Accuracy#58.2%$Graph Classification#REDDIT-B#Accuracy#89.0$Graph Classification#IMDb-M#Accuracy#50.5%
2209.08179v1.pdf	Graph Classification#NCI109#Accuracy#83.6$Graph Classification#PTC#Accuracy#72.8%$Graph Classification#PROTEINS#Accuracy#78.2%$Graph Classification#NCI1#Accuracy#84.5%$Graph Classification#MUTAG#Accuracy#94.1%
1811.04393v1.pdf	Graph Classification#NCI109#Accuracy#82.86$Graph Classification#PTC#Accuracy#77.64%$Graph Classification#PROTEINS#Accuracy#77.65%$Graph Classification#NCI1#Accuracy#84.08%$Graph Classification#MUTAG#Accuracy#94.44%$Graph Classification#ENZYMES#Accuracy#62.50%
1811.09595v1.pdf	Graph Classification#NCI109#Accuracy#82.0$Graph Classification#PROTEINS#Accuracy#76.5%$Graph Classification#NCI1#Accuracy#83.4%$Graph Classification#MUTAG#Accuracy#89.1%$Graph Classification#ENZYMES#Accuracy#61.7%
1911.05954v3.pdf	Graph Classification#NCI109#Accuracy#80.67$Graph Classification#PROTEINS#Accuracy#84.91%$Graph Classification#NCI1#Accuracy#78.45%$Graph Classification#Mutagenicity#Accuracy#82.15$Graph Classification#ENZYMES#Accuracy#68.79%$Graph Classification#D&D#Accuracy#80.96%
1807.02653v1.pdf	Graph Classification#NCI109#Accuracy#80.66$Graph Classification#PTC#Accuracy#73.24%$Graph Classification#MUTAG#Accuracy#95.00%$Graph Classification#IMDb-B#Accuracy#79.90%$Graph Classification#COLLAB#Accuracy#83.16%$Graph Classification#ENZYMES#Accuracy#67.50%$Graph Classification#IMDb-M#Accuracy#54.53%
1904.13107v2.pdf	Graph Classification#NCI109#Accuracy#74.90$Graph Classification#NC1#Accuracy#0.770$Graph Classification#PROTEINS#Accuracy#76.60%$Graph Classification#MUTAG#Accuracy#79.5%$Graph Classification#ENZYMES#Accuracy#65.0%$Graph Classification#D&D#Accuracy#78.6%
1904.01098v2.pdf	Graph Classification#NCI109#Accuracy#74.48$Graph Classification#NCI109#Accuracy#69.17$Graph Classification#PTC#Accuracy#73.56%$Graph Classification#PTC#Accuracy#72.54%$Graph Classification#REDDIT-MULTI-12K#Accuracy#41.84$Graph Classification#REDDIT-MULTI-12K#Accuracy#39.97$Graph Classification#Web#Accuracy#45.03$Graph Classification#IMDb-M#Accuracy#50.97%$Graph Classification#IMDb-M#Accuracy#50.06%
1904.08082v4.pdf	Graph Classification#NCI109#Accuracy#74.06$Graph Classification#NCI109#Accuracy#67.86$Graph Classification#PROTEINS#Accuracy#71.86%$Graph Classification#PROTEINS#Accuracy#70.04%$Graph Classification#NCI1#Accuracy#74.06%$Graph Classification#NCI1#Accuracy#67.45%$Graph Classification#FRANKENSTEIN#Accuracy#62.57$Graph Classification#FRANKENSTEIN#Accuracy#61.73$Graph Classification#D&D#Accuracy#76.45%$Graph Classification#D&D#Accuracy#76.19%
1903.09022v3.pdf	Graph Classification#NCI109#Accuracy#71.06$Graph Classification#PTC#Accuracy#65.88%$Graph Classification#PROTEINS#Accuracy#76.78%$Graph Classification#NCI1#Accuracy#70.26%$Graph Classification#MUTAG#Accuracy#93.68%$Graph Classification#IMDb-B#Accuracy#75.70%
1911.07979v3.pdf	Graph Classification#NCI109#Accuracy#70.07$Graph Classification#PROTEINS#Accuracy#74.19%$Graph Classification#NCI1#Accuracy#71.48$Graph Classification#FRANKENSTEIN#Accuracy#66.26$Graph Classification#D&D#Accuracy#76.87
1902.08399v1.pdf	Graph Classification#NCI109#Accuracy#58.04$Graph Classification#PTC#Accuracy#69%$Graph Classification#PROTEINS#Accuracy#74.1%$Graph Classification#NCI1#Accuracy#65.9%$Graph Classification#MUTAG#Accuracy#88.9%$Graph Classification#ENZYMES#Accuracy#27%$Graph Classification#D&D#Accuracy#74.86%
2102.11533v4.pdf	Graph Classification#ToxCast#ROC-AUC#65.44$Graph Classification#HIV#ROC-AUC#77.56$Graph Classification#PROTEINS#Accuracy#75.09%$Graph Classification#Tox21#ROC-AUC#77.3$Graph Classification#MUTAG#Accuracy#83.44%$Graph Classification#BBBP#ROC-AUC#68.31$Graph Classification#IMDb-B#Accuracy#73.48%$Graph Classification#COLLAB#Accuracy#80.74%$Graph Classification#IMDb-M#Accuracy#50.66%$Graph Classification#HIV dataset#ROC-AUC#77.56$Graph Classification#D&D#Accuracy#78.72%
2203.10453v1.pdf	Graph Classification#ToxCast#ROC-AUC#64$Graph Classification#BACE#ROC-AUC#83.4$Graph Classification#HIV#ROC-AUC#78.2$Graph Classification#SIDER#ROC-AUC#63.5$Graph Classification#Tox21#ROC-AUC#75.6$Graph Classification#BBBP#ROC-AUC#70$Graph Classification#ClinTox#ROC-AUC#72$Graph Classification#MUV#ROC-AUC#80
1909.11855v9.pdf	Graph Classification#PTC#Accuracy#91.81%$Graph Classification#PTC#Accuracy#69.63%$Graph Classification#PROTEINS#Accuracy#80.01%$Graph Classification#PROTEINS#Accuracy#78.53%$Graph Classification#MUTAG#Accuracy#89.97%$Graph Classification#MUTAG#Accuracy#88.47%$Graph Classification#IMDb-B#Accuracy#96.41%$Graph Classification#IMDb-B#Accuracy#77.04%$Graph Classification#COLLAB#Accuracy#95.62%$Graph Classification#COLLAB#Accuracy#77.84%$Graph Classification#IMDb-M#Accuracy#89.20%$Graph Classification#IMDb-M#Accuracy#53.60%$Graph Classification#D&D#Accuracy#95.67%$Graph Classification#D&D#Accuracy#80.23%
1909.10086v3.pdf	Graph Classification#PTC#Accuracy#74.7%$Graph Classification#PROTEINS#Accuracy#81.70%$Graph Classification#IMDb-B#Accuracy#78.70%$Graph Classification#COLLAB#Accuracy#84.20%$Graph Classification#ENZYMES#Accuracy#67.30%$Graph Classification#IMDb-M#Accuracy#56.10%$Graph Classification#D&D#Accuracy#82.40%
2002.03283v1.pdf	Graph Classification#PTC#Accuracy#68.86%$Graph Classification#PROTEINS#Accuracy#77.09%$Graph Classification#MUTAG#Accuracy#90.85%$Graph Classification#IMDb-B#Accuracy#77.2%$Graph Classification#COLLAB#Accuracy#78.42%$Graph Classification#IMDb-M#Accuracy#53.4%
2006.09430v2.pdf	Graph Classification#PTC#Accuracy#67.5%$Graph Classification#PROTEINS#Accuracy#76.5%$Graph Classification#NCI1#Accuracy#76.8%$Graph Classification#MUTAG#Accuracy#88.3%$Graph Classification#RE-M5K#Accuracy#55.1%$Graph Classification#IMDb-B#Accuracy#75.4%$Graph Classification#COLLAB#Accuracy#79.8%$Graph Classification#RE-M12K#Accuracy#47.8%$Graph Classification#ENZYMES#Accuracy#60.5$Graph Classification#REDDIT-B#Accuracy#92$Graph Classification#IMDb-M#Accuracy#52%$Graph Classification#D&D#Accuracy#78.6%$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7757 ± 0.0111$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8101 ± 0.0097$Graph Property Prediction#ogbg-molhiv#Number of params#361064$Graph Property Prediction#ogbg-molhiv#Ext. data#No
1906.01277v2.pdf	Graph Classification#PTC#Accuracy#66.31%$Graph Classification#PROTEINS#Accuracy#74.28%$Graph Classification#NCI1#Accuracy#85.75%$Graph Classification#MUTAG#Accuracy#87.27%$Graph Classification#ENZYMES#Accuracy#59.13%$Graph Classification#D&D#Accuracy#79.69%
2111.06283v1.pdf	Graph Classification#PTC#Accuracy#66.3%$Graph Classification#PROTEINS#Accuracy#76.3%$Graph Classification#MUTAG#Accuracy#90.4%$Graph Classification#IMDb-B#Accuracy#75.7%$Graph Classification#IMDb-M#Accuracy#51.4%
1712.03563v1.pdf	Graph Classification#PTC#Accuracy#65.43%$Graph Classification#PROTEINS#Accuracy#75.1%$Graph Classification#COLLAB#Accuracy#68.34%$Graph Classification#AIDS#Accuracy#65.1$Graph Classification#D&D#Accuracy#77.21%
1907.04652v1.pdf	Graph Classification#PTC#Accuracy#65.02%$Graph Classification#PTC#Accuracy#63.53%$Graph Classification#PTC#Accuracy#62.94%$Graph Classification#PROTEINS#Accuracy#78.65%$Graph Classification#PROTEINS#Accuracy#78.23%$Graph Classification#PROTEINS#Accuracy#77.92%$Graph Classification#MUTAG#Accuracy#90.00%$Graph Classification#COLLAB#Accuracy#77.48%$Graph Classification#IMDb-M#Accuracy#49.06%$Graph Classification#D&D#Accuracy#81.71%
1904.09671v1.pdf	Graph Classification#PTC#Accuracy#63.14%$Graph Classification#NCI1#Accuracy#68.1%$Graph Classification#MUTAG#Accuracy#91.58%$Graph Classification#D&D#Accuracy#83.14%
1904.02278v1.pdf	Graph Classification#PTC#Accuracy#62.88%$Graph Classification#PROTEINS#Accuracy#76.33%$Graph Classification#NCI1#Accuracy#81.68%$Graph Classification#MUTAG#Accuracy#87.22%$Graph Classification#ENZYMES#Accuracy#58.17%
1810.09155v2.pdf	Graph Classification#PTC#Accuracy#62.8%$Graph Classification#PROTEINS#Accuracy#73.6%$Graph Classification#NCI1#Accuracy#75.2%$Graph Classification#MUTAG#Accuracy#88.4%$Graph Classification#ENZYMES#Accuracy#43.7%$Graph Classification#D&D#Accuracy#24.6%
1811.03508v3.pdf	Graph Classification#PTC#Accuracy#61.7%$Graph Classification#PROTEINS#Accuracy#74.7%$Graph Classification#PROTEINS#Accuracy#73.7%$Graph Classification#PROTEINS#Accuracy#72.7%$Graph Classification#NCI1#Accuracy#73.0%$Graph Classification#MUTAG#Accuracy#90.1%$Graph Classification#ENZYMES#Accuracy#35.3%$Graph Classification#D&D#Accuracy#77.5%$Graph Classification#D&D#Accuracy#75.5%
1908.01000v3.pdf	Graph Classification#PTC#Accuracy#61.65$Graph Classification#MUTAG#Accuracy#89.01%$Graph Classification#IMDb-B#Accuracy#73.03%$Graph Classification#IMDb-M#Accuracy#49.69%
1605.05273v4.pdf	Graph Classification#PTC#Accuracy#60.00%$Graph Classification#NCI1#Accuracy#76.34%$Graph Classification#MUTAG#Accuracy#92.63%$Graph Classification#MUTAG#Accuracy#88.95%$Graph Classification#IMDb-B#Accuracy#71.00%$Graph Classification#D&D#Accuracy#76.27%
1906.02319v1.pdf	Graph Classification#PTC#Accuracy#57.2%$Graph Classification#PROTEINS#Accuracy#70.8%$Graph Classification#MUTAG#Accuracy#81.4%$Graph Classification#ENZYMES#Accuracy#27.2$Node Classification#Flickr#Accuracy#0.656 ± 0.000$Node Classification#Wiki-Vote#Accuracy#99.8$Node Classification#USA Air-Traffic#Accuracy#64.7$Node Classification#Facebook#Accuracy#91.9$Node Classification#Brazil Air-Traffic#Accuracy#0.543 ± 0.034$Node Classification#Europe Air-Traffic#Accuracy#45.9$Node Classification#Eximtradedata#Accuracy#84.9%
1806.08804v4.pdf	Graph Classification#REDDIT-MULTI-12K#Accuracy#47.08$Graph Classification#PROTEINS#Accuracy#76.25%$Graph Classification#COLLAB#Accuracy#75.48%$Graph Classification#ENZYMES#Accuracy#63.33%$Graph Classification#ENZYMES#Accuracy#62.53%$Graph Classification#D&D#Accuracy#82.07%$Graph Classification#D&D#Accuracy#80.64%
2107.01410v1.pdf	Graph Classification#PROTEINS#Accuracy#80.71%$Graph Classification#MUTAG#Accuracy#96.66%$Graph Classification#Mutagenicity#Accuracy#80.66$Graph Classification#FRANKENSTEIN#Accuracy#73.46$Graph Classification#IMDb-B#Accuracy#82.13%$Graph Classification#COLLAB#Accuracy#79.66%$Graph Classification#IMDb-M#Accuracy#56.23%$Graph Classification#D&D#Accuracy#84.33%
2106.13061v4.pdf	Graph Classification#PROTEINS#Accuracy#77.8%$Graph Classification#NCI1#Accuracy#74.9%$Graph Classification#Pubmed#Test Accuracy#78.5$Graph Classification#ENZYMES#Accuracy#48.5
1905.05178v1.pdf	Graph Classification#PROTEINS#Accuracy#77.68%$Graph Classification#COLLAB#Accuracy#77.56%$Graph Classification#D&D#Accuracy#82.43%$Node Classification#Pubmed#Accuracy#79.6 ± 0.2%$Node Classification#Cora#Accuracy#84.4% ± 0.6%$Node Classification#Citeseer#Accuracy#73.2 ± 0.5%
1905.04579v3.pdf	Graph Classification#PROTEINS#Accuracy#77.44%$Graph Classification#PROTEINS#Accuracy#76.46%$Graph Classification#NCI1#Accuracy#83.65%$Graph Classification#NCI1#Accuracy#81.43%$Graph Classification#MUTAG#Accuracy#90.84%$Graph Classification#MUTAG#Accuracy#89.89%$Graph Classification#RE-M5K#Accuracy#49.75%$Graph Classification#RE-M5K#Accuracy#49.43%$Graph Classification#IMDb-B#Accuracy#73.00%$Graph Classification#COLLAB#Accuracy#81.50%$Graph Classification#COLLAB#Accuracy#81.34%$Graph Classification#RE-M12K#Accuracy#49.75%$Graph Classification#RE-M12K#Accuracy#49.43%$Graph Classification#ENZYMES#Accuracy#70.17%$Graph Classification#ENZYMES#Accuracy#69.50%$Graph Classification#IMDb-M#Accuracy#51.80%$Graph Classification#IMDb-M#Accuracy#51.20%$Graph Classification#D&D#Accuracy#78.78%$Graph Classification#D&D#Accuracy#78.62%
1904.05003v1.pdf	Graph Classification#PROTEINS#Accuracy#77.26%$Graph Classification#D&D#Accuracy#80.88%
1905.02850v3.pdf	Graph Classification#PROTEINS#Accuracy#77.09%$Graph Classification#COLLAB#Accuracy#66.97%$Graph Classification#D&D#Accuracy#78.36%
1907.02204v4.pdf	Graph Classification#PROTEINS#Accuracy#76.81%$Graph Classification#NCI1#Accuracy#82.28%$Graph Classification#MUTAG#Accuracy#90.44%$Graph Classification#RE-M5K#Accuracy#57.22%$Graph Classification#ENZYMES#Accuracy#58.45$Graph Classification#REDDIT-B#Accuracy#92.57
2007.00346v2.pdf	Graph Classification#PROTEINS#Accuracy#76.5$Graph Classification#NCI1#Accuracy#73.5$Graph Classification#IMDb-B#Accuracy#72.2$Graph Classification#REDDIT-B#Accuracy#89.4$Graph Classification#D&D#Accuracy#75.4
1810.02244v5.pdf	Graph Classification#PROTEINS#Accuracy#76.4%$Graph Classification#PROTEINS#Accuracy#75.9%$Graph Classification#NCI1#Accuracy#86.1%$Graph Classification#NCI1#Accuracy#76.2%$Graph Classification#MUTAG#Accuracy#87.7%$Graph Classification#MUTAG#Accuracy#86.1%$Graph Classification#IMDb-B#Accuracy#74.2%$Graph Classification#IMDb-B#Accuracy#73.5%$Graph Classification#IMDb-M#Accuracy#51.5%$Graph Classification#IMDb-M#Accuracy#49.5%
1805.08090v4.pdf	Graph Classification#PROTEINS#Accuracy#76.40%$Graph Classification#NCI1#Accuracy#82.72%$Graph Classification#IMDb-B#Accuracy#71.69%$Graph Classification#D&D#Accuracy#77.62%
1603.06186v2.pdf	Graph Classification#PROTEINS#Accuracy#76.34%
1904.12218v2.pdf	Graph Classification#PROTEINS#Accuracy#76.31%$Graph Classification#NCI1#Accuracy#85.12%
2206.07369v2.pdf	Graph Classification#PROTEINS#Accuracy#75.38%$Graph Classification#PROTEINS#Accuracy#75.34%$Graph Classification#PROTEINS#Accuracy#75.03%$Graph Classification#PROTEINS#Accuracy#74.91%$Graph Classification#MUTAG#Accuracy#86.9%$Graph Classification#MUTAG#Accuracy#86.05%$Graph Classification#COLLAB#Accuracy#72.24%$Graph Classification#COLLAB#Accuracy#69.87%$Graph Classification#COLLAB#Accuracy#65.89%$Graph Classification#COLLAB#Accuracy#64.47%$Graph Classification#IMDB-BINARY#Accuracy#69.93$Graph Classification#IMDB-BINARY#Accuracy#69.84$Graph Classification#IMDB-BINARY#Accuracy#69.8$Graph Classification#IMDB-BINARY#Accuracy#68.8$Graph Classification#REDDIT-BINARY#Accuracy#78.45$Graph Classification#REDDIT-BINARY#Accuracy#77.63$Graph Classification#REDDIT-BINARY#Accuracy#77.17$Graph Classification#REDDIT-BINARY#Accuracy#76
1903.02428v3.pdf	Graph Classification#PROTEINS#Accuracy#75.1%$Graph Classification#MUTAG#Accuracy#85.7%$Graph Classification#IMDb-B#Accuracy#72.8%$Graph Classification#COLLAB#Accuracy#80.6%$Graph Classification#REDDIT-B#Accuracy#92.1$Node Classification#Pubmed#Accuracy#79.4 ± 2.2$Node Classification#Cora#Accuracy#82.2% ± 1.5%$Node Classification#Citeseer#Accuracy#70.0 ± 1.4
1905.03046v1.pdf	Graph Classification#PROTEINS#Accuracy#75%
1902.02721v4.pdf	Graph Classification#PROTEINS#Accuracy#74.8%$Graph Classification#NCI1#Accuracy#80.7%$Graph Classification#MUTAG#Accuracy#86.3%$Graph Classification#ENZYMES#Accuracy#48.4%
1805.09114v3.pdf	Graph Classification#PROTEINS#Accuracy#74.55%$Graph Classification#NCI1#Accuracy#86.42%$Graph Classification#NCI1#Accuracy#85.82%$Graph Classification#NCI1#Accuracy#72.82%$Graph Classification#MUTAG#Accuracy#88.42%$Graph Classification#MUTAG#Accuracy#86.42%$Graph Classification#MUTAG#Accuracy#83.26%$Graph Classification#ENZYMES#Accuracy#71.00%
1912.09893v3.pdf	Graph Classification#PROTEINS#Accuracy#73.7%$Graph Classification#PROTEINS#Accuracy#73%$Graph Classification#NCI1#Accuracy#80%$Graph Classification#NCI1#Accuracy#76.4%$Graph Classification#IMDb-B#Accuracy#68.8%$Graph Classification#COLLAB#Accuracy#73.9%$Graph Classification#REDDIT-MULTI-5k#Accuracy#50$Graph Classification#ENZYMES#Accuracy#59.6%$Graph Classification#ENZYMES#Accuracy#58.2%$Graph Classification#REDDIT-B#Accuracy#84.3$Graph Classification#IMDb-M#Accuracy#47.6%$Graph Classification#D&D#Accuracy#76.6%
1905.10990v1.pdf	Graph Classification#PROTEINS#Accuracy#73.5%$Graph Classification#PROTEINS#Accuracy#72.5%
1905.06259v2.pdf	Graph Classification#PROTEINS#Accuracy#72.8%$Graph Classification#MUTAG#Accuracy#83.3%
1909.03287v1.pdf	Graph Classification#PROTEINS#Accuracy#72.1%$Graph Classification#NCI1#Accuracy#66.2%$Graph Classification#COLLAB#Accuracy#65.0%$Graph Classification#ENZYMES#Accuracy#24.1%$Graph Classification#D&D#Accuracy#76.0%
1708.05207v3.pdf	Graph Classification#NCI1#Accuracy#85.50%
1904.08745v2.pdf	Graph Classification#MUTAG#Accuracy#88.8%$Graph Classification#MUTAG#Accuracy#86.9%
1805.11921v3.pdf	Graph Classification#MUTAG#Accuracy#87.87%$Graph Classification#IMDb-B#Accuracy#74.45%$Graph Classification#D&D#Accuracy#71.51%
1708.02218v4.pdf	Graph Classification#RE-M5K#Accuracy#52.11%$Graph Classification#IMDb-B#Accuracy#70.40%$Graph Classification#COLLAB#Accuracy#71.76%$Graph Classification#RE-M12K#Accuracy#48.13%
2205.10803v3.pdf	Graph Classification#COLLAB#Accuracy#80.32%$Node Classification#Cora: fixed 20 node per class#Accuracy#84.2
2003.11702v1.pdf	Graph Classification#ENZYMES#Accuracy#78.39$Graph Classification#ENZYMES#Accuracy#65.13$Node Classification#PPI#F1#99.09 ± 0.03$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.3$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.2%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#81.9%$Node Classification#Cora: fixed 20 node per class#Accuracy#84.2
2010.02863v4.pdf	Graph Classification#CIFAR10 100k#Accuracy (%)#72.84$Node Classification#PATTERN 100k#Accuracy (%)#86.680$Graph Property Prediction#ogbg-molpcba#Test AP#0.2885 ± 0.0030$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2970 ± 0.0021$Graph Property Prediction#ogbg-molpcba#Number of params#6732696$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7970 ± 0.0097$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8470 ± 0.0047$Graph Property Prediction#ogbg-molhiv#Number of params#114065$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2006.05353v3.pdf	3D Object Recognition#SHREC11, Split16-4#Per-Class Accuracy#98.6$3D Object Recognition#SHREC11, Split10-10#Per-Class Accuracy#97.1$3D Object Recognition#Cube Engraving#Accuracy#98.6$3D Object Recognition#ModelNet40#Accuracy#92.3%
1604.03265v2.pdf	3D Object Recognition#ModelNet40#Accuracy#93.8%$3D Point Cloud Classification#ModelNet40#Overall Accuracy#89.2
1605.06240v3.pdf	3D Object Recognition#ModelNet40#Accuracy#88.4%
1705.05994v4.pdf	3D Object Recognition#ModelNet40#Accuracy#84.5%
1607.08764v1.pdf	Depiction Invariant Object Recognition#Photo-Art-50#Overall Accuracy#93.02%
1802.09127v1.pdf	Multi-Armed Bandits#Mushroom#Cumulative regret#1.82$Multi-Armed Bandits#Mushroom#Cumulative regret#1.92
1904.04195v1.pdf	Vision-Language Navigation#Room2Room#spl#0.61$Vision and Language Navigation#VLN Challenge#success#0.69$Vision and Language Navigation#VLN Challenge#length#686.82$Vision and Language Navigation#VLN Challenge#error#3.26$Vision and Language Navigation#VLN Challenge#oracle success#0.99$Vision and Language Navigation#VLN Challenge#spl#0.01$Vision and Language Navigation#VLN Challenge#success#0.51$Vision and Language Navigation#VLN Challenge#length#11.66$Vision and Language Navigation#VLN Challenge#error#5.23$Vision and Language Navigation#VLN Challenge#oracle success#0.59$Vision and Language Navigation#VLN Challenge#spl#0.47
1903.02547v2.pdf	Vision-Language Navigation#Room2Room#spl#0.41$Vision and Language Navigation#VLN Challenge#success#0.61$Vision and Language Navigation#VLN Challenge#length#196.53$Vision and Language Navigation#VLN Challenge#error#4.29$Vision and Language Navigation#VLN Challenge#oracle success#0.9$Vision and Language Navigation#VLN Challenge#spl#0.03$Vision and Language Navigation#VLN Challenge#success#0.54$Vision and Language Navigation#VLN Challenge#length#22.08$Vision and Language Navigation#VLN Challenge#error#5.14$Vision and Language Navigation#VLN Challenge#oracle success#0.64$Vision and Language Navigation#VLN Challenge#spl#0.41
1804.00823v4.pdf	SQL-to-Text#WikiSQL#BLEU-4#38.97
1804.03287v3.pdf	Multi-Human Parsing#MHP v2.0#AP 0.5#25.14%$Multi-Human Parsing#MHP v1.0#AP 0.5#57.09%$Multi-Human Parsing#PASCAL-Part#AP 0.5#59.70%
1705.07206v2.pdf	Multi-Human Parsing#MHP v2.0#AP 0.5#17.99%$Multi-Human Parsing#MHP v1.0#AP 0.5#50.10%
1709.03612v1.pdf	Multi-Human Parsing#PASCAL-Part#AP 0.5#40.60%
2210.07606v1.pdf	Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#76.08 ± 2.13$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#75.93 ± 1.71$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#75.51 ± 1.58$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#75.23 ± 1.72$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#68.51 ± 1.7$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#68.4 ± 2.05$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#68.38 ± 1.36$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#67.83 ±  2.63$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#67.53 ± 2.83$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#63.68 ± 1.62$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#61.66 ± 2.29$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#60.48 ± 1.55$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#58.73 ± 2.52$Node Classification#Chameleon (60%/20%/20% random splits)#1:1 Accuracy#46.72 ± 0.46$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.86 ± 1.48$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.84 ± 1.15$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.79 ± 1.01$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.66 ± 1.42$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.5 ± 1.54$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.4 ± 1.23$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.37 ± 1.37$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.27 ± 1.24$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.27 ± 0.8$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#41.1 ± 0.75$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#40.31 ± 1.6$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#40.13 ± 1.21$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#39.33 ± 1.25$Node Classification#Film (60%/20%/20% random splits)#1:1 Accuracy#38.58 ± 0.25$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#69.98 ± 1.53$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#69.81 ± 1.11$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#69.26 ± 1.11$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#68.56 ± 1.33$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#55.97 ± 2.03$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#55.73 ± 2.39$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#54.53 ± 2.09$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#53.48 ± 0.6$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#52.31 ± 1.57$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#46.4 ± 1.13$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#40.91 ± 1.39$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#40.9 ± 1.58$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#38.32 ± 1.5$Node Classification#Squirrel (60%/20%/20% random splits)#1:1 Accuracy#31.28 ± 0.27$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#82.28 ± 1.12$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#82.07 ± 1.04$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.87 ± 1.38$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.83 ± 1.65$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.79 ± 0.95$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.76 ±  1.25$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.69 ± 1.25$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.65 ± 1.48$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.58 ± 1.23$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.56 ± 1.15$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#81.32 ± 0.97$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#80.96 ±  0.93$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#80.93 ± 1.16$Node Classification#CiteSeer (60%/20%/20% random splits)#1:1 Accuracy#76.25 ± 0.28$Node Classification#genius#Accuracy#91.37 ± 0.07$Node Classification#genius#Accuracy#91.22 ± 0.13$Node Classification#genius#Accuracy#91.13 ± 0.09$Node Classification#genius#Accuracy#91.01 ± 0.18$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.75 ± 1.16$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.59 ± 1.58$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.47 ±  1.08$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.36 ± 1.26$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.33 ± 0.81$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.18 ± 1.11$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.1 ± 1.61$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.00 ± 1.35$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#89.00 ± 0.72$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#88.95 ± 1.04$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#88.83 ± 1.49$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#87.64 ± 0.99$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#86.63 ± 1.13$Node Classification#Cora (60%/20%/20% random splits)#1:1 Accuracy#76.44 ± 0.30$Node Classification#Cornell#Accuracy#95.9 ± 1.83$Node Classification#Penn94#Accuracy#86.08 ± 0.43$Node Classification#Penn94#Accuracy#85.95 ± 0.26$Node Classification#Penn94#Accuracy#85.05 ± 0.19$Node Classification#Penn94#Accuracy#84.95 ± 0.43$Node Classification#Chameleon#Accuracy#68.38 ± 1.36$Node Classification#Squirrel#Accuracy#54.53 ± 2.09$Node Classification#Texas#Accuracy#95.25 ± 3.15$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.80 ± 0.63$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.36 ± 0.70$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.30 ± 0.70$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#86.23 ±  4.71$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#76.00 ± 1.01$Node Classification#Cornell (60%/20%/20% random splits)#1:1 Accuracy#60.33 ± 28.53$Node Classification#Deezer Europe#1:1 Accuracy#67.5±0.53$Node Classification#Deezer Europe#1:1 Accuracy#67.44±0.31$Node Classification#Deezer Europe#1:1 Accuracy#67.4±0.44$Node Classification#Deezer Europe#1:1 Accuracy#67.3±0.48$Node Classification#Deezer Europe#1:1 Accuracy#67.15±0.41$Node Classification#Deezer Europe#1:1 Accuracy#67.01±0.38$Node Classification#Deezer Europe#1:1 Accuracy#66.86±0.53$Node Classification#Deezer Europe#1:1 Accuracy#66.67±0.56$Node Classification#Deezer Europe#1:1 Accuracy#66.6±0.57$Node Classification#Deezer Europe#1:1 Accuracy#66.53±0.57$Node Classification#Deezer Europe#1:1 Accuracy#66.42±0.56$Node Classification#Deezer Europe#1:1 Accuracy#66.39±0.56$Node Classification#Deezer Europe#1:1 Accuracy#66.38±0.45$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#91.44 ± 0.59$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#91.31 ± 0.6$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.96 ± 0.62$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.81 ± 0.52$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.74 ± 0.5$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.66 ± 0.47$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.63 ±  0.56$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.56 ± 0.39$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.46 ± 0.69$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.39 ± 0.33$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.18 ± 0.51$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.12 ± 0.4$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.09 ± 0.68$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#90.05$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#89.98 ± 0.54$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#89.98 ± 0.52$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#89.8 ± 0.3$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#89.15 ± 0.87$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#89.04 ± 0.49$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#88.9 ± 0.32$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#88.8 ± 0.82$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#88.79 ± 0.5$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#88.48 ± 0.41$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#87.78 ± 0.28$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#87.75 ± 0.88$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#87.04 ± 4.10$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#86.85 ± 0.11$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#86.43 ± 0.13$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#85.5 ± 0.76$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#85.36 ± 0.52$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#85.07 ± 0.09$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#85.02 ± 0.09$Node Classification#PubMed (60%/20%/20% random splits)#1:1 Accuracy#83.28 ± 0.12$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#97.5 ± 1.25$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#97.13 ± 1.68$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#97.00 ± 2.63$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.75 ± 1.79$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.63 ± 2.24$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.62 ± 1.86$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.62 ± 2.44$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.5 ± 2.08$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#96.38 ± 2.59$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#95.75 ± 2.03$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#94.63 ± 2.96$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#94.37 ± 2.81$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#94.00 ± 2.61$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#93.87 ± 3.33$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#93.75 ± 2.37$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#93.25 ± 2.92$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#92.00 ±  3.59$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#89.75 ± 6.37$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#89.12 ± 3.06$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#87.5 ± 1.77$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#83.25 ± 2.69$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#77.25 ± 7.80$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#75.5 ± 2.92$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#74.88 ± 3.42$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#74.75 ± 2.89$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#71.01 ± 4.66$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#70.38 ± 2.85$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#69.50 ± 3.12$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#69.5 ± 5.01$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#64.85 ± 5.14$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#64.12$Node Classification#Wisconsin (60%/20%/20% random splits)#1:1 Accuracy#62.50 ± 15.75$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#96.56 ± 2$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#95.74 ± 2.22$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#95.41 ± 2.82$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#95.25 ± 1.55$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#95.08 ± 2.07$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#94.92 ± 2.79$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#94.75 ± 2.41$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#94.75 ± 3.09$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#94.75 ±  2.91$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#93.61 ± 1.55$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#93.44 ± 2.54$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#93.28 ± 2.79$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#93.12 ± 0.65$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#92.92 ± 0.61$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#92.46 ± 1.97$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#92.26 ± 0.71$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#91.18 ± 0.70$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#88.85 ± 4.39$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#88.52 ± 3.02$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#85.90 ± 3.53$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#83.28 ± 5.43$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#83.11 ± 3.2$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#82.46 ± 4.58$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#81.31 ± 3.3$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#80.66 ± 1.91$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#79.03 ± 1.20$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#78.87 ± 0.86$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#76.39 ± 7.66$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#75.41 ± 7.18$Node Classification#Texas (60%/20%/20% random splits)#1:1 Accuracy#67.57$Node Classification#Wisconsin#Accuracy#96.62 ± 2.44$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#95.9 ± 1.83$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#95.25 ± 1.55$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#95.08 ± 3.11$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#94.92 ± 2.79$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#94.75 ± 3.8$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#94.26 ± 2.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.93 ± 1.05$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.93 ± 3.03$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.77 ± 2.17$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.77 ± 1.91$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.61 ± 2.79$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#93.44 ± 2.74$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#92.62 ± 2.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#92.62 ± 3.13$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#97.5 ± 1.25$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#97.13 ± 1.68$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#97.00 ± 2.63$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.75 ± 1.79$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.63 ± 2.24$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.62 ± 1.86$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.62 ± 2.44$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.5 ± 2.08$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#96.38 ± 2.59$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#95.75 ± 2.03$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#94.63 ± 2.96$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#94.37 ± 2.81$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#94.00 ± 2.61$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#93.25 ± 2.92$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#96.56 ± 2$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#95.74 ± 2.22$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#95.41 ± 2.82$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#95.25 ± 1.55$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#95.08 ± 2.07$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#94.92 ± 2.79$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#94.75 ± 2.41$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#94.75 ± 3.09$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#94.75 ±  2.91$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#93.61 ± 1.55$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#93.44 ± 2.54$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#93.28 ± 2.79$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#92.46 ± 1.97$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.86 ± 1.48$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.84 ± 1.15$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.79 ± 1.01$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.66 ± 1.42$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.5 ± 1.54$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.4 ± 1.23$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.37 ± 1.37$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.27 ± 1.24$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.27 ± 0.8$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#41.1 ± 0.75$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#40.31 ± 1.6$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#40.13 ± 1.21$Node Classification on Non-Homophilic (Heterophilic) Graphs#Film(60%/20%/20% random splits)#1:1 Accuracy#39.33 ± 1.25$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#76.08 ± 2.13$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#75.93 ± 1.71$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#75.51 ± 1.58$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#75.23 ± 1.72$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#68.51 ± 1.7$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#68.4 ± 2.05$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#68.38 ± 1.36$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#67.83 ±  2.63$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#67.53 ± 2.83$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#63.68 ± 1.62$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#61.66 ± 2.29$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#60.48 ± 1.55$Node Classification on Non-Homophilic (Heterophilic) Graphs#Chameleon(60%/20%/20% random splits)#1:1 Accuracy#58.73 ± 2.52$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#69.98 ± 1.53$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#69.81 ± 1.11$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#69.26 ± 1.11$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#68.56 ± 1.33$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#55.97 ± 2.03$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#55.73 ± 2.39$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#54.53 ± 2.09$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#53.48 ± 0.6$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#52.31 ± 1.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#46.4 ± 1.13$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#40.91 ± 1.39$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#40.9 ± 1.58$Node Classification on Non-Homophilic (Heterophilic) Graphs#Squirrel(60%/20%/20% random splits)#1:1 Accuracy#38.32 ± 1.5$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.5±0.53$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.44±0.31$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.4±0.44$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.3±0.48$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.15±0.41$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.01±0.38$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.67±0.56$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.6±0.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.53±0.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.39±0.56
2103.02885v1.pdf	Node Classification#Cora (3%)#Accuracy#84.18%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#74.6%$Node Classification#AMZ Photo#Accuracy#94.10%$Node Classification#Cora: fixed 10 node per class#Accuracy#84.1%$Node Classification#Cora: fixed 5 node per class#Accuracy#80.26%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#85.3%$Node Classification#Cora (0.5%)#Accuracy#77.3%$Node Classification#AMZ Computers#Accuracy#85.5%$Node Classification#Cora (1%)#Accuracy#80.24%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#83.20%
1906.02174v3.pdf	Node Classification#Cora (3%)#Accuracy#81.92%$Node Classification#Cora (3%)#Accuracy#80.96%$Node Classification#Cora (3%)#Accuracy#80.72%$Node Classification#Cora (3%)#Accuracy#79.52%$Node Classification#CiteSeer (1%)#Accuracy#69.03%$Node Classification#CiteSeer (1%)#Accuracy#67.07%$Node Classification#CiteSeer (1%)#Accuracy#65.85%$Node Classification#CiteSeer (1%)#Accuracy#64.23%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.86%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.32%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72.85%$Node Classification#PubMed (0.05%)#Accuracy#72.57%$Node Classification#PubMed (0.05%)#Accuracy#70.04%$Node Classification#PubMed (0.05%)#Accuracy#69.45%$Node Classification#PubMed (0.05%)#Accuracy#68.99%$Node Classification#PubMed (0.03%)#Accuracy#71.11%$Node Classification#PubMed (0.03%)#Accuracy#68.12%$Node Classification#PubMed (0.03%)#Accuracy#62.61%$Node Classification#PubMed (0.03%)#Accuracy#61.94%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.26%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.19%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.16%$Node Classification#CiteSeer (0.5%)#Accuracy#64.64%$Node Classification#CiteSeer (0.5%)#Accuracy#62.05%$Node Classification#CiteSeer (0.5%)#Accuracy#61.99%$Node Classification#CiteSeer (0.5%)#Accuracy#59.41%$Node Classification#Cora (0.5%)#Accuracy#74.89%$Node Classification#Cora (0.5%)#Accuracy#71.36%$Node Classification#Cora (0.5%)#Accuracy#69.99%$Node Classification#Cora (0.5%)#Accuracy#67.76%$Node Classification#PubMed (0.1%)#Accuracy#77.21%$Node Classification#PubMed (0.1%)#Accuracy#75.30%$Node Classification#PubMed (0.1%)#Accuracy#74.40%$Node Classification#PubMed (0.1%)#Accuracy#73.83%$Node Classification#Cora (1%)#Accuracy#78.15%$Node Classification#Cora (1%)#Accuracy#74.79%$Node Classification#Cora (1%)#Accuracy#74.78%$Node Classification#Cora (1%)#Accuracy#73.10%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#81.7%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#79.16%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#79.10%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#82.95 ± 2.1$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#82.62 ± 2.34$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#74.88 ± 3.42$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#69.5 ± 5.01$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#83.11 ± 3.2
2009.00952v1.pdf	Node Classification#Cora (3%)#Accuracy#78.5%$Node Classification#CiteSeer (1%)#Accuracy#68.9%$Node Classification#Cora#Accuracy#80.9%$Node Classification#PubMed (0.05%)#Accuracy#69.5%$Node Classification#PubMed (0.03%)#Accuracy#65.5%$Node Classification#CiteSeer (0.5%)#Accuracy#67.7%$Node Classification#Cora (0.5%)#Accuracy#66.9%$Node Classification#PubMed (0.1%)#Accuracy#73.1%$Node Classification#Cora (1%)#Accuracy#73.1%
1901.01484v2.pdf	Node Classification#Cora (3%)#Accuracy#77.7 ± 2.4$Node Classification#Cora (3%)#Accuracy#76.3 ± 2.3$Node Classification#CiteSeer (1%)#Accuracy#63.3 ± 1.8$Node Classification#CiteSeer (1%)#Accuracy#61.3 ± 3.9$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#68.7 ± 1.0$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#66.2 ± 1.9$Node Classification#PubMed (0.05%)#Accuracy#68.8 ± 5.6$Node Classification#PubMed (0.05%)#Accuracy#66%$Node Classification#PubMed (0.03%)#Accuracy#61%$Node Classification#PubMed (0.03%)#Accuracy#60.4 ± 8.6$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#80.4 ± 1.1$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#79.5 ± 1.8$Node Classification#CiteSeer (0.5%)#Accuracy#53.8 ± 4.7$Node Classification#CiteSeer (0.5%)#Accuracy#53.2 ± 4.0$Node Classification#Cora (0.5%)#Accuracy#60.8 ± 9.0$Node Classification#Cora (0.5%)#Accuracy#58.1 ± 8.2$Node Classification#PubMed (0.1%)#Accuracy#73.4 ± 5.1$Node Classification#PubMed (0.1%)#Accuracy#72.8 ± 4.6$Node Classification#Cora (1%)#Accuracy#67.5 ± 8.7$Node Classification#Cora (1%)#Accuracy#66.1 ± 8.2$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#78.3 ± 0.3$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#78.1 ± 0.4
1511.02136v6.pdf	Node Classification#Cora (3%)#Accuracy#76.7%$Node Classification#CiteSeer (1%)#Accuracy#62.2%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#69.4%$Node Classification#PubMed (0.05%)#Accuracy#66.7%$Node Classification#PubMed (0.03%)#Accuracy#60.9%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#79.7%$Node Classification#CiteSeer (0.5%)#Accuracy#53.1%$Node Classification#Cora (0.5%)#Accuracy#59.0%$Node Classification#PubMed (0.1%)#Accuracy#73.1%$Node Classification#Cora (1%)#Accuracy#66.4%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#76.8%
2112.01174v3.pdf	Node Classification#AMZ Computers: fixed 20 node per class#Accuracy#84.86$Node Classification#Cora: fixed 20 nodes per class#Accuracy#86.00$Node Classification#Pubmed: fixed 20 node per class#Accuracy#82.72$Node Classification#Citeseer: fixed 20 node per class#Accuracy#76.35
2106.08541v1.pdf	Node Classification#Amazon Computers#Accuracy#89.49%$Node Classification#Amazon Computers#Accuracy#89.44%$Node Classification#Amazon Computers#Accuracy#89.42%$Node Classification#Amazon Computers#Accuracy#88.85%$Node Classification#Pubmed#Accuracy#89.58%$Node Classification#Pubmed#Accuracy#89.53%$Node Classification#Pubmed#Accuracy#88.86%$Node Classification#Pubmed#Accuracy#88.79%$Node Classification#Coauthor Physics#Accuracy#97.05%$Node Classification#Coauthor Physics#Accuracy#96.91%$Node Classification#Coauthor Physics#Accuracy#96.87%$Node Classification#Cora Full with Public Split#Accuracy#57.05%$Node Classification#Cora Full with Public Split#Accuracy#55.87%$Node Classification#Cora Full with Public Split#Accuracy#53.43%$Node Classification#Cora Full with Public Split#Accuracy#51.78%$Node Classification#Cora#Accuracy#88.24%$Node Classification#Cora#Accuracy#87.89%$Node Classification#Cora#Accuracy#87.58%$Node Classification#Cora#Accuracy#87.54%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#70.96%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#70.79%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#70.27%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#70.26%$Node Classification#Citeseer#Accuracy#75.79%$Node Classification#Citeseer#Accuracy#75.77%$Node Classification#Citeseer#Accuracy#75.25%$Node Classification#Citeseer#Accuracy#74.72%$Node Classification#Cora Full#Accuracy#70.32%$Node Classification#Cora Full#Accuracy#69.87%$Node Classification#Cora Full#Accuracy#69.83%$Node Classification#Cora Full#Accuracy#69.53%$Node Classification#Coauthor CS#Accuracy#95.80%$Node Classification#Coauthor CS#Accuracy#95.74%$Node Classification#Coauthor CS#Accuracy#95.68%$Node Classification#Coauthor CS#Accuracy#95.66%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#81.39%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#81.19%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#81.05%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#80.79%$Node Classification#Amazon Photo#Accuracy#94.36%$Node Classification#Amazon Photo#Accuracy#94.12%$Node Classification#Amazon Photo#Accuracy#93.83%$Node Classification#Amazon Photo#Accuracy#93.75%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#75.64%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#75.41%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#74.06%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#72.41%
2006.06830v2.pdf	Node Classification#Flickr#Accuracy#0.682$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.3 ± 1.1$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.6 ± 0.5$Node Classification#Eximtradedata#Accuracy#77.6%
2210.07494v1.pdf	Node Classification#Flickr#Accuracy#0.563$Node Classification#Reddit#Accuracy#97.14%
1801.07606v1.pdf	Node Classification#Flickr#Accuracy#0.557$Node Classification#Wiki-Vote#Accuracy#46.3$Node Classification#USA Air-Traffic#Accuracy#58.2$Node Classification#USA Air-Traffic#Accuracy#57.3$Node Classification#Facebook#Accuracy#59.8$Node Classification#Brazil Air-Traffic#Accuracy#0.466$Node Classification#Brazil Air-Traffic#Accuracy#0.459$Node Classification#Europe Air-Traffic#Accuracy#44.3
1703.06103v4.pdf	Node Classification#AIFB#Accuracy#95.83$Node Classification#AM#Accuracy#89.29$Node Classification#BGS#Accuracy#83.10$Node Classification#MUTAG#Accuracy#73.23
2006.04131v2.pdf	Node Classification#DBLP#Accuracy#84.2 ± 0.1$Node Classification#Pubmed#Accuracy#86.7 ± 0.1$Node Classification#Cora#Accuracy#83.3% ± 0.4%$Node Classification#PPI#F1#66.2$Node Classification#PPI#Micro-F1#66.2$Node Classification#Citeseer#Accuracy#72.1 ± 0.5$Node Classification#Reddit#Micro-F1#94.2 ± 0.0
1912.08808v1.pdf	Node Classification#DBLP#Macro F1#87.64$Node Classification#DBLP#Micro F1#87.86$Node Classification#Wiki#Macro F1#15.97$Node Classification#Wiki#Micro F1#53.24$Node Classification#Eximtradedata#Macro F1#17.25$Node Classification#Eximtradedata#Micro F1#33.05
2203.01564v1.pdf	Node Classification#DBLP#Micro F1#80.58$Node Classification#Pubmed#F1#88.57$Node Classification#PPI#Micro F1#94.83$Node Classification#Citeseer#Accuracy#75.53$Node Classification#Deezer Romania#Micro-F1#0.68$Node Classification#Cora: fixed 20 node per class#Micro F1#75.12
2109.05641v1.pdf	Node Classification#Pubmed#Accuracy#91.44 ± 0.59$Node Classification#Pubmed#Accuracy#91.31 ± 0.6$Node Classification#Pubmed#Accuracy#90.81 ± 0.52$Node Classification#Pubmed#Accuracy#90.74 ± 0.5$Node Classification#Pubmed#Accuracy#90.56 ± 0.39$Node Classification#Cornell#Accuracy#95.25 ± 1.55$Node Classification#Cornell#Accuracy#95.08 ± 2.07$Node Classification#Cornell#Accuracy#94.75 ± 2.41$Node Classification#Cornell#Accuracy#94.26 ± 2.57$Node Classification#Cornell#Accuracy#93.61 ± 2.79$Node Classification#Cora#Accuracy#89.59% ± 1.58%$Node Classification#Cora#Accuracy#89.36% ± 1.26%$Node Classification#Cora#Accuracy#88.95% ± 1.04%$Node Classification#Cora#Accuracy#88.83% ± 1.49%$Node Classification#Cora#Accuracy#88.62% ± 1.22%$Node Classification#Citeseer#Accuracy#82.07 ± 1.04$Node Classification#Citeseer#Accuracy#81.79 ± 0.95$Node Classification#Citeseer#Accuracy#81.68 ± 0.97$Node Classification#Citeseer#Accuracy#81.58 ± 1.23$Node Classification#Citeseer#Accuracy#81.56 ± 1.15$Node Classification#Citeseer#Accuracy#81.32 ± 0.97$Node Classification#Chameleon#Accuracy#69.04 ± 1.74$Node Classification#Chameleon#Accuracy#68.51 ± 1.7$Node Classification#Chameleon#Accuracy#68.38 ± 1.36$Node Classification#Chameleon#Accuracy#67.83 ± 2.63$Node Classification#Chameleon#Accuracy#67.53 ± 2.83$Node Classification#Squirrel#Accuracy#58.02 ± 1.86$Node Classification#Squirrel#Accuracy#55.97 ± 2.03$Node Classification#Squirrel#Accuracy#55.73 ± 2.39$Node Classification#Squirrel#Accuracy#54.53 ± 2.09$Node Classification#Squirrel#Accuracy#53.48 ± 0.6$Node Classification#Squirrel#Accuracy#52.31 ± 1.57$Node Classification#Texas#Accuracy#95.74 ± 2.22$Node Classification#Texas#Accuracy#95.25 ± 1.55$Node Classification#Texas#Accuracy#95.08 ± 2.07$Node Classification#Texas#Accuracy#94.92 ± 2.88$Node Classification#Texas#Accuracy#94.75 ± 2.41$Node Classification#Texas#Accuracy#94.75 ± 3.09$Node Classification#Wisconsin#Accuracy#97.00 ± 2.63$Node Classification#Wisconsin#Accuracy#96.63 ± 2.24$Node Classification#Wisconsin#Accuracy#96.38 ± 2.59$Node Classification#Wisconsin#Accuracy#95.75 ± 2.03$Node Classification#Actor#Accuracy#41.84 ± 1.15$Node Classification#Actor#Accuracy#41.62 ± 1.15$Node Classification#Actor#Accuracy#41.4 ± 1.23$Node Classification#Actor#Accuracy#41.27 ± 0.8$Node Classification#Actor#Accuracy#41.1 ± 0.75$Node Classification#Actor#Accuracy#40.31 ± 1.6
2006.09022v1.pdf	Node Classification#Pubmed#Accuracy#90.21%$Node Classification#Cora#Accuracy#86.80%$Node Classification#Citeseer#Accuracy#80.09%
2008.09624v1.pdf	Node Classification#Pubmed#Accuracy#89.36 ± 0.57$Node Classification#Cora#Accuracy#90.16% ± 0.59%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#74.28 ± 0.67%$Node Classification#Citeseer#Accuracy#80.52 ± 0.14$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#82.84 ± 0.87%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.06 ± 0.34%
2002.06755v1.pdf	Node Classification#Pubmed#Accuracy#87.8 ± 0.6$Node Classification#Cora#Accuracy#88.5% ± 1.5%$Node Classification#Coauthor Phy#Accuracy#96.9 ± 0.2$Node Classification#Citeseer#Accuracy#78.7 ± 0.6$Node Classification#Coauthor CS#Accuracy#94.8 ± 0.4
1906.12269v1.pdf	Node Classification#Pubmed#Accuracy#86%$Node Classification#Cora#Accuracy#83%$Node Classification#Citeseer#Accuracy#68%
1910.10866v5.pdf	Node Classification#Pubmed#Accuracy#85.2 ± 0.3$Node Classification#Cora#Accuracy#86% ± 0.4%$Node Classification#Citeseer#Accuracy#74.7 ± 0.4$Node Classification#NELL#Accuracy#68.8 ± 0.3
1909.05729v2.pdf	Node Classification#Pubmed#Accuracy#83.0%$Node Classification#Pubmed#Accuracy#82.2%$Node Classification#Pubmed#Accuracy#81.7%$Node Classification#Pubmed#Accuracy#81.2%$Node Classification#Cora#Accuracy#85.5%$Node Classification#Cora#Accuracy#84.3%$Node Classification#Cora#Accuracy#83.9%$Node Classification#Cora#Accuracy#82.6%$Node Classification#Citeseer#Accuracy#73.7%$Node Classification#Citeseer#Accuracy#73.5%$Node Classification#Citeseer#Accuracy#72.7%$Node Classification#Citeseer#Accuracy#71.6%
1908.07558v3.pdf	Node Classification#Pubmed#Accuracy#82.92 ± 0.13
2110.13798v3.pdf	Node Classification#Pubmed#Accuracy#81.92±0.13$Node Classification#Cora#Accuracy#76.99±1.13%$Node Classification#Citeseer#Accuracy#61.25±1.29$Node Classification#Reddit#Accuracy#81.06±1.18%
1905.00067v3.pdf	Node Classification#Pubmed#Accuracy#80.8%$Node Classification#Pubmed#Training Split#20 per node$Node Classification#Pubmed#Validation#YES$Node Classification#Cora#Accuracy#81.9%$Node Classification#Cora#Training Split#20 per node$Node Classification#Cora#Validation#YES$Node Classification#Citeseer#Accuracy#71.4%$Node Classification#Citeseer#Training Split#20 per node$Node Classification#Citeseer#Validation#YES$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#60.33 ± 28.53$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#77.25 ± 7.80$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#76.39 ± 7.66$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.80±0.58
2102.02302v1.pdf	Node Classification#Pubmed#Accuracy#80.2$Node Classification#YouTube#Micro-F1@2%#38.59$Node Classification#YouTube#Macro-F1@2%#30.77$Node Classification#Cora#Accuracy#86.80%$Node Classification#Citeseer#Accuracy#75.7
1907.02586v1.pdf	Node Classification#Pubmed#Accuracy#80.0%$Node Classification#Pubmed#Accuracy#79.3%$Node Classification#Cora#Accuracy#83.5%$Node Classification#Cora#Accuracy#83.3%$Node Classification#Citeseer#Accuracy#73.5%$Node Classification#Citeseer#Accuracy#73.4%
1911.05485v6.pdf	Node Classification#Pubmed#Accuracy#79.95%$Node Classification#Citeseer#Accuracy#73.35%$Node Classification#AMZ Photo#Accuracy#92.93%$Node Classification#Coauthor CS#Accuracy#93.01%$Node Classification#AMZ Comp#Accuracy#86.77%
1908.05081v3.pdf	Node Classification#Pubmed#Accuracy#79.76 ± 0.27$Node Classification#Cora#Accuracy#85.46% ± 0.25%$Node Classification#Citeseer#Accuracy#76.22 ± 0.20$Node Classification#MS ACADEMIC#Accuracy#92.98 ± 0.07$Node Classification#MS ACADEMIC#Accuracy#92.87 ± 0.07
1810.05997v6.pdf	Node Classification#Pubmed#Accuracy#79.73 ± 0.31$Node Classification#Pubmed#Validation#YES$Node Classification#Cora#Accuracy#85.29% ± 0.25%$Node Classification#Cora#Validation#YES$Node Classification#Cora#Accuracy#85.09% ± 0.25%$Node Classification#Citeseer#Accuracy#75.83%$Node Classification#Citeseer#Validation#YES$Node Classification#Citeseer#Accuracy#75.73%$Node Classification#MS ACADEMIC#Accuracy#93.27 ± 0.08$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.80 ± 0.63$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#92.00 ±  3.59$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#91.18 ± 0.70$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.21±0.56
1904.11883v2.pdf	Node Classification#Pubmed#Accuracy#79.7%$Node Classification#Cora#Accuracy#84.8%$Node Classification#Citeseer#Accuracy#71.8%
1909.03184v2.pdf	Node Classification#Pubmed#Accuracy#79.7 ± 0.4%$Node Classification#Cora#Accuracy#83.6% ± 0.3%
1904.09981v2.pdf	Node Classification#Pubmed#Accuracy#79.6 ± 0.4%$Node Classification#Cora#Accuracy#84.2% ± 1.0%$Node Classification#PPI#F1#98.6 ± 0.1$Node Classification#Citeseer#Accuracy#73.1 ± 0.9%
1802.08888v1.pdf	Node Classification#Pubmed#Accuracy#79.5%$Node Classification#Cora#Accuracy#83.0%$Node Classification#Citeseer#Accuracy#72.2%
2001.07922v1.pdf	Node Classification#Pubmed#Accuracy#79.5%$Node Classification#Cora#Accuracy#85.1%$Node Classification#Citeseer#Accuracy#72.7%
1802.08352v2.pdf	Node Classification#Pubmed#Accuracy#79.40%$Node Classification#Cora#Accuracy#78.30%$Node Classification#Citeseer#Accuracy#71.60%
2001.05140v2.pdf	Node Classification#Pubmed#Accuracy#79.3%$Node Classification#Cora#Accuracy#84.3%$Node Classification#Citeseer#Accuracy#71.2%
1904.07785v1.pdf	Node Classification#Pubmed#Accuracy#79.1%$Node Classification#Cora#Accuracy#81.6%$Node Classification#Citeseer#Accuracy#71.7%
2111.14522v2.pdf	Node Classification#Pubmed#Accuracy#79.10±0.11$Node Classification#Cornell#Accuracy#54.60±0.39$Node Classification#Cora#Accuracy#82.76±0.23%$Node Classification#Citeseer#Accuracy#72.58±0.20$Node Classification#Chameleon#Accuracy#42.73±0.15$Node Classification#Squirrel#Accuracy#37.05±0.17$Node Classification#Texas#Accuracy#64.46±0.38$Node Classification#Wisconsin#Accuracy#55.51±0.27$Node Classification#Actor#Accuracy#28.42±0.75
1911.04822v2.pdf	Node Classification#Pubmed#Accuracy#78.45%$Node Classification#Cora#Accuracy#80.53%
1905.10769v2.pdf	Node Classification#Pubmed#Accuracy#78.4%$Node Classification#Pubmed#Training Split#20 per node with early stopping set$Node Classification#Pubmed#Validation#YES$Node Classification#Cora#Accuracy#82.9%$Node Classification#Cora#Training Split#20 per node with early stopping set$Node Classification#Cora#Validation#YES$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#74.5%$Node Classification#Citeseer#Accuracy#74.5%$Node Classification#Citeseer#Training Split#20 per node with early stopping set$Node Classification#Citeseer#Validation#YES$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#82.9%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#78.4%
1909.03211v2.pdf	Node Classification#Pubmed#Accuracy#77.4 ± 0.2$Node Classification#Cora#Accuracy#82.3%$Node Classification#Citeseer#Accuracy#69.7%
1809.10341v2.pdf	Node Classification#Pubmed#Accuracy#76.8 ± 0.6%$Node Classification#Cora#Accuracy#82.3 ± 0.6%$Node Classification#Citeseer#Accuracy#71.8 ± 0.7%
2110.08727v2.pdf	Node Classification#Pubmed#Accuracy#75.42 ± 2.31$Node Classification#Cora#Accuracy#80.54± 1.35%$Node Classification#Citeseer#Accuracy#71.77± 2.01$Node Classification#AMZ Photo#Accuracy#92.11± 1.08%$Node Classification#AMZ Computers#Accuracy#83.03± 1.87%
1905.07953v2.pdf	Node Classification#Pubmed#F1#79.9$Node Classification#Amazon2M#F1#90.41$Node Classification#PPI#F1#99.36$Node Classification#PPI#F1#92.9$Link Property Prediction#ogbl-citation2#Test MRR#0.8004 ± 0.0025$Link Property Prediction#ogbl-citation2#Validation MRR#0.7994 ± 0.0025$Link Property Prediction#ogbl-citation2#Number of params#296449$Link Property Prediction#ogbl-citation2#Ext. data#No
1909.11715v3.pdf	Node Classification#Coauthor Physics#Accuracy#94.49 ± 0.84$Node Classification#Bitcoin-OTC#F1-score#0.6635$Node Classification#Cora random partition#Accuracy#82.07 ± 1.17$Node Classification#Bitcoin-Alpha#F1-score#0.6534$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#74.52 ± 0.59$Node Classification#Pubmed random partition#Accuracy#80.72 ± 1.08$Node Classification#Cora: fixed 10 node per class#Accuracy#79.3$Node Classification#Coauthor CS#Accuracy#91.83 ± 0.51$Node Classification#Cora: fixed 5 node per class#Accuracy#71.99 ± 6.46$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#83.94 ± 0.57$Node Classification#Cora Full-supervised#Accuracy#61.8%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.98 ± 0.55$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.42%$Node Classification#CiteSeer with Public Split: fixed 5 nodes per class#Accuracy#58.55 ± 2.26$Node Classification#Citeseer random partition#Accuracy#76.45 ± 1.57
2007.09296v1.pdf	Node Classification#Coauthor Physics#Accuracy#94$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.3 ± 0.6$Node Classification#AMZ Photo#Accuracy#92%$Node Classification#Coauthor CS#Accuracy#92.8%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.4 ± 0.5$Node Classification#AMZ Computers#Accuracy#84.5 ± 1.2$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.5 ± 0.5
2203.06389v1.pdf	Node Classification#MAG-scholar-C#Accuracy#64.3$Node Classification#MAG-scholar-C#Accuracy#72.9$Node Classification#MAG-scholar-C#Accuracy#75.0$Node Classification#MAG-scholar-C#Accuracy#80.0
2210.00513v1.pdf	Node Classification#genius#Accuracy#90.85±0.64$Node Classification#snap-patents#Accuracy#69.50±0.39$Node Classification#arXiv-year#Accuracy#63.30±1.84
2110.14446v1.pdf	Node Classification#genius#Accuracy#90.77 ± 0.27$Node Classification#pokec#Accuracy#82.04±0.07$Node Classification#Penn94#Accuracy#84.71 ± 0.52$Node Classification#snap-patents#Accuracy#61.95±0.12$Node Classification#arXiv-year#Accuracy#56.00±1.34$Node Classification#twitch-gamers#Accuracy#66.06±0.19
2205.07308v1.pdf	Node Classification#pokec#Accuracy#83.05±0.07$Node Classification#Cornell#Accuracy#85.95±5.10$Node Classification#Cornell#Accuracy#83.51±4.26$Node Classification#Penn94#Accuracy#85.74±0.42$Node Classification#Chameleon#Accuracy#71.21±1.84$Node Classification#Chameleon#Accuracy#69.78±2.42$Node Classification#Squirrel#Accuracy#57.88±1.76–$Node Classification#Squirrel#Accuracy#57.54±1.39$Node Classification#Texas#Accuracy#84.32±4.15$Node Classification#Texas#Accuracy#84.05±4.90$Node Classification#arXiv-year#Accuracy#54.79±0.25$Node Classification#Wisconsin#Accuracy#88.04±3.22$Node Classification#Wisconsin#Accuracy#87.06±3.53$Node Classification#Actor#Accuracy#37.7±1.40$Node Classification#Actor#Accuracy#37.35±1.30
2202.11684v2.pdf	Node Classification#MuMiN-small#Claim Classification Macro-F1#0.6255$Node Classification#MuMiN-small#Tweet Classification Macro-F1#0.5450$Node Classification#MuMiN-small#Claim Classification Macro-F1#0.5795$Node Classification#MuMiN-small#Tweet Classification Macro-F1#0.5605$Node Classification#MuMiN-small#Claim Classification Macro-F1#0.4756$Node Classification#MuMiN-small#Tweet Classification Macro-F1#0.4877$Node Classification#MuMiN-small#Claim Classification Macro-F1#0.4007$Node Classification#MuMiN-small#Tweet Classification Macro-F1#0.3718$Node Classification#MuMiN-large#Claim Classification Macro-F1#0.5980$Node Classification#MuMiN-large#Tweet Classification Macro-F1#0.6145$Node Classification#MuMiN-large#Claim Classification Macro-F1#0.5790$Node Classification#MuMiN-large#Tweet Classification Macro-F1#0.5280$Node Classification#MuMiN-large#Claim Classification Macro-F1#0.4813$Node Classification#MuMiN-large#Tweet Classification Macro-F1#0.4887$Node Classification#MuMiN-large#Claim Classification Macro-F1#0.3879$Node Classification#MuMiN-large#Tweet Classification Macro-F1#0.3690$Node Classification#MuMiN-medium#Claim Classification Macro-F1#0.5770$Node Classification#MuMiN-medium#Tweet Classification Macro-F1#0.5410$Node Classification#MuMiN-medium#Claim Classification Macro-F1#0.5585$Node Classification#MuMiN-medium#Tweet Classification Macro-F1#0.5745$Node Classification#MuMiN-medium#Claim Classification Macro-F1#0.4806$Node Classification#MuMiN-medium#Tweet Classification Macro-F1#0.4856$Node Classification#MuMiN-medium#Claim Classification Macro-F1#0.3896$Node Classification#MuMiN-medium#Tweet Classification Macro-F1#0.3772
1907.10903v4.pdf	Node Classification#Citeseer Full-supervised#Accuracy#80.50%$Node Classification#Pubmed Full-supervised#Accuracy#91.70%$Node Classification#Reddit#Accuracy#97.02%$Node Classification#Cora Full-supervised#Accuracy#88.2%
1809.05343v3.pdf	Node Classification#Citeseer Full-supervised#Accuracy#79.66%$Node Classification#Pubmed Full-supervised#Accuracy#90.6%$Node Classification#Cora#Accuracy#87.44% ± 0.0034%$Node Classification#Reddit#Accuracy#96.27%$Node Classification#Cora Full-supervised#Accuracy#87.44±0.0034%
1801.10247v1.pdf	Node Classification#Citeseer Full-supervised#Accuracy#77.60%$Node Classification#Pubmed Full-supervised#Accuracy#88.00%$Node Classification#Reddit#Accuracy#93.70%$Node Classification#Cora Full-supervised#Accuracy#85.00%
2007.02133v1.pdf	Node Classification#Citeseer Full-supervised#Accuracy#77.13%$Node Classification#Pubmed Full-supervised#Accuracy#90.30%$Node Classification#PPI#F1#99.56$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.4%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#85.5%$Node Classification#Cora Full-supervised#Accuracy#88.49%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.2%$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#90.49 ± 4.45$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#89.18 ± 3.96$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#89.12 ± 3.06$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#83.25 ± 2.69$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#88.52 ± 3.02$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#82.46 ± 4.58$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.42±0.56$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.38±0.45
2110.11464v2.pdf	Node Classification#Citeseer Full-supervised#Accuracy#75.6434%$Node Classification#Cornell#Accuracy#82.4324$Node Classification#Pubmed Full-supervised#Accuracy#90.3524%$Node Classification#Chameleon#Accuracy#65.1754$Node Classification#Texas#Accuracy#80.5405$Node Classification#Cora Full-supervised#Accuracy#87.7867%$Node Classification#Wisconsin#Accuracy#86.2745
2210.15731v1.pdf	Node Classification#Citeseer Full-supervised#Accuracy#74.5±2.1$Node Classification#Cornell#Accuracy#81.1±6.0$Node Classification#Pubmed Full-supervised#Accuracy#89.2±0.3$Node Classification#Chameleon#Accuracy#76.2±1.2$Node Classification#Squirrel#Accuracy#71.2±1.5$Node Classification#Texas#Accuracy#84.3±4.4$Node Classification#Cora Full-supervised#Accuracy#86.0±1.0$Node Classification#Wisconsin#Accuracy#83.3±3.8$Node Classification#Actor#Accuracy#34.5±0.8
2205.08166v1.pdf	Node Classification#CellTypeGraph Benchmark#Top-1 accuracy#0.878$Node Classification#CellTypeGraph Benchmark#class-average Accuracy#0.797
2105.07634v1.pdf	Node Classification#Cornell#Accuracy#87.84$Node Classification#Chameleon#Accuracy#78.27±1.28$Node Classification#Chameleon#Accuracy#78.14±1.25$Node Classification#Squirrel#Accuracy#74.10±1.89$Node Classification#Texas#Accuracy#87.30 ± 5.55$Node Classification#Wisconsin#Accuracy#88.43$Node Classification#Actor#Accuracy#35.75±0.96
2206.08702v1.pdf	Node Classification#Cornell#Accuracy#85.95±7.72$Node Classification#Chameleon#Accuracy#65.21±2.04$Node Classification#Squirrel#Accuracy#45.19±1.57$Node Classification#Texas#Accuracy#86.16±2.24$Node Classification#Wisconsin#Accuracy#88.73±4.47
2102.06462v7.pdf	Node Classification#Cornell#Accuracy#85.68 ± 6.63$Node Classification#Chameleon#Accuracy#71.14 ± 1.84$Node Classification#Squirrel#Accuracy#55.17 ± 1.58$Node Classification#Texas#Accuracy#84.86 ± 4.55$Node Classification#Wisconsin#Accuracy#86.86 ± 3.29$Node Classification#Actor#Accuracy#37.54 ± 1.56
2205.15127v1.pdf	Node Classification#Cornell#Accuracy#84.32±7.29$Node Classification#Chameleon#Accuracy#74.53±1.19$Node Classification#Squirrel#Accuracy#68.13±2.59$Node Classification#Texas#Accuracy#84.60±5.32$Node Classification#Wisconsin#Accuracy#87.64±3.74$Node Classification#Actor#Accuracy#36.13±1.21
2106.12807v1.pdf	Node Classification#Cornell#Accuracy#84.05±4.67$Node Classification#Chameleon#Accuracy#77.48±0.80$Node Classification#Squirrel#Accuracy#74.17±1.83$Node Classification#Texas#Accuracy#87.57 ± 5.44$Node Classification#Crocodile#Accuracy#55.87±1.25$Node Classification#Wisconsin#Accuracy#86.67±4.22$Node Classification#Actor#Accuracy#34.59±1.32
2108.11022v1.pdf	Node Classification#Cornell#Accuracy#82.92 ± 6.61 (0, 2-6)$Node Classification#Cora#Accuracy#85.35% ± 0.49%$Node Classification#Texas#Accuracy#83.00 ± 4.50$Node Classification#Wisconsin#Accuracy#85.57 ± 3.78 (0, 3-5)
2209.08264v1.pdf	Node Classification#Cornell#Accuracy#82.88±5.56$Node Classification#Chameleon#Accuracy#74.57±2.56$Node Classification#Squirrel#Accuracy#72.24±1.52$Node Classification#Texas#Accuracy#84.86±5.01$Node Classification#Wisconsin#Accuracy#85.01±5.51$Node Classification#Actor#Accuracy#37.43±0.78
2006.11468v2.pdf	Node Classification#Cornell#Accuracy#79.46 ± 4.80$Node Classification#Cornell#Accuracy#78.11 ± 6.68$Node Classification#Chameleon#Accuracy#58.38 ± 1.76$Node Classification#Chameleon#Accuracy#52.96 ± 2.09$Node Classification#Squirrel#Accuracy#32.33 ± 1.94$Node Classification#Squirrel#Accuracy#28.98 ± 1.97$Node Classification#Texas#Accuracy#83.24 ± 7.07$Node Classification#Texas#Accuracy#80.00 ± 6.77$Node Classification#Wisconsin#Accuracy#84.31 ± 3.70$Node Classification#Wisconsin#Accuracy#83.14 ± 4.26$Node Classification#Actor#Accuracy#34.49 ± 1.63$Node Classification#Actor#Accuracy#34.31 ± 1.31$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#86.23 ±  4.71$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#87.5 ± 1.77$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#85.90 ± 3.53$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#67.22±0.90
2002.05287v2.pdf	Node Classification#Cornell#Accuracy#60.81$Node Classification#Cornell#Accuracy#56.76$Node Classification#Cornell#Accuracy#55.68$Node Classification#Chameleon#Accuracy#60.9$Node Classification#Chameleon#Accuracy#60.31$Node Classification#Chameleon#Accuracy#59.96$Node Classification#Squirrel#Accuracy#38.14$Node Classification#Squirrel#Accuracy#36.24$Node Classification#Squirrel#Accuracy#33.32$Node Classification#Texas#Accuracy#67.57$Node Classification#Texas#Accuracy#59.73$Node Classification#Texas#Accuracy#57.58$Node Classification#Wisconsin#Accuracy#64.12$Node Classification#Wisconsin#Accuracy#58.24$Node Classification#Wisconsin#Accuracy#56.67$Node Classification#Actor#Accuracy#31.63$Node Classification#Actor#Accuracy#30.3$Node Classification#Actor#Accuracy#29.09$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#60.81$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#64.12$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#67.57
1711.08267v1.pdf	Node Classification#Wikipedia#Accuracy#21.30%$Node Classification#Wikipedia#Macro-F1#0.194$Node Classification#Eximtradedata#Accuracy#23.20%$Node Classification#Eximtradedata#Macro-F1#0.221
1704.03165v3.pdf	Node Classification#Wikipedia#Accuracy#21.10%$Node Classification#Wikipedia#Macro-F1#0.190$Node Classification#Eximtradedata#Accuracy#22.80%$Node Classification#Eximtradedata#Macro-F1#0.216
1503.03578v1.pdf	Node Classification#Wikipedia#Accuracy#17.50%$Node Classification#Wikipedia#Macro-F1#0.164$Node Classification#Eximtradedata#Accuracy#20.50%$Node Classification#Eximtradedata#Macro-F1#0.192
1903.11960v4.pdf	Node Classification#Cora#Accuracy#84.08 ± 0.4%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#75.0%$Node Classification#Citeseer#Accuracy#75.0$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.1%$Node Classification#Cora: fixed 20 node per class#Accuracy#84.1
1909.01315v2.pdf	Node Classification#Cora#Accuracy#83.98% ± 0.52%
1809.09925v1.pdf	Node Classification#Cora#Accuracy#83.5% ± 0.4%$Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#73.4 ± 0.7$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#78.9 ± 0.7$Node Classification#Cora: fixed 20 node per class#Accuracy#83.5 ± 0.4
1902.08226v2.pdf	Node Classification#Cora#Accuracy#82.6%$Node Classification#Citeseer#Accuracy#73.7%$Node Classification#NELL#Accuracy#64.7%
2009.04535v2.pdf	Node Classification#Cora#Accuracy#82.2%$Node Classification#Citeseer#Accuracy#66.6$Node Classification#Coauthor CS#Accuracy#88.7%
1804.00099v2.pdf	Node Classification#Cora#Accuracy#81.9%
1710.09599v2.pdf	Node Classification#Cora#Accuracy#67.9%$Node Classification#Citeseer#Accuracy#51.5%
1907.04931v4.pdf	Node Classification#PPI#F1#99.50$Node Classification#Reddit#Accuracy#97.0%$Link Property Prediction#ogbl-citation2#Test MRR#0.7985 ± 0.0040$Link Property Prediction#ogbl-citation2#Validation MRR#0.7975 ± 0.0039$Link Property Prediction#ogbl-citation2#Number of params#296449$Link Property Prediction#ogbl-citation2#Ext. data#No
1803.07294v1.pdf	Node Classification#PPI#F1#98.7
1806.03536v2.pdf	Node Classification#PPI#F1#97.6
2110.14363v1.pdf	Node Classification#PPI#F1#97.37$Node Classification#Reddit#Accuracy#94.5 ± .0024$Link Property Prediction#ogbl-collab#Test Hits@50#0.4673 ± 0.0164 .$Link Property Prediction#ogbl-collab#Test Hits@50#0.4316 ± 0.0134$Link Property Prediction#ogbl-collab#Test Hits@50#0.4102 ± 0.0099
2004.11198v3.pdf	Node Classification#PPI#F1#96.50$Node Classification#AMZ Photo#Accuracy#91.72 ± 1.20$Node Classification#Coauthor CS#Accuracy#91.98 ± 0.50$Node Classification#Reddit#Accuracy#96.60%$Node Classification#AMZ Comp#Accuracy#85.93 ± 1.21
2005.11079v4.pdf	Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#75.4 ± 0.4$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#85.4 ± 0.4$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#82.7 ± 0.6
1911.01731v3.pdf	Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72.9%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.7%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80%
1902.06667v4.pdf	Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72.8%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.5%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#79.8%
2204.04879v1.pdf	Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72.6%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.3%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#81.7%
1910.12241v2.pdf	Node Classification#CiteSeer with Public Split: fixed 20 nodes per class#Accuracy#72%$Node Classification#Cora with Public Split: fixed 20 nodes per class#Accuracy#84.31%$Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#80.95%
1904.04849v2.pdf	Node Classification#Citeseer#Accuracy#74.50%
2110.08128v3.pdf	Node Classification#Chameleon#Accuracy#69.4 ±1.4$Node Classification#Squirrel#Accuracy#55.8 ±1.1$Node Classification#Texas#Accuracy#84.5 ±5.1$Node Classification#Crocodile#Accuracy#77.4 ±0.6
2206.02386v1.pdf	Node Classification#Chameleon#Accuracy#68.4 ± 2.3$Node Classification#Squirrel#Accuracy#56.3 ± 2.2$Node Classification#Actor#Accuracy#36.2 ± 1.0
2210.05382v1.pdf	Node Classification#arXiv-year#Accuracy#56.50±0.13
1903.01888v3.pdf	Node Classification#CiteSeer (0.5%)#Accuracy#44.3%
2203.10983v2.pdf	Node Classification#Reddit#Accuracy#97.17%
2201.07858v1.pdf	Node Classification#Reddit#Accuracy#97.13%$Node Classification#Reddit#Accuracy#97.03%
2202.00408v2.pdf	Node Classification#Reddit#Accuracy#96.26 ± 0.02%
2009.00934v2.pdf	Node Classification#PubMed with Public Split: fixed 20 nodes per class#Accuracy#83.8 ± 0.1%
2102.05034v2.pdf	Graph structure learning#Cora#Accuracy#73.4
2106.10994v3.pdf	Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#92.13 ± 1.64$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#93.12 ± 0.65
2006.07988v6.pdf	Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.36 ± 0.70$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#91.30 ± 0.70$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#74.43 ± 10.24$Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#66.56 ± 13.82$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#93.75 ± 2.37$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#92.92 ± 0.61$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#92.26 ± 0.71$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#80.66 ± 1.91$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#75.41 ± 7.18$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.90±0.50
2101.00797v1.pdf	Node Classification on Non-Homophilic (Heterophilic) Graphs#Cornell (60%/20%/20% random splits)#1:1 Accuracy#88.03 ± 5.6$Node Classification on Non-Homophilic (Heterophilic) Graphs#Wisconsin(60%/20%/20% random splits)#1:1 Accuracy#89.75 ± 6.37$Node Classification on Non-Homophilic (Heterophilic) Graphs#Texas(60%/20%/20% random splits)#1:1 Accuracy#88.85 ± 4.39$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#66.86±0.53
2010.13993v2.pdf	Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#64.60±0.57$Node Classification on Non-Homophilic (Heterophilic) Graphs#Deezer-Europe#1:1 Accuracy#64.52±0.62
1903.07293v1.pdf	Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#93.11%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#92.24%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#93.70%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#93.99%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#93.08%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#92.99%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#92.03%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#93.31%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#93.29%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#92.53%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#92.73%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#91.64%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#93.39%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#92.53%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#93.44%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#92.69%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#91.68%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#93.27%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#92.34%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#92.05%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#91.17%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#92.69%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#92.69%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#91.80%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#91.96%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#90.97%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#91.84%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#92.55%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#91.73%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#91.71%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#90.79%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#92.62%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#93.09%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#92.38%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#91.53%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#90.16%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#92.48%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#92.80%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#91.89%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#79.37%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#77.43%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (60% training data)#85.27%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#86.26%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#84.81%
1911.08538v5.pdf	Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#91.75%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#90.94%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#92.26%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#91.53%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (20% training data)#90.62%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (20% training data)#89.88%$Heterogeneous Node Classification#DBLP (PACT) 14k#Micro-F1 (80% training data)#91.92%$Heterogeneous Node Classification#DBLP (PACT) 14k#Macro-F1 (80% training data)#91.06%
2009.01181v1.pdf	Medical Image Generation#Chest X-Ray Images (Pneumonia)#Frechet Inception Distance#1.289
2210.03786v1.pdf	Medical Image Generation#ChestXray14 1024x1024#FID#3.52$Medical Image Generation#SLIVER07#FID#10.78$Medical Image Generation#ACDC#FID#21.17
2010.03975v2.pdf	Medical Image Generation#ChestXray14 1024x1024#FID#8.02
2105.05318v2.pdf	Medical Image Generation#SLIVER07#FID#29.06$Medical Image Generation#ACDC#FID#24.74
2111.01587v1.pdf	Meta-Learning#ML45#Meta-train success rate#74.9$Meta-Learning#ML45#Meta-test success rate (zero-shot)#18.5$Meta-Learning#ML45#Meta-train success rate#77.2$Meta-Learning#ML45#Meta-test success rate (zero-shot)#17.7$Meta-Learning#ML10#Meta-train success rate#97.8%$Meta-Learning#ML10#Meta-test success rate (zero-shot)#25$Meta-Learning#ML10#Meta-train success rate#97.6%$Meta-Learning#ML10#Meta-test success rate (zero-shot)#26.5
2003.13661v2.pdf	Meta-Learning#MT50#Average Success Rate#60.0%
1910.10897v2.pdf	Meta-Learning#MT50#Average Success Rate#35.85%$Meta-Learning#ML10#Meta-train success rate#25%$Meta-Learning#ML10#Meta-test success rate#36%$Meta-Learning#ML10#Meta-train success rate#50%$Meta-Learning#ML10#Meta-test success rate#10%$Meta-Learning#ML10#Meta-train success rate#42.78%$Meta-Learning#ML10#Meta-test success rate#0%
2003.07305v1.pdf	Meta-Learning#MT50#Average Success Rate#26%
2012.02788v1.pdf	Meta-Learning#MT50#Average Success Rate#11%
1606.06329v2.pdf	Surgical Skills Evaluation#MISTIC-SIL#Accuracy#0.895$Surgical Skills Evaluation#MISTIC-SIL#Edit Distance#19.5$Surgical Skills Evaluation#JIGSAWS#Accuracy#0.833$Surgical Skills Evaluation#JIGSAWS#Edit Distance#14.6
1806.02750v1.pdf	Surgical Skills Evaluation#JIGSAWS#Accuracy#0.98
2107.10388v4.pdf	Music Modeling#JSB Chorales#NLL#0.208
1911.11775v3.pdf	Music Modeling#JSB Chorales#NLL#0.220
1809.04281v3.pdf	Music Modeling#JSB Chorales#NLL#0.335
1903.07227v1.pdf	Music Modeling#JSB Chorales#NLL#2.22
1206.6392v1.pdf	Music Modeling#JSB Chorales#NLL#5.56$Music Modeling#JSB Chorales#NLL#6.27
1412.3555v1.pdf	Music Modeling#JSB Chorales#NLL#8.54
1809.03672v5.pdf	Click-Through Rate Prediction#Amazon Dataset#AUC#0.7792
2102.07619v2.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8131
2002.06987v3.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8123$Click-Through Rate Prediction#Criteo#Log Loss#0.4395$Click-Through Rate Prediction#Avazu#AUC#0.7897$Click-Through Rate Prediction#Avazu#LogLoss#0.3748
2008.13535v2.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8115$Click-Through Rate Prediction#Criteo#Log Loss#0.4406
2107.12025v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8113
2209.05016v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8110
2006.12753v2.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8107$Click-Through Rate Prediction#Android Malware Dataset#AUC#0.7402
1905.06336v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8104$Click-Through Rate Prediction#Criteo#Log Loss#0.4416
1905.09433v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8103$Click-Through Rate Prediction#Criteo#Log Loss#0.4423
2108.01265v3.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8101$Click-Through Rate Prediction#Criteo#Log Loss#0.4417$Click-Through Rate Prediction#Criteo#AUC#0.8094$Click-Through Rate Prediction#Criteo#Log Loss#0.4423$Click-Through Rate Prediction#Avazu#AUC#0.8062$Click-Through Rate Prediction#Avazu#LogLoss#0.3637$Click-Through Rate Prediction#Avazu#AUC#0.8060$Click-Through Rate Prediction#Avazu#LogLoss#0.3638$Click-Through Rate Prediction#iPinYou#AUC#0.7825$Click-Through Rate Prediction#iPinYou#LogLoss#0.005604$Click-Through Rate Prediction#iPinYou#AUC#0.7800$Click-Through Rate Prediction#iPinYou#LogLoss#0.00564
2007.03519v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8100
1910.05552v2.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8062$Click-Through Rate Prediction#Criteo#Log Loss#0.4453$Click-Through Rate Prediction#Avazu#AUC#0.812$Click-Through Rate Prediction#Avazu#LogLoss#0.3817
1810.11921v2.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8061$Click-Through Rate Prediction#Criteo#Log Loss#0.4454$Click-Through Rate Prediction#MovieLens 1M#AUC#0.846$Click-Through Rate Prediction#MovieLens 1M#Log Loss#0.3784$Click-Through Rate Prediction#KDD12#AUC#0.7881$Click-Through Rate Prediction#KDD12#Log Loss#0.1545$Click-Through Rate Prediction#Avazu#AUC#0.7752$Click-Through Rate Prediction#Avazu#LogLoss#0.3823
1803.05170v3.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8052$Click-Through Rate Prediction#Criteo#Log Loss#0.4418$Click-Through Rate Prediction#Bing News#AUC#0.84$Click-Through Rate Prediction#Bing News#Log Loss#0.2649$Click-Through Rate Prediction#Bing News#AUC#0.03$Click-Through Rate Prediction#Bing News#Log Loss#0.3382$Click-Through Rate Prediction#Dianping#AUC#0.8639$Click-Through Rate Prediction#Dianping#Log Loss#0.3156$Click-Through Rate Prediction#Dianping#AUC#0.8318
1904.04447v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8022$Click-Through Rate Prediction#Criteo#Log Loss#0.5388$Click-Through Rate Prediction#Huawei App Store#AUC#0.9407$Click-Through Rate Prediction#Huawei App Store#Log Loss#0.1134$Click-Through Rate Prediction#Avazu#AUC#0.7883$Click-Through Rate Prediction#Avazu#LogLoss#0.3746
2006.05312v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8020$Click-Through Rate Prediction#Criteo#Log Loss#0.5409
2003.11235v3.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8010$Click-Through Rate Prediction#Criteo#Log Loss#0.5405
1703.04247v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.8007$Click-Through Rate Prediction#Criteo#Log Loss#0.45083$Click-Through Rate Prediction#Bing News#AUC#0.8376$Click-Through Rate Prediction#Bing News#Log Loss#0.2671$Click-Through Rate Prediction#Dianping#AUC#0.8481$Click-Through Rate Prediction#Dianping#Log Loss#0.3333$Click-Through Rate Prediction#MovieLens 20M#AUC#0.7324$Click-Through Rate Prediction#Company*#AUC#0.8715$Click-Through Rate Prediction#Company*#Log Loss#0.02618$Click-Through Rate Prediction#Amazon#AUC#0.8683
2006.15939v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.7991
1611.00144v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.7987$Click-Through Rate Prediction#Criteo#Log Loss#0.45214$Click-Through Rate Prediction#Criteo#AUC#0.7982$Click-Through Rate Prediction#Criteo#Log Loss#0.45256$Click-Through Rate Prediction#Criteo#AUC#0.7972$Click-Through Rate Prediction#Criteo#Log Loss#0.45323$Click-Through Rate Prediction#Bing News#AUC#0.8321$Click-Through Rate Prediction#Bing News#Log Loss#0.2775$Click-Through Rate Prediction#Dianping#AUC#0.8445$Click-Through Rate Prediction#Dianping#Log Loss#0.3424$Click-Through Rate Prediction#MovieLens 20M#AUC#0.7321$Click-Through Rate Prediction#iPinYou#AUC#0.8174$Click-Through Rate Prediction#iPinYou#AUC#0.7914$Click-Through Rate Prediction#iPinYou#AUC#0.7661$Click-Through Rate Prediction#Company*#AUC#0.8672$Click-Through Rate Prediction#Company*#Log Loss#0.02636$Click-Through Rate Prediction#Company*#AUC#0.8664$Click-Through Rate Prediction#Company*#Log Loss#0.02637$Click-Through Rate Prediction#Company*#AUC#0.8658$Click-Through Rate Prediction#Company*#Log Loss#0.02641$Click-Through Rate Prediction#Amazon#AUC#0.8679
1606.07792v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.7981$Click-Through Rate Prediction#Criteo#Log Loss#0.46772$Click-Through Rate Prediction#Criteo#AUC#0.7850$Click-Through Rate Prediction#Criteo#Log Loss#0.45382$Click-Through Rate Prediction#Bing News#AUC#0.8377$Click-Through Rate Prediction#Bing News#Log Loss#0.2668$Click-Through Rate Prediction#Dianping#AUC#0.8361$Click-Through Rate Prediction#Dianping#Log Loss#0.3364$Click-Through Rate Prediction#MovieLens 20M#AUC#0.7304$Click-Through Rate Prediction#Company*#AUC#0.8673$Click-Through Rate Prediction#Company*#Log Loss#0.02634$Click-Through Rate Prediction#Company*#AUC#0.8661$Click-Through Rate Prediction#Company*#Log Loss#0.02640$Click-Through Rate Prediction#Amazon#AUC#0.8637
1601.02376v1.pdf	Click-Through Rate Prediction#Criteo#AUC#0.7963$Click-Through Rate Prediction#Criteo#Log Loss#0.45738$Click-Through Rate Prediction#iPinYou#AUC#0.7619$Click-Through Rate Prediction#Company*#AUC#0.8683$Click-Through Rate Prediction#Company*#Log Loss#0.02629
1708.05123v1.pdf	Click-Through Rate Prediction#Criteo#Log Loss#0.4419
1901.08907v1.pdf	Click-Through Rate Prediction#Last.FM#AUC#0.689$Click-Through Rate Prediction#Last.FM#Accuracy#64.5$Click-Through Rate Prediction#Children's Book Test Common noun#AUC#0.734$Click-Through Rate Prediction#Children's Book Test Common noun#Accuracy#70.4$Click-Through Rate Prediction#MovieLens 1M#AUC#0.917$Click-Through Rate Prediction#MovieLens 1M#Accuracy#84.3
1803.03467v4.pdf	Click-Through Rate Prediction#Bing News#AUC#0.678$Click-Through Rate Prediction#Bing News#Accuracy#63.2$Click-Through Rate Prediction#Book-Crossing#AUC#0.729$Click-Through Rate Prediction#Book-Crossing#Accuracy#0.662$Click-Through Rate Prediction#MovieLens 1M#AUC#0.921$Click-Through Rate Prediction#MovieLens 1M#Accuracy#84.4
1801.08284v2.pdf	Click-Through Rate Prediction#Bing News#AUC#0.659
1906.03776v2.pdf	Click-Through Rate Prediction#Avito#AUC#0.8395$Click-Through Rate Prediction#Avito#Log Loss#0.05448
1906.04365v3.pdf	Click-Through Rate Prediction#Avito#AUC#0.7927$Click-Through Rate Prediction#Avito#Log Loss#0.05518$Click-Through Rate Prediction#Company*#AUC#0.7674$Click-Through Rate Prediction#Company*#Log Loss#0.2341
1908.04032v2.pdf	Click-Through Rate Prediction#MovieLens 1M#AUC#0.9449
1706.06978v4.pdf	Click-Through Rate Prediction#MovieLens 20M#AUC#0.7348$Click-Through Rate Prediction#MovieLens 20M#AUC#0.7337$Click-Through Rate Prediction#Amazon#AUC#0.8871$Click-Through Rate Prediction#Amazon#AUC#0.8818
1911.04690v4.pdf	Click-Through Rate Prediction#Avazu#AUC#0.75
2105.06466v2.pdf	Novel View Synthesis#PhotoShape#PSNR#37.67$Novel View Synthesis#PhotoShape#LPIPS#0.022$Novel View Synthesis#Dosovitskiy Chairs#PSNR#21.78$Novel View Synthesis#Dosovitskiy Chairs#LPIPS#0.141
2201.05023v2.pdf	Novel View Synthesis#SWORD#PSNR#25.54$Novel View Synthesis#SWORD#SSIM#0.79$Novel View Synthesis#SWORD#LPIPS#0.113$Novel View Synthesis#SWORD#PSNR#25.28$Novel View Synthesis#SWORD#SSIM#0.78$Novel View Synthesis#SWORD#LPIPS#0.102$Novel View Synthesis#SWORD#PSNR#25.95$Novel View Synthesis#SWORD#SSIM#0.81$Novel View Synthesis#SWORD#LPIPS#0.096
2104.07652v2.pdf	Novel View Synthesis#RealEstate10K#FID#48.84$Novel View Synthesis#RealEstate10K#PSNR#12.51$Novel View Synthesis#RealEstate10K#NLL#4.836$Novel View Synthesis#RealEstate10K#PSIM#3.05$Novel View Synthesis#RealEstate10K#SSIM#0.44$Novel View Synthesis#ACID#FID#42.88$Novel View Synthesis#ACID#NLL#5.341$Novel View Synthesis#ACID#PSIM#2.83$Novel View Synthesis#ACID#PSNR#15.54$Novel View Synthesis#ACID#SSIM#0.42
2205.05509v1.pdf	Novel View Synthesis#KITTI#Average PSNR#23.28
2208.00277v2.pdf	Novel View Synthesis#Mip-NeRF 360#PSNR#0.2146$Novel View Synthesis#Mip-NeRF 360#SSIM#0.458$Novel View Synthesis#Mip-NeRF 360#LPIPS#0.515$Novel View Synthesis#Mip-NeRF 360#PSNR#21.95$Novel View Synthesis#Mip-NeRF 360#SSIM#0.47$Novel View Synthesis#Mip-NeRF 360#LPIPS#0.47$Novel View Synthesis#Mip-NeRF 360#PSNR#22.76$Novel View Synthesis#Mip-NeRF 360#SSIM#0.548$Novel View Synthesis#Mip-NeRF 360#LPIPS#0.427$Novel View Synthesis#NeRF#PSNR#31$Novel View Synthesis#NeRF#SSIM#0.947$Novel View Synthesis#NeRF#LPIPS#0.081$Novel View Synthesis#NeRF#PSNR#30.9$Novel View Synthesis#NeRF#LPIPS#0.062$Novel View Synthesis#NeRF#PSNR#31.65$Novel View Synthesis#NeRF#SSIM#0.952$Novel View Synthesis#NeRF#LPIPS#0.051$Novel View Synthesis#NeRF#PSNR#30.38$Novel View Synthesis#NeRF#SSIM#0.95$Novel View Synthesis#NeRF#LPIPS#0.05$Novel View Synthesis#LLFF#PSNR#26.5$Novel View Synthesis#LLFF#SSIM#0.811$Novel View Synthesis#LLFF#LPIPS#0.25$Novel View Synthesis#LLFF#PSNR#25.91$Novel View Synthesis#LLFF#SSIM#0.825$Novel View Synthesis#LLFF#LPIPS#0.183$Novel View Synthesis#LLFF#PSNR#25.63$Novel View Synthesis#LLFF#SSIM#0.818$Novel View Synthesis#LLFF#PSNR#26.92$Novel View Synthesis#LLFF#SSIM#0.831$Novel View Synthesis#LLFF#LPIPS#0.173
2205.07058v2.pdf	Novel View Synthesis#RTMV#PSNR#14.588$Novel View Synthesis#RTMV#SSIM#0.483$Novel View Synthesis#RTMV#PSNR#12.149$Novel View Synthesis#RTMV#SSIM#0.629$Novel View Synthesis#RTMV#SSIM#0.523$Novel View Synthesis#RTMV#PSNR#12.126$Novel View Synthesis#RTMV#SSIM#0.318
2207.11243v1.pdf	Novel View Synthesis#10,000 People - Human Pose Recognition Data#avg_fp_quality#54
2103.08833v5.pdf	Sign Language Recognition#AUTSL#Rank-1 Recognition Rate#0.9853$Sign Language Recognition#WLASL-2000#Top-1 Accuracy#58.73
2008.00932v2.pdf	Sign Language Recognition#AUTSL#Rank-1 Recognition Rate#0.6203
1910.11006v2.pdf	Sign Language Recognition#WLASL100#Top-1 Accuracy#65.89$Sign Language Recognition#WLASL-2000#Top-1 Accuracy#32.48
2104.02330v2.pdf	Sign Language Recognition#RWTH-PHOENIX-Weather 2014#Word Error Rate (WER)#22.1
2101.04632v1.pdf	Sign Language Recognition#RWTH-PHOENIX-Weather 2014#Word Error Rate (WER)#29.7
2010.05468v1.pdf	Sign Language Recognition#RWTH-PHOENIX-Weather 2014 T#BLEU-4#13.41
2007.12131v2.pdf	Sign Language Recognition#WLASL-2000#Top-1 Accuracy#46.82
2202.06167v1.pdf	Entity Typing#OntoNotes#Macro F1#86.6$Entity Typing#OntoNotes#Micro F1#81.4$Entity Typing#Open Entity#F1#50.6$Entity Typing#FIGER#Macro F1#80.1$Entity Typing#FIGER#Micro F1#83.3
2205.01826v1.pdf	Entity Typing#Open Entity#F1#49.9
2106.04098v1.pdf	Entity Typing#Open Entity#F1#49.1$Entity Typing#Ontonotes v5 (English)#F1#49.1$Entity Typing#Ontonotes v5 (English)#Precision#53.6$Entity Typing#Ontonotes v5 (English)#Recall#45.3
2109.05744v1.pdf	Entity Typing#Open Entity#F1#45.4
2101.00345v2.pdf	Entity Typing#Open Entity#F1#44.8
1905.01566v1.pdf	Entity Typing#Open Entity#F1#40.1$Entity Typing#Ontonotes v5 (English)#F1#40.2$Entity Typing#Ontonotes v5 (English)#Precision#51.5$Entity Typing#Ontonotes v5 (English)#Recall#33
1903.02591v1.pdf	Entity Typing#Open Entity#F1#36.9$Entity Typing#Ontonotes v5 (English)#F1#36.9$Entity Typing#Ontonotes v5 (English)#Precision#50.3$Entity Typing#Ontonotes v5 (English)#Recall#29.2
1807.04905v1.pdf	Entity Typing#Open Entity#F1#31.3$Entity Typing#Ontonotes v5 (English)#F1#32.0$Entity Typing#Ontonotes v5 (English)#Precision#47.1$Entity Typing#Ontonotes v5 (English)#Recall#24.2
1911.11134v3.pdf	Sparse Learning#ImageNet#Top-1 Accuracy#77.1$Sparse Learning#ImageNet#Top-1 Accuracy#76.4$Sparse Learning#ImageNet#Top-1 Accuracy#71.9$Sparse Learning#ImageNet#Top-1 Accuracy#68.1
2106.10404v4.pdf	Sparse Learning#ImageNet#Top-1 Accuracy#76$Sparse Learning#ImageNet#Top-1 Accuracy#74.5
2102.02887v3.pdf	Sparse Learning#ImageNet#Top-1 Accuracy#75.84$Sparse Learning#ImageNet#Top-1 Accuracy#73.82
2207.04106v1.pdf	Entity Disambiguation#ACE2004#Micro-F1#93.4$Entity Disambiguation#MSNBC#Micro-F1#94.8$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#90.4$Entity Disambiguation#AQUAINT#Micro-F1#92.6$Entity Disambiguation#WNED-CWEB#Micro-F1#78.2$Entity Disambiguation#WNED-WIKI#Micro-F1#90.4$Entity Disambiguation#ShadowLink-Top#Micro-F1#64.2$Entity Disambiguation#ShadowLink-Shadow#Micro-F1#47.6
1909.00426v5.pdf	Entity Disambiguation#ACE2004#Micro-F1#91.9$Entity Disambiguation#MSNBC#Micro-F1#96.3$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#95.0$Entity Disambiguation#AQUAINT#Micro-F1#93.5$Entity Disambiguation#WNED-CWEB#Micro-F1#78.9$Entity Disambiguation#WNED-CWEB#Micro-F1#76.2$Entity Disambiguation#WNED-WIKI#Micro-F1#89.1$Entity Disambiguation#WNED-WIKI#Micro-F1#86.2
1704.04920v3.pdf	Entity Disambiguation#ACE2004#Micro-F1#88.5$Entity Disambiguation#MSNBC#Micro-F1#93.7$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#92.22$Entity Disambiguation#AQUAINT#Micro-F1#88.5$Entity Disambiguation#WNED-CWEB#Micro-F1#77.9$Entity Disambiguation#WNED-WIKI#Micro-F1#77.5
1705.02494v3.pdf	Entity Disambiguation#TAC2010#Micro Precision#87.7$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#94.7
1712.01813v1.pdf	Entity Disambiguation#TAC2010#Micro Precision#87.4$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#94.0
1601.01343v4.pdf	Entity Disambiguation#TAC2010#Micro Precision#85.2$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#93.1$Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#91.5
2008.05190v3.pdf	Entity Disambiguation#AIDA-CoNLL#In-KB Accuracy#94.94
2010.10363v3.pdf	Entity Disambiguation#AIDA-CoNLL#Micro-F1#96.8
2001.01447v1.pdf	Entity Disambiguation#AIDA-CoNLL#Micro-F1#93.54
2011.02690v1.pdf	Entity Disambiguation#Mewsli-9#Micro Precision#89.0
2103.12528v1.pdf	Entity Disambiguation#Mewsli-9#Micro Precision#90.6
1902.06626v3.pdf	Website Fingerprinting Defense#Website Traffic Data on Tor#Accuracy (%)#42
2001.01290v2.pdf	Partial Label Learning#MPII Movie Description#F1-Score#0.768$Partial Label Learning#MPII Movie Description#Accuracy#76.5$Partial Label Learning#M-VAD Names#Accuracy#90.3
2206.04170v5.pdf	Partial Label Learning#ISIC 2019#Balanced Multi-Class Accuracy#0.7258$Partial Label Learning#Autoimmune Dataset#F1 score#0.8717$Partial Label Learning#Autoimmune Dataset#F1 score#0.8445$Classification#Autoimmune Dataset#F1 score#0.8894$Classification#Autoimmune Dataset#F1 score#0.8639$Classification#ISIC 2019#Balanced Multi-Class Accuracy#0.6519$Classification#Brain Tumor MRI Dataset#F1 score#0.9909$Classification#Brain Tumor MRI Dataset#F1-score#0.99
2112.02706v1.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.9523$Continual Learning#ASC (19 tasks)#F1 - macro#0.8811$Continual Learning#ASC (19 tasks)#F1 - macro#0.8362$Continual Learning#ASC (19 tasks)#F1 - macro#0.7807$Continual Learning#ASC (19 tasks)#F1 - macro#0.7664$Continual Learning#DSC (10 tasks)#F1 - macro#0.8875
1801.01423v3.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.9521$Continual Learning#ASC (19 tasks)#F1 - macro#0.7816$Continual Learning#F-CelebA (10 tasks)#Acc#0.5673$Continual Learning#DSC (10 tasks)#F1 - macro#0.8614
2112.10017v1.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.9516$Continual Learning#ASC (19 tasks)#F1 - macro#0.6864$Continual Learning#F-CelebA (10 tasks)#Acc#0.7564$Continual Learning#F-CelebA (10 tasks)#Acc#0.6909$Continual Learning#DSC (10 tasks)#F1 - macro#0.8651
2112.03271v1.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.9504$Continual Learning#ASC (19 tasks)#F1 - macro#0.8140$Continual Learning#DSC (10 tasks)#F1 - macro#0.7651
1612.00796v2.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.9180$Continual Learning#ASC (19 tasks)#F1 - macro#0.7452$Continual Learning#ASC (19 tasks)#F1 - macro#0.5243$Continual Learning#F-CelebA (10 tasks)#Acc#0.6545$Continual Learning#DSC (10 tasks)#F1 - macro#0.6576$class-incremental learning#cifar100#10-stage average accuracy#50.53
1909.03329v2.pdf	Continual Learning#20Newsgroup (10 tasks)#F1 - macro#0.4572$Continual Learning#ASC (19 tasks)#F1 - macro#0.8059
1801.06519v2.pdf	Continual Learning#CUBS (Fine-grained 6 Tasks)#Accuracy#84.59$Continual Learning#CUBS (Fine-grained 6 Tasks)#Pretrained#Yes$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2838$Continual Learning#visual domain decathlon (10 tasks)#Avg. Accuracy#76.60$Continual Learning#Flowers (Fine-grained 6 Tasks)#Accuracy#94.77$Continual Learning#Wikiart (Fine-grained 6 Tasks)#Accuracy#71.33$Continual Learning#Stanford Cars (Fine-grained 6 Tasks)#Accuracy#89.62$Continual Learning#Sketch (Fine-grained 6 Tasks)#Accuracy#79.91$Continual Learning#ImageNet (Fine-grained 6 Tasks)#Accuracy#76.16
1711.05769v2.pdf	Continual Learning#CUBS (Fine-grained 6 Tasks)#Accuracy#80.41$Continual Learning#CUBS (Fine-grained 6 Tasks)#Pretrained#Yes$Continual Learning#Cifar100 (20 tasks)#Average Accuracy#67.5$Continual Learning#Flowers (Fine-grained 6 Tasks)#Accuracy#93.04$Continual Learning#Wikiart (Fine-grained 6 Tasks)#Accuracy#69.40$Continual Learning#Stanford Cars (Fine-grained 6 Tasks)#Accuracy#86.11$Continual Learning#Sketch (Fine-grained 6 Tasks)#Accuracy#76.17$Continual Learning#ImageNet (Fine-grained 6 Tasks)#Accuracy#75.71
1606.04671v4.pdf	Continual Learning#CUBS (Fine-grained 6 Tasks)#Accuracy#78.94$Continual Learning#CUBS (Fine-grained 6 Tasks)#Pretrained#Yes$Continual Learning#Flowers (Fine-grained 6 Tasks)#Accuracy#93.41$Continual Learning#Wikiart (Fine-grained 6 Tasks)#Accuracy#74.94$Continual Learning#Stanford Cars (Fine-grained 6 Tasks)#Accuracy#89.21$Continual Learning#Sketch (Fine-grained 6 Tasks)#Accuracy#76.35$Continual Learning#ImageNet (Fine-grained 6 Tasks)#Accuracy#76.16
1907.00274v1.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3744$Continual Learning#visual domain decathlon (10 tasks)#Avg. Accuracy#79.64
1902.00927v2.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3507$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3234
1803.10082v1.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3412$Continual Learning#visual domain decathlon (10 tasks)#Avg. Accuracy#78.07$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3159
1705.08045v5.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#3131$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2643$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2621$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2503$Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2118
1705.04228v2.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2851$Continual Learning#visual domain decathlon (10 tasks)#Avg. Accuracy#77.01
1606.09282v3.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#2515$Continual Learning#visual domain decathlon (10 tasks)#Avg. Accuracy#76.93$class-incremental learning#cifar100#10-stage average accuracy#45.12$Disjoint 15-1#PASCAL VOC 2012#mIoU#5.3$Disjoint 10-1#PASCAL VOC 2012#mIoU#4.3$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#54.9
1701.07275v1.pdf	Continual Learning#visual domain decathlon (10 tasks)#decathlon discipline (Score)#1363
2105.05155v3.pdf	Continual Learning#Cifar100 (20 tasks) - 1 epoch#Average Accuracy#62.79$Continual Learning#mini-Imagenet (20 tasks) - 1 epoch#Accuracy#57.2$Continual Learning#CUB-200-2011 (20 tasks) - 1 epoch#Accuracy#61.58$Continual Learning#5-dataset - 1 epoch#Accuracy#62.59
2106.03027v3.pdf	Continual Learning#Coarse-CIFAR100#Average Accuracy#84.27$Continual Learning#Cifar100 (20 tasks)#Average Accuracy#94.99$Continual Learning#Rotated MNIST#Average Accuracy#99.66$Continual Learning#Permuted MNIST#Average Accuracy#97.71
2102.11343v1.pdf	Continual Learning#Cifar100 (20 tasks)#Average Accuracy#81$Continual Learning#ImageNet-50 (5 tasks)#Accuracy#68.1$Continual Learning#Cifar100 (10 tasks)#Average Accuracy#84.9$Continual Learning#Permuted MNIST#Average Accuracy#97.988$Continual Learning#Permuted MNIST#MLP Hidden Layers-width#2-100$Continual Learning#Permuted MNIST#Pretrained/Transfer Learning#No
1810.01256v3.pdf	Continual Learning#ASC (19 tasks)#F1 - macro#0.7931
1812.00420v2.pdf	Continual Learning#ASC (19 tasks)#F1 - macro#0.7844$class-incremental learning#cifar100#10-stage average accuracy#45.76
2112.10021v1.pdf	Continual Learning#ASC (19 tasks)#F1 - macro#0.7738$Continual Learning#DSC (10 tasks)#F1 - macro#0.8123
1905.11614v3.pdf	Continual Learning#ASC (19 tasks)#F1 - macro#0.7599
2004.07211v2.pdf	Continual Learning#ASC (19 tasks)#F1 - macro#0.7508
1906.00695v4.pdf	Continual Learning#F-CelebA (10 tasks)#Acc#0.6036
1701.08734v1.pdf	Continual Learning#F-CelebA (10 tasks)#Acc#0.5764
2004.00070v1.pdf	Continual Learning#ImageNet-50 (5 tasks)#Accuracy#35.24
1904.03137v4.pdf	Continual Learning#ImageNet-50 (5 tasks)#Accuracy#17.82$Continual Learning#ImageNet-50 (5 tasks)#Accuracy#15.16
2107.01349v1.pdf	class-incremental learning#cifar100#10-stage average accuracy#68.18
1611.07725v2.pdf	class-incremental learning#cifar100#10-stage average accuracy#63.24$Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#57.17$Incremental Learning#ImageNet-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#65.56$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#38.40$Incremental Learning#ImageNet - 10 steps#Final Accuracy#22.70$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#63.70$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#44.00$Incremental Learning#ImageNet - 10 steps## M Params#11.68$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#83.60$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#63.80$Incremental Learning#ImageNet100 - 10 steps## M Params#11.22$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#52.57
2106.09701v2.pdf	class-incremental learning#cifar100#10-stage average accuracy#54.44
1902.10486v4.pdf	class-incremental learning#cifar100#10-stage average accuracy#48.66
2210.03980v1.pdf	FG-1-PG-1#OntoNotes 5.0#F1 (micro)#0.5894$FG-1-PG-1#OntoNotes 5.0#F1 (macro)#0.4222$FG-1-PG-1#2010 i2b2/VA#F1 (micro)#0.6273$FG-1-PG-1#2010 i2b2/VA#F1 (macro)#0.3626$FG-1-PG-1#conll2003#F1 (micro)#0.8091$FG-1-PG-1#conll2003#F1 (macro)#0.7911
1902.04980v1.pdf	Acoustic Novelty Detection#A3Lab PASCAL CHiME#F1#93.6
1906.02739v2.pdf	3D Shape Modeling#Pix3D S2#box AP#72.2$3D Shape Modeling#Pix3D S2#mask AP#63.9$3D Shape Modeling#Pix3D S2#mesh AP#28.8$3D Shape Modeling#Pix3D S1#box AP#94.0$3D Shape Modeling#Pix3D S1#mask AP#88.4$3D Shape Modeling#Pix3D S1#mesh AP#51.1
2004.07922v1.pdf	Document Text Classification#Tobacco-3482#Accuracy#46$Document Text Classification#Tobacco-3482#Training time (hours)#2$Document Text Classification#Tobacco-3482#Accuracy#43.5$Document Text Classification#Tobacco-3482#Training time (hours)#0.43$Document Text Classification#Tobacco-3482#Accuracy#42$Document Text Classification#Tobacco-3482#Training time (hours)#1$Document Text Classification#Tobacco small-3482#Accuracy#84$Document Text Classification#Tobacco small-3482#Training time (min)#9$Document Text Classification#Tobacco small-3482#Accuracy#83$Document Text Classification#Tobacco small-3482#Training time (min)#2$Document Text Classification#Tobacco small-3482#Accuracy#82.5$Document Text Classification#Tobacco small-3482#Training time (min)#5
2207.05833v1.pdf	Weather Forecasting#SEVIR#MSE#3.6957$Weather Forecasting#SEVIR#mCSI#0.4419$Weather Forecasting#SEVIR#MSE#3.7532$Weather Forecasting#SEVIR#mCSI#0.4185
2112.03566v1.pdf	Weather Forecasting#Shifts#R-AUC MSE#1.1406288012
2107.07455v3.pdf	Weather Forecasting#Shifts#R-AUC MSE#1.3353865316
1904.01561v5.pdf	Molecular Property Prediction#ClinTox#ROC-AUC#90.6$Molecular Property Prediction#SIDER#ROC-AUC#57.0$Molecular Property Prediction#QM7#MAE#103.5$Molecular Property Prediction#FreeSolv#RMSE#2.082$Molecular Property Prediction#QM8#MAE#0.0190$Molecular Property Prediction#ToxCast#ROC-AUC#65.5$Molecular Property Prediction#BACE#ROC-AUC#80.9$Molecular Property Prediction#Tox21#ROC-AUC#75.9$Molecular Property Prediction#ESOL#RMSE#1.050$Molecular Property Prediction#Lipophilicity#RMSE#0.683$Molecular Property Prediction#BBBP#ROC-AUC#71.0$Molecular Property Prediction#QM9#MAE#0.00814
2106.06130v4.pdf	Molecular Property Prediction#ClinTox#ROC-AUC#90.1$Molecular Property Prediction#ClinTox#Molecules (M)#20$Molecular Property Prediction#SIDER#ROC-AUC#67.2$Molecular Property Prediction#QM7#MAE#58.9$Molecular Property Prediction#FreeSolv#RMSE#1.877$Molecular Property Prediction#QM8#MAE#0.0171$Molecular Property Prediction#ToxCast#ROC-AUC#69.2$Molecular Property Prediction#BACE#ROC-AUC#85.6$Molecular Property Prediction#Tox21#ROC-AUC#78.1$Molecular Property Prediction#ESOL#RMSE#0.798$Molecular Property Prediction#Lipophilicity#RMSE#0.66$Molecular Property Prediction#BBBP#ROC-AUC#72.4$Molecular Property Prediction#QM9#MAE#0.00746
1806.09206v2.pdf	Molecular Property Prediction#ClinTox#ROC-AUC#87.5$Molecular Property Prediction#ClinTox#ROC-AUC#77.5$Molecular Property Prediction#SIDER#ROC-AUC#66.8$Molecular Property Prediction#SIDER#ROC-AUC#65.5$Molecular Property Prediction#QM7#MAE#81.9$Molecular Property Prediction#QM7#MAE#92.8$Molecular Property Prediction#FreeSolv#RMSE#2.688$Molecular Property Prediction#FreeSolv#RMSE#5.061$Molecular Property Prediction#QM8#MAE#0.0215$Molecular Property Prediction#QM8#MAE#0.0236$Molecular Property Prediction#BACE#ROC-AUC#79.1$Molecular Property Prediction#BACE#ROC-AUC#77.9$Molecular Property Prediction#Tox21#ROC-AUC#75.8$Molecular Property Prediction#Tox21#ROC-AUC#74.3$Molecular Property Prediction#Lipophilicity#RMSE#0.812$Molecular Property Prediction#Lipophilicity#RMSE#2.072$Molecular Property Prediction#BBBP#ROC-AUC#69.7$Molecular Property Prediction#BBBP#ROC-AUC#69.1$Molecular Property Prediction#QM9#MAE#0.00964$Molecular Property Prediction#QM9#MAE#0.01037
2007.02835v2.pdf	Molecular Property Prediction#ClinTox#ROC-AUC#81.2$Molecular Property Prediction#ClinTox#Molecules (M)#11$Molecular Property Prediction#ClinTox#ROC-AUC#76.2$Molecular Property Prediction#SIDER#ROC-AUC#65.4$Molecular Property Prediction#SIDER#ROC-AUC#64.8$Molecular Property Prediction#QM7#MAE#92.0$Molecular Property Prediction#QM7#MAE#94.5$Molecular Property Prediction#FreeSolv#RMSE#2.176$Molecular Property Prediction#FreeSolv#RMSE#2.272$Molecular Property Prediction#QM8#MAE#0.0218$Molecular Property Prediction#QM8#MAE#0.0224$Molecular Property Prediction#ToxCast#ROC-AUC#65.4$Molecular Property Prediction#ToxCast#ROC-AUC#65.3$Molecular Property Prediction#BACE#ROC-AUC#82.6$Molecular Property Prediction#BACE#ROC-AUC#81.0$Molecular Property Prediction#Tox21#ROC-AUC#74.3$Molecular Property Prediction#Tox21#ROC-AUC#73.5$Molecular Property Prediction#Lipophilicity#RMSE#0.817$Molecular Property Prediction#Lipophilicity#RMSE#0.823$Molecular Property Prediction#BBBP#ROC-AUC#70.0$Molecular Property Prediction#BBBP#ROC-AUC#69.5$Molecular Property Prediction#QM9#MAE#0.00984$Molecular Property Prediction#QM9#MAE#0.00986
2209.01712v1.pdf	Molecular Property Prediction#ClinTox#ROC-AUC#56.3$Molecular Property Prediction#ClinTox#Molecules (M)#77$Molecular Property Prediction#BACE#ROC-AUC#79.9$Molecular Property Prediction#BACE#RMSE#0.01363$Molecular Property Prediction#Delaney#RMSE#0.889$Molecular Property Prediction#Lipophilicity#RMSE#0.798$Molecular Property Prediction#BBBP#ROC-AUC#72.8
2110.01717v1.pdf	3D Geometry Prediction#Molecule3D test#MAE#0.483$3D Geometry Prediction#Molecule3D test#RMSE#0.753$3D Geometry Prediction#Molecule3D test#Validity#1.69$3D Geometry Prediction#Molecule3D test#Validity3D#0.03$3D Geometry Prediction#Molecule3D test#MAE#0.571$3D Geometry Prediction#Molecule3D test#RMSE#0.961$3D Geometry Prediction#Molecule3D test#Validity#100$3D Geometry Prediction#Molecule3D test#Validity3D#100$3D Geometry Prediction#Molecule3D val#MAE#0.482$3D Geometry Prediction#Molecule3D val#RMSE#0.749$3D Geometry Prediction#Molecule3D val#Validity#1.71$3D Geometry Prediction#Molecule3D val#Validity3D#0.02$3D Geometry Prediction#Molecule3D val#MAE#0.509$3D Geometry Prediction#Molecule3D val#RMSE#0.849$3D Geometry Prediction#Molecule3D val#Validity#100$3D Geometry Prediction#Molecule3D val#Validity3D#100
2008.05994v1.pdf	NMR J-coupling#QM9#avg. log MAE#-3.241$NMR J-coupling#QM9#avg. log MAE#-3.453
2010.06907v6.pdf	Compressive Sensing#BSD68 CS=50%#Average PSNR#36.33$Compressive Sensing#BSDS100 - 2x upscaling#Average PSNR#35.95$Compressive Sensing#Set11 cs=50%#Average PSNR#40.32$Compressive Sensing#Urban100 - 2x upscaling#Average PSNR#35.86
1804.04970v1.pdf	Compressive Sensing#Set5#Average PSNR#improving about 0.2-0.3dB
2001.09346v2.pdf	Synthetic Data Generation#UCI Epileptic Seizure Recognition#AUROC#0.92
2110.04458v1.pdf	COVID-19 Diagnosis#COVID-19 CXR Dataset#Average Precision#0.953$COVID-19 Diagnosis#COVID-19 CXR Dataset#Average Recall#0.938$COVID-19 Diagnosis#COVID-19 CXR Dataset#Average F1#0.946
1911.03531v1.pdf	Arabic Text Diacritization#Tashkeela#Diacritic Error Rate#0.0169$Arabic Text Diacritization#Tashkeela#Word Error Rate (WER)#0.0509
2011.00538v1.pdf	Arabic Text Diacritization#Tashkeela#Diacritic Error Rate#0.0183$Arabic Text Diacritization#Tashkeela#Word Error Rate (WER)#0.0534$Arabic Text Diacritization#Tashkeela#Diacritic Error Rate#0.0185$Arabic Text Diacritization#Tashkeela#Word Error Rate (WER)#0.0553
1905.01965v1.pdf	Arabic Text Diacritization#Tashkeela#Diacritic Error Rate#0.0373$Arabic Text Diacritization#Tashkeela#Word Error Rate (WER)#0.1119
2206.14180v2.pdf	Virtual Try-on#VITON-HD#FID#10.91
2103.16874v2.pdf	Virtual Try-on#VITON-HD#FID#11.74
1902.11026v1.pdf	Virtual Try-on#Deep-Fashion#SSIM#0.744$Virtual Try-on#Deep-Fashion#IS#3.03
1909.02165v1.pdf	Virtual Try-on#Deep-Fashion#SSIM#0.7251$Virtual Try-on#Deep-Fashion#IS#2.7904
2205.03835v2.pdf	Automated Essay Scoring#ASAP#Quadratic Weighted Kappa#0.791
1804.07954v2.pdf	Automated Essay Scoring#ASAP#Quadratic Weighted Kappa#0.785
1711.04981v1.pdf	Automated Essay Scoring#ASAP#Quadratic Weighted Kappa#0.764
2102.00781v1.pdf	Automated Essay Scoring#ASAP#Quadratic Weighted Kappa#0.764
1612.04642v2.pdf	Rotated MNIST#Rotated MNIST#Test error#1.69
2206.04374v1.pdf	Bias Detection#PlantVillage_8px#Accuracy (%)#49.0
2004.09456v1.pdf	Bias Detection#StereoSet#ICAT Score#72.97$Bias Detection#StereoSet#ICAT Score#72.03$Bias Detection#StereoSet#ICAT Score#71.73$Bias Detection#StereoSet#ICAT Score#71.21$Bias Detection#StereoSet#ICAT Score#70.54$Bias Detection#StereoSet#ICAT Score#69.89$Bias Detection#StereoSet#ICAT Score#67.50$Bias Detection#StereoSet#ICAT Score#62.10
2002.06644v1.pdf	Bias Detection#Wiki Neutrality Corpus#F1#70.4
2006.05849v3.pdf	Self-Supervised Learning#STL-10#Accuracy (%)#89.67
2111.12062v1.pdf	Self-Supervised Learning#DABS#Natural Images#10.1$Self-Supervised Learning#DABS#Text#42.3$Self-Supervised Learning#DABS#Speech#24.9$Self-Supervised Learning#DABS#Sensors#69.8$Self-Supervised Learning#DABS#Med. Imaging#68.1$Self-Supervised Learning#DABS#Images & Text#57.5$Self-Supervised Learning#DABS#Natural Images#20.9$Self-Supervised Learning#DABS#Text#48.4$Self-Supervised Learning#DABS#Speech#36.5$Self-Supervised Learning#DABS#Sensors#88.7$Self-Supervised Learning#DABS#Med. Imaging#74.5$Self-Supervised Learning#DABS#Images & Text#54.3$Self-Supervised Learning#DABS#Natural Images#27.9$Self-Supervised Learning#DABS#Text#44.1$Self-Supervised Learning#DABS#Speech#41.8$Self-Supervised Learning#DABS#Sensors#79.5$Self-Supervised Learning#DABS#Med. Imaging#72.4$Self-Supervised Learning#DABS#Images & Text#48.9
2012.07788v1.pdf	Meme Classification#Hateful Memes#ROC-AUC#0.825
2012.12975v1.pdf	Meme Classification#Hateful Memes#ROC-AUC#0.811
2011.12091v1.pdf	Ad-hoc video search#TRECVID-AVS19 (V3C1)#infAP#0.167$Ad-hoc video search#TRECVID-AVS17 (IACC.3)#infAP#0.234$Ad-hoc video search#TRECVID-AVS18 (IACC.3)#infAP#0.128$Ad-hoc video search#TRECVID-AVS16 (IACC.3)#infAP#0.164
2009.05381v2.pdf	Ad-hoc video search#TRECVID-AVS17 (IACC.3)#infAP#0.231$Ad-hoc video search#TRECVID-AVS18 (IACC.3)#infAP#0.121$Ad-hoc video search#TRECVID-AVS16 (IACC.3)#infAP#0.152
1805.01978v1.pdf	Contrastive Learning#imagenet-1k#ImageNet Top-1 Accuracy#56.5
2010.14022v2.pdf	Cover song identification#Covers80#MAP#0.906$Cover song identification#Da-TACOS#mAP#0.743$Cover song identification#SHS100K-TEST#mAP#0.836$Cover song identification#YouTube350#MAP#0.955
1910.12551v2.pdf	Cover song identification#Covers80#MAP#0.844$Cover song identification#YouTube350#MAP#0.885
1911.00334v1.pdf	Cover song identification#Covers80#MAP#0.840$Cover song identification#SHS100K-TEST#mAP#0.655$Cover song identification#YouTube350#MAP#0.917
2209.14916v2.pdf	Motion Synthesis#HumanML3D#FID#0.544$Motion Synthesis#HumanML3D#Diversity#9.559$Motion Synthesis#HumanML3D#Multimodality#2.927$Motion Synthesis#HumanAct12#FID#0.08$Motion Synthesis#HumanAct12#Accuracy#0.99$Motion Synthesis#HumanAct12#Multimodality#2.58
2201.06701v4.pdf	Motion Synthesis#LaFAN1#L2Q@5#0.11$Motion Synthesis#LaFAN1#L2Q@15#0.32$Motion Synthesis#LaFAN1#L2Q@30#0.57$Motion Synthesis#LaFAN1#L2P@5#0.13$Motion Synthesis#LaFAN1#L2P@15#0.47$Motion Synthesis#LaFAN1#NPSS@5#0.0014$Motion Synthesis#LaFAN1#NPSS@15#0.0217$Motion Synthesis#LaFAN1#NPSS@30#0.1217$Motion Synthesis#LaFAN1#L2P@30#1.00
2103.00776v1.pdf	Motion Synthesis#LaFAN1#L2Q@5#0.14$Motion Synthesis#LaFAN1#L2Q@15#0.36$Motion Synthesis#LaFAN1#L2Q@30#0.61$Motion Synthesis#LaFAN1#L2P@5#0.22$Motion Synthesis#LaFAN1#L2P@15#0.56$Motion Synthesis#LaFAN1#NPSS@5#0.0016$Motion Synthesis#LaFAN1#NPSS@15#0.0234$Motion Synthesis#LaFAN1#NPSS@30#0.1222$Motion Synthesis#LaFAN1#L2P@30#1.1
2102.04942v1.pdf	Motion Synthesis#LaFAN1#L2Q@5#0.17$Motion Synthesis#LaFAN1#L2Q@15#0.42$Motion Synthesis#LaFAN1#L2Q@30#0.69$Motion Synthesis#LaFAN1#L2P@5#0.23$Motion Synthesis#LaFAN1#L2P@15#0.65$Motion Synthesis#LaFAN1#NPSS@5#0.002$Motion Synthesis#LaFAN1#NPSS@15#0.0258$Motion Synthesis#LaFAN1#NPSS@30#0.1328$Motion Synthesis#LaFAN1#L2P@30#1.28
2106.04004v1.pdf	Motion Synthesis#LaFAN1#L2Q@5#0.24$Motion Synthesis#LaFAN1#L2Q@15#0.54$Motion Synthesis#LaFAN1#L2Q@30#0.94
1911.07056v1.pdf	Thai Word Segmentation#BEST-2010#F1-Score#0.9839
2004.03037v2.pdf	Breast Tumour Classification#PCam#AUC#0.975$Colorectal Gland Segmentation:#CRAG#F1-score#0.874$Colorectal Gland Segmentation:#CRAG#Dice#0.891$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#138.4$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.826$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#60
1711.07289v3.pdf	Breast Tumour Classification#PCam#AUC#0.971$Breast Tumour Classification#PCam#AUC#0.969$Breast Tumour Classification#PCam#AUC#0.963$Colorectal Gland Segmentation:#CRAG#F1-score#0.861$Colorectal Gland Segmentation:#CRAG#Dice#0.888$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#139.5$Colorectal Gland Segmentation:#CRAG#F1-score#0.855$Colorectal Gland Segmentation:#CRAG#Dice#0.870$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#156.2$Colorectal Gland Segmentation:#CRAG#F1-score#0.837$Colorectal Gland Segmentation:#CRAG#Dice#0.869$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#164.8$Colorectal Gland Segmentation:#CRAG#F1-score#0.811$Colorectal Gland Segmentation:#CRAG#Dice#0.848$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#175.9$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.820$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#55.8$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.818$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#54.3$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.809$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#54.2$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.791$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#51.0
2002.08725v1.pdf	Breast Tumour Classification#PCam#AUC#0.968$Breast Tumour Classification#PCam#AUC#0.962$Colorectal Gland Segmentation:#CRAG#F1-score#0.837$Colorectal Gland Segmentation:#CRAG#Dice#0.866$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#157.4$Colorectal Gland Segmentation:#CRAG#F1-score#0.818$Colorectal Gland Segmentation:#CRAG#Dice#0.834$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#192.2$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.814$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#53.4$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.811$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#51.9
1602.07576v3.pdf	Breast Tumour Classification#PCam#AUC#0.964$Colorectal Gland Segmentation:#CRAG#F1-score#0.833$Colorectal Gland Segmentation:#CRAG#Dice#0.856$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#170.4$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.793$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#49.0
1806.03962v1.pdf	Breast Tumour Classification#PCam#AUC#0.963
1612.09346v3.pdf	Breast Tumour Classification#PCam#AUC#0.898$Breast Tumour Classification#PCam#AUC#0.881$Breast Tumour Classification#PCam#AUC#0.871$Colorectal Gland Segmentation:#CRAG#F1-score#0.776$Colorectal Gland Segmentation:#CRAG#Dice#0.782$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#251.9$Colorectal Gland Segmentation:#CRAG#F1-score#0.745$Colorectal Gland Segmentation:#CRAG#Dice#0.758$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#287.5$Colorectal Gland Segmentation:#CRAG#F1-score#0.711$Colorectal Gland Segmentation:#CRAG#Dice#0.721$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#318.9$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.813$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#51.4$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.808$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#50.7$Multi-tissue Nucleus Segmentation#Kumar#Dice#0.800$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#49.9
1806.01963v4.pdf	Colorectal Gland Segmentation:#CRAG#F1-score#0.869$Colorectal Gland Segmentation:#CRAG#Dice#0.883$Colorectal Gland Segmentation:#CRAG#Hausdorff Distance (mm)#146.2
2208.13975v1.pdf	Multi-tissue Nucleus Segmentation#Kumar#Dice#0.843$Multi-tissue Nucleus Segmentation#Kumar#Jaccard Index#0.652$Multi-tissue Nucleus Segmentation#Kumar#PQ#0.625$Multi-tissue Nucleus Segmentation#CoNSeP#Dice#0.855$Multi-tissue Nucleus Segmentation#CoNSeP#Jaccard Index#0.576$Multi-tissue Nucleus Segmentation#CoNSeP#PQ#0.559
1812.06499v5.pdf	Multi-tissue Nucleus Segmentation#Kumar#Dice#0.826$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#59.7$Multi-tissue Nucleus Segmentation#CoNSeP#Dice#0.853$Multi-tissue Nucleus Segmentation#CoNSeP#Jaccard Index#0.571$Multi-tissue Nucleus Segmentation#CoNSeP#PQ#0.547
1903.05358v1.pdf	Multi-tissue Nucleus Segmentation#Kumar#Dice#0.818$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#57.7
1804.08145v2.pdf	Multi-tissue Nucleus Segmentation#Kumar#Dice#0.797$Multi-tissue Nucleus Segmentation#Kumar#Hausdorff Distance (mm)#51.9
2111.01557v1.pdf	Multi-tissue Nucleus Segmentation#CoNSeP#Dice#0.822$Multi-tissue Nucleus Segmentation#CoNSeP#Jaccard Index#0.56$Multi-tissue Nucleus Segmentation#CoNSeP#PQ#0.545
2003.06520v1.pdf	Occluded 3D Object Symmetry Detection#YCB-Video#PR AUC#0.516$Symmetry Detection#YCB-Video#PR AUC#0.516
2104.08967v3.pdf	Deep Clustering#Searchsnippets#1:1 Accuracy#80.6$Deep Clustering#Searchsnippets#NMI#69.5$Deep Clustering#Searchsnippets#ARI#66.3$Deep Clustering#Stackoverflow#1:1 Accuracy#79.7$Deep Clustering#Stackoverflow#NMI#75.6$Deep Clustering#Stackoverflow#ARI#60.6
2109.15149v1.pdf	Deep Clustering#Coil-20#NMI#80.06$Deep Clustering#MNIST#NMI#91.06$Deep Clustering#USPS#NMI#82.23
2002.08645v1.pdf	Core set discovery#Letter#F1(10-fold)#65.9$Core set discovery#Amazon-employee-access#F1(10-fold)#91.5$Core set discovery#Glass identification#F1(10-fold)#64.3$Core set discovery#Electricity#F1(10-fold)#69.3$Core set discovery#Credit-g#F1(10-fold)#74.3$Core set discovery#Mozilla4#F1(10-fold)#91.2$Core set discovery#Soybean#F1(10-fold)#91.1$Core set discovery#ISOLET#F1(10-fold)#90.5$Core set discovery#micro-mass#F1(10-fold)#83.9$Core set discovery#Kr-vs-kp#F1(10-fold)#93.7$Core set discovery#Abalone#F1(10-fold)#18.6$Core set discovery#UCI GAS#F1(10-fold)#94.6$Core set discovery#JM1#F1(10-fold)#77.1$Core set discovery#MNIST#F1(10-fold)#77.2
2006.13760v2.pdf	NetHack Score#NetHack Learning Environment#Average Score#780
1911.10720v3.pdf	Historical Color Image Dating#HCI#MAE#0.62
1902.01378v2.pdf	General Reinforcement Learning#Obstacle Tower (Strong Gen) varied#Score#0.8$General Reinforcement Learning#Obstacle Tower (Strong Gen) varied#Score#0.6$General Reinforcement Learning#Obstacle Tower (Strong Gen) fixed#Score#0.6$General Reinforcement Learning#Obstacle Tower (No Gen) fixed#Score#7$General Reinforcement Learning#Obstacle Tower (No Gen) fixed#Score#5$General Reinforcement Learning#Obstacle Tower (Weak Gen) fixed#Score#1.2$General Reinforcement Learning#Obstacle Tower (Weak Gen) fixed#Score#1$General Reinforcement Learning#Obstacle Tower (Weak Gen) varied#Score#3.4$General Reinforcement Learning#Obstacle Tower (Weak Gen) varied#Score#0.8$General Reinforcement Learning#Obstacle Tower (No Gen) varied#Score#4.8$General Reinforcement Learning#Obstacle Tower (No Gen) varied#Score#1
2005.06194v1.pdf	Multi-target regression#Google 5 qubit random Hamiltonian#Average mean absolute error#1.05
2111.11029v2.pdf	Action Quality Assessment#MTL-AQA#Spearman Correlation#95.89$Action Quality Assessment#MTL-AQA#Spearman Correlation#94.52$Action Quality Assessment#MTL-AQA#Spearman Correlation#92.31$Action Quality Assessment#JIGSAWS#Spearman Correlation#0.86$Action Quality Assessment#JIGSAWS#Spearman Correlation#0.76$Action Quality Assessment#JIGSAWS#Spearman Correlation#0.72$Action Quality Assessment#AQA-7#Spearman Correlation#85.20%$Action Quality Assessment#AQA-7#Spearman Correlation#82.58%
2108.07797v1.pdf	Action Quality Assessment#MTL-AQA#Spearman Correlation#95.12$Action Quality Assessment#MTL-AQA#RL2(*100)#0.260$Action Quality Assessment#MTL-AQA#Spearman Correlation#93.81$Action Quality Assessment#MTL-AQA#RL2(*100)#0.394$Action Quality Assessment#MTL-AQA#Spearman Correlation#93.41$Action Quality Assessment#MTL-AQA#RL2(*100)#0.365$Action Quality Assessment#MTL-AQA#Spearman Correlation#91.96$Action Quality Assessment#MTL-AQA#RL2(*100)#0.465$Action Quality Assessment#AQA-7#Spearman Correlation#84.01%$Action Quality Assessment#AQA-7#RL2(*100)#2.12$Action Quality Assessment#AQA-7#Spearman Correlation#76.01%$Action Quality Assessment#AQA-7#RL2(*100)#3.20
2102.10555v2.pdf	Action Quality Assessment#MTL-AQA#Spearman Correlation#93.15
2006.07665v1.pdf	Action Quality Assessment#MTL-AQA#Spearman Correlation#92.73$Action Quality Assessment#MTL-AQA#RL2(*100)#0.451$Action Quality Assessment#MTL-AQA#Spearman Correlation#92.31$Action Quality Assessment#MTL-AQA#RL2(*100)#0.468$Action Quality Assessment#MTL-AQA#Spearman Correlation#91.58$Action Quality Assessment#MTL-AQA#RL2(*100)#0.654$Action Quality Assessment#MTL-AQA#Spearman Correlation#90.66$Action Quality Assessment#MTL-AQA#RL2(*100)#0.609$Action Quality Assessment#MTL-AQA#Spearman Correlation#89.21$Action Quality Assessment#AQA-7#Spearman Correlation#81.02%$Action Quality Assessment#AQA-7#RL2(*100)#2.57$Action Quality Assessment#AQA-7#Spearman Correlation#74.72%
1901.10435v3.pdf	Action Quality Assessment#KIMORE#Average mean absolute error#0.0379$Action Quality Assessment#UI-PRMD#Average mean absolute error#0.0253
2008.05977v1.pdf	Action Quality Assessment#Rhythmic Gymnastic#Spearman Correlation#62.3
1812.06367v2.pdf	Action Quality Assessment#AQA-7#Spearman Correlation#69.37%$Action Quality Assessment#AQA-7#Spearman Correlation#64.78%$Action Quality Assessment#AQA-7#Spearman Correlation#61.65%
2209.05044v1.pdf	Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#35.34$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#51.56$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#22.03$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#82.56$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#58.01$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#38.29$Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#14.29$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#41.41$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#22.36$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#13.28$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#73.10$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#41.62$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#24.24$Action Anticipation#EGTEA#Top-1 Accuracy#49.8
2106.02036v2.pdf	Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#34.36$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#20.16$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#16.84$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#80.03$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#51.57$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#36.52$Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#16.7$Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#12.6$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#30.66$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#15.64$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#10.41$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#72.17$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#40.76$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#24.27$Action Anticipation#EPIC-KITCHENS-100#Recall@5#15.9
2101.04924v2.pdf	Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#35.44$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#22.79$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#14.66$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#79.72$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#52.09$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#34.98$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#29.33$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#15.50$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#9.25$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#70.67$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#35.78$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#22.19
1707.04818v1.pdf	Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#29.35$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#16.07$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#8.08$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#74.49$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#38.83$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#18.19$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#22.52$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#7.81$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#2.65$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#62.65$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#21.42$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#7.57
1804.02748v2.pdf	Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#31.81$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#16.22$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#6.00$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#76.56$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#42.15$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#28.21$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Verb#29.76$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Noun#15.15$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 1 Accuracy - Act.#4.32$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Verb#76.03$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Noun#38.56$Action Anticipation#EPIC-KITCHENS-55 (Seen test set (S1))#Top 5 Accuracy - Act.#15.21$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#25.30$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#10.41$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#2.39$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#68.32$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#29.50$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#6.63$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Verb#25.23$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Noun#9.97$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 1 Accuracy - Act.#2.29$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Verb#68.66$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Noun#27.38$Action Anticipation#EPIC-KITCHENS-55 (Unseen test set (S2)#Top 5 Accuracy - Act.#9.35
2005.02190v2.pdf	Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#11.2
2107.09504v1.pdf	Action Anticipation#EPIC-KITCHENS-100 (test)#recall@5#11.0
2207.12080v1.pdf	Action Anticipation#Ego4D#ED@20 Verb#0.752$Action Anticipation#Ego4D#ED@20 Noun#0.748$Action Anticipation#Ego4D#ED@20 Action#0.93
2006.00830v2.pdf	Action Anticipation#Assembly101#Actions Recall@5#9.1$Action Anticipation#Assembly101#Verbs Recall@5#59.2$Action Anticipation#Assembly101#Objects Recall@5#31.3
2103.14635v2.pdf	3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.906$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.9$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.104$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#0.927
1912.10644v1.pdf	3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.872
2108.08035v2.pdf	3D Point Cloud Classification#IntrA#F1 score (5-fold)#0.858
2201.12296v1.pdf	3D Point Cloud Classification#ModelNet40-C#Error Rate#0.163
2102.01929v3.pdf	3D Point Cloud Classification#ModelNet40-C#Error Rate#0.173$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.5$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.745
2101.01461v2.pdf	3D Point Cloud Classification#ModelNet40-C#Error Rate#0.173$3D Point Cloud Classification#ModelNet40-C#Error Rate#0.191$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.4
2008.06374v1.pdf	3D Point Cloud Classification#ModelNet40-C#Error Rate#0.193$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.028
2209.10318v1.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#88.3$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#87.0$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.5$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.9
2210.04208v1.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#86.7$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#84.8$3D Point Cloud Classification#ScanObjectNN#Number of params#12.6M$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.4$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.2$3D Point Cloud Classification#ModelNet40#Number of params#1.62M
2205.14401v2.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#86.4$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.0
2202.07123v1.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#85.7$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#84.4$3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#83.8$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#81.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.5$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.4$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#0.977
2203.06604v2.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#85.2$3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.0$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#0.927
2205.00847v2.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#84.1
2111.14819v2.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#83.1$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8
2112.04903v1.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#82.1$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#79.1$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.7$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.2
1911.12885v5.pdf	3D Point Cloud Classification#ScanObjectNN#Overall Accuracy#80.5$3D Point Cloud Classification#ScanObjectNN#Mean Accuracy#77.8$3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.8$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.0
2201.00785v2.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#94.2$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.6$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#92.1
2106.05304v1.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.9$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.047
2202.10251v1.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.7$3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.4
2010.07215v2.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#93.0$3D Point Cloud Classification#ModelNet40#Mean Accuracy#90.4
1803.05827v1.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#92.1
1505.00880v3.pdf	3D Point Cloud Classification#ModelNet40#Overall Accuracy#90.1
1608.04236v2.pdf	3D Point Cloud Classification#ModelNet40#Mean Accuracy#91.33$3D Point Cloud Classification#ModelNet40#Mean Accuracy#88.98
1406.5670v3.pdf	3D Point Cloud Classification#ModelNet40#Mean Accuracy#77.3
2204.04662v2.pdf	Incremental Learning#ImageNet100 - 20 steps#Average Incremental Accuracy#74.49$Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#69.46$Incremental Learning#ImageNet-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#77.54$Incremental Learning#CIFAR100-B0(10steps of 10 classes)#Average Incremental Accuracy#72.9$Incremental Learning#CIFAR-100 - 50 classes + 25 steps of 2 classes#Average Incremental Accuracy#63.83$Incremental Learning#ImageNet-100 - 50 classes + 25 steps of 2 classes#Average Incremental Accuracy#69.34$Incremental Learning#CIFAR100B020Step(5ClassesPerStep)#Average Incremental Accuracy#70.65$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#68.34$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy#77.75$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#67.95
2103.16788v1.pdf	Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#72.60$Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#67.60$Incremental Learning#CIFAR100B050S(2ClassesPerStep)#Average Incremental Accuracy#72.05$Incremental Learning#ImageNet-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#77.73$Incremental Learning#CIFAR100-B0(10steps of 10 classes)#Average Incremental Accuracy#74.64$Incremental Learning#CIFAR100B020Step(5ClassesPerStep)#Average Incremental Accuracy#73.98$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#68.84$Incremental Learning#ImageNet - 10 steps#Final Accuracy#60.16$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#88.17$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#82.86$Incremental Learning#ImageNet - 10 steps## M Params#116.89$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#66.73$Incremental Learning#ImageNet - 10 steps#Final Accuracy#58.62$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#87.08$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#81.89$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy#77.18$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy#66.70$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#93.23$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#87.52$Incremental Learning#ImageNet100 - 10 steps## M Params#112.27$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy#76.12$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy#66.07$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#92.79$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#88.38$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#72.45$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#66.36
2102.09517v1.pdf	Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#67.17$Incremental Learning#ImageNet-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#76.77$Incremental Learning#ImageNet-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#79.44$Incremental Learning#ImageNet - 500 classes + 5 steps of 100 classes#Average Incremental Accuracy#68.04$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#65.86
2004.13513v3.pdf	Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#64.83$Incremental Learning#ImageNet - 500 classes + 10 steps of 50 classes#Average Incremental Accuracy#64.13$Incremental Learning#CIFAR-100 - 50 classes + 50 steps of 1 class#Average Incremental Accuracy#57.98$Incremental Learning#ImageNet-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#73.14$Incremental Learning#CIFAR-100 - 50 classes + 25 steps of 2 classes#Average Incremental Accuracy#60.72$Incremental Learning#ImageNet-100 - 50 classes + 25 steps of 2 classes#Average Incremental Accuracy#67.28$Incremental Learning#ImageNet-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#75.82$Incremental Learning#ImageNet - 500 classes + 5 steps of 100 classes#Average Incremental Accuracy#66.95$Incremental Learning#ImageNet-100 - 50 classes + 50 steps of 1 class#Average Incremental Accuracy#62.08$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#63.19
1905.13260v1.pdf	Incremental Learning#CIFAR-100 - 50 classes + 5 steps of 10 classes#Average Incremental Accuracy#56.86$Incremental Learning#CIFAR-100 - 50 classes + 50 steps of 1 class#Average Incremental Accuracy#47.09$Incremental Learning#CIFAR-100 - 50 classes + 25 steps of 2 classes#Average Incremental Accuracy#48.96$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#84.00$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#73.20$Incremental Learning#ImageNet - 10 steps## M Params#11.68$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#90.60$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#84.40$Incremental Learning#ImageNet100 - 10 steps## M Params#11.22$Incremental Learning#ImageNet-100 - 50 classes + 50 steps of 1 class#Average Incremental Accuracy#46.49$Incremental Learning#CIFAR-100 - 50 classes + 10 steps of 5 classes#Average Incremental Accuracy#53.21
2111.11326v3.pdf	Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#71.29$Incremental Learning#ImageNet - 10 steps#Final Accuracy#63.34$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#88.59$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#84.49$Incremental Learning#ImageNet - 10 steps## M Params#11.36$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy#77.15$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy#69.10$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#92.04$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#87.98$Incremental Learning#ImageNet100 - 10 steps## M Params#11.01
1911.07053v1.pdf	Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy#65.67$Incremental Learning#ImageNet - 10 steps#Final Accuracy#55.60$Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#86.60$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#81.10$Incremental Learning#ImageNet - 10 steps## M Params#11.68$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#91.00$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#84.10$Incremental Learning#ImageNet100 - 10 steps## M Params#11.22
1807.09536v2.pdf	Incremental Learning#ImageNet - 10 steps#Average Incremental Accuracy Top-5#72.09$Incremental Learning#ImageNet - 10 steps#Final Accuracy Top-5#52.29$Incremental Learning#ImageNet - 10 steps## M Params#11.68$Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#89.92$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#80.29$Incremental Learning#ImageNet100 - 10 steps## M Params#11.22
1906.01120v3.pdf	Incremental Learning#ImageNet100 - 10 steps#Average Incremental Accuracy Top-5#87.90$Incremental Learning#ImageNet100 - 10 steps#Final Accuracy Top-5#74.00
2202.03377v3.pdf	Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.571$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.574$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.590$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.601$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.863$Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.180
2110.05379v1.pdf	Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#0.814
2010.01089v3.pdf	Point Cloud Classification#PointCloud-C#mean Corruption Error (mCE)#1.047$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#0.977$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.130$Point Cloud Segmentation#PointCloud-C#mean Corruption Error (mCE)#1.173$3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#89.2
2202.03772v2.pdf	Jet Tagging#JetClass#Accuracy#0.861$Jet Tagging#JetClass#AUC#0.9877
1902.08570v3.pdf	Jet Tagging#JetClass#Accuracy#0.844$Jet Tagging#JetClass#AUC#0.9849
2103.17249v1.pdf	Image Manipulation#10-Monty-Hall#10-20% Mask PSNR#177
2109.06151v3.pdf	Image Manipulation#LRS2#LPIPS (S1)#0.12$Image Manipulation#LRS2#SIFID (S1)#0.07$Image Manipulation#LRS2#LPIPS (S2)#0.21$Image Manipulation#LRS2#SIFID (S2)#0.12$Image Manipulation#LRS2#LPIPS (S3)#0.1$Image Manipulation#LRS2#SIFID (S3)#0.04$Image Manipulation#LRS2#LPIPS (S4)#0.22$Image Manipulation#LRS2#SIFID (S4)#0.12$Image Manipulation#LRS2#LPIPS (S5)#0.14$Image Manipulation#LRS2#SIFID (S5)#0.06$Image Manipulation#LRS2#LPIPS (S1)#0.44$Image Manipulation#LRS2#SIFID (S1)#0.51$Image Manipulation#LRS2#LPIPS (S2)#0.47$Image Manipulation#LRS2#SIFID (S2)#0.49$Image Manipulation#LRS2#LPIPS (S3)#0.41$Image Manipulation#LRS2#SIFID (S3)#0.5$Image Manipulation#LRS2#LPIPS (S4)#0.53$Image Manipulation#LRS2#SIFID (S4)#0.26$Image Manipulation#LRS2#LPIPS (S5)#0.46$Image Manipulation#LRS2#SIFID (S5)#0.44
1909.07095v2.pdf	Inductive logic programming#RuDaS#H-Score#0.2321$Inductive logic programming#RuDaS#R-Score#0.335$Inductive logic programming#RuDaS#H-Score#0.152$Inductive logic programming#RuDaS#R-Score#0.2728$Inductive logic programming#RuDaS#H-Score#0.1025$Inductive logic programming#RuDaS#R-Score#0.1906$Inductive logic programming#RuDaS#H-Score#0.0728$Inductive logic programming#RuDaS#R-Score#0.1811
2007.05056v4.pdf	Multimodal Text and Image Classification#CD18#F-measure (%)#88.3$Multimodal Text and Image Classification#CD18#Accuracy#88
2112.07566v2.pdf	image-sentence alignment#VALSE plurality#Accuracy (%)#62.0$image-sentence alignment#VALSE plurality#pairwise accuracy#72.4$image-sentence alignment#VALSE plurality#Accuracy (%)#55.1$image-sentence alignment#VALSE plurality#pairwise accuracy#64.4$image-sentence alignment#VALSE plurality#Accuracy (%)#50.3$image-sentence alignment#VALSE plurality#pairwise accuracy#61.2$image-sentence alignment#VALSE plurality#pairwise accuracy#56.2$image-sentence alignment#VALSE plurality#pairwise accuracy#53.1$image-sentence alignment#VALSE plurality#pairwise accuracy#51.9$image-sentence alignment#VALSE plurality#Accuracy (%)#46.5$image-sentence alignment#VALSE plurality#pairwise accuracy#45.7$image-sentence alignment#VALSE existence#pairwise accuracy#95.6$image-sentence alignment#VALSE existence#Accuracy (%)#89.0$image-sentence alignment#VALSE existence#pairwise accuracy#78.6$image-sentence alignment#VALSE existence#Accuracy (%)#55.8$image-sentence alignment#VALSE existence#pairwise accuracy#66.9$image-sentence alignment#VALSE existence#pairwise accuracy#66.5$image-sentence alignment#VALSE existence#Accuracy (%)#2.4$image-sentence alignment#VALSE existence#pairwise accuracy#61.8$image-sentence alignment#VALSE existence#pairwise accuracy#58.0$image-sentence alignment#VALSE existence#pairwise accuracy#39.7$image-sentence alignment#VALSE existence#Accuracy (%)#49.3$image-sentence alignment#VALSE#Average Accuracy#63.2$image-sentence alignment#VALSE#average pairwise accuracy#75.1$image-sentence alignment#VALSE#average pairwise accuracy#64.0$image-sentence alignment#VALSE#Average Accuracy#51.3$image-sentence alignment#VALSE#average pairwise accuracy#63.7$image-sentence alignment#VALSE#average pairwise accuracy#60.7$image-sentence alignment#VALSE#average pairwise accuracy#60.1$image-sentence alignment#VALSE#Average Accuracy#53.5$image-sentence alignment#VALSE#average pairwise accuracy#59.6$image-sentence alignment#VALSE#Average Accuracy#48.8$image-sentence alignment#VALSE#average pairwise accuracy#46.4$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#88.8$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#87.1$image-sentence alignment#VALSE foil-it (noun phrases)#Accuracy (%)#70.8$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#86.9$image-sentence alignment#VALSE foil-it (noun phrases)#Accuracy (%)#71.5$image-sentence alignment#VALSE foil-it (noun phrases)#Accuracy (%)#55.9$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#80.7$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#77.5$image-sentence alignment#VALSE foil-it (noun phrases)#pairwise accuracy#48.5$image-sentence alignment#VALSE foil-it (noun phrases)#Accuracy (%)#46.6$image-sentence alignment#VALSE actant swap#pairwise accuracy#76.9$image-sentence alignment#VALSE actant swap#pairwise accuracy#72.2$image-sentence alignment#VALSE actant swap#pairwise accuracy#68.6$image-sentence alignment#VALSE actant swap#Accuracy (%)#50.4$image-sentence alignment#VALSE actant swap#pairwise accuracy#68.3$image-sentence alignment#VALSE actant swap#Accuracy (%)#52.2$image-sentence alignment#VALSE actant swap#pairwise accuracy#58.9$image-sentence alignment#VALSE actant swap#Accuracy (%)#48.5$image-sentence alignment#VALSE actant swap#pairwise accuracy#45.8$image-sentence alignment#VALSE actant swap#Accuracy (%)#49.7$image-sentence alignment#VALSE actant swap#pairwise accuracy#44.4$image-sentence alignment#VALSE action replacement#pairwise accuracy#75.6$image-sentence alignment#VALSE action replacement#pairwise accuracy#70.7$image-sentence alignment#VALSE action replacement#Accuracy (%)#52.6$image-sentence alignment#VALSE action replacement#pairwise accuracy#66.8$image-sentence alignment#VALSE action replacement#pairwise accuracy#65.9$image-sentence alignment#VALSE action replacement#Accuracy (%)#57.3$image-sentence alignment#VALSE action replacement#pairwise accuracy#65.4$image-sentence alignment#VALSE action replacement#pairwise accuracy#54.8$image-sentence alignment#VALSE action replacement#Accuracy (%)#51.1$image-sentence alignment#VALSE action replacement#pairwise accuracy#49.2$image-sentence alignment#VALSE action replacement#Accuracy (%)#48.8$image-sentence alignment#VALSE counting small numbers#Accuracy (%)#69.2$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#80.2$image-sentence alignment#VALSE counting small numbers#Accuracy (%)#55.4$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#69.2$image-sentence alignment#VALSE counting small numbers#Accuracy (%)#50.6$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#62.9$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#62.5$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#49.8$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#48.7$image-sentence alignment#VALSE counting small numbers#Accuracy (%)#47.8$image-sentence alignment#VALSE counting small numbers#pairwise accuracy#48.2$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#77.3$image-sentence alignment#VALSE counting adversarial#Accuracy (%)#66.7$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#73.7$image-sentence alignment#VALSE counting adversarial#Accuracy (%)#51.8$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#69.5$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#57.5$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#50.0$image-sentence alignment#VALSE counting adversarial#Accuracy (%)#50.0$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#45.3$image-sentence alignment#VALSE counting adversarial#pairwise accuracy#42.6$image-sentence alignment#VALSE counting adversarial#Accuracy (%)#49.9$image-sentence alignment#VALSE coreference standard#pairwise accuracy#75.7$image-sentence alignment#VALSE coreference standard#Accuracy (%)#54.4$image-sentence alignment#VALSE coreference standard#pairwise accuracy#54.5$image-sentence alignment#VALSE coreference standard#pairwise accuracy#52.1$image-sentence alignment#VALSE coreference standard#pairwise accuracy#49.5$image-sentence alignment#VALSE coreference standard#Accuracy (%)#50.0$image-sentence alignment#VALSE coreference standard#pairwise accuracy#47.2$image-sentence alignment#VALSE coreference standard#pairwise accuracy#46.8$image-sentence alignment#VALSE coreference standard#Accuracy (%)#49.8$image-sentence alignment#VALSE coreference standard#pairwise accuracy#45.6$image-sentence alignment#VALSE spatial relations#pairwise accuracy#77.2$image-sentence alignment#VALSE spatial relations#pairwise accuracy#75.0$image-sentence alignment#VALSE spatial relations#Accuracy (%)#53.4$image-sentence alignment#VALSE spatial relations#pairwise accuracy#67.7$image-sentence alignment#VALSE spatial relations#pairwise accuracy#64.3$image-sentence alignment#VALSE spatial relations#Accuracy (%)#50.8$image-sentence alignment#VALSE spatial relations#pairwise accuracy#60.2$image-sentence alignment#VALSE spatial relations#Accuracy (%)#49.9$image-sentence alignment#VALSE spatial relations#pairwise accuracy#57.2$image-sentence alignment#VALSE spatial relations#Accuracy (%)#49.3$image-sentence alignment#VALSE spatial relations#pairwise accuracy#39.7$image-sentence alignment#VALSE coreference clean#Accuracy (%)#54.3$image-sentence alignment#VALSE coreference clean#pairwise accuracy#69.2$image-sentence alignment#VALSE coreference clean#pairwise accuracy#50.0$image-sentence alignment#VALSE coreference clean#pairwise accuracy#49.7$image-sentence alignment#VALSE coreference clean#Accuracy (%)#50.0$image-sentence alignment#VALSE coreference clean#pairwise accuracy#48.1$image-sentence alignment#VALSE coreference clean#pairwise accuracy#47.6$image-sentence alignment#VALSE coreference clean#pairwise accuracy#45.2$image-sentence alignment#VALSE coreference clean#Accuracy (%)#49.0$image-sentence alignment#VALSE coreference clean#pairwise accuracy#44.2$image-sentence alignment#VALSE counting balanced#pairwise accuracy#76.7$image-sentence alignment#VALSE counting balanced#Accuracy (%)#64.9$image-sentence alignment#VALSE counting balanced#pairwise accuracy#62.2$image-sentence alignment#VALSE counting balanced#Accuracy (%)#52.0$image-sentence alignment#VALSE counting balanced#pairwise accuracy#62.1$image-sentence alignment#VALSE counting balanced#pairwise accuracy#58.6$image-sentence alignment#VALSE counting balanced#Accuracy (%)#50.7$image-sentence alignment#VALSE counting balanced#pairwise accuracy#51.6$image-sentence alignment#VALSE counting balanced#pairwise accuracy#51.2$image-sentence alignment#VALSE counting balanced#pairwise accuracy#48.2$image-sentence alignment#VALSE counting balanced#Accuracy (%)#48.3
2111.08683v1.pdf	Graph Learning#CAMELS#R^2#0.97$Graph Learning#CAMELS#absolute relative error#0.7
2109.05534v1.pdf	Text based Person Retrieval#RSTPReid#R@1#39.05$Text based Person Retrieval#RSTPReid#R@5#62.60$Text based Person Retrieval#RSTPReid#R@10#73.95$Text based Person Retrieval#CUHK-PEDES#R@1#59.98$Text based Person Retrieval#CUHK-PEDES#R@10#87.56$Text based Person Retrieval#CUHK-PEDES#R@5#80.41
2110.10807v1.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#64.08$Text based Person Retrieval#CUHK-PEDES#R@10#88.19$Text based Person Retrieval#CUHK-PEDES#R@5#81.73$Text based Person Retrieval#CUHK-PEDES#mAP#60.08
2105.11628v1.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#63.63$Text based Person Retrieval#CUHK-PEDES#R@10#89.01$Text based Person Retrieval#CUHK-PEDES#R@5#82.82
2101.08238v3.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#61.9$Text based Person Retrieval#CUHK-PEDES#R@10#85.75$Text based Person Retrieval#CUHK-PEDES#R@5#79.4$Text based Person Retrieval#CUHK-PEDES#mAP#57.38
2107.12666v2.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#61.37$Text based Person Retrieval#CUHK-PEDES#R@10#86.73$Text based Person Retrieval#CUHK-PEDES#R@5#80.15$Text based Person Retrieval#ICFG-PEDES#Rank-1#54.23
2101.03036v1.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#59.94$Text based Person Retrieval#CUHK-PEDES#R@10#86.7$Text based Person Retrieval#CUHK-PEDES#R@5#79.86
2005.07327v2.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#55.97$Text based Person Retrieval#CUHK-PEDES#R@10#83.52$Text based Person Retrieval#CUHK-PEDES#R@5#75.84
1906.09610v1.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#53.10$Text based Person Retrieval#CUHK-PEDES#R@10#82.90$Text based Person Retrieval#CUHK-PEDES#R@5#75.00
1808.01571v1.pdf	Text based Person Retrieval#CUHK-PEDES#R@1#43.58$Text based Person Retrieval#CUHK-PEDES#R@10#76.26$Text based Person Retrieval#CUHK-PEDES#R@5#66.93
2007.02662v2.pdf	Multi-object colocalization#VOC12#Detection Rate#51.5$Multi-object colocalization#VOC_all#Detection Rate#49.4$Single-object discovery#VOC_6x2#CorLoc#72.5$Single-object discovery#Object Discovery#CorLoc#89.2$Single-object discovery#VOC12#CorLoc#51.9$Single-object discovery#VOC12#CorLoc#51.2$Single-object discovery#COCO_20k#CorLoc#53.0$Single-object discovery#COCO_20k#CorLoc#48.5$Single-object discovery#VOC_all#CorLoc#49.4$Single-object discovery#VOC_all#CorLoc#49.3$Multi-object discovery#COCO_20k#Detection Rate#12.0$Multi-object discovery#VOC12#Detection Rate#41.2$Multi-object discovery#VOC12#Detection Rate#40.4$Multi-object discovery#VOC_all#Detection Rate#38.3$Multi-object discovery#VOC_all#Detection Rate#37.6
1904.03148v1.pdf	Single-object discovery#VOC_6x2#CorLoc#60.2$Single-object discovery#Object Discovery#CorLoc#83$Single-object discovery#VOC_all#CorLoc#39.8
2210.07920v2.pdf	Single-object discovery#COCO_20k#CorLoc#71.9$Single-object discovery#COCO_20k#CorLoc#66.6
1707.06397v1.pdf	Single-object discovery#COCO_20k#CorLoc#38.2
1902.06421v4.pdf	Website Fingerprinting Attacks#Website Traffic Data on Tor#Accuracy (%)#98.40
1911.03911v2.pdf	Semantic Retrieval#Contract Discovery#Soft-F1#0.84$Semantic Retrieval#Contract Discovery#Soft-F1#0.51$Semantic Retrieval#Contract Discovery#Soft-F1#0.39$Semantic Retrieval#Contract Discovery#Soft-F1#0.38$Semantic Retrieval#Contract Discovery#Soft-F1#0.31
2010.14464v1.pdf	Semantic Retrieval#Contract Discovery#Soft-F1#0.51
2011.05440v1.pdf	Traffic Accident Detection#custom#Average F1#48%
2106.10197v2.pdf	Accident Anticipation#CCD#TTA#4.87$Accident Anticipation#CCD#AP#99.6
2008.00334v1.pdf	Accident Anticipation#CCD#TTA#4.74$Accident Anticipation#CCD#AP#99.5
2010.03790v1.pdf	Commonsense Reasoning for RL#commonsense-rl#Avg #Steps#15.00 ± 3.29$Commonsense Reasoning for RL#commonsense-rl#Avg #Steps#15.00 ± 2.00$Commonsense Reasoning for RL#commonsense-rl#Avg #Steps#43.27 ± 0.70$Commonsense Reasoning for RL#commonsense-rl#Avg #Steps#49.21 ± 0.58$Commonsense Reasoning for RL#commonsense-rl#Avg #Steps#49.36 ± 7.50
2005.09112v4.pdf	Unsupervised Pre-training#Measles#Accuracy (%)#73
2103.04628v1.pdf	Personalized Federated Learning#Omniglot#ACC@1-50Clients#81.89$Personalized Federated Learning#Omniglot#ACC@1-50Clients#72.03$Personalized Federated Learning#CIFAR-10#ACC@1-10Clients#92.47$Personalized Federated Learning#CIFAR-10#ACC@1-50Clients#90.08$Personalized Federated Learning#CIFAR-10#ACC@1-100Clients#88.09$Personalized Federated Learning#CIFAR-10#ACC@1-500#83.2$Personalized Federated Learning#CIFAR-10#ACC@1-10Clients#90.83$Personalized Federated Learning#CIFAR-10#ACC@1-50Clients#88.38$Personalized Federated Learning#CIFAR-10#ACC@1-100Clients#87.97$Personalized Federated Learning#CIFAR-100#ACC@1-10Clients#68.15$Personalized Federated Learning#CIFAR-100#ACC@1-50Clients#60.17$Personalized Federated Learning#CIFAR-100#ACC@1-100Clients#52.40$Personalized Federated Learning#CIFAR-100#ACC@1-500#34.1$Personalized Federated Learning#CIFAR-100#ACC@1-10Clients#65.74$Personalized Federated Learning#CIFAR-100#ACC@1-50Clients#59.46$Personalized Federated Learning#CIFAR-100#ACC@1-100Clients#53.24
2106.15482v2.pdf	Personalized Federated Learning#CIFAR-10#ACC@1-50Clients#88.6$Personalized Federated Learning#CIFAR-10#ACC@1-100Clients#87.4$Personalized Federated Learning#CIFAR-10#ACC@1-500#86.9$Personalized Federated Learning#CIFAR-10#ACC@1-50Clients#89.2$Personalized Federated Learning#CIFAR-10#ACC@1-100Clients#88.8$Personalized Federated Learning#CIFAR-10#ACC@1-500#87.6$Personalized Federated Learning#CIFAR-10#ACC@1-50Clients#89.9$Personalized Federated Learning#CIFAR-10#ACC@1-500#86.8$Personalized Federated Learning#CIFAR-100#ACC@1-50Clients#60.2$Personalized Federated Learning#CIFAR-100#ACC@1-100Clients#58.5$Personalized Federated Learning#CIFAR-100#ACC@1-500#55.7$Personalized Federated Learning#CIFAR-100#ACC@1-50Clients#63.3$Personalized Federated Learning#CIFAR-100#ACC@1-100Clients#61.3$Personalized Federated Learning#CIFAR-100#ACC@1-500#50.6$Personalized Federated Learning#CIFAR-100#ACC@1-50Clients#61.2$Personalized Federated Learning#CIFAR-100#ACC@1-100Clients#59.8$Personalized Federated Learning#CIFAR-100#ACC@1-500#49.2
2110.15718v3.pdf	Ensemble Learning#SMS Spam Collection Data Set#Accuracy#0.9838$Spam detection#SMS Spam Collection Data Set#Accuracy (%)#98.39
2009.13166v1.pdf	Dialogue Rewriting#Rewrite#ROUGE-L#93.5$Dialogue Rewriting#Multi-Rewrite#Rewriting F3#47.7
2008.01474v3.pdf	Dialogue Rewriting#Multi-Rewrite#Rewriting F3#46.4$Dialogue Rewriting#Multi-Rewrite#Rewriting F2#52.5$Dialogue Rewriting#Multi-Rewrite#BLEU-1#92.2$Dialogue Rewriting#Multi-Rewrite#BLEU-2#89.6$Dialogue Rewriting#Multi-Rewrite#ROUGE-1#92.1$Dialogue Rewriting#Multi-Rewrite#ROUGE-2#86.0$Dialogue Rewriting#Multi-Rewrite#Rewriting F1#62.4$Dialogue Rewriting#CANARD#BLEU#54.80
2010.08641v2.pdf	Sleep spindles detection#DREAMS sleep spindles#MCC#0.455
2104.05745v1.pdf	Misinformation#NLP4IF-2021--Fighting the COVID-19 Infodemic#Average F1#89.7
2110.10546v1.pdf	Reflection Removal#SIR^2(Objects)#PSNR#24.87$Reflection Removal#SIR^2(Objects)#SSIM#0.896$Reflection Removal#Nature#PSNR#23.85$Reflection Removal#Nature#SSIM#0.810$Reflection Removal#SIR^2(Wild)#PSNR#25.48$Reflection Removal#SIR^2(Wild)#SSIM#0.89$Reflection Removal#Real20#PSNR#23.26$Reflection Removal#Real20#SSIM#0.806$Reflection Removal#SIR^2(Postcard)#PSNR#22.91$Reflection Removal#SIR^2(Postcard)#SSIM#0.884
1904.00637v1.pdf	Reflection Removal#SIR^2(Objects)#PSNR#24.87$Reflection Removal#SIR^2(Objects)#SSIM#0.896$Reflection Removal#SIR^2(Wild)#PSNR#24.25$Reflection Removal#SIR^2(Wild)#SSIM#0.853$Reflection Removal#Real20#PSNR#22.89$Reflection Removal#Real20#SSIM#0.803$Reflection Removal#SIR^2(Postcard)#PSNR#22.04$Reflection Removal#SIR^2(Postcard)#SSIM#0.876
1911.06634v2.pdf	Reflection Removal#SIR^2(Objects)#PSNR#24.87$Reflection Removal#SIR^2(Objects)#SSIM#0.893$Reflection Removal#Nature#PSNR#23.57$Reflection Removal#Nature#SSIM#0.783$Reflection Removal#SIR^2(Wild)#PSNR#24.71$Reflection Removal#SIR^2(Wild)#SSIM#0.886$Reflection Removal#Real20#PSNR#21.86$Reflection Removal#Real20#SSIM#0.762$Reflection Removal#SIR^2(Postcard)#PSNR#23.39$Reflection Removal#SIR^2(Postcard)#SSIM#0.875
2006.00556v1.pdf	Next-basket recommendation#Instacart#Recall@10#0.3952$Next-basket recommendation#Instacart#nDCG@10#0.3825$Next-basket recommendation#TaFeng#Recall@10#0.1301$Next-basket recommendation#TaFeng#nDCG@10#0.1011
1607.08807v1.pdf	Food recommendation#Oktoberfest Food Dataset#10 fold Cross validation#90
2110.01200v1.pdf	Voice Anti-spoofing#ASVspoof 2019 - LA#EER#0.83%$Voice Anti-spoofing#ASVspoof 2019 - LA#min t-dcf#0.0275
2109.02774v1.pdf	Voice Anti-spoofing#ASVspoof2019#EER#1.54
2210.14441v2.pdf	Model extraction#UML Classes With Specs#Exact Match#0.171
1703.05908v2.pdf	Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (1-shot)#56.1$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (2-shots)#60.3$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (5-shots)#64.1$Generalized Few-Shot Learning#AwA2#Per-Class Accuracy (10-shots)#67.8$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (1-shot)#27.4$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (2-shots)#33.4$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (5-shots)#37.4$Generalized Few-Shot Learning#SUN#Per-Class Accuracy (10-shots)#40.8$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (1-shot)#36.3$Generalized Few-Shot Learning#CUB#Per-Class Accuracy  (2-shots)#41.1$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (5-shots)#44.6$Generalized Few-Shot Learning#CUB#Per-Class Accuracy (10-shots)#50.9
1902.09707v6.pdf	Video Enhancement#MFQE v2#Incremental PSNR#0.56$Video Enhancement#MFQE v2#Parameters(M)#0.25
1803.04680v4.pdf	Video Enhancement#MFQE v2#Incremental PSNR#0.46$Video Enhancement#MFQE v2#Parameters(M)#1.79
2011.01787v1.pdf	Intubation Support Prediction#COVID chest X-ray#AUC-ROC#0.84
2005.13837v5.pdf	Question Generation#Natural Questions#QAE#37.18$Question Generation#Natural Questions#R-QAE#29.39$Question Generation#Natural Questions#QAE#31.45$Question Generation#Natural Questions#R-QAE#32.78$Question Generation#TriviaQA#QAE#35.45$Question Generation#TriviaQA#R-QAE#21.65$Question Generation#TriviaQA#QAE#30.2$Question Generation#TriviaQA#R-QAE#34.41$Question Generation#SQuAD#QAE#71.18$Question Generation#SQuAD#R-QAE#38.8$Question Generation#SQuAD#QAE#69.46$Question Generation#SQuAD#R-QAE#37.57
1902.11049v2.pdf	Question Generation#SQuAD1.1#BLEU-4#13.5
1704.01792v3.pdf	Question Generation#SQuAD1.1#BLEU-4#13.27
1808.03986v2.pdf	Question Generation#COCO Visual Question Answering (VQA) real images 1.0 open ended#BLEU-1#65.1$Question Generation#Visual Question Generation#BLEU-1#36.0
1512.03460v1.pdf	Question Generation#COCO Visual Question Answering (VQA) real images 1.0 open ended#BLEU-1#59.4$Question Generation#COCO Visual Question Answering (VQA) real images 1.0 open ended#BLEU-1#38.8
2105.10861v1.pdf	Discourse Parsing#RST-DT#RST-Parseval (Span)#87.6$Discourse Parsing#RST-DT#RST-Parseval (Nuclearity)#76.0$Discourse Parsing#RST-DT#RST-Parseval (Relation)#61.8$Discourse Parsing#RST-DT#Standard Parseval (Span)#74.3$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#64.3$Discourse Parsing#RST-DT#Standard Parseval (Relation)#51.6$Discourse Parsing#RST-DT#Standard Parseval (Full)#50.2$Discourse Parsing#RST-DT#Standard Parseval (Span)#71.1$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#59.6$Discourse Parsing#RST-DT#Standard Parseval (Relation)#47.7$Discourse Parsing#RST-DT#Standard Parseval (Full)#46.8
2210.08355v2.pdf	Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#68.0$Discourse Parsing#RST-DT#Standard Parseval (Relation)#57.3$Discourse Parsing#RST-DT#Standard Parseval (Full)#55.4$Discourse Parsing#RST-DT#Standard Parseval (Span)#78.5$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#67.9$Discourse Parsing#RST-DT#Standard Parseval (Relation)#56.6$Discourse Parsing#RST-DT#Standard Parseval (Full)#54.4$Discourse Parsing#RST-DT#Standard Parseval (Span)#77.8$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#67.4$Discourse Parsing#RST-DT#Standard Parseval (Relation)#57.0$Discourse Parsing#RST-DT#Standard Parseval (Full)#54.8$Discourse Parsing#RST-DT#Standard Parseval (Span)#77.3$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#66.6$Discourse Parsing#RST-DT#Standard Parseval (Relation)#55.8$Discourse Parsing#RST-DT#Standard Parseval (Full)#53.8$Discourse Parsing#RST-DT#Standard Parseval (Span)#76.1$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#66.5$Discourse Parsing#RST-DT#Standard Parseval (Relation)#55.4$Discourse Parsing#RST-DT#Standard Parseval (Full)#53.7$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#65.9$Discourse Parsing#RST-DT#Standard Parseval (Relation)#56.3$Discourse Parsing#RST-DT#Standard Parseval (Full)#54.2$Discourse Parsing#RST-DT#Standard Parseval (Span)#76.5$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#65.4$Discourse Parsing#RST-DT#Standard Parseval (Relation)#54.5$Discourse Parsing#RST-DT#Standard Parseval (Full)#52.2$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#65.3$Discourse Parsing#RST-DT#Standard Parseval (Relation)#54.9$Discourse Parsing#RST-DT#Standard Parseval (Full)#52.7$Discourse Parsing#RST-DT#Standard Parseval (Span)#69.8$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#59.1$Discourse Parsing#RST-DT#Standard Parseval (Relation)#48.3$Discourse Parsing#RST-DT#Standard Parseval (Full)#46.6$Discourse Parsing#RST-DT#Standard Parseval (Span)#68.3$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#57.8$Discourse Parsing#RST-DT#Standard Parseval (Relation)#47.8$Discourse Parsing#RST-DT#Standard Parseval (Full)#46.0$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#77.8$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#60.0$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#51.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#44.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#77.3$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#57.9$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#50.0$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#43.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#73.6$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#56.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#47.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#40.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#75.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#56.1$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#48.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#41.5$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#73.2$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#55.5$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#47.9$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#41.4$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#74.3$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#55.2$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#47.0$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#40.2$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#73.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#54.5$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#42.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#36.7$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#72.9$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#53.8$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#46.0$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#40.5$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#66.6$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#46.3$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#39.5$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#32.9$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#65.3$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#44.6$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Relation)#37.6$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Full)#30.9
2102.02080v2.pdf	Discourse Parsing#RST-DT#Standard Parseval (Span)#73.1$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#62.3$Discourse Parsing#RST-DT#Standard Parseval (Relation)#51.5$Discourse Parsing#RST-DT#Standard Parseval (Full)#50.3$Discourse Parsing#RST-DT#Standard Parseval (Span)#72.7$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#61.7$Discourse Parsing#RST-DT#Standard Parseval (Relation)#50.5$Discourse Parsing#RST-DT#Standard Parseval (Full)#49.4$Discourse Parsing#RST-DT#Standard Parseval (Span)#70.2$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#60.1$Discourse Parsing#RST-DT#Standard Parseval (Full)#49.2$Discourse Parsing#RST-DT#Standard Parseval (Span)#70.6$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#59.9$Discourse Parsing#RST-DT#Standard Parseval (Relation)#50.6$Discourse Parsing#RST-DT#Standard Parseval (Full)#49.0
2011.03203v1.pdf	Discourse Parsing#RST-DT#Standard Parseval (Span)#72.94$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#61.86$Discourse Parsing#RST-DT#Standard Parseval (Span)#72.43$Discourse Parsing#RST-DT#Standard Parseval (Nuclearity)#61.38$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#65.41$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#46.59$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Span)#64.55$Discourse Parsing#Instructional-DT (Instr-DT)#Standard Parseval (Nuclearity)#44.41
1701.02946v1.pdf	Discourse Parsing#RST-DT#RST-Parseval (Span)#81.3*$Discourse Parsing#RST-DT#RST-Parseval (Nuclearity)#68.1*$Discourse Parsing#RST-DT#RST-Parseval (Relation)#56.3*$Discourse Parsing#RST-DT#RST-Parseval (Full)#56.0*
1707.02131v2.pdf	Handwriting Verification#CEDAR Signature#FAR#4.63
2009.04532v3.pdf	Handwriting Verification#CEDAR Signature#FAR#5.7$Handwriting Verification#AND Dataset#Average F1#0.81
2108.11515v1.pdf	Video Matting#ImageNet#Alpha - MAD#6.08$Video Matting#ImageNet#Alpha - MSE#1.47$Video Matting#ImageNet#Alpha - Grad#0.88$Video Matting#ImageNet#Alpha - Conn#0.41$Video Matting#ImageNet#Alpha - dtSSD#1.36$Video Matting#ImageNet#Alpha - MAD#9.41$Video Matting#ImageNet#Alpha - MSE#4.30$Video Matting#ImageNet#Alpha - Grad#1.89$Video Matting#ImageNet#Alpha - Conn#0.81$Video Matting#ImageNet#Alpha - dtSSD#2.23
2104.01785v2.pdf	Column Type Annotation#VizNet-Sato-MultiColumn#Macro-F1#83.8$Column Type Annotation#VizNet-Sato-Full#Macro-F1#84.6$Column Type Annotation#WikiTables-TURL-CTA#F1 (%)#92.45$Columns Property Annotation#WikiTables-TURL-CPA#F1 (%)#91.72
1911.06311v3.pdf	Column Type Annotation#VizNet-Sato-MultiColumn#Weighted-F1#92.5$Column Type Annotation#VizNet-Sato-MultiColumn#Macro-F1#73.5$Column Type Annotation#VizNet-Sato-Full#Macro-F1#75.6$Column Type Annotation#VizNet-Sato-Full#Weighted-F1#90.2
2105.02584v1.pdf	Column Type Annotation#VizNet-Sato-Full#Weighted-F1#97.2
1906.00781v1.pdf	Column Type Annotation#T2Dv2#Accuracy (%)#96.6$Column Type Annotation#WikipediaGS-CTA#Accuracy (%)#65.5
2006.14806v2.pdf	Column Type Annotation#T2Dv2#Accuracy (%)#96.2$Column Type Annotation#WikiTables-TURL-CTA#F1 (%)#94.75$Column Type Annotation#WikipediaGS-CTA#Accuracy (%)#74.6$Cell Entity Annotation#WikiTables-TURL-CEA#F1 (%)#68$Cell Entity Annotation#WikipediaGS#F1 (%)#67$Columns Property Annotation#WikiTables-TURL-CPA#F1 (%)#94.91
1811.01304v2.pdf	Column Type Annotation#T2Dv2#F1 (%)#94.9
1910.09796v4.pdf	Fact Verification#FEVER#Accuracy#74.1$Fact Verification#FEVER#FEVER#70.4
1908.01843v1.pdf	Fact Verification#FEVER#Accuracy#71.6$Fact Verification#FEVER#FEVER#67.1
2110.00976v3.pdf	Natural Language Understanding#LexGLUE#ECtHR Task A#71.4 / 64.0$Natural Language Understanding#LexGLUE#ECtHR Task B#87.6 / 77.8$Natural Language Understanding#LexGLUE#SCOTUS#70.5 / 60.9$Natural Language Understanding#LexGLUE#EUR-LEX#71.6 / 55.6$Natural Language Understanding#LexGLUE#LEDGAR#87.7 / 82.2$Natural Language Understanding#LexGLUE#UNFAIR-ToS#87.5 / 81.0$Natural Language Understanding#LexGLUE#CaseHOLD#70.7$Natural Language Understanding#LexGLUE#ECtHR Task A#71.2 / 64.6$Natural Language Understanding#LexGLUE#ECtHR Task B#88.0 / 77.2$Natural Language Understanding#LexGLUE#SCOTUS#76.2 / 65.8$Natural Language Understanding#LexGLUE#EUR-LEX#72.2 / 56.2$Natural Language Understanding#LexGLUE#LEDGAR#88.1 / 82.7$Natural Language Understanding#LexGLUE#UNFAIR-ToS#88.6 / 82.3$Natural Language Understanding#LexGLUE#CaseHOLD#75.1$Natural Language Understanding#LexGLUE#ECtHR Task A#71.2 / 64.2$Natural Language Understanding#LexGLUE#ECtHR Task B#88.0 / 77.5$Natural Language Understanding#LexGLUE#SCOTUS#76.4 / 66.2$Natural Language Understanding#LexGLUE#EUR-LEX#71.0 / 55.9$Natural Language Understanding#LexGLUE#LEDGAR#88.0 / 82.3$Natural Language Understanding#LexGLUE#UNFAIR-ToS#88.3 / 81.0$Natural Language Understanding#LexGLUE#CaseHOLD#75.6$Natural Language Understanding#LexGLUE#ECtHR Task A#70.5 / 63.8$Natural Language Understanding#LexGLUE#ECtHR Task B#88.1 / 76.6$Natural Language Understanding#LexGLUE#SCOTUS#71.7 / 61.4$Natural Language Understanding#LexGLUE#EUR-LEX#71.8 / 56.6$Natural Language Understanding#LexGLUE#LEDGAR#87.7 / 82.1$Natural Language Understanding#LexGLUE#UNFAIR-ToS#87.7 / 80.2$Natural Language Understanding#LexGLUE#CaseHOLD#70.4$Natural Language Understanding#LexGLUE#ECtHR Task A#69.6 / 62.4$Natural Language Understanding#LexGLUE#ECtHR Task B#88.0 / 77.8$Natural Language Understanding#LexGLUE#SCOTUS#72.2 / 62.5$Natural Language Understanding#LexGLUE#EUR-LEX#71.9 / 56.7$Natural Language Understanding#LexGLUE#LEDGAR#87.7 / 82.3$Natural Language Understanding#LexGLUE#UNFAIR-ToS#87.7 / 80.1$Natural Language Understanding#LexGLUE#CaseHOLD#72.0$Natural Language Understanding#LexGLUE#ECtHR Task A#69.5 / 60.7$Natural Language Understanding#LexGLUE#ECtHR Task B#87.2 / 77.3$Natural Language Understanding#LexGLUE#SCOTUS#70.8 / 61.2$Natural Language Understanding#LexGLUE#EUR-LEX#71.8 / 57.5$Natural Language Understanding#LexGLUE#LEDGAR#87.9 / 82.1$Natural Language Understanding#LexGLUE#UNFAIR-ToS#87.7 / 81.5$Natural Language Understanding#LexGLUE#CaseHOLD#71.7$Natural Language Understanding#LexGLUE#ECtHR Task A#69.1 / 61.2$Natural Language Understanding#LexGLUE#ECtHR Task B#87.4 / 77.3$Natural Language Understanding#LexGLUE#SCOTUS#70.0 / 60.0$Natural Language Understanding#LexGLUE#EUR-LEX#72.3 / 57.2$Natural Language Understanding#LexGLUE#LEDGAR#87.9 / 82.0$Natural Language Understanding#LexGLUE#UNFAIR-ToS#87.2 / 78.8$Natural Language Understanding#LexGLUE#CaseHOLD#72.1
2109.07234v2.pdf	Natural Language Understanding#LexGLUE#ECtHR Task A#66.3 / 55.0$Natural Language Understanding#LexGLUE#ECtHR Task B#76.0 / 65.4$Natural Language Understanding#LexGLUE#SCOTUS#74.4 / 64.5$Natural Language Understanding#LexGLUE#EUR-LEX#65.7 / 49.0$Natural Language Understanding#LexGLUE#LEDGAR#88.0 / 82.6
2104.10674v1.pdf	Vision and Language Navigation#robo-vln#SPL (Sucess Weighted by Path Length)#0.40
2108.09105v1.pdf	Vision and Language Navigation#VLN Challenge#success#0.78$Vision and Language Navigation#VLN Challenge#length#686.54$Vision and Language Navigation#VLN Challenge#error#2.58$Vision and Language Navigation#VLN Challenge#oracle success#0.99$Vision and Language Navigation#VLN Challenge#spl#0.01
2004.14973v2.pdf	Vision and Language Navigation#VLN Challenge#success#0.73$Vision and Language Navigation#VLN Challenge#length#686.62$Vision and Language Navigation#VLN Challenge#error#3.09$Vision and Language Navigation#VLN Challenge#oracle success#0.99$Vision and Language Navigation#VLN Challenge#spl#0.01
1911.07883v4.pdf	Vision and Language Navigation#VLN Challenge#success#0.71$Vision and Language Navigation#VLN Challenge#length#40.85$Vision and Language Navigation#VLN Challenge#error#3.24$Vision and Language Navigation#VLN Challenge#oracle success#0.81$Vision and Language Navigation#VLN Challenge#spl#0.21$Vision and Language Navigation#VLN Challenge#success#0.68$Vision and Language Navigation#VLN Challenge#length#10.43$Vision and Language Navigation#VLN Challenge#error#3.69$Vision and Language Navigation#VLN Challenge#oracle success#0.75$Vision and Language Navigation#VLN Challenge#spl#0.65
2106.07876v3.pdf	Vision and Language Navigation#VLN Challenge#success#0.65$Vision and Language Navigation#VLN Challenge#length#13.11$Vision and Language Navigation#VLN Challenge#error#3.87$Vision and Language Navigation#VLN Challenge#oracle success#0.72$Vision and Language Navigation#VLN Challenge#spl#0.59
2107.07201v3.pdf	Vision and Language Navigation#VLN Challenge#success#0.58$Vision and Language Navigation#VLN Challenge#length#12.98$Vision and Language Navigation#VLN Challenge#error#4.37$Vision and Language Navigation#VLN Challenge#oracle success#0.66$Vision and Language Navigation#VLN Challenge#spl#0.54
1901.03035v1.pdf	Vision and Language Navigation#VLN Challenge#success#0.48$Vision and Language Navigation#VLN Challenge#length#18.04$Vision and Language Navigation#VLN Challenge#error#5.67$Vision and Language Navigation#VLN Challenge#oracle success#0.59$Vision and Language Navigation#VLN Challenge#spl#0.35
1903.01602v1.pdf	Vision and Language Navigation#VLN Challenge#success#0.48$Vision and Language Navigation#VLN Challenge#length#13.69$Vision and Language Navigation#VLN Challenge#error#5.69$Vision and Language Navigation#VLN Challenge#oracle success#0.56$Vision and Language Navigation#VLN Challenge#spl#0.4
1908.03409v2.pdf	Vision and Language Navigation#VLN Challenge#success#0.48$Vision and Language Navigation#VLN Challenge#length#10.27$Vision and Language Navigation#VLN Challenge#error#5.49$Vision and Language Navigation#VLN Challenge#oracle success#0.56$Vision and Language Navigation#VLN Challenge#spl#0.45
2203.13838v1.pdf	Vision and Language Navigation#map2seq#Task Completion (TC)#46.7$Vision and Language Navigation#map2seq#Task Completion (TC)#45.1$Vision and Language Navigation#map2seq#Task Completion (TC)#17$Vision and Language Navigation#map2seq#Task Completion (TC)#14.7$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#29.1$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#24.2
2009.13112v3.pdf	Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#16.68$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#14.13
2007.00229v3.pdf	Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#16.2$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#14.9$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#11.9$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#11.8
2001.03671v1.pdf	Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#12.8
1811.12354v7.pdf	Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#10.7$Vision and Language Navigation#Touchdown Dataset#Task Completion (TC)#5.5
2103.05368v2.pdf	Scene Change Detection#ChangeSim#Category mIoU#26.1$Scene Change Detection#ChangeSim#macro F1#30.6$Scene Change Detection#ChangeSim#Category mIoU#23.0$Scene Change Detection#ChangeSim#macro F1#29.8
2104.10538v1.pdf	Table Recognition#ICDAR2013 table structure recognition#F-Measure#95.46
2105.01848v1.pdf	Table Recognition#PubTabNet#TEDS (all samples)#96.76
2210.05391v2.pdf	Table Recognition#PubTabNet#TEDS (all samples)#96.31$Table Recognition#PubTabNet#TEDS-Struct#97.01
2208.14687v1.pdf	Table Recognition#PubTabNet#TEDS (all samples)#96.2$Table Recognition#PubTabNet#TEDS-Struct#97.1
2111.13359v2.pdf	Table Recognition#PubTabNet#TEDS (all samples)#95.4
2105.06224v3.pdf	Table Recognition#PubTabNet#TEDS (all samples)#94.6$Table Recognition#PubTabNet#TEDS-Struct#96.7
2107.05214v3.pdf	Table Recognition#PubTabNet#TEDS (all samples)#93.7
2010.04565v1.pdf	Table Recognition#PubTabNet#TEDS (all samples)#90.1$Table Recognition#PubTabNet#TEDS-Struct#90.1
1911.10683v5.pdf	Table Recognition#PubTabNet#TEDS (all samples)#88.3
2208.04921v1.pdf	Table Recognition#PubTabNet#TEDS-Struct#97.5
2203.09056v2.pdf	Table Recognition#PubTabNet#TEDS-Struct#97
2112.07194v2.pdf	Dialogue Evaluation#USR-TopicalChat#Spearman Correlation#0.5109$Dialogue Evaluation#USR-TopicalChat#Pearson Correlation#0.4575
2005.00456v1.pdf	Dialogue Evaluation#USR-TopicalChat#Spearman Correlation#0.4192$Dialogue Evaluation#USR-TopicalChat#Pearson Correlation#0.4220$Dialogue Evaluation#USR-TopicalChat#Spearman Correlation#0.3245$Dialogue Evaluation#USR-TopicalChat#Pearson Correlation#0.4068$Dialogue Evaluation#USR-TopicalChat#Spearman Correlation#0.3086$Dialogue Evaluation#USR-TopicalChat#Pearson Correlation#0.3345$Dialogue Evaluation#USR-TopicalChat#Spearman Correlation#0.1419$Dialogue Evaluation#USR-TopicalChat#Pearson Correlation#0.3221$Dialogue Evaluation#USR-PersonaChat#Spearman Correlation#0.4814$Dialogue Evaluation#USR-PersonaChat#Pearson Correlation#0.6087$Dialogue Evaluation#USR-PersonaChat#Spearman Correlation#0.4693$Dialogue Evaluation#USR-PersonaChat#Pearson Correlation#0.4115$Dialogue Evaluation#USR-PersonaChat#Spearman Correlation#0.0795$Dialogue Evaluation#USR-PersonaChat#Pearson Correlation#0.0788$Dialogue Evaluation#USR-PersonaChat#Spearman Correlation#-0.0495$Dialogue Evaluation#USR-PersonaChat#Pearson Correlation#-0.0454
1712.00032v2.pdf	LIDAR Semantic Segmentation#Paris-Lille-3D#mIOU#0.31
2106.15277v2.pdf	LIDAR Semantic Segmentation#nuScenes#mIOU#0.77
2206.02099v1.pdf	LIDAR Semantic Segmentation#nuScenes#mIOU#0.76
1910.10202v2.pdf	Music Transcription#MusicNet#APS#74.22$Music Transcription#MusicNet#Number of params#11.61M$Music Transcription#MusicNet#APS#71.3$Music Transcription#MusicNet#Number of params#9.79M
1611.09827v2.pdf	Music Transcription#MusicNet#APS#67.8
2207.14012v1.pdf	Video Instance Segmentation#HQ-YTVIS#Tube-Boundary AP#44.8$Video Instance Segmentation#HQ-YTVIS#Tube-Boundary AP#32.5$Video Instance Segmentation#HQ-YTVIS#Tube-Boundary AP#30.7
2112.08275v2.pdf	Video Instance Segmentation#HQ-YTVIS#Tube-Boundary AP#43.3$Video Instance Segmentation#YouTube-VIS validation#mask AP#59.3$Video Instance Segmentation#YouTube-VIS validation#AP50#82.1$Video Instance Segmentation#YouTube-VIS validation#AP75#66.4$Video Instance Segmentation#YouTube-VIS validation#AR1#51.7$Video Instance Segmentation#YouTube-VIS validation#AR10#64.4$Video Instance Segmentation#YouTube-VIS validation#mask AP#49.0$Video Instance Segmentation#YouTube-VIS validation#AP50#71.1$Video Instance Segmentation#YouTube-VIS validation#AP75#55.7$Video Instance Segmentation#YouTube-VIS validation#AR1#46.8$Video Instance Segmentation#YouTube-VIS validation#AR10#56.9$Video Instance Segmentation#YouTube-VIS validation#mask AP#47.4$Video Instance Segmentation#YouTube-VIS validation#AP50#69.8$Video Instance Segmentation#YouTube-VIS validation#AP75#51.8$Video Instance Segmentation#YouTube-VIS validation#AR1#45.5$Video Instance Segmentation#YouTube-VIS validation#AR10#54.8$Video Instance Segmentation#YouTube-VIS validation#mask AP#45.1$Video Instance Segmentation#YouTube-VIS validation#AP50#66.9$Video Instance Segmentation#YouTube-VIS validation#AP75#50.5$Video Instance Segmentation#YouTube-VIS validation#AR1#45.6$Video Instance Segmentation#YouTube-VIS validation#AR10#54.6
2206.04403v2.pdf	Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#57.5$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#80.6$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#61.0$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#62.6$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#47.7$Video Instance Segmentation#YouTube-VIS validation#mask AP#63.0$Video Instance Segmentation#YouTube-VIS validation#AP50#86.9$Video Instance Segmentation#YouTube-VIS validation#AP75#67.9$Video Instance Segmentation#YouTube-VIS validation#AR1#56.3$Video Instance Segmentation#YouTube-VIS validation#AR10#68.1$Video Instance Segmentation#OVIS validation#mask AP#27.7$Video Instance Segmentation#OVIS validation#AP50#51.9$Video Instance Segmentation#OVIS validation#AP75#24.9$Video Instance Segmentation#OVIS validation#AR1#14.9$Video Instance Segmentation#OVIS validation#AR10#33.0
2207.10661v1.pdf	Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#56.1$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#80.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#63.5$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#60.1$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#45$Video Instance Segmentation#YouTube-VIS validation#mask AP#64.3$Video Instance Segmentation#YouTube-VIS validation#AP50#87.5$Video Instance Segmentation#YouTube-VIS validation#AP75#71.0$Video Instance Segmentation#YouTube-VIS validation#AR1#55.6$Video Instance Segmentation#YouTube-VIS validation#AR10#69.1$Video Instance Segmentation#YouTube-VIS validation#mask AP#49.5$Video Instance Segmentation#YouTube-VIS validation#AP50#74$Video Instance Segmentation#YouTube-VIS validation#AP75#52.9$Video Instance Segmentation#YouTube-VIS validation#AR1#47.7$Video Instance Segmentation#YouTube-VIS validation#AR10#58.7$Video Instance Segmentation#OVIS validation#mask AP#42.6$Video Instance Segmentation#OVIS validation#AP50#65.7$Video Instance Segmentation#OVIS validation#AP75#45.2$Video Instance Segmentation#OVIS validation#AR1#17.9$Video Instance Segmentation#OVIS validation#AR10#49.6$Video Instance Segmentation#OVIS validation#mask AP#30.2$Video Instance Segmentation#OVIS validation#AP50#51.3$Video Instance Segmentation#OVIS validation#AP75#30$Video Instance Segmentation#OVIS validation#AR1#15$Video Instance Segmentation#OVIS validation#AR10#37.5
2208.02245v1.pdf	Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#55.3$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#76.6$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#62$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#60.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#45.9$Video Instance Segmentation#YouTube-VIS validation#mask AP#61.6$Video Instance Segmentation#YouTube-VIS validation#AP50#83.3$Video Instance Segmentation#YouTube-VIS validation#AP75#68.6$Video Instance Segmentation#YouTube-VIS validation#AR1#54.8$Video Instance Segmentation#YouTube-VIS validation#AR10#66.6$Video Instance Segmentation#OVIS validation#mask AP#39.4$Video Instance Segmentation#OVIS validation#AP50#61.5$Video Instance Segmentation#OVIS validation#AP75#41.3$Video Instance Segmentation#OVIS validation#AR1#18.1$Video Instance Segmentation#OVIS validation#AR10#43.3
2207.11103v1.pdf	Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#54.4$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#77.7$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#59.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#57.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#43.8$Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#43.1$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#66.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#46.6$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#50.1$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#38.0$Video Instance Segmentation#YouTube-VIS validation#mask AP#57.1$Video Instance Segmentation#YouTube-VIS validation#AP50#80.8$Video Instance Segmentation#YouTube-VIS validation#AP75#66.3$Video Instance Segmentation#YouTube-VIS validation#AR1#50.8$Video Instance Segmentation#YouTube-VIS validation#AR10#61.0$Video Instance Segmentation#YouTube-VIS validation#mask AP#44.4$Video Instance Segmentation#YouTube-VIS validation#AP50#66.7$Video Instance Segmentation#YouTube-VIS validation#AP75#48.6$Video Instance Segmentation#YouTube-VIS validation#AR1#42.4$Video Instance Segmentation#YouTube-VIS validation#AR10#51.6$Video Instance Segmentation#OVIS validation#mask AP#35.5$Video Instance Segmentation#OVIS validation#AP50#59.3$Video Instance Segmentation#OVIS validation#AP75#38.3$Video Instance Segmentation#OVIS validation#AR1#16.6$Video Instance Segmentation#OVIS validation#AR10#39.8$Video Instance Segmentation#OVIS validation#mask AP#23.7$Video Instance Segmentation#OVIS validation#AP50#47.6$Video Instance Segmentation#OVIS validation#AP75#20.8$Video Instance Segmentation#OVIS validation#AR1#12.0$Video Instance Segmentation#OVIS validation#AR10#28.9
2208.10547v1.pdf	Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#51.0$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#73.7$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#56.9$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#56.0$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#42.8$Video Instance Segmentation#YouTube-VIS 2021 validation#mask AP#40.8$Video Instance Segmentation#YouTube-VIS 2021 validation#AP50#62.4$Video Instance Segmentation#YouTube-VIS 2021 validation#AP75#43.7$Video Instance Segmentation#YouTube-VIS 2021 validation#AR10#48.1$Video Instance Segmentation#YouTube-VIS 2021 validation#AR1#36.1$Video Instance Segmentation#YouTube-VIS validation#mask AP#56.3$Video Instance Segmentation#YouTube-VIS validation#AP50#78.0$Video Instance Segmentation#YouTube-VIS validation#AP75#64.2$Video Instance Segmentation#YouTube-VIS validation#AR1#50.9$Video Instance Segmentation#YouTube-VIS validation#AR10#61.6$Video Instance Segmentation#YouTube-VIS validation#mask AP#45.6$Video Instance Segmentation#YouTube-VIS validation#AP50#68.6$Video Instance Segmentation#YouTube-VIS validation#AP75#49.6$Video Instance Segmentation#YouTube-VIS validation#AR1#42.1$Video Instance Segmentation#YouTube-VIS validation#AR10#53.5$Video Instance Segmentation#Youtube-VIS 2022 Validation#mAP_L#26.3$Video Instance Segmentation#Youtube-VIS 2022 Validation#AP50_L#44.6$Video Instance Segmentation#Youtube-VIS 2022 Validation#AP75_L#27.3$Video Instance Segmentation#Youtube-VIS 2022 Validation#AR1_L#25.0$Video Instance Segmentation#Youtube-VIS 2022 Validation#AR10_L#29.2$Video Instance Segmentation#Youtube-VIS 2022 Validation#mAP_L#24.8$Video Instance Segmentation#Youtube-VIS 2022 Validation#AP50_L#49.5$Video Instance Segmentation#Youtube-VIS 2022 Validation#AP75_L#26.7$Video Instance Segmentation#Youtube-VIS 2022 Validation#AR1_L#23.9$Video Instance Segmentation#Youtube-VIS 2022 Validation#AR10_L#30.1$Video Instance Segmentation#OVIS validation#mask AP#22.8$Video Instance Segmentation#OVIS validation#AP50#42.5$Video Instance Segmentation#OVIS validation#AP75#21.61$Video Instance Segmentation#OVIS validation#AR1#12.9$Video Instance Segmentation#OVIS validation#AR10#29.3$Video Instance Segmentation#OVIS validation#mask AP#20.0$Video Instance Segmentation#OVIS validation#AP50#40.7$Video Instance Segmentation#OVIS validation#AP75#18.1$Video Instance Segmentation#OVIS validation#AR1#12$Video Instance Segmentation#OVIS validation#AR10#27.1
2112.10764v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#60.4$Video Instance Segmentation#YouTube-VIS validation#AP50#84.4$Video Instance Segmentation#YouTube-VIS validation#AP75#67.0$Video Instance Segmentation#YouTube-VIS validation#mask AP#49.2$Video Instance Segmentation#YouTube-VIS validation#AP50#72.8$Video Instance Segmentation#YouTube-VIS validation#AP75#54.2$Video Instance Segmentation#YouTube-VIS validation#mask AP#46.4$Video Instance Segmentation#YouTube-VIS validation#AP50#68.0$Video Instance Segmentation#YouTube-VIS validation#AP75#50.0
2106.06649v2.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#54.3$Video Instance Segmentation#YouTube-VIS validation#AP50#76.6$Video Instance Segmentation#YouTube-VIS validation#AP75#65.6$Video Instance Segmentation#YouTube-VIS validation#AR1#47$Video Instance Segmentation#YouTube-VIS validation#AR10#57.9
2106.10452v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#48.8$Video Instance Segmentation#YouTube-VIS validation#AP50#69.4$Video Instance Segmentation#YouTube-VIS validation#AP75#54.9$Video Instance Segmentation#YouTube-VIS validation#AR1#40.1$Video Instance Segmentation#YouTube-VIS validation#AR10#55.0
2106.03299v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#42.8$Video Instance Segmentation#YouTube-VIS validation#AP50#65.8$Video Instance Segmentation#YouTube-VIS validation#AP75#46.8$Video Instance Segmentation#YouTube-VIS validation#AR1#43.8$Video Instance Segmentation#YouTube-VIS validation#AR10#51.2
2011.14503v5.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#40.1$Video Instance Segmentation#YouTube-VIS validation#AP50#64.0$Video Instance Segmentation#YouTube-VIS validation#AP75#45.0$Video Instance Segmentation#YouTube-VIS validation#AR1#38.3$Video Instance Segmentation#YouTube-VIS validation#AR10#44.9$Video Instance Segmentation#YouTube-VIS validation#mask AP#36.2$Video Instance Segmentation#YouTube-VIS validation#AP50#59.8$Video Instance Segmentation#YouTube-VIS validation#AP75#36.9$Video Instance Segmentation#YouTube-VIS validation#AR1#37.2$Video Instance Segmentation#YouTube-VIS validation#AR10#42.4
2202.03747v2.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#36.7$Video Instance Segmentation#YouTube-VIS validation#AP50#57.2$Video Instance Segmentation#YouTube-VIS validation#AP75#38.6$Video Instance Segmentation#YouTube-VIS validation#AR1#36.9$Video Instance Segmentation#YouTube-VIS validation#AR10#44.5$Video Instance Segmentation#OVIS validation#mask AP#15.5$Video Instance Segmentation#OVIS validation#AP50#33.5$Video Instance Segmentation#OVIS validation#AP75#13.4
2104.05970v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#36.6$Video Instance Segmentation#YouTube-VIS validation#AP50#57.3$Video Instance Segmentation#YouTube-VIS validation#AP75#39.7$Video Instance Segmentation#YouTube-VIS validation#AR1#36$Video Instance Segmentation#YouTube-VIS validation#AR10#42$Video Instance Segmentation#OVIS validation#mask AP#18.1$Video Instance Segmentation#OVIS validation#AP50#35.5$Video Instance Segmentation#OVIS validation#AP75#16.9$Video Instance Segmentation#OVIS validation#mask AP#14.9$Video Instance Segmentation#OVIS validation#AP50#32.7$Video Instance Segmentation#OVIS validation#AP75#12.1
2111.07529v3.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#36.0$Video Instance Segmentation#YouTube-VIS validation#AP50#59.4$Video Instance Segmentation#YouTube-VIS validation#AP75#39.2$Video Instance Segmentation#YouTube-VIS validation#AR1#39.1$Video Instance Segmentation#YouTube-VIS validation#AR10#47.7
2012.03400v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#35.3$Video Instance Segmentation#YouTube-VIS validation#AP50#56.0$Video Instance Segmentation#YouTube-VIS validation#AP75#38.6$Video Instance Segmentation#YouTube-VIS validation#AR1#33.1$Video Instance Segmentation#YouTube-VIS validation#AR10#40.3
2102.01558v6.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#35.1$Video Instance Segmentation#YouTube-VIS validation#AP50#55.6$Video Instance Segmentation#YouTube-VIS validation#AP75#38.1$Video Instance Segmentation#YouTube-VIS validation#mask AP#32.1$Video Instance Segmentation#YouTube-VIS validation#AP50#52.8$Video Instance Segmentation#YouTube-VIS validation#AP75#34.9$Video Instance Segmentation#OVIS validation#mask AP#15.4$Video Instance Segmentation#OVIS validation#AP50#33.9$Video Instance Segmentation#OVIS validation#AP75#13.1$Video Instance Segmentation#OVIS validation#APso#28.6$Video Instance Segmentation#OVIS validation#APmo#18.7$Video Instance Segmentation#OVIS validation#APho#4.1$Video Instance Segmentation#OVIS validation#mask AP#14.3$Video Instance Segmentation#OVIS validation#AP50#29.9$Video Instance Segmentation#OVIS validation#AP75#12.5$Video Instance Segmentation#OVIS validation#APso#23$Video Instance Segmentation#OVIS validation#APmo#12.8$Video Instance Segmentation#OVIS validation#APho#2.7
1905.04804v4.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#30.3$Video Instance Segmentation#YouTube-VIS validation#AP50#51.1$Video Instance Segmentation#YouTube-VIS validation#AP75#32.6$Video Instance Segmentation#YouTube-VIS validation#AR1#31$Video Instance Segmentation#YouTube-VIS validation#AR10#35.5
1703.07402v1.pdf	Video Instance Segmentation#YouTube-VIS validation#mask AP#27.8$Video Instance Segmentation#YouTube-VIS validation#AP50#31.3
2204.08412v1.pdf	Video Instance Segmentation#OVIS validation#mask AP#17.4$Video Instance Segmentation#OVIS validation#AP50#34.9$Video Instance Segmentation#OVIS validation#AP75#15.0
2012.10852v1.pdf	Speech Denoising#LRS3+VGGSound#PESQ#2.72$Speech Denoising#LRS3+VGGSound#CSIG#3.18$Speech Denoising#LRS3+VGGSound#CBAK#2.47$Speech Denoising#LRS3+VGGSound#COVL#2.25$Speech Denoising#LRS3+VGGSound#STOI#0.88$Speech Denoising#LRS2+VGGSound#PESQ#2.71$Speech Denoising#LRS2+VGGSound#CSIG#3.16$Speech Denoising#LRS2+VGGSound#CBAK#2.41$Speech Denoising#LRS2+VGGSound#COVL#2.15$Speech Denoising#LRS2+VGGSound#STOI#0.87
2012.04005v1.pdf	Clinical Assertion Status Detection#2010 i2b2/VA#Micro F1#0.939
1902.08691v4.pdf	Clinical Concept Extraction#2010 i2b2/VA#Exact Span F1#90.25
2010.01150v1.pdf	Clinical Concept Extraction#2010 i2b2/VA#Exact Span F1#87.4
2012.11820v4.pdf	Recognizing Emotion Cause in Conversations#RECCON#Exact Span F1#34.64$Recognizing Emotion Cause in Conversations#RECCON#F1#75.71$Recognizing Emotion Cause in Conversations#RECCON#F1(Pos)#60.00$Recognizing Emotion Cause in Conversations#RECCON#F1(Neg)#86.02$Recognizing Emotion Cause in Conversations#RECCON#Exact Span F1#32.63$Recognizing Emotion Cause in Conversations#RECCON#F1#75.45$Recognizing Emotion Cause in Conversations#RECCON#F1(Pos)#58.17$Recognizing Emotion Cause in Conversations#RECCON#F1(Neg)#85.85$Causal Emotion Entailment#RECCON#F1#77.06$Causal Emotion Entailment#RECCON#Pos. F1#66.23$Causal Emotion Entailment#RECCON#Neg. F1#87.89$Causal Emotion Entailment#RECCON#F1#76.51$Causal Emotion Entailment#RECCON#Pos. F1#64.28$Causal Emotion Entailment#RECCON#Neg. F1#88.74
2109.08828v2.pdf	Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#41.3$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#81.1$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#95.0$Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#17.3$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#48.1$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#68.4$Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#13.8$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#40.6$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#61.2$Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#13.4$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#36.2$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#49.3$Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#12.7$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#35.8$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#55.0$Recognizing Emotion Cause in Conversations#EmoCause#Top-1 Recall#10.7$Recognizing Emotion Cause in Conversations#EmoCause#Top-3 Recall#30.6$Recognizing Emotion Cause in Conversations#EmoCause#Top-5 Recall#48.5
1908.09216v1.pdf	2D Human Pose Estimation#JHMDB (2D poses only)#PCK#94.0
2007.11858v1.pdf	2D Human Pose Estimation#COCO-WholeBody#WB#54.1$2D Human Pose Estimation#COCO-WholeBody#body#74.3$2D Human Pose Estimation#COCO-WholeBody#foot#79.8$2D Human Pose Estimation#COCO-WholeBody#face#62.3$2D Human Pose Estimation#COCO-WholeBody#hand#40.1
2104.06954v1.pdf	Infinite Image Generation#LHQ#InfinityFID#7.8
2202.06690v3.pdf	Fact Selection#ArgSciChat#Fact-F1#16.22$Fact Selection#ArgSciChat#Fact-F1#13.65$Fact Selection#ArgSciChat#Fact-F1#10.58$Fact Selection#ArgSciChat#Fact-F1#8.50$Response Generation#ArgSciChat#Message-F1#19.54$Response Generation#ArgSciChat#BScore#86.64$Response Generation#ArgSciChat#Mover#8.53$Response Generation#ArgSciChat#Message-F1#16.14$Response Generation#ArgSciChat#BScore#86.00$Response Generation#ArgSciChat#Mover#4.54$Response Generation#ArgSciChat#Message-F1#14.25$Response Generation#ArgSciChat#BScore#85.85$Response Generation#ArgSciChat#Mover#2.25
2101.02661v2.pdf	Domain Labelling#BabelDomains#F1-Score#92.14
2012.10018v3.pdf	Speech-to-Text Translation#libri-trans#Case-insensitive tokenized BLEU#18.7$Speech-to-Text Translation#libri-trans#Case-insensitive sacreBLEU#17.2$Speech-to-Text Translation#libri-trans#Case-sensitive sacreBLEU#16.3$Speech-to-Text Translation#libri-trans#Case-sensitive tokenized BLEU#17.8$Speech-to-Text Translation#libri-trans#Case-insensitive tokenized BLEU#17.9$Speech-to-Text Translation#libri-trans#Case-insensitive sacreBLEU#16.5$Speech-to-Text Translation#libri-trans#Case-sensitive sacreBLEU#15.5$Speech-to-Text Translation#libri-trans#Case-sensitive tokenized BLEU#16.9$Speech-to-Text Translation#MuST-C EN->ES#Case-sensitive sacreBLEU#27.4$Speech-to-Text Translation#MuST-C EN->ES#Case-sensitive sacreBLEU#26.8$Speech-to-Text Translation#MuST-C EN->FR#Case-sensitive sacreBLEU#33.3$Speech-to-Text Translation#MuST-C EN->FR#Case-sensitive sacreBLEU#32.3$Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#22.8
2109.04574v1.pdf	Speech-to-Text Translation#MuST-C EN->NL#Case-sensitive sacreBLEU#27.7$Speech-to-Text Translation#MuST-C EN->ES#Case-sensitive sacreBLEU#28.5$Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#23.6
2106.01463v2.pdf	Speech-to-Text Translation#MuST-C EN->ES#Case-sensitive sacreBLEU#28.73$Speech-to-Text Translation#MuST-C#SacreBLEU#26.61$Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#24.63
2011.00747v1.pdf	Speech-to-Text Translation#MuST-C EN->ES#Case-sensitive sacreBLEU#28.12$Speech-to-Text Translation#MuST-C#SacreBLEU#25.62$Speech-to-Text Translation#MuST-C EN->FR#Case-sensitive sacreBLEU#33.45$Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#23.63
2105.04512v2.pdf	Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#28.22
2010.05171v2.pdf	Speech-to-Text Translation#MuST-C EN->DE#Case-sensitive sacreBLEU#22.7
2203.11027v1.pdf	Multi-hop Question Answering#ConcurrentQA#Answer F1#56.5
2012.02515v2.pdf	Lip password classification#MIRACL-VC1#2-Class Accuracy#0.981
2112.03221v1.pdf	Neural Stylization#Meshes#Mean Opinion Score (Q1:Overall)#3.9 ± 0.37$Neural Stylization#Meshes#Mean Opinion Score (Q2: Content)#4.04 ± 0.53$Neural Stylization#Meshes#Mean Opinion Score (Q3: Style)#3.91 ± 0.51$Neural Stylization#Meshes#Mean Opinion Score (Q1:Overall)#2.83 ± 0.39$Neural Stylization#Meshes#Mean Opinion Score (Q2: Content)#3.6 ± 0.68$Neural Stylization#Meshes#Mean Opinion Score (Q3: Style)#2.59 ± 0.44
1902.00175v1.pdf	Document Dating#NYT#Accuracy#58.9$Document Dating#APW#Accuracy#64.1
2008.01972v2.pdf	Weakly Supervised Classification#THYME-2016#F1#72.9$Weakly Supervised Classification#ShARe/CLEF 2014: Task 2 Disorders#F1#92.7
2206.09500v1.pdf	Semi-Supervised Object Detection#COCO 0.5% labeled data#mAP#21.26 ± 0.21$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#31.85±0.09$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#28.37±0.03$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#26.07±0.36$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#35.08±0.02
2107.05031v1.pdf	Semi-Supervised Object Detection#COCO 0.5% labeled data#mAP#19.62±0.37$Semi-Supervised Object Detection#COCO 100% labeled data#mAP#42.79$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#31.35±0.13$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#28.69±0.17$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#26.07±0.46$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#34.92±0.22
2111.10958v2.pdf	Semi-Supervised Object Detection#COCO 0.5% labeled data#mAP#18.54$Semi-Supervised Object Detection#COCO 100% labeled data#mAP#42.11$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#28.52$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#24.84$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#21.88$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#31.87
2102.09480v1.pdf	Semi-Supervised Object Detection#COCO 0.5% labeled data#mAP#16.94± 0.23$Semi-Supervised Object Detection#COCO 100% labeled data#mAP#41.3$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#28.27± 0.11$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#24.324.30 ± 0.07$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#20.75± 0.12$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#31.5± 0.10
2209.01589v2.pdf	Semi-Supervised Object Detection#COCO 100% labeled data#mAP#47.20$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#36.1$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#30.4$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#25.3$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#40.0
2203.16317v2.pdf	Semi-Supervised Object Detection#COCO 100% labeled data#mAP#46.1$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#32.5$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#27.77$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#22.43$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#36.06
2106.00168v2.pdf	Semi-Supervised Object Detection#COCO 100% labeled data#mAP#43.3$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#28.4 ± 0.15$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#23.34± 0.18$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#19.02 ± 0.25$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#32.23± 0.14
2103.11402v1.pdf	Semi-Supervised Object Detection#COCO 100% labeled data#mAP#40.2$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#26.75$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#22.45$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#18.05$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#30.40
2005.04757v2.pdf	Semi-Supervised Object Detection#COCO 100% labeled data#mAP#39.2$Semi-Supervised Object Detection#COCO 5% labeled data#mAP#24.38±0.12$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#18.25±0.25$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#13.97±0.35$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#28.64±0.21
2203.16089v1.pdf	Semi-Supervised Object Detection#COCO 5% labeled data#mAP#30.2$Semi-Supervised Object Detection#COCO 2% labeled data#mAP#23.2$Semi-Supervised Object Detection#COCO 1% labeled data#mAP#18.6$Semi-Supervised Object Detection#COCO 10% labeled data#mAP#34.1
2206.10186v1.pdf	Semi-Supervised Object Detection#COCO 10% labeled data#mAP#32.166
2106.10456v1.pdf	Semi-Supervised Object Detection#COCO 10% labeled data#mAP#31.61
1905.05700v1.pdf	Poem meters classification#PCD#Accuracy#96.38
2107.04721v1.pdf	Optic Disc Detection#IDRiD#Euclidean Distance (ED)#20.5$Fovea Detection#REFUGE#Euclidean Distance (ED)#32.5$Fovea Detection#IDRiD#Euclidean Distance (ED)#32.1$Fovea Detection#ADAM#Euclidean Distance (ED)#25.4
1910.00177v3.pdf	OpenAI Gym#Humanoid-v2#Average Return#4996$OpenAI Gym#Hopper-v2#Average Return#3405$OpenAI Gym#HalfCheetah-v2#Average Return#9136$OpenAI Gym#Ant-v2#Average Return#5067$OpenAI Gym#LunarLander-v2#Average Return#229$OpenAI Gym#Walker2d-v2#Average Return#5813
2012.07723v3.pdf	OpenAI Gym#Mountain Car#Average Return#-101.72$OpenAI Gym#Mountain Car#Average Return#-106.02$OpenAI Gym#LunarLander-v2#Average Return#272.14$OpenAI Gym#Cart Pole (OpenAI Gym)#Average Return#500$OpenAI Gym#CartPole-v1#Average Return#500
2104.00808v1.pdf	Multi-target Domain Adaptation#Office-Home#Accuracy#69.8$Multi-target Domain Adaptation#Office-31#Accuracy#88.8$Multi-target Domain Adaptation#DomainNet#Accuracy#34.4
1907.03389v1.pdf	Multi-target Domain Adaptation#Office-Home#Accuracy#64.0$Multi-target Domain Adaptation#Office-31#Accuracy#80.2
2007.07077v4.pdf	Multi-target Domain Adaptation#Office-31#Accuracy#85.2
1904.12347v1.pdf	Multi-target Domain Adaptation#DomainNet#Accuracy#21.5
2205.03432v1.pdf	Phone-level pronunciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.68$Phone-level pronunciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.61$Word-level pronunciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.60$Word-level pronunciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.55$Utterance-level pronounciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.74$Utterance-level pronounciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.73
2104.01378v2.pdf	Phone-level pronunciation scoring#speechocean762#Pearson correlation coefficient (PCC)#0.45
2104.10283v2.pdf	Graph Question Answering#GQA#Accuracy#96.30
2104.11980v2.pdf	Trajectory Modeling#NBA SportVU#1x1 NLL#0.472
1704.00077v1.pdf	Video Segmentation#SegTrack v2#Accuracy#86.86
1906.03363v1.pdf	Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#F score#0.7686$Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#FPS#93
1705.03281v2.pdf	Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#F score#0.7534$Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#FPS#86$Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#F score#0.7349$Camera shot boundary detection#ClipShots#F1 score#75.9
1705.08214v1.pdf	Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#F score#0.7492$Camera shot boundary detection#MSU Shot Boundary Detection Benchmark#FPS#94
1808.04234v1.pdf	Camera shot boundary detection#ClipShots#F1 score#76.1
2008.04838v1.pdf	Camera shot boundary detection#ClipShots#F1 score#77.9
1612.09161v2.pdf	Zero-Shot Transfer Image Classification#SUN#Accuracy#23.0$Zero-Shot Transfer Image Classification#aYahoo#Accuracy#72.4
2205.11283v4.pdf	Salient Object Detection#HKU-IS#MAE#0.024$Salient Object Detection#HKU-IS#E-measure#0.959$Salient Object Detection#HKU-IS#max_F1#0.947$Salient Object Detection#HKU-IS#S-measure#0.930$Salient Object Detection#ECSSD#MAE#0.027$Salient Object Detection#ECSSD#max_F1#0.957$Salient Object Detection#ECSSD#S-measure#0.935$Salient Object Detection#ECSSD#E-measure#0.928$Salient Object Detection#DUTS-TE#MAE#0.026$Salient Object Detection#DUTS-TE#max_F1#0.916$Salient Object Detection#DUTS-TE#E-measure#0.920$Salient Object Detection#DUTS-TE#S-measure#0.911$Salient Object Detection#PASCAL-S#MAE#0.050$Salient Object Detection#PASCAL-S#max_F1#0.894$Salient Object Detection#PASCAL-S#S-measure#0.874$Salient Object Detection#PASCAL-S#E-measure#0.872$Salient Object Detection#DUT-OMRON#max_F1#0.836$Salient Object Detection#DUT-OMRON#MAE#0.041$Salient Object Detection#DUT-OMRON#E-measure#0.886$Salient Object Detection#DUT-OMRON#S-measure#0.856
2105.13865v3.pdf	Salient Object Detection#HKU-IS#MAE#0.027$Salient Object Detection#HKU-IS#E-measure#0.954$Salient Object Detection#HKU-IS#max_F1#0.938$Salient Object Detection#HKU-IS#S-measure#0.918$Salient Object Detection#ECSSD#MAE#0.033$Salient Object Detection#ECSSD#max_F1#0.945$Salient Object Detection#ECSSD#S-measure#0.921$Salient Object Detection#ECSSD#E-measure#0.923$Salient Object Detection#DUTS-TE#MAE#0.034$Salient Object Detection#DUTS-TE#max_F1#0.889$Salient Object Detection#DUTS-TE#E-measure#0.903$Salient Object Detection#DUTS-TE#S-measure#0.878$Salient Object Detection#PASCAL-S#MAE#0.059$Salient Object Detection#PASCAL-S#max_F1#0.875$Salient Object Detection#PASCAL-S#S-measure#0.854$Salient Object Detection#PASCAL-S#E-measure#0.853$Salient Object Detection#DUT-OMRON#max_F1#0.810$Salient Object Detection#DUT-OMRON#MAE#0.045$Salient Object Detection#DUT-OMRON#E-measure#0.856$Salient Object Detection#DUT-OMRON#S-measure#0.820
2009.10181v5.pdf	Meter Reading#Copel-AMR#Rank-1 Recognition Rate#96.98$Meter Reading#Copel-AMR#Rank-1 Recognition Rate#95.43$Meter Reading#UFPR-AMR#Rank-1 Recognition Rate#94.75$Meter Reading#UFPR-AMR#Rank-1 Recognition Rate#94.37
2005.03106v2.pdf	Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#75.25$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#74.75$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#73.75$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#72.25$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#71.75$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#71.25$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#68$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#54.25$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#51.75$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#47.75$Meter Reading#UFPR-ADMR-v1#Rank-1 Recognition Rate#42.25
1902.09600v1.pdf	Meter Reading#UFPR-AMR#Rank-1 Recognition Rate#94.13$Meter Reading#UFPR-AMR#Rank-1 Recognition Rate#92.3$Meter Reading#UFPR-AMR#Rank-1 Recognition Rate#87.69
2107.09817v1.pdf	Audio captioning#AudioCaps#CIDEr#0.693$Audio captioning#AudioCaps#SPIDEr#0.426$Audio captioning#AudioCaps#SPICE#0.159
2007.00225v1.pdf	Audio captioning#Clotho#CIDEr#0.319$Audio captioning#Clotho#SPIDEr#0.207$Audio captioning#Clotho#SPICE#0.094
2006.03391v3.pdf	Audio captioning#Clotho#CIDEr#0.18
2009.08709v2.pdf	Blind Face Restoration#CelebA-Test#LPIPS#42.4$Blind Face Restoration#CelebA-Test#FID#47.59$Blind Face Restoration#CelebA-Test#NIQE#5.123$Blind Face Restoration#CelebA-Test#Deg.#39.69$Blind Face Restoration#CelebA-Test#PSNR#24.71$Blind Face Restoration#CelebA-Test#SSIM#0.6557
1912.07116v2.pdf	Blind Face Restoration#CelebA-Test#LPIPS#45.84$Blind Face Restoration#CelebA-Test#FID#82.27$Blind Face Restoration#CelebA-Test#NIQE#6.422$Blind Face Restoration#CelebA-Test#Deg.#55.45$Blind Face Restoration#CelebA-Test#PSNR#24.30$Blind Face Restoration#CelebA-Test#SSIM#0.6758
2105.06070v1.pdf	Blind Face Restoration#CelebA-HQ#PSNR#20.80$Blind Face Restoration#CelebA-HQ#FID#31.72$Blind Face Restoration#CelebA-HQ#LPIPS#0.346$Blind Face Restoration#CelebA-HQ#PSNR#21.33$Blind Face Restoration#CelebA-HQ#FID#56.67$Blind Face Restoration#CelebA-HQ#LPIPS#0.392$Blind Face Restoration#CelebA-HQ#PSNR#20.45$Blind Face Restoration#CelebA-HQ#FID#76.89$Blind Face Restoration#CelebA-HQ#LPIPS#0.494$Blind Face Restoration#CelebA-HQ#PSNR#21.70$Blind Face Restoration#CelebA-HQ#FID#134.92$Blind Face Restoration#CelebA-HQ#LPIPS#0.597$Blind Face Restoration#CelebA-HQ#PSNR#19.84$Blind Face Restoration#CelebA-HQ#FID#135.84$Blind Face Restoration#CelebA-HQ#LPIPS#0.569$Blind Face Restoration#CelebA-HQ#PSNR#21.56$Blind Face Restoration#CelebA-HQ#FID#136.83$Blind Face Restoration#CelebA-HQ#LPIPS#0.616
2105.12306v1.pdf	Chinese Spell Checking#SIGHAN 2015#Detection F1#79.3$Chinese Spell Checking#SIGHAN 2015#Correction F1#77.8
2105.14078v1.pdf	Phrase Ranking#KP20k#P@5K#100.0$Phrase Ranking#KP20k#P@50K#98.5$Phrase Ranking#KP20k#P@5K#96.5$Phrase Ranking#KP20k#P@50K#96.5$Phrase Ranking#KP20k#P@5K#81.5$Phrase Ranking#KP20k#P@50K#78.0$Phrase Ranking#KPTimes#P@5K#99.0$Phrase Ranking#KPTimes#P@50K#96.5$Phrase Ranking#KPTimes#P@5K#96.5$Phrase Ranking#KPTimes#P@50K#95.5$Phrase Ranking#KPTimes#P@5K#85.5$Phrase Ranking#KPTimes#P@50K#71.0$Keyphrase Extraction#KPTimes#Recall#83.4$Keyphrase Extraction#KPTimes#F1@10#10.9$Keyphrase Extraction#KPTimes#Recall#77.8$Keyphrase Extraction#KPTimes#F1@10#10.3$Keyphrase Extraction#KPTimes#Recall#64.5$Keyphrase Extraction#KPTimes#F1@10#9.4$Keyphrase Extraction#KPTimes#Recall#63.4$Keyphrase Extraction#KPTimes#F1@10#8.5$Keyphrase Extraction#KP20k#Recall#73.0$Keyphrase Extraction#KP20k#F1@10#19.2$Keyphrase Extraction#KP20k#Recall#72.9$Keyphrase Extraction#KP20k#F1@10#19.7$Keyphrase Extraction#KP20k#Recall#62.9$Keyphrase Extraction#KP20k#F1@10#18.2$Keyphrase Extraction#KP20k#Recall#59.5$Keyphrase Extraction#KP20k#F1@10#15.3$Keyphrase Extraction#KP20k#Recall#57.1$Keyphrase Extraction#KP20k#F1@10#12.6$Keyphrase Extraction#KP20k#Recall#53.3$Keyphrase Extraction#KP20k#F1@10#15.0$Keyphrase Extraction#KP20k#Recall#51.7$Keyphrase Extraction#KP20k#F1@10#13.9$Phrase Tagging#KPTimes#Precision#69.1$Phrase Tagging#KPTimes#Recall#78.9$Phrase Tagging#KPTimes#F1#73.5$Phrase Tagging#KPTimes#Precision#60.9$Phrase Tagging#KPTimes#Recall#65.6$Phrase Tagging#KPTimes#F1#63.2$Phrase Tagging#KPTimes#Precision#44.2$Phrase Tagging#KPTimes#Recall#47.7$Phrase Tagging#KPTimes#F1#45.9$Phrase Tagging#KPTimes#Precision#32.0$Phrase Tagging#KPTimes#Recall#36.3$Phrase Tagging#KPTimes#F1#34.0$Phrase Tagging#KP20k#Precision#69.9$Phrase Tagging#KP20k#Recall#78.3$Phrase Tagging#KP20k#F1#73.9$Phrase Tagging#KP20k#Precision#58.1$Phrase Tagging#KP20k#Recall#64.2$Phrase Tagging#KP20k#F1#61.0$Phrase Tagging#KP20k#Precision#55.2$Phrase Tagging#KP20k#Recall#45.2$Phrase Tagging#KP20k#F1#49.7$Phrase Tagging#KP20k#Precision#39.8$Phrase Tagging#KP20k#Recall#41.4$Phrase Tagging#KP20k#F1#40.6
2210.05245v2.pdf	Keyphrase Extraction#Inspec#F1@10#30.99
2108.07978v2.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#35.9721$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1296$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9918
2105.13084v2.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#34.9894$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1830$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#34.9894
2004.01179v1.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#34.2872$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.2630$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9845
1803.02266v2.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#34.0555$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1942$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9892
2005.07335v1.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#33.5267$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1000$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9907
1710.07480v1.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#33.0200$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1919$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9663
2104.09386v1.pdf	Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-PSNR#31.6717$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-VQM#0.1350$Inverse-Tone-Mapping#MSU HDR Video Reconstruction Benchmark#HDR-SSIM#0.9884
2106.09712v1.pdf	IFC Entity Classification#IFCNetCore#Balanced Accuracy#85.54$IFC Entity Classification#IFCNetCore#F1 Score#86.93$IFC Entity Classification#IFCNetCore#Balanced Accuracy#83.32$IFC Entity Classification#IFCNetCore#F1 Score#85.72$IFC Entity Classification#IFCNetCore#Balanced Accuracy#79.11$IFC Entity Classification#IFCNetCore#F1 Score#82.15
2111.11638v1.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.5971 ± 0.0245$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.5995 ± 0.0205$Link Property Prediction#ogbl-ppa#Number of params#735426$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-ppa#Test Hits@100#0.4005 ± 0.0138$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.4058 ± 0.0123$Link Property Prediction#ogbl-ppa#Number of params#556033$Link Property Prediction#ogbl-ppa#Test Hits@100#0.3683 ± 0.0099$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.3834 ± 0.0082$Link Property Prediction#ogbl-ppa#Number of params#410113$Link Property Prediction#ogbl-ddi#Test Hits@20#0.5770 ± 0.1523$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.7323 ± 0.0040$Link Property Prediction#ogbl-ddi#Number of params#1618433$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.5483 ± 0.1581$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.7121 ± 0.0038$Link Property Prediction#ogbl-ddi#Number of params#1487361$Link Property Prediction#ogbl-collab#Test Hits@50#0.5359 ± 0.0056$Link Property Prediction#ogbl-collab#Validation Hits@50#0.6281 ± 0.0046$Link Property Prediction#ogbl-collab#Number of params#591873$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.5348 ± 0.0040$Link Property Prediction#ogbl-collab#Validation Hits@50#0.6273 ± 0.0040$Link Property Prediction#ogbl-collab#Number of params#428033
2106.15810v1.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.5324 ± 0.0000$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.5142 ± 0.0000$Link Property Prediction#ogbl-ppa#Number of params#0$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.7495 ± 0.0317$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.6696 ± 0.0198$Link Property Prediction#ogbl-ddi#Number of params#1421057$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.6548 ± 0.0000$Link Property Prediction#ogbl-collab#Validation Hits@50#0.9735 ± 0.0000$Link Property Prediction#ogbl-collab#Number of params#0$Link Property Prediction#ogbl-collab#Ext. data#No
0901.0553v2.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.4933 ± 0.0000$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.4722 ± 0.0000$Link Property Prediction#ogbl-ppa#Number of params#0$Link Property Prediction#ogbl-ppa#Ext. data#No
2010.16103v5.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.4880 ± 0.0316$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.5125 ± 0.0252$Link Property Prediction#ogbl-ppa#Number of params#709122$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.8767 ± 0.0032$Link Property Prediction#ogbl-citation2#Validation MRR#0.8757 ± 0.0031$Link Property Prediction#ogbl-citation2#Number of params#260802$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.3056 ± 0.0386$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.2849 ± 0.0269$Link Property Prediction#ogbl-ddi#Number of params#531138$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.6474 ± 0.0043$Link Property Prediction#ogbl-collab#Validation Hits@50#0.6495 ± 0.0043$Link Property Prediction#ogbl-collab#Number of params#501570$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.5471 ± 0.0049
2012.15024v2.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.4123 ± 0.0159$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.4332 ± 0.0092$Link Property Prediction#ogbl-ppa#Number of params#36904259$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.8549 ± 0.0029$Link Property Prediction#ogbl-citation2#Validation MRR#0.8556 ± 0.0033$Link Property Prediction#ogbl-citation2#Number of params#306716$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.9538 ± 0.0094$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.8943 ± 0.0281$Link Property Prediction#ogbl-ddi#Number of params#3506691$Link Property Prediction#ogbl-ddi#Ext. data#No
2005.00687v7.pdf	Link Property Prediction#ogbl-ppa#Test Hits@100#0.3229 ± 0.0094$Link Property Prediction#ogbl-ppa#Validation Hits@100#0.3228 ± 0.0428$Link Property Prediction#ogbl-ppa#Number of params#147662849$Link Property Prediction#ogbl-ppa#Ext. data#No$Link Property Prediction#ogbl-citation2#Test MRR#0.5186 ± 0.0443$Link Property Prediction#ogbl-citation2#Validation MRR#0.5181 ± 0.0436$Link Property Prediction#ogbl-citation2#Number of params#281113505$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.1368 ± 0.0475$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.3370 ± 0.0264$Link Property Prediction#ogbl-ddi#Number of params#1224193$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.3886 ± 0.0029$Link Property Prediction#ogbl-collab#Validation Hits@50#0.4896 ± 0.0029$Link Property Prediction#ogbl-collab#Number of params#60514049$Link Property Prediction#ogbl-collab#Ext. data#No
2202.13538v2.pdf	Link Property Prediction#ogbl-citation2#Test MRR#0.8883 ± 0.0018$Link Property Prediction#ogbl-citation2#Validation MRR#0.8891 ± 0.0021$Link Property Prediction#ogbl-citation2#Number of params#79617$Link Property Prediction#ogbl-citation2#Ext. data#No
2112.02936v6.pdf	Link Property Prediction#ogbl-citation2#Test MRR#0.8492 ± 0.0029$Link Property Prediction#ogbl-citation2#Validation MRR#0.8490 ± 0.0031$Link Property Prediction#ogbl-citation2#Number of params#146514551$Link Property Prediction#ogbl-citation2#Ext. data#No$Link Property Prediction#ogbl-ddi#Test Hits@20#0.9088 ± 0.0313$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.8242 ± 0.0253$Link Property Prediction#ogbl-ddi#Number of params#3497473$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.7059 ± 0.0029$Link Property Prediction#ogbl-collab#Validation Hits@50#1.0000 ± 0.0000$Link Property Prediction#ogbl-collab#Number of params#34980864$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.6872 ± 0.0052$Link Property Prediction#ogbl-collab#Number of params#35112192
2210.01301v2.pdf	Link Property Prediction#ogbl-ddi#Test Hits@20#0.9542 ± 0.0000$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.8258 ± 0.0000$Link Property Prediction#ogbl-ddi#Number of params#3506691$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.7096 ± 0.0055$Link Property Prediction#ogbl-collab#Validation Hits@50#0.9620 ± 0.0040$Link Property Prediction#ogbl-collab#Number of params#60449025$Link Property Prediction#ogbl-collab#Ext. data#No
2208.05781v1.pdf	Link Property Prediction#ogbl-ddi#Test Hits@20#0.9284 ± 0.0047$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.8306 ± 0.0134$Link Property Prediction#ogbl-ddi#Number of params#3499009$Link Property Prediction#ogbl-ddi#Ext. data#No
2106.02172v2.pdf	Link Property Prediction#ogbl-ddi#Test Hits@20#0.8608 ± 0.0198$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.8405 ± 0.0284$Link Property Prediction#ogbl-ddi#Number of params#837635$Link Property Prediction#ogbl-ddi#Ext. data#No
2102.05246v2.pdf	Link Property Prediction#ogbl-ddi#Test Hits@20#0.6781 ± 0.0294$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.7010 ± 0.0082$Link Property Prediction#ogbl-ddi#Number of params#1228897$Link Property Prediction#ogbl-ddi#Ext. data#No
2006.07846v2.pdf	Link Property Prediction#ogbl-ddi#Test Hits@20#0.6230 ± 0.0912$Link Property Prediction#ogbl-ddi#Validation Hits@20#0.6675 ± 0.0058$Link Property Prediction#ogbl-ddi#Number of params#1576081$Link Property Prediction#ogbl-ddi#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.6909 ± 0.0055$Link Property Prediction#ogbl-collab#Validation Hits@50#1.0000 ± 0.0000$Link Property Prediction#ogbl-collab#Number of params#35200656$Link Property Prediction#ogbl-collab#Ext. data#No$Link Property Prediction#ogbl-collab#Test Hits@50#0.5221 ± 0.0072$Link Property Prediction#ogbl-collab#Validation Hits@50#0.6088 ± 0.0059$Link Property Prediction#ogbl-collab#Number of params#1069489
2207.11673v1.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.7362 ± 0.0006$Link Property Prediction#ogbl-wikikg2#Test MRR#0.7353 ± 0.0006$Link Property Prediction#ogbl-wikikg2#Number of params#19215402$Link Property Prediction#ogbl-wikikg2#Ext. data#No
2205.14209v1.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.7288 ± 0.0008$Link Property Prediction#ogbl-wikikg2#Test MRR#0.7201 ± 0.0011$Link Property Prediction#ogbl-wikikg2#Number of params#86762146$Link Property Prediction#ogbl-wikikg2#Ext. data#No
2204.08401v2.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.6988 ± 0.0006$Link Property Prediction#ogbl-wikikg2#Test MRR#0.6882 ± 0.0019$Link Property Prediction#ogbl-wikikg2#Number of params#19215402$Link Property Prediction#ogbl-wikikg2#Ext. data#No
2202.04897v1.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.6893 ± 0.0015$Link Property Prediction#ogbl-wikikg2#Test MRR#0.6779 ± 0.0018$Link Property Prediction#ogbl-wikikg2#Number of params#19215402$Link Property Prediction#ogbl-wikikg2#Ext. data#No
2106.12144v2.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.5806 ± 0.0047$Link Property Prediction#ogbl-wikikg2#Test MRR#0.5703 ± 0.0035$Link Property Prediction#ogbl-wikikg2#Number of params#6860602$Link Property Prediction#ogbl-wikikg2#Ext. data#No
2011.03798v3.pdf	Link Property Prediction#ogbl-wikikg2#Validation MRR#0.5423 ± 0.0020$Link Property Prediction#ogbl-wikikg2#Test MRR#0.5208 ± 0.0027$Link Property Prediction#ogbl-wikikg2#Number of params#500334800$Link Property Prediction#ogbl-wikikg2#Ext. data#No$Link Property Prediction#ogbl-biokg#Test MRR#0.8164 ± 0.0005$Link Property Prediction#ogbl-biokg#Validation MRR#0.8172 ± 0.0005$Link Property Prediction#ogbl-biokg#Number of params#187750000$Link Property Prediction#ogbl-biokg#Ext. data#No
2006.07739v1.pdf	Link Property Prediction#ogbl-collab#Test Hits@50#0.5273 ± 0.0047$Link Property Prediction#ogbl-collab#Validation Hits@50#0.6187 ± 0.0045$Link Property Prediction#ogbl-collab#Number of params#117383$Link Property Prediction#ogbl-collab#Ext. data#No$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.7712 ± 0.0071$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.7313 ± 0.0078$Graph Property Prediction#ogbg-ppa#Number of params#2336421$Graph Property Prediction#ogbg-ppa#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2781 ± 0.0038$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2920 ± 0.0025$Graph Property Prediction#ogbg-molpcba#Number of params#5550208$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7858 ± 0.0117$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8427 ± 0.0063$Graph Property Prediction#ogbg-molhiv#Number of params#531976$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2107.00184v2.pdf	Link Property Prediction#ogbl-biokg#Test MRR#0.8536 ± 0.0003$Link Property Prediction#ogbl-biokg#Validation MRR#0.8548 ± 0.0002$Link Property Prediction#ogbl-biokg#Number of params#192047104$Link Property Prediction#ogbl-biokg#Ext. data#No
2012.07219v1.pdf	Graph Property Prediction#ogbg-ppa#Test Accuracy#0.7976 ± 0.0072$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.7518 ± 0.0080$Graph Property Prediction#ogbg-ppa#Number of params#1369397$Graph Property Prediction#ogbg-ppa#Ext. data#No
2010.09891v3.pdf	Graph Property Prediction#ogbg-ppa#Test Accuracy#0.7752 ± 0.0069$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.7484 ± 0.0052$Graph Property Prediction#ogbg-ppa#Number of params#2336421$Graph Property Prediction#ogbg-ppa#Ext. data#No$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.7245 ± 0.0114$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6789 ± 0.0079$Graph Property Prediction#ogbg-ppa#Number of params#3288042$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.6944 ± 0.0052$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6638 ± 0.0055$Graph Property Prediction#ogbg-ppa#Number of params#1930537$Graph Property Prediction#ogbg-ppa#Test Accuracy#0.6905 ± 0.0092$Graph Property Prediction#ogbg-ppa#Validation Accuracy#0.6465 ± 0.0070$Graph Property Prediction#ogbg-ppa#Number of params#1836942$Graph Property Prediction#ogbg-molpcba#Test AP#0.2842 ± 0.0043$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2952 ± 0.0029$Graph Property Prediction#ogbg-molpcba#Number of params#5550208$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2834 ± 0.0038$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2912 ± 0.0026$Graph Property Prediction#ogbg-molpcba#Number of params#3374533$Graph Property Prediction#ogbg-molpcba#Test AP#0.2483 ± 0.0037$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2556 ± 0.0040$Graph Property Prediction#ogbg-molpcba#Number of params#2017028$Graph Property Prediction#ogbg-molpcba#Test AP#0.2395 ± 0.0040$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2451 ± 0.0042$Graph Property Prediction#ogbg-molpcba#Number of params#1923433$Graph Property Prediction#ogbg-molpcba#Test AP#0.2116 ± 0.0017$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2150 ± 0.0022$Graph Property Prediction#ogbg-molpcba#Number of params#565928$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7942 ± 0.0120$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8425 ± 0.0061$Graph Property Prediction#ogbg-molhiv#Number of params#531976$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7748 ± 0.0096$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8438 ± 0.0128$Graph Property Prediction#ogbg-molhiv#Number of params#3336306$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7683 ± 0.0102$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8176 ± 0.0087$Graph Property Prediction#ogbg-molhiv#Number of params#527701$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7654 ± 0.0114$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8225 ± 0.0155$Graph Property Prediction#ogbg-molhiv#Number of params#1885206
2110.13197v1.pdf	Graph Property Prediction#ogbg-molpcba#Test AP#0.3007 ± 0.0037$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3059 ± 0.0056$Graph Property Prediction#ogbg-molpcba#Number of params#44187480$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2832 ± 0.0041$Graph Property Prediction#ogbg-molpcba#Validation AP#0.2915 ± 0.0035$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7986 ± 0.0105$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8080 ± 0.0278$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7834 ± 0.0186$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8317 ± 0.0199
2011.15069v2.pdf	Graph Property Prediction#ogbg-molpcba#Test AP#0.2979 ± 0.0030$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3126 ± 0.0023$Graph Property Prediction#ogbg-molpcba#Number of params#6147029$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molpcba#Test AP#0.2917 ± 0.0015$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3065 ± 0.0030
2103.16584v1.pdf	Graph Property Prediction#ogbg-molpcba#Test AP#0.2947 ± 0.0026$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3068 ± 0.0025$Graph Property Prediction#ogbg-molpcba#Number of params#1690328$Graph Property Prediction#ogbg-molpcba#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7934 ± 0.0116$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8217 ± 0.0089$Graph Property Prediction#ogbg-molhiv#Number of params#110909$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2110.03753v3.pdf	Graph Property Prediction#ogbg-molpcba#Test AP#0.2930 ± 0.0044$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3047 ± 0.0007$Graph Property Prediction#ogbg-molpcba#Number of params#3081029$Graph Property Prediction#ogbg-molpcba#Ext. data#No
2103.15565v1.pdf	Graph Property Prediction#ogbg-molpcba#Test AP#0.2881 ± 0.0028$Graph Property Prediction#ogbg-molpcba#Validation AP#0.3035 ± 0.0047$Graph Property Prediction#ogbg-molpcba#Number of params#5572026$Graph Property Prediction#ogbg-molpcba#Ext. data#No
2201.12987v3.pdf	Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.8067 ± 0.0950$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8347 ± 0.0031$Graph Property Prediction#ogbg-molhiv#Number of params#249602$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2009.03294v3.pdf	Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7883 ± 0.0100$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.7904 ± 0.0115$Graph Property Prediction#ogbg-molhiv#Number of params#526201$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2006.12179v1.pdf	Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7880 ± 0.0082$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#Please tell us$Graph Property Prediction#ogbg-molhiv#Number of params#153029$Graph Property Prediction#ogbg-molhiv#Ext. data#No
2104.01481v5.pdf	Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7818 ± 0.0153$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8396 ± 0.0097$Graph Property Prediction#ogbg-molhiv#Number of params#317265$Graph Property Prediction#ogbg-molhiv#Ext. data#No$Graph Property Prediction#ogbg-molhiv#Test ROC-AUC#0.7721 ± 0.0110$Graph Property Prediction#ogbg-molhiv#Validation ROC-AUC#0.8366 ± 0.0074$Graph Property Prediction#ogbg-molhiv#Number of params#317013$Graph Property Prediction#ogbg-code2#Test F1 score#0.1595 ± 0.0019$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1464 ± 0.0021$Graph Property Prediction#ogbg-code2#Number of params#10986002$Graph Property Prediction#ogbg-code2#Ext. data#No$Graph Property Prediction#ogbg-code2#Test F1 score#0.1570 ± 0.0032$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1453 ± 0.0025$Graph Property Prediction#ogbg-code2#Number of params#10992050$Graph Property Prediction#ogbg-code2#Test F1 score#0.1552 ± 0.0022$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1441 ± 0.0016$Graph Property Prediction#ogbg-code2#Number of params#10971506$Graph Property Prediction#ogbg-code2#Test F1 score#0.1528 ± 0.0025$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1427 ± 0.0020$Graph Property Prediction#ogbg-code2#Number of params#11156530
2210.13148v2.pdf	Graph Property Prediction#ogbg-code2#Test F1 score#0.1982 ± 0.0010$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1821 ± 0.0013$Graph Property Prediction#ogbg-code2#Number of params#14952882$Graph Property Prediction#ogbg-code2#Ext. data#No
2202.03036v3.pdf	Graph Property Prediction#ogbg-code2#Test F1 score#0.1937 ± 0.0028$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1773 ± 0.0023$Graph Property Prediction#ogbg-code2#Number of params#15734000$Graph Property Prediction#ogbg-code2#Ext. data#No
2101.07965v3.pdf	Graph Property Prediction#ogbg-code2#Test F1 score#0.1751 ± 0.0049$Graph Property Prediction#ogbg-code2#Validation F1 score#0.1607 ± 0.0040
2205.06207v2.pdf	Extreme Summarization#CiteSum#ROUGE-1#44.17$Extreme Summarization#CiteSum#ROUGE-2#27.22$Extreme Summarization#CiteSum#ROUGE-L#38.32$Extreme Summarization#CiteSum#ROUGE-1#42.02$Extreme Summarization#CiteSum#ROUGE-2#19.44$Extreme Summarization#CiteSum#ROUGE-L#33.78$Extreme Summarization#CiteSum#ROUGE-1#42.01$Extreme Summarization#CiteSum#ROUGE-2#19.34$Extreme Summarization#CiteSum#ROUGE-L#33.72$Extreme Summarization#CiteSum#ROUGE-1#41.89$Extreme Summarization#CiteSum#ROUGE-2#19.51$Extreme Summarization#CiteSum#ROUGE-L#33.73$Extreme Summarization#CiteSum#ROUGE-1#41.86$Extreme Summarization#CiteSum#ROUGE-2#19.36$Extreme Summarization#CiteSum#ROUGE-1#41.85$Extreme Summarization#CiteSum#ROUGE-2#19.21$Extreme Summarization#CiteSum#ROUGE-L#33.42$Extreme Summarization#CiteSum#ROUGE-1#41.56$Extreme Summarization#CiteSum#ROUGE-2#18.63$Extreme Summarization#CiteSum#ROUGE-L#33.45$Extreme Summarization#CiteSum#ROUGE-1#29.32$Extreme Summarization#CiteSum#ROUGE-2#12.53$Extreme Summarization#CiteSum#ROUGE-L#23.99$Extreme Summarization#CiteSum#ROUGE-1#21.94$Extreme Summarization#CiteSum#ROUGE-2#7.35$Extreme Summarization#CiteSum#ROUGE-L#17.36
2110.01159v2.pdf	Extreme Summarization#TLDR9+#RG-1(%)#30.26$Extreme Summarization#TLDR9+#RG-2(%)#9.74$Extreme Summarization#TLDR9+#RG-L(%)#20.60$Extreme Summarization#TLDR9+#RG-1(%)#23.59$Extreme Summarization#TLDR9+#RG-2(%)#9.69$Extreme Summarization#TLDR9+#RG-L(%)#18.62$Extreme Summarization#TLDR9+#RG-1(%)#23.05$Extreme Summarization#TLDR9+#RG-2(%)#9.48$Extreme Summarization#TLDR9+#RG-L(%)#18.07$Extreme Summarization#TLDR9+#RG-1(%)#20.94$Extreme Summarization#TLDR9+#RG-2(%)#4.98$Extreme Summarization#TLDR9+#RG-L(%)#14.48
2007.15815v1.pdf	Anxiety Detection#Well-being Dataset#F1-score#82.1
1905.04388v1.pdf	Control with Prametrised Actions#Robot Soccer Goal#Goal Probability#0.789$Control with Prametrised Actions#Platform#Return#0.987$Control with Prametrised Actions#Half Field Offence#Goal Probability#0.913
1912.11077v1.pdf	Control with Prametrised Actions#Robot Soccer Goal#Goal Probability#0.728$Control with Prametrised Actions#Platform#Return#0.981$Control with Prametrised Actions#Half Field Offence#Goal Probability#0.639
2204.01851v1.pdf	Sound Event Localization and Detection#L3DAS21#SELD score#0.324
2206.01948v2.pdf	Sound Event Localization and Detection#STARSS22#Localization-dependent error rate (20°)#71$Sound Event Localization and Detection#STARSS22#location-dependent F1-score (macro)#21$Sound Event Localization and Detection#STARSS22#location-dependent F1-score (micro)#0.36$Sound Event Localization and Detection#STARSS22#Class-dependent localization error#29.3$Sound Event Localization and Detection#STARSS22#Class-dependent localization recall#46$Sound Event Localization and Detection#STARSS22#location-dependent F1-score (macro)#18$Sound Event Localization and Detection#STARSS22#Class-dependent localization error#32.2$Sound Event Localization and Detection#STARSS22#Class-dependent localization recall#47
2110.00275v3.pdf	Sound Event Localization and Detection#TAU-NIGENS Spatial Sound Events 2021#ER≤20°#0.376$Sound Event Localization and Detection#TAU-NIGENS Spatial Sound Events 2021#F1≤20°#0.744$Sound Event Localization and Detection#TAU-NIGENS Spatial Sound Events 2021#LE-CD#11.1$Sound Event Localization and Detection#TAU-NIGENS Spatial Sound Events 2021#LR-CD#0.722
2203.15135v2.pdf	Sound Event Localization and Detection#PodcastFillers#event-based F1 score#92.8$Sound Event Localization and Detection#PodcastFillers#event-based F1 score#71.0
2103.16397v2.pdf	Affordance Detection#3D AffordanceNet#mAP#0.464$Affordance Detection#3D AffordanceNet#AIOU#0.178$Affordance Detection#3D AffordanceNet Rotate z#mAP#0.448$Affordance Detection#3D AffordanceNet Rotate z#AIOU#0.161$Affordance Detection#3D AffordanceNet Partial View#mAP#0.422$Affordance Detection#3D AffordanceNet Partial View#AIOU#0.138$Affordance Detection#3D AffordanceNet Rotate SO(3)#mAP#0.373$Affordance Detection#3D AffordanceNet Rotate SO(3)#AIOU#0.128
2209.11807v1.pdf	Formation Energy#JARVIS-DFT#MAE#0.0325$Formation Energy#Materials Project#MAE#21.2
2106.01829v3.pdf	Formation Energy#JARVIS-DFT#MAE#0.0331$Formation Energy#QM9#MAE#0.30
1706.08566v5.pdf	Formation Energy#JARVIS-DFT#MAE#0.045$Formation Energy#QM9#MAE#0.31
1806.03146v1.pdf	Formation Energy#Materials Project#MAE#22.7$Formation Energy#Materials Project#MAE#31.8$Formation Energy#QM9#MAE#0.242$Formation Energy#QM9#MAE#0.314
1812.05055v1.pdf	Formation Energy#Materials Project#MAE#28$Formation Energy#QM9#MAE#0.21$Formation Energy#QM9#MAE#0.28
1712.06113v3.pdf	Formation Energy#Materials Project#MAE#35
1710.10324v3.pdf	Formation Energy#Materials Project#MAE#39
1811.05660v1.pdf	Formation Energy#Materials Project#MAE#41
2009.12710v1.pdf	Formation Energy#QM9#MAE#0.138
1902.08408v2.pdf	Formation Energy#QM9#MAE#0.14$Formation Energy#QM9#MAE#0.19
1710.00017v1.pdf	Formation Energy#QM9#MAE#0.256
1702.05532.pdf	Formation Energy#QM9#MAE#0.58
2208.13764v1.pdf	Circulatory Failure#HiRID#AUPRC#0.406±0.003$Circulatory Failure#HiRID#Recall@50#32.3$Respiratory Failure#HiRID#AUPRC#0.604±0.002$Respiratory Failure#HiRID#Recall@50#77.0
2111.12689v1.pdf	Remaining Useful Lifetime Estimation#NASA C-MAPSS-2#Score#3.651
2108.07253v2.pdf	Person-centric Visual Grounding#Who’s Waldo#Accuracy#63.5
1902.10482v2.pdf	Few-Shot Text Classification#ODIC 10-way (5-shot)#Accuracy#78.27$Few-Shot Text Classification#ODIC 5-way (10-shot)#Accuracy#88.49$Few-Shot Text Classification#ODIC 5-way (5-shot)#Accuracy#87.16$Few-Shot Text Classification#ODIC 10-way (10-shot)#Accuracy#81.64
2205.05638v2.pdf	Few-Shot Text Classification#RAFT#Avg#0.758$Few-Shot Text Classification#RAFT#ADE#0.804$Few-Shot Text Classification#RAFT#B77#0.695$Few-Shot Text Classification#RAFT#NIS#0.833$Few-Shot Text Classification#RAFT#OSE#0.676$Few-Shot Text Classification#RAFT#SOT#0.915$Few-Shot Text Classification#RAFT#SRI#0.508$Few-Shot Text Classification#RAFT#TAI#0.736$Few-Shot Text Classification#RAFT#ToS#0.75$Few-Shot Text Classification#RAFT#TEH#0.586$Few-Shot Text Classification#RAFT#TC#0.879$Few-Shot Text Classification#RAFT#Over#0.95
2109.14076v3.pdf	Few-Shot Text Classification#RAFT#Avg#0.735$Few-Shot Text Classification#RAFT#ADE#0.830$Few-Shot Text Classification#RAFT#B77#0.607$Few-Shot Text Classification#RAFT#NIS#0.857$Few-Shot Text Classification#RAFT#OSE#0.646$Few-Shot Text Classification#RAFT#Over#0.917$Few-Shot Text Classification#RAFT#SOT#0.908$Few-Shot Text Classification#RAFT#SRI#0.468$Few-Shot Text Classification#RAFT#TAI#0.609$Few-Shot Text Classification#RAFT#ToS#0.627$Few-Shot Text Classification#RAFT#TEH#0.722$Few-Shot Text Classification#RAFT#TC#0.897$Few-Shot Text Classification#RAFT#Avg#0.627$Few-Shot Text Classification#RAFT#ADE#0.686$Few-Shot Text Classification#RAFT#B77#0.299$Few-Shot Text Classification#RAFT#NIS#0.679$Few-Shot Text Classification#RAFT#OSE#0.431$Few-Shot Text Classification#RAFT#Over#0.937$Few-Shot Text Classification#RAFT#SOT#0.769$Few-Shot Text Classification#RAFT#SRI#0.516$Few-Shot Text Classification#RAFT#TAI#0.656$Few-Shot Text Classification#RAFT#ToS#0.574$Few-Shot Text Classification#RAFT#TEH#0.526$Few-Shot Text Classification#RAFT#TC#0.821$Few-Shot Text Classification#RAFT#Avg#0.514$Few-Shot Text Classification#RAFT#ADE#0.543$Few-Shot Text Classification#RAFT#B77#0.023$Few-Shot Text Classification#RAFT#NIS#0.626$Few-Shot Text Classification#RAFT#OSE#0.475$Few-Shot Text Classification#RAFT#Over#0.838$Few-Shot Text Classification#RAFT#SOT#0.455$Few-Shot Text Classification#RAFT#SRI#0.506$Few-Shot Text Classification#RAFT#TAI#0.556$Few-Shot Text Classification#RAFT#ToS#0.560$Few-Shot Text Classification#RAFT#TEH#0.443$Few-Shot Text Classification#RAFT#TC#0.625$Few-Shot Text Classification#RAFT#Avg#0.481$Few-Shot Text Classification#RAFT#ADE#0.452$Few-Shot Text Classification#RAFT#B77#0.149$Few-Shot Text Classification#RAFT#NIS#0.408$Few-Shot Text Classification#RAFT#OSE#0.343$Few-Shot Text Classification#RAFT#Over#0.681$Few-Shot Text Classification#RAFT#SOT#0.406$Few-Shot Text Classification#RAFT#SRI#0.493$Few-Shot Text Classification#RAFT#TAI#0.605$Few-Shot Text Classification#RAFT#ToS#0.565$Few-Shot Text Classification#RAFT#TEH#0.554$Few-Shot Text Classification#RAFT#TC#0.636$Few-Shot Text Classification#RAFT#Avg#0.458$Few-Shot Text Classification#RAFT#ADE#0.600$Few-Shot Text Classification#RAFT#B77#0.121$Few-Shot Text Classification#RAFT#NIS#0.561$Few-Shot Text Classification#RAFT#OSE#0.245$Few-Shot Text Classification#RAFT#Over#0.498$Few-Shot Text Classification#RAFT#SOT#0.380$Few-Shot Text Classification#RAFT#SRI#0.492$Few-Shot Text Classification#RAFT#TAI#0.612$Few-Shot Text Classification#RAFT#ToS#0.498$Few-Shot Text Classification#RAFT#TEH#0.311$Few-Shot Text Classification#RAFT#TC#0.723$Few-Shot Text Classification#RAFT#Avg#0.382$Few-Shot Text Classification#RAFT#ADE#0.234$Few-Shot Text Classification#RAFT#B77#0.332$Few-Shot Text Classification#RAFT#NIS#0.615$Few-Shot Text Classification#RAFT#OSE#0.360$Few-Shot Text Classification#RAFT#Over#0.462$Few-Shot Text Classification#RAFT#SOT#0.644$Few-Shot Text Classification#RAFT#SRI#0.026$Few-Shot Text Classification#RAFT#TAI#0.469$Few-Shot Text Classification#RAFT#ToS#0.122$Few-Shot Text Classification#RAFT#TEH#0.543$Few-Shot Text Classification#RAFT#TC#0.400$Few-Shot Text Classification#RAFT#Avg#0.331$Few-Shot Text Classification#RAFT#ADE#0.446$Few-Shot Text Classification#RAFT#B77#0.000$Few-Shot Text Classification#RAFT#NIS#0.353$Few-Shot Text Classification#RAFT#OSE#0.164$Few-Shot Text Classification#RAFT#Over#0.337$Few-Shot Text Classification#RAFT#SOT#0.271$Few-Shot Text Classification#RAFT#TAI#0.344$Few-Shot Text Classification#RAFT#ToS#0.471$Few-Shot Text Classification#RAFT#TEH#0.366$Few-Shot Text Classification#RAFT#TC#0.391$Few-Shot Text Classification#RAFT#Avg#0.292$Few-Shot Text Classification#RAFT#ADE#0.163$Few-Shot Text Classification#RAFT#NIS#0.572$Few-Shot Text Classification#RAFT#OSE#0.323$Few-Shot Text Classification#RAFT#Over#0.378$Few-Shot Text Classification#RAFT#SOT#0.628$Few-Shot Text Classification#RAFT#SRI#0.027$Few-Shot Text Classification#RAFT#TAI#0.362$Few-Shot Text Classification#RAFT#ToS#0.164$Few-Shot Text Classification#RAFT#TEH#0.303$Few-Shot Text Classification#RAFT#TC#0.290
2105.07364v1.pdf	2D Semantic Segmentation#xBD#Weighted Average F1-score#0.806
2010.14014v2.pdf	2D Semantic Segmentation#xBD#Weighted Average F1-score#0.804
2004.05525v1.pdf	2D Semantic Segmentation#xBD#Weighted Average F1-score#0.741
1911.09296v1.pdf	2D Semantic Segmentation#xBD#Weighted Average F1-score#0.265
2107.07468v1.pdf	2D Semantic Segmentation#GF-PA66 3D XCT (composite material 3D tomography)#Jaccard (Mean)#87
2106.11562v3.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#68.58$Disjoint 15-1#PASCAL VOC 2012#mIoU#64.01$Disjoint 10-1#PASCAL VOC 2012#mIoU#53.50$Disjoint 10-1#PASCAL VOC 2012#mIoU#50.87$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#69.83$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#69.10
2203.05402v1.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#54.7$Disjoint 10-1#PASCAL VOC 2012#mIoU#18.2$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#67.3
2103.06342v3.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#48.7$Disjoint 10-1#PASCAL VOC 2012#mIoU#14.3$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#67.3
2011.11390v3.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#46.5$Disjoint 10-1#PASCAL VOC 2012#mIoU#8.4$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#64.3
2002.00718v2.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#39.9$Disjoint 10-1#PASCAL VOC 2012#mIoU#6.9$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#65.9
1907.13372v4.pdf	Disjoint 15-1#PASCAL VOC 2012#mIoU#7.9$Disjoint 10-1#PASCAL VOC 2012#mIoU#5.4$Disjoint 15-5#PASCAL VOC 2012#Mean IoU#58.9
2105.11408v1.pdf	Czech Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.22$Vietnamese Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#98.53$Romanian Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#98.64$Slovak Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.32$Latvian Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#98.63$Polish Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.66$Irish Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#98.88$Hungarian Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.41$French Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.71$Turkish Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#98.95$Spanish Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.62$Croatian Text Diacritization#Multilingual Dataset for Training and Evaluating Diacritics Restoration Systems#Alpha-Word accuracy#99.73
2107.01091v2.pdf	Crowdsourced Text Aggregation#CrowdSpeech test-other#Word Error Rate (WER)#13.41$Crowdsourced Text Aggregation#CrowdSpeech test-other#Word Error Rate (WER)#15.66$Crowdsourced Text Aggregation#CrowdSpeech test-other#Word Error Rate (WER)#15.67$Crowdsourced Text Aggregation#CrowdSpeech test-clean#Word Error Rate (WER)#7.29$Crowdsourced Text Aggregation#CrowdSpeech test-clean#Word Error Rate (WER)#8.59$Crowdsourced Text Aggregation#CrowdSpeech test-clean#Word Error Rate (WER)#8.6
2203.12745v2.pdf	Moment Retrieval#QVHighlights#mAP#38.08$Moment Retrieval#QVHighlights#mAP#36.12$Moment Retrieval#Charades-STA#R@1 IoU=0.5#49.35$Moment Retrieval#Charades-STA#R@1 IoU=0.7#26.16$Moment Retrieval#Charades-STA#R@5 IoU=0.5#89.41$Moment Retrieval#Charades-STA#R@5 IoU=0.7#54.95$Moment Retrieval#Charades-STA#R@1 IoU=0.5#48.31$Moment Retrieval#Charades-STA#R@1 IoU=0.7#29.25$Moment Retrieval#Charades-STA#R@5 IoU=0.5#88.79$Moment Retrieval#Charades-STA#R@5 IoU=0.7#56.08$Highlight Detection#YouTube Highlights#mAP#74.9$Highlight Detection#TvSum#mAP#83.1$Highlight Detection#QVHighlights#mAP#39.12$Highlight Detection#QVHighlights#mAP#38.18
2107.10649v1.pdf	Question-Answer categorization#QC-Science#R@5#0.86$Question-Answer categorization#QC-Science#R@10#0.92$Question-Answer categorization#QC-Science#R@15#0.95$Question-Answer categorization#QC-Science#R@20#0.96$Question-Answer categorization#QC-Science#R@5#0.85$Question-Answer categorization#QC-Science#R@10#0.93$Question-Answer categorization#QC-Science#R@20#0.97$Question-Answer categorization#QC-Science#R@5#0.79$Question-Answer categorization#QC-Science#R@10#0.89$Question-Answer categorization#QC-Science#R@15#0.93$Question-Answer categorization#QC-Science#R@20#0.95$Question-Answer categorization#QC-Science#R@5#0.76$Question-Answer categorization#QC-Science#R@10#0.87$Question-Answer categorization#QC-Science#R@15#0.92$Question-Answer categorization#QC-Science#R@20#0.94$Question-Answer categorization#QC-Science#R@5#0.72$Question-Answer categorization#QC-Science#R@10#0.86$Question-Answer categorization#QC-Science#R@15#0.91$Question-Answer categorization#QC-Science#R@5#0.30$Question-Answer categorization#QC-Science#R@10#0.40$Question-Answer categorization#QC-Science#R@15#0.47$Question-Answer categorization#QC-Science#R@20#0.52
2106.09672v4.pdf	Image Similarity Detection#DISC21 dev#w/o normalization#17.32$Image Similarity Detection#DISC21 dev#with normalization#37.15$Image Similarity Detection#DISC21 dev#Time (ms)#150$Image Similarity Detection#DISC21 dev#hardware#Tesla P-100$Image Similarity Detection#DISC21 dev#dimension#1500$Image Similarity Detection#DISC21 dev#w/o normalization#16.47$Image Similarity Detection#DISC21 dev#with normalization#36.42$Image Similarity Detection#DISC21 dev#Time (ms)#23$Image Similarity Detection#DISC21 dev#hardware#Tesla V100$Image Similarity Detection#DISC21 dev#dimension#256$Image Similarity Detection#DISC21 dev#w/o normalization#15.56$Image Similarity Detection#DISC21 dev#hardware#CPU, 2.2 GHz, 40 threads$Image Similarity Detection#DISC21 dev#dimension#960$Image Similarity Detection#DISC21 dev#w/o normalization#14.42$Image Similarity Detection#DISC21 dev#Time (ms)#0.55
2005.13209v2.pdf	EditCompletion#C# EditCompletion#Accuracy#53.2$EditCompletion#C# EditCompletion#Accuracy#41.4$EditCompletion#C# EditCompletion#Accuracy#40.9$EditCompletion#C# EditCompletion#Accuracy#32.6$EditCompletion#C# EditCompletion#Accuracy#30.7$EditCompletion#C# EditCompletion#Accuracy#25.5$EditCompletion#C# EditCompletion#Accuracy#22.5
1911.07034v2.pdf	Instance Shadow Detection#SOBA#Bounding Box SOAP 50#50.5$Instance Shadow Detection#SOBA#Bounding Box SOAP 75#16.4$Instance Shadow Detection#SOBA#Bounding Box SOAP#21.8$Instance Shadow Detection#SOBA#mask SOAP 50#50.9$Instance Shadow Detection#SOBA#mask SOAP 75#14.4$Instance Shadow Detection#SOBA#mask SOAP#21.6$Instance Shadow Detection#SOBA#Bounding Box SOAP 50#47.8$Instance Shadow Detection#SOBA#Bounding Box SOAP#19.6$Instance Shadow Detection#SOBA#mask SOAP 50#48.1$Instance Shadow Detection#SOBA#mask SOAP 75#12.5$Instance Shadow Detection#SOBA#mask SOAP#20.1$Instance Shadow Detection#SOBA#Bounding Box SOAP 50#40.3$Instance Shadow Detection#SOBA#Bounding Box SOAP 75#14.0$Instance Shadow Detection#SOBA#Bounding Box SOAP#16.7$Instance Shadow Detection#SOBA#mask SOAP 50#41$Instance Shadow Detection#SOBA#mask SOAP 75#10$Instance Shadow Detection#SOBA#mask SOAP#16.7
1902.02860v3.pdf	Crop Yield Prediction#2018 Syngenta (2016 val)#RMSE#12.79
2108.02481v1.pdf	Point Cloud Quality Assessment#M-PCCD#Pearson Correlation Coefficient#95.6
2104.06903v1.pdf	Line Detection#NKL#F_measure (EA)#0.803$Line Detection#SEL#AUC_F#86.83$Line Detection#SEL#HIoU#81.03
2003.04676v4.pdf	Line Detection#NKL#F_measure (EA)#0.719
2203.15285v1.pdf	Line Detection#SEL#AUC_F#86.29$Line Detection#SEL#HIoU#80.23
2210.17517v1.pdf	Mathematical Reasoning#Lila (IID)#Accuracy#0.604$Mathematical Reasoning#Lila (IID)#Accuracy#0.48$Mathematical Reasoning#Lila (IID)#Accuracy#0.394$Mathematical Reasoning#Lila (IID)#Accuracy#0.384$Mathematical Reasoning#Lila (IID)#Accuracy#0.252$Mathematical Reasoning#Lila (IID)#Accuracy#0.204$Mathematical Reasoning#Lila (OOD)#Accuracy#0.586$Mathematical Reasoning#Lila (OOD)#Accuracy#0.448$Mathematical Reasoning#Lila (OOD)#Accuracy#0.384$Mathematical Reasoning#Lila (OOD)#Accuracy#0.268$Mathematical Reasoning#Lila (OOD)#Accuracy#0.238$Mathematical Reasoning#Lila (OOD)#Accuracy#0.177
2110.13100v1.pdf	Parameter Prediction#ImageNet#Top 5 Accuracy (ID-test)#27.2$Parameter Prediction#ImageNet#Top 5 Accuracy (Wide)#19.4$Parameter Prediction#ImageNet#Top 5 Accuracy (Deep)#24.7$Parameter Prediction#ImageNet#Top 5 Accuracy (Dense)#26.4$Parameter Prediction#ImageNet#Top 5 Accuracy (BN-free)#7.2$Parameter Prediction#ImageNet#Top 5 Accuracy (ResNet-50)#5.3$Parameter Prediction#ImageNet#Top 5 Accuracy (ViT)#4.4$Parameter Prediction#CIFAR10#Classification Accuracy (Deep)#60.5$Parameter Prediction#CIFAR10#Classification Accuracy (ID-test)#66.9$Parameter Prediction#CIFAR10#Classification Accuracy (Wide)#64$Parameter Prediction#CIFAR10#Classification Accuracy (Dense)#65.8$Parameter Prediction#CIFAR10#Classification Accuracy (BN-free)#36.8$Parameter Prediction#CIFAR10#Classification Accuracy (ResNet-50)#58.6$Parameter Prediction#CIFAR10#Classification Accuracy (ViT)#11.4
2108.03576v1.pdf	Online Beat Tracking#Ballroom#F1#77.41$Online Beat Tracking#Ballroom#F1#70.79$Online Beat Tracking#Ballroom#F1#56.73$Online Beat Tracking#GTZAN#F1#75.44$Online Beat Tracking#GTZAN#F1#74.18$Online Beat Tracking#GTZAN#F1#73.77$Online Beat Tracking#GTZAN#F1#68.99$Online Beat Tracking#GTZAN#F1#64.63$Online Beat Tracking#GTZAN#F1#57.09$Online Beat Tracking#Rock Corpus#F1#73.13$Online Beat Tracking#Rock Corpus#F1#68.55$Online Beat Tracking#Rock Corpus#F1#59.83
2111.00704v2.pdf	Online Beat Tracking#GTZAN#F1#76.48
1507.03196v1.pdf	Font Recognition#AdobeVFR real#Top-1 Error Rate#28.58$Font Recognition#AdobeVFR real#Top 5 Error Rate#18.21$Font Recognition#AdobeVFR real#Top 1 Accuracy#71.42$Font Recognition#AdobeVFR real#Top 5 Accuracy#81.79$Font Recognition#VFR-Wild#Top-1 Error Rate#38.15$Font Recognition#VFR-Wild#Top 5 Error Rate#20.62$Font Recognition#VFR-Wild#Top 1 Accuracy#61.85$Font Recognition#VFR-Wild#Top 5 Accuracy#79.38$Font Recognition#AdobeVFR syn#Top-1 Error Rate#1.03$Font Recognition#AdobeVFR syn#Top 5 Error Rate#0$Font Recognition#AdobeVFR syn#Top 1 Accuracy#98.97$Font Recognition#AdobeVFR syn#Top 5 Accuracy#100$Font Recognition#AdobeVFR syn#Top-1 Error Rate#6.58$Font Recognition#AdobeVFR syn#Top 1 Accuracy#93.42$Font Recognition#AdobeVFR syn#Top-1 Error Rate#7.4$Font Recognition#AdobeVFR syn#Top 1 Accuracy#92.6
2110.10872v1.pdf	Font Recognition#AdobeVFR real#Top 1 Accuracy#47.41$Font Recognition#AdobeVFR real#Top 5 Accuracy#65.11$Font Recognition#Explor_all#Top 1 Accuracy#86.31$Font Recognition#Explor_all#Top 5 Accuracy#98.48$Font Recognition#AdobeVFR syn#Top 1 Accuracy#98.23$Font Recognition#AdobeVFR syn#Top 5 Accuracy#99.98
2103.16150v1.pdf	Font Recognition#AdobeVFR syn#Top 1 Accuracy#78.2
2111.05464v1.pdf	Adversarial Robustness#ImageNet#Accuracy#77.4$Adversarial Robustness#ImageNet#Accuracy#76.9$Adversarial Robustness#ImageNet#Accuracy#76.8$Adversarial Robustness#ImageNet#Accuracy#76.4$Adversarial Robustness#Stylized ImageNet#Accuracy#13.0$Adversarial Robustness#Stylized ImageNet#Accuracy#8.4$Adversarial Robustness#Stylized ImageNet#Accuracy#8.3$Adversarial Robustness#Stylized ImageNet#Accuracy#8.1$Adversarial Robustness#ImageNet-C#mean Corruption Error (mCE)#48.0$Adversarial Robustness#ImageNet-C#mean Corruption Error (mCE)#56.9$Adversarial Robustness#ImageNet-C#mean Corruption Error (mCE)#57.9$Adversarial Robustness#ImageNet-C#mean Corruption Error (mCE)#59.3$Adversarial Robustness#ImageNet-A#Accuracy#12.2$Adversarial Robustness#ImageNet-A#Accuracy#3.3$Adversarial Robustness#ImageNet-A#Accuracy#3.2$Adversarial Robustness#ImageNet-A#Accuracy#3.1
2111.02840v2.pdf	Adversarial Robustness#AdvGLUE#Accuracy#0.6086$Adversarial Robustness#AdvGLUE#Accuracy#0.5922$Adversarial Robustness#AdvGLUE#Accuracy#0.5682$Adversarial Robustness#AdvGLUE#Accuracy#0.5371$Adversarial Robustness#AdvGLUE#Accuracy#0.5048$Adversarial Robustness#AdvGLUE#Accuracy#0.5021$Adversarial Robustness#AdvGLUE#Accuracy#0.4603$Adversarial Robustness#AdvGLUE#Accuracy#0.4169$Adversarial Robustness#AdvGLUE#Accuracy#0.3369$Adversarial Robustness#AdvGLUE#Accuracy#0.3029
1908.07007v1.pdf	Uncropping#Places2 val#FID#11.8$Uncropping#Places2 val#PD#129.3$Uncropping#Places2 val#Fool rate#20.7
2111.12591v2.pdf	Partial Point Cloud Matching#4DMatch#NFMR#83.9$Partial Point Cloud Matching#4DMatch#IR#80.9$Partial Point Cloud Matching#4DMatch#NFMR#83.7$Partial Point Cloud Matching#4DMatch#IR#82.7$Partial Point Cloud Matching#4DMatch#NFMR#82.2$Partial Point Cloud Matching#4DMatch#IR#85.4$Partial Point Cloud Matching#4DMatch#NFMR#56.8$Partial Point Cloud Matching#4DMatch#IR#59.3$Partial Point Cloud Matching#4DMatch#NFMR#56.4$Partial Point Cloud Matching#4DMatch#IR#60.4$Partial Point Cloud Matching#4DMatch#NFMR#56.1$Partial Point Cloud Matching#4DMatch#IR#55.3$Partial Point Cloud Matching#4DMatch#NFMR#55.5$Partial Point Cloud Matching#4DMatch#IR#54.7$Partial Point Cloud Matching#4DMatch#NFMR#53.3$Partial Point Cloud Matching#4DMatch#IR#60$Partial Point Cloud Matching#4DMatch#NFMR#51.6$Partial Point Cloud Matching#4DMatch#IR#52.7
2210.05549v1.pdf	Continual Pretraining#AG News#F1 - macro#63.77
2204.08454v3.pdf	Semi-supervised Change Detection#WHU - 20% labeled data#IoU#74.8$Semi-supervised Change Detection#WHU - 40% labeled data#IoU#77.2$Semi-supervised Change Detection#LEVIR-CD - 5% labeled data#IoU#72.5$Semi-supervised Change Detection#WHU - 5% labeled data#IoU#65.8$Semi-supervised Change Detection#WHU - 10% labeled data#IoU#68.1$Semi-supervised Change Detection#LEVIR-CD - 40% labeled data#IoU#77.2$Semi-supervised Change Detection#LEVIR-CD - 10% labeled data#IoU#75.5$Semi-supervised Change Detection#LEVIR-CD - 20% labeled data#IoU#76.2
2107.02233v3.pdf	Classification#BiasBios#1:1 Accuracy#86
2209.14774v1.pdf	Classification#HOWS#Overall accuracy after last sequence#57.83$Classification#HOWS long#Overall accuracy after last sequence#40,65
2010.02146v2.pdf	Classification#CWRU Bearing Dataset#10 fold Cross validation#7
2208.03558v1.pdf	Classification#Chest X-Ray Images (Pneumonia)#Accuracy#98.41
2203.07665v1.pdf	Multi-agent Integration#BBAI Dataset#P@1#83.55
2203.11163v2.pdf	Math Information Retrieval#ARQMath2 - Task 1#P@10#0.276$Math Information Retrieval#ARQMath2 - Task 1#NDCG#0.447$Math Information Retrieval#ARQMath2 - Task 1#MAP#0.215$Math Information Retrieval#ARQMath2 - Task 1#P@10#0.252$Math Information Retrieval#ARQMath2 - Task 1#bpref#0.202
2207.07646v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#64.7$Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#60.8$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#87.1$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#82.6
2101.07042v3.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#43.2$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#53.9$Zero-Shot Action Recognition#Olympics#Top-1 Accuracy#68.4
2205.01657v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#41.1$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#58.7$Zero-Shot Action Recognition#ActivityNet#Top-1 Accuracy#32.5
2203.15381v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#39$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#58
2108.02833v2.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#35.3$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#51.8$Zero-Shot Action Recognition#Olympics#Top-1 Accuracy#60.2$Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#42.1$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#73.1$Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#37.1$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#69.3
2003.01455v4.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#32.7$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#48$Zero-Shot Action Recognition#ActivityNet#Top-1 Accuracy#26.6
1706.09317v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#21.8$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#24.4
1611.08663v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#19.7$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#15.8$Zero-Shot Action Recognition#Olympics#Top-1 Accuracy#44.3
1510.06939v1.pdf	Zero-Shot Action Recognition#HMDB51#Top-1 Accuracy#15.6$Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#30.3
1502.01540v1.pdf	Zero-Shot Action Recognition#UCF101#Top-1 Accuracy#10.9
1611.05088v4.pdf	Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#23.6$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#49.5
2008.12432v1.pdf	Zero-Shot Action Recognition#Kinetics#Top-1 Accuracy#22.3$Zero-Shot Action Recognition#Kinetics#Top-5 Accuracy#49.7
2203.16434v2.pdf	Spatio-Temporal Video Grounding#VidSTG#Declarative m_vIoU#30.4$Spatio-Temporal Video Grounding#VidSTG#Declarative vIoU@0.3#42.5$Spatio-Temporal Video Grounding#VidSTG#Declarative vIoU@0.5#28.2$Spatio-Temporal Video Grounding#VidSTG#Interrogative m_vIoU#25.7$Spatio-Temporal Video Grounding#VidSTG#Interrogative vIoU@0.3#35.7$Spatio-Temporal Video Grounding#VidSTG#Interrogative vIoU@0.5#23.2$Spatio-Temporal Video Grounding#HC-STVG1#m_vIoU#32.4$Spatio-Temporal Video Grounding#HC-STVG1#vIoU@0.3#49.8$Spatio-Temporal Video Grounding#HC-STVG1#vIoU@0.5#23.5$Spatio-Temporal Video Grounding#HC-STVG2#Val m_vIoU#36.4$Spatio-Temporal Video Grounding#HC-STVG2#Val vIoU@0.3#58.8$Spatio-Temporal Video Grounding#HC-STVG2#Val vIoU@0.5#30.6
2207.02756v1.pdf	Spatio-Temporal Video Grounding#HC-STVG2#Val m_vIoU#38.7$Spatio-Temporal Video Grounding#HC-STVG2#Val vIoU@0.3#65.5$Spatio-Temporal Video Grounding#HC-STVG2#Val vIoU@0.5#33.8
2206.15157v1.pdf	2D object detection#Clear Weather#clear hard (AP)#79.48$2D object detection#Dense Fog#light fog hard (AP)#86.5$2D object detection#Dense Fog#dense fog hard (AP)#78.21$2D object detection#Dense Fog#snow/rain hard (AP)#78.09
1902.08913v3.pdf	2D object detection#Clear Weather#clear hard (AP)#79.46$2D object detection#Dense Fog#light fog hard (AP)#84.9$2D object detection#Dense Fog#dense fog hard (AP)#76.69$2D object detection#Dense Fog#snow/rain hard (AP)#77.85
2205.03346v1.pdf	2D object detection#ExDark#mAP#77.7
2204.02380v1.pdf	Explanation Generation#CLEVR-X#B4#87.4$Explanation Generation#CLEVR-X#M#58.9$Explanation Generation#CLEVR-X#RL#93.4$Explanation Generation#CLEVR-X#C#639.8$Explanation Generation#CLEVR-X#Acc#63.0$Explanation Generation#CLEVR-X#B4#78.8$Explanation Generation#CLEVR-X#M#52.5$Explanation Generation#CLEVR-X#RL#85.8$Explanation Generation#CLEVR-X#C#566.8$Explanation Generation#CLEVR-X#Acc#80.3
2204.05312v1.pdf	Nature-Inspired Optimization Algorithm#CIFAR-10#training time (s)#23$Nature-Inspired Optimization Algorithm#CIFAR-10#training time (s)#50$Nature-Inspired Optimization Algorithm#MNIST#training time (s)#227$Nature-Inspired Optimization Algorithm#MNIST#training time (s)#282
2205.06175v2.pdf	Skill Generalization#RGB-Stacking#Group 1#24.5$Skill Generalization#RGB-Stacking#Group 2#33$Skill Generalization#RGB-Stacking#Group 3#50.5$Skill Generalization#RGB-Stacking#Group 4#76.5$Skill Generalization#RGB-Stacking#Group 5#66.5$Skill Generalization#RGB-Stacking#Average#50.2$Skill Mastery#RGB-Stacking#Group 1#58$Skill Mastery#RGB-Stacking#Group 2#57.6$Skill Mastery#RGB-Stacking#Group 3#78.5$Skill Mastery#RGB-Stacking#Group 4#89$Skill Mastery#RGB-Stacking#Group 5#95.1$Skill Mastery#RGB-Stacking#Average#75.6
2110.06192v2.pdf	Skill Generalization#RGB-Stacking#Group 1#23$Skill Generalization#RGB-Stacking#Group 2#39.3$Skill Generalization#RGB-Stacking#Group 3#39.3$Skill Generalization#RGB-Stacking#Group 4#77.5$Skill Generalization#RGB-Stacking#Group 5#66$Skill Generalization#RGB-Stacking#Average#49$Skill Mastery#RGB-Stacking#Group 1#75.6$Skill Mastery#RGB-Stacking#Group 2#60.8$Skill Mastery#RGB-Stacking#Group 3#70.8$Skill Mastery#RGB-Stacking#Group 4#87.8$Skill Mastery#RGB-Stacking#Group 5#78.3$Skill Mastery#RGB-Stacking#Average#74.6
2203.00680v3.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#91.2
2112.05213v1.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.9
2008.00305v2.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.7
1901.08396v2.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.6
1811.02744v1.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#90.2
1712.07262v2.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#88.4
1907.12704v1.pdf	3D Point Cloud Linear Classification#ModelNet40#Overall Accuracy#88.4
2206.02336v2.pdf	Arithmetic Reasoning#GSM8K#Accuracy#83.2$Arithmetic Reasoning#GSM8K#Parameters#175
2203.11171v3.pdf	Arithmetic Reasoning#GSM8K#Accuracy#74.4$Arithmetic Reasoning#GSM8K#Parameters#540
2210.16257v1.pdf	Arithmetic Reasoning#GSM8K#Accuracy#63.2$Arithmetic Reasoning#GSM8K#Parameters#12
2205.11916v3.pdf	Arithmetic Reasoning#GSM8K#Accuracy#58.1$Arithmetic Reasoning#GSM8K#Parameters#540$Arithmetic Reasoning#GSM8K#Accuracy#55.0$Arithmetic Reasoning#GSM8K#Parameters#175$Arithmetic Reasoning#GSM8K#Accuracy#51.5$Arithmetic Reasoning#GSM8K#Accuracy#41.3$Arithmetic Reasoning#GSM8K#Accuracy#40.7$Arithmetic Reasoning#GSM8K#Accuracy#17.9$Arithmetic Reasoning#GSM8K#Accuracy#10.4$Arithmetic Reasoning#MultiArith#Accuracy#78.7$Arithmetic Reasoning#MultiArith#Accuracy#17.7
2204.02782v3.pdf	Initial Structure to Relaxed Energy (IS2RE)#OC20#Energy MAE#0.348
2203.09697v1.pdf	Initial Structure to Relaxed Energy (IS2RE)#OC20#Energy MAE#0.3712
2106.09575v1.pdf	Initial Structure to Relaxed Energy (IS2RE)#OC20#Energy MAE#0.436675
2106.07971v2.pdf	Initial Structure to Relaxed Energy (IS2RE)#OC20#Energy MAE#0.47225
2210.03117v1.pdf	Prompt Engineering#ImageNet-R#Top-1 accuracy %#76.98$Prompt Engineering#UCF101#Harmonic mean#80.82$Prompt Engineering#ImageNet-A#Top-1 accuracy %#50.90$Prompt Engineering#ImageNet#Harmonic mean#73.47$Prompt Engineering#EuroSAT#Harmonic mean#82.35$Prompt Engineering#ImageNet-S#Top-1 accuracy %#49.15$Prompt Engineering#ImageNet V2#Top-1 accuracy %#64.07$Prompt Engineering#FGVC-Aircraft#Harmonic mean#36.50$Prompt Engineering#SUN397#Harmonic mean#79.75
2203.05557v2.pdf	Prompt Engineering#ImageNet-R#Top-1 accuracy %#76.18$Prompt Engineering#UCF101#Harmonic mean#77.64$Prompt Engineering#ImageNet-A#Top-1 accuracy %#50.63$Prompt Engineering#EuroSAT#Harmonic mean#28.75$Prompt Engineering#ImageNet-S#Top-1 accuracy %#48.75$Prompt Engineering#ImageNet V2#Top-1 accuracy %#64.07$Prompt Engineering#FGVC-Aircraft#Harmonic mean#27.74$Prompt Engineering#SUN397#Harmonic mean#78.27
2201.01928v1.pdf	Active Speaker Localization#EasyCom#ASL mAP#0.8632
2206.05149v1.pdf	Referring Image Matting (Prompt-based)#RefMatte#SAD#11.05$Referring Image Matting (Prompt-based)#RefMatte#MSE#0.0037$Referring Image Matting (Prompt-based)#RefMatte#MAD#0.0063$Referring Image Matting (Prompt-based)#RefMatte#SAD#12.95$Referring Image Matting (Prompt-based)#RefMatte#MSE#0.0045$Referring Image Matting (Prompt-based)#RefMatte#MAD#0.0074$Referring Image Matting (Expression-based)#RefMatte#SAD#55.38$Referring Image Matting (Expression-based)#RefMatte#MSE#0.0289$Referring Image Matting (Expression-based)#RefMatte#MAD#0.0313$Referring Image Matting (Expression-based)#RefMatte#SAD#57.08$Referring Image Matting (Expression-based)#RefMatte#MSE#0.0296$Referring Image Matting (Expression-based)#RefMatte#MAD#0.0323
2009.12664v1.pdf	Multispectral Object Detection#KAIST Multispectral Pedestrian Detection Benchmark#Reasonable Miss Rate#6.13$Multispectral Object Detection#FLIR-aligned#mAP50#72.4
2205.13445v1.pdf	Human Judgment Correlation#Flickr8k-Expert#Kendall's Tau-c#54.9$Human Judgment Correlation#Flickr8k-CF#Kendall's Tau-b#37.3$Human Judgment Classification#Pascal-50S#Mean Accuracy#85.2
2104.08718v3.pdf	Human Judgment Correlation#Flickr8k-Expert#Kendall's Tau-c#53.0$Human Judgment Correlation#Flickr8k-Expert#Kendall's Tau-c#51.2$Human Judgment Correlation#Flickr8k-CF#Kendall's Tau-b#36.4$Human Judgment Correlation#Flickr8k-CF#Kendall's Tau-b#34.4$Human Judgment Classification#Pascal-50S#Mean Accuracy#83.1$Human Judgment Classification#Pascal-50S#Mean Accuracy#80.7
2207.07027v1.pdf	Phenotype classification#MIMIC-CXR, MIMIC-IV#AUROC#0.77
2102.02335v1.pdf	Fact Checking#CDCD#Precision#0.26$Fact Checking#CDCD#Recall#0.11
2204.11241v1.pdf	Movie Recommendation#MovieLens 1M#NDCG#0.33$Movie Recommendation#MovieLens 1M#NDCG#0.32$Movie Recommendation#MovieLens 1M#NDCG#0.27
2110.10374v1.pdf	2048#2048#Average Score#1024$2048#2048#Average Score#256
2203.16518v1.pdf	Situation Recognition#imSitu#Top-1 Verb#44.66$Situation Recognition#imSitu#Top-1 Verb & Value#35.98$Situation Recognition#imSitu#Top-5 Verbs#73.31$Situation Recognition#imSitu#Top-5 Verbs & Value#57.76$Grounded Situation Recognition#SWiG#Top-1 Verb#44.66$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#35.98$Grounded Situation Recognition#SWiG#Top-1 Verb & Grounded-Value#29.05$Grounded Situation Recognition#SWiG#Top-5 Verbs#73.31$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#57.76$Grounded Situation Recognition#SWiG#Top-5 Verbs & Grounded-Value#46.25
2112.05375v1.pdf	Situation Recognition#imSitu#Top-1 Verb#44.2$Situation Recognition#imSitu#Top-1 Verb & Value#35.24$Situation Recognition#imSitu#Top-5 Verbs#71.21$Situation Recognition#imSitu#Top-5 Verbs & Value#55.75$Grounded Situation Recognition#SWiG#Top-1 Verb#44.2$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#35.24$Grounded Situation Recognition#SWiG#Top-1 Verb & Grounded-Value#29.22$Grounded Situation Recognition#SWiG#Top-5 Verbs#71.21$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#55.75$Grounded Situation Recognition#SWiG#Top-5 Verbs & Grounded-Value#46
2111.10135v1.pdf	Situation Recognition#imSitu#Top-1 Verb#40.63$Situation Recognition#imSitu#Top-1 Verb & Value#32.15$Situation Recognition#imSitu#Top-5 Verbs#69.81$Situation Recognition#imSitu#Top-5 Verbs & Value#54.13$Grounded Situation Recognition#SWiG#Top-1 Verb#40.63$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#32.15$Grounded Situation Recognition#SWiG#Top-1 Verb & Grounded-Value#25.49$Grounded Situation Recognition#SWiG#Top-5 Verbs#69.81$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#54.13$Grounded Situation Recognition#SWiG#Top-5 Verbs & Grounded-Value#42.5
2003.12058v1.pdf	Situation Recognition#imSitu#Top-1 Verb#39.94$Situation Recognition#imSitu#Top-1 Verb & Value#31.44$Situation Recognition#imSitu#Top-5 Verbs#67.6$Situation Recognition#imSitu#Top-5 Verbs & Value#51.88$Situation Recognition#imSitu#Top-1 Verb#39.36$Situation Recognition#imSitu#Top-1 Verb & Value#30.09$Situation Recognition#imSitu#Top-5 Verbs#65.51$Situation Recognition#imSitu#Top-5 Verbs & Value#50.16$Grounded Situation Recognition#SWiG#Top-1 Verb#39.94$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#31.44$Grounded Situation Recognition#SWiG#Top-1 Verb & Grounded-Value#24.86$Grounded Situation Recognition#SWiG#Top-5 Verbs#67.6$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#51.88$Grounded Situation Recognition#SWiG#Top-5 Verbs & Grounded-Value#40.6$Grounded Situation Recognition#SWiG#Top-1 Verb#39.36$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#30.09$Grounded Situation Recognition#SWiG#Top-1 Verb & Grounded-Value#22.73$Grounded Situation Recognition#SWiG#Top-5 Verbs#65.51$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#50.16$Grounded Situation Recognition#SWiG#Top-5 Verbs & Grounded-Value#36.6
1708.04320v1.pdf	Situation Recognition#imSitu#Top-1 Verb#36.72$Situation Recognition#imSitu#Top-1 Verb & Value#27.52$Situation Recognition#imSitu#Top-5 Verbs#61.90$Situation Recognition#imSitu#Top-5 Verbs & Value#45.39$Grounded Situation Recognition#SWiG#Top-1 Verb#36.72$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#27.52$Grounded Situation Recognition#SWiG#Top-5 Verbs#61.90$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#45.39
1703.06233v2.pdf	Situation Recognition#imSitu#Top-1 Verb#35.9$Situation Recognition#imSitu#Top-1 Verb & Value#27.45$Situation Recognition#imSitu#Top-5 Verbs#63.08$Situation Recognition#imSitu#Top-5 Verbs & Value#46.88$Grounded Situation Recognition#SWiG#Top-1 Verb#35.9$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#27.45$Grounded Situation Recognition#SWiG#Top-5 Verbs#63.08$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#46.88
1612.00901v1.pdf	Situation Recognition#imSitu#Top-1 Verb#34.12$Situation Recognition#imSitu#Top-1 Verb & Value#26.45$Situation Recognition#imSitu#Top-5 Verbs#62.59$Situation Recognition#imSitu#Top-5 Verbs & Value#46.88$Grounded Situation Recognition#SWiG#Top-1 Verb#34.12$Grounded Situation Recognition#SWiG#Top-1 Verb & Value#26.45$Grounded Situation Recognition#SWiG#Top-5 Verbs#62.59$Grounded Situation Recognition#SWiG#Top-5 Verbs & Value#46.88
2104.09570v2.pdf	Joint Event and Temporal Relation Extraction#TB-Dense#Event Detection F-score#91.0
1902.05377v1.pdf	Fine-Grained Urban Flow Inference#TaxiBJ-P3#MSE#20.2140$Fine-Grained Urban Flow Inference#TaxiBJ-P3#MAE#2.318$Fine-Grained Urban Flow Inference#TaxiBJ-P3#MAPE#0.315$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MSE#12.2570$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MAE#1.815$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MAPE#0.308$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MSE#12.666$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MAE#1.845$Fine-Grained Urban Flow Inference#TaxiBJ-P4#MAPE#0.309$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MSE#18.7402$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MAE#2.224$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MAPE#0.313$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MSE#19.2369$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MAE#2.258$Fine-Grained Urban Flow Inference#TaxiBJ-P2#MAPE#0.320$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#15.6025$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.011$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.327$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#16.1202$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.047$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.332$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#17.2723$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.368$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.614$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#17.2972$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.213$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.467$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#17.3388$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.457$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.713$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#17.6904$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.497$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.732$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#18.4642$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.491$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.714$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MSE#22.4770$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAE#2.251$Fine-Grained Urban Flow Inference#TaxiBJ-P1#MAPE#0.336
2208.12510v1.pdf	Partially Relevant Video Retrieval#ActivityNet Captions#Recall@Sum#140.1$Partially Relevant Video Retrieval#TVR#Recall@Sum#172.3$Partially Relevant Video Retrieval#Charades-STA#Recall@Sum#68.4
2209.06192v1.pdf	Story Continuation#PororoSV#FID#21.64$Story Continuation#PororoSV#Char-F1#40.28$Story Continuation#PororoSV#F-Acc#20.94$Story Continuation#PororoSV#FID#23.27$Story Continuation#PororoSV#Char-F1#40.25$Story Continuation#PororoSV#F-Acc#18.16$Story Continuation#PororoSV#FID#30.45$Story Continuation#PororoSV#Char-F1#39.32$Story Continuation#PororoSV#F-Acc#34.65$Story Continuation#PororoSV#FID#31.68$Story Continuation#PororoSV#Char-F1#35.29$Story Continuation#PororoSV#F-Acc#16.73$Story Continuation#FlintstonesSV#FID#28.37$Story Continuation#FlintstonesSV#Char-F1#74.28$Story Continuation#FlintstonesSV#F-Acc#52.35$Story Continuation#FlintstonesSV#FID#29.21$Story Continuation#FlintstonesSV#Char-F1#72.18$Story Continuation#FlintstonesSV#F-Acc#53.28$Story Continuation#FlintstonesSV#FID#35.04$Story Continuation#FlintstonesSV#Char-F1#73.94$Story Continuation#FlintstonesSV#F-Acc#52.72$Story Continuation#FlintstonesSV#FID#36.28$Story Continuation#FlintstonesSV#Char-F1#72.44$Story Continuation#FlintstonesSV#F-Acc#51.32
2210.01776v1.pdf	Blind Docking#PDBBind#Top-1 RMSD (%<2)#38.2±1.0$Blind Docking#PDBBind#Top-1 RMSD (Med.)#3.30±0.11$Blind Docking#PDBBind#Top-1 RMSD (%<2)#35.0±1.4$Blind Docking#PDBBind#Top-1 RMSD (Med.)#3.56±0.05$Blind Docking#PDBBind#Top-1 RMSD (%<2)#28.8$Blind Docking#PDBBind#Top-1 RMSD (Med.)#4.9$Blind Docking#PDBBind#Top-1 RMSD (Med.)#5.5$Blind Docking#PDBBind#Top-1 RMSD (%<2)#22.9$Blind Docking#PDBBind#Top-1 RMSD (Med.)#7.7$Blind Docking#PDBBind#Top-1 RMSD (%<2)#21.8$Blind Docking#PDBBind#Top-1 RMSD (Med.)#9.3$Blind Docking#PDBBind#Top-1 RMSD (%<2)#20.9$Blind Docking#PDBBind#Top-1 RMSD (%<2)#20.4$Blind Docking#PDBBind#Top-1 RMSD (Med.)#4.0$Blind Docking#PDBBind#Top-1 RMSD (Med.)#6.9$Blind Docking#PDBBind#Top-1 RMSD (%<2)#18.7$Blind Docking#PDBBind#Top-1 RMSD (Med.)#7.1
2202.05146v4.pdf	Blind Docking#PDBBind#Top-1 RMSD (%<2)#23.2$Blind Docking#PDBBind#Top-1 RMSD (Med.)#6.5$Blind Docking#PDBBind#Top-1 RMSD (%<2)#5.5$Blind Docking#PDBBind#Top-1 RMSD (Med.)#6.2
1909.09314v2.pdf	MuJoCo Games#Sawyer Pusher#Average Return#-27.16$MuJoCo Games#Point Maze#Average Return#-7.37$MuJoCo Games#Ant#Average Return#846.18$MuJoCo Games#Sweeper#Average Return#-74.17
1710.11248v2.pdf	MuJoCo Games#Ant#Average Return#127.61
2108.11667v1.pdf	Handwritten Text Recognition#HKR#CER#3.49$Handwritten Text Recognition#Saint Gall#CER#3.65$Handwritten Text Recognition#Bentham#CER#1.73$Handwritten Text Recognition#IAM-B#CER#3.77$Handwritten Text Recognition#IAM-D#CER#3.01$Handwritten Text Recognition#Digital Peter#CER#2.5
2205.14879v1.pdf	Handwritten Text Recognition#IAM#CER#2.75
2012.03868v2.pdf	Handwritten Text Recognition#IAM#CER#4.45$Handwritten Text Recognition#IAM#WER#14.55
2203.12273v3.pdf	Handwritten Text Recognition#READ 2016#CER (%)#3.22$Handwritten Text Recognition#READ 2016#WER (%)#13.63
